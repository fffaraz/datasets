Nice, can be very useful to when non-AWS tech. Is there anywhere I can read what all the API calls are? Also, to confirm, this doesn't contain a built-in DNS server but instead just aggs zones and zone changes and then the outside is expected to update their DNS server w/ zone changes from this?
A nice article, thanks.
Definitely plan on running outside AWS. This came up a few times recently. There are a small number of tables that can be moved over to Postgres or MySQL. For SQS, the interface is less well-defined but totally doable. I plan on opening an RFC and discussing it in the open. SQS is where the FS2 bits come into play, and it is a pull based / http interface. You are correct, VinylDNS is a front-end / interface. The way we run it all updates / integrations go through VinylDNS. You can imagine that out-of-band updates need to be synced. Right now, there is a manual "Sync" process to overlay VinylDNS with the authoritative backend. Having a DNS (or multiple DNS) as secondaries is something that we discussed. Should totally be possible. Thanks for reaching out!
Johnson Controls uses spark
A `foldLeft` call would do it I think. Also, avoid using `return` in Scala; it doesn't behave the same way as in Java and uses exceptions to return early. val last = arr.length - 1 val (diagonal1, diagonal2, _) = arr.foldLeft((0, 0, 0)) { case ((d1, d2, i), row) =&gt; (d1 + row(i), d2 + row(last - i), i + 1) } Math.abs(diagonal1 - diagonal2)
There are a huge number of companies using Spark. Far too many to list here I would guess. Going looking at job advertisements if you want to get an idea on what kinds of companies are using it.
[This should give you more information on how companies in the UK are using Spark.](https://www.itjobswatch.co.uk/jobs/uk/apache%20spark.do)
We are using Flink at www.districtm.ca which is in the adtech sector, not sure I'm really at liberty to say what exactly it does though.
Check your config, the first time you open a second project it asks you if you want to use the same window or a new one
&gt; www.districtm.ca Thanks for this. Do you use a 3rd party cloud computing service to handle the computation load? If so, which one and how has your experience been? I know that Google and AWS offer pretty great incentives so companies who use their services, I just want to see if it lives up to the hype, or if there are any other lesser known options I should be considering. Cheers!
I think that you are being unkind here. While you mention later that language could be the issue, it does not seem to stop you from claiming that u/Odersky is wrong, based on the assumption that *pure/no side effects* equates to *referentially transparent.* &gt;Except, **IO is 100% pure (referentially transparent)** Also in your talk that you linked, you seem to be again ready to believe that everyone else is wrong based on the same definition of *pure.* However, in my experience the more common meaning of *pure function* matches more the one given for example by Wikipedia: &gt;1. Its [return value](https://en.wikipedia.org/wiki/Return_statement) depends only on its [parameters](https://en.wikipedia.org/wiki/Parameter_(computer_programming)) and not on any internal or external state (such as local [static variables](https://en.wikipedia.org/wiki/Static_variable), [non-local variables](https://en.wikipedia.org/wiki/Non-local_variable) or inputs from [I/O devices](https://en.wikipedia.org/wiki/Input/output)). &gt; &gt;2. Its evaluation has no [side effect](https://en.wikipedia.org/wiki/Side_effect_(computer_science)) (such as mutation of local static variables or non-local variables, or performing I/O operations). According to that definition, `IO` is not pure in many cases, for example if it does I/O, and most of your criticism is based on `IO`'s supposed purity. No one of us gets to define what words mean, and it would be great if we could give others the benefit of the doubt before castigating them in public. Your post below about the benefits of IO is excellent and enlightening by the way.
Well there is an implicit scala subtitle instance in the scope of this subreddit
Those are some cool features! I've been wanting the auto completion of pattern matching branches since forever, and the implicit hints must be great for diving into new code/libraries - can't wait to play more with it. 
These kinds of under the hood articles really let the syntactic-sugar of Scala shine. Imagine if you had to do this all by hand for every class you wanted to have as a case class. Oh, wait, that's Java!
I finally had the time to sit down and finish reading it now. Scala.js is huge achievement, and the thesis is very well written as well. It makes me happy to see how such a principled development process pays off and leads to the friction free, performant and stable project we have today. Cheers for that, and congrats! :) 
Why don't Scala developers ever say thanks to JetBrains for all their hard work on Intellij? Since you folks won't, I will. Thanks! To JetBrains for doing an all too often thankless job for so many Scala developers! I sincerely appreciate your hard work on Scala!
What framework to use for Rest API integration tests? 
That problem is why I made my one contribution to the Akka project: [https://github.com/akka/akka/pull/20226](https://github.com/akka/akka/pull/20226). But, in general, I think it's interesting to consider the possibility of a syntactic context where a block is considered a *literal collection* of statements rather than a normal block. It would make for DSLs that are less noisy and less error prone.
Thank you :)
Also initial docs are up at http://vinyldns.io
I'm new to Scala. What are some libraries that everyone should know? So far, it seems that cats and fs2 implement a lot of useful fp stuff (I am familiar with functional programming already). I am also looking specifically for libraries for: * http, the simpler the better - if I can make a function from requests to responses and call it a day, I'll be happy. So far, http4s looks promising. * Databases - specifically, I'd like to interact with a postgres db. I prefer something strongly typed. Slick looks promising. * Json serialization. Haven't gotten around to look at these yet, so suggestions are welcome. If you know any alternatives that you feel are better than the ones I've listed, please let me know! 
&gt; I sincerely appreciate your hard work on Scala! Did you mean on IntelliJ? What's new in Scala that came from JetBrains?
We use AWS's EMR service for our deployments of both Flink and Spark but I don't know what kind of incentives you're talking about. We deploy on r3.xlarge and r4.2xlarge instances and it is pretty easy to get it set up with spark or flink, on yarn. It's pretty cheap too, like $0.03/hour/instance or something.
How practical is it to develop android apps in scala-android?
&gt; So is it less efficient than the imperative and oop coutnerparts? Frequently, yes. For games, absolutely. &gt; Would I actually be saving time writing code? Why do you think you're going to save time by writing a game in a language that doesn't have lots of support for writing games? 
Could it be done? Probably, people typically don't use the JVM when they have real-time performance requirements. Garbage collection and JIT make realtime performance nearly impossible to reason about. You could use scala-native without a GC, but you're one of a few people in the world to attempt game development in that context. So if you're looking to save time, it's not going to happen.
Have a look at what John Carmack has to say about FP in game dev - here is a start [https://www.gamasutra.com/view/news/169296/Indepth\_Functional\_programming\_in\_C.php](https://www.gamasutra.com/view/news/169296/Indepth_Functional_programming_in_C.php)
What about ScalaRX? Is FRP ever used in Scala?
Hi, can you paste the code you don't understand please? I remember that example for not any of the details. It would help you to get better help :)
I think that section in particular has an errata item mentioning this as a mistake in the published version. You are not taking crazy pills.
So use IO or Task instead of future. They are nearly identical in practice, other than you must call unsafeRun to eventually execute them.
It's not Scala, but I found F#+Monogame to be an enjoyable development experience. It was a very simple game, though -- it wasn't anything particularly intensive, so I can't speak to efficiency.
On Scala support for IntelliJ IDEA.
I recently installed the latest. It's gotten a lot faster, and feels more lightweight. Right now, it's certainly the best tooling for Scala. Nothing I've tried comes close.
Also, their collaboration on BSP
Return state is not stored anywhere because the purpose of this example is to show a bug when using just `nonNegativeLessThan` and not to show how to use the rng in general case. You are right that you have to pass in the state to execute `rollDie`which they do by passing `SimpleRNG(5)`. With the initial state `SimpleRNG(5)` they show the result is `0` which is not a valid die value. They fix it later by changing the definition to `def rollDie: Rand[Int] = map(nonNegativeLessThan(6))(_ + 1)`
Some of the Scala developers tried to do a game engine in a reactive programming way back in 2014. He has a nice presentation. He is talking about ask the things you have to look out for. GC problems on the jvm and so on. https://speakerdeck.com/axel22/a-reactive-3d-game-engine-in-scala?slide=19 Ps: generally speaking is it no problem to develop a game on the JVM. There are so many successful ones out there. So just pick the programming language you are most comfortable with.
It's very practical. I write all my games using functional programming (except for rendering), nowadays in Scala. There are no good game libraries written specifically for Scala as far as I know, but [LibGDX](https://libgdx.badlogicgames.com/) can be used with Scala and provides all you need to write a game, and there are many successful games running on the JVM. Compared to writing a game using Java or C++, you're definitely saving time once you've gotten used to it. Rendering code will be mostly the same, while game features will be both quicker to implement and easier to test. Performance is more or less equivalent to a C++ game core with Lua scripting, and game developers rarely find issue with *that*, so it shouldn't be an issue. And if it is, optimizing pure Scala code isn't *too* hard. 
Reminds me of https://medium.com/@maximilianofelice/builder-pattern-in-scala-with-phantom-types-3e29a167e863 with a good illustration of how phantom types help enforcing such rules.
Hi /u/lihaoyi , this looks great! By chance, do you have any plans to publish requests-scala against scala-native? I can see it coming well in hand with short-lived scripts server-side which I'm currently rewriting from python :)
Cool stuff! I've never heard of LibGDX. It says that it can target android so maybe I'll consider doing something there. How did you learn? 
 &gt; I think that you are being unkind here. [..] and it would be great if we could give others the benefit of the doubt before castigating them in public. I have nothing but the the outmost respect for Odersky's and his work. I do hope that criticism is still allowed though. Please note that I tried to word my comments to be aimed at Odersky's _post_, _statements_, or _comments_, and not at _him_. I'm making technical points based on what I can read here, not "castigating him in public". ----------------------- &gt; it does not seem to stop you from claiming that u/Odersky is wrong, based on the assumption that pure/no side effects equates to referentially transparent. No, most of my criticism does not depend on whether you want to define purity as referential transparency or not, because Odersky's original post doesn't challenge that. It stems instead because a distinction is drawn between referentially transparent code and IO-based code, whereas IO-based code is referentially transparent as well. You can see it here (emphasis mine): &gt; First, the type of a function tells you _whether_ it is referentially transparent _or_ has side-effects when run. &gt; The other argument for going to monads and IO is that it makes composition of effectful code more cumbersome than composition of pure code. [..] Using effects should be painful, so that you are pushed towards referentially transparent solutions _instead_. ------------------------ &gt; However, in my experience the more common meaning of pure function matches more the one given for example by Wikipedia: Its return value depends only on its parameters) and not on any internal or external state (such as local static variables, non-local variables or inputs from I/O devices). Its evaluation has no side effect) (such as mutation of local static variables or non-local variables, or performing I/O operations). **According to that definition, IO is not pure in many cases, for example if it does I/O, and most of your criticism is based on IO's supposed purity.** That's incorrect. Even according to this (lousy, imho) definition, a function returning `IO` still has zero side-effects. Compare: def sideEffectful: Unit = { println("hello") () } scala&gt; sideEffectful hello Side effects happen. def pure: IO[Unit] = IO { println("hello") () } scala&gt; pure res1: cats.effect.IO[Unit] = IO$407415524 Nothing happens (no side effects according to your definition), and you only get an `IO` value back. Now when you _run_ the resulting `IO`, things will happen, but that's consistent with saying that `unsafeRunSync` is not referentially transparent, and it goes back to the last paragraph of my initial point about there being no caller to observe it. Note that without referential transparency as the foundational concept, it's harder to make this difference precise, and it's even harder to see the point, since ultimately the runtime behaviour will be the same (and in fact that's what Paolo said above ;) ). This leads into the trap of thinking that `IO` is just a signalling mechanism. On the other hand, with referential transparency we get a more precise definition of side-effects, and more importantly we can clearly describe the difference between `IO`-based code and side-effectful code by explaining the different properties they have with respect to substitution, and from there argue for its benefits, like I did in the second part of my comment that you seemed to appreciate. ------------------ Finally, note that in Haskell-land the phrases "IO has side-effects" or "side effects are things like doing i/o or mutation" are used very liberally, all the time (especially in older publications), even by the likes of SPJ. When you already know pure FP and `IO`, this is mostly fine: it's an abuse of notation, but it's clear from the context. However, if you are a beginner or someone who's trying to understand the point of `IO` and purity, this is nothing short than a pedagogical disaster. Apart from the reasons explained above, it just leads to an immediate contradiction, because you hear: "Haskell is a purely functional language, which means it has no side-effects" "Haskell `IO` has side effects" These two statements contradict each other, and trying to square them leads to endless confusion, and it leads the way for more and more misconceptions, until people rightfully conclude that it makes zero sense. And in fact, newer texts like `Haskell from First Principles` and `Functional Programming in Scala` use referential transparency instead, which leads to no contradictions, it's more precise, and it allows to explain all the benefits I've already outlined above. 
I really wish someone could write a Scala binding for Godot game engine. As far as I know, it should be possible since the engine supports variety of ways to integrate non-official languages, and there are many open source language extensions even for such a language like Haskell.
Yes it is used quite widely in the scala.js community. There are loads and loads of libraries ( https://github.com/rtimush/scalatags-rx , https://github.com/OlivierBlanvillain/monadic-html/ , https://github.com/raquo/laminar ) for using FRP to develop UI in the browser. Imo the best lib for FRP at the moment is porbably Monix.
well if you depend on it then you must pass it as argument on every call. Simple as that. Why do you need more magic? And if you ask if we can do better than pass it at every function, yes we can, without magic. Proceed with book and you'll learn how.
If you want to make a game on the JVM I recommend looking at jmonkeyengine
With Gluon javafx-mobile it is fairly practical and you also get to use your app on basically all platforms. You can find the project here: [https://github.com/javafxports/javafxmobile-plugin](https://github.com/javafxports/javafxmobile-plugin) Take a look at these examples: [https://github.com/rladstaetter/fx-tictactoe](https://github.com/rladstaetter/fx-tictactoe) [https://github.com/gluonhq/gluon-samples/tree/master/gluon-SQLite-scala](https://github.com/gluonhq/gluon-samples/tree/master/gluon-SQLite-scala) All the other ways I could find are not really maintained any longer... sadly
Nobody should be using this anymore. There is a reason why this is called cake anti pattern. This has a number of downsides, e.g. high compile times, ultra long list of mixed in stuff. There are far better options, e.g. macwire.
Reasons to know cake pattern: 1. when you see it you know you should run
Very good article! Thanks üëç
I have received similar comments last week when I released the first part of this video, so you might be interested continuing this discussion [over here](https://www.reddit.com/r/scala/comments/90wpce/a_fully_working_example_of_the_good_old_cake/e2vimuq), especially since I will release the last part of this series next week. Thank You!
I have received similar comments last week when I released the first part of this video, so you might be interested continuing this discussion [over here](https://www.reddit.com/r/scala/comments/90wpce/a_fully_working_example_of_the_good_old_cake/e2vimuq), especially since I will release the last part of this series next week. Thank You!
There are good tutorials for LibGDX and also example projects, and if you run into issues there's a lot of documentation on Stack Overflow. As for learning how to write games, I picked a very simple game to start with, then added more complex features over time.
What about the scala android project in the sidebar? [http://scala-android.org/](http://scala-android.org/)
I wouldn't recommend the Scala clients for Redis as most of them are out of maintenance. Java clients are probably the way to go - [Jedis](https://github.com/xetorthio/jedis) as mentioned in the other reply is a good blocking client, and [Lettuce](https://lettuce.io/) is a good one with support for non-blocking operations.
Even the person who came up with the Cake pattern says no-one should use it.
Thank you for this series and please continue. I will see it soon. I'm happy someone goes to the effort of explaining this since the documentation I found around the web was confusing about it and never saw a clear working example of it working. Although I have seen it used in internal projects or variations of it which were never understandable or really useful. So these kind of videos and information is really good for people that will see this in other codebases and have no idea what they are looking at.
https://github.com/twilio/guardrail
Why not use the rest+json support for protobuf or for thrift? protobuf rest library: https://github.com/googleapis/googleapis/blob/master/google/api/http.proto protobuf json support: https://developers.google.com/protocol-buffers/docs/proto3#json thrift-over-http: https://medium.com/airbnb-engineering/building-services-at-airbnb-part-1-c4c1d8fa811b thrift human readable json: https://www.parsable.com/parsable-blog/using-human-readable-json-endpoints-with-thrift-for-free 
I agree this should not be taught to Scala beginners. We came a long way and found better ways to solve this problem (eg. MTL / Tagless Final). Appreciate the time the author put up on these videos though, I know it's not an easy task. But I'd suggest to focus your energy on something that people can recommend (from beginners to experts). That's my sincere feedback. 
Yep, using the swagger generators for Scala is a pretty bad experience. I've defaulted to writing the .yaml file by hand (it's pretty easy) and include a small parser + validator in a test that checks for typos and the like.
fp: the other main contender in this area is [scalaz](https://scalaz.github.io/). http: http4s is my favorite design at the moment, and worked great as a client, but when i last used it i had trouble getting it to handle more than ~1k/rps as a server. maybe that's improved in the last 2 years. i'd say start with this and just be aware that you might have to profile and switch to something else if you need to scale in place. databases: i use slick at work and it's.. fine.. i guess. i can't say i'm a fan. i'm looking for an opportunity to try [doobie](https://tpolecat.github.io/doobie/). json: json4s is nice and simple and works with case classes out of the box, but its not exactly built with performance in mind; it's serialization speed is especially poor if you require a number of custom serializers. [circe](https://circe.github.io/circe/) is the next one i want to try followed closely by [upickle](http://www.lihaoyi.com/upickle/). one nice thing is that http4s/doobie/circe are all built on top of the cats library so you can go all-in on that ecosystem and have a pretty unified setup. other fp things you didn't mention but might look into: - [monix](https://monix.io/), especially its `Task` vs cats' `IO` vs [scalaz-zio](https://github.com/scalaz/scalaz-zio) - [matryoshka](https://github.com/slamdata/matryoshka) - [shapeless](https://github.com/milessabin/shapeless)
Thank you! I'll look into doobie and circe for sure. I tried messing around with http4s and slick yesterday, and I liked slick well enough, but making it work with http4s was a bit clumsy. And thanks for the other recommendations too. I always find that the most time consuming part of learning a new language is learning the libraries, so it's great to have a shortlist of good/widely-used libraries. 
as for how to make it beneficial, usually it is done through using maps/flatmaps or their cleaner alternative - using for comprehensions.
They stopped really working on it mid 2017, as far as these graphs show: [https://github.com/scala-android/sbt-android/graphs/contributors](https://github.com/scala-android/sbt-android/graphs/contributors) (I don't have sources for the following statement right now, therefor don't quote me on this) I have read somewhere, that this is because of some back and forth between the scala developers and the scala-android team. Which is a shame So this might not give you a future proof integration, but depending on what you want to do with your android app, you should give it a try
Another alternative =&gt; [https://sangria-graphql.org/](https://sangria-graphql.org/)
You could try it with https://github.com/http4s/rho - they have built-in generation.
I have not worked on my template for some time, but this terrible spaghetti code: https://github.com/Daxten/bay-scalajs.g8/blob/master/codegen/src/main/scala/app/SwaggerCodegen.scala generates play routes as traits, which then have to be implemented by you. It also uses circe for encoding/decoding, but doesn't support constraints.
Swagger is a hacked solution to making unstructured APIs over HTTP look like structured APIs. It doesn't really fit and i share the same grievances, i often rip it out of code bases to get rid of the hassle. To me its solving the wrong problem. If you want swagger what you really want is grpc/thrift.
I'll try the gluon if its being updated while this one isn't. Thanks
Recently go laid off from a NYC startup and decided to use my newly found free time to re-write my **mini-java compiler** in Scala. It was our final project for the compilers course in college two years ago. Planning on implementing the Language Server Protocol using play and ANTLR4 for the parsing and syntax errors. Should be fun. Also, if anyone is looking for an experience Scala dev in the NYC area then lemme know :) .
If you use [uJson](http://www.lihaoyi.com/upickle/#uJson), you don't need to choose: - Just need case classes? Read/write directly to case classes - Need an AST? Read/write directly to the AST - Specifically want some *other* AST that's not the uJson AST? You can read/write directly to the circe/play-json/etc. ASTs too - Don't need case classes or an AST, and just want to pretty-print JSON? Read/write directly `String -&gt; String` - Don't need any output at all, and just want to parse+validate your JSON? You can do that too. ASTs are a thing you sometimes want, but they don't need to be in the critical path if you want some other thing. If you want one, great, if you want something else, a visitor-based library like uJson can give you that something else directly and without fuss.
In my experience it does not work that well and I had to manually code the models most of the time. In total I don't think it's worth switching from http4s-dsl to rho. 
Working on a data visualization project which graphically shows links between related subtopics in Mathematics. Based on data from MathSciNet.
CS student working on a Trello clone using this as the base project: [https://github.com/pauljamescleary/scala-pet-store](https://github.com/pauljamescleary/scala-pet-store). I'm a beginner to FP and Scala, but so far this has been really fun. :) Just trying to figure out how I should combine services now (creating a new Board should also create an initial task column for example).
Thanks for the reply. The incentives I was mentioning are only anecdotal. I have heard that AWS allows startups to use these features (like EMR) for free or super cheap compared to a freelancer or hobbyist. Thanks again for your info on this.
Oh, totally forgot about another json library I intend to try: [jsoniter-scala](https://github.com/plokhotnyuk/jsoniter-scala)
What do you mean by mini-java? As in it's a small ambition project that covers Java or a project that targets some specific subset of Java?
I'm currently working on how to use `scalacheck` more effectively with SQL queries.
I'm not sure what you're asking for.
Any use of FP in the role?
&gt; Where you use these tons of implicits in practice?) Implicits are a very powerful tool for library/DSL authors to make the syntax more palatable while retaining a lot of power/flexibility. I'd say best not to worry about them. They do not have a strong use case for "simple" code. It's a tool to make more advanced code look simple.
My bad, it's monthly: [https://www.reddit.com/r/scala/comments/933jzv/who\_is\_hiring\_monthly\_rscala\_job\_postings\_thread/](https://www.reddit.com/r/scala/comments/933jzv/who_is_hiring_monthly_rscala_job_postings_thread/)
I use implicit a great deal because the libraries I use require it - doobie, cats, http4s, circe, etc. I tend not to have to write many implicits because those libs provide what I need usually.
I couldn‚Äôt say one particular thing. If I had to pick it‚Äôs - never think you know everything. Example: some guy wrote a script to leverage something for us. Read what he wrote, pages and pages of code. I was mind boggled. He‚Äôs a 10+ year veteran. I rewrote it in 6 lines.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/scalaroasts] [So you say, but if you actually just pissed off, rather than repeatedly popping back up like an unwanted skin condition, we'd all be very grateful.](https://www.reddit.com/r/ScalaRoasts/comments/938ac2/so_you_say_but_if_you_actually_just_pissed_off/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/scalaroasts] [Well, \/u\/tsec-jmc is not known for being constructive](https://www.reddit.com/r/ScalaRoasts/comments/938inb/well_utsecjmc_is_not_known_for_being_constructive/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/scalaroasts] [Poor sarcasm from someone that probably has zero contributions, both to this channel and the Scala community ... Oh Reddit, you crack me up.](https://www.reddit.com/r/ScalaRoasts/comments/938jqq/poor_sarcasm_from_someone_that_probably_has_zero/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
Mini-java is a subset of java that supports only boolean and integers. You can check out the spec here: [http://www.cs.tufts.edu/\~sguyer/classes/comp181-2006/minijava.html](http://www.cs.tufts.edu/~sguyer/classes/comp181-2006/minijava.html)
any tips or tricks to share on getting that up and running? we are on a scala play framework stack, what about you?
I can only speak from personal experience working as a software engineer for 20 years. Most of the Java concepts I learned in the 90's (class inheritance, design patterns, XML configurations etc.) I would never use today and would gladly unlearn. They were just work arounds for limitations in the Java (and to a certain extent C++) programming language, and there are much simpler and better ways of doing it with FP. My take away from this was to focus on learning stuff that has a solid theoretical foundation in math or type theory, not best practices based on "experts" opinions and experiences. Those are the things that will stand the test of time.
Twilio's Guardrail is a code generation tool from OpenAPI/Swagger to akka-http and http4s.
Paidy | Software Engineer (semi-senior / senior) | Tokyo, Japan | ONSITE | Full Time We are expanding very quickly and are in need of hiring more devs to join our different teams. At the moment we have 3 different teams (using different tech stack). 1. Eff, Grafter, Akka (actors, cluster, persistence, http) 2. Typelevel stack: Cats, Cats-Effect, Http4s, Fs2, Circe, Shapeless, etc (the team I'm leading). 3. Data Science team: Spark, Akka persistence, Sttp, Http4s, Fs2. Contact me if interested: gabriel.volpe at paidy dot com. I'm frequently in the `http4s`, `cats-effect` and `cats` Gitter channels. 
\&gt; Does such strong language have no simpler examples of application? [https://github.com/lightbend/lightbend-emoji](https://github.com/lightbend/lightbend-emoji) :-)
I think that unlearning the acceptance of null and of varying values of truthiness would go a long way. Those concepts would probably never go away but rather strongly learning to reject them would go really long way.
The real takeaway for me from that was that ArchUnit existed. ``` noClasses().that().resideInAPackage("..domain..") .should().accessClassesThat() .resideInAPackage("..application..") ``` Is some black magic right there.
[removed]
One thing you can do with implicits is implicit classes, so you can add functions to other peoples objects. This sounds simple but in java and other languages is actually requires inheritance.
Interesting. I was thinking about this as well. I wonder if inheritance and related principles of OOP are gradually falling off CS curricula.
I've just added integration with Futures to [Airstream](https://github.com/raquo/Airstream), my state propagation and event streaming library. Not much time for open source work in the summer, so pretty happy that I squeezed that in! Overall I'm working on polishing [Laminar](https://github.com/raquo/Laminar) to production level.
What do you mean? 
The first thing that comes to my mind that I find hard switching to FP style code is mutable state. I think you should avoid using mutable state as much as possible. Use pure functions as much as possible. Of course, depending on the language, sometimes it just makes more sense to use variables instead of values and have some mutable state and some impure functions, but it's about how you approach a problem. A lot of problems can be solved without mutable state and mostly pure code with just as much complexity if not more. Some can't. This doesn't just go for Scala. Having learned Scala/Haskell has made me a better programmer even when I write Python code and I'm really glad I did it.
Scala's syntax for extension methods is actually rather verbose compared to other languages. True, Java doesn't have any, but that is a pretty low bar. 
I would consider use of a macro for such a small piece of functionality to be an anti-pattern, particularly with the concerns around support for macros in future versions of Scala. Realistically though MacWire is probably established enough that it will be supported. I don't see cake as an anti-pattern, even full cake, but like any pattern it's more verbose and cumbersome than it should be. Thin cake weakens some of the guarantees for the sake of a substantial code saving. That's usually a good tradeoff IMO, but it is a tradeoff.
Things I think we overuse due to legacy and would be better off moving away from (which is not to say there aren't niches where they still make sense, just that I don't think they should be the default that everyone learns to use): * IEEE754 floating-point * Non-UTF8 strings * Regular expressions * Exceptions * SQL * Relational databases * Control flow keywords * ACID * Fixed-precision arithmetic * Multi-user operating systems * General recursion Honestly I don't find much of the CS part of my degree that useful in retrospect - if anything I think I use more from the Maths course, even as a regular programmer working in industry.
Hopefully only the useful parts from OO will remain like traits (interfaces, type classes or whatever you wanna call them) and objects as modules. This is where Scala shines compared to other OO languages. I think the populatity of OO is fading as new languages like Rust and Go only have traits/interfaces and structs, not proper classes. It's a healthy trend.
What's the problem with SQL / Relational database?
Pretty much all that you described is still useful and one way or another, I still use pretty much all of what you're describing in my daily job. I agree that maybe one shouldn't have to know everything in detail (I don't think you need to know how the float is represented in memory and how many bits are used; but it's definitely worth knowing that two float point numbers may be slightly different even though they should be the same ) but they're still important concepts nonetheless. Even exceptions (agree, their awful) I don't really see how someone would work w/ Scala not knowing what they are / how they're used ..
SQL: not a machine-friendly representation even though that's what it's mostly used for these days (a few years ago MySQL showed some profiling results where 75% of the time to process a simple primary key fetch was spent parsing the SQL), COBOL-style uncanny-valley pseudo-English syntax, limited tooling, not at all compositional. Relational databases: cumbersome to represent collections, virtually impossible to represent sum types, tri-state logic is an unnatural and confusing model.
&gt; Pretty much all that you described is still useful and one way or another, I still use pretty much all of what you're describing in my daily job. Nothing ever goes away completely; everything that's ever been part of a CS curriculum is probably still in use *somewhere*. Most jobs use most of my list, but I think they're things the industry could and should move away from. &gt; Even exceptions (agree, their awful) I don't really see how someone would work w/ Scala not knowing what they are / how they're used .. They're a thing that happens but I don't think we need to cover them as a special-case topic the way I've seen CS courses do. You need them on the boundary and you might need to do something with uncaught exception handlers, but that's pragmatic plumbing rather than an important part of principled software design.
Objects as modules is one of the failings of OO. Classes were reused for modularity because classes was the only thing these languages had. A proper module system is superior 
You‚Äôre getting no comments because there isn‚Äôt really much to say. A good article. Even more so for people wanting to write their first action builders and struggling with the docs. I‚Äôm sure Google will send a lot of traffic your way.
That's where I'm not sure. Frameworks such as Spring tied into relational databases probably will always have a part to play in business applications, especially customer service. But it has taken me two years to come to grips with functional and distributed programming. So it seems to me that newcomers to the field are going to have a bunch more to learn (FP, noSQL, Hadoop type systems etc) while still needing to learn OOP, SQL etc.
TRue, but the best programmers in every team were warning us about this 20 years ago. In other words, we should never have learned mutable in the first place
(although last week I did create a field level var in scala (sigh))
&gt; Frameworks such as Spring tied into relational databases probably will always have a part to play in business applications, especially customer service. I don't get what you mean here, on multiple levels. Spring is primarily a DI framework, nothing to do with relational databases, and I don't see the connection to customer service. &gt; So it seems to me that newcomers to the field are going to have a bunch more to learn (FP, noSQL, Hadoop type systems etc) while still needing to learn OOP, SQL etc. Possibly. That's the nature of progress in any field though - there's always more for newcomers to learn because we're always discovering new things. I would hope that SQL and "extends" style OO will go away; direct support for delegation a la Kotlin (or even Go) offers an easier-to-understand way of doing OO, IMO. As we understand these things better we get better at teaching them. But there's only so much you can do.
I said Spring "tied into" relational databases. ....but for sure I left half the thought in my head. Trying to elaborate would probably require me sitting down, clarifying my thoughts for 15 minutes and trying to get it into a response. I'd be happy to do that, but only if my interlocutor is sufficiently interested in the topic. Let me know :)
Runar just made two new Scala libraries https://github.com/runarorama/latr https://github.com/runarorama/scala-mset 
JDK 9
Thanks for reply, but Im still missing something obvious. I went through state monad material on different resources and as I understood they were discussing about local effects eg one can chain multiple stateful actions inside a function. To put it other way: how should you develop REST service which would utilize the rollDie function on a get method, for an example?
and JDK 10 and JDK 11
In practice I've found this to basically neveratter because it trips a compile error on a type annotation somewhere near the error, and on top of that I find it very rare to use inheritance much at all barring ADTs
Me too! Any way to have ArchUnit work in sbt?
What languages are you referring to, Scala? And what do you mean by "proper module system", ML's module system? How is it superior to traits/objects?
"-Xlint:infer-any" Not perfect, but should help a bunch.
Is mixin-composition useless, since always in my cases that it can be replaced with object composition.
We do not have a date yet. The current version we are working on is 2.7. There are milestone releases for it already: https://blog.playframework.com/play-2-7-0-m2-released/ Anything you are specially interested?
[removed]
I don't think there's a meaningful difference between 'functional reactive programming' and 'reactive programming', other than the later might imply a more data driven approach. They're both still declarative approaches to defining the propagation of change. &gt; But is it needed to do FRP to perhaps make a game? No. People often mention FRP in the context of games, but I never understood the appeal. Having your game loop be a endomorphic function for some game state, and having a separate function describe operations to render a given game state always seemed like a much more appealing design to me.
Going out on a limb here, but I *think* JDK 12 might be next.
What does it do exactly?
Ah. It makes "an expression's inferred type was Any" into a warning, which combined with warnings-as-errors will help catch most (but not all) of the cases that you're likely to run into the "incompatible types lead to a widening at Any" problem.
images for text is not a good idea :)
FRP is just one model. [Elm](http://elm-lang.org/) is a good example of how to make web applications simple pure functional code that doesn't mention FRP concepts like signals, streams or behaviors. To some degree, you can also make games with Elm. However, since Elm produces HTML, there's no model for collision detection and response, or anything like that, so you'd have to write a lot of code to handle that. One could imagine an "Elm for games" that produced a 3D scene graph instead, where you could listen for collisions in the same manner you can listen for clicks in Elm. For Scala, see the side bar for a list of libraries. I maintain a React-based library [React4s](http://www.react4s.org/) that comes with support for writing purely functional webapps. 
I abuse it in my [static site generator](https://github.com/sake92/hepek). I could've make `PageSettings` class and compose it in a `Page`, but then you'd need to override it like this: `override def pageSettings = super.pageSetting.copy(title= "abc")`. With mixins it's just an override: `override def pageTitle ="abc"`. Of course, you get name clashes more easily so I needed to choose names carefully.
It's useful when you're actually using subtyping - you want `List(dog) :+ cat` to return `List[Animal]`. I'm not the right person to make the case for subtyping except to say that it's what sets Scala apart from other functional languages, so I don't see it going away (at least I hope not).
React4s is not based on scalajs-react - it's a fresh alternative to it that exposes a vastly simpler API. Simpler types, simpler lifecycle, no macros, no implicits. Everything but the first section on [react4s.org front page](http://www.react4s.org) are essentially differences from scalajs-react. 
Please post this in the monthly who's hiring threads
Yes, but you want to dig up the jars that Teradata provides for doing this sort of thing and you want to use JDBC. If you happen to be using Spark, then you can use some of the DataFrame methods as well. Unfortunately it's been a couple of years since I've done it so I can't dig up any example code for you, but I have done this, if it makes you feel more emboldened in your search. 
Thanks
Looking for four contractors to fill four Java/Scala Developer roles in either Glasgow, Edinburgh, Herfordshire or Belfast: [http://www.enigmapeople.com/job-details/226445000005772152/](http://www.enigmapeople.com/job-details/226445000005772152/) 
This is already fixed in Circe and the upcoming Scala JSON AST, also this issue isn't restricted to using AST's. If you were to parse directly into a case class you would get the same issue.
Yeah, I don't think type widening by itself is that bad. I think that widening all the way up to the top type is the problem. I think most Scala devs would be fine if Scala didn't have a singular top type but, unfortunately, the JVM disagrees.
I don't know much gradle (I use maven), but you probably need some kind of scala compilation plugin to get gradle to actually run the scala compiler on your code. Once you're actually compiling it, running it should be no different from running a java main (since it's the same kind of bytecode once it's compiled).
Will `CompositeProject` become a replacement of `crossProject`?
1) Circe doesn't sets a math context and doesn't limit a scale. ``` def toBigDecimal: Option[BigDecimal] = if (scale.compareTo(BiggerDecimal.MaxInt) &lt;= 0 &amp;&amp; scale.compareTo(BiggerDecimal.MinInt) &gt;= 0) { Some(new BigDecimal(unscaled, scale.intValue)) } else None ``` Where `BiggerDecimal.MinInt` and `BiggerDecimal.MaxInt` have values of `Int.MinValue` and `Int.MinValue` accordingly. So, your services that are open to the wild world can be easy DoS'ed, if you do not check the scale and the math context before any call of the following operations: https://github.com/scala/bug/issues/10882 2) Jsoniter-scala doesn't use maps when parsing case classes by codecs that are generated using its macro. Here is an example of generated code: https://github.com/plokhotnyuk/jsoniter-scala/blob/master/jsoniter-scala-core/src/test/scala/com/github/plokhotnyuk/jsoniter_scala/core/UserAPI.scala#L17-L139
&gt; Where BiggerDecimal.MinInt and BiggerDecimal.MaxInt have values of Int.MinValue and Int.MinValue accordingly. So, your services that are open to the wild world can be easy DoS'ed, if you do not check the scale and the math context before any call of the following operations: This isn't true, I have already tested trying to overflow circe with numbers of a large scale, with the exact code you have done in your scala ticket, i.e. "1e1000000000" As a JSON number, and it parsed it without hanging the CPU (at least last time I checked). Travis Brown (creator of Circe) actually this out to me when I made my own Json AST (which also doesn't have this problem since it doesn't even use `BigDecimal`)
This is in London, if anyone else is wondering.
You should put your scala code insode \`src/main/scala/com/.../\`
Here is a PR which reproduces hanging on `+ 1` after parsing BigDecimal with that level of scale by circe: https://github.com/plokhotnyuk/jsoniter-scala/pull/138/files Now just need to run `ArrayOfBigDecimalsBenchmarkSpec` test.
Ok, but now I get this error: :compileJava UP-TO-DATE :compileScala FAILED FAILURE: Build failed with an exception. * What went wrong: A problem was found with the configuration of task ':compileScala'. &gt; No value has been specified for property 'zincClasspath'. I have also added `compile group: 'org.scala-sbt', name: 'zinc-classpath_2.12', version: '1.2.0'` but I still get the error
I am sorry, this is quite different to what you are stating. Circe parses any size number fine, so if someone sends a JSON number with `"1e1000000000"` Circe will not use excessive CPU to parse it (which is what you were implying). This issue only comes up when you serialize the number directly to a BigDecimal (or bigger decimal) rather than something like a `Double` **and** you do math on it.
The gradle docs go over this. I'm on mobile so can't really help atm. But you need to provide gradle the main class and possibly a manifest for the classpaths 
so what database you prefer for structured data ?
Saying "database" is kind of begging the question. A lot of the time you don't need a database at all and would be better off with e.g. protocol buffers on the filesystem, or even just keeping data in memory - or, at the other end, with a streaming-based system like Kafka/Samza. For the cases where you actually do want a conventional datastore I'd generally use Cassandra but that's partly just experience; I've heard good things about Riak. Part of the problem I'm complaining about is that people just assume any application is going to need an RDBMS without really thinking about it; replacing RDBMS with any other word there you'd still have the same problem. Rather I'd say: think about your problem and what tools you might use to solve it. There are even times when a relational database is the answer, they're just a lot rarer than people think. 
Thank you. I tried what you suggested and indeed it worked with the system java. So they messed up with their custom patches. Although I will actually use the bundled one as it has better font rendering on linux. I chose to disable the follow focus option for now.
This was a really excellent tutorial.
I setup a simple project here: https://github.com/amdelamar/ScalaTest Hope this helps.
I mean I just want to write some of the classic games to get a feel of how functional programming would click in Scala. I was considering just using something like LWJGL or just plain openGL but I wasn't sure if that would be more hassle than convenience. Would you have any suggestions? I don't know much about the web front end :(. I know basic JS and HTML and that's about it(i hate JS)
Would you have any suggestions for what I could do? I was considering using LWJGL but I wasn't sure where to begin. What topics should I read on first so I can get an idea of what to do? 
I wouldn't recommend Jedis (or any Scala wrapper of it) at all. Go with Lettuce. And if you are keen on pure FP solutions I wrote this one: https://gvolpe.github.io/fs2-redis/ but still doesn't have support for Redis cluster (PRs welcome :) ) 
Here's the [gradle documentation for the scala plugin](https://docs.gradle.org/current/userguide/scala_plugin.html). And yeah, be sure to use the latest version of gradle :D
Here's the [gradle documentation for the scala plugin](https://docs.gradle.org/current/userguide/scala_plugin.html). And yeah, be sure to use the latest version of gradle :D
It took a while to get rolling, but it was well worth the watch in the end. It was really helpful to see how IO and State arise rather simply out of the need to defer side effects and keep things composable.
How do people build these type classes like his: trait Command[F[_]] { def getStrLn(): F[String] def putStrLn(string: String): F[Unit] } When you want to provide a richer typeclass with many methods implemented in terms of the others? You need a context bound on the F[_] like Monad, in order to combine results from the other methods, but context bounds don't work with traits because there's no trait params yet. Do people instead use abstract classes?
Yes, you can use an abstract class like you suggested. Another approach is to place the context bounds at the method definition level. Keep in mind that currently the context binding, `A : B` , is basically syntactic sugar that ends being converted to `(implicit ev: B[A])` by the Scala compiler. trait Command[F[_]] { def getStrLn: F[String] def get2StrLns(implicit ev: Monad[F]): F[String] = getStrLn.flatMap(a =&gt; getStrLn.map(b =&gt; a + "\n" + b)) def putStrLn(string: String): F[Unit] }
Either an abstract class or just an abstract method to provide the `Monad` (or `Applicative` or what have you) instance. One fun trick I've been using lately is that you can have an abstract class that traits then extend, so you can still use multiple inheritance if you need to. Something like: abstract class Monadic[F[_]](implicit val monad: Monad[F]) trait SomeCommands[F[_]] extends Monadic[F] { def someStep: F[String] final def compositeStep = for { a &lt;- someStep ; b &lt;- someStep } yield someFunction(a, b) } trait OtherCommands[F[_]] extends Monadic[F] { ... } class FullCommandImplementation extends Monadic[MyCommandType] with SomeCommands[MyCommandType] with OtherCommands[MyCommandType] { override def someStep = ... }
woah, what a surprise! congratulations Spark team!
This is weird, your comment shows up on my inbox but not in the thread itself.
CAP in practice :)
I wouldn't start with LWJGL if you want to make a purely functional game. I'd only attempt to use it once you're comfortable controlling complex imperative effects. I'd start with a simple text based game, and generalize until you're drawing graphics in a console, then graphics in 2D. Once you're at the a point I'd start looking at game libraries.
This is wonderful. I wonder how much it will take to build against 2.13.0-M4. I'm going to have to try this weekend.
Maybe a text based tic tac toe would be good. When you say 'complex imperative effects' could you be more specific? What specifications would I need to meet in order to actually learn something about FP? I guess not mutating any state is obvious, but I feel like that's too simple. What else am I supposed to achieve?
There is much annoyance here, but your post is IMO too jumbled and confused (and a bit wrong), as wel as too much of a common complaint to be very useful as a discussion starter.
You should check https://github.com/scala/scala-collection-compat then :) 
Thanks, I will.
It should be mentioned, that there is a semantic difference between the two approaches. With an abstract class, it is guaranteed to have only one monad typeclass instance for all method calls and over the whole lifetime, whereas in your example, it could change for every method call. As different instances (maybe not for monad but for other types) are a thing in Scala, it would be nice if someone with more experience could shed some light on this, especially when it comes to applying e.g. final tagless in real world application. I myself did use the method-level approach and didn'd experience any problems, but that was not on big project or even a public library, so who knows...
Id love more of these videos. I still dont really understand typeclasses and what `F[_]` and `self` represents, the video kind of ramped up very quick from this point but I feel like I am a step closer to understanding what `IO` actually is while not really getting it just yet.
Fucking finally!
Well I only read the comment that you posted, not the entire conversation. Not only that, but your original title is very misleading, this issue has **nothing** specifically got to do with "Why I don't use JSON ASTs". If you serialized it directly to a `case class` with `BigDecimal` representation, you would have the same issue (the underlying issue being the Math context being used, not whether or not you are using an AST)
Twitter uses Scala extensively.
I've been working at 3 different companies in the Bay Area that use Scala, for the last 5 years (although not doing "pure FP"). Places to look: all the companies that sponsor or give presentations at local Scala conferences and meet ups, like Scala by the Bay, etc. Check out any forums for those groups, there may be job postings. Look on craigslist. Check out this ["survey"](https://stackoverflow.com/jobs/salary/); enter your location and scala, it will bring up a bunch of job listings. There are teams in large companies using Scala; the Apple maps group (you will find listings on craigslist); also Verizon labs (some pure FP guys from Verizon used to post here a lot). I don't know about Google / Facebook...
Data infrastructure at Stripe is in Scala. Stripe is also a great place to work.
See Daniel Spiewak's talk if you want to understand F\[\_\] (higher kinded types) [https://vimeo.com/28793245](https://vimeo.com/28793245)
We use Scala for services here at CreditKarma. Feel free to message me if you want me to forward your resume to HR. We are located in downtown San Francisco.
We're not huge like the companies you mentioned but my team is hiring. https://jobs.lever.co/rocketlawyer/362a41de-29fa-4256-9a1f-ab80a548a52e PM me if you want to chat.
this is awesome, meanwhile I'm still stuck with old Spark version at work :(
With jsoniter-scala you can safely parse to `BigDecimal` and will _not_ have such issues because by default a scale is limited to 300 and math context is : https://github.com/plokhotnyuk/jsoniter-scala/blob/12ecb0dbf1726933705d645bbde78e17a3ecf889/jsoniter-scala-macros/src/main/scala/com/github/plokhotnyuk/jsoniter_scala/macros/JsonCodecMaker.scala#L49 And even when you write a custom codec it uses safe defaults: https://github.com/plokhotnyuk/jsoniter-scala/blob/12ecb0dbf1726933705d645bbde78e17a3ecf889/jsoniter-scala-core/src/main/scala/com/github/plokhotnyuk/jsoniter_scala/core/JsonReader.scala#L2722-L2723 Or allow you to specify the limit for scale and math context for parse parsing of `BigDecimal` values: https://github.com/plokhotnyuk/jsoniter-scala/blob/12ecb0dbf1726933705d645bbde78e17a3ecf889/jsoniter-scala-core/src/main/scala/com/github/plokhotnyuk/jsoniter_scala/core/JsonReader.scala#L290 
Tufts grad?
IIRC Evan describes the Elm architecture as a variant of FRP in one of his talks. 
What are you stuck migrating on? Or is migrating just not something you do at $JOB?
&gt; With jsoniter-scala you can safely parse to BigDecimal and will not have such issues because by default a scale is limited to 300 and math context is : I am not disagreeing with this, I know you can safely parse avoiding this issue. My point was with the thread title, as you have said yourself earlier ScalaJSON AST doesn't have this issue (and its an AST) &gt; But you are right that the title should be more clear, like this: "Usually designers of ASTs do not pay attention on security, so I don't use their coproducts". Understood, my point is that it has nothing to do with AST's specifically. If you serialized the JSON straight to a case class you would still theoretically get this problem. This is more of a case of being aware of how `BigDecimal` works, rather than anything AST specific
You're describing a bunch of different annoyances, but you're not identifying them correctly. You say &gt; Of course what is causing this is the type widening "feature" of the apply method of List, or more generally the fact that Functions are "contravariant" This is flat out wrong. Close, but no cigar. The problem is subtyping, plain an simple. The problem is that given trait Animal class Cat extends Animal class Dog extends Animal a valid `Animal` is also a valid `Cat` and also a valid `Any`, and that you can pass a value of type `Animal` to a method that expects an argument of type `Any`. In other words, that val felix = new Cat val fido = new Dog then `List.apply[Any](felix, fido)` returns a `List[Any]`, and scalac sees is no problem, because both `felix` and `fido` are perfectly cromulent `Any`'s that can be passed to the method `List.apply[Any]` Likewise, `List.apply[Animal](felix, fido)` returns a `List[Animal]`, and scalac is fine with this. `List.apply[Cat](felix, fido)` or `List.apply[Dog](felix, fido)` are compile errors. lastly, the unannotated `List.apply(felix, fido)` is inferred to be `List.apply[Animal](felix, fido)`, because Animal is the LUB of `Cat` and `Dog`. Your suggestion to use scalaz IList is a nice suggestion - sometimes you want an invariant list. But using IList doesn't fix the problem you describe. It also has nothing to do with FunctionN being contravariant in its argument type. You have some (IMO) real and reasonable issues with some language features, but the way you present this, where you present what's "obviously" the problem, and where you insert scare quotes around "features" while you completely misidentify the issues causing you grief don't make for a great post IMO.
It is not really under my control and there is a lot of projects that use Spark 2.0 that I'm not sure whether they will break when update.
Why do American jobs never list salaries. I'm genuinely confused by this.
Not as big as those, but we use a lot of Scala at Zendesk.
Because it's unacceptable to acknowledge that some people are better than others. You want to be able to offer better people higher salaries than less good people, but if you advertise a salary then you can only offer everyone that salary, and if you advertise a salary range then anyone who doesn't get an offer at the top of the range will be offended. So the only way to do it is not to advertise anything specific.
&gt; The rest of the world seems to manage by listing a salary. The rest of the world doesn't pay good devs at levels competitive with the US. &gt; But 95% of jobs I look at have no salary. Is one supposed to go through the interview process to find out they're offering $50k less than what I want. &gt; How do yanks approach this. Raise it at the end of the initial phone call, or go through a recruiter. 
London salaries seem higher than what I've seen advertised in Chicago albeit probably less tax to pay. I've no idea about the bay but living expenses must be enormous. Thanks for the info.
Good luck. I wrote some instruction for you on how to use scala-collection-compat: https://github.com/scala/scala-collection-compat/issues/132 You will need to migrate it's scala dependencies first, for example Twitter chill. I generated the dependency graph and the dependency tree for you: https://github.com/MasseGuillaume/spark-dependency-graph
Thanks, those are some nice getting starteds. It's probably going to take a while though. I don't understand how Maven works properly, and right now, my edit-compile loop takes over an hour :(
You can use sbt: https://github.com/apache/spark/blob/master/project/SparkBuild.scala
Top kek 
Same problem the Python community faces. Much as I don't like how fast Python 3 moves, it hasn't seemed to hurt adoption. 
I agree, it's really slow. One of my script at work was rejected because it was using a too recent version of python. Python 2.7!
Idk why are people complaining so much... You'll get a far better language and features. So what if you'll have to rewrite some of your old code? If it doesn't pay off, stay on Scala 2 and that's it? Don't like Scala 3 at all? Pick another language and stop ruining the fun for the rest of people..
I believe in tasty unless proven otherwise
The underlying \`F\[\_\]\` would still be the same between calls, so as long as you don't have multiple instances for the particular \`F\` under use, it will not be a problem.
Here's another way to view the approach outlined in the chapter. Say the program we wish to write involves stateful transformations like random number generation. One approach to write such a program is to use state actions i.e., functions that take an input state and return the next state. One can then write combinators that take input actions and return new output actions. One example is the *map* combinator that takes an input action s, and a function f, and returns a new output action that applies f to the random value and a new state. Since the map combinator returns an action, i.e., a function that takes an input state and returns an output state, there is no need to reference the state explicitly while defining the map combinator. The type signature for an action is *type Rand[+A] = RNG =&gt; (A, RNG)* and the map combinator can be defined as def map[A,B](s: Rand[A])(f: A =&gt; B): Rand[B] = rng =&gt; { val (a,rng2) = s(rng) (f(a), rng2) } As you can see from example map function, there is no need to explicitly reference the state since the state is passed as input to the action and not the map combinator. The red book is not a simple read but well worth it, especially if one does the exercises in the book as you are doing. Good luck!
...what?
 I wish Sam all the best. I appreciate his contributions. This does highlight an issue with Scala ecosystem I've encountered recently. Given the organization of certain projects, i understand why a migration to Scala 3 would appear unmanageable. (I removed specific project references below) For example, ??? could have progressively evolved into exactly the design desired. A choice was made to start from scratch. This choice was executed poorly. Resulting in a significant, potentially unmanageable, increase in project complexity. For instance, the treatment of ??? tickets was amateur. The result is, imo, quiet a mess and arguably a regression for customers. From an engineering perspective I could imagine this appearing unwinnable. This is a volunteer role for Sam and i doubt his professional projects are run the same. That said if the opensource projects are representative, then i won't consider the migration issues listed having the claimed cost. That's all organizational aspects. Unrelated to technical. For technical, I can't say much. I may have lucked out by joining Scala relatively late (and from Haskell). Looks like I avoided a lot of (now) bad advice that was popular even a few years back. 
Scala 3 is going to be a simpler transition... I think.
We dont't use really recent binaries I may say.
Java has many orders of magnitude more lines of code in production than Scala, and plenty of enterprise users are paying Oracle significant amounts of money for this platform. It does not make sense for Scala to be as slow moving as Java because Scala's current situation is not nearly the same. Besides, like others said, it seems that there are significant efforts to simplify / automate the migration to Scala 3. I think this is quite a reasonable tradeoff.
FUD
When I was working in python shortly after v3 was released, the fact that many python 3 features were backported to python 2 was actually often cited as one of the reasons developers were so reluctant to upgrade to python 3. &gt; The Scala 3 compiler has a -language:Scala2 option that lets it compile most Scala 2 code and at the same time highlights necessary rewritings as migration warnings. I think Scala's approach is better.
&gt; kind of ramped up very quick This is how I feel about all Scala presentations.
Sam's ideas about Scala 3, and other's, have been recently debunked by Martin and his team. If you believe Sam, the newly self-ascribed Haskellator, then clearly you must seek Haskell nirvana. /s
Do you not use virtualenv?
This is premature and FUD. Dotty is nowhere near finished yet, and there are several strategies in development to prevent a split. Everyone is keenly aware of Python 2/3 and trying to prevent that 
no. And their is at least 3 binaries of python 2.7 and two of 2.6 somewhere in the filesystem. But I dont really care, I work in C++.
Multiple e.g. \`Monad\[F\]\` instances are exactly what I was talking about. The effect type itself will stay the same, that's right.
Return only uses exceptions when inside a closure. In all the other situations it behaves identically to Java (still no reason to put it in the last statement though).
Your solution is not only functional enough, it's also faster than any "more functional" solution would be.
This comes across as whining
Am I correct that while Scala charges ahead, anyone integrating with Spark (most of us?) are still stuck on 2.11? I get why this is the case, but does anyone know when we can port our spark apps to 3?
Spark now builds against 2.12 so I would hope there should be a 2.12 release soon. Porting to 3 will be up to the Spark maintainers. Hopefully the migration will be as easy as possible in general, but Spark does do some low-level things (e.g. it can make heavy use of JVM serialization) that may be difficult to port. At least, I can only assume that's the reason for how long it took to port to 2.12 (though IMO there was little compelling reason to do so, so that may also have played a part).
Spark just compiled against Scala 2.12. 
Tooling is one of the big problems with scala right now. And instead of providing better tooling now they go for a breaking change that kills a lot of the existing scala tooling. I know they want to provide a language server but that will only be available when scala 3 is released. In the meantime a lot of scala developers lost interest in maintaining their project until it gets replaced by scala 3. So until then we're left with unmaintained tooling for scala 2.
According to my own (biased) measurements, Scala Native is approximately 2 times slower than Java but uses very little memory (11Mb). Could be good fit for command-line tools and small daemons on memory-restricted boxes. Test application source: object Main { def main(args: Array[String]): Unit = { println("Hello, world!") println(Seq(1, 2, 3)) var t = System.nanoTime var n = 0 var k = 0 while (true) { val seq = Seq(1, 2, 3) seq.foreach(k += _) n += 1 if (System.nanoTime - t &gt; 1000 * 1e6) { println(n) n = 0 t = System.nanoTime } } } }
Maybe you could explain why this is relevant and what you want the scala community to take from this?
Agreed, the only IDE which is maintained enough is to Intellij IDE and Lightbend(TypeSafe) stopped funding to /ScalaIDE. The language server route also not certain since no many adopted it so far.
I think everyone leaving is aware of those claims. You might ask yourself why they are unconvinced of these "debunkings".
I don't think this is accurate. There is ongoing work to provide LSP implementation in Scala 2. This is happening in parallel to the LSP implementation in Dotty, and the two teams are apparently working together in order to ensure that the efforts are converging towards a unified vision. https://slideslive.com/38908105/six-steps-from-zero-to-ide In addition, there's ongoing work to create a protocol that would allow editors to communicate with build tools, ensuring further separation between editors and builds and allowing better https://www.youtube.com/watch?v=Ppj0EFns59M&amp;frags=pl%2Cwn 
that's not true at all many countries don't mention salary for example, I'm from Central Europe and I almost never see salary, it's up to negotiating during the job interview
I know there is a lot of work going on. But scala already has a language server: ensime. The project is good but lacks contributers. It is already supported by a lot of editors . But for some reason they need to reimplement it. They could have contributed there. Now we need to wait until the new thing has the features ensime already has instead of getting new ones. 
Look into Scala consulting shops in NA.
Do you have experience with scalajs and react bindings 
No, my experience is designing and building backend services (micro services), message driven systems, using Akka (akka-http), Play, Circe, cats, Monix, Kafka, gRPC) among others.
I really am tired of official final-departure/last-words/goodbye posts. It serves no purpose other than to spread FUD and flip a middle finger to all the people that one has worked with to contribute to Scala over the years, and from which he has undoubtedly learned a great deal. It also seems really unnecessarily tribalistic or something. The language I have used most, and continue to use the most, is Scala, but that doesn't mean I don't learn other languages like Kotlin and Rust. But just because I learn them doesn't mean I "left Scala". With very little effort, these style blog posts have a much greater negative impact to an ecosystem's reputation than the equivalent positive impact yielded by spending the same amount of effort trying to improve things, and that's probably why they get written so much. Furthermore, these posts are often (and also in this case) a bit deceptive. For example, a couple months ago someone from pager duty wrote a similar piece about how their product started as a Rails app, then moved to Scala services, and now they're moving on again to Elixir from now on. I later heard that actually it was just the author that felt that way, and that even the service that was written in Elixir is being rewritten in Scala now. Regarding this post here, I personally have seen the author asking questions/help about writing some tricky Scala macros in the Scala Gitter channels after this article was written. So I guess this isn't a final divorce after all? So I guess he still uses Scala but decided he felt one day like taking a steaming pile of shit on it and that's all? Thanks!
It really depends on what framework you are using for building the API, most of them provide a way for testing the API, if you are using play, take a look into [playsonify](https://github.com/AlexITC/playsonify), it has a module that simplifies testing play APIs. Or, probably, you are talking about building integration tests that execute against another project? if that's the case, picking an HTTP library should be enough (like sttp).
TIOBE now has Scala at position 27. If TIOBE can be taken seriously that would mean that Scala has lost half of it's market share (percentage wise) in the last 3 months (which doesn't seem plausible).
Stripe has several scala remotes in Canada (the data org uses a lot of scala): https://stripe.com/jobs You can DM me on Twitter: posco
I think spring with its singleton beans everywhere is effectively a module system built on classes. Using instance variables as pointers to other initialised modules aka beans. I am personally a big fan of SQL and think it fits in quite well with functional programming. I know scaling it can be an issue. However you can get very far before you have those problems, using techniques such as indexing, partitioning etc. Many nosql solutions are tailored to specific use cases, which is fine. But more often than not, I like having the flexibility that sql provides, I like db type safety through schemas.
&gt; I like db type safety through schemas. I would if it aligned with the types I want to represent. But since there's no way of representing sums/variants, I find DB schemas do more harm than good.
&gt; There is ongoing work to provide LSP implementation in Scala 2 Yeah. I know. I wrote the blueprint for it: http://ensime.org/lsp-wg/
Hi Josh. You're not a very nice person.
I think having a schema really helps me see the shape of the data, and how things are connected, and find it helpful in data analysis tasks, since I dont have to look at the application code to determine the shape of the data. Just like having type safety helps in in scala to perform static analysis to verify the soundness of code. Not sure what you mean by having types to represent sums/variants. 
I'm hesitant to believe what anyone claims about themselves or their own product. The core Scala team has a lot of money riding on their credibility. I just can't get on board with claims like "We know what's best for you - believe us". It's probably more intellectually honest to listen to critiques from people who: 1. Have contributed a lot to the ecosystem (or to FOSS in general) 2. Have no conflict of interest in making claims one way or another
2.12 is still the current Scala series afaik.
I genuinely wish you good luck with that kind of honesty and curiosity, while pursuing Scala as a programming language. 
Most of the people who insist on telling the world that they are leaving Scala seem to be pure-FP guys, who contribute to projects like Scalaz or Cats. Not all of course (Paul Phillips comes to mind, but he left several years ago). FOSS projects have inevitable churn. I'm sure some key guys have quit the Apache Foundation, Hibernate or Spring over the last decade, but they don't seem to be writing anti-Java manifestos. Or if they do, no one cares...
Looks like Scala is coming down with a major case of the Osborne effect. People are waiting for Scala3 (Dotty) and not investing in developing Scala 2. The longer it takes before Scala 3 is available the worse it will get.
&gt; I'm sure some key guys have quit the Apache Foundation, Hibernate or Spring over the last decade, but they don't seem to be writing anti-Java manifestos. You should ask why.
Hit me up, remote Canadian Scala dev who's team is hiring
Where did Paul leave to? His recent github activity only show Scala stuff.
It would be nice if they would say, or at least acknowledge them
That wasn't a very nice thing to say
I would also like to know why, but knowing what I know of the people involved, there is probably a good reason. Also, knowing what I know of the relevant people, probably other people have counterarguments and would disagree. This really isn't that big of a deal, although I sympathize with the people who put effort into ensime like /u/fommil. It's not fun to put a lot of work into something and then have people move out, but that does happen a lot in the software world.
I don't see that happening
The main issue was with the lambda encoding change for Java 8. Other than that, something needed an API change which would have to wait for a new major spark version, but they solved that too.
&gt;atures ensime already ha The ensime folks has a compatible LSP server impl which again needs volunteers.
I believe that in general, we shouldn't take things at face value. For sure their bias may lead them to paint the picture more rosy than it is. That said, to suggest that (a) their expressed commitment is just dishonest lip service, i.e., they aren't going to do their best, and/or (b) that the people screaming that the world is on fire and the scala community is in a terrible situation don't have their share of biases... seems pretty disingenuous to me. 
Very mature of you too, as usual
Sure the exact same reasons don't apply to Scala 2/3. But the problem with Scala is that a huge array of functionality depends either on macros directly or on Scalaz/Cats/etc which in turn depend on macros. So to act like the incompatibility issue is somehow smaller than Python is simply not true. It's as serious if not far, far more. The problem with Dotty is that there is no clear indication even now of whether the same capabilities that exist today in macros will work in the new implementation of macros.
If you wish to contribute to the discussion about the cake pattern, please consider doing so in the comment section for the first part of this video, which you can find [over here](https://www.reddit.com/r/scala/comments/90wpce/a_fully_working_example_of_the_good_old_cake/e2vimuq). Thank you!
Here's my guess: Scala devs have a decade's track record of incompatibility, abandoned projects, poor IDE support, libraries that rapidly changed from "the best thing ever arriving soon" to "unmaintained" and all the broken promises that went with it. So the new promise that everything will be different this time, while also swapping out the compiler and adding half a dozen new things to the language, is not met with a lot of trust.
I think there is some truth in there. A lot of fixes which just didn't happen because they were not invented at the EPFL. I certainly wouldn't look at Scala today and say "these are the engineering and quality standards I want to have my name associated with".
That's one perspective. Here's a different one: 1. Scala 2.12 seemingly posed a unique challenge, because Spark had hard-coded a "closure cleaner" against the scala 2.11 (pre-Java 8) lambda encoding 2. For whatever reason, there wasn't much communication about the issue -- the Spark maintainers had their priorities etc. etc. Someone finally opened a thread about it in the end of March. This began some actual communication involving the community, the Spark maintainers, and the scalac team. Within a few months the issues were solved. 3. In the end, once the right path was identified, Scala 2.12 actually makes life easier for Spark -- a lot of the hard-coded logic they had needed was no longer necessary. 4. There is also the issue of adding support for a new Scala version without bumping the Spark API version, which IIUC can be tricky but usually can be done. In short, I don't feel like it's the biggest issue in the world. Also given that we don't know when Scala 3 will be released, I wouldn't worry to much about Spark... it might be more useful to worry about Scala 2.13 (and eventually 2.14) support in Spark...
link?
Scalaz does not use macros.
My app uses Http4s. Which is built on FS2, which is built on Cats, which is built on macros. If macros in Scala3 don't provide the functionality that Cats needs then I can't use Scala3 without replacing Http4s with something else. So no it is not just library owners who will need to rewrite code. And I am kind of sick to death of this "oh just trust everything will be fine nonsense". Why can't there be a clear roadmap and a clear understanding now (before code is written) what libraries will be affected and what functionality will be missing. 
He's moving on. Nothing to see here. Thanks for all the hard work Sam and good luck in your endeavors.
Scala 8 is a work in progress: nobody is using Scalaz 8.
The only macros I'm aware of that Cats uses is simulacrum, which in the worst case can be replaced with some extra boilerplate or an external code generation tool.
thanks! :-)
Scala IDE works for 2.12, and there's potential for a 2.13 supported release (one former committer plans on doing that). Using VS Code with Angular/TypeScript on the frontend, will switch away from Scala IDE when Dotty lands. While not rosy, things aren't all that dire on the tooling front -- SBT has been making great strides over the past year or so, and we have several alt-build tool options available as well.
Why‚Äôd you post it to reddit if you didn‚Äôt want discussion here? Reddit.com/wiki/selfpromotion
Definitely don‚Äôt reply on reddit, he needs engagement numbers
The moves to make Spark work with Scala 2.12 have been made possible by Lightbend‚Äôs fast data teams helping out, and you can assume much more such symbiotic ecosystem fostering in the future. If anything, things are getting smoother, not the opposite. 
&gt; Not sure what you mean by having types to represent sums/variants. Cases where the type is "A or B", like `Either` in Scala. You can't nicely represent that in a database schema.
What‚Äôs the relevance of the age? There are bad programmers straight out of school and there are bad senior programmers, that shouldn‚Äôt touch your codebase with a barge pole.
We are fully remote and have a person in Canada. Shoot me a dm.
I'm adding support for [PureCSS](https://purecss.io/) framework to [hepek](https://github.com/sake92/hepek/pull/16). Using same abstractions, you only need to switch `trait` you extend/import and you get your page rendered with different framework. Currently, only Bootstrap3 and Pure are supported. Help/feedback is welcome! :)
Cats has a dependency on the \[Typelevel Machinist\]([https://github.com/typelevel/machinist](https://github.com/typelevel/machinist)) macro library. Do you see where I am going with this ? It's possible that almost every Scala project in existence has a transitive dependency on macros. Even Playframework uses macros and that was a big reason Scala is even popular today. And it just takes one of those macro libraries to not be implementable in Scala 3 for that to have a ripple effect that could affect significant number of users. 
&gt; If macros in Scala3 don't provide the functionality that Cats needs Agreed, however my point is that's a very big if. I cannot see that happening. &gt; And I am kind of sick to death of this "oh just trust everything will be fine nonsense". I didn't say that. However I am equally tired of hearing "the sky is falling" all the time. The fact is, we don't know yet, and the best we can do is participate in the process. &gt; Why can't there be a clear roadmap and a clear understanding now Pretty much whatever has been finalized is documented, and whatever isn't documented is still up in the air. If you have concerns, get involved. Chat on gitter, on relevant GitHub issues, forums, whatever. You can influence things.
Yep. It's perhaps only unfortunate that they didn't reach out earlier
I'm not saying everything will be fine. Prudent, constructive concern is certainly appropriate. However that's not what this post was.
Yay, the blogspammers found /r/scala
Thank you Sam. Your work on Ensime had made my job far more easier / enjoyable. I never used Emacs before but 4 years ago the Intelij Scala suppport was terrible and I lost so much time with false error reporting I decided to try Ensime and Emacs, I now mainly work in Emacs for everything because of Ensime. I've also watched the recent progress with Scalaz and it seems like you went all in on it, the project is starting to move again with big goals looking at the recent repos. Good luck with Haskell, like you I'd rather be using it and do use it for personal projects as find it so much simpler after going down the pure functional route. I still have to pay the bills so Scala is a halfway house and Scalaz is a fantastic library which allows me to deliver better software, i treat it as the missing stdlib.
https://github.com/typelevel/cats/pull/2365
&gt; The reason why is because scala attracts people that are much more perfectionist Nah, many of the programmers who aspire to be skilled and "perfectionist", and who once visited scala, have then left scala behind some time ago. This seems to have gone unnoticed.
I don't really know what to say in response to your claims of FUD... I only said positive things about Scala in this article and I've been very actively involved with the parts of dotty that I cite, e.g. LSP. What, specifically, is FUD? Where is this comparison with Python coming from? That's not something I've said. I am sorry to say but this entire thread is going to stay with with as my final interaction with the Scala community and it is not pleasant. I will certainly point people at this thread in the future and say "look, this is what the Scala community is really like, not the happy joy joy vibes that come from Lightbend and EPFL".
My ideas about Scala 3? You mean... the presentation compiler? I spoke to Martin about it at Scala World and he decided to put a student on it, which I was very happy about. I think everybody is in agreement that this is a good idea and will give Scala 3 an LSP out of the box. I don't think anybody is trying to debunk this. I am confused why you would say this.
What exactly is FUD, I only said good things about Scala! Did you read the article?
That will only allow scala 2 code to run alongside scala 3 code, so long as no APIs have changed. If a method gets renamed or the signature changed, then TASTY will not help you. That is not sufficient for the needs of any of the projects I have been paid to work on, especially anything that uses internal compiler APIs. It also wouldn't work at all for ENSIME, which does classfile indexing. It would require a complete rewrite.
Ha! Now that you mention it, yes. There is a feeling of that in the tooling circles. When Scala 3 was announced, a lot of people excited about LSP in Scala 2 certainly lost their energy.
&gt; Cats has a dependency on the Typelevel Machinist macro library. Same kind of thing as simulacrum, same answers. &gt; It's possible that almost every Scala project in existence has a transitive dependency on macros. There are, like, maybe 2 important macros (I can only actually think of one, the shapeless LabelledGeneric one) and then a handful of tiny convenience ones that can easily be replaced by code. Everything does have a transitive dependency on macros because everything uses the same few libraries, so you're right that losing one of those libraries would do major damage, but by the same token there's only a few libraries that will need to be migrated. I just don't see any grounds to panic. If a foundational library turns out not to be possible in Scala 3 then of course that will be disastrous, but of course the scala maintainers won't let that happen. There's nothing special about macros here, any other feature deprecation would have the same theoretical concerns - but deprecation is absolutely essential to language development.
He still works in Scala but he stopped contributing to the compiler, AIUI.
Seems there's a big misunderstanding going on. I think everybody took the post different than it was intended.
Hi, I hope I didn't mischaracterize your intent. Perhaps I (and others) are wrongly seeing it in the context of the recent controversy started (also with good intent) by JDG.However, I feel strongly that your blog post creates some wrong impressions, even if unintentionally. 1. Scala 3 is not a new programming language. By that measure, C# is like 7 different languages, and similar of many other languages. Languages evolve. Scala, for most of its lifetime, evolved a lot. It was only in the "Typesafe" era that things slowed, and the community wasn't happy about it. IMO Scala 3 is a return to the status quo of innovation. 2. The only parts of the post that are "in consonance" so to speak with the title are "Scala 3 is an innovation step change," "Unfortunately, I cannot see any of the projects I√¢‚Ç¨‚Ñ¢ve worked on (public or private) being able to migrate. Therefore, I believe the community will fracture into 'Legacy Scala 2' and 'Innovative Scala 3' camps," and "But taking a step back, Scala 3 is actually more like a new programming language. It has forced me to consider alternatives." These are feeding into the fear that Scala 3 is a ticking time bomb, a disaster waiting to happen. Again, you didn't say anything of the sort. I apologize for reading that suggestion into it. However given the recent FUD from JDG, who bemoaned the direction of Dotty and predicted certain people leaving, I think I'm not the only one that read it that way. Also, I think it's significant which parts are in consonance with the title because, as in music, that has an "amplification" effect so to speak. 3. There are a couple of non sequiturs. The only way I can read it is that you never thought about leaving before, but since scala 3 is kinda sorta a new language, that opened your mind to the idea of trying other languages too, but that doesn't sound like you at all, and besides, that's no reason to stop writing Scala. That being the case, could you comment on [/u/simon\_o](https://www.reddit.com/r/scala/comments/949vxw/scala_3_as_a_new_programming_language_sam_halliday/)'s insinuation that your real reason for leaving has nothing to do with any of the points mentioned in the blog post, but rather because of certain behind the scenes highly inappropriate and damaging behavior committed by representative individuals? In short, I hope I didn't offend you, I posted not to rebuke you but to caution other readers that there's no need for a stampede.
I sincerely apologize for misreading it
I kinda lost hope for the future viability of ensime when I tried to get involved in making it compatible with java 9+ and was told to pound sand
Then you return something like \`MyDataStructure(inner: List\[List\[???\]\])\` and have some functions somewhere else that can work work that type. Where is the problem now?
I don't know you expected to do it for you, but I've given up maintaining ENSIME to spend more time with my family.
Thanks for speaking out! :-) It's appreciated.
To quote from your article: \&gt; I cannot see any of the projects I‚Äôve worked on (public or private) being able to migrate. Therefore, I believe the community will fracture into ‚ÄúLegacy Scala 2‚Äù and ‚ÄúInnovative Scala 3‚Äù camps That's pretty much what happened with Python 2-3, so I don't think it's fair to say you never said that. To respond that you do not recognize your article spreading FUD, you literally say projects will not be able to migrate from Scala 2 to 3. Do you not agree that this is a bit premature to say about a pre-alpha version of a language release? I agree with you that it is a very valid concern. I do not agree with you that projects will not be able to migrate. I do not see large blockers in my current projects, but I am not a maintainer of a library having scalaz or shapeless levels of complexity.
Thanks for the clarifications, and I'm sorry that you had those experiences. P.S. people should treat employees nicely too :D
To clarify about your work projects -- is there an alternative scenario where scala gets the same improvements but whatever is preventing upgrading would be solved? Or is it just a fact of life that breaking changes break things?
You are making a lot of disingenuous conclusions from what I said, but I have only said positive things about Scala. Decisions and contingencies are already being made in industry, it is not premature to see where this is going. I am sure many projects, especially microservices and smaller companies, will be able to upgrade. However I have been working on huge, extremely complex, projects that you have no experience of (assuming we have not worked together). Forking a stable language is nothing new. If you find a company with enough investment in a particular version of a language, they will do this, even create their own language. I have seen this many times, I've even seen companies hire the original language authors to help maintain their fork and then specialise it to their usecase. This is an advantage of Free Software over proprietary solutions. Scala 3 will have minimal impact on Scalaz 7. I don't know why you would think that it would be impacted the most. ENSIME must however be abandoned, and much of my other public work will need to be rewritten. I have no time or interest in updating those things, maybe others will. I can't speak for other projects.
The link to "Ask anything threads" is broken. Possibly unrelatedly, the current "Got a quick question?" thread has unpinned. Could these be updated? IMO having a quick questions thread available is very important as a place for beginners to be able to get help.
Well, you already mentioned the (in my opinion) usually better alternatives. Finding functions that operates on this type is easy in Scala - they are put into the companion object. Otherwise (if it is 3rd party functionality) you will have the same problem in Java: where to put them? Into a Wrapper? (how to find it?) Into some static methods like apache.commons (how to find them?)? It's not convincing me yet.
That's true for Scala's macros. Not for all Scala ecosystem.
What are the benefits of using curried functions? I understand how they work but don't see very much of it's practical every-day use. It's kinda similar to partial application. Alternative to both is to make a helper `def` to call the original function... Right? Not trying to be dismissive, I'm surely missing something here?
It makes partial application easier, if you're doing a lot of it. I agree that in Scala it's fairly niche, but it can save a few characters, particularly for higher-order functions where you might otherwise need to do an explicit lambda, e.g. you can write: someList map myFunction(4) whereas without currying you'd have to write someList map { myFunction(4, _) } or perhaps even someList map { x =&gt; myFunction(4, x) } As you say it's possible to make a helper `def`, but that's a lot more verbose: { // may have to make an extra block to put the def in def myFunction4(x: SomeComplexTypeSignature) = myFunction(4, x) someList map myFunction4 } In a language like Haskell it becomes a lot more important because there's no other way to have functions of multiple arguments. In Scala we could probably do without it to be honest.
Good point. `data.fun(1, 2)` is identical to `fun(data, 1, 2)` or `fun(data)(1, 2)` for final classes. But then comes another point - virtual functions. Modern OOP software starts up in two phases - initialization (where every module/class is configured with dependencies and specific dependency implementation) and runtime (dependencies never change) For program assembled from modules and functions dependencies between modules are hard coded, you can not switch module implementations easily. Nice example of module-based aka procedural programming is Linux core - guess how much does it covered by unit tests? It doesn't :-) 
complex imperative effects would include things like GL render contexts, real time input, timers for controlling the speed of simulation, all of the things what would be found in a modern game engine, typically exposed as side effects. If you were to attempt to write a game functionally you'd have to be comfortable with transforming impure programs given to you by the library and wrap them in functional constructs that would make them pure again. &gt; I guess not mutating any state is obvious, but I feel like that's too simple. What else am I supposed to achieve? All you need to be is referentially transparent to do functional programming. Not mutating state one of the basic ways of achieving referential transparency, but not the only way, nor is it always necessary. From there, because you're programming in Scala specifically, you would work to make maximal use of the type system to ensure program correctness.
&gt;The link to "Ask anything threads" is broken. Sorry about that, will fix this soon :-) &gt;the current "Got a quick question?" thread has unpinned . These threads are scheduled for every second Monday at around 8:00 AM EST, but so far as I know, there is no way to schedule the unpinning of the previous thread. So I have to manually unpin the previous one each time, which I do every Sunday evening typically (unless I forget). So then for that evening and the early morning hours of Monday there will be a period where there's no Ask Anything thread pinned. 
So you are talking about polymorphism? That can be achieved with inheritance which allows to use a specific implementation, true. But you can have the same thing in Scala with typeclasses - consider how programs are designed when using final tagless. And here you are still not bundling data and functions but you can still abstract over interfaces (or typeclasses) and their implementations. I don't think you were talking about that, but I can see that Encapsulation can get handy when state comes into play and can't really be mitigated. But that still only applies to a very specific number of problem areas and is nowhere close to be a reason to force that kind of bundling \*everywhere\* (or at least discourage not to do it).
Simple question. I want to create a future that takes 30 seconds to complete and the does so successfully. My understanding is that Thread.sleep effectively puts the whole thread to sleep so can effectively just block the whole app and make all the tests run after tha future has finished. (This is a test suite test, with parallel testing enabled) This works: import scala.concurrent._ import scala.concurrent.duration._ def hang() :Future[Boolean] = { val t = new java.util.Timer() val delayedPromise = Promise[Boolean] val task = new java.util.TimerTask { def run() = { delayedPromise.success(true) println("done") } } t.schedule(task, 20000L, 40000L) delayedPromise.future } hang() // race condition check... Await.result(hang, Duration.Inf) Is there anything better/cleaner/nicer? 
I hear that. Although, I'd rather measure "more incrementally" after I see what's in 2.14, not to mention 2.13. Ultimately their goal is to do it incrementally, but yeah more would be better. I think the reason they're thinking about so many features at once is because they affect each other, that's my theory. But they don't have to be released at once. If that's important the community should make their give heard.
Along with what /u/m50d points out, it also aids the compiler with type inference in some scenarios. The red book notes this to be the case with functions that accept higher-order functions as arguments whose type parameters rely on the previous arguments. Example: `def dropWhle[A](l: List[A], f: A=&gt; Boolean): List[A]` This `dropWhile` is not the Scala standard library version, but one used as an example in the red book. Without currying the parameters, its usage would be: val xs: List[Int] = List(1, 2, 3, 4, 5) val ex1 = dropWhile(xs, (x: Int) =&gt; x &lt; 4) Notice how we have to specify the type of `x` in the anonymous function we pass to `dropWhile`. Scala's type inference either only gets us half-way. We end up having to define the concrete type manually when what we really want is for the compiler to understand that because the first argument passed was `Int` then the argument to the function must *also* be an `Int`. We can achieve this by defining `dropWhile` in its curried form, using multiple argument groups. `def dropWhile[A](x: List[A])(f: A =&gt; Boolean): List[A]` Which then allows us to use the function as: `val ex2 = dropWhile(xs)(x =&gt; x &lt; 4)` or `val ex3 = dropWhile(xs)(_ &lt; 4)` From the red book: &gt; More generally, when a function definition contains multiple argument groups, type information flows from left to right across these argument groups
I'm sorry man, I must have been in a bad mood and took your post the wrong way. I was overly harsh on you for sure.
&gt; Scala devs have a decade's track record of incompatibility, abandoned projects, poor IDE support, libraries that rapidly changed from "the best thing ever arriving soon" to "unmaintained" and all the broken promises that went with it. The more you say it it won't become more truth Simon.
While some external contributors have certainly felt that their efforts in improving Scala 2 won't have as much impact for Scala 3 users as they expected (I count you there, Sam), this is generally not true. The Scala Center has been working on tooling for Scala 2.x mainly for the past two years (and we continue to heavily invest in Scala 2.x users), with a focus on making compiler-independent tooling (e.g. Scala 2 and Scala 3 compatible). There is a solid belief that we want to continue improving the life of Scala 3 developers for a long time, especially in the fields of compilation performance and tooling, so that those that cannot afford upgrading to Scala 3 continue to keep up with improvements in their tooling. The whole migration store is being done so that both Scala 2 and Scala 3 can live together in the same classpath for a long time until we finally move the whole community to Scala 3.
Not at all. The complications of upgrading to Scala 2.12 were the lambda encoding in JDK 8 and its use in the Scala 2.12.x series. This is an exception rather than the norm.
I haven't read your blog post @fommil (and I don't have the time for it unfortunately). However, I'd like to say that I wish you the best and that you're a great person! We have not always agreed, but our long discussions (both online and offline) have always been fruitful and actionable, and I have enjoyed quite a bunch hanging out with you in conferences. People come and go, for sure, but it's important for me to acknowledge publicly that I appreciate all your work around tooling (I may have been one of the persons that has benefitted the most from it one way or another) despite the fact that it's no secret that we disagree quite a lot in social media (:P). You were one of the first people to motivate me to hack on Ensime and improve my Scala several years ago (I bet you didn't know that), so I hope that your enthusiasm to fix and improve things is now of some use in the Haskell community and, most importantly, that you have fun.
Thanks!
thanks! :-)
Thanks, looks great!
Jetbrains has this in most of their editors. Almost certain it works for Java, it works pretty well for python, especially if you use typing, works great for cpp
Spark Datasets have the following signature for `flatMap`: `def flatMap[U : Encoder](func: T =&gt; TraversableOnce[U]): Dataset[U]` The type bound on U appears prevent using a Dataset in a for comprehension; at least I have a piece of code that breaks when I try to convert it. It compiles, but I get a run time error about what I think is the missing implicit Encoder. Is there any way to make a for comprehension work with this? I'm using Scala v2.11.x and Spark 2.2.0.
You should really use something like virtualenv or conda (conda has does dep + env management). It will make your builds reliable and your life easier :D
Well, Scala has its own Futures. It would not be *this* technique but you can use e.g. Monix's Task with [CircuitBreaker](https://monix.io/docs/3x/eval/circuit-breaker.html) to throttle number of requests you app is making and add some (exponential?) retry to it. It would be async of course. You wouldn't need an extra library for it as you could literally generalize it into 10-lines-long utility function.
Some more detail: I'm reviewing a piece of code (at work, so I can't post it here) that has two flatMaps and a map all nested (map innermost). So, naturally I think, "That looks like it wants to be a for comprehension," and I try to pretty it up. There were some intermediate steps within the nested code, so there are some assignments within the for block. One of which involves an `Envelope`. Here's the error: ``` No Encoder found for com.vividsolutions.jts.geom.Envelope - field (class: "com.vividsolutions.jts.geom.Envelope", name: "_2") - root class: "scala.Tuple2" java.lang.UnsupportedOperationException: No Encoder found for com.vividsolutions.jts.geom.Envelope - field (class: "com.vividsolutions.jts.geom.Envelope", name: "_2") - root class: "scala.Tuple2" ``` I'm not sure why an Encoder for Envelope should even be needed. There must be some nuance to how the for comprehension desugars that I'm not getting.
I don't know whether that technique is provided out of the box by some library but my impression is that it can be easily implemented in a few lines of code using `cats-effect`'s IO` and `Deferred`.
Most often cache stampede prevention is handled by the caching library itself. As the article shows, `ConcurrentHashMap#computeIfAbsent` provides this mechanism. One might use [Scaffeine](https://github.com/blemale/scaffeine) `AsyncLoadingCache` for an asynchronous Scala version using futures. In DoorDash's case it would be a cache that immediately evicts, though typically one would hold the result for a longer duration. Sometimes the RPC layer will automatically debounce for you, such as in memcached clients, rather than require the optimization be placed in every application call-site. The technique is often referred to as memoization and you'll find a lot of Scala articles and libraries using that term.
Even if you can't post the exact code, a sanitized version of it with the basic structure may be helpful. Without more information it's hard to say for sure, but just from your description and the error it looks like there's a two-step process going on that is only tangentially related to the comprehension. First, there's an encoder for `(A, B)`, e.g. `implicit def pairEncoder[A: Encoder, B: Encoder](pair: (A, B)): Encoder[(A, B)]` that will create an `Encoder` for pairs if each thing also has an `Encoder`. In your case, `B = Envelope`. Second, it seems like there's an overly generic `Encoder` registry that's getting used, or something along the lines of `implicit def encoder[A &lt;: AnyRef]: Encoder[A]` where it could apply to anything, you just have to register it first or it breaks at run time. So somewhere you have a pair, the second element of which is an `Envelope`, and you have a generic `Encoder` that could encode anything but doesn't actually encode an `Envelope`. Then when the implicit `Encoder` is resolved, it finds the one for the pair, and goes looking for the `Envelope` encoder so it can handle the second element, ultimately finding this generic one without `Envelope` support. The fact that an implicit was resolved allows compilation to succeed, but when you try to execute the generic encoder found at compile time goes to look up how to encode the `Envelope` and discovers it doesn't actually have the encoder and throws an error. Given all that, I'd wager 1. You have accidentally changed the type to be encoded from something other than `Envelope` to `Envelope`, or 2. The imports that resolved the correct encoder for `Envelope` have been changed, possibly automatically by the IDE, such that it now resolves the super generic one.
Works for rust, both in intellij and clion.
It‚Äôs an extension of that idea, I‚Äôm sure you‚Äôll like it when you start using it!
Thanks 
Thanks 
This has got to be the slickest CLI I've ever seen. As a plugin author, I'm a little disappointed by the lack of a plugin interface, but his proposal of flipping the responsibility around (by allowing other tools to query Fury for the information of the project/build) is an interesting one, and I'm really looking forward to how it pans out.
IntelliJ has very specific requirements about presentation compilers because they need to make it compatible with their IDE infrastructure (called PSI). That is one of the reasons why IntelliJ implemented its own presentation compiler and didn't use Scala's. However, I've been chatting with the IntelliJ guys and they are interested in using Tasty as the interchange format to re-use Dotty's backend in Scala 3. That will give a coherent IDE experience to all Scala developers (no matter if they use IntelliJ or vscode).
is the a different key combination then? I have most of Jetbrains IDEs, tried to do it in Clion it didn't work, tried to do it with Rust plugin in Idea it also didn't work. Using the same key combination I did in scala. I also searched the keymappings for type info and it is only in scala.
It may be bound to different shortcut for other languages. For example, for Java it is Ctrl + Shift + P.
There are libraries for scheduling things to run after a particular time, but those libraries will ultimately be doing much the same thing as you're doing here. It will be difficult to find race conditions with something like this - frankly I don't think it's practical to find race conditions with unit tests at all. I'd look to design your system in such a way that races are impossible (e.g. by requiring all mutable data to have a single owner) instead.
Assignments in a for comprehension desugar to `map`s which are probably the part that's failing to be encoded. Can you write the for comprehension without any `=`es "at top level", perhaps by using blocks on the right hand side of `&lt;-`s?
Unix philosophy, I guess...
Farewell Sam, all the best with your new venture, and thanks for all the contributions over the years :) 
Not sure on the specifics of the reddit api but I like play-ws library https://github.com/playframework/play-ws
I haven‚Äôt played with it to be honest as the past 2 clients I had were already using mockito, hence my motivation to make it easier to use it in Scala I know (guess?) Scalamock is probably the way to go, but sometimes we don‚Äôt have that option so this library aims to ease those scenarios Hope you like it!
It looks good but how would I do OAuth requests on that library?
You use the same `ConcurrentHashMap`, the same `computeIfAbsent`, and just return a scala `Future` instead of a `Deferred`. There's nothing Kotlin-specific there as far as I can see. If you're talking about a more functional approach, you wouldn't get yourself into this position in the first place because you wouldn't have pervasive implicit concurrency. Rather you'd do something like Haxl and similar frameworks: form a free applicative for the operations you want to perform, analyze that to find the set of requests you need to perform, perform the requests you actually need to perform (so you naturally only perform each request once, no need for a mutable cache) and then interpret the applicative using those results.
Thanks. That solved it.
The code looks something like this: ``` for { r &lt;- records // this is a Dataset envelope = r.getEnvelope i &lt;- createIteratorFrom(envelope) a = something(i) b = somethingElse(i) x &lt;- maybe(a, b) } yield (a, x) ``` u/m50d's suggestion to put the envelope in a block on the right hand side of `i` solved the problem. I think you're correct about why the Encoder is missing; what I don't understand is why `envelope` is getting put into a tuple in the first place.
if you liked spray-json-shapeless you'll love the typeclass derivation chapter of my book ;-) I'm going back and doing it properly as the focus of the chapter. Check it out in a few days.
"insist on telling the world" I was thanking my friends for the good times. There is no need to be an ass about it.
The desugaring assumes you would be using `envelope` multiple times further down in the `for`/`yield` (otherwise why have it as a value at all?) but don't want to recompute it every time. So it has to desugar as `records map { r =&gt; (r, r.getEnvelope) } flatMap { (r, envelope) =&gt; ... }`. If you think about how else you'd desugar it you'll see there's not really any other way to do it.
&gt; by allowing other tools to query Fury for the information of the project/build This is the approach taken in Bazel via their query command and protocol :-)
Personally I really like sttp (https://github.com/softwaremill/sttp)
Awesome yours works thank man!
Maybe it's worth noting that the people that are complaining are not the ones that maintain those macro-heavy libraries and supposedly should be most affected by the change. I find it interesting to see that some of these people are not unhappy and often contributing to the the language; I am pretty sure that they already have ideas on how to address the upcoming changes (e.g. there are some new language features that remove the need for macros in certain areas) and that's what makes this argument feel so much FUD to me.
Any advice about how i can prepare for a technical interview where i will be discussing my solution to a technical assignment ? the job is for a backend engineer. what i have noted so far are: * read the documentation of the used stack. * take notes about what can be improved. * try to improve the solution. * try to anticipate some the solutions to some problems they may ask, for example what if we need to scale this to double or triple the users... * prepare some questions about their stack. I don't have any experience with this style of interviews, so any advice would be much appreciated.
https://github.com/wsargent/play-box-content-api
[https://github.com/lihaoyi/requests-scala](https://github.com/lihaoyi/requests-scala) very simple. I like it
/u/mrxtravis Removing because this was posted here 5 days ago
&gt; I expect Haskell, and all other languages, have similar problems. Haskell has additional issues in the form of all tooling (including doc generator) being very tightly coupled with GHC, high centralization of development, slow committee, pain-points and bugs being left unaddressed for 3 decades (i.e. records, namespacing, verbose imports, qualified exports, re-export support in haddock, circular modules support which is part of Haskell98 standard but was never implemented and more) and people not addressing them themselves due to lack of compiler plugin API, which was a major enabler of language development in Scala, where many plugins got merged into scalac after becoming popular.
fs2 has [`debounce`](https://github.com/functional-streams-for-scala/fs2/blob/v0.10.5/core/jvm/src/test/scala/fs2/SchedulerSpec.scala#L26-L39) as part of its API/
I was looking for something exactly like your `ValueClassMatchers` a few weeks ago. I realize using a macro makes a lot of sense. There's a way with Shapeless but it's not perfect, or so I've heard. As someone who knows nothing about macros, you could briefly comment how it works?
By the way, I recommend using Bloop with Gradle to have faster compilation times and better incremental compilation (unfortunately, Gradle uses a version of Scala's incremental compiler for more than 3 years ago). We recently merged Bloop's gradle plugin and we're looking for interested users to try it out and help us improve it. Tune in at https://scalacenter.github.io/bloop/docs/installation/
Just this particular problem. Thanks!
All right, so basically ValueClasses only exist at compile time, so with vanilla mockito, what you have to do for the matchers to work is to put them inside an instance of the value class, e.g. if we were using `ArgumentMatchers.eq` then we would have to do something like `when(myMock.myMethod(MyValueClass(ArgumentMatchers.eq(someValue)) thenReturn &lt;something&gt;` instead of `when(myMock.myMethod(ArgumentMatchers.eq(MyValueClass(someValue))) thenReturn &lt;something&gt;` So basically, what we want to achieve is to avoid as much of that boilerplate as we can, for this I use a combination of Macros and Type Classes (in the scaladoc they are called implicit macros) So, what we want is a magic factory that constructs an instance of `MyValueClass` wrapping the matcher we want to use (currently only any and eq are supported), here is where the macro comes in place, given the trait trait ValueClassMatchers[T] { def anyVal: T def eqToVal(v: Any): T } and a value class case class MyValueClass(v: String) extends AnyVal then the macro will inspect the type (it's like doing reflection but at compile time) and it will create an implementation that will look like (I've simplified the code for readability) new ValueClassMatchers[MyValueClass] { def anyVal: MyValueClass = new MyValueClass(ArgumentMatchers.any[String]()) def eqToVal(v: Any): MyValueClass = new MyValueClass(ArgumentMatchers.eq[String](v)) } Now, how do we get an instance for our type (or how the compiler know for what type it need to create this), well this is where the TypeClass comes into play For example, the `anyVal[T]` method in the ArgumentMatcherSugar trait has the following signature def anyVal[T](implicit valueClassMatchers: ValueClassMatchers[T]): T = valueClassMatchers.anyVal So basically when we do `anyVal[MyValueClass]` in our test code, the compiler looks for an implicit instance of the type `ValueClassMatchers[MyValueClass]`... where does it comes from? Well, the companion object of ValueClassMatchers trait has a method like implicit def materializeValueClassMatchers[T]: ValueClassMatchers[T] = macro materializeValueClassMatchersMacro[T] This method acts as an implicit factory for instances of that TypeClass in where the actual instances are created by the macro definition Makes sense?
# Gigahorse[ ](http://eed3si9n.com/gigahorse/#Gigahorse) Gigahorse is an HTTP client for Scala that can wrap either [Square OkHttp](http://square.github.io/okhttp/), [Async Http Client](https://github.com/AsyncHttpClient/async-http-client/tree/1.9.x), or [Akka HTTP](http://doc.akka.io/docs/akka-http/current/scala.html) underneath. 
I'm using intellij IDE and want launch a compiled program in windows promt console/ gitbash. In visual studios it felt like i could test making my own program with c++. I really dislike intellij console but want it to handle all the lib and class stuff. Is it possible to run obj ext App in such a way? 
Yes, it makes perfect sense, thanks again!
Huh, really? I had gotten contacted by a Zendesk recruiter on LinkedIn and didn't really consider it. How do you like working there?
I honestly think it comes to personal preference. One thing I do: users.groupBy(user =&gt; (user.Id, user.productType)) .mapValues(_.map(_.productValue)) .mapValues(list =&gt; list.sum / list.size) .toList .sortBy(_._1) .foreach(println) Is break up the method calls on new lines. It helps me see the order of the calls
Insert newlines. Preferably after open braces/parens and before the period of chained method calls
Well, for one, you don't need to put everything in one line: users .groupBy(user =&gt; (user.Id, user.productType)) .mapValues(_.map(_.productValue)) .mapValues(list =&gt; list.sum / list.size) .toList .sortBy(_._1) .foreach(println)
Along with everyone else's answer, another thing you can do to make it more readable is to use pattern matching to access values in a tuple. I never really liked how scala use \_1, \_2 to access values in a tuple. .sortBy(_._1) for example can be changed to .sortBy({ case (userId: String, _) =&gt; userId }) To me, it is more explicit on how it is being sorted. Just a personal preference.
it might give some people cancer too but I break my lambdas up on new lines a lot of times like list.map(thing =&gt; val someValMaybe = f(thing) doStuff(someValMaybe) ) where obviously it would be a messier situation IRL but sometimes it's nice if not overused 
The type i'm trying to sort is in the form of List[((String, String), Double)] So i'm sorting the (String, String) part by using _1 How would pattern matching work for this case?
So it wouldn't be any different. .sortBy({ case (userId: String, _) =&gt; userId }) would be .sortBy({ case (userId: Tuple2[String, String], _) =&gt; userId }) because the type in the first spot is a tuple now instead of a String in my prev example. You would probably change the variable name to something more accurate .sortBy({ case (stringPair: Tuple2[String, String], _) =&gt; stringPair }) and scala is smart so you wouldn't even need to specify type in most cases: .sortBy({ case (stringPair, _) =&gt; stringPair }) So what ever is in the first location (in this case a tuple of length 2), it'll sort by that.
Surprised no one suggested this yet: https://github.com/http4s/http4s
Thanks lot this is a very good explanation 
Does http4s support oauth2 requests?
Not sure I understand the question. From a client side perspective, oauth2 is just a sequence of requests that take in account the access token.
you can simplify some code blocks using the **for** generator. Anything with a flatmap and map could be converted into a for generator. for example: (taken from martin's course on coursera) \`\`\` (1 until n) .flatMap(i =&gt; (1 until i) .withFilter(j =&gt; isPrime(i + j)) .map(j =&gt; (i, j))) \`\`\` \`\`\` for { i &lt;- 1 until n j &lt;- 1 until i if isPrime(i + j) } yield (i, j) \`\`\` Although , it doesn't work for every use case its a nice way to write when it is possible. 
`val request = sttp.auth` `.basic("name","secret")` `.body(Map("grant_type" -&gt; "password", "username" -&gt; "peet", "password" -&gt; "slimo"))` `.header("User-Agent" , "Get Pics")` `.post(uri"https://www.reddit.com/api/v1/access_token")` `implicit val backend = HttpURLConnectionBackend()` `val response = request.send()` `println(response.unsafeBody)` How would I replicate this? Or more specifically how would I specify the part the above code where auth.basic is?
Thanks I got it to work with HTTP4s. Your reply made me think about it from a different angle.
Unless it improves readability a lot, I prefer to use syntax like: \`list.map(thing =&gt; f(thing) |&gt; doStuff)\` or in this specific case even \`list.map(f andThen doStuff)\`
I guess you are coming from python. In Scala this construct is called `for comprehension`
I really like it, but I'm not in the SF office.
Convert your list to map then build two sets for names and fruits. After that just print fruits' names and for each name print corresponding map's values with zero as default 
I think best practice is to keep with the one-liners, adding line breaks to keep them to screen width. Being able to fit more code on a single screen is a huge advantage for overall code readability even if it doesn't feel like it - bug rates go way up once a function or class gets too long to fit on a single screen (whatever size a "single screen" is for you, it's the having to scroll that triggers it).
I have a bunch of JavaScript files in app/assets/js/. I want to Minify them and concatinate them into a single file called app.js. I‚Äôm unsure if sbt-uglifyjs would do this, or if I need require.js, both of which I‚Äôve played with but don‚Äôt really understand the difference or application for them. Can some explain please?
I think Sam was talking about his own personal projects (only criticism of the article would be to make this point more clear), in which case he is right (ENSIME for example is stuck on Scala 2.x)
Transposing usually means swapping the rows and colums in something like a `List[List[A]]` that represents a matrix. That's not what you're trying to do, so transpose is going off in the wrong direction. The tricky part is what you want to have as a result type (and why!). You show a table, but what do you want to do with that? Lookup? Print? Different use-cases have different demands on the resulting data, and trade-offs in getting there.
Using [Requests-Scala](https://github.com/lihaoyi/requests-scala) to match the same thing you are doing down below with STTP: requests.post( "https://www.reddit.com/api/v1/access_token", data = Map("grant_type" -&gt; "password", "username" -&gt; "peet", "password" -&gt; "slimo"), headers = Map("User-Agent" -&gt; "Get Pics"), auth = new requests.RequestAuth.Basic("name", "secret") ).text() Basically the same as what you have below; I like it more, but it's just a matter of preference
Yeah, it was misunderstood. He's even still contributing to stuff.
This is better, but not good. Since everything is anonymous, and thus devoid of documentation, and I have no chance of understanding the intention behind each step. If I encountered a bug in it, I'd probably rewrite it rather than try to reverse engineer it. I'd much prefer if it was split up into smaller steps, and if it stored the intermediate results in well-named variables.
At [Mnubo](https://mnubo.com/) we use a combination of [Akka-Http LruCache](https://doc.akka.io/docs/akka-http/current/common/caching.html) and a `ConcurrentHashMap` to do that, that's pattern we use a lot when calling cachable external services. We use it in two flavors) - if the data is older that X, refresh, update the cache and return it - if the data is older that X, launch a future that will update the cache in the background but return the previous value immediately ```scala private val cache = LruCache[K](timeToLive = ttl) private val lastKnownCache = new ConcurrentHashMap[K, V]() override def getPartitionsAsync(key: K): Future[V] = { val fromCache: Future[V] = cache(key, () =&gt; actuallyFetchData()) if(lastKnownCache.contains(key)) Future.successful(lastKnownCache.get(key)) else fromCache } ```
This is kind of FUD, the same attitude that happens with new Scala versions will apply to Dotty (which will be Scala3 as well) i.e. when a new Scala version is released as a milestone, the most common libraries (which include the ones you mention) are built against it if its source compatible, Seth even manages a community build which automates this. The community is already aware, and has experience, for cross building to newer Scala versions, and Dotty also provides a `scala2` option for working with sources coded in Scala2 syntax. 
Personaly I would build a \`Map\[String, Map\[String, Double\]\]\` which for each name stores how much of things a person has: val data: List[((String, String), Double)] val thingsByName: Map[String, Map[String, Double]] = data .groupBy { case ((name, _), _) =&gt; name } .mapValues { nameThingAmountList =&gt; nameThingAmountList.map { case ((_, thing), amount) =&gt; thing -&gt; amount }.toMap } Then I would figure out the list of all possible things to own: val possibleThings: List[String] = thingsByName .values .toSet .flatMap((_: Map[String, Double]).keys.toSet) .toList And then I could print it: println(("Name" +: possibleThings).mkString(", ")) thingsByName .map { case (name, things) =&gt; (name +: possibleThings.map(thing =&gt; things.get(thing).getOrElse(0.0).toString)).mkString(", ") } .foreach(println) 
I tried your package but it doesn't work for my correct details. It just gives me a 401 response
Probably the same as some other already mentioned, but here goes my solution: `val list = List(` `(("Anna", "Apple"), 450.0),` `(("Anna", "Orange"), 450.0),` `(("Anna", "Kiwi"), 450.0),` `(("Bob", "Apple"), 450.0),` `(("Bob", "Kiwi"), 450.0),` `(("Bob", "Papaya"), 450.0)` `)` `val byFruit = list` `.groupBy { case ((_, f), _) =&gt; f }` `.mapValues(_.groupBy { case ((p, _), _) =&gt; p }` `.mapValues(_.head._2))` `val persons = list.groupBy { case ((p, _), _) =&gt; p }.keys.toList.sorted` `val fruits = byFruit.keys.toList.sorted` `val table = persons.map { person =&gt;` `val prices = for {` `fruit &lt;- fruits` `value = byFruit(fruit).getOrElse(person, 0.0)` `} yield value` `(person, prices)` `}` `val tableFormatted = table` `.map { case (p, prices) =&gt; s"$p ${prices.mkString(" | ")}" }` `.mkString("\n")` `println(s"Name ${fruits.mkString(" | ")}")` `println(tableFormatted)` 
This - and once you decide on a style, use scalafmt so you no longer have to think about it
So is the former basically a unix pipe-y library? I miss magrittr pipes in R and abuse them for my shell scripts so I could get behind that
Jep. Very easy to introduce in your project. Here is an example: [https://scalafiddle.io/sf/N3OyNdm/1](https://scalafiddle.io/sf/N3OyNdm/1) Or you can also use [the mouse library](https://github.com/typelevel/mouse). Just add it to your build and `import mouse.all._` and you can use the pipe syntax on everything.
What does your code really do? If it is just accessing the database, I‚Äôd say you need not to unit test it, as you can expect that the DB (and the API) work without any problems. If you transform the data in any kind after reading / before writing, extract that in an own function and test that function; no need to mock the DB
I am looking to unit test code that has already been written. It involves making CRUD actions on a database, passing in the appropriate objects. However accessing the DB has proven troublesome. 
Why is the fact that it's a database relevant? Just mock the interfaces?
If the existing code assumes pervasive access to a database and interleaves that with the logic you want to test, it's not going to be practical to test it without something that behaves like a database. I'd recommend using an in-memory database (e.g. H2 in in-memory mode) for the moment, so that you can write the most important business-logic tests without worrying. Performance will be much worse than a true unit test, but much better than having to use your actual database, so it's a worthwhile incremental step. Going forward you should try to unpick/separate/decouple the database access from the business logic so you can have true unit tests of the business logic. Actual database-access code can hopefully be kept simple enough as to be obviously correct and not need testing (or maybe a small amount of integration testing).
&gt; Is it possible to run obj ext App in such a way? Or pointing me to an environment/framework to do similar is good. The totality of a language like scala, and how it is made useful as a program is hard to grasp for a pleb(Advice here is welcome too). Taking a step back, what I think you want to do is configure a build manager for your project (to handle "all the lib and class stuff"), and then you'll be able to use that tool to build/run from the command line, and IntelliJ or any other IDE will be able to use your build manager config to configure dependencies/... . IntelliJ has integration with at least Maven/Gradle/SBT. In practice it will look the same, but conceptually you need to think of the build manager config as being the "source of truth" and the intellij set up as being generated from that. There's a list of "Build Tools" in the sidebar; I feel obliged to point out that most of the community prefers SBT. Personally I find SBT virtually incomprehensible and can't understand why anyone would ever use it, especially as a beginner, but if you want to use SBT then hopefully someone will show up who can help you with that. I use maven, and here's how I'd personally get started: * Install maven on your computer. Make sure it's on your path i.e. that you can run `mvn --help` from a command prompt. * Create a project folder with a basic `pom.xml` file, `src/main/scala` and `src/test/scala` directories. I don't bother with any of their wizards/activator/..., you just need a name/groupId/version and to configure the scala plugin. https://github.com/m50d/deliciouslie/blob/master/pom.xml is the most basic example I have to hand (you don't need all those dependencies or the surefire plugin; you might need to add `&lt;packaging&gt;jar&lt;/packaging&gt;). Check that you can do a `mvn install` at this stage and have it complete successfully (it will build an empty `jar` file, that's fine). https://maven.apache.org/guides/getting-started/maven-in-five-minutes.html is a more detailed version of what you should be doing at this stage (just that you additionally want the scala plugin). Once you have it working on the command line, import the project into your IDE. * Once you create your `object Foo extends App`, check that it runs fine in the IDE, then try to run it via the [maven exec plugin](https://www.mojohaus.org/exec-maven-plugin/usage.html#Command_line) : `mvn exec:java -Dexec.mainClass="com.mypackage.Foo"` . You can use this to get a basic "my application is running", and I've even known people to run a production web service that way, though I wouldn't recommend it. Any JUnit tests in `src/test/scala` will be run as part of a `mvn install` (I tend to just use JUnit, there are some Scala-specific frameworks but I don't feel like they add enough to be worth the complexity). * When you want to create something that you can distribute and run on another machine, use the [maven shade plugin](https://maven.apache.org/plugins/maven-shade-plugin/examples/executable-jar.html). This will include libraries in the jar and add a "manifest" saying which class to launch, so then you can run your application via `java -jar target/myapp-0.1-SNAPSHOT.jar`, and you can copy that jar file around to where you want to run the program * When you don't want to have to copy jars around manually, look into running a Nexus server somewhere. Use `mvn deploy` instead of `mvn install` to upload the built jar to the nexus server. * When you want a less ad-hoc version of doing releases, use the maven release plugin. * Then you might want to get a build server to do your builds/releases, via Jenkins or similar. Might also want to have it kick off deployments via e.g. puppet or fabric. * Whenever you want to do some new task as part of your build e.g. generating source from thrift/protocol buffers, look for a maven plugin to do it - usually there'll be a "standard" one Maven is well documented with lots of tutorials, but most of those assume you're using Java. Since Scala compiles to the same bytecode, most things should work just the same (e.g. I already talked about the exec plugin and the shade plugin). Best of luck, and happy to answer any followup questions.
You could try mock the HttpResponses you are supposed to recieve, or at least their status. Mockito example: when(queryDb).thenReturn(Status.NotFound)
Awesome. Wondering anyone has tried Scala Mock and compare both?
Sttp+1
Maybe you can setup an in memory database? https://www.playframework.com/documentation/2.6.x/Developing-with-the-H2-Database 
I wrote a small project in ScalaJS a couple of weeks ago (a mahjong rank calculator, https://github.com/m50d/plus-minus-zero - still need to write a readme etc. but the basic code works) and was pleasantly surprised at how easy all of it was, so I would recommend giving it a go if you know/like Scala. (I don't know about scalajs-react specifically, and that game is blocked where I'm working)
&gt; you can expect that the DB (and the API) work without any problem I'd disagree with this assumption. While I'd expect uptime in general from a DB, no piece of infrastructure will have 100% up time. Forcing these rare error conditions is a great use case for mocks since it can be virtually impossible to trigger those conditions using real implementations.
I've used this pretty successfully in the past. Works as long as you're not using any implementation specific DB functions, but sticking to generic SQL
In context there have been people spreading FUD in the Scale community lately which is why I suspect people are more on edge. Sam's article touches on a lot of these areas where the FUD has been spread. My only criticism of the article would have be that it's written from a PoV of it being "my personal situation".
scala mock has nicer syntax and implicit verification, which is very nice when it works. The problem is that it breaks in a week after you start using it, just because there are so many cases it doesnt support. So you end up writing workarounds or fallbacking to mockito.
This is purely my opinion, and I'm only barely scratching Scala at frontend myself, but I've found [slinky](http://slinky.shadaj.me/) and [react4s](http://react4s.org/) superior to scalajs-react. Both provide better compile times and add way less concepts to learn. Slinky is very close to React in terms of API and its DSL it's nicer, while react4s is more lightweight, has no macro magic (hence compiles faster) and actually greatly reduces React's API surface, especially component lifecycle.
I recently wanted to create my own wrapper around mockito. I expressed the main features in this \`mockit-scala\` issue: [https://github.com/mockito/mockito-scala/issues/17](https://github.com/mockito/mockito-scala/issues/17) cross-posting here so more people have chance to see it and discuss/propose improvements.
There are different types of biases, you are hedging all of your bets on one of them. Furthermore this point &gt; we shouldn't take at face value what people say about things they clearly have a vested interest in? Doesn't make any sense in context. Scala's own vested interest is actually making the migration as painless as possible, which is the opposite of what you are implying. Heck I wouldn't be surprised if Lightbend's own vested interested is for Scala3 to never happen because of it being difficult (in terms of migration). EPFL/ScalaCenter are not sales people selling you snake oil, this kind of attitude isn't apt here.
 val list = List( (("Anna", "Apple"), 450.0), (("Anna", "Orange"), 450.0), (("Anna", "Kiwi"), 450.0), (("Bob", "Apple"), 450.0), (("Bob", "Kiwi"), 450.0), (("Bob", "Papaya"), 450.0) ) val names = list.map{case ((n, _), _) =&gt; n}.distinct val fruits = list.map{case ((_, f), _) =&gt; f}.distinct val listAsMap = list.toMap val result = names.map { n =&gt; List(n :: Nil, fruits.map { f =&gt; listAsMap.getOrElse((n, f), 0.0) }).flatten } 
Still, not reliable. I remember that in some (older) version of PostgreSQL you couldn't use upsert reliably - it compiled, it worked with H2, it blew up as soon as you switched to PostgreSQL. Of course, you can define a subset of "safe" operations, but then you have to check them yourself, as e.g. Slick will gladly compile and generate a failing query in runtime.
+1, `IntegrationTest` config is the way to go! Run non-integration test (unit, functional) without dependency on database, and test against actual DB in some reliable environment e.g. using Docker or dedicated local test db (whichever you prefer).
In perfect world it shouldn't, but in our world there is Slick. And with Slick you [might have issues mocking](https://stackoverflow.com/questions/44336658/mocking-slick-dbio-dbio-composition-in-specs2/48902135#48902135) (shameless autopromotion). With Quill/Doobie you might have less issues, though integration test against an actual (test) database is still the most reliable thing.
Nice work!
The teams did reach out to each other. Setting up the initial collaboration too time I guess, but as you see now it's ongoing and that's only good news for Scala moving faster in Spark in the future :-)
https://danielwestheide.com/blog/2013/02/13/the-neophytes-guide-to-scala-part-13-path-dependent-types.html Describes path dependent types, using fan fiction. But in the example of where it's a compile error due to mis-matching PDTs How could I define a method/class that accepts Characters from different franchises (on purpose) in a class or method called CrossoverSpecial() for example. e.g. that crossing franchises is allowed, but only specifically in this class / method that's designed for it?
Are you guys doing any FP or is it mostly Play, etc.?
I sympathize with this opinion about long lines but do you have some evidence for this? 
Can't find it immediately - I remember seeing some kind of study (probably linked from reddit) but it was a while ago. 
I usually go with something like the `State` monad from Cats if I want to with something that doesn't just return dummy results :)
Thanks!
When you want more flexible constraints on types, the way to do it is with a (possibly multi-parameter) typeclass, and then you define instances only for the cases that are valid. Unfortunately since singleton types are only sort of "real" types, at this point you probably want to make the franchises themselves first-class types and have a character's franchise be part of their type in the normal way. So something like: trait Franchise[F &lt;: Franchise[F]] // self-type parameter so that people don't accidentally just pass Franchise everywhere and undermine safety case class Character[F &lt;: Franchise[F]](name: String) trait Crossover extends Franchise[Crossover] sealed trait ValidPairing[F &lt;: Franchise[_], C1 &lt;: Character[_], C2 &lt;: Character[_]] object ValidPairing{ // implicit instances define which (Franchise, Character, Character) combinations are valid implicit def sameFranchise[F &lt;: Franchise[F]]: ValidPairing[F, Character[F], Character[F]] = new ValidPairing[F, Character[F], Character[F]]{} implicit def crossoverOk[C1 &lt;: Character[_], C2 &lt;: Character[_]]: ValidPairing[Crossover, C1, C2] = new ValidPairing[Crossover, C1, C2]{} } // Have to use a structural type trick to allow us to specify one type parameter to a 3-type-parameter method. import scala.language.reflectiveCalls def createFanFiction[F &lt;: Franchise[F]] = new { def apply[C1 &lt;: Character[_], C2 &lt;: Character[_]](c1: C1, c2: C2)(implicit valid: ValidPairing[F, C1, C2]) = {} } trait StarTrek extends Franchise[StarTrek] trait StarWars extends Franchise[StarWars] val quark = Character[StarTrek]("Quark") val jadzia = Character[StarTrek]("Jadzia Dax") val luke = Character[StarWars]("Luke Skywalker") val yoda = Character[StarWars]("Yoda") And then we have the behaviour we want: you can write Luke/Yoda in the Star Wars universe: scala&gt; createFanFiction[StarWars](luke, yoda) You can't write Luke/Quark in the Star Wars universe (or the Star Trek universe): scala&gt; createFanFiction[StarWars](luke, quark) &lt;console&gt;:18: error: could not find implicit value for parameter valid: ValidPairing[StarWars,Character[StarWars],Character[StarTrek]] createFanFiction[StarWars](luke, quark) ^ But you can write Luke/Quark in the crossover universe: scala&gt; createFanFiction[Crossover](luke, quark)
For now I thank you for the reply! I suspected this was the stuff I needed more information about maven ect. I've hesitated on figuring out concepts where maven belong as I didn't know if they gave me anything as a (for now) hobbyist. I'll follow your points and see where end up. Thanks
Only if you interpret immediately into future and turn that future into something else (F[_]). If you wanted to compose DBIO then your TTFI would have to have layer of services and layer of persistence and also pass some sort of natural transformation from one into the other. And you cannot really flexibly compose DBIO without importing the driver api which is a leaky abstraction. So you can would end up with mocking values returned by database but with no ability to pattern match DBIO argument as it gives you no ability to test for equality. Or you can mock whole service, which is good for composing services, but not for testing your queries without database.
You can use monadic composition with slick-cats; we do this and so far it's worked out well. What you can't do is mark transaction boundaries outside of the tagless implementation
Are you using a framework like Play or just the standard sbt-native-packager? Usually that error means you are missing an entry in plugins.sbt or Ivy resolution didn't complete successfully
Thanks I forgot an entry in plugins.sbt!
Touche, I think now I actually had problem with Query mapping
Yeah, it can be hard to know where to start - the Java tooling is a bit disorganized as it's an old language, but I find maven is the best entry point to start from, even for a small throwaway utility. I hope I was clear that you don't have to go any further than using `mvn exec:java` if you just want to write some code and run it.
`Try(getIt()).toOption` ?
I feel like I'm stating the obvious, but just define a function and catch it? def npe[T](t: =&gt; T): Option[T] = try { Option(t) } catch { case npe: NullPointerException =&gt; None } npe(foo.getBar())
That would swallow other potential errors.
Option(null) == None, so Option(javaObj.getNullableField) will safely obtain the value if it exists. Keep in mind that Some(..).map(null) will produce Some(null) so it can't be properly chained.
Imo, if you can afford to have a None as a return value &amp; can use it in your code then u/pixelflat 's answer is good enough. In the end what you really care about is the value, not the error. If you still want the error then it should return a Try or an Either. There is no benefits making a non-total function by re-throwing other exceptions when we're trying to avoid all the Java nastiness in the first place.
really neat demo, looking forward to seeing the finished work!
That's a great time to use flatMap(Option(f(_)) on the chaining.
If you don't mind cats dependency, you can use its provided Monoid to combine those val rawData = List( ("Anna", "Apple", 450.0), ("Anna", "Orange", 450.0), ("Anna", "Kiwi", 450.0), ("Bob", "Apple", 450.0), ("Bob", "Kiwi", 450.0), ("Bob", "Papaya", 450.0) ).map { case (a,b,c) =&gt; Map((a, Map((b,c)))) } Monoid.combineAll(rawData) .map { case (name, data) =&gt; List( name, data.getOrElse("Apple", 0), data.getOrElse("Orange", 0), data.getOrElse("Kiwi", 0), data.getOrElse("Papaya", 0) ).mkString(", ") }.foreach(println)
Please explain why.
I already did. That would swallow other potential errors and OP didn't say he wanted to catch anything besides null pointer exception.
That's just being pedantic and providing a solution to a theoretical assignment you interpreted from OPs post, with no real world relevance.
There's some nice libraries I've played around with in general in their repo. eg.) [https://github.com/ovotech/kafka-serialization](https://github.com/ovotech/kafka-serialization) Also they're hiring in London, UK: [https://stackoverflow.com/jobs/197192/fullstack-developer-ovo-energy](https://stackoverflow.com/jobs/197192/fullstack-developer-ovo-energy)
You can test this yourself, make foo() and bar() do Thread.sleep with a reasonable time and see how long it takes to execute. This should help you figure it out. Remember for comprehension is just syntactic sugar for a series of flatMap and map operations. If you want them to run in parallel you can use Future.sequence or evaluate the futures before the for comprehension.
First time I've seen this project, and I really like the approach. 
That's just it. If your futures don't depend on each other and you want to start them simultaneously, then you don't need a for comprehension.
All that really changes is which method gets wrapped in the Option.apply; instead of Option(javaObj.getNullableField) it'd be Option(otherJavaObj.getJavaObj)
You just run them like you would a normal function call. foo() bar()
Support for native Time-To-Live state is very welcome, as is the ability to store timer state outside of memory (in rocksdb). We have an application at work which stores a timer per key, and the memory required to store that many timers posed the biggest scalability issues.
I don't mock databases. I run an instance using a convenient wrapper. Examples are https://github.com/vorburger/MariaDB4j and https://github.com/yandex-qatools/postgresql-embedded
Have you ever tried to debug a problem where the root cause is getting swallowed silently by a big catch(Exception e) { return everythingIsFine; }, as you're suggesting? I have. It \*sucks\*. Be as narrow and specific as you can when catching exceptions.
This ended up working the best for my particular use case (ended up being that I had a long chain of getters where somewhere along the line the return result was null so it didn't have a child object to call a getter on). 
example uses (might be outdated) https://github.com/shawjef3/sdbc/blob/master/postgresql/src/test/scala/com/rocketfuel/sdbc/postgresql/HasPostgreSqlPool.scala https://github.com/shawjef3/sdbc/blob/master/mariadb/src/test/scala/com/rocketfuel/sdbc/mariadb/HasMariaDbPool.scala
How would this work if it were like this: `Option(otherJavaObj.getJavaObj1.getJavaObj2)` and JavaObj1 is null so there is no getJavaObj2 getter to call? I still get a NullPointerException.
I agree, but if that is the case we are no longer talking about some POJO getter. Plus, OP explicitly asked for something other than a try/catch block.
val futureF = foo() val futureB = bar() for { f &lt;- futureF b &lt;- futureB } yield (f, b)
Personally I used own wrapper for database backend, but still, you cannot do: ```database.run(expectedDBIO) returns Future.successful(result)``` because DBIO (like many other pipelines recipes) cannot be tested for equality. You could mock DBIO generating code (though as a result of a pure function mocking it is quite sad), or use some more or less crazy workaround for the issue. Or don't mock at all and test against database.
Try this: `Option(otherJavaObj.getJavaObj1).map(_.getJavaObj2)`.
No. However, you can do this: for{ \_ &lt;- Future.successful(()) f = foo() b = bar() fooResult &lt;- f barResult &lt;- b } yield (fooResult, barResult) And \`foo()\` and \`bar\` will run in parallel. Of course this is annoying, so if you bring in cats you can do this `import cats.syntax.apply._` `import cats.instances.future._` `import scala.concurrent.Future` `import` [`scala.concurrent.ExecutionContext.Implicits.global`](https://scala.concurrent.ExecutionContext.Implicits.global) `def foo: Future[Int] = Future.successful(1)` `def bar: Future[String] = Future.successful("Hello")` `(foo, bar).mapN(Tuple2.apply _)`
&gt; that's just being pedantic You must be a real treat in PR reviews
Would at least add logging when it's _not_ a null pointer exception Source: am author of bugs
It might have come across a bit ruder as intented (not my first language). But I stand by my point...
you stand behind a decision to swallow errors...? 
Which errors? It's a getter that throws NPE when the value is `Null`. If you wrap it in a `Try().toOption`, nothing prevents you from logging on `None`. I [already said](https://old.reddit.com/r/scala/comments/95xwhm/avoiding_nullpointerexception_on_java_getter/e3wa2w4/) if you want to handle more Exceptions individually you can match the result. But OP did not say anything about that...
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/programming] [Continuous Delivery Implemented with Event Sourcing at eBay](https://www.reddit.com/r/programming/comments/962gmy/continuous_delivery_implemented_with_event/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
No. If you must return Unit, you have to have a side effect or just the pure function that does nothing but return `()`. A question is can you turn things inside out and put the Java method inside an IO.
Sadly the interface I'm implementing gets consumed in another Java class, so I don't think I have any control over that. Basically there's some sort of loop running in that class takes in `EWrapper` that calls these methods to side effect.
That's fine. Sometimes you don't have a better choice when interacting with Java libs. I do the same here: https://github.com/gvolpe/fs2-rabbit/blob/master/core/src/main/scala/com/github/gvolpe/fs2rabbit/interpreter/AMQPClientStream.scala#L43
Yeah it's powered by `AtomicReference` and `compareAndSet` internally
Shouldn't `???` just be `(x: A) =&gt; Some(f(x))`?
Thanks, easy as that :)
btw, a "function accepting function" is called a "higher order function" :)
As a follow up question I assume one needs to explicitly "use the optionLiftable". Is this assumption correct? So I can do `Some(1).flatMap(optionLiftable.lift(x =&gt; x+1))` but not `Some(1).flatMap(lift(x =&gt; x+1)) //doesnt compile` I know the implicit thing with function parameters, so my question isnt about that.. It would just be nice to be able to use the latter syntax..
Another follow up question, why optionLiftable is null?
Oh, it needs to be declared before using it :)
Just put the `lift` method on an object somewhere. If you're really using this as a typeclass with multiple implementations then the usual approach would be to put the method on the typeclass' own companion object, something like: object Liftable { def lift[M[_],A,B](f: A =&gt; B)(implicit liftable: Liftable[M]): A =&gt; M[B] = liftable.lift(f) } import Liftable.lift Some(1).flatMap(lift(x =&gt; x+1)) You would almost certainly need to build with `-Ypartial-unification` and even then this specific example might not work, I don't know if the type inference is good enough to figure `M` out from context here. But that's the general idea.
You might be interested in the `Kleisli` abstraction : https://typelevel.org/cats/datatypes/kleisli.html In particular, it comes with the ability to `lift` : https://github.com/typelevel/cats/blob/38c52ad439d759739daa63bc2489ab8522e7776e/core/src/main/scala/cats/data/Kleisli.scala#L320
Thanks!
We have a akka-http api that provides a layer over a graph database. I'm building a job to import and export graph data. It uses gremlin-scala but I wish it used RDF instead.
Thanks for sharing this article!
Better examples for Monad Transformers are Option or Either in something like Task or IO Monad. You need those to compose multiple steps in your Program in a for comprehension. I think List is a very poor example.
Thanks for the answer, but it is about getting birthday of persons spoupes (if any) :) Also some for comprehension would be nice..
Maybe, but option and list are probably most easiest to grasp, especially with java background
Are those normal salaries for Europe? They're absurdly low for the US. 
scalajs-react has no mandatory macros. I'm getting a bit tired of this incorrect information. For some of the optional, add-on features (the router, \`Reusability\`, etc) there are a few tiny macros for typeclass derivation. In core the only macro is \`.renderBackend\` which is optional too and so simple that I'd be very surprised to see any evidence that it causes some big slowdown in compilation time. Not to take a poop on slinky or react4s but in my opinion and very significant experience, use scalajs-react if you care about having a working maintainable product. It's got lots of type-safety, is FP, has lots of add-ons, has a huge story around testing, reliability, and performance.
Hi! The Scalaz group is currently organizing several collaborative projects at all skill levels. https://scalaz.mobilize.io If that link doesn't work let me know. On mobile and not entirely sure. 
If you like web dev, see my https://github.com/sake92/hepek project. It's really simple and fun, welcome! :)
Yes check out the Scalaz projects, it should be a great learning experience with the added mentoring they are offering.
Yep there is a huge gap between EU and US salaries, especially in tech. But that salary in Europe is still a very decent salary for any industry. The living costs here in comparison to say New York or San Fran are also very far apart. That salary for a developer in for example Poland, which is 5 times cheaper to live in to New York, is fantastic. All depends on your local economic situation :) But I think this role will be better suited for an EU based developer anyway as even though it‚Äôs remote they‚Äôll need the person to work standard CEST working hours!
Hey, this is really cool. Is there an explanation somewhere on what the different choices mean?
If you want to try web development, I'm the author of [https://github.com/AlexITC/crypto-coin-alerts](https://github.com/AlexITC/crypto-coin-alerts), happy to help if you want to contribute.
Okay, I have a few style issues to report. So basically you should never use nulls in Scala. If you want to signal that a value can be absent - that's what Options are for. So I would start with redefining your case class as follows: `case class Person(marriedTo: Option[Person], birthDate: Date)` Also, you shouldn't be using vars if you want to write idiomatic Scala code, so personX definitions could rather look like this: val person1 = Person(None, new Date()) etc. Functions getSpouse and getBirthday are unnecessary, because you can access case class fields directly. If you wanted to make birthDay field optional, then, again, it should be reflected in the field's type inside the case class. (I didn't make this one optional though) To be honest, there is no need to use monad transformers at all to achieve what you've described. Function `getBirthdays` can look like this: `def getBirthDays(persons: List[Person]): List[Option[Date]] = persons.map(spouseOpt =&gt; spouseOpt.map(spouse =&gt; spouse.birthDay))` After calling getBirthdays(persons) you will end up with List(None, Date(...), None, Date(...)) as expected. If you want to avoid writing this nested map (that's the reason to use monad transformers in the first place - to "unnest maps"), you can do def getBirthdaysMonadTransformer(persons: List[Person]): List[Option[Date]] = { val spouses: List[Option[Person]] = persons.map(_.marriedTo) val spousesT: OptionT[List, Person] = OptionT(spouses) spousesT.map(_.birthDay).value } Here is the complete code: [https://gist.github.com/agluszak/400b95f063dcd4b580b0bc1a277ba2f6](https://gist.github.com/agluszak/400b95f063dcd4b580b0bc1a277ba2f6) I recommend reading Cats documentation on OptionT ([https://typelevel.org/cats/datatypes/optiont.html](https://typelevel.org/cats/datatypes/optiont.html)) and - if you want to know more - these books: [https://www.manning.com/books/functional-programming-in-scala](https://www.manning.com/books/functional-programming-in-scala) [https://underscore.io/books/scala-with-cats/](https://underscore.io/books/scala-with-cats/)
Do you want something targeting end users (as suggested by your experience) or it can be any project, including libraries and tools?
Plus one on this 
I'm glad I could help :)
[https://github.com/SpongePowered/Ore/](https://github.com/SpongePowered/Ore/) Is a 'package manager' for Minecraft Plugins for the SpongeAPI Using Scala + Play. We desperately need help from \*\*experienced\*\* Scala developers, rather then just Java dev's that have a little experience. I've spent a fair amount of time splitting tickets into milestones, and what direction we are heading in, But I'm an extreme Scala novice. It's supposed to be the SpongeAPI equivalent of say [dev.bukkit.org](https://dev.bukkit.org) or [https://minecraft.curseforge.com/](https://minecraft.curseforge.com/) Except with the long term goals of having reviewed jar's by volunteers, as well as nice API's + maven like structure so developers can easily and automatically depend on other plugins API for better and larger interoperability. If you are interested, drop by our Discord, [https://www.spongepowered.org/chat](https://www.spongepowered.org/chat) Or hit us up on #spongeore on EsperNet
 For a pair of futures, just use f1 zip f2 which works fine. For 3 futures, see https://gist.github.com/tomaszperek/a6863bba0b169a4bb08d In the general case, Applicative is what you need.
Based on your background you might be interested in scalaz-analytics, scalaz-ml or scalaz-tensorflow, but there are plenty of others if you want something else too :)
Let me try by combining parts of the two snippets you shared: **Type classes define classes of types**, by acting like an *interface or API that represents some functionality we want to implement* and the classes that implement the type class can be said to belong to a class of types...**same way types define classes of objects** and objects that are instances of that class, can be said to belong to the same class of objects. Did this help?
Expounding a little bit on this I would say that in typical style OOP, When we create a class, and we create instances, one of the reasons we might do this, is that we want to guarantee that all the instances of this class, have the same behavior (methods and properties etc). Hence all the instances can be rightly said to belong to the same class, because they are instances of the same Class. They can be rightly grouped this way. When we also create type classes and provide instances, we want to provide a mechanism that ensures that classes that might be an instance of different classes can still be seen to belong to the same category, same "class", as long as they exhibit the same set of behaviors. The similarity in this two endeavor is why I guess the comparison was made in the article you shared. Typeclasses in Scala is a pattern and I personally found that it requires having a good understanding of other language features and concepts before it can be truly grokked. I put together a series of blog post on type classes...You can find it here [Exploring Type class in Scala: A knowledge pack](http://www.geekabyte.io/2017/11/exploring-typeclass-in-scala-knowledge.html), perhaps it would help you in your quest to understand it. Regarding the sentence, you referenced, that your colleagues make...I am not sure I understand the intent. Perhaps more context would help
I do not know \`cats\` but would this code just work fine for what you want? `package demo` `import java.util.Date` `class MonadTrans {` `var person1 = Person(None, new Date())` `var person2 = Person(Some(person1), new Date())` `var person3 = Person(None, new Date())` `var person4 = Person(Some(person3), new Date())` `var persons : List[Person] = List(person1, person2, person3, person4)` `def getBirthdays(persons : List[Person]) : List[Option[Date]] = persons.map( p =&gt; p.marriedTo.map(spouse =&gt; spouse.birthDay))` `def getSpouse(person:Person) = Option(person.marriedTo)` `def getBirthday(person:Person) = Option(person.birthDay)` `}` `case class Person(marriedTo:Option[Person], birthDay:Date)`
You can also do: \`\`\`scala for (((a, b), c) &lt;- futA zip futB zip futC) yield a + b + c \`\`\` There's also zipWith (I don't think it can be used with 3 though): \`futA.zipWith(futB)((a, b) =&gt; a + b)\`
It is all coming together! That's for the blog post, I found it before you shared it! ;) The first entry on polymorphism is great, and it helps a lot! 
Thanks for your explanation and elaboration on these two definitions. It's all coming together now! :) 
I agree with [agluszak](/u/agluszak) that it is better to model Person as case class Person(marriedTo: Option[Person], birthDate: Date) Using the definition above one can get the spouse birthdays using nested maps as below def getBirthdays(persons: List[Person]): List[Option[Date]] = persons.map(_.marriedTo.map(_.birthDay)) and using a for comprehension with monad transformer as below def getBirthdays(persons : List[Person]) : OptionT[List, Date] = for { spousesT &lt;- OptionT(persons.map(_.marriedTo)) } yield spousesT.birthDay Hope this helps.
A type class in Scala is a strategy object. It encapsulates behavior and is used as a parameter for methods as per the strategy pattern. Except, it's an implicit parameter. tldr A type class is an autowired strategy. 
A slightly different view that may be helpful for intuition. Ignore the OO definition of "class" and consider the set theoretic definition: "a class is a collection of sets (or sometimes other mathematical objects) that can be unambiguously defined by a property that all its members share." In this case the mathematical object is "types" and the trait directly defines the properties that all its members must share. The properties that define a type class (in Scala) include kind, related types, values and functions. Others have discussed the value and function properties. The "kind" property is worth mentioning because it's a bit obtuse. The kind is communicated by the structure of the type parameter of the trait. EG: "trait Bar[T]" and "trait Zab[F[_]]" express different kind properties. Specifically "*" and "* -&gt; *". (I'm glossing over poly kinds)
This is quite interesting! It gives some perspective that you could have a type class of anything - groups, vector spaces, integrable functions, differentiable functions etc. Is that correct? Are there any real life scenarios where you would define mapping between two different type classes? For example the obvious ones, from group to monoid or monoid to semigroup? If so, is that kind of mapping possible to write programatically? 
Within limits of the properties scala can express: yes! Fortunately, this matches well with category theory. If there is a category theory representation of the properties then this can be mapped to a type class. Which had resulted in a large number of mathematical objects having type classes. Scala is a bit less developed than Haskell here. I'm unaware of a differentiable function representation. However, the others you mentioned have type classes in Spire: https://github.com/non/spire/blob/master/README.md As for functions between type classes: yes! That is a very useful feature called implicit derivation. Which exactly implements the idea of relation between type classes. For instance "if a type has the properties of a monoid then the type has the properties of a semigroup" can be written as a function from an instance of a monoid to semigroup instance. That said, both Scala and Haskell typically use subclassing for that relationship given its so common. Eg: requiring defining the semigroup properties to define the monoid properties of a type. There are other relationships that don't match subclassing where implicit derivation is essential.
Part of the problem, IMO, is there are several ways you can represent the "typeclass" concept in Scala. In fact, that motivated Michael Pilquist to develop the wonderful [Simulacrum](https://github.com/mpilquist/simulacrum) library for providing simple syntax support for defining typeclasses in Scala in a perspicuous way. One thing that all of the definitions do seem to have in common is an understanding that a typeclass must have a type parameter, e.g. `Semigroup[A]` (stealing from the Simulacrum page). You can read that as "`A` forms a `Semigroup`" assuming there is, in fact, an instance of `Semigroup[A]`. The machinery Simulacrum generates makes it possible, with just an `import` or two, to say things like `foo |+| bar` for values `foo` and `bar` of any type `A` for which there is a `Semigroup[A]`. That's an admittedly trivial example. Where this becomes more useful is in using libraries providing many such basic typeclasses (`Semigroup`, `Monoid`, `Functor`, `Applicative`, `Traverse`, `Monad`, etc.) along with their relationships (all `Monad`s are `Functor`s and `Applicative`s, too) and the functions and/or syntax to make using them straightforward. What's a bit surprising, maybe, is: once you get used to saying things like `(implicit M: Monad[M])` and using `M.bind` to sequence operations and the like, it becomes apparent that you're automatically excluding a raft of incorrect behavior patterns, because you don't even know what the type `M` actually is, so you can't accidentally use any weird, inconsistent behavior it might possess. If it has a `Monad` instance `Monad[M]`, then you can constrain yourself to _only_ using its `Monad` (or `Applicative`, or `Functor`...) features, and those features satisfy a handful of laws guaranteeing that using them together works in an orderly, predictable way. And this is why those of us who do functional programming in Scala do so.
Thanks for the help :-)
Fixed!
Cool! Thanks! The whole point of this excercise was to teach myself monad transformers with java background and then it makes sense to try to combine "Monads" available in java (there's also ComtebaleFuture). Now I'm thinking [mart187](https://www.reddit.com/user/mart187) is correct, List is poor example and it probably makes no sense with Option as Option can be though also List with 0/1 elements
There are two directions you can go here. You could use shapeless typeclass derivation to define your typeclass in a way that can automatically derive an instance for `Animal`, [see this example code](https://github.com/milessabin/shapeless/blob/master/examples/src/main/scala/shapeless/examples/shows.scala#L74). Or you could use a `HList` instead of a `List` so that you keep the specific types of each element as part of the list type.
What about something like this ? `implicit val showAnimal: Show[Animal] = Show.show {` `case Dog() =&gt; "dog"` `case Cat() =&gt; "cat"` `}`
Ahhh yes that's exactly what implicit resolution meant for ... yes shapeless is the way to go! thanks @m50d
That's a good plan! However I would like to build my code without subtyping polymorphic where possible .. but still thanks for the idea:)
Not completely, because vanilla scala has no way of treating an ADT in a generic way. That's the one part that you have to rely on a macro for, and it's probably better to reuse the one from Shapeless than reimplement it yourself. (Look at `LabelledGeneric` if you want to know the details, but they're pretty gnarly). I think singleton types may also be waiting for an SIP before you can use them directly without a macro. I've forgotten what the real syntax for labelled types is, so I'm going to write `Labelled['myLabel, T]` below; hopefully the actual syntax is somewhat similar. The rest of it you can do yourself, and it's worth it as an exercise IMO; you essentially build up the typeclass instance inductively, so you define a case for `CNil` and a case for where you have a `Labelled['myLabel, T] :+: Rest` (an type that represents) where you have a typeclass instance for `Rest` and one for `T`. The implementation of `LabelledTypeClassCompanion` is actually pretty simple and worth reading, it just covers most of the boilerplate for you. So you should be able to write some code that generically derives an instance of `Show[Labelled['Cat, Cat] :+: Labelled['Dog, Dog] :+: CNil]`, which is a generic representation of `Animal` - shapeless' Coproducts `:+:` are a generic "one of these" type (where `CNil` has no instances, it's just a base case) and `Labelled` is a phantom type that represents the names at compile time (if you don't need to use the actual names of the types then you can use `TypeClassCompanion` and everything becomes a lot simpler, you only need to derive an instance of `Show[Cat :+: Dog :+: CNil]`). The part that you can't do in vanilla Scala is the translation back and forward between `Animal` and `Cat :+: Dog :+: CNil`. Maybe in a future version...
Oh hey! This is something that really annoys me too about typeclasses, especially since I learned that Rust supports this which kind of whet my appetite. You should check out [this discussion](https://contributors.scala-lang.org/t/trait-objects-for-better-use-of-type-classes/1684), where I also link to existing library [polymorphic](https://github.com/alexknvl/polymorphic) which contains an implementation of "trait objects" which they call "instance". 
Brilliant!! I will figure out the rest! Thanks for the details:)
These SIPs are not very controversial. 
If you use `scalaz-deriving`, as documented in https://leanpub.com/fpmortals and https://gitlab.com/fommil/scalaz-deriving you need only type: ``` import scalaz._ @deriving(Show) sealed abstract class Animal final case class Cat() extends Animal final case class Dog() extends Animal ```
How is the latter different from a Java interface?
Meh, not everyone likes or wants XML literals in the Scalajs ecosystem. Some libraries like Binding.scala use them but most don't, and they really don't have to, given how easy it is to implement a similar enough DSL (that could actually improve on XML literals)
I'm not picking sides here, just predicting vigorous debate. That said, given the choice between any Turing complete language, you really don't have to anything. It's just a matter of choice what you choose to have as a language feature, how much it offers in ergonomics, and how much it costs in terms of syntactic overhead. I read below that there are js devs that will gag at syntax like `x"&lt;div&gt;I find the language tools offered to me grounds for hyperbole like &lt;blink&gt;gagging&lt;/blink&gt; at syntax&lt;/div&gt;"` I don't think reasonable discussion can be had with such statements. Hopefully, there will also be more measured arguments on both sides that rely less on emotion and more on merit.
Its all about how you organize it, thats all. With classes its like this: Class { Method1 Method2 ... } Whereas with type classes: Method1 { Type1 Type2 .... } So for example you could implement Add() for different types like Int and Float.
What matters is not if they are controversial or not, but rather the process. We'll follow this process for both the controversial and non-controversial SIPs, so that everyone has a say in every feature/removal/improvement in the Scala 2 -&gt; Scala 3 migration.
The majority of developers might as well choose `div(cls := "wrap", div(content))`. That's what most libraries offer right now when they don't use XML literals.
I see. It sounds like that famous duality thing between FP and OOP. Adding methods is easier in one, adding types/classes is easier in the other.
The choice of wording there is a bit odd, as if you wrote the blueprint and various constructions firms are now building off of your blueprint. It would be more accurate to say multiple people set off on multiple explorations of how to build language servers, and afterwords you wrote a blog article on how you have already thought all of this through. It's true, you have been working on this for a long time, but I don't know of any of those other implementations that are working from your blueprint.
Javascript also has custom interpolators, it just uses backticks instead of double quotes. The term they use is for it is "template literals" but it's essentially the same thing. Here is one library that uses it instead of JSX: https://github.com/choojs/hyperx 
We don't use the play framework as far as I know. Scala is used for microservice development. Most teams try to follow FP principals.
Whats the Scala strategy to adopt developer mindshare?
I am not aware of any official strategy, and wish one existed, but I also do not feel too concerned about it. I feel Scala's gotten to where it is almost purely off it's technical strengths and I expect it will continue growing on that same basis. It might not grow its user base as fast as it could or as fast as other languages with a concerted effort to bring people in, yet I doubt it's going to fall off a cliff and disappear any time soon. 
That's not really subtype polymorphism though, or at least it's a kind of subtype polymorphism that you'll be using everywhere else in your code if you have an ADT - how else would you deconstruct your value of type Animal into either Cat or Dog? See [this typelevel article](https://typelevel.org/blog/2014/11/10/why_is_adt_pattern_matching_allowed.html) for a more in depth discussion about why this is perfectly acceptable. I would consider not even providing instances for Dog and Cat - conceptually, they're not types, they're values of type Animal. It's basically the same reason I wouldn't write an instance for true and another for false, but a single one for Boolean.
Nice work, but unfortunately this is not quite full-proof, mainly when your service goes down while the request is processed (normal operations or reverts) one end-up with corrupted state regardless. (Yes quite rare issue, but still it would be nice if someone came up with solution to this problem)
Someone with maintainer access to ScalaZ said so on the ScalaZ IRC channel, which is as official as it gets for a project like that. 
No, *anyone* has always had maintainer access. Just ask. None of the core contributors knew anything about typelevel. Someone simply wrote the sentence on the internet. A "project like that" has no obligation to correct the wrong things on the internet. "I now own Microsoft." It was as silly as that. 
If people choose to use or ignore the "blueprint", or "recommendations", that is their choice. But it is there, and it covers all the challenges that anybody writing an LSP will uncover. There are very little areas for innovation since the majority of challenges are integration. Time will tell if anybody gets LSP working on Scala 2 to a level that it competes with IntelliJ. However, it certainly seems that the steam has run out: nobody cares enough to push ENSIME over the line with LSP or metacp, EPFL / Lightbend have abandoned ScalaIDE and the presentation compiler, and there is no commercial funding forthcoming for the LSP-WG. In any case, I don't care anymore. And this whole thread has been a complete and utter clusterfuck. So thanks, Scala community.
As far as anyone on the outside could tell, Hupel was a "core contributor" at that point. Microsoft puts out press releases on Microsoft.com and has a phone number you can call if you're not sure if one is genuine or not. ScalaZ announcements normally happen through some random blog post or person saying so on IRC.
No, not as far as "anyone could tell." Hupel was never a core contributor. Ask any of the actual core contributors, who are all examples of anyones who could not tell. No, that is not how "ScalaZ announcements" occur. I sympathise with anyone who believes it, but it is incorrect, among many things. Scalaz never had anything to do with typelevel. The Z is lower-case, by the way. 
You don't get to define what did or didn't happen just by vigorously asserting it. ScalaZ was part of typelevel, because it performed all the actions that an organisation joining typelevel would do; that is to say, a representative of the project communicated to those users that the project was part of typelevel. Perhaps some contributors did not want Hupel to be a representative of the protect; nevertheless, since users reasonably understood him to be one, he was, whatever those contributors' feelings on the subject. The question of who represents an organisation is a matter of mutual consensus, not of who declares themselves privately to be the "actual core contributor" without making any effort to communicate with users. 
&gt; No, I am not defining it by asserting it. Yes you are. You're repeatedly asserting your definition of ScalaZ and the only substantiation you give is more assertions. (If you'd put half as much effort into actually conveying understanding as you do into asserting that you're right and asserting that others are wrong then the whole debacle would probably never have happened in the first place) &gt; Some observers may believe that. Even many observers. That still did not make it true. For purely semantic questions, which this is, consensus is in fact what makes them true or not. ScalaZ is what people think it is and is not what people think it is not, because projects are social constructs; you will not find a physical atom of ScalaZ anywhere.
OK fine. I am asserting the definition according to *every core contributor to Scalaz*. No it's not "what people think it is", but even so, you're *still wrong*. I personally know thousands of people who know the definition of Scalaz, and subsequently, that you are wrong. You do not have the same numbers. You have a bias. It is understandable that you are wrong. 
*I'm* biased? You very clearly have a close personal involvement here. I'm actually a neutral third party - I have no involvement with or love for typelevel (aside from tiny code contributions, and I've done those for ScalaZ too) or any side of the whole mess. Whatever people say now, at the time it was widely understood that ScalaZ was part of typelevel - just look at IRC logs from the time. Heck, even Morris agreed that was the case - look at the readme from his "scalazeta" fork where he talks about "restoring the original goals of ScalaZ".
Yes, you have a sampling bias, not a bias because some other involvement. You have heard some words from a small number of very noisy people. Subsequently, you believe you now know how "Scalaz announcements" occur, and many other, weird and incorrect things. No, it was not widely understood that Scalaz (lower-case Z by the way) was part of typelevel. Again, ask *any of the core contributors* of Scalaz, of which Lars Hupel, and anything to do with typelevel, was not a part of. I could find a hundred people within 50km of me right now who know this is not true. This is a terrible way to make the point, but it was definitely not "widely understood" and even if it was, that does not make it true. Just like if it became "widely understood" that I now own Microsoft, I do not suddenly thereby take ownership. &gt; even Morris agreed that was the case This is also not true. FWIW, this is very weird, given how fantastically untrue it is, yet a) I understand why you believe it b) you believe it with such conviction.
I'm unconvinced by removing early initializers - doesn't that make anonymous classes more of a special case than they currently are? What's the benefit? Is there an actual SIP for the DelayedInit/OnCreate one? I didn't see a clear conclusion in the thread.
A common pattern to to put all calls to external systems (ws client, db access) into a class with Repository in the name. When writing controllers, mock out your business logic. When writing unit tests for your models and business logics mock out the repositories. For the repositories you have now massively simpler situation regarding what to test. I normally just have those functions write to my regular local testing database but use Unique ids, to isolate my test data from the rest of the data.
Caitie McCaffrey has a good approach to doing this: [https://www.youtube.com/watch?v=0UTOLRTwOX0](https://www.youtube.com/watch?v=0UTOLRTwOX0) Essentially, you need a log/database that you persist when you start/complete each action. There are additional constraints (idempotent requests, compensating actions cannot fail, etc.) covered in the video which need to be covered for this work properly
How do you define different instances of Show?
you don't! That would break typeclass coherence.
Has anyone got Emacs and lsp-mode working for Scala?
You could just use the \`getOrElse\` function on Option like so: \`opt.getOrElse(Nil)\`. Despite the fact that Option and List are monads, they aren't the same monad and have different unit values (\`None\` for Option and \`Nil\` for List). You'd need a monad transformer like Cats' [OptionT](https://typelevel.org/cats/datatypes/optiont.html) to deal with the nested monad in this example (although OptionT does the exact inverse of what you're trying to do).
You can fold it. The syntax varies between monads, either curried or comma separated something like: Optlist.fold[List[T]](List.empty)(identity). Where optlist is your Option[List[T]]. Have a look at the fold signature on option.
The reason you can't flatten is because option is not a list. Flatten is for flattening nested contexts into a flatter structure e.g. M[M[_]] to M[_]. 
What does OptionT do?
```Welcome to Scala 2.11.11 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_111). Type in expressions for evaluation. Or try :help. scala&gt; val v = Some(List(1,2,3,4)) v: Some[List[Int]] = Some(List(1, 2, 3, 4)) scala&gt; v.toList res0: List[List[Int]] = List(List(1, 2, 3, 4)) scala&gt; v.toList.flatten res1: List[Int] = List(1, 2, 3, 4) scala&gt;```
I would say `.getOrElse(Nil)` would be your best bet. Another way to do it, though: val optList : Option[List[T]] = ... val list = optList match { case Some(x) =&gt; x case None =&gt; Nil }
I mean what's wrong with just exhaustively cover your world: val x: Option[List[T]] = ??? x match { case Some(l) =&gt; // do something with `l` here case None =&gt; // what do you want to happen in this case }
OptionT is a monad transformer. Quoted from [Cats](https://typelevel.org/cats/datatypes/optiont.html): OptionT[F[_], A] is a light wrapper on an F[Option[A]] This actually doesn't apply to your case, since you have `Option[List[T]]` and not `List[Option[T]]`. If you had the latter case, you could utilize OptionT in the form `OptionT[List, T]`.
Morgan Stanley
Really? I've seen some of their job postings, which don't strike me as being big on functional programming.
Twitter. It might not be "hardcore" enough for you (not a lot of scalaz or cats) but most teams lean heavily on scala's functional concepts. Definitely goes beyond "better java".
You can just convert you option into list and then flatten. Like this : `@ Some(List(1, 2, 3)).toList.flatten` `res11: List[Int] = List(1, 2, 3)` `@ None.toList.flatten` `res12: List[Nothing] = List()`
How do you do FP in Scala without cats or scalaz? Honest question
You could write the parts you would normally get from cats or scalaz yourself. I remember reading that some user in this sub had to do that because cats and scalaz were not allowed (actually a few days ago).
Scala has lots of built in support for FP. Twitter‚Äôs approach is about a balance of readability, performance, and ‚Äúpure‚Äù FP. You will have to make a *really* good case for yourself if you want to get a function with a side effect through code review. 
Cool. I assume you work for twitter? Where is the line drawn? What is used to capture effects for instance? 
The monad thing is a red herring. You wouldn't expect to be able to turn `Option[Int =&gt; A]` into `Int =&gt; A`, even though both `Option` and `Int =&gt; _` are perfectly cromulent monads - that the stdlib offers some automatic conversion between collections is mostly unrelated to monads. `opt.toList.flatten` is a reasonable thing to do, but if `None` and `Some(Nil)` actually represent the same thing, not having an `Option[List[T]]` in the first place but having a `List[T]` instead is the better idea. 
&gt; you ideally would do a map on the Option and then apply .getOrElse(...) Ideally you would use `fold` for this case, IMO - it makes it clearer that you intend to handle both cases.
I left a few years ago. The, maybe unsatisfactory, answer to your question is that those sorts of details will vary from team to team. There‚Äôs something like 2000 engineers that work there making it basically impossible to enforce consistency at the level you‚Äôre asking about. 
Obviously Java and C++ make up a larger proportion of the reqs, but they have probably one of the largest scala code bases in the industry and they employ quite a large number of scala devs. That being said they may not be hiring scala devs in NY at the moment.
Thanks for being amazing Sam! I'm glad you could turn Scala into your Haskellator and join us all in the promised land. You'll find that both Haskell and Eta simultaneously appear, and _are_ greener pastures for competent developers. 
That's a good point. Fold if definitely more functional. I guess I prefer the map ... getOrElse approach because it seems more readable to me. Also I like having the default case as the last expression in the call.
Awesome! PM'd you.
I guess this is the most general way to do it - &gt;&gt;&gt; import Data.Foldable &gt;&gt;&gt; asum $ Just [1,2,3] [1,2,3] &gt;&gt;&gt; asum (Nothing :: Maybe [Int]) [] I'm guessing there's a way to do something similiar in Cats or Scalaz. Put me down for using `.getOrElse` though :) 
Here is a list of Cats adopters. I haven't looked at which of them are in NYC (the only one I know is the one I am working for which is iHeartRadio. ) [https://github.com/typelevel/cats#adopters](https://github.com/typelevel/cats#adopters)
Do they use IO for logging or just side effect?
I can't remember exactly but logging/metrics were definitely an area where we were lax on side effects.
&gt;Should probably stop reading reddit now you're getting it
I used vscode for everything other than scala/sbt, there's simply nothing better than the scala plugin in Intellij
Have you noticed that the underline that marked implicit conversion application is not shown anymore? It's still enabled by default in IntelliJ's Scala options, but when I write e.g. `val someRange: Range = 1 to 5` I don't see `to` method being underlined in 2018.2, as it was in previous version.
There is a VSCode integration using LSP in the latest version of sbt: [https://developer.lightbend.com/blog/2017-11-30-sbt-1-1-0-RC1-sbt-server/#vs-code-extension](https://developer.lightbend.com/blog/2017-11-30-sbt-1-1-0-RC1-sbt-server/#vs-code-extension)
Please, correct me if I'm wrong, I'm pretty new at all of this, but isn't SBT a build tool like Maven? Wouldn't that mean that SBT wouldn't be used if Maven is being used? I thought Maven built a file that linked all other files in a project together. So wouldn't using an SBT plug on Maven project just cause issues since it wouldn't be able to use the Maven resources?
You can use this Ensime-based VSCode plugin (disclaimer, I'm the main author): [marketplace link](https://marketplace.visualstudio.com/items?itemName=dragos.scala-lsp). The extension is based on Ensime, a Scala language "toolkit" that supports several build tools, including Maven: [http://ensime.github.io/build\_tools/](http://ensime.github.io/build_tools/) You'll need to follow the Ensime instructions for obtaining the .ensime file, and from there on the VSCode extension would pick it up. It's still rough around the edges, but it seems to work for many people.
I guess the mantra of keeping things technical rather than personal is quite selective...
I work at Twitter and I approve this message :D
what hardware mostly effects compilation times? has anyone noticed improvement for scala compilation with macbook's new 2.9ghz 6-core processor? or is motherboard the limiting factor? 
Ross did and he wrote a plugin (https://github.com/rossabaker/lsp-scala).
You are correct
Thanks for answering that. I thought I had some big misunderstanding of Maven.
Thanks for a hint. I think I've found the ticket that you've mentioned: https://youtrack.jetbrains.com/issue/SCL-13823
&gt; If there isn't a good plugin setup, would you recommend any educational resources that would allow me to learn how to use Scala with Maven from the command line? That would at least allow me to write scripts I could use in VSCode. I'd recommend looking at ordinary maven tutorials e.g. https://maven.apache.org/guides/getting-started/maven-in-five-minutes.html , rather than anything Scala-specific. Maven is very plugin-based and so Scala support is just a matter of enabling the/a scala plugin for compilation and then everything else works the same way it would with Java. So a lot of what you'll find about Maven will assume you're using Java, but almost everything works the same. If you get stuck on anything specific feel free to ask me here, or I'm lmm on the discord linked from the sidebar.
While currently the situation is not so good, there is https://scalameta.org/metals/ on the horizon, which will hopefully provide an amazing vscode experience in a few months.
There are things expressible with type classes but inexpressible with regular interfaces. For example, interface methods are always _instance_ methods, you can't have a polymorphic "static" operation with a different implementation for each type. Example: zero element in a monoid. Also, type class instances are provided for arbitrary _types_ instead of entire _classes_. For example, you can provide an `Ordering[Seq[T]]` (lexicographical order) only if there is already an `Ordering[T]` available. You can't express that constraint with e.g. Java `Comparable` - the entire `Seq` class would have to implement `Comparable` and there would be no way to express that it's comparable only for some element types.
Tray.io | Senior Scala developer | London, UK | ONSITE | Full Time | # Description Tray.io is ushering in the era of the automated organisation We believe that any organisation can and should automate. With Tray.io, citizen automators throughout organisations can easily automate complex processes through a powerful, flexible platform, and can connect their entire cloud stack thanks to APIs. Today businesses like IBM, GitHub, Forbes, Lyft, and Digital Ocean rely on Tray.io to connect and automate data flow between the tools they use every day. With Tray.io visual workflow builder our customers create automations to drive their business processes without writing a single line of code. Our challenge is to build a cutting-edge product that is powerful and complete while also being beautiful and easy to use. You'll contribute directly to this mission with a team that fully supports you to do your best work. You'll join humble but fiercely ambitious people like yourself, who also take great pride in what they do, working in a culture built on friendship, transparency, and above all, looking out for one another. You'll have endless opportunities to learn and grow professionally in a fun, fast-paced, and open environment. Plus, you'll get to make your mark at a rapidly-growing company positioned to completely reinvent a multibillion-dollar industry. # Your mission Tray.io backend infrastructure processes millions of requests per day and is a mission-critical component of our customers' businesses. As a Software Engineer working in the Platform team at Tray.io, you‚Äôll be part of a team responsible for designing, building and running the software and systems which underpin our large-scale, real-time, distributed infrastructure. We expect you to build flexible services and tooling which allows Tray.io to rapidly scale whilst delivering a seamless experience to our customers. The Platform team is responsible for providing a production environment where connectors integrations and automations can run reliably and at scale. This involves dealing with compute providers, networking, packaging, storage, monitoring, logging, and security. This necessitates building the services and APIs that expose these services to internal and external users of our infrastructure. # Responsibilities: * Developing flexible services &amp; tooling that allows people to store and run integrations at scale * Building internal and external facing tooling and API‚Äôs that allow our users to fluidly build on our platform * Working collaboratively with Product managers to deliver key security, scalability and reliability features * Growing a motivated, high-performing team * Automate the testing and deployment of your work * Envision new features that help our users connect services faster and easier ### Minimum qualifications: * BS degree in Computer Science or related technical field, or equivalent practical experience. * Solid experience in a stand-out production environment * Expert knowledge of at least two programming languages and paradigms (e.g. Scala, Java, Kotlin, Groovy, Go) * An irrational passion for building distributed systems * The desire to learn, improve and work together * Good knowledge of internet networking and performance * Passionate about troubleshooting, debugging, and automation * Experience building web services and APIs ### Preferred qualifications: * Experience launching cloud-based services * Experience with real-time, distributed systems * Experience with writing multi-threaded software * Passion for performance and tuning * Experience in capacity planning and load testing * Experience with clustering technologies (e.g. Kubernetes, CoreOS, Mesos) * Previous IaaS or PaaS experience ### Tech Stack * Scala, Go, JavaScript, TypeScript * PostgreSQL, Redis, ElasticSearch, Cassandra, AWS SQS, AWS Kinesis * Docker, Terraform, AWS Lambda, Serverless Framework * Jenkins, Grafana, Prometheus * AWS &amp; Linux # # Benefits Working at Tray.io offers many perks, but most importantly we are a talented team with a passion for the product we are building. * Competitive salary * Stock options * Unrestricted holiday policy &amp; work from home days * Flexible working hours * A fun and supportive working environment * Top of the range equipment budget * Drinks fridge &amp; stocked kitchen * Social events (team breakfasts/lunches, evenings out &amp; trips) * Employer contributory pension scheme * Cycle to work scheme * Private healthcare * 50% off Virgin Active gym membership # To apply: Send us your resume here [https://tray-io.workable.com/j/50E49D5631](https://tray-io.workable.com/j/50E49D5631) or shoot me a PM # Equal Opportunity Tray.io is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, colour, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics.
Scalameta != macros, not anymore at least :) Navigation in Metals is built with SemanticDB https://github.com/scalameta/scalameta/blob/master/semanticdb/semanticdb3/semanticdb3.md which is compiler agnostic like the rest of the Scalameta tools (scalafix, scalafmt) so Dotty support is doable.
Wow this looks really really cool, thanks!
Regarding writing libraries abstracting Future/Task/IO, I noticed that the future implementation requires an implicit ExecutionContext in order to actually create futures (as they are eager). In this implementation, is the global ExecutionContext usually assumed? What if (for example in Akka) we would like to use a different ExecutionContext instead? How do I avoid polluting the interface with an implementation detail specific to futures?
&gt; Regarding writing libraries abstracting Future/Task/IO, I noticed that the future implementation requires an implicit ExecutionContext in order to actually create futures as they are eager, whereas the other two do not as they are lazy. In this implementation, is the global ExecutionContext usually assumed? What if (for example in Akka) we would like to use a different ExecutionContext instead? How do I avoid polluting the interface with an implementation detail specific to futures? I would say the typeclass instance for `Async` (or w/e) should carry the execution context, and it can be resolved implicitly at the point where you summon that typeclass instance if you want to stay consistent with how future's `ExecutionContext` is usually used.
In the process of learning scala, I occasionally get hit with sentences that I totally can't make heads or tails of, can anybody help me out: &gt; Since a while now, the community talks about the tagless final encoding where you write an algebra and let the effect type be a F[_]. Write an algebra?
Very nice! Just a couple of very minor thoughts: 1. Maybe try to use the term "tagging" vs. "labelling," just for the sake of terminological consistency with other resources/tools. 2. Maybe add a section on deploying locally to [Minikube](https://kubernetes.io/docs/setup/minikube/) first. A lot of people, in my experience, get overwhelmed with setting up Kubernetes, even on something with as much simplification layered onto it as GKE has. Anyway, nice job!
You can look at the implementation here: https://github.com/Verizon/delorean/blob/master/core/src/main/scala/delorean/package.scala#L24 Note that for `Task ~&gt; Future`, the ExecutionContext is implicit (to use `onComplete`). If you won't want to pollute your interfaces, don't use Futures, otherwise your implementations will have to depend on some global EC.
Thanks for that. I might use that in the future, but right now, I'm not going to mess with the build system that the team has been using. If I built it using an SBT plugin that no one else on the team uses, I would surely break some things. I was just looking for an interpreter that would be able to link function and variable declarations and possibly give me a little error highlighting.
Please see the [Scalor Maven Plugin](https://github.com/random-maven/scalor-maven-plugin). I assume you already have the [Maven for Java](https://marketplace.visualstudio.com/items?itemName=vscjava.vscode-maven) plugin. I just successfully cloned the Scalor repo, `cd`ed to the `demo` directory, did `code .` in my shell, expanded the `Maven Projects` section of the `Explorer`, right-clicked on `scalor-maven-plugin-demo`, chose `install` from the pop-up menu, and it built successfully. To use in your own projects, look at the demo and pay attention to the plugin configuration and how it varies, e.g. depending on whether you're compiling for the JVM, Scala.js, etc. and what the plugin's various goals are. It's reasonably straightfoward. Hope this helps, but please don't hesitate to ask questions!
Thanks for doing this. There is (in my opinion) a lack of doc or support for docker or k8s in the scala community 
You don't need to add \` enablePlugins(DockerPlugin)\` explicitly. It should be taken care of by \`JavaAppPackaging\`.
Great article, i personally abide by these principles but trying to convey their value in a clear and concise way is a constant struggle for me (not being a native English speaker doesn't help)
Hm... Better invest the seven minutes into reading the main page of Scala-lang.org. üòâ
Last I looked, remote actors are notoriously slow. Is this still the case?
How do salaries in Japan compare to the SF Bay Area? &amp; what about cost of living?
I use sbt docker compose with success as well
Salaries are more comparable to European salaries. We all know that in the US you get paid crazy money but also the cost of living in the Bay Area is ridiculous.
Agree, but then that'd be more academic &amp; there'd be lots of theory. Here, we skip directly to the good parts &amp; one should/can always refer to official doc for ref. :) 
I would think cost of living in Tokyo is comparable though no?
I would say no. You can take a look here for a quick reference: https://www.numbeo.com/cost-of-living/compare_cities.jsp?country1=United+States&amp;city1=San+Francisco%2C+CA&amp;country2=Japan&amp;city2=Tokyo But the main difference is housing, followed by food.
The more you know. I'm assuming the role is with Paidy. Pretty enticing offer really.
Thanks!
Thanks for taking the time to read it and comment! Good point about "tagging" vs "labelling", changed it üëç The Minikube suggestion is a great idea too - I haven't used it myself yet :D
Uh, I haven't done any performance measurement myself. I imagine that network transfer time would be a much heavier factor than library inner workings.
Looks great, even simpler and better documented than Scalatra. 
Simple http services yes!
Glad you found it helpful! I think you'll like the Minikube experience. It's quite handy to be able to spin up a local one-node Kubernetes cluster for development, and have confidence your workflow will be identical when you use a hosted cluster!
Reminder: Verizon has a nice functional graph library, [Quiver](https://verizon.github.io/quiver/).
Thanks! If you work with play check also the mock auto reseter for when you have to give the mocks to guice 
Awesome, just like your other Scala projects.
The syntax seems very nice and lightweight, how's the footprint? 
So ,... Why reinventing the wheel. If I am using Python Flask and I'm also able to write Scala, do I have good reason to use Cask ?
Nice work! I love the annotations, they make routes more readable (compared for instance to how one defines routes in Akka Http). The callback approach seems to be a little verbose - like the Websocket example.
Because you like Scala better?
Shouldn't this be a macro instead of being integrated into the language?
The first thing would be to tell us what is the `MongoDAO` trait you are using and what library it comes from (cannot tell without looking at the imports). There is just a chance it requires an implicit value that needs to be brought in the scope of your program.
How do I extract an element from a collection and getting its original type. case class Book (Int, String, Int, String) *makes some books* val books = Set(book1,book2, book3) *Wants extract each element into individual books again* for (book &lt;- books) book This is simplified, meaning I have tried like 30 ways to do it Loving this type system, but it drives me crazy lol. Are they doomed to be a collection forever? 
Thanks. Quick follow up. From a design perspective, do you think it makes sense to have the `toJson` function as part of the model? To me it makes sense to have something like `cat.toJson` accessible from the DAO rather than letting the DAO handle marshalling models to json?
Hi, since you are using PlayJson I'd recommend adding this PlayJsonSupport ([https://github.com/hseeberger/akka-http-json](https://github.com/hseeberger/akka-http-json)) in your dependency, and extend it to your trait. And yes you'll need an implicit to convert you Model to Json e.g: `implicit val catFormat: OFormat[Cat] = Json.format[Cat]` Happy coding :)
I think the concept you're not familiar with here might be [type classes](https://danielwestheide.com/blog/2013/02/06/the-neophytes-guide-to-scala-part-12-type-classes.html). 
You can. Though the signature you have chosen inherently ties your model to a particular JSON library through the return type. I prefer to design my APIs with a little more flexibility with something like I posted above. Note that it's `OWrites[M]` and not `OWrites[JsObject]` so you don't even have to call `toJson`; you can just pass it directly. This allows you to either define a "direct" serializer that formats an `M` appropriately as well as to provide one built of a function that does `M =&gt; JsObject` and then uses an `OWrites[JsObject]`. If it's the `.toJson` syntax you like, you can always define this with extension methods. For example implicit class ToJson[T](val t: T)(implicit w: OWrites[T]) extends AnyVal { def toJson: JsObject = { w write t } }
My bad. This is hard to know what is wrong without seeing the dependencies you are using - putting the imported classes and/or dependencies would help. But it seems that other users have a clue of what is going on!
That looks very simple and neat. Congratulations!
x.ai
ok. one reason is because I am both using Python and Scala for different projects, I 'd rather choose frameworks with similar API on both sides , whereas switching between Play and Flask is painful since they are very different API style.
If only the ensime client was actually usable for professional work on VSCode.
There are alternatives to ensime: https://github.com/scalameta/metals https://github.com/scalacenter/bloop
It got a lot faster with the option to use sbtcli
The Session capability ([https://medium.com/@bbonanno\_83496/introduction-to-mockito-scala-part-3-383c3b2ed55f](https://medium.com/@bbonanno_83496/introduction-to-mockito-scala-part-3-383c3b2ed55f)) seems a potential match for Scala ARM ([http://jsuereth.com/scala-arm/usage.html](http://jsuereth.com/scala-arm/usage.html)) ; what do you think? Test failures would be thrown exceptions in the finalizer presumably but it should work?
Sell me on VS Code. I use IntelliJ mostly as an editor, letting sbt do its own thing most of the time. IntelliJ seems pretty good in the role. Would VS code make me happier?
The good part of Visual Studio Code is that it is light and fast. You will have less distractions. The bad part is that you will have to find the right Scala plugins and figure out the imports by yourself. I have 2 browser tabs open to see the APIs: one for Scala, one for Spark. As usual, when you switch to another editor, you will be slower in the first week, because you don't know where to find the function X and the shortcut Y. I switched to Visual Studio Code because SBT imports were too slow. Every time I had to waste a lot of time waiting for IntelliJ to get in sync with SBT. After switching, I understood that with Scala, I don't need an IDE to generate getters and setters for me, like it was with Java.
I‚Äôm not familiar with it, but I definitely take a look Cheers!
But intellij has so many more features than vsc. Yeah, sbt import is slow, but are you really changing your build file that much? Intellij code navigation and auto-complete are so much better.
This plugin will provide you basic code navigation and compile error underlining: [https://marketplace.visualstudio.com/items?itemName=lightbend.vscode-sbt-scala](https://marketplace.visualstudio.com/items?itemName=lightbend.vscode-sbt-scala) This plugin will provide you auto-complete, advanced class navigation and immediate error underlining: [https://marketplace.visualstudio.com/items?itemName=dragos.scala-lsp](https://marketplace.visualstudio.com/items?itemName=dragos.scala-lsp) However, if you are fine with IntelliJ, keep using it. If it doesn't satisfy you, there is a good alternative.
1. An implicit will definitely need to be available. You can specify it explicitly, as you have done already, or you can make it available in the implicit scope. The two usual ways to do that are to import it or to define it in a location that the compiler searches automatically. I usually place my implicits in the companion object of the type as this is a convenient, automatically searched location that is also easy to import. 2. Yes, I think you have things too coupled at the moment. The trait should not have an implicit value in it, nor should the case class. I haven't executed this code, but here's how I might structure your example. trait GenericModel { val id: String } object GenericModel { // might need/want // implicit def jsWriter[T &lt;: GenericModel]: OWrites[T] = OWrites[T] { ... } implicit val jsWriter: OWrites[GenericModel] = OWrites[GenericModel] { m =&gt; Json.obj( "id" -&gt; m.id ) } } case class ConcreteModel(description: String) extends GenericModel { val id: String = hashCode().toString val name: String = getClass.getSimpleName } object ConcreteModel { implicit val jsWriter: OWrites[ConcreteModel] = OWrites[ConcreteModel] { m =&gt; Json.obj( "id" -&gt; m.id, "name" -&gt; m.name, "description" -&gt; m.description ) } } trait DAO { def create[M &lt;: GenericModel](m: M)(implicit w: OWrites[M]): Boolean = { val js = Json.toJson(m) // Validate is json Try(js).isSuccess } } case object Repo extends DAO object CustomJson { implicit val jsWriterOmitName: OWrites[ConcreteModel] = OWrites[ConcreteModel] { m =&gt; Json.obj( "id" -&gt; m.id, "description" -&gt; m.name ) } } In this setup, all implicit values have been moved to their companion objects, and explicitly specify their type. I also moved the `M &lt;: GenericModel` constraint from the DAO trait to the method of that trait. This lets you have one trait that works for all models rather than needing one trait/object per model. You might notice that the method can even work without the `GenericModel` restriction, in which case you have a repo that can store anything so long as it's convertible to a JSON object, not just models. So now `Repo create ConcreteModel("mock object")` should Just Work ^(TM) and find the `OWrites[ConcreteModel]` from `object ConcreteModel`. If you `import CustomJson.jsWriterOmitName`, then the same code will still Just Work ^(TM) but find the now-imported version.
[removed]
I have been working on the new collections in Scala 2.13. In particular, I have been working on trying to make views completely stack- and heap-safe in this and other PRs https://github.com/scala/scala/pull/7048. This change should allow you to do things like: `(1 to 100).view.drop(1).slice(5, 90).appendedAll(1 to 100).....` infinitely many times without consuming any more stack or heap.
Dragos-scala is pretty good.
Monadic `flatMap` in the typical Scala uses is behaving much like `add` does in your example: it's an operation that `F` must support. You're right that this breaks serialization, so for some purposes it wouldn't be good enough. But often for all the cases you care about, a pure expression is equivalent to its evaluation (or rather, because that's the definition of purity, we should say: functions that are pure in Scala are also pure in your algebra) and you want to allow `map`-ing with pure functions. What properties are you concerned about this breaking?
I'm trying to understand the difference between "tagless final" and "making OOP interfaces out of monadic functions" 
"OOP" means different things to different people, but to my mind an OOP interface would generally be implemented by an object i.e. a thing that contains state. Typeclasses implement ad-hoc polymorphism which is one component of OOP but not the whole thing.
I mean that tagless final can be interpreted to get AST. Well, if there are no map-s.
Can you give me an example of typeclass usage in Scala tagless final? 
Everything I've seen points to FP projects in Scala getting bigger with more contributors. There have been developers who have left, but I'm extremely skeptical that this indicates anything bad for the community
I don't/can't watch videos, so I can't comment on whatever's in your video. Turnover happens in every language community for any number of reasons, and is normal and healthy. (You're correct that there are cases where one person leaving could sink a library, but if the library in question was so heavily dependent on one person then it was probably already unhealthy, unimportant, or both). In terms of ScalaZ specifically, a lot of people and projects have switched to using Cats for the same functionality (mostly for community-politics reasons), so a decline in ScalaZ does not mean a decline in FP in Scala. (My personal experience is that several (people who represent themselves as) "pioneers of FP in Scala" are deeply unpleasant; if certain "major developers" are leaving because the rest of the community has finally tired of their behaviour (particularly in terms of bullying newcomers) then that's no bad thing, indeed I'd say it's the best thing that could possibly happen for the long-term future of the language). Scala attracts a lot of FUD for some reason, but I haven't seen any decline in FP libraries (and frankly they're one of the easier things to fix yourself if there ever was a problem with them). I really wouldn't worry.
From where I sit (as a professional developer in Scala doing purely-functional programming): The Typelevel (Cats etc.) ecosystem is doing fine. The Scalaz ecosystem seems to be getting a shot in the arm, perhaps ironically largely thanks to John De Goes. It remains to be seen how the newly-announced "scalaz-stream reboot" fares against fs2, and how whatever else emerges competes with, e.g. http4s and Doobie. But it does seem like there's some motion there, or at least some publicity around it, that's heartening. That said, it's also true that R√∫nar Bjarnason, Sam Halliday, Emily Pillmore, Tony Morris, and no doubt others I'm forgetting have moved on to work in Haskell. To some extent I imagine this just reflects that pure FP in Scala is needlessly painful (just, to me, not so painful that going back to Java or, God help us, Go, or something _worse_ is indicated). But I think it also reflects a dawning realization in industry that pure FP really is a superior approach to imperative/OO programming, and so some uptick in the available Haskell jobs. Of _much_ greater concern to me regarding Scala is that the Scala IDE for Eclipse is now unmaintained, ENSIME is unmaintained, Metals is still for developers-of-Metals only, and the IDEA plugin still struggles with most FP or macro-heavy code. Scala tooling has always been three-steps-forward-two-steps-back at best; recently it's two-steps-forward-three-steps-back. I'm also not looking forward to the Scala 3 transition the way I once was. I think the libraries that make professional work in Scala tolerable will take years to adapt, if they ever do. So I suppose all of this adds up, I would say, to being cautiously pessimistic about Scala at the moment. Which is one reason among several I'm glad to be joining a half-FP-Scala, half-Haskell company soon.
Well, take any language and you'll see that (unless someone's bills are paid by developing the language), devs migrate from one language to another after several years. Some people are leaving (ATM I can only think of Sam Halliday). But, it's not like it's a massive migration that will end up with all libraries abandoned. New people will step in and whole things will roll - maybe these parts of ecosystem that were developed by few super-geniuses will slow down, but at some point they would leave anyway (retirement and stuff) so it might be actually beneficial for community to slowly take over their responsibilities and not over-rely on a few people. What do you understand by loosing momentum? Scalaz is (being?) rewritten to improve the quality of the codebase, Cats reached a stable version, 2.13 is incoming with fixed collections, Akka Actors got Typed, both Scalaz and Cats has quite rich ecosystems, you have a plenty of books and articles available (The Red Book, Typelevel books, Sam Halliday's book), Akka Streams and Akka HTTP are production-ready, more HTTP and streaming libraries are available, several IO libraries to choose from... Tons of thins happening, if there is something to complain about is that *major developers* are so preoccupied with rewriting IO and introducing another FP-flavour-of-the-month that *less known developers* are more often responsible for writing integrations and utilities. Things could be better, but everyone is aware of that and they make a slow but steady effort towards improving things. But I understand if it might be too slow (IDE other than IntelliJ, shorter build times, thing with macros, etc).
I'm not sure what you mean by "in Scala tagless final". Any function or class that uses a context bound `F[_]: SomeTrait` is likely using `SomeTrait` as a typeclass.
This. Having people leaving is not always bad. How many people joined in the meantime? I‚Äôm new to this community and I love it so far. Since I learned this language, I‚Äôve seen talks from jdegoes and too many are just complains about how bad this language or community is and how many people are playing politics. Not sure this is really helping and if one person constantly complaining is a signal or a declining community. My 2 newbie cents: I just try to follow people contributing and trying to move forward. I am very thankful to have this subreddit and other active contributors in the community (like Alvin or tpolecat)
OO rediscovered tagless final under the name of "Object algebras". This blog post explains the equivalence: https://oleksandrmanzyuk.wordpress.com/2014/06/18/from-object-algebras-to-finally-tagless-interpreters-2/ However in practical usage the main difference is that OO interfaces don't return values (in the FP sense of the term), but are often side-effectful, which means what you get is not an effectful program that you can manipulate, but a result with side-effects. This strongly limits your ability to build and understand programs compositionally.
Kafka might be a step too far, but having a bunch of threads running whenever worries me. I'd like to see something like fs2 with more controlled/explicit interleaving of events and their handling. Perhaps I'll try to fork the code and see what I can come up with.
&gt; I have seen an "unhealthy" open source project used heavily be many big corporations and the project was developed only by one guy who had barely any extra money after paying for rent and food. Some projects can be immensely popular, feature-rich and well supported (I mean by the authors, not externally), yet without any other contributors. Sure, that does happen, but that's an unhealthy situation whether or not that person quits. If the project is that widely used then it will likely get picked up (maybe by one or other of those big corporations). Ultimately if no-one is willing to support a given project then that project dies, but that's always true. &gt; This sounds quite bad, any sources or names? This isn't the place to get into it, particularly as my experiences were years ago now (I've avoided most of that community since). &gt; Did all those people left just because disagreements? So Scala as a language wasn't the cause? I don't know, I still have no idea who you're talking about or what reasons they gave. 
Glad to hear their leaving hasn't destabilize the libraries. &gt; Tons of thins happening, if there is something to complain about is that major developers are so preoccupied with rewriting IO and introducing another FP-flavour-of-the-month Well, those big fishes are who push boundaries and who originally introduced "higher FP" to Scala, so FP in Scala is beyond simple pattern matching and recursion (at least according to the video). I would honestly fear about a library which halts all progress to just fixing minor bugs. &gt; Things could be better, but everyone is aware of that and they make a slow but steady effort towards improving things. But I understand if it might be too slow (IDE other than IntelliJ, shorter build times, thing with macros, etc). Even IntelliJ IDEA has severe issues with macros and many popular libraries. Yeah, build times are painfully slow in many cases. I did really suffer when developing a game with not so much advanced stuff (mainly using Java libraries, so no dozens of implicits everywhere and other build-slowing monsters, mainly just limited usage of lens and pimps). I hope Dotty is here to save us soon :D.
[removed]
For auto-complete, my first guess would be to rely on introspection: as the user build code, it will compile and you can use the latest version that was compiling to suggest names. That would be easy and cheap. The second way to proceed is to build your own parser but this would be more tricky and might not catch all cases. Also, since you are talking about building a Scala IDE in particular, looking at introspection might not be enough because it will not understand all tricks of the Scala syntax (implicits and all). To catch this, having your own parser might be the only solution.
&gt; Is it true that major developers behind FP libraries are leaving Scala? No, it's FUD and it's ridiculous. FP in Scala has never been stronger, there are more "major developers" than ever before, and the language itself is changing in ways that will make FP in Scala easier and better. I use and contribute to the Typelevel/Cats ecosystem and honestly is growing so quickly I can't even keep up.
This is a very hard problem. The most promising project in this realm is [Metals](https://github.com/scalameta/metals) so you might check out what they're doing.
Thank you! SBT LSP seems like a great abstraction/infrastructure One question: Why JavaFX?
&gt;One question: Why JavaFX? It's cross platform, and is the successor to Swing. Also looks better.
Before starting something new, you should survey what others are doing, here's some pointers in no particular order: - https://slideslive.com/38908105/six-steps-from-zero-to-ide - https://geirsson.com/post/2018/03/ide/ - https://slideslive.com/38908727/integrating-ides-with-dotty-the-experimental-scala-compiler - http://guillaume.martres.me/ide_paper.pdf - https://www.scala-lang.org/blog/2018/06/15/bsp.html - http://ensime.github.io/lsp-wg/
Wow, the first link is exactly my thought. Thank you for these links; I'll read through them.
I don‚Äôt know anything and am miles from a machine but could you define a function in the trait that‚Äôs abstract and must return a Show[T] object, forcing the callers to explicitly offer up their type classes?
Why are you thinking about building a new one? May be just contribute to existing ones? [http://ensime.github.io](http://ensime.github.io) is already functional and [https://github.com/scalameta/metals](https://github.com/scalameta/metals) is promising and most likely will become the base of the future scala ide.
Can anyone give insight how much Scala3 is different than Scala2?From the video, he mentioned that it seems like going to be Python3. 
Scalex graph is another one that has both mutable and immutable interfaces
Have you taken a look through the website? http://dotty.epfl.ch/ Also looking at Martin Odersky's talks on the future of Scala are a good place to start https://slideslive.com/38908638/preparing-for-scala-3
If you like doing FP in Scala, there's no reason stop doing it. People leave the community from time to time, but that's normal. People join it, too. The worst thing you can do is give up, unless you really feel that's the best course for you. I watched that video too. He makes some good points and it's sad, but it's not hopeless.
1. First build a text editor 2. Build a file explorer/tabs 3. Work out how to do colour coding of keywords 4. Look at ensime . It‚Äôs a server for compiling and getting information about Scala classes and programs. There are plugins for lots of different editors. You could build their stuff into your editor. I use ensime-vim with my text editor. It‚Äôs that hard but you‚Äôre worried about: http://ensime.github.io/getting_started/
&gt; There were 7 names mentioned, so it is quite a lot, if they really were main developers. I haven't watched the video but if they're the names I've seen mentioned around here and some other usual suspects, then that are 7 people who have left over the course of multiple years. Not all of them left because they were deeply unsatisfied. Some just moved on for other reasons. And some are just unpleasant people, who despite leaving still pay regular visits to this subreddit to complain. If Paulp was mentioned, he left Lightbend (some years ago) but still seems to be using Scala.
Yes, lots of highly skilled programmers have left Scala behind. Many of those programmers do not comment in public, especially on Scala forums, due to reasons, so you won't know those people exist. You'll likely hear responses about political tribes such as Scalaz and Cats and how that is somehow relevant to your question. It is relevant, but at a meta level. Technically, Scala is very obviously doomed. You cannot do Functional Programming in Scala to any practical extent. Anyone who has genuinely tried, has failed, and subsequently moved on. Some are in the process of still trying before acknowledging failure.
This is essentially my tl;dr. I was already an enthusiastic recreational OCaml'er when Scala hit the US, so my reaction to it was "Hey, roughly OCaml for the JVM!" And for the most part, that hasn't changed. _I've_ changed; I've adopted pure FP preferentially and think the JVM confers very little actual benefit today. But momentum alone will keep the JVM and Linux in place professionally for a very long time to come, and FP in Scala continues to be the path that seems to me to require the fewest professional compromises. I do think the uptick in Haskell jobs is worth keeping an eye on. A lot of that seems to me to be driven by adoption by various blockchain companies who put a high premium on correctness (as they should) and therefore are adopting Haskell. Whether the mapping from "Haskell" to "correctness" is as straightforward as some of them seem to think very much remains to be seen.
I believe van Rossum is on record that the biggest problem with Python's transition was not having a type system in place before it, and it would have gone much more quickly and smoothly in a typed language.
Hey, 94hDp, just a quick heads-up: **remeber** is actually spelled **remember**. You can remember it by **-mem- in the middle**. Have a nice day! ^^^^The ^^^^parent ^^^^commenter ^^^^can ^^^^reply ^^^^with ^^^^'delete' ^^^^to ^^^^delete ^^^^this ^^^^comment.
Not to speak for others but I've been doing FP in Scala for 6 years now and I've published a bunch of FP Scala OSS libs. I'm not going anywhere. :) Don't believe the hype about mass exodus or Scala 3 being technically doomed.
&gt;Why is it so hard to build a good IDE for Scala? Primarily, because so much of the modern Scala ecosystem is powered by macros. Parsing and typing most non-trivial programs requires macro expansion which means you can't simply examine the source.
No, it's not true. Cats is doing very well. There are always people who join and people who leave, and it's completely normal. Please see https://kubuszok.com/2018/scala-fud-faq-for-newbies/ as well. 
I agree. It doesn't look like anything to me.
That is a good point. But how do you also know the new contributors are or will not be core contributors too? The presentation talks about who left, not who joined- or stayed - and to me it seems that this data is very biased.
Go away
&gt;My personal experience is that several (people who represent themselves as) "pioneers of FP in Scala" are deeply unpleasant; if certain "major developers" are leaving because the rest of the community has finally tired of their behaviour (particularly in terms of bullying newcomers) then that's no bad thing Something I've noticed in several communities is that working with highly technical, open source contributors can be like playing with fire. The same diligence that can drive many amazing, free contributions can occasionally slip into a stubbornness when they feel something is wrong. And when leadership doesn't stop it early enough it sometimes slips into a vileness that turns people off. Due to Scala's more technical nature it appears the community has a higher proportion of these odious people than most. I think leadership - after humoring them for a long time - has realized that some of them do more harm than good. Unfortunately, these people rarely just leave. They stick around making snarky tweets and sassy comments and smirk to themselves about their cleverness. What's even more unfortunate is that I often agree with their original critiques.
Dragos-scala-mode in vscode and ensime in emacs has these things already. If you are looking to learn, that project needs maintainers at the server level.
Bad bot
Last time (many months ago) I checked Cats it seemed to me like poorer ScalaZ. Not that I would be using to much advanced FP, but utilities-wise it seemed to missing many useful stuff and looked quite verbose. Probably should check again, since I keep hearing a lot about it.
How about this: If you come from a mainstream language like Python, Scala can be a bit intimidating at first, but exciting at the same time. The better you get at it, the more you like it, despite not being a perfect language / implementation at all. Since you have experience with most mainstream languages, you understand that all languages have flaws and made compromises along the way. Nevertheless, Scala allows you to gradually mature in your understanding of Type Systems and FP, and apply those ideas at your workplace. After a while and with a bit of effort you can even understand Haskell and read academic FP papers! And after reading so many passive aggressive comments by some very toxic and immature Haskellers, you start empathizing more with devs of other langs that you don't love anymore like JavaScript or Python. On the other hand if you're already a Haskeller (or Ocaml'er I guess), I suggest looking elsewhere. You won't find here the purity or super fast compilation times, or extra terse syntax, or global type inference you're used to. In particular you'll dislike the OO part of the language. 
The people who wrote Cats first tried politically manoeuvring to own Scalaz. That political agenda started way back when Scalaz started in ~2005, but became very public during 2012-2014 and during that time, the Scalaz code significantly degraded in quality. The political agenda failed. Since it failed, the Cats project copied all the code (including bugs) from Scalaz. Nothing of any particular note has been done since. 
Oh yes, it will take time. Currently [Python 3 have 75%](https://opensource.com/article/18/5/numbers-python-community-trends). I think Python is fine, Perl sounded as a much worse case. And I guess it is not only the conversion itself, but about devs actually learning how to do things in a new version. As long as older version of the language is being fixed for a few years (well, probably a bit more than a few), I think it should turn ok. I don't know much about Python, but Scala 3 looks great in many aspects. Many painpoints seem to be addressed - e.g. compilation times, enums, new features like union types, tuples as HLists, auto-tupling of function parameters (this was always a headache for me). It's not all roses and unicorns, I will miss dearly the procedure syntax and I doubt macros could be auto-migrated. But I think it is important to not let warts pile up (like in Java), I believe in the long run it will make the language better.
Does IntelliJ allow you to build on top of it? Sounds like that would be the quickest
I work on Monix and Cats-Effect and I contribute to Cats too. These days I don‚Äôt even work with Scala at work, I work with Python,Javascript and Java. Not by choice mind you, I love Scala, the problem being that the startup I joined has had no use for it yet and personally I pick projects and people, technologies being low on my list of priorities. I do miss it though. That said, I contribute to Scala libraries _in my free time_, without being paid for it, even though I do not use Scala at work. On celebrities leaving Scala, I don‚Äôt get what the big issue is: 1. celebrities are the ones you notice when leaving, but let me tell you, as a project leader I‚Äôm noticing new contributors all the time; and a few of them are shaping up to be the next celebrities you‚Äôll talk about 2. people‚Äôs circumstances change (e.g. I‚Äôm actually one of the outliers for contributing to Scala without using it at work), we change jobs, we also get bored easily I also know Haskell, learning more about its ecosystem gradually and some day I might end up working in Haskell if I‚Äôll find a good project; would that say anything about Scala? If anything consider that I‚Äôve been using Scala since approximately 2011 and given that I also worked with a dozen other languages in production, the newsworthy part as far as I‚Äôm concerned is that I‚Äôve been staying with a language and a community for so long üòâ Personally I think Scala the language and its community have been awesome. Also I‚Äôve noticed several ex-Scala developers that migrated to Haskell and that keep trolling Scala ... but for me that has been a turnoff for Haskell. I put people first, as I believe the ecosystem is the most important part when making a choice. A language like Haskell has plenty to offer, being currently the lingua franca of FP, but it has plenty of drama in it, drama created by some of the same developers that left Scala, just saying üòê
&gt; if certain "major developers" are leaving because the rest of the community has finally tired of their behaviour (particularly in terms of bullying newcomers) then that's no bad thing I certainly hope you're not insinuating what I think you're insinuating.
&gt; As an example, Scala's main contributor did twice as much work in half the time as the person in the second position. &gt; How do you measure that? 
I invite you to have another look at Cats, it's grown to have quite its own identity over the years and has quite a few unique design decisions and utilities as well. I personally don't think it's missing any all-to-useful stuff, but I might be biased of course. If there's something in particular you think that's missing I'd be happy to have a look! As to verbosity, I'm not quite sure what you mean, maybe you could elaborate on that :)
I use IntelliJ on my day to day work and I have very little to no complains. What are the complains on Idea?
&gt; These days I don‚Äôt even work with Scala at work, I work with Python,Javascript and Java. Yeah, I know too well what you are talking about (using JavaScript and to smaller extend TypeScript at work). I was working for quite a long time with Scala, at start only in my spare time or a few school projects, then for like over 2 years on a game (part-time). I was essentially using Scala to have better experience with Java libraries (written so many pimps, even few simple macros). &gt; personally I pick projects and people, technologies being low on my list of priorities. I do miss it though. Again, I am in a similar boat. While I would love to work more in Scala/Eta/Haskell/PureScript, "start up" I am currently working in has great people, easy to work and talk with. &gt; A language like Haskell has plenty to offer, being currently the lingua franca of FP, **but it has plenty of drama in it**, drama created by some of the same developers that left Scala, just saying üòê Drama? I never encountered that. Maybe I am just lucky, or too much of a greenhorn to participate in discussions about most advanced topics :D.
After watching today (most recent?) talk from Mr. Odersky and hearing about binary compatibility (ability to use Scala 3 and Scala 2 alongside), I am no worried about "Scala 2 vs 3" issue.
Someone else posted here great talk - https://slideslive.com/38908638/preparing-for-scala-3. I no longer believe it will be such an issue, since it will be possible to mix Scala 2 and 3 modules allowing gradual migration.
I've been a Scala developer for the last 5 years, both as my main profession and in my spare time. This feeling that Scala is dying or that there is something fundamentally wrong with it is 95% due to some noisy preachers in search of proselytes and some people who need to vent their frustrations on the public square; most of these people end up spreading FUD to serve their own ego at the expense of a community which is actually pretty alive and diverse (and couldn't give less of a s*** about their holy wars). For example, there is this FUD spreading about Scala 3 breaking every library out there (and possibly causing the heath death of the universe); to see how it is purely FUD it is enough to notice that some of the people who actually maintain the libraries who are more likely to be broken (e.g. because they heavily rely on macros or implicit resolution quirks) are actually active contributors to the language and regularly participate in SIP discussions or open PRs against the compiler. I wish there was a way to really show the real proportion between the quantity of people who just get on with their work and are good citizens of the communitiy and those who instead spread toxicity.
I believe so. But the way he told that Scala3 is completely different language!!!
&gt;No, it's not true. Cats is doing very well. I think it was rather about ScalaZ. &gt; Please see https://kubuszok.com/2018/scala-fud-faq-for-newbies/ as well. That seems quite biased. E.g.: &gt; IntelliJ Idea works great with Scala. IDEA breaks apart when using several popular libraries, for example trivial use of Shapeless (mapping tuples, IDEA probably fails on macros) or a Java library LibGDX (their representation of arrays). Last time I tried interestingly looking framework Udash, whole files in IDEA were broken (something with imports), ScalaCSS as well (incorrect type inference of implicits). &gt; Currently, you can use ensime to provide some of these features to editors like Atom, Sublime Text, Visual Studio Code or Emacs via plugins. Isn't Ensime dead?
I love Scala collections, many of its features and a rich selection of libraries. I don't use "hardcore" FP stuff, but it is on my todo list. I am toying with Haskell and it has some amazing stuff (syntax is so clean), but some basic things are just terrible (oh those records, so much pain). Just watched (somewhere in this topic posted) https://slideslive.com/38908638/preparing-for-scala-3 and many things look brighter now :). Didn't know Scala 2 and 3 could be combined in one project making gradual upgrade possible.
[removed]
It is quite dangerous posting about "Scala is very obviously doomed" on a Scala subreddit ;-). You have some interesting points - I have no idea how to measure for example those people leaving for Haskell if they are not vocal or discussing at all. While it seems growth of Scala has stopped (at least according to several popular rankings which I have some doubts if they are actually reflecting anything relevant from real world), I do think it is still used quite a lot in start-ups and enterprises alike. &gt; You cannot do Functional Programming in Scala to any practical extent. Anyone who has genuinely tried, has failed, and subsequently moved on. Do you have any data/articles on that? I lived in a belief a significant part of Scala users use advanced FP at work on a daily basis. &gt; You'll likely hear responses about political tribes such as Scalaz and Cats and how that is somehow relevant to your question. It is relevant, but at a meta level. I keep hearing about these "politics" regarding ScalaZ&amp;Cats, but not anything specific. Is it meant in way of "different opinions on lib design, e.g. getting close to Haskell" or actual politics (I hope that's not the case)?
oh wow, I didn't realise that you weren't paid to work on Scala. More respect to you for everything you've contributed to the FP ecosystem! It's a sad state of affairs when one of the most prolific contributors is doing it as a form of escapism (e.g from Python and Java), instead of by the people using it to solve their own problems. It was quite common 5 to 10 years ago to see this, when Scala was not yet well adopted and people wanted a way to flex their muscles, but it just makes me sad to see it nowadays. I often wonder what would have happened if somebody had written scalaz-effect / zio 5 years ago, perhaps we could have avoided the cats reboot. I personally find the Scala community to be quite horrible, confirmed by many other authors of popular tools and libraries, which was a big reason for me to step down from ENSIME. The FP subset of Scala is even worse: becoming politically organised has meant that there is a social "in crowd" and an "out crowd"... human tribalism takes over from there. That said, my reasons to leave for Haskell were purely technical, as I'd already accepted that FP in Scala was stunted. But I just spread FUD, apparently, so what do I know ;-)
By verbosity I meant that ScalaZ offers (or offered) quite a lot of symbolic operators (hard to learn at first, but can make life easier in a long run IMO). I prefer having both - symbolic operators and classic methods, so I can choose when to use what variant (Monocle library does this and I liked it very much). As I wrote, I know only few things from ScalaZ (helpful small utilities like a conditional operator, fold on boolean and so on) and nothing from Cats apart from a brief look at some getting started article.
Also, he made it clear from as far back as I remember that he preferred Haskell (at least in most respects). So he really isn't part of this alleged trend.
&gt; This feeling that Scala is dying or that there is something fundamentally wrong with it I did not write Scala is dying, only was concerned about FP on Scala. I am pretty sure even Mr. Odersky said few times he doesn't like advanced FP in Scala (I think he was talking about ScalaZ). So if such major language person is not in favor of this, weight lies on libraries. &gt; about Scala 3 breaking every library out there Well, IIRC they are taking like a year before releasing Scala 3 to let libraries catch up. I don't think it will be an issue. &gt; diverse . &gt;spread toxicity When I see these words, I become very vigilant, because in current times "toxic" is often for many people on a left synonym to "being alive" (identity politics)...
There are a few cases where that isn't all that far from the truth, but not recent ones
for a start, nobody has left Scala because people got "tired of their behaviour". It is well known that m50d has a problem with Tony Morris (his github projects even have a huge rant about it). But it is really very hurtful to see people I've worked with insinuate that I've been bullying newcomers. Especially after writing a book and spending many years putting up with the shit, every single day, in ensime, with newcomers who didn't even know how to start sbt. Boo, m50d, boo.
There are a ton more differences apart from those you named, I agree it did not necessarily need a fork, but forking happens all the time. That said, Lars had nothing to do with Cats inception IIRC, Erik Osheim wrote it from the ground up and since then it gained a huge amount of contributors.
This kind of thing has gone okay much more often than the two famous failures. Every C# version makes a lot of changes. ES6 changed javascript almost beyond recognition. SBT 1.0. And so on. But the truth is before we can have a conversation we have to define our terms. What constitutes "okay"? What constitutes "failure"? If the standard is that no one is stuck on the old version for even a month after the new version is released, then obviously most scenarios are failures. And if the standard is that we avoid a situation where people are stuck with a codebase that spontaneously becomes unusable without a complete rewrite, then obviously most scenarios are okay. I guess those are the extreme ends of the spectrum of possible definitions. I think part of the issue is that different people have different definitions. We should be explicit about what standard we want, so we can have effective conversations, and make fair comparisons to other ecosystems.
What technology is not like that?
Anyone remember the "Java is Dead" FUD from not that many years ago? How about the terrifying thought of creating an SBT 1.0? If there was a stampede (and there isn't), just remember that stampedes are not necessarily evidence of actual danger. Wikipedia says, &gt; Anything unusual may start a stampede among cattle. Especially at night, things such as lighting a match, someone jumping off a horse, a horse shaking itself, a lightning strike, a tumbleweed blown into the herd, or "a horse running through a herd kicking at a saddle which has turned under its belly" have been known to cause stampedes. Let's not start one.
Also, IntelliJ lets you mark a particular import as always used, so it's not that big of a deal in practice
&gt; oh wow, I didn't realise that you weren't paid to work on Scala. More respect to you for everything you've contributed to the FP ecosystem! Indeed. I wish there was some sort of funding. Imagine what we could achieve if we could pay people to work on these libraries full-time! &gt; I personally find the Scala community to be quite horrible, confirmed by many other authors of popular tools and libraries, which was a big reason for me to step down from ENSIME. Is it? I think there's so many great people in the Scala community. Like Alex, Li Haoyi and Odersky himself of course. And all the typelevel guys. &gt; The FP subset of Scala is even worse: becoming politically organised has meant that there is a social "in crowd" and an "out crowd" Hmm? I haven't heard about that. What exactly? Got a link? &gt; That said, my reasons to leave for Haskell were purely technical, as I'd already accepted that FP in Scala was stunted. But I just spread FUD, apparently, so what do I know ;-) If you want pure FP with lazy evaluation, that is the definition of Haskell I guess, so that's probably a better fit. For _me_ I love the hybrid nature of Scala. Having the conveniences of immutability and easy testability that comes with FP, but while still being able to write KISS imperative code that newcomers can actually comprehend is a big win. It's kinda like having your cake and eating it too. But different strokes for different folks I guess ;)
&gt; Erik Osheim wrote it from the ground up Cheers for the giggles :)
&gt; Imagine what we could achieve if we could pay people to work on these libraries full-time! If I was paid to work on ENSIME / tooling there would probably be enhanced support for FP across all editors, and an LSP of course. This is not something that Lightbend or EPFL seem to care about (at least not in Scala 2). The Scala Center is about 1/10 the size it needs to be for this industry. &gt; I think there's so many great people in the Scala community. Like Alex, Li Haoyi and Odersky himself of course. If Alex, Li Haoyi and Odersky were the ones sending me messages every day about ENSIME, I'm sure it would have been a very different experience! You can't just point at some good examples and call it a good community. There is a long tail of extremely self-entitled users in Scala who seem to enjoy making ad hominem attacks at contributors, demanding support for their free software, and expressing moral outrage on twitter when they don't get it (often disguised under the banner of social justice). Contributors are burned when they don't bend over backwards for the holy "newcomer", causing us to put more energy than we want (or should) into responding to github, gitter and twitter complaints. &gt; Hmm? I haven't heard about that. What exactly? Got a link? People don't tend to put their underhanded behaviours in public ;-) When my book title changed from "cats" to "scalaz" I got kicked out of the "in crowd". I even have a private message from a typeLevel founder telling me that "we're not friends anymore". It's all very "playground".
Honestly on long term, I would bet on sbt server rather than ensime.
Only because you never took the time to understand why ENSIME didn't work for you. You will continue to have the same problems until Scala 3 comes out, even with Metals, and we can only assess Scala 3 when it arrives. The most interesting thing about Metals is their use of scalameta as an underlying technology. It is kind of a shame that this wasn't just done as a fork of ENSIME (so much work was duplicated instead of focusing on new technical problems). I had already concluded that the use of flat files was the way forward for indexing, but they actually did it and it works great. But interactive mode is never going to work (e.g. autocompletions and type-at-point for uncompiled code). I had hoped metacp would be ported to ENSIME, but everybody has lost the energy to contribute ever since Scala 3 was announced. I think most of the misinformed opinions on this thread are hilarious, and it has made me glad that I walked away. The way to build a great LSP for Scala 2 is very obvious and simple: it just needs people to read the docs (smarter's dump is pretty good), talk to the people who've done this already, and dedicate time to deliver. There are far too many people with opinions, and not enough people pushing code.
I think you misunderstand what the sbt server's LSP implementation aims to achieve, and you are going to be bitterly disappointed.
Did ES6 or C# make backwards incompatible changes that broke old code, though? Or did they just add new features that existing code bases could slowly start to take advantage of? If they didn't break old code in a way that forces people to fix it before upgrading to the new language version, then it's not really a good example. Dotty breaks backwards compatibility, so it's not really comparable to version bumps that don't. I think a failure is when the community necessarily splits its efforts for an extended period of time, like in python 2 vs 3. If a large majority of the community isn't working on dotty codebases within a reasonable amount of time (say, a year), I'd call that a failure.
&gt; It is well known that m50d has a problem with Tony Morris errrm, anyone who spent time on IRC before Gitter came around knows full well the toxicity that TM brought to the community. He's brilliant, but during the IRC days a wretch-inducing person to interact with online.
I can't imagine how anyone could think you were a bully. But I can think of two people who were banned and that may have affected their feelings about Scala. Now, I don't view those people as bad. I myself got banned, from the Lift community. I don't think they were right, but I like to think my communication skills improved since then. 
 &gt;Unfortunately, these people rarely just leave. No matter how much they announce it. They stick around making snarky tweets, sassy comments, and/or long diatribes then smirk to themselves about how clever they are. I see you also follow Tony on Twitter ....
Any explanation?
As a newcomer, when I see ‚ÄúScala wars‚Äù and so many politics debate around this, I just want to get out no matter how great this project is. I want to be in a constructive community, not one when people openly put they are fighting in a war. 
&gt; I have asked for these decisions to be explicitly listed many times, but nobody has given me a satisfactory answer. - `Eval`, which is really more like `Need` + `Name` + `Value` + `Trampoline` + Several other elements which explicitly stem from this, such as the guarantees of `foldRight` on `Foldable`. Scalaz is *right now* struggling with some of the consequences of relying on `=&gt;` rather than an explicitly checked nominal type for laziness (see: the issue tracker). `Eval` avoids all of that. - cats-mtl, which actually has its roots in quasar, not in scalaz - cats-effect (remember that John De Goes' `IO` actually post-dates cats-effect by a fair bit) - `tailRecM` I don't personally support the decision to put this on `Monad`, but it *is* different from scalaz. - Various differences and consolidations in the hierarchy, as well as some additions (e.g. cats has `Group`, scalaz does not; scalaz's `Arrow` hierarchy is a bit better differentiated) Ultimately, there aren't massive differences. But that's to be expected from a pair of libraries which primarily focus on typeclasses derived from algebra and category theory. The main technical advantage to cats is the consolidated ecosystem without the need for shims. Also, cats provides a more gradual migration path than scalaz 8, quite ironically. &gt; Lars tried to shoot Tony in the head, but shot FP Scala in the foot. This is revisionist, and the actual story is considerably more complicated than you're making it out to be. I don't really support the way that Lars went about what he did, but I also don't support the way that Tony went about what he did. Both were seriously at fault, and yet both also acted relatively rationally in the moment. In the end, my sympathies come down on the side of the one who *didn't* act like an unmitigated asshole for a decade (and counting). It's also worth noting that, at the time, the scalaz community *wanted* the fork, and what ultimately became the cats community did not. Kmett was the first to publicly push for it.
&gt; I think it was rather about ScalaZ. If you want to say "ScalaZ is dying" then I suppose you can make that argument. &gt; IDEA breaks apart when using several popular libraries, You may want to check again then, as 2018.2 has some explicitly implicit enhancements: https://blog.jetbrains.com/scala/2018/08/17/how-to-use-the-new-features-of-intellij-scala-plugin-2018-2/ &gt; Isn't Ensime dead? I always get confused by this. No one deleted it off the Internet. It works fine. If people need to work on it, they will. Personally I'd go for Visual Studio Code and use SBT 1.2.1 with the LSP support https://developer.lightbend.com/blog/2017-11-30-sbt-1-1-0-RC1-sbt-server/index.html#sbt-server but Whatever works for you.
Last I heard Runar was back working with PaulC building Unison...in Scala.
&gt; JVM ecosystem, eg spark There is a new project - Eta. It attempts to bring Haskell to JVM platform (not other language based on Haskell, real Haskell, they are aiming to be as close to Haskell as possible). I have tried it a bit, I quite like tooling (etlas), but it is immature. It is fun, but so far I hit quite nasty performance problem (in probably GC implementation). The plus side is that their developers are very active - on gitter and on github. And even others are joining, for example Eta IntelliJ IDEA plugin is very basic, but works reliably and is easy to setup (and even compile). That is something where Haskell plugins failed me many times. They were either useless (like lacking even dumb fuzzy context-less autocomplete) or somewhat working, but unexpectedly breaking, probably because of their external dependencies (even when I didn't change anything). &gt; pure FP wouldnt allow this but even in Haskell purity is sometimes absurd. Logging is my favorite example. Logging is often good, even in an otherwise pure function. It is doable (trace IIRC), but because of "laziness" it can get confusing. I found tests-based approach to be better, at least for my needs. But yes, in general it can be more problematic. &gt; Dot to get values in an object Oh yes, I miss this in Haskell too. Using lenses it gets a bit better, but overall records in Haskell are not great (even with lenses makeFields are issues, maybe some language option handles it better). I think PureScript has dot notation even though being based on Haskell. &gt; reading left to right rather than right to left I was quite confused by this as well. At first I was using flow library, but in the end I found that many operators are already in Haskell or some major library (e.g. `&amp;` for pipe [flipped application], `&gt;&gt;&gt;` flipped composition, `&lt;&amp;&gt;` flipped fmap). &gt; I can generally not use monad transformer stacks. Yes i know how to use them. No it‚Äôs not hard. Yes they are incredibly obnoxious. Haven't tried full FP in Scala yet, but I am hearing a lot of conflicting opinions whether it's worth it. Still planning on at least trying it :).
For the lay, can you define blackbox vs whitebox macros?
&gt; I don't think that's what it means. It only shows that people who want to do category theory and live in a pure, monads-only and lazy-evaluated universe might be better of in Haskell, true. But that world has its own tradeoffs. I definitely wouldn't say "better", but different. That's more or less what I was driving at with my observations about the blockchain startups using Haskell. The only thing I'd quibble with is the implication Scala offers some other means to the same ends. That is, what are the contexts in which _not_ being referentially transparent is advantageous? My answer is: there aren't any. Obviously, not everyone agrees. But the people who have poured their time and energy into the Scalaz and Typelevel ecosystems obviously do, and since the thread is about "major developers behind FP libraries," I've focused on that. As for "better," I mean something very specific by that: the ability to have 99.99% confidence in your code before you run it. That comes from referential transparency and equational reasoning, which is what FP is about. That _is_ a clear, objective qualitative benefit to FP, and that's a hill I'm willing to die on. So _in that context_, I stand by my (still tentative!) observation there are more Haskell jobs appearing over the past year or so than any time before, and sure, that's attracted some people who were committed to FP in Scala. In other words, I still think we basically agree on the reasons some of those who have left have done so, while (maybe; I'm not sure) disagreeing on its significance for Scala or, more specifically, the libraries they contributed to.
The bot's suggested technique for not misspelling "remember" is to remember -mem-. It's not a very helpful technique to be honest..
I'm mostly referring to Paul Phillips' observations about the likelihood of being able to automate the conversion process, coupled with the nuts-and-bolts histories of the FP libraries under discussion here, just in the context of supporting Scala 2.10, 2.11, 2.12, and 2.13, plus the various evolutions of macro support over time. tl;dr Scala has a lengthy history of overpromising on the backward compatibility front, at least for code that makes heavy use of, if you will, almost every feature in the language spec, and often drives many bug reports against the language itself (cf. Shapeless, the Typelevel Scala compiler, etc.)
All little things. Here are some examples: \- when importing a class with alt+enter, it always popups a list of 'Create object' and etc, where importing class is the fourth choice. I never used 'Create object'. Then, the class I want is never at the top. If the list is ranked by how close it is to the current package, the first choice would be right most of the time. \- Also, it is sometimes slow. Sometimes it's not. My best guess is that IntelliJ is trying to do too much. Most of the times we use a build system and a version control through a command-line (not IntelliJ). I just imagine that the IDE can be much simpler and faster if we eliminate these features.
- Eval is a minor change from Name. What do you mean "see issue tracker"? - cats-mtl is an abandoned add-on package. Mostly written by Ed Noble (a scalaz contributor) - cats-effect is an add-on package. cats-effect could have been written on top of scalaz, it has nothing to do with the reason for forking. - tailRecM on Bind instead of BindRec. Come on, this is not innovation. I also disagree with the choice. - a new typeclass... really? You're basically confirming what I said: cats was a political fork, not a technical experiment. Reasonable people may disagree about who the asshole is. Scalaz 8 is a work in progress, I don't think it's relevant to this discussion. It is an actual technical experiment.
Would love to learn the differences between them. Thank you!
then ask the sbt authors, or read their blog posts https://developer.lightbend.com/blog/2018-02-01-sbt-1.2-roadmap/index.html#more-sbt-server-lsp-enhancements
what makes you think the SBT LSP will implement autocomplete, type checking and syntax highlighting? Add classpath search and you're basically talking about embedding ENSIME into sbt.
I have a few questions about this: \- What's smarter dump? \- Why did everyone lose their energy when Scala 3 was announced?
"cats-mtl is an abandoned add-on package", I hope this careless statement doesn't hurt the feelings of the people who are actively contributing to cats-mtl. It's only fair to them to quickly point out that this is not true. 
&gt; Eval is a minor change from Name. What do you mean "see issue tracker"? It's not. Did you read what I wrote? As for "see issue tracker", I mean, literally see [the scalaz issue tracker](https://github.com/scalaz/scalaz/issues/1942). A large part of the issue Edmund raised boils down to the fact that laziness is transparently "lost" in scala when you use raw by-name. &gt; cats-mtl is an abandoned add-on package. Mostly written by Ed Noble (a scalaz contributor) Odd that it has recent commits. Dogs is abandoned. cats-mtl is not. Also yes, mostly written by Edmund, who was primarily a cats contributor before he was a scalaz contributor‚Ä¶‚Ä¶ are we really going to argue about who contributes to what? Seriously? &gt; cats-effect is an add-on package. cats-effect could have been written on top of scalaz, it has nothing to do with the reason for forking. No of course not. None of these things have to do with the reason for forking. That's not what you asked for though. You asked for technical distinctions; I'm giving them to you. Scalaz is more monolithic than cats (a serious misfeature IMO). You can't just throw away the cats-* packages as "irrelevant add ons" when the contributors consciously chose to make them separate repos rather than part of the core. That is, in and of itself, a technical distinction. &gt; tailRecM on Bind instead of BindRec. Come on, this is not innovation. Ah, now who's being subjective? It's a technical distinction, and there are strong (though IMO not strong enough) reasons for it. Whether or not it's "innovative" is in the eye of the beholder. Is the scalaz `|@|` syntax "innovative"? Hell if I know. &gt; a new typeclass... really? https://en.wikipedia.org/wiki/Group_theory You seem pretty bound and determined to ignore everything that's different about cats. This is probably why no one has ever given you a satisfactory answer. By your own moving standards, no answer will ever be satisfactory. &gt; You're basically confirming what I said: cats was a political fork, not a technical experiment. All of these things could have been discussed and implemented in a minor release of Scalaz. Except they couldn't be. You're pretending that the process of contributing code is wholly dispassionate, performed entirely by emotionless and apolitical automata in fleshy bodies. Tony alone disproves that theory. Politics are *always* a part of everything. Here's the reality of it: the scalaz community has been toxic for *over a decade.* It's been toxic because it was *set up* to be toxic. It has actively pushed people away from Scala FP for just as long. Yes, I realize some people have had great experiences in that community, and I'm truly happy for them. Many, many more have not. For every "Tony helped me" or "my Scalaz PR got merged and I feel amazing" story, there are 20 more "Tony called me a cunt for asking a question about `var`" and "my Scalaz PR devolved into a toxic ad hominem mess". Cats was an attempt to push the reset button on all that. An attempt to achieve broadly the same technical goals (which is why there is so little differentiation) while avoiding as much as possible the toxicity which befell Scalaz. So you can call that a political fork if you would like. Maybe that's even accurate. No one ever would pretend that cats was created originally to experiment with ideas that couldn't be experimented with in scalaz, your strawmen notwithstanding. There *are* technical differences, some of which (like `Eval`) are quite interesting, but just as obviously those technical differences are not its raison d'etre. &gt; Reasonable people may disagree about who the asshole is. Sure. (not sarcastic) Just remember that you're not fully in possession of all the facts here because a lot of them (on both sides) haven't been made public. Getting a complete understanding of what *actually* happened is quite difficult; neither Tony or Lars are telling the whole story. *Also* remember that Tony has been publicly exhibiting behavior which is objectively toxic for a very, very long time. Scalaz isn't the first community that he was kicked out of, or even the first Scala community, and Lars is far from the first person to attempt the kicking. It's just the first community with which he had any original involvement. Remember that a lot of people have been hurt quite badly by Tony. Remember that a lot of objective damage has been done. Yes, reasonable people may disagree, and you're welcome to do so, but subjectively I would prefer if you disagreed with me on the basis of the complete corpus of data.
I don't even know what you're arguing about anymore. You've ran out of actual technical experiments, which is what I asked about, and now you're lobbing extension libraries at me. I don't think Tony's public behaviour is "toxic". I understand that many people believe it is. I think we can just agree that we all have different social norms. If your goal is to form a religion around FP and try to evangelise newcomers, then I can see why Scalaz may not be compatible with that goal. However, if people think they have been "hurt" by Tony they need to grow the fuck up and learn what that word means. I know more of the facts than you think. I was very much inside the ranks of Typelevel when this all went down.
On those points: - usually pops up an import suggestion for me and I just hit alt enter - agree but new IntelliJ and new scala plugins made much much better - it also got much faster with new sbt options (and using newer sbt versions) End comment: ¬Ø\_(„ÉÑ)_/¬Ø 
LOC changed divided by time active.
Ed was quite clear why he abandoned the project, the status of which is reflected in the github contributor chart: https://github.com/typelevel/cats-mtl/graphs/contributors If somebody (i.e. you) gets offended that I'm pointing this out, then I don't really know what to say to you... umm... sorry your project's main contributor left?
You are right, there is nothing you can say here that will satisfy me that cats has been a worthwhile technical experiment, because I've been through all the code and know what the differences are... and I remain unimpressed. Or at least when there is something that has been implemented better (e.g. the FreeAp encoding, arguably Eval), I don't see why it could not have been contributed to Scalaz. But we are where we are, and the community is split *technically*, regardless of whether they prefer Scalaz or cats, or believe Tony over Lars. I am pleased that people are willing to be honest that cats was a socially / politically motivated fork, because until recently the "technical experiment" drum was banging, which was intellectually dishonest. The modular structure is perhaps one thing we can call a worthy technical experiment, but anybody who has written and released scala libraries could have told you how that would play out. Binary hell. As a user (until last week) I rule it a failure, I much prefer having a single core library that doesn't require me to remember the names of fluffy creatures or to consult a version matrix when I want to upgrade something. As a contributor I like being able to make a change and see how it impacts the entire library. &gt; The truth is much more complicated than the public perception, and vastly more complicated than the story handed down by Tony or by the Cats community. Sounds like nobody knows the full truth, other than you. So I guess we'll have to wait for your best selling novel to come out and reveal all. If you're alluding to the "Tony abused Lars over email" incident, yes I've seen the whole thread and I don't think it was abuse. If you are alluding to the commercial aspirations of Typelevel (at the time) then I can understand why a political fork was warranted but I think they were crazy to think anybody would pay them for anything.
Fun talk about it at https://youtu.be/knqlWboqf_U
There is a great misunderstanding about what sbt lsp actually does. It is not a replacement for ensime. ensime is not as good as it could be. The 2.0 indexer didn't work out so well, we should have used flat indexes stored with the jar files instead of centralised in an OrientDB file. There is an abandoned PR to replace it with metacp. It will likely require a dedicated contributor to add support for scala 2.13, but it's more or less in maintenance mode for now because nobody seems to be working on the LSP or "bus" ideas documented in the issue tracker. I wouldn't say dead, but it's definitely not healthy.
I don't remember a time when he liked Scala more than Haskell. He always viewed Scala as a pragmatic, necessary compromise, relative to Haskell, the Holy Grail.
Whitebox macros are able to refine their result type at every call site while blackbox macros are constrained by their declared signature. Example: ``` def foo: Any = macro whitebox def bar: Any = macro blackbox ``` A call-site to `foo` will be ascribed the precise type of the expanded tree (for example `Int` if it expands to the constant `2`). A call-site to `bar` will be ascribed `Any` regardless of the expansion.
I'm going to guess it was a reference, since I'm pretty sure that emily pi "left scala" some time ago.
Not all of it. The runtime, I think. I have looked at a PR that was completely in Haskell just this week. 
Suspicious quotations
&gt; It is well known that m50d has a problem with Tony Morris A *huge* number of people have a problem with him, specifically online.
I don't remember anyone saying that cats was originally a technical fork, it was created because of the bad image/community that scalaz was fostering at the time. People wanted a FP project which had a community that was more positive and at the time many people believed it wasn't possible with certain people still being part of scalaz. &gt; Binary hell. As a user (until last week) I rule it a failure I have personally had far more issues with scalaz being monolithic than cats being modular, especially considering that cats itself is maintaining binary compatibility as per their release guidelines.
He also founded FJ. I'm pretty sure he was never committed to Java as an alternative to Haskell.
I wouldn't personally use the verb "to leave &lt;language&gt;", because it doesn't really make a lot of sense to me personally. I am not a huge fan of Python ever since starting in Scala but I have never thought that I "left Python". And, after all, you're still here aren't you :-). So is Sam.
I‚Äôm not a celebrity Scala programmer by any standards. Most of my work in Scala has been closed source albeit extensive. I‚Äôve been using Scala to implement the entire backend infrastructure at CentralApp. Even being humble I‚Äôd still consider my work in Scala non trivial. I‚Äôve spent a good five years with Scala and I‚Äôve learnt a lot from the language and the ecosystem behind it. However that‚Äôs not the reason why I‚Äôve started to think about leaving. For me, it has to do with the paradigm of the language. Somehow FP in Scala always feels like it‚Äôs second class. It isn‚Äôt as seamless as it is in Haskell. Haskell is built from the ground up with FP in mind and it shows. Scala isn‚Äôt and that also shows. While Scala has its merits and it is hugely applicable to many problems, and you can come up with elegant solutions in it, it still treats FP as a second class citizen. I‚Äôm personally not swayed by the ‚Äòcelebrities‚Äô leaving Scala at all but I can say from my own experience is that the reason to leave is mostly because one starts yearning for a language that puts functional programming at a more accessible distance. Moreover as you dabble with parts of category theory you cannot help but realise that these ideas are more naturally expressed in Haskell. It‚Äôs very attractive. Also while Scala is at the forefront of the merger between imperative and functional programming, the choice is clearer in Haskell. It‚Äôs a matter of taste really. I got attracted to Scala as I was getting interested in functional programming and as my knowledge and interest progressed, I grew more interested in solving problems applying what I had learnt. I just enjoyed this process more in Haskell. In the end it‚Äôs not a good vs bad question at all. Both languages have their merits and so do their ecosystems. Just that people entering the Scala world with a keen eye on functional programming will yearn for more naturally expressive functional programming languages. That‚Äôs what has happened, in my opinion, with many of these celebrity programmers. Having said that, I do think drastic changes in the language convince me further that I have no wish to write newer services in Scala. It‚Äôs just too much pain. That has been a large factor in my case as well. 
I agree! I'll pop in and out, helping out with the FP libraries, so I won't really be "gone", but my focus will generally be in a different direction, which means less community interaction and 1 on 1 mentoring and so on. That said, I couldn't resist the Westworld reference :)
&gt; remember that Tony has been publicly exhibiting behavior which is objectively toxic for a very, very long time Holy shit I wish you hypocrites had the ability to understand how funny this is.
https://twitter.com/dibblego/status/1029333683667230721
Shouldn't be a problem with runtime libraries. But libraries using macros is a completely different story. Macros in current form will not be available in Scala 3. So far it seems that all macro libraries will have to be completely rewritten to whatever the new macro/derivation engine will be. It doesn't matter that macros are (perpetually) experimental. Since their inception they have become a core part of many, very popular libraries. So this might be a big migration blocker.
Toxic threads for 500.
&gt; The only thing I'd quibble with is the implication Scala offers some other means to the same ends. Scala offers completely different means when it comes to program structuring due to having an actual, best-in-class module system.
I'm only here because people are talking about me, by name, and I want to make sure nobody says any more bullshit about what I did and didn't supposedly say. Also, there is a thread about IDEs and I kinda know a few things about that. But don't worry, just ignore me, everything I say is FUD.
Nice article! A couple of corrections: &gt; And look, we can even change the order in the stack, it does not matter: That's not true in general, but it just so happens that `ReaderT` commutes. Try with EitherT and WriterT and you'll see that chaining the order changes the behaviour (one keeps the log in case of errors, the other discards it). ```scala case class SimpleState[F[_]: Monad, S](var state: S) extends DefaultMonadState[F, S] { override val monad: Monad[F] = Monad[F] override def get: F[S] = Applicative[F].pure(state) override def set(s: S): F[Unit] = (state = s).pure[F] } implicit val st = SimpleState[IO, Ads](ads) ``` As written, this is impure for several reasons: you can't use `Monad.pure` to suspend a side effect like `state = s`, you need something like cats-effect `IO.apply` (`F.delay` on `Sync`). The video linked uses `Task.delay`, but it's still impure because the creation of mutable state (`create` in the video, `st` in the post) needs to be wrapped in `IO/Task` as well. I suggest using cats-effect `Ref` (or something equivalent), which always does the right thing (ops are suspended, including creation), and it's concurrency safe as well.
You can convert `Future` to `IO/Task`, but you can't really write meaningful abstractions over both `Future` and `Task/IO`. One is side-effectful, the others aren't, and therefore the code will behave entirely differently. 
I got -9 points, for thanking @alexelcu for going above and beyond. Reddit is truly a playground of petty children.
&gt; On the other hand if you're already a Haskeller (or Ocaml'er I guess), I suggest looking elsewhere. You won't find here the purity or super fast compilation times, or extra terse syntax, or global type inference you're used to. In particular you'll dislike the OO part of the language. Not necessarily! I came from Haskell to Scala, and while, yeah, I really disliked it at first, I then really fell in love with Scala's module system ‚Äì Haskell is very anti-modular, type system ‚Äì singletons for _everything_! and macros ‚Äì extreme power, including hooking up/redefining implicit search on your own, while "magical classes" in Haskell are all built-ins.
Sure, I think the point being, if you must be on the JVM for some reason, Scalaz makes the necessity a lot less painful than otherwise. Today, someone thinking in the same terms might choose [Eta](https://eta-lang.org/) instead.
They're so nice, because they have a CoC! 
At the cost of everything else, without a library like Scalaz. That's one hell of a trade-off‚Äîone people concerned about reasoning about their code before it runs aren't likely to make. But with Scalaz (or Cats), there's no need to, so I'm still not sure what the actual argument is.
No, but if you must program in Java, doing so with FJ is a lot better than doing so without.
Sure. The point is only that, by exercising some discipline, libraries like Scalaz or Cats give you the _opportunity_ to use equational reasoning, thanks to referential transparency. But you're right; it's still "opt-in," and easy to get wrong. I also prefer OCaml's ergonomics to Haskell's, all in all. But at this point I'd trade off in favor of referential transparency and equational reasoning by default, vs. also having to rely on programmer discipline in OCaml as in Scala, even at the cost of Haskell's pain points.
That is a good choice.
You gotta watch out for that one dude that commited 1 LOC's feelings man...
\&gt;my sympathies come down on the side of the one who *didn't* act like an unmitigated asshole for a decade (and counting). Holy shit this is not even close to the original story. TypeLevel really has fantastic PR. 
It's a lie, among a sea of lies. How are you enjoying the FUD? :0
\&gt; TypeLevel really has fantastic PR thank you! \&gt; The core members of TypeLevel didn't want to fork Scalaz they wanted to be in \*charge\* of Scalaz This is actually not only true, but in fact typelevel was in charge of the scalaz project. I mean typelevel was born from #scalaz. we scalaz developers wanted to create an umbrella that covered scalaz, typelevel and spire. If you go back to the scalaz mailing list posts about when this was all going down, it was readily referred to as a "typelevel project" and we were discussing what to do with it in relation to the other typelevel projects. Nobody at that point as objecting to it being referred to as a typelevel project. typlevel had already been obviously been born at that point by scalaz developers in order to maintain scalaz and other projects that felt "near" to scalaz \&gt; When they couldn't convince people \*perma-ban\* Tony We didn't have to convince people, we actually did it.... but then ultimately decided we'd all rather abandon the project and let him have it. \&gt;, the PR campaign started about how the Scalaz community was toxic to women and minorities Yes, and it was largely successful. &amp;#x200B;
&gt; What reaction were you expecting from the Scala community, exactly? Horribleness, of course. ‚ô• Captain Obvious. 
yeah, it makes him a huge bottleneck . we have tons of code we want to write and tons of things we want to say, but it all has to get approval from lars which ends up being a huge bottleneck, obviously...
Care to explain why is this topic "toxic"? In online gaming such term is connected with vulgarity, racism, harassment and so on. I don't believe anything from OP qualify as such.
&gt; Yes, and it was largely successful. But it wasn‚Äôt true. The only time I ever felt weird about being latino *ever* in the Scala community was when people (typelevel folks? Supporters? Not maintainers) started tweeting shit about how ‚Äúonly white males matter in Scalaz‚Äù...implying what, maybe there‚Äôs some secret cabal I don‚Äôt know about? Maybe they didn‚Äôt think my and other contributions matter? I asked other folks who were either non white or latino and they didn‚Äôt feel the community was toxic to them. Certainly some behavior was unacceptable to many, and it should be dealt with, but it was only after the 'split' that it even became an issue. Here's the thing, you've admitted before that *one* person that was crossing the line. One person doesn't make up a community. You and others could have said "there's a community that is filled with great people and one person I hate" but you didn't. You grouped us all together under that umbrella term despite the fact that everyone seems to think Kenji, myself, and plenty of others are good people. 
While it will take time to rewrite macro-based libraries, Dotty release has a whole year reserved for essentially this ("beta" testing and waiting for libraries to catch up). He has a slide about it - there are 3 approaches (depending on safety) which will replace macros. But to not just sugar coat it, even the most powerful approach is less powerful that current macros. He shortly talked about it and said, that many use cases of current maros are supported by Dotty directly, so no macros will be required to implement those use cases. I don't have any deeper experience with macros, so really can't evaluate if it will be a problem. &gt; It doesn't matter that macros are (perpetually) experimental. Since their inception they have become a core part of many, very popular libraries. Yeah, because of this I don't understand why IntelliJ IDEA is not supporting them...
&gt;Eval &gt; &gt; is just &gt; &gt;scalaz.Name Tip your waiters! unfortunately this comedian will be here all week.
I've spent dozens of hours on cats-mtl, it is in no way abandoned!
&gt; best-in-class module system. I've seen this claim many times but have never seen any actual examples where all of this "power" is being exploited. Got any examples you could like to? (I definitely believe the claim at a technical level... but AFAICT that's only relevant in the Turing Tarpit sense in that a lot of things may be *possible*, but you don't really do them because they're so painful on various axes.)
I've never even interacted with him directly and *I* have a problem with TM's behavior online(!).
&gt; Haven't tried full FP in Scala yet, but I am hearing a lot of conflicting opinions whether it's worth it. Still planning on at least trying it :). You definitely do NOT want monad stacks in Scala. The type signatures get even more obnoxious than they already are (plus local inference is already pretty bad) and they have absolutely terrible (unfixable) performance.
[endpoints](https://github.com/julienrf/endpoints) is a good example, where the need for servant-like type level interpreters is obviated with module composition.
Typical...
Protip: If you care that much about the rating of your posts, try to be less insulting (generally speaking people don't take kindly to being insulted so they are unlikely to rate you highly for it)
\&gt; What reaction were you expecting from the Scala community, exactly? &amp;#x200B; From other contributors: agreement and acknowledgement (it's ok, I've already had plenty) From useless people who just rant on reddit: exactly this. I am not even remotely surprised. This place is a hive of scum and villainy. If you ever have a successful FLOSS project in Scala, I assure you your mailbox will be full of messages from the latter. EPFL, Scala Center, Lightbend, you're not helping contributors at all with your patronising tone.
I don't mean to be flippant, but I don't quite see what this buys me over the Servant-like approach...? Could you expound a bit on that? (I have no experience with anything Servant-like in Scala, though funnily-enough I do have an in-house approach to 'generic' browser-server interaction that's very similar to Endpoints.) (Aside: Am I the only one that actually prefers an IDL+codegen approach for this type of thing? Just codegen a trait and let the user implement it. It's incredibly simple and lets you follow a contract-first/top-down approach to services.)
I agree!
Hmm. That sounds dark. I don't know any of the typelevel guys personally; I'm just a semi-regular conference-goer. Maybe there's more dirt going on behind the scenes than most people know. &gt; Just the other day I was blocked by a Typelevel dev on Twitter for simply pointing out that Scalaz was created by Tony Morris and was never a Typelevel project. Huh :\ weird. I mean that's just stating a fact, isn't it? There's gotta be more to the story than that?
It is a fact, but the problem is that if you admit this is true, then the rest of the story about the Scalaz drama falls apart and it's clear that the drama was just the fallout from an attempted hostile takeover by the supposedly great Typelevel people. The fiction that Tony was "kicked out" of the community because of his behavior can only be maintained if you believe that the people doing the "kicking out" were actually in charge of the community. Accordingly, pointing out these facts results in anger on behalf of some really "great" people. ...but they have a CoC, so I must be wrong, I guess...
What do you use instead? I find intellij to be absolutely amazing.
What patronizing tone are you talking about? Nobody from neither the Scala Center nor Lightbend has answered your childish comments in this thread.
You counting the IntelliJ Scala team lead as leaving is disingenuous at best. To the best of my knowledge, he moved to the rust team because he wanted to grow technically and he already knew everything there was to know about implementing a Scala compiler, not because he disagreed with the direction of the language as you or Paul. I would recommend anyone reading your links to take them as a pinch of salt, many things have been fixed and improved since then.
&gt; These have all largely been taken into account with the new collections ... Not at all. &gt; it's really on you or whoever wants to critique scala to show why the new collections are not satisfactory I suggest you watch the videos I linked, because they apply to the rewrite just as well as they did to the old implementation.
We are less trendy than php?
For what it's worth, I don't believe there was ever any racism or sexism in Scalaz. (I've heard it argued that caustic discussion disproportionately affects the most vulnerable people; be that as it may I don't think it's fair or productive to label general rudeness as racism or sexism). &gt; Here's the thing, you've admitted before that one person was crossing the line or being toxic or whatever label you feel fits. One person doesn't make up a community. You and others could have said "there's a community that is filled with great people and one person I hate" but you didn't. You grouped us all together under that umbrella term despite the fact that everyone seems to think Kenji, myself, and plenty of others are good people. "That community is toxic" does not mean "every individual involved in that community is individually toxic". It means that the community, considered as a whole, is toxic, and in my experience that much is 100% accurate. Time and again over a number of years I saw newcomers arrive seeking help and be met with responses that, while perhaps factually true and (if read carefully) not technically personal attacks, were crafted to upset them and often succeeded in doing so. It happened too often to be accident or coincidence (and FWIW I don't think it was all one person, though the majority was). It was enough of a pattern that I'd consider anyone who had significant involvement in that project to be complicit (even if you're not on your project's IRC or mailing lists yourself, if it's your project then those are your spaces). Even if that no longer happens in today's Scalaz (and my experience was bad enough that I have no intention of ever revisiting anywhere involved with the project to find out), if you're continuing the project under that name then that's the legacy you're claiming. (And I would fear that as long as Scalaz's name is spoken, newcomers will continue to find Morris and he will continue to upset them). &gt; Do you really think it's helpful for people to group me under the umbrella term toxic? That if companies see that I'm a contributor to Scalaz and see claims of the toxic community, that the'd be better off not hiring me? I don't doubt your good intentions. I do believe that the Scalaz project is indelibly tainted with a legacy of bullying that reflects poorly on anyone involved in it, and its continued existence does more harm than good. (And I do fear that the time I spent trying to help people on the project IRC channel, although also well-intentioned, also ultimately did more harm than good and should be held against me).
Thank you, fommil, for the answers and for the explanation around the interactive mode (e.g. autocompletion for uncompiled code). They are insightful.
IntelliJ is the best one. There's no comparable alternative. But I don't feel it's absolutely amazing. I think it's too heavy weight. Most of the features aren't necessary (e.g. version control, sbt console). Here are some little things: [https://www.reddit.com/r/scala/comments/98vwte/what\_would\_it\_take\_to\_build\_a\_scala\_ide/e4kqocn/](https://www.reddit.com/r/scala/comments/98vwte/what_would_it_take_to_build_a_scala_ide/e4kqocn/)
\&gt; Even if that no longer happens in today's Scalaz (and my experience was bad enough that I have no intention of ever revisiting anywhere involved with the project to find out), if you're continuing the project under that name then that's the legacy you're claiming. That's quite the standard to hold people to. I don't have to look hard to find people who have had bad experiences with the Scala community as a whole. Why not hold the \*entire\* community to that standard, and realize that the fighting, division, name calling, and bad behavior isn't necessarily at the granularity that is convenient for you? Maybe by even posting here and being helpful, you're doing more harm than good by helping a community that's been tainted by its past? 
&gt; useless people who just rant on reddit You're not a contributor anymore, since you "left Scala", so I think you fit into your own "scum and villainy" category of "useless people who just rant on reddit" quite well.
small [strawpoll clone](https://github.com/cnguy/strawpoll) (without the auth stuffs for now) with http4s on backend and Reason on the frontend. I'm having a lot of fun! (normally I use JavaScript / TypeScript) 
&gt; blocked by a Typelevel dev on Twitter for simply pointing out that Scalaz was created by Tony Morris Could you link to the actual offending tweet, please? 
I understood it as: The matching is done at compile time (type equality proof by the compiler), instead of at runtime (pattern matching).
I released a book today, about Scala, that has 650 readers already. I never expected to recoup any financial reward. Indeed all profits already went to aid the Scala Center and the ENSIME sponsorship fund. Tomorrow, I'm doing a faithful handover of several of my free software projects, on my own time, as my last act for the community: because there are still good people in this community, despite the politicians and useless people. It certainly doesn't feel like I'm not a contributor... although I was tone policed by Lightbend today for smiling on a ticket. Literally smiling on a ticket. You couldn't make this shit up. They went into total lockdown. Genuinely ask yourself if you have enough data points to confirm that this is a friendly, welcoming, and diverse community of deep thinkers... or just an Old Boy's Club fuelled by knee jerk reactions. You may not be able to see anything from the center of the fog.
I was tone policed by Lightbend today for smiling on a ticket. Literally smiling on a ticket. You couldn't make this shit up. They went into total lockdown.
Thanks for your corrections /u/SystemFw, I appreciate! I'll give a try and update the post accordingly.
&gt;I meet people in Rust or wherever who want nothing to do with Scala and think I must be a bad person to favour the language as much as I do, and maybe they're right. You've always been awesome and extremely helpful here on reddit, and it would suck for people to jump to conclusions about you based on a general view of the Scala community at large. Don't you \*want\* people to talk about folks who like Scala with nuance, to treat them as individuals, to be respectful to you about that? Wouldn't you feel pretty shitty if folks went around talking to the Rust community before you got there making generic statements about your toxicity so that when you showed up, you weren't given a chance? &amp;#x200B;
Why? So you and your pals can pile on?
Don't do it.
Hey, sake\_92, just a quick heads-up: **acheive** is actually spelled **achieve**. You can remember it by **i before e**. Have a nice day! ^^^^The ^^^^parent ^^^^commenter ^^^^can ^^^^reply ^^^^with ^^^^'delete' ^^^^to ^^^^delete ^^^^this ^^^^comment.
They must be pretty tired of you. Regardless, the Scala Center has nothing to do with this kind of discussions; we work to improve things instead. You get wrong even the things we work for or we care about, so stop finding any opportunity to blame us. Nobody from the team has engaged in your discussions. Be respectful and fair if you want others to be the same to you.
At my Job we are currently concerning to build a *simple CMS toolkit*. Kind of a custom made headless CMS. I am not very excited with the idea of implementing file upload, user acls and all of that stuff (once more). How do you treat the need for content in some applications? Does everyone build those custom solutions?
you're Scala Center and you're here tone policing me right now. That is: &amp;#x200B; \- EPFL \- Lightbend \- Scala Center &amp;#x200B; all in the space of 24 hours. &amp;#x200B; Well done, you're making the community a much friendlier place for everybody.
with some familiar contributors.
Although I sympathise with the general plot of the article, the following statement is clearly wrong : &gt; Task and IO both have an instances of Traverse. This would mean that you can transform a `IO[Option[A]]` into a `Option[IO[A]]`, which is simply impossible. 
Passing around the execution context will get easier with implicit function types: ‚Äã type Async[T] = implicit ExecutionContext =&gt; Future[T] def httpPost(...): Async[HTTPResponse] def parseServiceResponse(httpResponse: HTTPResponse): ServiceResponse def callSomeService(args): Async[ServiceResponse] = httpPost(...).map(parseServiceResponse) ‚Äã
Yes. Now apply these lessons to collections and you'll understand why they will never be fast, or even remotely competitive with Java streams.
That may be for the current collections and maybe even the upcoming 2.13 variety; I haven't looked into them much yet. Still, are you saying that an Iterator isn't guaranteed to be lazy after applying any combination of non-terminating operations like map/filter?
I also would love to link you to stuff but it seems Scala devs haven't managed to build the 2.13 nightly docs since half a year. I think your restriction on non-terminating operations (I assume you use the word in the Java streams sense) is a core part of the issue. If you look at the question "which operations are supposed to be terminating", it's easily possible to present examples where non-termination makes a substantial difference for operations which are "obviously" terminating. Examples: - Should `sorted` be terminating? What about `elems.sorted.take(10)`? - Should `groupBy` be terminating? What about `elems.groupBy(...).apply(...)`? There are frankly no safe non-terminating operations outside an explicit "now run this". Having a mixed-mode API (views) is barely any better than all operations being terminating (collections proper).
Mad!
\&gt; Use sbt shell for build and import (requires sbt 0.13.5+) Check that box and it will get as fast as SBT can.
emilypii, your user flair does look like something to me: a Lightbend logo. Care to explain what's up with that?
You are clearly right, I'm sorry about that, it was late, I don't know what I was thinking. I've strikethrough'ed this text and added an edit. Thanks for the correction.
You do you. Flair just reminds me of Office Space. As far as the rest of this thread, more like a Herzog documentary.
Yes. 
&gt; Scala 3 being technically doomed. It's definitely technically doomed, at least insofar as you want to do real FP.
I‚Äôd love to hear what your issues were using Scalafix. I use it fairly heavily and just love it and am finding other users in my company picking it up fairly quickly (days not hours though). There are few things that feel as good as writing a fix for a deprecated api and after running it deleting not only the api but also the fix, because you know it is truly gone, 100% everywhere in your whole codebase. Monorepos have their pros and cons but that is one bit I really enjoy.
&gt; Should sorted be terminating? What about elems.sorted.take(10)? &gt; Should groupBy be terminating? What about elems.groupBy(...).apply(...)? &gt; Hey you bring up a great point! I am just noticing that `groupBy`, `groupMap` and `groupMapReduce` are the only transformations on views that are terminating (other than really terminating things like `max` etc). Some thoughts: * I don't know how unsafe this really is, because it is not as if this is hidden. It's right there in the types that this returns a `immutable.Map[K, View[V]]`. I would agree if it said it returned a `MapView[K, View[V]]` or something, but actually forced the computation. * No other transformations from java streams are terminating in this way, and these three transformations aren't actually supported by jStreams, so it doesn't seem that scala's missing out on java stream functionality It may be difficult to swap out `MapView` return types for these three transformations, since they inherit from the `Iterable` in the hierarchy, so `ItrerableOps` would have to be changed (maybe include a `+M[_, _]` type parameter, and have these methods return `M[K, CC[V]]` etc?). Maybe instead it's fine to just add view versions of these methods? AKA: * `groupedBy: MapView[K, View[V]]` * `groupedMap: MapView[K, View[B]]` * `groupedMapReduce: MapView[K, B]`
I got all kinds of weird exceptions and just general weird behavior where fixes wouldn't get picked up properly (using SBT, btw). I can't remember the details, unfortunately, should have made a bug report, but didn't. (Shame on me. I'll try to do better next time.) I absolutely *love* the idea of having scalafix and once we/they hopefully get it working properly, I'm pretty sure we'll actually also be implementing scalafixes for some code migrations :). It would be an absolute godsend when doing library upgrades. Unfortunately our largest project -- where scalafix would be *really* helpful -- is still stuck on 2.11 for reasons mostly unrelated to the scala ecosystem itself (except possibly bincompat hell).
I have used it via sbt, coursier, but most commonly for my day job on a large monorepo using pants. Scalafix works just fine on 2.11 btw.
No worries :)
Really? I've been using a lot of editors through the years, and continue to experiment with new ones as they appear, but IntelliJ is still by far my favorite editor ever! It has so insanely many nice features and is extremely keyboard-centric (as opposed to your "stereotype IDE" which wants you to use the GUI). IntelliJ is however very resource damanding and I would really appreciate if they focused on making it more lightweight and snappy. In the meantime I recommend giving IntelliJ way more RAM - at least 2gb. That should make it much snappier. That, and maybe get a better computer if your current one is a slouch. Remember, the Scala compiler itself also demands a ton of cpu, ram, etc to compute - it's not just IntelliJ thar struggles with Scala code.
Sbt console is a waste for me too personally. But the VCS is absolutely unparallel to everything else. It is really good once you explore all the features available there. The only drawback is that you can get a little detached from how git actually works underneath. When I'm using the terminal I feel kinda crippled.
&gt; Scalafix works just fine on 2.11 btw. Well, that wasn't *my* experience, obviously :).
&gt; But all I can expect is that in a year or two a next &gt; exciting monad &gt; will appear and all speaker will talk about it, while common folks still will fight much more down to earth issues. What the fuck are you talking about? 
Good point, I didn't mean to say it worked for you, just wasn't sure if you knew it was available. Ping me sometime if I can help, or ask in the scalafix gitter channel, I'd be happy to try and help you get unstuck.
I'm _really_ confused by this thread's use of the word "terminating." Do you guys mean "terminal" (as in the Java streams sense)? By the way, `groupBy` _has_ to force the whole collection before returning a result, so a `MapView` wouldn't be useful here.
Wait, why does `groupBy` have to force? All the other transformations just basically track what transformation needs to be done, and defers it.
Real FP in Scala 3 is gonna be fine.
In ten years it didn't learn to correctly parse all possible Scala code.
&gt; Also looks better. That's arguable. There are very good look-and-feels for Swing, compared to which JavaFX looks bad.
I want people to make the best judgement they can based on the information available to them. If they know the individual in detail, great. If all they know is that that person came from Scala, I want them to treat that person with caution rather than naively, because there really has been a lot of bad behaviour in Scala that other communities quite rightly want to keep out. And that has a collateral impact on good people who choose to be part of Scala, sure, but I don't think that's unfair; we know how bad it is and choose to participate anyway. We are judged by the company we keep.
Of course it'll support polymorphic recursion, what are you talking about
Could somebody try explain what happen to newbie. Isn't it just what sequence want to do? that is, swap the Seq and IO.
&gt; Q: How does this book compare to the red book? &gt; &gt; A: This book is blue.
We all make do with what we have and at least should try to avoid the politics side of the community. At least I do, otherwise becomes impossible to actually work. I was thinking about buying the physical copy, but you mentioned profits going to scala center? Can you clarify? I though the money was going to you for your great work and the FSF.
I feel like this was very related to my comment on the last article here (https://www.reddit.com/r/scala/comments/97s9bc/types_never_commit_too_early/e4aqo9d). I have thought a lot about this problem in the meantime since, and for the most part, I agree. In fact, personally, I found that was the toughest part about getting accustomed to Akka (its tight coupling to futures, I mean). I think that one advantage (correct me if I'm wrong) of using futures in Akka is because of the dispatcher configuration - by pipelining the results through a single context, we lose the ability to configure different execution contexts for each part of the program, which can have performance implications. Using futures also provides certain message ordering guarantees. If we were to "deprecate" futures, we would need some method of addressing these problems. Do you (or anybody reading this) have any ideas for this? I tried working on this a little bit actually, but as /u/SystemFw mentioned, finding meaningful abstractions between Future/Task/IO is not easy in the context of the Akka specifically.
I'd probably stick with `self` and maybe make it a `val`, but this feels like an XY problem to me. What are you trying to achieve by having `this` implicitly in its own implementation? Any method you invoke that would resolve `self` would essentially be calling `this.method(this)`, and `method` already has access to `this`, so it seems unnecessary. And if it's for something like a visitor with `this.member.method(this)` then it's probably better to be explicit anyway (because resolving `this` implicitly is unusual and likely to be surprising to future readers) or to separate the behavior out into another location that associates the two types. Maybe what you have is the best way but I usually consider it a bit of a smell if I have to pass `this`; it usually implies my code is not factored properly.
Where is the free PDF link?
You can pay as much as you want but moving the sliders. I suggest paying something to show appreciation for a fellow community member :) 
S√ªre! Thanks, looks pretty good so far.
You're doing great work everywhere. We are all paying attention :3 Thanks.
Do you have any ideas how we can promote a better community / better behaviour? Any suggestions for this subreddit?
Will I start hating Scala if I read it? 
if this and the quotes on the cover havenv't sold you on this book, I dom't know what will
It shouldn‚Äôt. Look at a talk of Don Syme on F# called ‚Äúpath to relaxation‚Äù https://youtu.be/yL7xBhWrdKw even though that talk is not about Scala directly, F# is a hybrid FP language just like Scala so some of the points listed there are relevant to us. According to don keeping the best from both worlds in harmony is ‚Äúrelaxation‚Äù.
That's true, it's the purpose of sequence. The thing is you can't define a sensible `sequence` method for IO, because IO is lazy and `sequence` would require peeking inside. To sequence `IO[Option[Int]]` you would have to call `unsafeRunSync` to see if the value inside is `None` or `Some` to decide what to wrap the IO in.
This is the gist of my problem: ```scala trait Page { def relTo(other: Page) = ??? // relative path from this to other } ``` When I have 2 pages `A` and `B` I can say in `A`: ```val link = relTo(B)``` but I'd like to say: ```val link = B.ref``` because it's more natural to me. In order to implement `ref` I need `implicit caller: Page` to know which page wants relative path to this page.
It doesn't. It's not that black and white. It just has more cases in which it would need to reify more of the incoming stream of values. But again, this is only an issue in the first place, because you have operations that evaluate things. If the implementation stops implicitly evaluating operations, suddenly all these cases of "we did all this work and it turned out that the next operation asked only for 1% of the data, and now we wasted a lot of CPU and memory" disappear. That collections (`BitSet`, `TreeSet` etc.) have various operations that lose types and come back with different semantics is a symptom of the same cause. It's only a problem because collections demand that you reify a data structure for every immediate step. Views are just as bad as strict collections, by the way. Compare val set: BitSet = BitSet(1,2,3).map(_.toString).map(_.toInt) with val set: BitSet = BitSet(1,2,3).view.map(_.toString).map(_.toInt).force 
&gt;Newcomers would probably benefit from having a compiler that optimized polymorphic recursion, among other things. Good thing they have such a compiler then...
&gt; I think that one advantage (correct me if I'm wrong) of using futures in Akka is because of the dispatcher configuration - by pipelining the results through a single context, we lose the ability to configure different execution contexts for each part of the program, which can have performance implications. The article mentions it in passing: you explicitly call `executeOn` or similar when you want to explicitly execute on a different context. While I'm normally in favour of explicit over implicit, I think requiring an execution context for every single `map`/`flatMap` is going too far: most of the time if I'm just transforming a result I don't want to think about where my two lines of transformation logic are going to run, I just want them to run in the same place that the thing that produced the result ran. The `implicit ec: ExecutionContext` becomes noise - which then means that it's very easy to accidentally use the wrong one in cases where you really do want to use a specific context (e.g. you have an implicit executioncontext on the class itself, but you accidentally add one as a method parameter anyway out of habit, which then silently overrides the class-level one). You're right that the akka approach is more configurable, but I find that ends up being an antipattern: your logic ends up split between code and config, and config is less easy to test. Better to have all the important stuff in the same place. &gt; Using futures also provides certain message ordering guarantees. How so? I would think it would be easier to ensure correct ordering with `Task`/`IO`/etc., since those give you control over when execution starts.
It's "Functional Programming for Mortals with Scalaz" :-) not "for mere mortals"... that's the name of a talk that somebody else once gave. &amp;#x200B; Don't forget to point out that it is \*free\*.
Hold on to your belongings while we ascent the Haskellator!
This is the worst book ever written. The author doesn't have a clue what he's talking about. And he smells.
Thanks for the link to this talk, I wasn't familiar with it.
LOL, I think you meant to say TOXIC! The ENSIME sponsorship fund isn't going anywhere. Save your money for the physical version if you're having to economise and slide it to zero ;-)
Free, not Open :-) [https://www.gnu.org/philosophy/free-sw.html](https://www.gnu.org/philosophy/free-sw.html)
can u say in one single line why to choose Haskell over Scala &amp;#x200B;
You can reuse typeclasses like `Applicative` with stdlib `Future`, and have the typeclass instance carry the `ExecutionContext`, then it's just as easy as using `Future` directly, and code that's written in `F[_]` style doesn't have to worry about execution contexts at all. If you believe that precise control over sequencing and parallelism is vital then even `Task`/`IO`/... don't give you the level of control you need - look at the discussions around having `Applicative` instances for these things, where the conclusion was that since in Scala generally we consider computing the same value at different speeds to be equivalent, we can consider running two tasks in parallel and running them serially to be equivalent. That's not an invalid perspective, but it does reduce `Task`/`IO`/... to (semantically) an overly complicated `Eval`. So I think there's something a little hypocritical about the scorn being poured on stdlib `Future` in terms of lawfulness etc.: stdlib future is a perfectly lawful monad if used with pure code, and `Task`/`IO`/... don't provide any nontrivial law-abiding semantics in terms of async/parallelism/concurrency. It *is* true that `Task`/`IO`/... can be used to encapsulate impure code a la `Eval` and stdlib `Future` cannot, but that's really a side issue; if that was what you cared about you'd just use `Eval`. In the context of being a best-effort unprincipled "run this (presumed pure) code in parallel as much as you can", *which is all the semantics that `Task`/`IO`/... offer*, both memoization and starting immediately are legitimate choices, may well align better with user expectations, and can sometimes yield better performance. (I've been playing around in [tierney](https://github.com/m50d/tierney) with the possibility of offering some more concrete serial-versus-parallel semantics that the applicative/monad laws would respect, but that's an experimental project rather than something production-ready). I do think stdlib `Future` makes some design decisions that were wrong in retrospect; I think the implicit `ExecutionContext` on `map`/`flatMap` is a mistake and implicit function types represent a worrying doubling-down on it. But I don't like the "`Future` is awful and broken and `Task`/`IO`/... are right" narrative. `Future` not only works, but sometimes offers better performance than the alternatives; `Task`/`IO`/... represent a tidying up of some warts and a change of focus rather than a massive improvement that everyone should immediately leap to.
The trouble with using `F[_]` for everything is that you're making your interface more complex. You've gone from functions that return custom types to functions that require the caller to provide an instance of a particular interface, [which is more complicated to work with](http://www.lihaoyi.com/post/StrategicScalaStylePrincipleofLeastPower.html#published-interfaces). There are cases where it's worthwhile, but if `F` is only ever going to be monix `Task` I'd rather express my code in terms of `Task` than have an extra layer of indirection. Scala is an easy language to refactor in, so if it turns out the code needs to be flexible over different `F`s then it's easy enough to change that as and when needed.
I wrote about my reasons in detail already :-) [https://medium.com/@fommil/scala-3-considered-as-a-new-programming-language-a335ff67e075](https://medium.com/@fommil/scala-3-considered-as-a-new-programming-language-a335ff67e075) &amp;#x200B;
Congrats Sam, I'm happy for you and the book is incredible as usual! I hope it becomes as standard and well-distributed as PFIS, and I imagine it will be, since the context is both more modern, and provides some very juicy stuff previous books left out. 
oh shucks, I don't think it can compare to the Red Book... that's a different league.... but I appreciate the thought!
Wonderful news! Thank you for this fantastic submission to the Scala ecosystem. 
Scalatags offer a better alternative on this point : http://www.lihaoyi.com/scalatags/
Thank you so much! I really appreciate it. I have been feeling a little unloved and unappreciated by Lightbend recently. It means a lot :-)
See: vigorous debate.
Thanks for you book, also I am surprised this book is free (minimum) now. ps: The old quotes are a lot of more interesting than current.
I like to keep them moving... I'm thinking about quoting people quoting the quotes next.
Ah, yeah, good point. :) Even proprietary stuff (e.g Unreal Engine 4) can be open source. 
It's always going to be an uphill struggle, because an unpleasant community is self-perpetuating: sensitive people were driven away from Scala especially in the past, so the experienced people we have today are, at best, people who have the best of intentions and want to be welcoming but don't quite understand how viscerally upsetting the kind of conversations that have sometimes been common can be. Perhaps we can slowly crawl out of the hole, gradually becoming a place where slightly more sensitive people can still be comfortable and in turn those people can lead the community to better norms of discussion. But part of me thinks that retrofitting good behaviour onto a language community is even harder than retrofitting good design onto another language, and the future belongs to languages that put community first from the start.
Monads, like monoids, come from math - particularly, abstract algebra and category theory. In object oriented programming, it's really common to think of different implementations of an abstraction as being interchangeable and mix-and-matchable. For example, being able to append any traversable collection to a list, whether or not it's a map, set, vector, etc. By contrast, abstract algebraic abstraction is about characterizing common behavior of very, very different and non-interchangeable things. Why? Because you can prove something is true for the abstraction, you don't need to prove it for each concrete instance. So a monoid, for example, is a type with some well behaved combining function and an identity element for that operation. Integers, for example, form a monoid under both addition and multiplication. Lists form a monoid under list concatenation. `A =&gt; A` forms a monoid under function composition. But you can't combine an int with a list or a function. You can only combine ints with ints, lists with lists, and functions with functions.
I think there's a few considerations for this: - There's a lot of concern about Scala's newest direction w/ Scala 3, and whether that will cause a similar problem that Python 3 did by splitting the community. I'm not trying to stamp my own opinion on this matter, but it does seem to be a common concern among maintainers of Scala libraries and tooling. - Writing FP in Scala isn't particularly satisfying when compared to Haskell. There has been a significant number of people that joined the Scala community -&gt; Learned Scala FP via Cats/Scalaz -&gt; Learned Haskell -&gt; Got a job to code in Haskell. There's some truth to Orderskey's joke regarding Scala being a Haskellator. - Many come into Scala and simply use it for a better-Java. Unfortunately, Java and Kotlin have made significant gains on their feature sets since Scala's introduction. Java and Kotlin also provide a much better tooling experience than Scala, particularly in the IDE. Kotlin also has an advantage of being a first-class Android language, while Scala struggles a lot here. So many users see no reason to continue to use Scala, and gravitate back towards Java/Kotlin.
As someone who is newish to Scala and not aware of the context, it mostly feels like toxic people dramatically ejecting themselves from the community. Scala3 is their excuse to yell "fuck you" and save face. Personally, I've had nothing but positive interactions with the typelevel community and I've seen nothing but childish bile and whining from the anti-typelevel crew. Gee, which side to believe? 
Are you sure you are not blowing this out of proportion? There has been one "loud" exit recently and that was /u/fommil. The other one I can remember was /u/simon_o from last year. That's *two*. Within a *year*. Two is, I don't know, your average *day* in /r/rust or /r/golang or /r/python. It's certainly natural for people to feel strongly about a language they care so strongly about. Both /u/fommil and /u/simon_o were long-time contributors to the language and its ecosystem. I don't know about you, but I'm more scared of the veteran contributors who *don't* say anything, and just leave. It's not anger or frustration that we have to look out for. It's indifference or silence.
&gt; Unfortunately, Java and Kotlin have made significant gains on their feature sets since Scala's introduction. That's far from unfortunate - we all want better programming languages and better programs. Scala isn't an end in itself; if the features that make Scala great spread to other languages, that's mission accomplished.
The runtime is Scala. The \*runtime\*. :P
Many of the people "slamming doors" have spent much of their free time making scala better, and have personally helped me out asking nothing in return, and the same goes for the typelevel folks. It's not really as simple as a bunch of toxic people leaving 
You're adding to the noise with this thread, you know. 
It's perfectly normal for people to want attention. I'm sure most programming languages will encounter people who go on at length about how much they've contributed [1] and then flounce out. The more salient question is why we're paying attention to them. Scala has always attracted a disproportionate amount of criticism, and I think that's ultimately all that's going on here - people want to attack Scala and here is an issue they can use to do so. I'm not sure why there would be so many anti-Scala folk, but if I had to guess: partly people who took a quick look at the language and were treated rudely by the community (which happened a lot, especially in the early days) and partly because the design is inherently an awkward compromise between OO and functional that will always be subject to (entirely legitimate as far as it goes) criticism from purists on both sides. [1] Though Scala does seem to attract this strange cult-of-personality style where people talk about their libraries/projects but really emphasize how it was them specifically who made them. I don't know why that is - maybe just an accident of history where early conference speakers did it and later ones followed them?
It is unfortunate for the Scala community, which is the context of the post. I'm not trying to say Java and Kotlin shouldn't have made these improvements, rather that the Scala community suffers as a result.
There has also been some sniping from John De Goes, including his infamous "Scala Infinity Wars" presentation, where he modestly proposed that the Scala maintainers should eliminate most of the OO features from Scala and embrace full "pure FP". In additions to the allegations about "toxic personalities" in the pure FP community, my observation is that the pure FP crowd wants Scala to be something that it never has been (and never will be). Rather than just switching to Haskell (or Eta, etc), they come here and insult people. Like many here, I was attracted to Scala by the powerful mix of OO and FP features, and I'm not leaving anytime soon. My career has been pure Scala for 6 years.
1. Usually, when people slam the door they are leaving not entering. 2. How many newcomers are people with 3k Twitter followers shouting "I am starting Scala!"? None. Because, to get these 3k followers they would have to build a recognition way before. 3. People with recognition in FP communities usually have their own opinions and language of choice already. To balance the "I'm leaving" wave you would have to take a lot of known developers from e.g. Java or Kotlin or Go or whatever, convert them to Scala, then make them loud about the fact. But somehow, many people outside Scala and Haskell are not so radical that they blow up because they cannot implement that one things as elegantly as in this paper they read last night... And I don't blame the languages. It's more like the people with such personality trait gravitate towards languages that let the express their radical stance the best. But not every Haskell or Scala programmer is like that, is just any of such people stand out 1000x more than 1000 other devs that wouldn't crucify you for using IO monad.
I don't know - on the one hand it means less reason to use Scala instead of those languages, but it also means moving to Scala is less of a leap, and there's more support in the rest of the ecosystem for Scala constructs (e.g. Spring has added support for autowiring optionals, driven by Java 8, but that opens the door to doing the same in Scala). I really want to get away from thinking of this as a zero-sum competition, because it doesn't have to be.
I've been playing with Kotlin a little with the gradle-dsl for kotlin. I can't say I'm too impressed. the syntax around their closures with custom context or whatever they call it is super unwieldy compared to implicit function in Dotty IMO.
&gt; There's a lot of concern about Scala's newest direction w/ Scala 3, and whether that will cause a similar problem that Python 3 did by splitting the community. I'm not trying to stamp my own opinion on this matter, but it does seem to be a common concern among maintainers of Scala libraries and tooling. I've said this numerous times before, but lots of precautions are being taken to ensure Python 2 and Python 3 don't happen again. The most notorious difference between Scala 3 and Python 3 is that we're a typed language, both Scala 2 and Scala 3 share the standard library (Python people wished this was the case for them) and both of them will be able to be used in the same classpath, which means no rush to migrate and interoperability between libraries compiled with both compilers (so long as no Scala 3 specific features are used). 
I think it implies that such posts invite lots of comments and discussion -- not much more :)
Honestly, I don't think it happened as much as is often implied, although I can't speak about pre-2.7 days. Certainly it got a lot better. Although, that should never be achieved by stifling important subjects.
&gt; But all I can expect is that in a year or two a next &gt; exciting monad &gt; will appear and all speaker will talk about it, while common folks still will fight much more down to earth issues. You're right, we should make a compiler without features so that people won't be able to give high-level talks! That's definitely a good idea and not an excuse for not having features in the first place.
I found his name quite ironic lol
I don't know if it's the worst, but I sure hate it. ;)
This is precisely what led me to creathe this post
I love them all. C# scala f# haskel... my name implies range!
It‚Äôs not that many people. They‚Äôre just loud. Also you‚Äôre not hearing about every time someone starts learning Scala.
Can you cite such posts?
&gt; for taking into account the critiques levied against views by Paul Phillips and others such as yourself I think this is an assessment both Paul and I disagree with. &gt; They are extremely simple and easy to understand or implement ... ... as shown by the recent `LazyList` troubles? :-) &gt; Lots of languages are directly trying to adopt the wins that Scala has made in the past. Pretty much every language has chosen not to adopt the semantics Scala picked for its collections, prime example: Java. Some languages have even switched from Scala's old model to a better one. Examples: Ruby, Python.
`groupBy` cannot be a `MapView` because it has to go through the whole collection before it can figure out whether a particular key is defined, or especially to make sure that it is _not_ (which is one thing you can and do query a `MapView` for). Delaying this traversal doesn't buy you much if anything at all. I am not sure what /u/simon_o thinks when he says `groupBy` doesn't have to force -- his problem: &gt; we did all this work and it turned out that the next operation asked only for 1% of the data, and now we wasted a lot of CPU and memory does not apply here AFAIK.
&gt; Delaying this traversal doesn't buy you much if anything at all. Respectfully, I disagree! By delaying, you may be able to optimize such operations as `get(key)`, because you don't have to materialize maps. You could also optimize `filterKeys`, or `take(5)` (you can avoid materializing the map for any key not in the first 5 you see)
That's exactly the kind of FP bigotry that needs to leave the scala community.
&gt; FP bigotry Do you have literally any idea what the word bigotry means?
&gt; childish bile and whining Drive-by insults, aisle 10.
Let's see. https://en.wikipedia.org/wiki/Bigot_(disambiguation) Bigot is a term used to describe someone intolerant of the opinions of others. Yep. It fits.
&gt; my name implies range I'm curious, how are FP discussions like in the C# and F# communities? Some would argue that the Haskellator only goes from `Scala =&gt; Haskell` with no detours!
Imagine a small city, and a person that goes around and keeps antagonizing people. The chances that his victims meet are really small. Now imagine that this person keeps up his behavior for years ... his victims may meet each other by chance and start talking, uncovering more and more victims until things reach a critical mass. This is what's happening in Scala. &gt; I don't know about you, but I'm more scared of the veteran contributors who don't say anything, and just leave. It's not anger or frustration that we have to look out for. It's indifference or silence. Other contributors have left silently with the same reasons for years already. I know this, because I made a point of checking up on people who contributed and then disappeared, listening to them and making sure they are fine.
Now you are fighting against argument I did not use :P Promoting one, consistent way of doing things (as opposed to changing preferences every season) is not an argument against high-level talks on their own, and surely not for removing features from compiler.
So you could fork it if you want.
We say this a lot, yet there is no good tooling I know of to support building for 2.12 and 2.13 even. The cats change to do this was non-trivial. I think for this migration to be easy in scala 3 we need to be showing tooling based migration in 2.13 and 2.14 and show it working well. This will give confidence. I fear the answer is: we don‚Äôt have bandwidth to make that tool now. And if so, I‚Äôm not sure I am confident we will have bandwidth later for scala 3.
I've had extra reading time recently and purchased and read what was published of the book at the time (what looks like most of chapters 1-7, but missing the now added 8 and 9). I'm very grateful that this resource exists and found it both an enjoyable read and a good explanation of the material. My only worry is that with Sam leaving the community that it won't be updated. Are there any plans to make sure the content stays fresh/relevant?
I'm surprised there wasn't *this* much fud in community with Java 8 vs 9.
&gt; Can someone maybe give a TLDR on what the issue was, who fought who, and what happened in general? The value returned by this function depends on who you ask. Such is with drama.
I didn‚Äôt even know there was drama
Yeah I make sure to do all the exercises without looking at the solutions. It's a tough book but I'm slowly working my way through. I'm guessing they want to see actual Scala projects right? As far as contributing to high profile open source... Would they really want some student? As far as applying goes, I want to feel confident first. I would like to give my all to finishing this book if it would help a lot. I also live in a remote area in Canada which would prove to be an issue... Do you think remote is out of the question given my lack of experience? I figure that if I would like to be employable, I will have to put out a lot of effort on my part to compensate for this. Do you have any other books to recommend? I realllly like this one because it's fully emphasized on exercises. I know there's the sidebar, but there are so many choices(some seem old) that I do not know what to pick out. Thank you for the advice btw! &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B;
There are definitely organizations doing pure FP in Scala. When you're ready to start looking, get in touch, and I'll be happy to make sure you know who to talk to.
I would not compare 2.12 and 2.13 with 2 and 3. In the latter there will be no library change, so an upgrade or cross build would be influenced by the ability of both compilers to accept Scala code, not by tricks to make code work across two different standard libraries such as the change in cats you mention. That being said, I‚Äôm optimistic that tool will be in place for 2.14 and Scala 3. To the best of my knowledge that‚Äôs exactly the reason why Scalafix was created and proposed by the Scala Center Advisory Board. And the tool is getting better and better over time.
(most) companies do not care if you have experience in FP or not. What is important is you degree of awareness, if you want to learn and if you are a good problem solver. My two cents: continue to do projects, read books, do exercise, try to contribute. And you will be fine. Do not demonstrate *only* your Scala abilities but your overall skills in computer science and problem solving. Source: I was hired at Twitter, had no scala experience and developed lot of Scala code within my first 6 months.
&gt; I made a point of checking up on people who contributed and then disappeared Based on what I've heard from other languages/projects, people making contributions for some time and then leaving is absolutely normal and in fact very common.
Thank you i will do so! :) 
Do you have any recommendations for books similar to FP in SCala? I really enjoy this one because it's full of exercises and not so many boring explanations. It is also improving my ability to think abstractly which is really nice. 
Ah, I was afraid of that. I don't mean any ill will with my post. And any coincidence with timing is very unintentional. I hear your advice with letting it go. But it does seem funny that even new people are exposed to these vague references. As an outsider, it seems that the community as a whole still needs to move past it, whatever it was.
I would definitively look for "Functional Programming Simplified". Lots of exercises, recommendations and examples. https://alvinalexander.com/scala/functional-programming-simplified-book
It does seem to me that there is a bit of a Streisand effect going on here. I want to learn more about the language, so I start reading some blogs, subscribe to the Reddit, etc. I want to learn more about FP in Scala. But then these mentions start popping up, but no one really says exactly what the issue is. I have to admit, I want to find out more. I know I probably shouldn't care, but then here I am.
Same here, get in touch when ready. We hire junior devs if we see potential and we write pure FP code in Scala.
It's not that people don't want you to know about it, it's just that most people don't want to talk about it.
&gt; but the amount of people making waves around Scala and splashing water is too big. If it was only a few people, I'd probably agree with you and dismiss these complaints as purely drama. However, like you said, it's a lot of people doing this! Plus, most programmers despise drama. You really need to be asking **why a large number of people are complaining** and vocal, not dismissing them as drama. I'd imagine a lot of us in the community used to primarily program in Java, and most of us probably also found Java to be verbose, limiting, and stagnant. After doing this for several years, we stumble across Scala, which seems to fix many of our major complaints. They also discover that not only is Scala awesome, but clean/correct functional programming also REALLY powerful. It's only natural that many people who really "get" (understand with depth) can become very passionate about FP and Scala. After a lot of hard work they finally get an offer for a Scala job, or convince their current employer to use Scala for production. "Finally, I don't have to write Java!" "I can't wait to work with and learn from other Scala/FP devs!" Sounds like a fairy-tale "happily ever after," right? Unfortunately, this is where the story takes a dark turn. As this person starts to integrate into the team, they start to notice the code is riddled with FP anti-patterns. People make mistakes, or maybe are new to Scala, so that's forgivable, and addressable with PR comments nudging them in the right direction. The situation then gets even worse. Their teammates no only refuse to make simple changes, but they also argue or imply that pure FP is anal and impractical. They're literally the only person who cares about FP, and nobody else gives a fuck. The team's refusal to grow and learn basically means they're only unlocking maybe 10% of what Scala &amp; FP has to offer. I'm fairly confident that most of the "I'm leaving Scala drama" is because of stories similar to the above. This "drama" is an expression of passion and love for Scala, but also a lot of frustration around "writing Java in Scala devs."
Functional Programming for mere mortals Advanced Scala with Cats
100% agree with @juli1pb. As a graduate/junior, you should focus on your computer science and software engineering foundation. If you can demonstrate that you have proper foundations, companies will hire you, no matters if you have previous experience with scala and FP. What it is really matter is to show that you are capable to catch up quickly, solve problems and that you can actually learn from the seniors around you. I moved to a new job working with Scala about a year ago without having any scala experience. (I was using java before) Personally, I would avoid any company where they ask language specific questions in the interview. I am not a Java developer, I am not a Scala developer. I am a software engineer. 
Why would F# be on that list? It's pretty much .NET flavored OCaml
When and where will the dead tree copy be available?
100% agree with @juli1pb. As a graduate/junior, you should focus on your computer science and software engineering foundation. If you can demonstrate that you have proper foundations, companies will hire you, no matters if you have previous experience with scala and FP. What it is really matter is to show that you are capable to catch up quickly, solve problems and that you can actually learn from the seniors around you. I moved to a new job working with Scala about a year ago without having any scala experience. (I was using java before) Personally, I would avoid any company where they ask language specific questions in the interview. I am not a Java developer, I am not a Scala developer. I am a software engineer. Obviously, you can always demonstrate your skills with the language or with FP in a coding exercise and they will take that into consideration. 
I have been maintaining Cats for more than 2 years. I don't think I know the "history" much more than you. To me what matters is the principles Cats and typelevel strive for. And arguably as a result, I see a rapidly expanding ecosystem of FP libraries in the last couple of years. There is also a trend of tighter collaboration between Lightbend, epfl and Typelevel the pure FP community. I don't know what could be more important than those two things for FP in Scala. I hope you will enjoy developing Scala as much as I do, or, at least, you won't be told by someone that you shouldn't. 
I could not have said it better myself. Thank you, Kai, for all that you do and all your hard work!
Likewise, my co-maintainer. You brought so much to FP in Scala that I wouldn't even care if Martin Odersky announced he left Scala for Haskell. 
What I would want to see is someone who wrote a program that they - or better still, their friends - actually use. Doesn't have to be pretty, doesn't have to be particularly functional - if anything a pure-functional background is seen (rightly or wrongly) as a risk factor for someone who might focus on virtuoso code rather than business value. So if your worry is employability your android apps might actually be the most important thing you've done, even for a Scala position. My advice would be to talk about the problems you solved and how the code you've written saves people time; if you want to talk about functional programming, frame it in terms of the concrete benefits you see from it (code that's clearer and more maintainable, lower defect rates, that sort of thing). The people making hiring decisions don't care about OO versus functional versus imperative for their own sake; if you make it clear that you can solve problems for them then the specifics of what tools and techniques you use are up to you.
- most people are enthusiastic about Scala 3 and the future; concerns about the Python 3 story are legitimate, but being intimate with Python‚Äôs story, I very much doubt it - writing FP in Scala is very satisfying actually; people that are expecting Haskell will have issues of course; if you want Haskell, use Haskell, obviously - but as a matter of fact Scala is among the vey few mainstream languages in which pure FP is practiced and other languages like F# or Clojure don‚Äôt qualify ‚Ä™ - I‚Äôm currently working with Java 8+, those saying that Java added FP features don‚Äôt know what they are talking about - Java is not and will never be a language that makes FP practical and all claims otherwise are a marketing effort that works, sadly
I don‚Äôt know what your talking about, but to be honest it‚Äôs no wonder that your colleagues have been dismissive of your recommendations for FP. If you‚Äôre as much fun to talk to as this comment implies, you must be fun to have around. Change your attitude or change your job, otherwise you won‚Äôt find happiness, not with a language choice at least üòâ
Why not scalacheck?
Hey there /u/alexelcu, before I reply I just want to say that I really appreciate your contributions to the community. Big fan of Monix. Just a few things that I wanted to note: - There are reasons to be enthusiastic, of course. All I'm pointing out is that the user base has expressed concern here, and that concern is a contributing factor to the posts that the OP alluded to. - RE satisfaction of FP, I challenge that notion. Is it more satisfying than OOP in Scala? Absolutely. But the truth here is that Haskell is the FP baseline today, and it is far easier to write good Haskell FP than Scala. This is a common reason FP minds leave; Haskell is just a better interface for this style. Simply saying it's a separate or more popular language is beside the point. As you said "if you want Haskell, use Haskell". That's exactly what the developers in question are doing. - I didn't try to claim that Java or Kotlin challenges Scala in FP. My point was that developers that are looking at Scala for a "better Java" OOP experience are seeing very few advantages in Scala today. That's a big part of the Scala community, and is one that is shrinking due to improvements in Kotlin and Java. 
The usage is more verbose and the generated value (by arbitrary\[..\]) is too wild .
Poster has already said he has seen this video lol
Seconded
Based on some googling I believe the the byte array is compressed with run length encoding. Where each "run" is an expressed as an Int where the first byte in the int represents the run-length and the remainder is the number to use in the run. For example: Array(0x02, 0x00, 0x00, 0x04, 0x01, 0x00, 0x00, 0x01) would result in `Array(4, 4, 1)` ## For the actual scala code: `source.map(_ &amp; 0xFF)` : I'm not sure if this is required but it could be ensuring the bytes are the right size. It is taking each byte and bitwise ANDing it against the byte `0xFF` `.grouped(4)` : subdivides our array into arrays of 4 (4 bytes to an int) `.map({ case Array(run, a, b, c) =&gt; })` : This extracts out all the pieces in the subdivided array getting us 4 the bytes per Int (`run`, `a`, `b`, `c`) `Array.fill(run)((a &lt;&lt; 16) | (b &lt;&lt; 8) | c)` This fills an array of the length of our run with the 3 other bytes. We bit shift those bytes up into an integer. `.flatten`: this takes our array of arrays and joins all the sub arrays into 1 array `.toArray`: I've called most returned values arrays but in reality they're mostly scala collections. This turns the scala collection into an Array
OO works great, for larger modules behind facades that need to maintain state, as you can think of a system as an object. FP is great for small domains, where the whole puzzle can be dealt with at once, and manipulated. Do we (as an industry) want to write 100 small services / projects using FP that need to tie into each other basically at the network point? Or would we rather make several \*\*tiny\*\* FP systems, glued together by OO, that can run on a cluster of servers we can view as one whole, refactor as one whole, and control runtime scaling of those individual services? The future of Scala in my mind is firmly in that area. Tiny systems, that are provably correct, glued together by OO.
Seconded too, happy to help moderation if necessary.
\&gt; IMO the job space isn't jumping towards Haskell because people view it as a niche, mathematics/academically driven language (which is mostly BS OO programmers I work with view \_\_SCALA\_\_ as that, let alone Haskell. and They have toyed with Haskell. The sheer complexity of FP decomposed to business rules and usecases is massive. Unless you entered it from a CS background, don't FP programmers just remember what they were like before they went pure FP?
That's brilliant! Thanks so much for the detailed answer
I wish I could \*\*not\*\* learn FP, but still get the benefits from FP via Libraries, dealing with abstractions at a level where they make business sense, not abstract computer science sense.
It's been a while since i worked with scalacheck, but isn't it possible to supply your own `Arbitrary[String]` with less wild data?
Aye. There's not a succinct way to understand the history of the drama and its current state. I say keep that drama outside of this forum as much as possible.
It'd be a much larger range if it was from GoToHaskell :-D 
I don't think there really is that much drama. There have been some threads about it the last couple weeks, but they are easy to ignore, if that is your wish.
I don't really like censorship anywhere and this topic seems to be on-topic of this subreddit. After all it is about Scala community and Scala library developers (as far as I know, but I don't know much about it as explained later). &gt; To outsiders, it probably makes the Scala community look like a bunch of petty divas, when in reality it‚Äôs 99.9% professionals trying to get things done. If this was true, then why aren't those "toxic" threads down-voted to oblivion? I tried to learn more about this (specifically if/why leading FP devs are leaving FP libraries) and got a lot of responses saying it's not an issue without explaining anything at all. Only post which actually provided some source, some facts, wasn't very encouraging (essentially a quote of threatening of silencing a library developer [which I think did happen] and possibly seizing an open-source library [not sure about this one, got conflicting responses without any sources]). Maybe get together a wiki page (with sources and quotes) to objectively summarize what actually did happen instead of trying sweep it under a rug again and again?
Yeah, I would like to know too and preferably got facts together (not just opinions, retold history by one side). I got one response suggesting that even politics were involved. And from the other responses which were lacking any sources and seemed to only discourage me from even asking about the topic, I get a feeling it might be true which is quite sad. I really hate pushing propaganda to movies, series, games and (unrelated to real life politics) communities like this one. Other thread is suggesting censoring this kind of topics, how "progressive".