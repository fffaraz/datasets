&gt; Because whether or not unlift breaks referential transparency depends on whether we treat it as syntax or not. Actually it doesn't. There is no syntax in Scala currently that indicates any sought of referential transparency, its either done by convention or through the type system Which means that `lift` (or `unlift`) isn't breaking anything because there wasn't anything to break in the first place
&gt; Yeah, I just don't understand how he's managed to avoid creating bugs when using them. They've been a major source of bugs in every codebase I've seen that uses them. I use implicits all of the time (also as a source of DI) and have never had bugs via implicits, I guess YMMV &gt; I've talked through that argument with him and I'm not at all convinced; it seems to be an argument from failure of imagination. He's very focused on this specific model of program execution, whereas to me the whole value of a type system comes from modeling things in the way that's best suited to your goals and what you care about. Actually the talk I was talking about was him talking about software verification in type systems, which is precisely the topic at hand &gt; More fundamentally I don't believe any argument that humans can do something that computers fundamentally can't. Whenever I've seen people resort to reasoning informally about side effects, it's only ever taken a little effort to make that formal, and the cases that are difficult are often the cases that aren't actually sound. The problem isn't that an answer (i.e. some abstraction for the problem at hand) doesn't exist, the problem is the "user finding the right answer and being able to comprehend it". The general gist of what he is saying is that a lot of these models are very abstract or have complex underpinnings. &gt; What I don't see a lot of is this semi-managed effect style Can you define what you mean by semi-managed? &gt; Is that a reason to think the decisions are any better? In any case Dotty is bringing substantial changes to central aspects of the design as well. (Which I think is great, to be clear) Yup but there isn't any change in Dotty in this specific area, apart from the addition of Phantom Types which are being used to create the effect system (i.e. Martin's version of checked effects). 
&gt; Is there any IDE that can evaluate cats code correctly? No. 
Did you even read what I wrote beyond the first sentence? Because you are missing the point spectacularly. I never said there was any syntax that guarantees any sort of referential transparency. I'm talking about whether we should treat `unlift` itself **as syntax**, so that the notion of substitution doesn't make sense, or as a normal expression (for which the notion of substitution makes sense).
IntelliJ file menu has Export to HTML. There used to be sxr - Scala x-ray that generated html from source code, fully hyperlinked.
Thanks for suggesting. 
Interesting. Play and Akka-http target different use cases so it is not an apples to apples comparison but I wonder if Play's relative decline is due to the 2.12 version still not being available six months after the release of Scala 2.12 or if there are other factors at work.
Python people in my experience take shortcuts. They're not ideological but that cuts both ways since I've seen big Python codebases with no guiding principles at all. 
Comment on `(7:49) this is the free monad` Well it is actually a bit more than the free monad, under the hood there is some use of Coyoneda (inlined in the Suspend and Bind constructors) to remove the functor constraints of `F`. [this](https://scalafiddle.io/sf/GwXDgya/1) is the standard free monad. The reason I want to mention this, is because when I was trying to learn more of the theory behind the free monad using other resources (mainly ones with Haskell) this use of overlapping terminology was one of the confusing points for me.
&gt; It's unwise to use Free just because it's cool. It's also unwise not to use Free just because someone said it's slow. Indeed. It's extremely useful in Scala (more so than in Haskell I think ‚Ä¶ it lets us deal with some problems that Haskell doesn't have). The granularity of your algebra will determine whether the constant factor matters. Most of the time it won't. 
Migration fatigue could be a factor as well; 2.4, 2.5, and 2.6 all entail fairly painful refactorings (mind you, for the good, the framework itself is moving in a good direction, leaving static/global state legacy behind). Also, Lightbend's investing a lot of resources into Java projects. When Typesafe bought Play from the original developers it was a Scala only project (with Play 1.x Java effectively abandonded). Fast forward to the present and Play Java is roughly at parity with Play Scala. That it will be more than 6 months after the Scala 2.12 release that a supported Play version will be available is really unfortunate, hope this doesn't become a trend. EDIT: oh, and Akka has a Scala.js port (Akka.js) while Play is JVM only.
I'm not proposing anything. It's about how we look at it: my argument (and /u/tpolecat 's) it's exactly that `unlift` is assigned to a val like everything else in Scala, so the standard substitution model applies (just like you said). In that case, `unlift` is a side effect, because it breaks referential transparency (unlike, say, Option.apply). The opposing argument (as argued by /u/cvogt, and /u/lihaoyi) is that `unlift` shouldn't be looked at as normal scala, but as new syntax (and yes, you can't enforce that, it's a convention), for which the substitution model ought not to make sense, and so you can't say that it breaks referential transparency (just like `&lt;-` doesn't, because you don't expect to inline the right hand side of `&lt;-`) EDIT: &gt;In that case, `unlift` is a side effect, because it break referential transparency (unlike, say, Option.apply). Note that I'm not discussing whether this is good or bad, that's another debate and I accept that other people don't care :)
 val res = for { consumerAccount &lt;- EitherT.right(getConsumerAccountDetails(registerCardReq.data.cardNum)) : EitherT[Future, ErrorMessage1, Option[SsConsumerAccountRow]] isRegistered &lt;- if (consumerAccount.isDefined) EitherT.right(isCardAlreadyRegistered(consumerAccount.head.id, consumerAccount.head.cardnum)) : EitherT[Future, ErrorMessage1, Boolean] else EitherT.left(Future.successful(ErrorMessage1("error1"))) : EitherT[Future, ErrorMessage1, Any] lol &lt;- EitherT.right(query1()) : EitherT[Future, ErrorMessage1, Int] id &lt;- if (isRegistered == false) EitherT.right(registerCard(consumerAccount.head, registerCardReq.consumerId)) : EitherT[Future, ErrorMessage1, SsConsumerCardRow] else EitherT.left(Future.successful(ErrorMessage1("error2"))) : EitherT[Future, ErrorMessage1, SsConsumerCardRow] } yield { id } res.run onComplete{ case Success(x) =&gt; { println("Success",x) } case Failure(x) =&gt; { println("Failure",x) } } } Finally, this worked for me, do you think I would need to pass explicit type parameters to all the if-else conditions?
Hmm, that's unfortunate. You can pass them as type parameters on the call rather than a type annotation at the end but that doesn't save much. All I can suggest is defining a type alias (e.g. `type Result[A] = EitherT[Future, ErrorMessage1, A]`) and/or helper methods that call `EitherT.right`/`EitherT.left` and return the correct type. There are fancy techniques that might reduce some of the boilerplate but they're all a bit experimental at the moment.
this.
In that case, we pretty much agree. My main point is that the opposing argument (that `unlift` is just new syntax) is more idiomatic to Scala's design rather than treating it in a special way
Very nice! Already used the RC in a new project and very glad it hits release before I push it to production :)
Implicit class is just syntactic sugar for a class paired with an implicit conversion method with the same name
I completely agree. There's a reason I use scala. It's not fair to call them religious though, they are the opposite.
When I started learning play framework ... I found the activator very very odd. I wondered to myself why didn't they just use SBT/Giter8. and now here we are....
same experience for me, I found it very off-putting
Hi, I would highly recommend Neophyte's series of posts (as a supplementary material): http://danielwestheide.com/scala/neophytes.html
In Play 2.6.x this is possible, because the internal global state is removed. https://github.com/playframework/playframework/pull/5964/commits/625a3ebec43472cf0e01bccdd23552397b3cdbab
their blogs are always very poorly written, style and content wise. for instance: &gt; Scala (The Beast) has imported efficiency and elegance to the programming world by combining coziness of object oriented programming with the magic of functional programming. what is that even supposed to mean?
Whoa whoa hold on. They're reimplementing *Java* APIs, under a license that's not compatible with GPL2? Do they want a lawsuit from Oracle? Because that's how you get a lawsuit from Oracle.
Exactly. Remember, if you can write a lawful `flatMap`, you can even derive `map`.
Is the Scala license not compatible with the GPL2 license? *genuine question*
Did they have bindings for Gtk+/Qt?
Not in the sense of not getting sued by Oracle for implementing Java APIs under that license, no. That doesn't apply to Scala itself, though, because it doesn't implement any Java APIs.
Seems like an awesome post. Cheers! 
Short answer: they are. Longer answer here: https://scala-native.readthedocs.io/en/latest/contrib/contributing.html#very-important-notice-about-javalib
Your source for that? That is not the case as far as i know ( or [wikipedia](https://en.wikipedia.org/wiki/Oracle_America,_Inc._v._Google,_Inc.) for that matter)
Other important use case would be Enterprise deployments. Since most Enterprise clients do not need the scale, they just want their private version.
Ooh, I like all that. Thanks for answering!
your account (/u/akashsethi24) is in violation of reddit rules: [It's perfectly fine to be a redditor with a website, it's not okay to be a website with a reddit account.](https://www.reddit.com/wiki/selfpromotion) honestly, i don't understand why you guys over at knoldus keep embarrassing yourselves by always publishing such low quality, low effort, poorly written content
your account (/u/srivastava_anurag) is in violation of reddit rules: [It's perfectly fine to be a redditor with a website, it's not okay to be a website with a reddit account.](https://www.reddit.com/wiki/selfpromotion) honestly, i don't understand why you guys over at knoldus keep embarrassing yourselves by always publishing such low quality, low effort, poorly written content
well the case is all over the internet. google won the API case with fair use: - https://patentlyo.com/patent/2017/02/google-oracle-copyrighted.html - https://www.google.de/search?q=google+fair+use+oracle Guess fair-use can be applied to Scala.JS, too. But IANAL
I'm well aware of the case, but the claim that the lawsuit was "because the Android java implementation was incomplete" needs substantiation.
Scatalite? I do call Haskell programmes Haskellites...
You're welcome and thanks for mentioning better-files.
Oracle can sue anybody for anything. Given their large patents portfolio, they might even win. Also, it's not the license that matters. What would be safer would be to *fork* OpenJDK, but I don't think that a Scala Native implementation could claim to be a fork, GPL2 or not.
Activator never worked right on Lubuntu. SBT did.
20 seconds is really not that slow, especially when you consider that the guarantees of a strong type system prevent you from having to handle huge categories of errors. Is Scala your first compiled language? Everything in engineering is a trade-off. When you choose a statically typed language, you're choosing safety, speed, and compile-time guarantees at the expense of more time up front compiling.
Hello! Author here. Yeah I'm sorry about that. I hope you used the migration script which covers around 80% of the change. The migrations are normally small enough that my little migration snippets cover it 100% but, this 1.0 was a big one and there's only so much I can do with regex. Changes won't be as big and disruptive again unless there's a 2.0 which will be years and years away. :) And also, thanks to yourself and the community for taking the time to deal with the manual portion of the migration. It costs all of us a little bit of pain now, but it really allows the library to evolve into a much better shape.
For me it's all about developing a workflow around the strengths and weaknesses of Scala. When I was coding Javascript I had this habit of constantly making small changes and then checking whether the thing still runs, either in the browser or by re-running the tests. I had to because it's too easy to introduce a typo or make another mistake that the compiler would catch (except there isn't one). And if you have too big of a diff, it's hard for you to catch such errors manually. With Scala my workflow is completely different. I could be coding for hours without waiting for anything to compile because the IDE (IntelliJ) is pretty good about highlighting obvious errors, and I have good confidence that the app works the way it should. I still have a `~compile` or `~test` session running in the background, but I never wait for its results, just check that it's still green occasionally. It does get annoying when I do need to actually run my code, but that usually happens when I finished making my changes and everything compiles. And it becomes a problem only if it compiles but does not work as expected at runtime, which does not happen often for me.
What project is it?
If twenty seconds is making or breaking your productivity, you need to either code better or move on to a different occupation. Work smarter. Trial-and-error is not professional.
I bill by the hour
Hehe I did use the script, it works great. I was chating with /u/olafurpg about how we could provide a scalafix rewrite. The other changes I did not find in the migration guide: * `accessDirect` in a `componentDidUpdate`. I think I found a proper solution without using unpure state in the PR. https://github.com/scalacenter/scastie/pull/170/files#diff-a2fe55369a2d7906f6b21ce5698e7ef9L78 * funky implicit import for the router https://github.com/scalacenter/scastie/pull/170/files#diff-9a206b141a2ff17cd328f07f5f851b14R6 (this one was really hard to find)
It's a lightweight place to put initialization that you want to happen once. E.g. reading some semi-static data from a database or file, running service discovery to find your upstream services, registering yourself with service discovery. It's kind of dangerous in that it renders the object it's in untestable (so I'd only ever do it in dedicated IoC objects, not in my actual service object), but honestly there are no good frameworks for IoC with lifecycle management - something like Spring introduces more safety issues than it solves. So I'm sympathetic to doing impure initialization "by hand". (My own effort at making this better, [deliciouslie](https://github.com/m50d/deliciouslie), might actually be usable once the recursive implicit resolution performance fixes have gone into the language (or has that happened already?) - I'll have to dust it off).
Are you invoking sbt every time? Don't do that, instead use the sbt shell and take advantage of incremental compilation
Why would you want to represent semi-static data with a lazy val though? def with a cache is much saner, cause as you said the data is semi-static and a lazy val cannot be recalculated without junking the object it's attached to
(If using SBT) Currently SBT has file-level granularity. Meaning that if you define a lot of classes in a single file, changing the interface of any one of them will actually triggers a recompilation of any file depending on any classes in the modified file. This page shows some useful tips on how to structure application to prevent such issues : http://www.scala-sbt.org/0.13/docs/Understanding-Recompilation.html
well, i'm using ehcache with play, and i can trigger an update for an element by specifically reloading it into the cache. i can see using lazy vals this way if you're junking and spinning up whole applications, but it still seems like something better suited to a synchronized cache or something to me
&gt; i can see using lazy vals this way if you're junking and spinning up whole applications, but it still seems like something better suited to a synchronized cache or something to me Yeah, it's the sort of thing I'd expect to migrate to something more robust as a project matured. But a lazy val is a very lightweight way of doing it in the early stages.
I really wish I knew.
Scala does a lot lot more then Go , or even D. Implicits, Higher kind types, Generics, Macros, and a few little things. Assuming you use some kind of web framework, most of them use all of the above.
I often do, because it can make it hard to distinguish between the current compile result and the one before (especially with multiple error messages) and because of the cpu tax. I rather compile within my IDE on demand or with something like `clear; sbt compile` on the console. I wish there was a nice way to remove the previous compile output.
There's a couple manning books for Reactive Application Development: I personally have https://www.manning.com/books/reactive-design-patterns and several others, but this one is the only one I've gotten to reading so far. A search for Reactive on their site will reveal a pretty good list of books. To go along with Play/Akka: https://www.manning.com/books/reactive-web-applications I've generally been very satisfied with Manning books, and can recommend them as a reasonable resource to learn stuff :)
I feel like this would be better solved by something like CloudFoundry or something like that. That way your applications can get an isolated JVM, and you can still have a bit more elastic infrastructure. Maybe that's a bit off topic, but reading comments about "Enterprise" deployments made me think that trying to run multiple apps in the same JVM is just applying enterprise thinking to newer technologies. They're really better off in their own JVMs.
I could easily jump over to another language, but there are certain features I demand now: strong static type system with type inference, concise syntax, pattern matching, sane equality, facilitates for immutability first (ie. something like case classes that's immutable but makes it really easy to modify (.copy)), and a vibrant friendly active community with lots of libraries. I also need "reach" -- Scala allows you to target both JVM (desktop+android+webservers+bigdata/ai), JS (the worlds biggest platform?) and now Native. So while Scala isn't a religion to me, it has definitely raised the bar substantially for what I want from a language. edit: Oh, and I almost forgot the most important thing: Tooling! Scala works excellently with IntelliJ (and others?). That is a huge benefit.
That's what I subsumed with "better".
[Mark lewis](https://www.youtube.com/watch?v=85bHg5AipvU&amp;list=PLLMXbkbDbVt8JLumqKj-3BlHmEXPIfR42) lectures on youtube are also a pretty good source.
BuckleScript (OCaml to JS) has sub-second compiles.
You're talking about transpiling Scala.js to JS, right? I.e. the `fastOptJS` command? That's slow mostly because it has to link together the Scala library dependencies and your code every time. There is a way to set it up so that it becomes just a fast file append operation, but the tip is somewhere in the Scala.js documentation and I don't remember where üòä Edit: the closest I can find to what I mentioned is some hints in the 'Decomposition in three files' section in http://www.scala-js.org/doc/internals/compile-opt-pipeline.html
which also summons /u/tpolecat whenever you have more than one `unsafeRun` in your codebase...
So can this can used as a build-integrated formatter?
Heh, I didn't announce this post but I guess people found it anyway. So yeah if you have any suggestions let me know. It's work in progress, as noted.
Macros are truly powerful, especially implicit macros. However, for their use case, I think a simple syntax-driven `@product` macro on case classes could work, to implement exactly what they are complaining the compiler is not doing (generic `ProductN` extension with companion access). Something like this: @product case class Person(name: String, age: Int) Would expand to: case class Person(name: String, age: Int) extends Prod2[String,Int] { val companion = Person } object Person extends Prod2Comp[String,Int] { type Self = Person } Where: trait Prod2[A,B] { val companion: Prod2Comp[A,B] } trait Prod2Comp[A,B] { type Self &lt;: Prod2[A,B]; def apply(a:A,b:B): Self } Seems more difficult for generic case classes, though, especially since we can't abstract over type kinds. Probably something like: trait Prod2Comp1 { type Self[_]; type _1[_]; type _2[_]; def apply[A](_1: _1[A], _2: _2[A]): Self[A] } And have somewhere the right implicits to deal with them. 
This is very nice - thanks for sharing the idea, but I'd argue that "self-inception" is a slightly better solution (although obviously less generic), because you don't have to tediously annotate every case-class you want to inspect (especially in code-base you inherited). You might be better off using shapeless' Generic for more or less the same effect minus extra typing. Also, (client) dependency on macro-paradise is slightly annoying. All in all, what you probably can't achieve any other way is selective implicit resolution (turned out to be helpful for spray-json formats)
This one takes the cake. Q : What are your superpowers again? A : Well my code runs in production.
I'm working on [kebs](https://github.com/theiterators/kebs) - macro library that reduces boilerplate you usually write when using slick/spray-json/play-json
This is much needed now considering how Oracle is handling the licensing issues. If you guys don't have this on the roadmap yet, then please consider something like [shenondoah](http://openjdk.java.net/projects/shenandoah/) GC. 
[You said it brother!](https://github.com/MateuszKubuszok/SBTScalaMultiproject2.g8/blob/master/src/main/g8/project/Settings.scala)
&gt; Their Java-related patent was shot down a long time ago. That probably won't work. What Oracle prevailed on was the copyrightability of the API itself, not the implementation. Oracle has plenty of patents related to programming languages and runtimes, given they've bought Sun, which did research on Self and Smalltalk / Strongtalk even before Java. &gt; So long as your code is GPL2, you might argue that you took it from OpenJDK and modified it (which GPL2 allows). But this code isn't GPL2, so you'd have the same problem in court as Google did. No, that's not how copyright works. Also, Google won.
&gt;Oracle has plenty of patents related to programming languages and runtimes, given they've bought Sun, which did research on Self and Smalltalk / Strongtalk even before Java. [The patents asserted by Oracle were found not to apply to Android.](https://en.wikipedia.org/wiki/Oracle_America,_Inc._v._Google,_Inc.#District_Court) They do not appear to apply to Scala, either. Moreover, one of them (RE38104) appears to have expired, and the other (6061520) describes a JVM optimization that frankly doesn't even look useful. &gt;No, that's not how copyright works. Enlighten me, then. &gt;Also, Google won. [False.](https://en.wikipedia.org/wiki/Oracle_America,_Inc._v._Google,_Inc.#Second_trial)
I went through several compilation flags a while ago. I'm not aware of any new flags since then, so I hope it can help you in some way: http://pedrorijo.com/blog/scala-compiler-review-code-warnings/
can we ban blog.knoldus.com? they spam this sub with low quality content and now they are creating a new fake account per post, violating reddit rules. for instance /u/ShivangiGupta1015 and /u/anuj1207
&gt; The patents asserted by Oracle were found not to apply to Android. When you're starting a lawsuit, you don't go with your full patents portfolio, because patents are in fact brittle, can get invalidated if challenged, which can cost the company more than they can win. You haven't seen the last from Oracle, given they are one of those companies owning more than 10,000 patents, over 7,500 of which they've bought from Sun. &gt;&gt; No, that's not how copyright works. &gt; Enlighten me, then. To receive the protections of the GPLv2 license, which is copyright, along with its implicit patents grant (which wouldn't hold that well in Europe btw), the work has to be an actual derivate. In other words: 1. no, you can't argue, unless you literally fork the OpenJDK repository and have proof that your work is a derivate of it 2. you can't pick a licence "compatible with GPLv2", there's no such thing because *nothing* allows you to change the licence, not even if we are talking about BSD or MIT ... in other words the license has to be GPLv2, with the linking exception, the exact same license, word for word, that OpenJDK is distributed with &gt;&gt; Also, Google won. &gt; False. You linked to an article that has this to say: *On May 26, 2016, the jury found that Android does not infringe Oracle-owned copyrights because its re-implementation of 37 Java APIs is protected by fair use.*
&gt; ` lines &lt;- readLines("names.txt").shift(BlockingFileIO).shift(Main)` Very not-impressed. Especially after the sermon about `Future` and its eager execution. At least there you can use `blocking` inside the future's body. Here you will have to know the unknowable from the API user's side. That doesn't make any sense to me, and is clearly in contradiction to encapsulation. Or, to use another FP's red rag, compare this to Akka Stream where the stage logic defines _from the inside_ whether it should use a blocking executor or not. Overall, the `IO` type seems simple enough when it comes to monadic composition, but I'm not convinced this is doing any service to handling concurrency correctly and predictably.
yes I really loved it.
People have hesitated to adopt cats because this piece was missing, so this is a really important development.
I don't have a lot of Scala experience, but my first "real-world" project was a rewrite of an existing Node API with [Finch](https://github.com/finagle/finch). There was some Java interop involved because I was using a couple Java SDKs including [Firebase](https://firebase.google.com/docs/admin/setup). I have some Java experience, but not knowing any Java wouldn't have been much of an issue. 
This will be my third cat. The virtual one )
&gt; Very not-impressed. Especially after the sermon about Future and its eager execution. Future being eagerly executed means that it cannot be used for suspending side-effects and you can't control execution very well either. Personally I like `Future`, I find it to be a complementary to a well grown `Task` / `IO` data type. Some people more experienced in Haskell could live without it. But personal preferences don't invalidate the main point, which is that if you want referential transparency / functional programming, then `Future` is not adequate and that's a fact. &gt; At least there you can use blocking inside the future's body. Nothing stops you from using `blocking` here, or from "encapsulating" the thread-pool if that's what you want. The article talks about that, but maybe it hasn't made it clear: def read(path: String, ec: ExecutionContext): IO[List[String]] = IO.async { callback =&gt; ec.execute(new Runnable { def run() = { try callback(Right(blocking(readLines(path))) catch { case NonFatal(ex) =&gt; callback(Left(ex)) } } }) } &gt; Or, to use another FP's red rag, compare this to Akka Stream where the stage logic defines from the inside whether it should use a blocking executor or not. That's apples versus oranges. &gt; Overall, the IO type seems simple enough when it comes to monadic composition, but I'm not convinced this is doing any service to handling concurrency correctly and predictably. This `IO` type is not about concurrency (although it could do it, since it handles asynchrony). Daniel makes this clear in the article. A type that's more potent for handling concurrency is the Monix Task: - [documentation](https://monix.io/docs/2x/eval/task.html) - [slides from Scala Days](https://speakerdeck.com/alexandru/monix-task-lazy-async-and-awesome-scala-days-chicago-2017)
This is indeed an amazing development
I think this is an important idea. If anything, I don't think he went far enough in terms of how applicable this idea is. This talk focused a lot on advanced and new type systems and compiler techniques, but I think 95% of code doesn't really have use for that kind of thing. That's not to say you shouldn't still be thinking about letting the compiler help you... for instance, which of these is better: def getPhotos(userId: Long, albumId: Long): List[Photo] or class UserId(id: Long) extends AnyVal class AlbumId(id: Long) extends AnyVal def getPhotos(userId: UserId, albumId: AlbumId): List[Photo] Clearly the latter will let the compiler prevent you from mixing up argument order.
Ah, gotcha. Thanks for explaining! (And sorry about the late reply; work caught up...)
I think this is really exciting news! One thing I noticed in the post is the double shifting paradigm, I feel it would be better if we provide two functions: `shift` (for shifting the current one operation, `shiftAll`(for shifting all the operations in the continuations). It's like renaming the current `shift` to `shiftAll`(or a better name, naming is hard), and add a `shift` that does the single shift operation. Unless `shiftAll` is a lot more common than shifting a single operation (which I'm not sure), having the double shifting operation is a bit confusing, especially to new comers who are not familiar with this pattern. Alternatively, it could be `shift` and `spawn` (which is the single version, again naming is hard :p), the point is having them as separate APIs
Hey, if you want to provide feedback, please do so on the project's issue tracker: https://github.com/typelevel/cats-effect Also see this discussion: https://github.com/typelevel/cats-effect/pull/10#issuecomment-296391075
I don't know the details of akka streams, but I would assume you explicitly interleave all your streams and throttle the overall stream? Or alternatively define your own "shared throttle" combinator that uses an actor or similar underneath.
While all three are broadly considered "general purpose" programming languages I think they all have their own problem space they are best suited for. C++ is great for high performance computing, graphics, etc, python is great for scripting, numerical / scientific computing. Scala has taken off in the big data community because of its strong type system, Java-interop (so libraries built on top of Hadoop ecosystem can easily be used and extended in Scala) and preference for immutability and side-effect free code, which makes distributed computing much easier to reason about. Even if you're not interested in big data, I think for you specifically learning Scala would be great for you to 1) have exposure to real functional programming concepts (much more than what python can offer), and 2) have some exposure to a JVM-language (maybe this isn't so important but still nice to have). I don't think it's ever "not worth it" to learn another language, but there's an opportunity cost in the time invested obviously. In your case I think it would really round out your knowledge of programming paradigms and be an asset to you in the future, even if you stay with C++ and python.
I've answered on another thread, see here: https://www.reddit.com/r/scala/comments/672s2a/effects4s_common_communication_protocol_for_io/dgp19ak/
I don't really know how to make `shift` better, other than perhaps splitting the "prefix" and "suffix" shift operations. I agree that the double-shift idiom seems quite bizarre from the outside. Another way of looking at it, and perhaps a better way of explaining it, is to say that the *prefix* component of `shift` is idempotent on all parameters (i.e. subsequent calls have no effect, regardless of parameterization), but the suffix component is only idempotent on equal parameterization. Here's the problem: `IO` is *two* monads in one. The first is very analogous to `cats.Eval`, in that it suspends a value of type `() =&gt; A` and provides lazy and stack-safe operations over it. The second is analogous to `scalaz.Cont`, in that it suspends a value of type `(A =&gt; R) =&gt; R` and provides lazy (but necessarily not stack-safe) operations. The `Monad` interface allows us to merge these two into the same type quite elegantly, which is an undeniable benefit, but it does mean that operations which affect evaluation semantics end up differing considerably depending on which constructor is sitting underneath. Here's a question for you: would it be better to have two separate operations, `shiftPrefix` and `shiftSuffix` which themselves have varying semantics depending on what sort of `IO` you're looking at? By that I mean, `shiftPrefix` would be a no-op on any `IO` constructed with `IO.async`, and in fact any `IO` bind chain *beginning* with `IO.async`, even if the rest of the chain is entirely `IO.apply`. Meanwhile, `shiftSuffix` would have absolutely no effect whatsoever on the evaluation of the `IO` on which it is called, only on the evaluation of `IO` actions sequentially bound *following* that action. Is this a preferable situation? Right now, `shift` contains both of those operations, simply because in my experience teaching people how to use `scalaz.concurrent.Task`, no one understands `fork` (or any of its variants) or how to use it, they just want a single "make this go to a different pool" operation. Some specific rebuttals‚Ä¶ &gt; Here you will have to know the unknowable from the API user's side. Or you can just call `shift` safely and be absolutely sure that things are working the way you want. There's no harm in it other than a thread context bounce. &gt; That doesn't make any sense to me, and is clearly in contradiction to encapsulation. Or we're just encapsulating something different than you think we are. üòÉ `IO` encapsulates *effects*, it does not encapsulate evaluation. I think /u/alexelcu was touching on this a bit. Evaluation semantics are external to the effects themselves, and thus it is *by design* that the underlying thread pool on which an effect is evaluated can be changed from outside its definition. &gt; Overall, the IO type seems simple enough when it comes to monadic composition, but I'm not convinced this is doing any service to handling concurrency correctly and predictably. And it's not designed to do so. If you care about concurrency, use fs2 or Monix. I tried to make that very clear! In fact, in the original design of `IO`, there was no `shift` at all, and I hesitated for a long time before adding `unsafeToFuture`. I didn't want any thread-related anything in the library, because I've seen first hand just how much chaos arises when an insufficient abstraction tries to provide concurrency semantics that *seem* sane but have hidden pitfalls (hello, `scalaz.concurrent.Task`). The only reason we added `shift` was because it turned out to be very difficult to do anything useful with `IO` without it, and while it's relatively easy to define in "user-land" (especially the suffix component), it's far more convenient if `IO` (and `Effect`) just define it for you.
It also looks easier to get right than if `shift` were absent.
Hey Daniel - thanks for taking the time to answer this to such great detail, your work is very much appreciated!
I looked a lot of Scala code for the first time today and honestly it looks really cluttered compared to well written Java code. Thoughts?
Let's say I have the following `Functor` instance for `Either` (using Kind Projector), and implicit `FunctorOps` in scope that work with `List`, `Option`, etc. no problem. implicit def eitherFunctor[L] = new Functor[Either[L, ?]] { override def fmap[A,B](fa: Either[L,A])(f: A =&gt; B): Either[L,B] = fa map f } How can I get the last line below to compile? def functorPrinter[F[_]: Functor, A, B](fa: F[A])(f: A =&gt; B): Unit = println(fa fmap f) val either: Either[String, Int] = Right(1) functorPrinter(either)(_ + 1) // &lt;-- Doesn't compile I read/watched something about using an `unapply` function to coerce type inference somewhere, but I can't seem to find it now, and I couldn't find any examples in the Cats source when trying. If anyone could point me to any resources on dealing with types like `Either` and `Map` in these situations, I'd really appreciate it. 
You could probably rewrite the "well-written Java code" in Scala without the explicit types, semi-colons, `return`, `throws ImpossibleToReasonAboutException`, etc. and *remove* a lot of clutter. Beyond that it's difficult to comment without knowing anything about the code you were looking at. Scala's type system offers a lot more features than Java's, so if you're looking at code that utilises it without prior knowledge, then it may look like a mess. Similarly, return types that favour referential transparency like `Option` and `Either` add some amount of bloat, but also provide a lot of power and flexibility in other places (you can forget about `if (x != null)` and `try/catch` for example). 
Uhm, any tips for a person who easily loses focus on seeing the next shiny thing?
Find small useful things. And practice the art of actually finishing your projects. (he says, having had a release of tierney almost ready for about 2 weeks now and still not doing it)
&gt; Why do you think I should stick with Rust instead of Scala in the immediate time? Just because there aren't the rough edges around JVM compatibility and tooling (and, to be honest, the community is much nicer). E.g. the good build tool on the JVM (Maven) doesn't support cross-building for multiple versions of Scala, so most Scala users use SBT which has impenetrable, poorly-documented syntax, is pretty slow, and breaks compatibility of build definitions pretty frequently. E.g. you have to pass `ClassTag`s around to be able to do certain operations like instantiating an array, and pattern-matching will not work correctly on parameterized types, because of the details of how the JVM works. E.g. `null` is still there in the language for the sake of Java compatibility, though thankfully almost all Scala libraries know better than to use it. Don't get me wrong, Scala is the best language going for serious work, once you commit the time to it (if I didn't believe this I wouldn't be here). But it's not a great place to start, and it's probably better to learn ML style in a more elegant language first. &gt; Can you give me an example of ML tasks with Scala which is easier to do instead of doing that with another language? I don't understand the question. Note I'm talking about the ML language family, not machine learning.
If you're on a new enough version of Scala to have it, does building with `-Ypartial-unification` make it work?
Scala tends to allow a dense style where you can replace 10 lines with 1. You don't have to, but experienced Scala folk tend to favour that style; IMO people underestimate how valuable having a class or method that fits on a single page is, even if that means you have to spend a few seconds "unpacking" a line to read it. On the other hand you can write a very Python-like style of Scala if that's what you want.
&gt; I don't understand the question. Note I'm talking about the ML language family, not machine learning. Oh, well, it sounds strange to me, too. I thought ML was for machine learning. What's the ML language family?
and once you get used to mental unpacking, you become very quick at it. So you have a lot of code on single page that you have unconsiously unpacked....
As a side note I highly recommend using something like [parboiled2](https://github.com/sirthias/parboiled2) instead of the parser combinators. Basically much nicer API, a few hundred times faster, much easier/nicer/better error reporting. Only downside is requirement shapeless and thus requires scala 2.10.3+ which for most code bases shouldn't be an issue. But still very well written article.
[fastparse](http://www.lihaoyi.com/fastparse/) is also very nice.
&gt; Like most languages, Scala has a ‚Äúfatal warnings‚Äù flag which will promote warnings into errors. But it doesn‚Äôt have any way to suppress individual warnings. &gt; The result is an ‚Äúabstinence only‚Äù kind of situation ‚Äì you either have to commit to never introducing a single warning of any kind, or else you can‚Äôt benefit from fatal warnings at all. While I definitely want some kind of localized "suppress warning" annotation for fine-grained control, you can still get some benefit from `-Xfatal-warnings` by globally turning off specific warnings. For instance, in one of my projects I have `-Ywarn-dead-code:false` because of mocks, and `-Yinline-warnings:false` because of Slick. In another I have `-Xlint:_,-missing-interpolator` because the syntax in `@implicitNotFound` looks like it should involve interpolation but doesn't, and `-Yunused-import:false` because of scalaxb. I still benefit from avoiding all the other warnings like value discarding, adapted args, deprecations, features, unchecked, etc.
LLVM is under a MIT/BSD-style license.
Fair enough - I can't fault Azul for trying to make a buck, and Zing is certainly a very impressive product. I can't help but think that contributing a GC without stop-the-world pauses back to the community would be a good gesture from them, however. They would have nothing if it wasn't for the millions of people who built the community in the first place. Of course, it's completely both ethically and legally their right to keep it proprietary, and I don't really begrudge them for doing so, but it's also my right to not purchase their product.
Well technically Zing still has "stop the world" pauses, they just guarantee that they will always be less than a certain value (I think its 40ms iirc). Still a very impressive piece of technology though. There is also apparently an open source version, you can try it out here https://www.azul.com/zing-oss-open-source-developer-access/ Lets see where scala-native will get us though, all of these performance enhancements scala native also has access to (since it also uses LLVM as the backend), the main thing in scala-native is making a really good GC Also according to the article &gt; Of course Falcon is not just about leveraging other people's work and contributions. We like that, but we had to sink in a bunch of our own work and contributions to make it all possible. The Falcon project at Azul has made significant improvements to LLVM's ability to optimize code in managed runtime environments that includes things like JITs, speculative optimization, deoptimization, and Garbage Collection. When we started, LLVM was able to deal with these concepts to various degrees, but having any of them around in actual code ended up disabling or defeating most optimizations. Over the past three years, Azul's LLVM team has improved that situation dramatically, and successfully and repeatedly landed those improvements upstream such that they can benefit others in the LLVM community (in other runtimes, not just in Java). Azul has contributed many improvements upstream to LLVM (mainly with LLVM's JIT), so its not like they are completely freeloading. It will actually be interesting to see if languages like Julia (LLVM and heavily reliant on JIT) will benefit from such upstream changes.
Yup, and this was done deliberately. LLVM originated out of Apple's frustration from using the GCC compiler, and Apple did this so it was easier to use LLVM in their own toolchain (from a legal perspective, as well as the obvious technical one)
why not just use a akka-stream? - if you really need non-blocking stuff? a akka-stream is basically a managed actor and terminates, when the work is done. it has a well defined async boundary and as a bonus you get backpressure for free. Something like Source.tick(2.seconds, 20.millis).flatMapConcat, etc..
Could you explain how to call external web service from Akka the right way? I have to perform callbacks from my Akka app. I'm not interested in response, just call HTTP service and forget. 
I would just make a call that returns a future (using akka-http client) and then discard the future.
Can you wipe your .Idea folder? It is also one of the main plugins that you're invited to install on first run.
Make sure that you don't have any filter in your plugin window (be it a search term, repository or category). If that doesn't help, you can manually install the plugin. Download it from [here](https://plugins.jetbrains.com/plugin/1347-scala) and choose "Install plugin from disk" instead of "Install JetBrains plugin".
Try choosing "Browse repositories" in the plugins dialog.
Do not know what to say. Next post will, probably, describe the astonishing insight that streams must be closed... I mean that is obvious that engineer should think about memory deallocation.
Ok, great! Thank you for that link. I've gone there and downloaded the .zip file. Where should I extract it?
You don't need to extract it. Go to plugins, click "Install plugin from disk" and select the zip archive. Simple as that. :-)
Ah yes, that worked. Thank you so much!
Because often all of that is overkill if you just need async. Plain `Future` covers a lot of the use cases.
I never encountered any of these, ever. It just shows that you should always declare you return type. Just to recap: ##Example 1: I don't think you should ever do that, but even if you do, you will get a compiler error as soon as you try to use any of the variables. ##Example 2 The compiler should be smarter, and should throw an Error when you are comparing types that would never be equal. But it's not a problem with symbols, especially since you don't really compare literals, and when the declaration and the actual functions is in a different place, you will get an error. ##Example 3 That's not a scala question, but a bracket/ brace question, that is in almost EVERY single language that is inspired by C. This is very easy to overcome. Use a code formatter, and the indentation will make it clear that it's in the wrong place, or make braces mandatory for multiline expressions, enforce it automatically with code formatter. And further more, it's also a problem with side effects, which should be avoided when possible. ## Example 4 I don't see how it's a bug. If you define a block it will result in a single value, NOT a function, and the block will be run exactly once. enabling to write {} for function calls is necessary for DSL-s to work, but it really should not be used in ordinary code. The real bug is the example, relying on side effects. ##Example 5 Well, you mean what you write don't you? It's easy to avoid it by writing the type declarations. I really feel that this example is just to try to demonstrate something, i don't see that it could cause real bugs. And even in the example, it will case a failed test, you just revisit it. I admit, ScalaTest has some weird quirks, but that has nothing to do with Scala. And of course, you don't test literals against each other, that's stupid.
Not really. LLVM was started as an academic project in 2000. It was adopted by Apple in 2005... 
You may not get update notifications (for the plugin) when installing this way (not sure?) It sounds like there's an issue with the overall IntelliJ install, you (tampers_w_evidence) might want to think about doing a clean reinstall even though you got the plugin installed.
Cool, thanks for the advice. I'm not heavily invested in it yet (just installed today to align with the tools the rest of the team is using) so doing a clean reinstall is no big deal. Thanks for the heads up!
How would you manage schema changes on developer machines and CI then? 
/u/DisruptiveHarbinger is talking about the first time you run IntelliJ after you install it. There definitely is a wizard that you go through where you select whether you want to import settings from an old version, you decide what color theme you want to use, and you decide what plugins to enable. https://www.jetbrains.com/help/idea/2017.1/running-intellij-idea-ultimate-for-the-first-time.html That wizard might only exist for IJ Ultimate. Once you've gone through this wizard, it won't prompt again unless you wipe out your user preference directory. On my Windows box, that directory is `%USERPROFILE%\.IntelliJIdea2017.1`. 
I'm talking about the *other* side - not about us.
I've never used actors because I've never been able to work at a job that uses Scala. However, after studying them a little I've ported some ideas from Scala actors into different java codebases I've worked on. Essentially, I create the concept of a "Channel", where a channel is just a message queue coupled with a message processing function. Clients send messages to channels, and those channels process the messages asynchronously. If a client needs to "wait" on the result, the message simply needs to include a shared Promise object that the channel can fulfill when message processing is complete. Implementing the above can generally be done in a single java source file and works well with fork/join pools. Now you can definitely add more features like limiting the number of messages a channel is willing to process before yielding its thread, or customizing the queues like adding boundedness, but the basics are there in one file. So, I'm generally curious, what are Akka's most useful features beyond simple message channels? I've read a little about supervisor hierarchies, but honestly the complexity of the system feels like it outweighs the benefits. An example of this complexity is given in this blog post where it turns out actors have to be manually released or they leak memory. I've also read there's also the possibility of sending actor messages to remote systems, but honestly for this I'd rather use an HTTP API. It's very rare that I'd want to treat a local message send the same way I'd want to treat a remote message send, and doing so honestly reminds me of things like CORBA.
Akka is also a Java project, so I wouldn't feel the need to use Scala to use it. For actors, themselves, I think they're most useful for two main things: encapsulating shared mutable state and implementing protocols more complicated than procedure calls. Akka provides a lot of value as a toolkit for designing distributed systems, even if you aren't implementing your own actors. We use Akka Cluster and Distributed Pub/Sub to implement a highly available web socket service, with updates immediately pushed to all connected users. It's pretty trivial with those building blocks. You kind of hook up ActorRefs of largely prebuilt pieces of infrastructure. We also use Akka Persistence, which is fantastic for implementing event sourcing and CQRS.
In my opinion, Akka is most beautiful when used for implementing DDD/CQRS/ES. Read the books by Vaughn Vernon. Life changing. Also, Akka provides very good scalability if you need it - but small web apps (that don't have to scale to millions of users) can benefit immensely from adopting Akka in combination with DDD/CQRS/ES.... 
So I now understand what happened here. When I first installed it, that wizard popped up and had two options: either go through the wizard step by step, or skip and use defaults. The first time I installed I skipped the wizard thinking I'd ad hoc my way through a setup later. When I did a clean reinstall I stepped thorough the wizard and was able to get everything setup correctly. Thanks for all the help!
Thank you so much everyone. I'm not sure *exactly* what the issue was, but I did a full reinstall, did so on a different network, walked through the wizard step-by-step...and it works! You guys are great, and thanks again for taking time to help me with this!
Depends on how RC1 is received, but soon. I would check out the 2.6.x versions of the examples, e.g. https://github.com/playframework/play-scala-rest-api-example/tree/2.6.x
One was posted a week or so ago. Assuming this is the same one, I'd like to see it succeed (and I'm hanging out there and trying to answer questions) but it seems to be pretty dead (last message Apr 25th)?
Very interesting but i can't help feel that implicits will do more evil than good in a large codebase. Is implicits something that is advocated for or against in typical large scale scala projects?
Implicits are a core feature of the language. Without implicits it's not Scala. 
Sure. But that does not mean that it has to be used everywhere all the time. Using implicits is a tradeof between readbillity and convinience and most of the time readability is more important than being able to save a few klicks on the keyboard.
they shouldn't. if you're importing so many implicits you don't know what your code is doing your codebase has more problems than implicits
This is true for implicit conversions, which happen in Java (and several other languages) as well. An example of this is string concatenation with + which implicitly converts a non-string value to a string. `"the number is " + 42 // 42 implicitly converted to String` This use of implicits is generally considered bad practice. Note however that this does not extend to type classes, which are more like proofs for the compiler. Either you have a proof that something belongs to a category, or you don't: there is no implicit conversion going on
Thanks for this post. 
No one says that you have to use them everywhere all the time. As mentioned in this thread implicits are used to encode type classes and I don't consider them to be merely convenient since they greatly affect how software is written in Scala. Martin Odersky gave a talk recently (at ScalaDays I think) where he contrasted the power of an abstraction or language feature with its "discoverability". You can achieve a lot with implicits but you have to make sure that it is still possible to tell what's going on by reading the code. Type classes are IMO quite "discoverable" for how powerful they are. 
Thanks! Though LightBend scala seems to be different than the standard compiler I'm using. I managed to find the advanced compiler options for my scala using the -X flag and found an entry: -Xdev Indicates user is a developer - issue warnings about anything which seems amiss which seems to be what I want. Now I just have to figure out how to get IntelliJ to use it. WartRemover also seems interesting and worth looking more into.
It's still somewhat new, so things are still picking up. Feel free to contribute, even with just a hi!
If you work with Java apis, wrap it in Option (unless you are sure they won't return null), i.e: Option(myJavaApi.someThing)
most scala devs don't use compiler in IntelliJ. I personally use IntelliJ as well, but have sbt running in separate shell, that does incremental compilation as I edit code`sbt ~compile`. Much faster than IntelliJ, which also will break on any non trivial codebase. I also sometimes, when doing TDD, run `~testOnly my.class` in split terminal :) 
When you interface with Java use `Option(javaCall)` and `javaCall(op.orNull)` to deal with nulls, and add `try/catch` or use `Try` to trap any exceptions you care about at the boundary and turn them into `Option` or `Either` or something. Avoid letting Java nonsense leak into your Scala program.
Spark offers async actions which you can leverage to produce to Kafka or perform any other I/O. See: https://github.com/apache/spark/blob/master/core/src/test/scala/org/apache/spark/rdd/AsyncRDDActionsSuite.scala
Well, it's pretty easy, you jus scala.NotImplementedError: an implementation is missing at scala.Predef$.$qmark$qmark$qmark(Predef.scala:230)
If you're a PhD in CS, picking up languages in a day or two should be bread and butter for you üòâ Try it out and see if you find it appealing. A good way is probably to watch a few of Martin Odersky's Scala course lectures and pick up some of the syntax and idioms, get a feel for the language.
Some links which make the above a bit more explicit: * http://jto.github.io/articles/type-all-the-things/ * https://github.com/alexandru/scala-best-practices
If you have any other questions dont hesitate to ask btw., we welcome all new scala-ers :)
Huh? IntelliJ uses SBT for Scala projects. You could use the same exact commands. I use it all the time.
Wartremover won't allow default values for this exact reason. I would highly advise using Wartremover in production to help enforce easily refactored code.
Option#get should not be used as it's partial.
Yes, I know, that's why it's inside a try. It's horrible, lazy, but kinda safe thing to do. 
Indeed, your definition of safety "how to write your code in a way your likely errors can be caught by the compiler" is exactly what I was asking about. In your article you spoke of using case classes instead of enums. One way I could use that to encode what used to be boolean flags. sealed trait MatchCaseFlag case object CaseSensitive extends MatchCaseFlag case object CaseInsensitive extends MatchCaseFlag perhaps a bit overkill, but it prevents me from passing the wrong boolean to functions.
At the most basic level there are two ways of waiting for input data: polling, and hardware interrupts. Polling means running in a loop and asking "have you got it yet?" over and over until the data is available (usually by checking a flag in an IO register). Hardware interrupts means "don't call us, we'll call you": the IO interface signals to the CPU that it should interrupt whatever it is doing and run a specific piece of code instead (that will read the data). I don't know how (or if) this is handled by the JVM or OS. If anyone could shed some light on that it would be great.
That is as simple as it gets, really. You can't simplify it further, because you are doing different things in each case.
Ok, this also helps me a lot. I have another case where I'm doing the same thing (returning Const(0), would it then be possible to simplify it? I'm just think about code duplication for the case where the order in the tuple doesn't matter‚Ä¶
**Practical suggestions:** - If you want to learn functional programming in scala, read the [Red Book](https://www.manning.com/books/functional-programming-in-scala) - If you want to get a feel for purely functional IO, watch [this talk](https://www.infoq.com/presentations/io-functional-side-effects) by Runar **Philosophical explanation:** These days one can find good resources explaining the _what_ of FP, but it's sometimes hard to get the _why_, so let me spend a few words on it: the key concept is *referential transparency*, a property that states that you can replace an expression by its bound value and get the same result. E.g. `x = 1; y = x + 2 ==== y = 1 + 2`. Code that respects this property is said to be _pure_, code that doesn't it's said to have _side effects_. Notice that side effects are defined as "things that break referential transparency", not as "reading from files, having state etc": it's possible to do all these things in pure FP as well! We just have to use different techniques so as to preserve referential transparency (purity). But why is purity important? The main reason is that referentially transparent code is _context insensitive_: it depends solely on its input, and all its effects are described solely by its output. Context insensitivity brings a lot of benefits, including but not limited to: - Reasoning about code: pure code requires only local reasoning, always. - Greater compositionality: the behaviour of a piece of code is the sum of the behaviour of its parts, there are no hidden interactions. - Greater composability and code reuse: it's easier to compose and reuse code _in ways that the original author didn't think of_, because there is no assumption about which context the code needs to be in Hope it helps, feel free to ask more :)
Yeah. I know. They are cool, but I'm talking about async I/O _INSIDE_ the actions. (for example foreachPartition). When I talk about async. I/O, I'm talking about the real old school event driven I/O interfaces that the Linux kernel provides. The great thing about this lib is that has connectors for all the services a backend system will use. So you will end up with a highly parallel,concurrent, nonblocking and functional composable system. 
Well, I have over 14 production applications. A few of them are batch oriented. Most of them are streaming applications that write to MySQL, Redis, HTTP endpoints and a few other stuff. The great thing abut using Finagle is that you only need to learn a single set of libraries that works together. And compose extremely well due to Twitter's Futures. The awesome thing about this stack is that all your input/output will be trully nonblocking I/O down to kqueue/epoll/IOCP (if you run in windows, not sure if the jvm use them) and it will be processed concurrently on thread pools. You also get for free a lot of complex stuff well designed and tested with Twitter's traffic. It's so fast that when you do numbers, you think that something doesn't work but it does. You are going to burn your ethernet cards for sure. I would love to make a blog about this. But I'll be using that time for doing a FOSS project. :) 
Well, pretty much anything is better than Node.js &gt; Node.js is one of the worst things to happen to the software industry in recent times. A whole generation of programmers are being taught the worst of all ways of doing concurrency in a system that doesn't scale either in performance or project size, and with one of the languages most plagued by pitfalls ever created. I know you are joking a little bit here, but I really agree with this.
Awesome
https://www.youtube.com/watch?v=_iRyxHVDdb0
&gt;[**I Swear On Me Mum Tyrone, I Cry Everytime! [0:39]**](http://youtu.be/_iRyxHVDdb0) &gt; [*^Based ^Tyrone*](https://www.youtube.com/channel/UC9Ih7hxN84T2OG449uvW98g) ^in ^Entertainment &gt;*^52,143 ^views ^since ^Aug ^2014* [^bot ^info](/r/youtubefactsbot/wiki/index)
Why would anyone not think this was a joke?
Because it it shiny truth! 15 years in NodeJS is no joke! :) Scala rulez!
Thanks for the explanation!
It's `TraversableOnce.FlattenOps`. Apart from possible constant-time overhead from unnecessary duplicate `hasNext` calls it is as efficient as it gets: def flatten: Iterator[A] = new AbstractIterator[A] { val its = travs.toIterator private var it: Iterator[A] = Iterator.empty def hasNext: Boolean = it.hasNext || its.hasNext &amp;&amp; { it = its.next().toIterator; hasNext } def next(): A = if (hasNext) it.next() else Iterator.empty.next() } 
`-Ypartial-unification` did the trick. Doesn't seem like IntelliJ supports it yet, but everything else works, and I was able to find more information by searching for 'partial unification'. Thanks for the reply.
The big point of actor systems like Erlang and Akka is that they are organised in a hierarchy and parent actors monitor and if necessary restart child actors which crash. Child actors themselves can be written to crash very easily and just throw meaningful exceptions to let their parents know what happened. This gives the whole system a 'self-healing' behaviour. Of course, the implementation is not necessarily as simple as I describe, and you have to study the API and the documentation to learn the idiomatic ways to build the actor hierarchy and monitoring and error recovery strategies. In this philosophy it's of course obvious that you would need to stop actors which are finished: or better yet don't use actors to model tasks which run only for a part of the lifetime of the whole application.
`-Xdev` is intended for developers of the Scala compiler itself ... it's unlikely to be what you want.
This is great that they're making progress on this. Can't wait until it's the standard way of using Akka. Personally, I really enjoyed the old API having a single unified way of creating typed Actors: through the behavior function. With that API, mutability could be implemented using closure. Now there's two ways. But I guess I understand why they went with the whole "mutable class" approach. People are more used to dealing with classes, it is a bit more explicit, and it'll probably encourage people to use the immutable approach. Does anyone have any links to the discussion around the API changes?
Thanks. Just to get a feeling for the amount of work the multiplexing thread has to perform: in general, non-blocking IO is described as a good solution for applications having to deal with a large amount of connections with relatively low traffic per connection (websites, chat applications ...). Does that mean that on the other hand, non-blocking IO is *not* an ideal approach for writing e.g. a file server? I guess the question is whether or not that single thread is able to saturate the outgoing bandwidth, in contrast to the thread per connection model. &gt; Note that you could expose the same Future API and use blocking network I/O instead. That's why I see a Future as something more abstract and higher level than blocking versus non-blocking I/O. This is also my understanding. Unfortunately, the usage of these terms is often ambiguous which doesn't help to identify non-blocking libraries. E.g. the (in fact non-blocking) [AsyncHttpClient](https://github.com/AsyncHttpClient/async-http-client) is just described as *"... allow Java applications to easily execute HTTP requests and asynchronously process the HTTP responses."*. This description is not wrong, but in my opinion it would also fit to a blocking library which is returning futures. The term *non-blocking* is only used once further down in the description, in parentheses, but I think it's the main feature of the whole library.
In general, is it safe to say that every Scala library that claims to be non-blocking is internally relying on Java NIO? Or are there any other approaches that I'm not aware of (apart from performing direct system calls using JNI).
It depends on how many client you going to serve at the same time. Basically here are thread + context switch overhead competing with multiplexing overhead.
It's true. I blindly added a library to my package.json without reading the dependencies first, and now I have brain cancer.
I love how eclipse is pulled up and he's talking shit on node 
I'm writing a white paper thingie about this, but very roughly speaking: * **Asynchronous**: A can happen before B, or B can happen before A. Typically happens when you can put A and B onto different threads and they get executed on different cores. * **Non-blocking**: If B is a blocking operation (i.e. it calls out to disk, network, or just has Thread.sleep), you can tell that operation to execute in a different thread pool, and the thread you're running in currently can keep going. The reason why there's a difference is that it's possible to have synchronous, non-blocking operations. For example, an HTTP request / response cycle is synchronous -- you must receive the entire HTTP request before you send back the response. That doesn't mean the server is blocked while that happens, but A must happen before B in that scenario. In terms of AsyncHttpClient / Play WS, there's an underlying Netty server that handles NettyRequest and NettyResponse. Netty 4.0 uses NIO.2 under the hood, and pretty much everything uses select() and epoll() eventually.
Eww.
It's massively bloated compared to Python as the type system works deeply against code reuse. 8 pages of Scala can be 1 line of Python. Plus the type system is seriously flawed. Where one an represent nulls the other forces you to handle edge cases that cannot occur.
Standard Java non-blocking I/O isn't good for writing a file server for the main reason that Linux has a specialized system call for sending files, called sendfile(). To my knowledge, high-performance servers like nginx and haproxy use sendfile for serving files. See, for instance: * https://t37.net/nginx-optimization-understanding-sendfile-tcp_nodelay-and-tcp_nopush.html * https://www.nginx.com/blog/thread-pools-boost-performance-9x/. If you wanted to, for whatever reason, write a high-performance file server in java, with Linux as your OS, you might look into something like Netty 4 whose epoll transport looks like it uses sendfile for sending DefaultFileRegion objects. I see very little documentation on the subject, though, so likely few if any have done so in production. At the end of the day, chasing high performance can be a bit of a dive down a rabbit hole, unfortunately. If you are trying to choose the best stack for your service from a performance perspective, I would suggest prototyping and benchmarking to see what works best for you, or simply pick an existing java or scala web library or framework.
is it just me, or "-Ywarn-unused:privates" and "-Ywarn-unused:locals" gives false positives when a private primary constructor is used with val definition in it?
A lot of Scala libraries use Netty 4, which on Linux uses it's own jni-based non-blocking IO implementation. It relies on Java nio on other platforms.
This actually inspired me to start learning Scala today.
The web service wasn't mine. I was allowed to make x calls in y minutes. I needed to call it a lot over a long period of time, but break or wait if the number of calls exceeded a certain amount in a specified period. I got blocked many times and had to wait an hour or two before I could try the next library. I tried a half dozen libraries and then gave up. It's on the list to write in something else. I also had normalization problems with mongoDB and it seemed the entire tech stack was working against me at the time.
Detailed explanation: Let's specify context to *non-blocking IO* (unlike non-blocking, asynchronous is more or less agreed on the same idea even without context I guess ?). Let's first discuss Linux network IO (windows works more or less the same). There are 4 common IO models: blocking, non-blocking, multiplexing, asynchronous. For a network IO call, it involves two system object. First is the process/thread calling the IO, second is the kernel. When a network IO call happens, it has *two* stages: 1. waiting for the buffer to be ready (having data to read or having space to write) 2. copying data from kernel/process to process/kernel (read/write) It's important to knowing these two stages because how process/kernel interactive during different stages is what differ these models. blocking: application kernel recvfrom() -------&gt; no data ready | | waiting for data | v data ready copy data | | copy data from kernel to user | return OK v &lt;------- complete for blocking model, the two stages are blocked altogether in a single call non-blocking: application kernel recvfrom() -------&gt; no data return EWOULDBLOCK &lt;------ recvfrom() -------&gt; no data waiting for data return EWOULDBLOCK &lt;------ recvfrom() -------&gt; no data return EWOULDBLOCK &lt;------ recvfrom() -------&gt; data ready | | | copy data from kernel to user | return | OK v &lt;------- complete for non-blocking model, first stage is always returned immediately, but block on second stage. multiplexing: application kernel select() -------&gt; no data ready | | waiting for data | return readable v &lt;------- data ready recvfrom -------&gt; copy data | | copy data from kernel to user | return OK v &lt;------- complete while this looks like blocking model, but the key different here is `select` can wait on *many socket at once*. asynchronous IO: application kernel aio_read() -------&gt; no data ready &lt;-------- | return | waiting for data | v data ready copy data | | copy data from kernel to user | signal signal v handler &lt;------- complete Now, when people talk about *non-blocking IO*, generally they refering to multiplexing model, which allows us handling *higher concurrency* (note that its advantage is *not* about single process speed, actually it may slower for low concurrency comparing to multi-thread + blocking model) due to using less thread and hence less context switch. In java, multiplexing model is exposed as `java.nio.channels.Selector` and `java.nio.channels.SelectableChannel`. As async model, for various reason peopel don't use it much in linux world. While java introduced `AsynchronousCahnnel` in NIO 2, its *nix implementations are emulated async using java threads (on the other hand, windows implementation does using async IO API provided by win32 API). Also, because there is no need to waiting for data in file IO, there is no such thing as non-blocking *file* IO (you can set the flag in linux but it has no effect at all). Note that whether blocking or non-blocking, both are still synchronous call. So when people talk about asynchronous library, generally there are some threads sitting between library call site and IO call. note: as [mercurialmaven pointed out](https://www.reddit.com/r/scala/comments/69loar/meanings_and_levels_of_async_and_nonblocking/dh9kkhc/), since 4.0.16 the popular Netty project has its own jni/epoll-based nonblocking implementation on linux for performance reason.
Try atto: https://github.com/tpolecat/atto It can do exactly what you want to accomplish: Define your own parser for your custom format.
Check out CSV parsers. Many allow you to customize the delimiter. 
Use a regex like so http://stackoverflow.com/questions/18144431/regex-to-split-a-csv 
https://xkcd.com/1171/
Of course, fixed, thanks! :)
ive always been very poor at data structures + algorithms and thats usually where I suffer in my interviews mostly because I hated doing them in java. is there a good data structure + algo book for scala? I am going through functional programming in scala (red book) currently but I meant more towards interviewing and really understanding the algos + data structures. 
I know it seems kind of crummy, but setInterval/setTimeout ain't half bad. You could set up a wait period as a variable, and if the wait period becomes too short, just up the time a bit for the next one.
Nice article ;) Something else that comes into my mind about the final encoding vs Free Monad approach: I think the `final encoding` is also nicer when embedding applicative programs, because you can write your programs in the final style and require only an `Applicative` context bound, such that they can seamlessly embedded in a monadic program but still be executed in an optimized way. Using the Free approach you have to build something like `Free[FreeAp[F, ?], ?]` which is a lot more boilerplate due to all the lifting. Having said that, this is just my gut feeling I never actually tried it ;)
------ PS - Okasaki's book and thesis have the same title. The thesis is freely available but may not be as approachable as the book, depending on your background.
good insight, thanks
Something like this should work..You would just need to extract all matches in the string which should be your data minus the delimeter edit: (?:([\(\[].+?[\)\]])|([^ ]+)) ?
Why one would favour such complex Free structures over simple traits/class implementations? Given repository pattern is very well known among java/scala developers, how many Scala developers and Scala first-steps developers are familiar with Free? How easy is to maintain and debug repository pattern vs Free? Free comes with great cost of complexity and maintenance and I highly discourage using such code in commercial environments. 
Adam, thanks for a really nice summary between the two approaches! That's really helpful. Some parts of this article contradicts my understanding of the topic, could you please elaborate on these points: &gt; Hence, these are different encodings of the same general idea. (If you are into category theory, **both are initial in that sense**) I might be wrong, but my understanding is the a Free Monad is an Initial approach encoded via ADT + Pat.Mat interpreters (that's what an initial approach is, isn't it?). And the word **Final** is in the name of the approach. Another thing that i'm not sure about is that it's correct to refer to the Final-Tagless approach as simply "tagless". In most cases Free Monad is also tagless (initial-tagless ??) cause we use GATD to define the program's algebra. The typer handles pattern matches GATD differently from ADT's, we are not using wrapper types to satisfy the compiler, no runtime tag type exist and hence the approach is tagless. Would be glad to be wrong about this and if someone can adjust my understanding.
Free is far more useful to library authors I think. Stuff like slick and Doobie make really good use of it
If you can live with traditional app then the easiest choice for web app is play framework. If you want scalajs-base SPA then this is your friend: https://github.com/ochrons/scalajs-spa-tutorial. When it comes to mobile development there is http://scala-android.org/ but I haven't used it and it supports only android. You can try runinng ionic with scalajs but the ionic2 with angulate2 is probably less than experimental(I'm not sure if anyone has managed to do that) so you will have to stick with 1st version of angular.
&gt; If you can imagine that as soon as you start using a dependency injection framework like Guice you end up adding Boilerplate that you wouldn't need in a language like Python. Don't do that then. You can use `object`s exactly like how you'd use modules in Python. (And FTR Guice doesn't require any boilerplate as far as I know). &gt; Then you have to write case classes for working with json libraries that again, in Python you wouldn't need. In Python you'd get a Map you can just probe. You can work with untyped json as a map if you want to - e.g. spray-json `JsObject` contains a `fields` map full of `JsValue`s that you can access directly. Most people find it worthwhile to create named types instead, but you don't have to. Better is to work with the type system and use a typed interface (e.g. thrift) rather than JSON. &gt; Then there's having to write case statements to handle Optional on things that can't fail. If it really couldn't fail there would be no need to make it optional. &gt; Such as marrying user input to a case object you may have to do this: No you don't, you just do: DayOfWeek.valueOf("Wednesday") 
Why though? We have higher order functions
As stated above, just use the built-in Netty web server. This can be done by simply calling the dist task. Now all you need to do is run that artifact. We also put nginx on the Node at my job, so that we can handle SSL termination and virtual hosts easily. Frankly, I find deploying Play applications much easier than older Apache and Tomcat applications.
You could also just use an abstract class. Provides the same ability to override just the methods you need.
**Here's a sneak peek of [/r/nodejs](https://np.reddit.com/r/nodejs) using the [top posts](https://np.reddit.com/r/nodejs/top/?sort=top&amp;t=year) of the year!** \#1: [Node.JS template engines benchmark](https://github.com/Deathspike/template-benchmark) | [1 comment](https://np.reddit.com/r/nodejs/comments/2c6qt6/nodejs_template_engines_benchmark/) \#2: [It clarified and confirmed what I had written for a recent system was essentially of the correct form (phew), and provided a better understanding of the difference between this.push(message) and processed callback. And of course, it was definitely fun to read :)](http://howtonode.org/coding-challenges-with-streams) | [0 comments](https://np.reddit.com/r/nodejs/comments/2c95z6/it_clarified_and_confirmed_what_i_had_written_for/) \#3: [Use of cluster in Nodejs](http://www.codingdefined.com/2014/07/use-of-cluster-in-nodejs.html) | [0 comments](https://np.reddit.com/r/nodejs/comments/2c7x69/use_of_cluster_in_nodejs/) ---- ^^I'm ^^a ^^bot, ^^beep ^^boop ^^| ^^Downvote ^^to ^^remove ^^| [^^Contact ^^me](https://www.reddit.com/message/compose/?to=sneakpeekbot) ^^| [^^Info](https://np.reddit.com/r/sneakpeekbot/) ^^| [^^Opt-out](https://np.reddit.com/r/sneakpeekbot/comments/5lveo6/blacklist/)
I have a repo of basic algorithms here: https://github.com/pathikrit/scalgos It uses plain Scala, no dependencies, is more or less idiomatic Scala and has lots of tests.
That's you, the legendary tpolecat?
Why not? (Seq(s.last) ++ s ++ Seq(s.head)).sliding(3, 1)
Okay. Can you give me a motivating example of where I might use this?
Data structures and algorithms are pretty language-independent. I learnt mine mostly from the author of *ML for the Working Programmer*. Not quite what you asked for but if you want a clean break from Java then anything ML-oriented should translate pretty directly into functional-style Scala.
You probably need a type parameter to represent the element type rather than using `_` (so that `col.last` can have a type). Then look at what `CanBuildFrom` is needed for the method you're calling. Bear in mind that all this stuff is horribly overengineered, not all that useful, and probably going away in Scala 3. You might be better off writing in terms of a more specific collection or a typeclass from scalaz/cats rather than trying to work with `CanBuildFrom`.
Free really isn't complex, just badly named. Java/Scala developers know the command pattern and its advantages, Free is just a generic command that takes some of the boilerplate out of implementing commands directly. I've actually called my current implementation "CommandChain" because that seems to provide a much more useful intuition than "Free".
You could try Iterator.continually(Range(0,5)).flatten.sliding(3)
&gt; Execution tracing is another effect that the interpreter can implement. Reinventing the wheel effect. Non-Free code has executing tracing (i.e stack traces) feature for Free.
I don't think it would honestly take me longer than other libraries. Free isn't really hard at a conceptual level, once you get the basics down, it's just that encoding in scala is really painful
Just because you don't understand something it doesn't mean it is not valuable. The point is this stuff is hard and you need to put effort to learn it. Functional programming is hard!
This gives me exactly what I want in a much simpler way. Thank you. I think I got caught up in trying to build the elements of the iterator instead of just prefixing and postfixing the elements I want to loop around.
Any link to these cluster stability issues? I'd be interested to hear more about this.
you best bet is scala + scalajs + react (+ react-native) -&gt; that allows to develop apps for web,android and ios (that is at the same time (correct me if i'm wrong) the only practically feasible way to develop really cross-platform) here scalajs-react getting-started: https://github.com/japgolly/scalajs-react/blob/master/doc/USAGE.md the scalajs-spa-tutorial link by @Krever may be a good way to start as well
I just checked it out, and it looks really great! Thanks for sharing.
Appreciate your interest! So imagine you have some client interface: trait Client { def start(): Unit def stop(): Unit def doSmth1(): Unit def doSmth2(): Unit .... } And the appropriate implementation that implements all of these methods: class ClientImpl extends Client { .... } You have an instance of the ClientImpl that of course possess some state: val client = new ClientImpl Now you want to decorate a behaviour of the *client* instance but you're interested in *start()* method only. You want to left the rest of the logic intact. So you implement the *Client* interface: class MyDecorator(original: Client) extends Client { def start(): Unit = { // Your logic original.start() } def stop(): Unit = original.stop() def doSmth1(): Unit = original.doSmth1() def doSmth2(): Unit = original.doSmth2() .... } So there is a lot of boilerplate code. With Metarator you can avoid this: class MyDecorator(original: Client) extends Client.Decorator(original) { def start(): Unit = { // Your logic original.start() } } The remaining methods will be generated automatically and proxy invocations to the decorated instance. As a result you redefine only those methods you actually want to redefine. Code looks nicer and cleaner. Does it make sense?
I use the play framework. I was trying to think of a simple example and just happened to see this one in the play framework google group: https://github.com/mfirry/web-frameworks-templates/tree/master/play It has the minimum number of files to get up and running (just look at the play directory). I would just just run it, tweak it and play with it. The two main files: Controller: https://github.com/mfirry/web-frameworks-templates/blob/master/play/src/main/scala/Application.scala Routes: https://github.com/mfirry/web-frameworks-templates/blob/master/play/src/main/resources/routes 
So I originally started learning scala because of spark, for the purposes of big data processing and using MLlib in spark to build machine learning applications. The intention for asking the question was to build on from here and to add to my Scala toolkit, so I thought restful web services would be important do build large scale systems. I haven't had much experience in RESTful , as back in my CS undergraduate we did SOAP in java. Thanks for your comment though, I shall look into akka-http as I'm looking to learn kafka also.
I see warnings when nothing uses the private constructor or val, but not otherwise. Can you show code?
From what I've seen of the straw-man, scala collections are largely going to be the same, AFAICT. How are they going to make CBF go away?
There is [Scalacaster project](https://github.com/vkostyukov/scalacaster) I started trying to prepare for some Scala interview. I got the job and (of course) nobody asked me to write a purely functional implementation of a RB tree. Yet people seemed to enjoy reading through Scalacaster's sources.
No, it should not.
...and wait like 4-5 seconds for startup and between *every* command. 
Are you using a thinkpad X40 by any chance? Because on my 6 year old laptop it takes about as much time as i lift my finger from the enter key, only the first command takes a few seconds.
Probably by doing something like this http://stackoverflow.com/questions/7615318/how-to-make-sbt-console-use-yrepl-sync gonna give it a test nowish
I can't imagine this is useful, you say legacy code or java interfaces, but in your example on github, you need to annotate the base interface, which is most certainly not possible with java interfaces and often with legacy code either. I always hated this monkey patching that's called 'decorators' in some languages they might be necessary, but in scala, they are completely unnecessary. Changing an object's behaviour without explicit notion of it is dangerous. Why not just extend the class with and implicit and call that method when you actually want the `decorated` value? And above all that the decorated value does not have the same type anymore, and by looking at the macros, it looks like it would fail with generics, and would run the constructor of the trait again upon decoration, which is most should not be done by a decorator. (i might be wrong, i'm not intimately familiar with scala.meta, only with the legacy macros.)
As of Scala 2.12.2 (via https://github.com/scala/scala/pull/5663) this is enabled by default when on non-Windows systems and in interactive mode (ie. stdin and stdout are attached).
Cats implements most of the same stuff as ScalaZ. I would look at matryoshka - that seems to be the popular implementation of fancy recursion-oriented stuff, and offers `ana` and various variations.
&gt; Is a macro the right approach for this? Maybe. I would try to find a way to express what I wanted in plain Scala if at all possible. E.g. maybe using a Shapeless `HMap` or record to represent a collection of labelled `Vector[Function1[A, Unit]]`s and have a single "register hook" function and a single "call hook" function. I don't now your use case though. &gt; Am I wasting my time with @inline? If you're asking the question then yes. I would never bother adding `@inline` before having the metrics in place that would tell me for sure whether it was helping or not. &gt; Is there an extra runtime cost to overloading thingHappenedHook(fn), (o), as opposed to having different function names? No, right, because that's resolved at compile time? Indeed. &gt; Is there a difference between (Thing) =&gt; Unit vs. Function1[Thing, Unit]? No, the former is just an alias for the latter AIUI.
[Sort of](https://github.com/scala/collection-strawman/blob/master/src/main/scala/strawman/collection/Iterable.scala). Map is map for an iterable view of a collection, from the small amount I have read. Everything is based off of an Iterable trait object, and when you map you convert your collection to this Iterable object, then it converts back when it is done (sort of, there's an embedded coll member that is the original collection type). It could be a lot simpler -- Spiewak had a straw man setting up functor / applicative / foldable / traverse / flatmap and having the immutables implement them. I don't see why you couldn't do the same thing on the mutable side, but lift the typeclass interfaces to Mappable/Purable/etc., removing the guarantees implied by the lawful typeclass names, but implement them with mutable builders or something. That way they keep the interface, but lose the extra semantics. Using them should be largely the same as today, except with typeclasses it would become more common to see abstraction over the collection type as an idiom in scala.
Do they? Because the ones I'm looking at play and akka-http are pretty slow compared to other scala libraries and even slower compared to some other languages 
I have to learn Akka for a project and I don't have any Java or Scala experience! Can someone point out what Akka is used for broadly and how much Scala should I learn to even start understanding Akka tutorials ? (Frankly all Akka tutorials are going over my head) Background : I am a first-year undergrad student and have some experience with C and Haskell. 
Really? It seems they are on par with various Ruby frameworks and Ruby language is notorious for being slow.
Im using ammonite often on macbook, and it's very fast, no complains. Besides first command, that always takes 5 seconds.
this is very interesting. thanks!!
Thanks /u/jroper . I saw those benchmarks and "returned error" is a clear sign of a benchmarker that can't be bothered to collect real data and should have fixed their own setup before publishing results. It's just benchmark porn, and we should treat it as such. That said, I can't totally agree with the way you're talking about prune. I've implemented several projects at almost as many companies (since play 2.0). I've read the docs cover to cover through those versions and read the project pulse tab on github daily and never once seen a reference to the benchmark results. I'm glad they're catching performance regressions before they make it into the wild, but they might as well be a private repo the way they're being used. See this year-old issue claiming that prune doesn't work with any 2.5.X release as supporting evidence: https://github.com/playframework/prune/issues/1 PS: thanks for all you've done to contribute to the framework, and as a result, my career.
Colossus is doing well in Best plain text responses which "may" be the more relevant benchmark (comparing the cost of the framework and not DB access or Json lib). https://www.techempower.com/benchmarks/#section=data-r14&amp;hw=ph&amp;test=plaintext
Magic. Works like a charm. Thank you :-)
What is the best way to learn scala, being experienced in java?
&gt; E.g. maybe using a Shapeless HMap or record to represent a collection of labelled Vector[Function1[A, Unit]]s and have a single "register hook" function and a single "call hook" function. I don't now your use case though. Could you show me a code sample? Normally I'd try something like `trait Hook[T]`, but as you know, problem is I'd like an object to have N of these, and for each hook to be statically named. 
http://underscore.io/training/ has some good books.
I was just trying out Finch for the first time, and read about the performance on the GiHub page and [this blog](http://vkostyukov.net/posts/how-fast-is-finch/), but it seems to have performed pretty badly this time (relatively speaking). The wild variations between benchmarks seem questionable, but I guess a lot can change in six months.
Idk if there's a best way, this is subjective. Also depending on what you want to optimise for. Probably all the better sources are listed in the sidebar. The coursera coursers are good if you like mooc's. You could also do a side project with a framework which you want to learn.(eg make a web api with http4s and you'll get familiar with monads.) Codingame (or any similar alternative) is good for getting familiar with the syntax and some useful built in functions. I don't overly like learning languages from books but I guess somebody prefers that. I also liked scalakata when I started out. It was convenient for trying things. (Since then there's an alternative provided by scalacenter , can't recall the name though ) 
I had a mixed cats/scalaz codebase but when http4s and doobie announced that they would be moving to cats I bit the bullet and migrated everything to fs2/cats. The hardest part of the migration was http4s-rho and that required a custom port from scalaz to cats (and was NOT a whole lot of fun). Scalaz is an awesome library but fs2/cats just seem cleaner to me. I realize that is purely subjective. :-) 
Akka is many things. I think the three biggest categories are actors, streams and akka-http. I assume you are not interested in akka-http now. The basic building modules of all of these are actors. Akka actors are the scala implementation of the actor model. The basic idea is to provide a thread safe concurrency model, to achieve this one actor instance is always single threaded. An actor's only input is its message queue. Those are the two most important features of actors. The two cool things which akka provides for actors is resilience, through the actor hierarchy and error propagation, and distribution (you can use multiple machines for one actor based program, relatively easily). I'll write what actors should be used for which is based on my limited experience and on the book functional and reactive domain modeling. Actors could be used for almost anything theoretically. They are relatively cheap(memory wise), thread safe building blocks. However you shouldn't use them generally, because they have some problems if you want to use them in a functional environment. In most cases you should use futures, except for guarding shared mutable state and building fault tolerance. Streams are a higher level abstraction on top of actors. They fix one shortcoming of actors, because they are type safe (this difference will go away in the near future as typed actors are being introduced)(currently if you send random messages which won't be handled the compiler won't tell you) According to my knowledge the main take away here is that you use streams if you need back-pressure. When your data needs to be processed in smaller portions so you don't overwhelm your processing resources. Akka-http is built on top of streams. Otherwise it's pretty straightforward what it's for. As for what to learn in order to be able to work with actors. I think if you have a basic grasp on the language that should be enough to start. I can refer to my previous [comment](https://www.reddit.com/r/scala/comments/68ll5m/fortnightly_scala_ask_anything_and_discussion/dhh0ymy) today 
I'm truly sorry you had that experience /u/jroper I think it's important to understand that the TechEmpower Framework Benchmarks are an open source project and we rely heavily on contributors like you to spot issues like this. The team isn't very large, and often we have to tend to other projects. Admittedly, in the past, we have not always done a great job communicating when we couldn't give 100% attention to the project. In recent months we've made big changes to the toolset, including monitoring processes that may cause problems for other tests. We've introduced continuous benchmarking to quickly identify issues and work with core contributors to solve them as quickly as possible. To your point /u/haimez it is not as easy as it sounds to maintain a fully functional benchmark of 100's of frameworks in 26 languages. Imagine the configuration problems you have working with just 1? Sometimes, it can be a nightmare. Yet, we still try and find a way so that anyone can come around, spin up a vagrant box, and run any one of these tests to improve them. It's also important to note, and we try to make this clear, these benchmarks are about improving performance among like-frameworks. It's meant for people to look at how their framework performs versus others in the area, and what those frameworks might be doing differently. With all that said, and continuous benchmarking in place, we will already have logs and preview data for Round 15 starting next week. I'd personally love to get you back on board and see what we can do to get a realistic representation of your framework (or remove it entirely if you wish.) Take care!
Who the fuck cares? Java can't catch up to where Scala was when it started, let alone keep up with where it's going now. It's an abomination and it deserves to die. Let it die.
&gt; The need for method injection would be moot if Scala was image based rather than file based. Creating wrapper classes is just a half baked solution to not being able to modify any classes but your own. What exactly do you mean by "image based rather than file based"?
Without default constructors/destructors and ADTs what's the point of pattern matching?
What's the best resource to learn web programming with Play! ?
Thanks kindly.
Thanks for responding. No need to apologise to me. I appreciate having the option to try out Finch in the first place, and from the post above it would seem like there are plenty of reasons to be skeptical about these benchmarks in the first place.
Scala nlp's chalk library is retired with no further development plan. Deep learning is for further nlp tasks down the pipe line and it has not yet evolved as mainstream/industrial grade nlp. In short there is no Scala based nlp library. My suggestion 1) Emory NLP is probably what you want. Much better than open nlp 2) Apache spark has basic NLP operations such tokenization, ngrams in it's ML pipeline There is no full fledged NLP library‚Äã such as Spacy for the JVM. Would be awesome if someone starts such a project‚Äã. I'll be happy to pitch in.
&gt; [Uniform function call syntax](https://en.wikipedia.org/wiki/Uniform_Function_Call_Syntax) would be better. Not really. You can still end up with methods being defined wherever you want rather than a single place that's shared by everything in the image. Enforcing that is more a feature of the IDE than it is of the image, but it is enabled by the image. Separation of classes you define from those you import is just dumb. It's as dumb as Java's separation of primitive types, and in practice, more frustrating. If I want to add a method to any class in the standard library, then it should be through the exact same mechanism I add a method to any class I've defined. Using images makes this easy.
Is it really that hard to Google? [Image-based](https://en.m.wikipedia.org/wiki/Smalltalk#Image-based_persistence) means that you develop in the runtime environment of the language and can modify any class in it, obviating the need for method injection. It provides a whole bunch of other neat things like transparent persistence and an object database, since the image itself is a container of objects. This includes classes and instances since in pure OO languages, classes are objects too.
&gt;It has little active development and few active contributors. I'm still a bit in shock you went from being a supporter/maintainer of the project to jumping on the 'spread FUD' bandwagon, how can you say it has 'little active development'? https://github.com/scalaz/scalaz/commits/series/7.3.x I'd say it's fairly active, and if you consider the experiments happening in forks I'd say it's definitely 'active'. &gt;Others have not made public statements to this effect but are soon to follow Yeah, and I've been private messaged by multiple big contributors of these projects saying more or less while they want to support both, they are not happy with Typelevel and are hoping Scalaz ends up the being the dominant FP library. So we both have anecdotes... I just think that we should be up front and honest rather than biased in comparing the two libraries, and it's hard to read your reply as anything but biased.
First of all, I'll say either library is better than none. That being said, there are good reasons to pick Cats and good reasons to pick Scalaz. I personally think Cats will encounter more growing pains and don't agree with some of the technical decisions it's making, but its documentation is much better and there are more easy to find learning materials. If you're onboarding a bunch of developerss who don't have any functional programming experience, and don't have the resources to train them, this could be a big help. If you (or the team) want to hack on doobie/http4s (not just use, but modify/contribute), it seems it'd make more sense to just use Cats, since they use (or will use?) Cats internally. However if you're just using the libraries, then I think this is a moot point, better to let other things influence the decision. Scalaz is a more comprehensive (monolithic) library, where as Cats went the modular route, so things just 'gel' a bit more in Scalaz imho. It's also more mature, so I believe you're less likely to run into bugs or design issues. The ecosystem is bigger for Scalaz, so more companies are using it and so developer familiarity with Scalaz will be higher. 
&gt; And you suck at Google. Oh yes, because google would have thrown your nonsense on me if I'd have searched for "image classes" or "class images".
&gt; Image-based means that you develop in the runtime environment of the language and can modify any class in it, obviating the need for method injection. That sounds even worse than implicit classes. &gt; It provides a whole bunch of other neat things like transparent persistence and an object database, since the image itself is a container of objects. This includes classes and instances since in pure OO languages, classes are objects too. 1. Classes aren't objects. An objects is an instance of a class. A class is a behavioural and stateful type descriptor. 2. Why the heck would we need such an "object database"? If you want to load a bunch of classes - load the jar. If you want to "load" data - use redis.
Here's the Play REST API and database backend with Flyways. Slick manages its own threads for database connections, so you only need to manage the job queue. * https://github.com/playframework/play-scala-rest-api-example * https://github.com/playframework/play-scala-isolated-slick-example
Scala runs on java, so you can use [Stanford Core NLP](https://stanfordnlp.github.io/CoreNLP/) and convert its outputs to Scala case classes or objects or whatever. It's a bit confusing to start with, unfortunately, but once you have converted a few things into actual Scala it is good. 
1 - I use scalikejdbc, it is fine. I like control of the sql. Need to wrap calls in Future which is not ideal. That said, I am looking to use doobie instead. 2 - I use akka-http, but plan on evaluating http4s myself. 3 - I use flyway migrations for altering the database. 4 - I do not use any codegen tools. I've been coding for a long time, and those have never ended well. 5 - With scalikejdbc, you can return the auto increment iirc ------- akka-http is ok, if you use the DSL, things are strange. This is one of the reasons I am looking at http4s. Also circe makes json so much easier than what I have had to do with json4s. slick is rather big, it is a framework. I used scalikejdbc because it fit my code style (better java) at the time better than doobie. That said, I have steadily introduced a more functional style into my code, so I will be changing to doobie shortly. 
Here is what I would have used if I was in your shoes. 1. Database: Quill. This library requires no boiler plate code AND you don't have to write RAW SQL in your code. this is best of all the world. This library is jus superb. its a joy to use. 2. REST API: I would go with Finatra. While there are 100s of options here. Finatra is unique because of "feature testing" which makes writing unit tests very very easy. in other frameworks, writing unit tests, integration tests and end-to-end tests is pretty painful. Finatra makes this easy. I don't know about others. But the biggest problem with my code has been lack of adequate testing. So anything which motivates and helps me test more is welcome. Finatra does that. Its from Twitter so you can expect great performance. 3. JS FrontEnd: Use ScalaJS. (or atleast try to use scalajs). 4. Migration Tool: Use Liquibase. Flyway is good if only a single developer works on the code. If you have multiple developers or if you have multiple teams, then flyway is a nightmare. (just search reddit for related discussions). Use liquibase 
We actually used Http4s and Slick for our last project (also my first encounter with these libraries). We didn't have bigger problems with Slick, however at this point I'm not entirely convinced about the advantages of Slick's Scala-like interface. Sometimes it was nice for composing complex where clauses (eg: dynamically add AND's), but I still think in terms of SQL when I write those lines, so I'm not sure if it's worth the additional layer and complexity. Now that I skimmed through the docs of Doobie I see that Fragments should be able to do this in a similar way, you don't have to do string concatenation as I initially thought based only on the github README. &gt; It integrates nicely with http4s: Tell Doobie you want to use Task and it will give you Task That's nice, one of the minor inconveniences with Slick was that it returned Future and Http4s wants Task. Even if it's just one function call to transform them it's nicer if Doobie can give a Task right away. Slick seems to be used more at companies though (with all the other lightbend frameworks). So that's one point to Slick. 
I think this article may help: [https://blog.stephencleary.com/2013/11/there-is-no-thread.html](https://blog.stephencleary.com/2013/11/there-is-no-thread.html) (it talks about how async works in .NET, but it should be applicable to other languages too)
I learned from [Programming in Scala](https://www.amazon.com/Programming-Scala-Updated-2-12/dp/0981531687) and [Akka in Action](https://www.amazon.com/Akka-Action-Raymond-Roestenburg/dp/1617291013). They're not really tutorials, but they explain a lot of the rationale.
http://www.artima.com/scalazine/articles/selfless_trait_pattern.html
Don't get me wrong, I think it's the future of data processing. Why have delays in data when it can be available in real time? But I'm not convinced of the *business need* of stream processing for a large majority of data processing.
The most idiomatic way is to use futures, since they are a first-class citizen in Akka HTTP. Futures are used in directives, marshallers, making connections, etc. Answer #2 on that SO thread and the blog post that it links to gives pretty good reasons to prefer futures over actors. In addition, most libraries that deal with external services (e.g. database, REST APIs, or caching) use futures. In my experience, a service should be written as a class or object whose methods return futures. If you plan on using actors anywhere (e.g. shared mutable state), you can wrap your actor-based APIs with futures in your service. I've found [this](https://github.com/ArchDev/akka-http-rest) to be a pretty good example of how you can define your services.
You can simplify `Const(v) if v == 0` to `Const(0)`.
It's not the selfless trait pattern because it doesn't have an object, and this is not a library
I cannot see how such thing would help in tests
Does it work with Scala.js?
I did not try to be honest but it should work ! 
Thanks I will take a look ! 
Cats has better notation for numerical computation: along with its companion libraries, there are separate typeclasses for groups, additive groups and multiplicative groups, while scalaz does not address numerics. Actually, the submodule `cats-kernel` supports the `typelevel/algebra` library, which in turn provides interoperability for the numerical libraries `spire` (typelevel) and `algebird` (twitter). 
Why not just write the case class without the trait though? 
I've been to https://www.meetup.com/amsterdam-scala/ before, it's a nice little group. I'm guessing you'll be able to find a similar group for Berlin.
It might be an attempt to keep binary compatibility under control. Case classes get a number of convenient methods by default, so you'd want to keep them part of the implementation, but expose only the interface to users. One can add another field later and clients continue to work (as long as they don't implement the interface, of course) by using only the getters they know about. Other than that I agree with you that it's useless.
If you mean "instead of matching `I[_]`", then standard Scala already does. You just need to write the type variable in lower-case: `case i: I[a]`.
I saw that! It doesn't seem like they have a meetup during the time frame I'll be there. 
You could offer to present your company / project in those meetups. If you should also happen to stop by in Hamburg, and would like to present, let me know, we'll try to find a host and put it on https://www.meetup.com/de-DE/Scala-Hamburg/
~4/5 days either before or after June 21st-23rd, dates are still flexible. As another commenter suggested, I'd be happy to present about our company and the work we're doing. 
Two Questions 1- I'm quickly finding that there are a fair number of implicits in our codebase. For things like slick mappers to json encoders/decoders, the occasional Show instance etc. How do people organize their implicits? Is just a big single object common or do people keep the implicits next to the case classes themselves? 2- I'm using slick for relational queries, and it's quite nice for a lot of things, but it seems quite painful for relationships. Is there any ORM for scala that has a similar level of reactive pleasantness as slick but also has something resembling a "has_one"/"has_many" type relationship querying? Maybe the one thing I miss from rails is ActiveRecord. 
&gt; I cannot see how such thing would help in tests It all depends on how the actual code works, but if the rest of the app is written in terms of `Person`, you could have mock `Person` subclasses, which have all sorts of uses. If `Person`/`PersonImpl` is just a container for data, then yeah, the trait doesn't provide much, except perhaps some binary compatibility help.
you don't have any type information inside the string stuff do you? So if anything there changes (let's say rename 1 column), you will have to go through your project and manually change it. I don't say this must be a major problem, but it can be a problem (specially in not so simple examples) and is a difference between slick / doobie in slick you have auto-complete / full type information inside the queries itself, doobie only does that on compiletime (please correct me if I'm wrong!)
We evaluated Stanford, but we found the licensing a turn off. We wanted to customize a small subset of the library but the licensing prevented us from doing so.
Seriously? That's the most ridiculous syntax ever but incredibly useful, thanks. 
We're called Apollo Agriculture. We're a pretty young company, we just finished making our first season of agricultural loans. (I didn't post initially because I don't want this to seem like a self promotion/hiring post. I really just want to meet some Scala folks.)
My company has like 15 Scala devs and we do Scala consulting in Amsterdam and other big Dutch cities. If you want I could give you contact information of my manager or one of our devs in the area. I'm sure someone would love to talk to you.
As I see it, you can create mocks also when the trait is used like a plain old interface (like Java's pre-8 interfaces). It would work both when handcrafting a mock and using a mock framework (like Mockito). The implementation being within the trait might help if we only want to mock subset of the trait's original methods, that I'll credit to it.
Well imagine they also want to extend `Person` in other cases too, not just in the `case class PersonImpl`, then it would be handy to have those methods defined in the `Person` trait right?
&gt; See this year-old issue claiming that prune doesn't work with any 2.5.X release Play dev here. Prune is really designed to help the developers keep an eye on Play's performance on the branches that are being actively maintained and changed, so we can track Play's performance when we make the changes. Prune is not really designed to be a full comparison of every version of Play, and it would be a lot of work to make it do that.
Oh that's too bad. It really depends what you're using it for, I suppose. 
Someone already posted it before?
I'll remove it
I know, it's awful syntax in that context too. 
But if you then call another method, which also takes an implicit `Caller`, it'll get *your* implicit `Caller`, rather than getting the correct one.
It depends on `Caller` macro implementation.
No it doesn't. The macro won't even be invoked, because there is already an implicit `Caller` instance in scope.
Where is the source code please?
That's the expected behavior when creating a DSL. As a DSL designer, you may want to always trace the outermost caller from DSL user, in order to help DSL user debug the user's code.
The ScalaCenter is organizing a [Scala Open Source Spree](https://github.com/scalacenter/sprees#open-source-spree). It's the 31 st May right before the conference (10am to 4pm). It's a good place to land your first open source pull request! Trifork is offering the food. We are giving away awesome TShirts to whom get a PR merged.
shameless plug. Precepte has something similar https://github.com/MfgLabs/precepte/blob/master/precepte-core/src/main/scala/default/macros.scala#L37
Wow, that's a door slam that wants to be loud. Some interesting (and balanced) content seems to be on the roadmap. It was submitted by simon on /r/programming already, even if the website is quite incomplete. https://www.reddit.com/r/programming/comments/6bh8xv/leaving_scala_after_six_years_of_development/ The currently available content is quite FUDdy (esp. regarding copyright issues), and should be addressed.
Sorry to see you go /u/simon_o , I really appreciated your effort to improving the state of www.scala-lang.org as well as www.scala-android.org
Interesting. For anyone who hasn't used Circe yet it really is the best Jason library by far. It's almost completely transparent. Just import a few things and bam, any case class has a .asJson method or can be decoded with the decode function. A million times easier than play jsons macros scattered everywhere.
Your article is a bit, er, vague. What pressing issues? What barrage of low-quality language extensions? What decline in language evolution, keeping in mind 2.13 (collections) and 2.14 (dotty)? What lack of communication? What organizational issues? What past mistakes?
You now need to write `case eq(None)` to match `None`, `case eq(Nil)` etc. and writing `case None` would still compile but mean entirely the wrong thing (you'll get an unused variable warning if you have those on, but I think few people do). 
That's just about the only open source Scala project I think I *could* contribute to. :D 
Interesting... is there a reasoning using union types as presented as a solution was not chosen? Is it because of backwards compatibility concerns, or implementation difficulties?
One approach is to to pass a memo around using the `State` monad and build it up as you go. I had enough time to write this but not to write comments, sorry. I'll try to edit it in a bit. import scalaz._, Scalaz._ type Memo = Map[(Int, Int), Long] type MemoState[A] = State[Memo, A] def lookup(r: Int, c: Int): MemoState[Option[Long]] = gets(_.get((r, c))) def store(r: Int, c: Int, a: Long): MemoState[Unit] = modify(_ + ((r, c) -&gt; a)) def table(r: Int, c: Int): MemoState[Long] = if (r &lt;= 0 || c &lt;= 0) 1L.point[MemoState] else lookup(r, c).flatMap { case Some(a) =&gt; a.point[MemoState] case None =&gt; for { a &lt;- table(r - 1, c) b &lt;- table(r, c - 1) _ &lt;- store(r, c, a + b) } yield a + b } scala&gt; table(20,20).eval(Map.empty) res1: scalaz.Id.Id[Long] = 137846528820 
&gt; 1) What makes one a good enough Scala developer/ Engineer to enter industry ? After learning core scala, what should one focus on next ? The ability to solve new problems. It's probably worth learning some generally-applicable libraries (shapeless and cats/scalaz come to mind) but the main thing is to be able to write programs to solve problems. Try writing some programs you'll use yourself. &gt; 2) Is it still a plus or a must to be from a Java background as most industry jobs tend to be around old Java systems being redeveloped into Scala, Akka etc ? If I know core Java from a while back , what should i focus on in the java space ? Spring ? EE ? Having a working knowledge of Java is probably good enough. Don't bother learning frameworks. &gt; 3) For learning pure FP is it better to learn Haskell before the red book in Scala ? No. &gt; 4) How is Scala used currently in the Finance industry ? I don't think I'm allowed to comment beyond "extensively".
Traditional services as far as possible. Anything you can do without actors, do without actors (IME this should probably be everything). In the cases where you do need actors, use them, and in that case calling `ask` directly in the routing is probably better than adding an extra layer of indirection.
Introduce a Scala class at top level (i.e. have Scala call Java, don't have Java call Scala) in a real project. Use it a little bit at a time. Don't try to jump straight into fancy libraries. At least, that's what worked for me.
Hi, I'm an engineer with the Dotty team. Union and intersection types are complicated beasts. Initially we did not let unions propagate via inference, because it tremendously slowed down the compilation. But we have since relaxed this constraint for if, match and try as you describe. When it comes to numeric widening, we have not yet taken a stance and are currently doing "what scalac" is doing, this is not something that's set in stone and I've opened an issue to track this here: https://github.com/lampepfl/dotty/issues/2451 We're also considering how to properly limit implicit conversions, and there's been discussion on our issue tracker with regards to this. In the Dotty project we make an effort to have open discussions surrounding language features and implementation details. That being said, we're a small team of research students and one engineer (me). Community contributions in these areas are super welcome and we'd love to help you or anyone else out on getting started. Please visit our gitter channel or ping us on Github. Cheers, Felix
If you're more broadly interested in purely functional dynamic programming, and you know Haskell, check out the [Lazy Dynamic Programming](http://jelv.is/blog/Lazy-Dynamic-Programming/) blogpost. It requires Haskell because it relies on laziness so it might be useless for you, but I thought I'd throw it out there anyway 
Oh my. I never once considered using a pattern match instead of the flatMap on Either's left. Yeah this doesn't look half bad. Thanks for noticing it! Problem with using `Left(x(s))` for me is that I want to pass different `String` parameters based on whether I'm folding `Here`s or `There`s so I can't pass `s` in `doHeres` because `There`'s function needs to receive a potentially different parameter.
That totally depends on you. there is no universal rule. Experiment and find out what works for you. don't look for cookie cutter simple answers because there aren't any. 
What does that even mean..
Haskell is a better language to learn typed FP because it's much simpler. After that it's straightforward to pick up Scala (which is a hybrid language) by analogy with both Haskell and Java. What's marketable is your understanding of computation and interest in learning. There are probably more Scala jobs out there than Haskell jobs but both are becoming more popular and nobody is going to expect deep experience in anything if you're coming out of school. So focus on learning the ideas, and learning how to learn. 
Excellent, thank you. I'll start with Haskell and learn the FP concepts first. You were friendly... can't thank you enough for your detailed response. 
I guess in json you would map it like this: * property not present, don't update * property present but set to null, set to None * property present with a value, set to value I bet there is a smart way via shapeless (see: LabelledGeneric) to generalize this
Add a type variable! The comment is kind of long, so I posted it here: ~~https://gist.github.com/anonymous/0112ce98f2b1367ae467b2a1b1ecb6b5~~ EDIT: Runnable example with repl output: https://gist.github.com/anonymous/81f209e3d6b959d332727abefc04599d
As stated in their faq some years ago: http://web.archive.org/web/20140720005253/http://kotlinlang.org:80/docs/reference/faq.html "...And, keeping the useful level of expressiveness (see above), make it way simpler than the most mature competitor Scala.."
u/ItsNotMineISwear Can you show some examples of how to use that code please?
I think it's only for the best. Hope Kotlin &amp; Scala will replace Java completely for web-dev &amp; big data respectively. (AFAIK, Spring supports Kotlin, so..) Java 9 so far was a disappointment in terms of new &amp; useful features for me, and Java 10 realistically will be released only in 2020 or later. Scala (Dotty) &amp; Kotlin will be far ahead in terms of language design by then. 
Here you go: https://gist.github.com/anonymous/81f209e3d6b959d332727abefc04599d My original gist had some errors due to some Scala rust on my part üòÖ This one compiles and runs though :)
I don't see it as a missed opportunity. Until Android makes commitments to staying up to date with the latest JDK, most of the Scala community works, it's just not going to happen with any official blessing.
Hmm... I mean it works, but it's not really in the spirit of what I was looking for. What I mean is, when programming imperatively and using mutable arrays, array elements can access other elements as the array is being initialized. Is there a way to access other elements in a similar manner in a for-comprehension? Example, let's say we want to map a vector A into B so that B\_i is the sum of A\_(i-1), A\_i, and A\_(i+1). So Vector(1, 10, 100, 1000) -&gt; Vector(11, 111, 1110, 1100). To start, I would write: val xs = Vector(1, 10, 100, 1000) val res = for (x &lt;- xs) yield { // only have access to 'x' // how can we get the values about its neighbors? } I mean, you can get the neighbors by doing a zipWithIndex and some index-fiddling, but that seems inelegant (not to mention inefficient on LinearSeqs). Is there really no other functional way to map a collection where element B_i depends on element A_j where i !=j?
Having taught Scala to more than half a million people, I disagree. In fact, I see a big role of Scala as a typed analogue of Python in education. And I also see Scala having quite a bit of success with kids. They don't have preconceived notions what programming is and that's an advantage. Scala is at its core a simple language, and we'll make it even simpler. People do complex stuff with it (sometimes to my taste too much so).
I'd use libgdx scala bindings 
If you *just* need to render a single image, pixel by pixel, and don't need anything else (like showing it on screen...) `java.awt.image.BufferedImage` is built in
Well, arguably Python and C are two other languages that qualify as highly popular, whether one likes them or not.
I would go and use Processing https://processing.org/ - I had my issues with Processing 3, as they change the whole back-end API and made it very complicated to start a sketch from other language, especially if you want to interoperate with Java2D. Perhaps just stick to Processing 2.x, or otherwise have a look here for Scala and Processing 3: https://github.com/Sciss/ProcessingTest An interesting question would be, now that there is both Processing.js and Scala.js, if you can actually make the two work together, i.e. write a sketch in Scala that will run through Processing in the browser.
I don't think it's that much a missed opportunity; if I were Google, I would likely have picked Kotlin as well. Using Scala has downsides; things like - Slow compilation speed, - Slow build tooling (hi SBT...), - Huge generated bytecode, - Overly-stuffed standard library (much of it of questionable quality/utility), - Overly-clever third-party libraries, - Hard-to-analyze core language semantics that confuse both humans and IDEs. I personally accept these trade-offs, but I personally know many people who wouldn't. Kotlin, on the other hand, has almost no downsides over using Java. Sure, you may not get as many *benefits* as (I think) you do using Scala, but it's still a huge step up, and you get basically no downsides. It's a "pure win" rather than a "bigger win with lots of controversial sacrifices" I think if we want Scala to become a good fit for widespread use (which is probably a *cause* of Google choosing Kotlin for android, not the *result*) we'd need to fix all this stuff. It's gotten better over the last 5 years I've been using Scala, and are trending in the right direction, but there's still a ways to go yet.
I think just some FP hipsters want to play with Scala like Haskell and this scare a lot of people aways from Scala. That's not Martin and Lightbend want.
If there is no Scalaz or similar, Scala will be much more popular and simple for people to start with. 
As mentioned, due to library overhead, scala isn't an obvious choice (yet). Though there are interesting developments in dotty, assuming the linker/optimizer in dotty works as well as shown in https://d-d.me/talks/scaladays2015/#/26. To go even further, but likely often overkill, combined with scala native and easy interop between scala native and scala jvm (something like autowire) and it is be possible to create really lean android apps in the future, where the ui is in java and the logic native. (of course it is a missed opportunity, it'll be a case of ~~too little~~, too late, and scala usage will be rather niche. Though i'd never argue kotlin development is more influencable by the community than scala's, when reading comments from jetbrains on things like macro's i'd not hold my breath, combined with their inability/unwillingness to fix their ide to work well with scala i'd argue they are way less open to feedback than the scala community is)
You're right that's nothing. Unfortunately, in my (not so recent) experience, the method count when using scala goes through the roof, where the roof is that 65k limit. No issue on the jvm, but needs to be dealt with on android. It's all manageable, but not easily.
Just go look at the standard library's stream. Almost every method on it is unsafe usually, and it's impossible to know for sure if you're using it in a safe context, unless you've done some prepping first. Implicitly converting to string is not useful, but any2string exists. Seq is a bad abstraction that is forced upon users in many places (varargs for example) ~~The Try type isn't a proper monad last I checked, but it masquerades as one~~ see u/alexelcu's response below I know there are many many more examples, but I don't need to list them all out. There are resources out there for that. I like Scala, but let's not go off saying it's standard library only contains useful and good things. 
Wasn't .NET support a thing that turned out to be impossible because CRL/IR's non-erased types?
I would be more lenient to the fluffiness of the piece if the author hadn't said in the same paragraph: "This makes Scala an attractive choice for cross platform applications well beyond Android." Scala native, in its current state, should not at all be used as an example to make Scala an attractive choice for cross platform applications. Scala.js, on the other hand, is leaps and bounds more mature, both technically and in terms of its community.
Oh, good to know, thanks!
I know I'm being picky, but this comment bothered me: &gt; ... reify generics. For instance, there's no integration with the type checker or pattern matching. AFAIK, reification at runtime is a bad thing, if you're interested in typesafety. For reified generics to work with pattern matching, it would have to be at runtime.
You could be right. However, I remember thinking long ago that the pattern matcher could do better if it wanted to. For instance, look at this archived scala forum post: http://www.scala-lang.org/old/node/11899.html From Adrian Moors: "a future(*) version of the pattern matcher will leverage manifests (when available) to perform type tests that aren't possible at run time due to erasure for now, what you figured out is the only way to do it, afaik"
Scala by its very nature is a testbed for experimental work. If you want a stable platform for development the Lightbend stack gives you that quite successfully. I won't reply to every point you raised, but really async/await is a non-issue, everyone just decided to use for comprehension syntax and moved on.
I don't believe your comment refutes anything I said. I said that scala native is immature, and based on Scala's history I wouldn't make any bets on it maturing. You're saying that Lightbend provides a stable platform. Looking at https://www.lightbend.com/platform, I don't see Scala native mentioned there anywhere. For that matter, neither do I see Scala.js or any of a number of interesting things that happen in the Scala community.
I think it's something a lot of people do but I've definitely built Android apps without it before, especially when just getting started
I was refuting your assertion that incubation experiments like Scala Native and the collections library redesign somehow make all of Scala an unstable platform, a 'graveyard' of unfinished projects.
&gt; I've personally seen multiple enterprise Scala projects go south because enthusiastic devs have jumped feet first into (say) Scalaz, and ended up in a complete mess, and Scala gets the reputation for being overly complex, and adoption is stopped. If you introduce scalaz, you **have** to be capable and willing to teach the parts you use from first principles. I introduced it to my team at Amazon (already using Scala) a couple years back, and I spent a good amount of time teaching the concepts (which was my responsibility). The end result was so much better than vanilla Scala! I can't speak for my coworkers, but my impression was they all picked up scalaz fine and enjoyed it to some degree. 
How much space does scala.io take compared to scala.collection? a fraction of percent probably.
Just as a counterpoint, Kotlin's inline functions are limited, i.e. only top level functions. Also, Kotlin does bloat boilerplate with it's insistent null checking at the top of functions. Lots of calls using their "Intrinsics" class. Not as much bloat as Scala, but not as little as Java.
You can do: implicit def apiResponseFormat(implicit tFormat: JsonFormat[T]): JsonFormat[ApiResponse] = jsonFormat2(ApiResponse) And then the caller just has to have an implicit `JsonFormat[Registrant]` in scope
Can someone please explain to me on what all this means to a Scala dev who is kind of getting his feet wet. Kind of around a year of casual learning and programming. Growingly concerned about whether I should spend my time and energy in learning Scala because I heard that the spring framework started official support for kotlin which was not related to Scala since it had play. But now kotlin has official support for Android. I honestly think Scala could have been there since it has the OOP capabilities as well. My opinions and experience on Scala are summarized below. - When I started with scala, I kind of envisioned it to be the next perfect language on the JVM. - The moderate mix of OOP and FP is a perfect way to start learning FP - Lot of good evolved tooling and support I could say more, but I guess that's obvious. What I did experience is the Scala community is kind of hard on newcomers. Honestly I don't know why. I understand that FP is hard but turning away users saying that you are not smart enough to learn Scala seems completely stupid and arrogant. This has happened to me personally and to a lot of my teammates as well. But we were not disheartened and kept on moving. We could argue that it can happen on Reddit‚Äã since people are anonymous, but it happens on the Scala gitter channel as well. This is more of a people problem that needs to be addressed. The community on the whole seems to be way too harsh on novices. This can be handled in two ways 1) Pointing them to generic resources on functional programming 2) A beginner friendly Scala language guide. This is my opinion if course gathered from my experience. Am I seeing too much into this or are there people who feel the same?
Ah whoops, I forgot that you have to also take it implicitly in the completeWithCircuitBreaker method (in order to pass it to apiResponseFormat trait RouteCircuitBreaker[T] extends SprayJsonSupport with DefaultJsonProtocol { case class ApiResponse(message: String, content: Seq[T]) implicit def apiResponseFormat(implicit tFormat: JsonFormat[T]): JsonFormat[this.ApiResponse] = jsonFormat2(ApiResponse) def completeWithBreaker(breaker: CircuitBreaker)(result: Future[Seq[T]])(implicit tFormat: JsonFormat[T]): Route = onCompleteWithBreaker(breaker)(result) { case Success(queryResult) =&gt; queryResult match { case Nil =&gt; complete((NotFound, "No data found.")) case _ =&gt; complete(ApiResponse("Success!", queryResult).toJson) } case Failure(ex: CircuitBreakerOpenException) =&gt; complete((ServiceUnavailable, ex.getMessage)) case Failure(ex) =&gt; complete((InternalServerError, s"An error occurred. $ex")) } }
Scala Native has made exactly one, non-stable release. That would be the only reason to reject the quote above. The rest of this list is, in my opinion, either overstated, overly subjective, or ignorant of popular community libraries that provide said behaviors. Given this list I would be surprised if you actively use Scala at all.
Reified generics break parametricity, and parametricity is the main reason why we can encode constraints in the types so that it catches errors for us. Type erasure on the JVM is a feature, not a bug
Why foreach takes a function A =&gt; Unit and returns Unit? Looks like it is intended for side effects. Does your idea allow to implement something like this https://github.com/pathikrit/metarest using Functors? It seems like the case class takes 2 Functors or am I wrong? One for updating and another one for forgetting?
I'm an idiot. I started to add that parameter to that function, then removed it before testing. I just tested it and it is working great! Thanks so much /u/joshlemer, you've saved me tons of time.
&gt; but I still find Seq to be a bad abstraction in general. Paulp has summed this up fine several times. Do you have a TLDR on this or a link to where he says it? Sounds familiar but I don't remember.
Sure, I believe he talks about it here. https://youtu.be/uiJycy6dFSQ He's given a similar presentation a few other times as well. 
Sorry that you've had a bad experience with the community. Although I didn't personally experienced this when I was a novice in Scala, it seems to be brought up by newcomers a lot. Me personally, I have always had my questions on /r/Scala or the gitter channel answered pretty quickly and politely, and now I try to do the same to newcomers here. Perhaps moderation here could be a bit more strict, in outright disallowing rude comments to newbies (or anyone for that matter), but it is of course tricky to do that without forbidding constructive arguments. 
I think it's a bit much to say that opt-in reified generics "break" parametricity, since nothing forces you to use them on a given method. And besides, reflection exists, so any "parametricity" on the JVM is based on holding ourselves to rules.
Require a JsonFormat [T] as an implicit arg for completeWithCircuitBreaker and the case class: case class ApiResponse(message: String, content: Seq[T])(implicit format:JsonFormat [T]) def completeWithBreaker(breaker: CircuitBreaker)(result: Future[Seq[T]])(implicit format:JsonFormat [T]): Route ... Additionally: you don't need the T in the trait. Put it on the circuit breaker method and you can use a context bound to declare the implicit. Extract ApiResponse to its own file as case class ApiResponse[F[_]: JsonFormat,T:JsonFormat](message: String, content: F[T]) object ApiResponse{ implicit def apiJsonFormat [F [_]:JsonFormat, T: JsonFormat]:JsonFormat [ApiResponse [F, T]] } Then you can use any main serializeable type with a hole in it for your Seq, and any serializeable type T for your T. When you use the route, you need to have the implicit formats in place, but can remove them from your trait. You end up with a much cleaner interface that leaves json binding up to the application developers. Disclaimer: Haven't compiled the above, but fairly certain it works.
You can use https://github.com/drbild/tristate It has both implicit and explicit None
Is it possible to do the same with tagless final encoding, or is Free the way to go here? I'm still confused when to use what. I really "like" Free, but tagless encoding seems a lot simpler and is waaay easier to combine. 
Sure, either approach works.
It really does help to be familiar with typed functional programming. Reading pretty much any book on any such language (e.g., FPiS) is a good way to get started as a beginner.
You don't absolutely necessary have to encode notion of partial updates in your domain. Circe, for example, can [automatically derive case class patchers](http://stackoverflow.com/a/39639397). Here is how [it's incorporated in Finch](https://finagle.github.io/finch/best-practices.html#picking-a-json-library).
&gt;I think just some FP hipsters want to play with Scala like Haskell Not sure exactly what you mean, but if you mean using libraries like Scalaz is 'hipster' I think you'd be mistaken. We use it in all our applications across a very large team. Most people aren't put off by our Scala, rather you see the same patterns over and over. Rarely we write a super clever bit of code but because it's *functional* (meaning, no magic, just input/output) most people don't care. 
&gt; this scare a lot of people To be honest, while I always advocate for an object-functional middle way, I don't see the problem of people using Scala as a Haskell-on-the-JVM, if they are happy with it. Why does this _scare_ someone, and why do we have to care? I mean, aren't people adults and can't we except from decision makers to inform themselves?
For the new starters they will assume Scala is scalaz and make them hard to understand the code which is unreadable. Then they will have the impression that Scala is too complicated.
Obviously, see the number of stars on GitHub is already more than Scala. More people involved will make it more popular.
&gt; Manifests, replaced by type tags &gt; Scala collections, slated to be replaced yet again &gt; reflection and macros, replaced by scala meta wat? Scala also has a long sad history of leaving ambitious projects unmaintained: * scala2.11, replaced by scala2.12 * scala2.10, replaced by scala2.11 * ...
&gt; but replacing them with xml"""&lt;div&gt;...&lt;/div&gt;"""string interpolation is the moment I stop using scala xml. Why, if your editor or IDE gives you the corresponding syntax highlighting and type checking? What is the difference then to the old model? There could be even advantages, such as using `"...".stripMargin` and thus being able to nicely indent the XML literals without having the whitespace inside.
Drowning in a sea of triple quotes? Not sure what your background is but if you do web development you work with tons of markup. With literals you get standard html syntax highlighting and it's very easy on the eyes. Triple quoted strings on the other hand just add pointless noise everywhere, there's no real advantage for the end user.
Thanks josh. I don't think the problem is just with one place. In general I see many senior scala devs seeing java/beginner scala folks as some kind of inferior race. It is kind of becoming like a cult I would say rather than a community. I hope this changes with the years to come. Please keep doing you moderation work in this sub. It needs it more than any other ones out there.
What do you recommend instead, especially if you're using Scala?
&gt; I think it's a bit much to say that opt-in reified generics "break" parametricity, since nothing forces you to use them on a given method. It's the other way around. If a library offers me a function that looks like `A =&gt; List[A]` and I call it with `myA: A` then I expect the resulting list to contain `myA` zero, one or multiple times. But the library should never be able to create some `otherA: A` out of thin air by breaking parametricity. Or, different example, something like `Option[A] =&gt; A` must be impossible to implement. If you can implement this function, you *must* be cheating and I can't rely on safely calling you. Reflections is breaking anything anyways, but still as with null, we can try to pretend it doesn't exist and blame those who use it. ;)
IntelliJ has a much better story wrt to these kinds of things
Thanks! This lets library authors write snippets that prospective users can try out immediately: https://scastie.scala-lang.org/Mj6pZYkjTrSypznWXLmsVw
I'm glad you like it. This is totally the idea. The next step for us is to work on an embedded mode to include in user documentation.
&gt;I wish you could see what we're doing with Scala at Verizon. People without much experience in it (or any!) are jumping in to very functional code bases and enjoying Scala! Could you share what you are doing to get people up to speed with functional Scala? In house presentations? pair programming? some written or video material? other things ?
 case class Nil() case object Nil How to distinguish the two ?
I don't think you need memoization for this: type Row = Vector[Long] type Table = Vector[Row] def tableOf(maxRows: Int, maxColumns: Int) = { def fillRows(t: Table, rIx: Int): Table = if(rIx == maxRows) t else { def fillRow(row: Row, cIx: Int): Row = if(cIx == maxColumns) row else { val v = if(rIx == 0 || cIx == 0) 1L else t(rIx - 1)(cIx) + row.last fillRow(row :+ v, cIx + 1) } fillRows(t :+ fillRow(Vector(), 0), rIx + 1) } fillRows(Vector(), 0) } I haven't tried it but I hope it's working as you've expected.
&gt; Even with type tags, there's still to my knowledge no great general way to reify generics. For instance, there's no integration with the type checker or pattern matching. Well, type tags and class tags can be viewed as reification in and of themselves (they are run-time values that _reify_ the compile-time notion of a generic type). They are a bit cleaner than C#'s specialization approach because the fact they are materialized as additional (implicit) parameters means they avoid breaking parametricity. As for integration with pattern-matching: scala&gt; def foo[T:ClassTag](x:Any) = x match { case y: T =&gt; true case _ =&gt; false } foo: [T](x: Any)(implicit evidence$1: scala.reflect.ClassTag[T])Boolean scala&gt; foo[Int](123) res0: Boolean = true scala&gt; foo[Int]("ko") res1: Boolean = false
This looks cool, I just experimented with it. 
Agreed! A copy of FPiS + ad-hoc 1-on-1 tutoring seemed to be good enough for ramping up new hires/interns.
They don't block. They suspend. It works with other stdlib high-order funs, because they are inline and this allow non-local control flow transfer. 
&gt; 4) How is Scala used currently in the Finance industry ? Judging by Goldman Sachs Collections, Blazing fast , typesafe and functional. Delay is lost opportunity, mistakes cost millions, repetition = more chances for mistakes.
Yeah, that's because I used a **class** tag, and the class of `List[String]` is the same as the class of `List[Int]`. Though it's true this can lead to surprises in cases like that. If you want full reification, use a **type** tag: scala&gt; def foo2[T:TypeTag,S:TypeTag](x:S) = typeOf[S] &lt;:&lt; typeOf[T] foo2: [T, S](x: S)(implicit evidence$1: reflect.runtime.universe.TypeTag[T], implicit evidence$2: reflect.runtime.universe.TypeTag[S])Boolean scala&gt; foo2[List[String],List[Int]](List(1,2,3)) res5: Boolean = false scala&gt; foo2[List[Any],List[Int]](List(1,2,3)) res10: Boolean = true
Been a fan of Scastie for a while. Nice to see active development :D
It gets way more interesting when you want to limit which attributes can be changed based on the capabilities of the user or application making the request. And way more frustrating because there's absolutely nothing that supports this.
&gt; You can say that Try is "good enough," but it could be better which I believe makes it's quality "questionable." Something pretending to be a monad, but isn't really a monad can cause issues for people who enjoy doing things with monads. Don't take this the wrong way, but this makes absolutely no sense. It makes no sense because `Try` has no alternative implementation that would make it a better monad. &gt; You wouldn't say an array that behaves like an array in all but a few situations is good. You would say it's bad because it's a landmine that doesn't work the way that it should sometimes. You might even argue that it's worse, since it took so long to discover that it was a problem, because it's non-array properties were obscure and now you've got it littered all over your codebase, because you believed it to work properly. I don't think we should defend things that are "good enough," we should be aware of their shortcomings and make efforts to improve them. This is how the collections rework came to be. And though I haven't caught up with what the news is on that, I'm sure it's better than what we have now. You wrote all of that as some sort of analogy and not one word on why you think `Try` isn't a good monad. &gt; Varargs are a good thing, what I don't like about them is that they default to Seq when you can probably safely put them in a Vector 100% of the time. Putting them in a `Vector` would be awful, because `Vector` has awful performance characteristics. Most of the time you want those args to be passed as `Array`, because that's the most useful and efficient implementation. Do a simple traversal test sometime, you'll see `Array` crushing all Scala's immutable collections and most mutable ones too. `Seq` is the common abstraction between `Array` and `Vector`, being Scala's way with which it allows you to use both. Java only allows Arrays. Pick your poison.
very cool!!!
I really appreciate these videos being uploaded on Vimeo. Thanks,
Very cool. Thanks.
The first question I always ask in interview is, "why did you learn Scala"? Be prepared with Scala and FP fundamentals and where the advantages / disadvantages lay over say Java.
Can anyone point me to a resource on converting a traditional CRUD app to an app that is backed by an actor system? I am having trouble figuring out which things should be represented by actors. For example, if my crud app had an SQL table of accounts. Does each account become an actor? Or is there one actor that manages all accounts? Similarly how would I model a many-to-many relationship? For example maybe my crud app has a table for cars, and then there is a link table: account-to-cars to support the many-to-many relationship. What would that look like in an actor system?
Thank you for that. You are right I need to wean myself off vim and get a real ide like idea. qq if you don't mind answering about `new` https://github.com/ironfish/reactive-application-development-scala/blob/master/chapter6_001_rarebooks/src/main/scala/com/rarebooks/library/RareBooksApp.scala#L30 If I undestand correctly "regular" class is being used because `RareBooksApp` is a not a value vs `BookCard` https://github.com/ironfish/reactive-application-development-scala/blob/master/chapter3_003_faulty/src/main/scala/com/rarebooks/library/RareBooksProtocol.scala#L49 is a value. Is that right ?
In the context of this example, I'd personally just keep the pattern match. In a larger application, I'd consider whether parsing a coproduct made more sense if there was actually a good reason to leverage a typeclass. In the context of your example, if I was going to force the typeclass approach (maybe the larger context of the codebase justifies it somehow) maybe I would do something quirky like `case class CommandWithRunner[A](cmd: A, runner: CommandRunner[A])`. You could then return a CommandWithRunner[A] from parse, and pass the runner explicitly to any downstream code that depends on it. I'd emphasize that this is a kind of bizarre thing to do, and I wouldn't expect to see it unless this was a unique corner of a much larger codebase and doing so allowed me to leverage otherwise widely used typeclass behavior.
Regarding the pattern matching solution: If you add the keyword `sealed` to the trait `Command`, it will enforce that the given trait can only be extended inside the file in which it is defined. This enables the compiler to check all pattern matching on it, and give warnings (or, depending on compiler flags, errors) if not all cases has been matched. This would make the pattern matching a nice solution. This does require, however, that it would make sense for your application only to define command types in one place, and that additional commands would not be needed to be defined outside your library/application later. Example: sealed trait Command case class Run(speed: Int) extends Command case class Walk(speed: Int) extends Command case class Sprint(speed: Int) extends Command val command: Command = Run(100) command match { case Run(speed) =&gt; ??? case Walk(speed) =&gt; ??? } This would give a compile-time warning at the pattern match, since the case `Sprint` has not been matched (the compiler will actually give the cases that has not been covered). This works with simple nested pattern matches on case classes and case objects that are part of a sealed type graph. For instance: val x: Option[Option[Int]] = None x match { case None =&gt; ??? case Some(None) =&gt; ??? } This would also give a compile-time warning, since the case `Some(Some(y))` is not matched. Do note that there are limitations to the pattern matcher of the Scala compiler, and that matches beyond the before-mentioned simple nested pattern matches on case classes and case objects that are part of a sealed type graph may not be fully checked at compile-time, even when the compiler has all the necessary information. For which cases the compiler does or does not check, there are blogs and forum posts here and there; I can find a link if you want. Also, the pattern matchers of the Scala compiler have improved over the years, though the basic checking has always worked AFAIK. EDIT: You can copy-paste the examples into your favourite REPL to see the warnings. In the basic Scala REPL, use ":paste" to paste.
I've been debating how to implement the concept of a variable in Bash in my DSL. All variables are declared with the declare construct so I don't have to specify "local", and there is strong enforcement of read-only in bash, but other than that, the types are "fuzzy". I could try to implement a class for the float type in bash, but I don't have a way to stop the user from assigning that float to an int in a statement.
&gt; "Scala also targets Native, and rather successfully". &gt; Thanks, I think it was an exaggeration. Updated it with my personal experience that it "worked the first time". :-)
That's the intention. I edited the article to disambiguate this point.
I concur, having started off my career with PHP.
Is it the first of April again?
The brace-less approach works well in F#. I think it's clear that people indent their code in a way that's consistent with its structure, so having both braces and indentation is generally redundant. Using indentation to denote structure is visually easier to scan than trying to match braces. It would be much more readable if Scala/Dotty switched to 4 char indents though - 2 chars is just too small.
Yeah, I love Python, too. 
I'm not sure about this. I kinda like my braces because it's easy to see where something begins and ends. I think it's a nice guide for they eyes to look for () [] {} &lt;&gt; the shapes line up with symmetry and it leaves no room for "interpretation". Personally I also find coffescript godawful to interpret in my head - holy moly are there many rules - and many rules that look similar but mean completely different things. I think the significant whitespace in coffescript is terribly implemented. I guess python on the other hand is alright though. It's designed to be whitespace significant from the start. There's also another thing I like about braces: when moving blocks text around you don't have to worry about the indentation being messed up - you can just run the reformatter and you *know* it's correct. With significant white space you'll have to be *really* careful when doing the same, or the meaning of your code will change *completely*. That said, it's always interesting to experiment with new syntax and language constructs. I think it's great to see that we're willing to change such fundamental things. It don't think we should stick with something just because "that's how we've always been doing it". Also details like cutting things like ';' is what makes Scala so pleasing to work with, so there's definitely a sweet spot between too much syntax and too little syntax. Curious to see how this develops!
How about event sourcing? You could use actor with akka persistence to store current state in var or using context.become and have history written to memory or database
Right question to ask is why is the need to convert it to actors, which are business requirements that make you made this choice, and which other architectures have you considered? If its just that "everyone talks about actors" then Id suggest to think twice about going down this rabbit hole.
I'm slightly skeptical (fighting indentation is a "thing" when refactoring python code), but there is no harm with experimentation. 
Significant indentation is a nightmare. It doesn't make the syntax cleaner it just removes the visible borders of functions, classes etc. I hope this won't make it into dotty.
could be confusing if you embed the function definition inside another function. at least with braces you are 100% sure where it starts and ends. 
Akka in Action pg 136 also has a section on it. 
 def parse(str: String): Command = str match { case "run" =&gt; Run(100) case "walk" =&gt; Walk(50) } Just fyi, you should consider wrapping this in Either. It can fail if you pass the wrong string obviously
Can't say I'm a fan of this
Can you add some examples? I don't see how it makes things more complicated, especially not with a decent editor.
nice meme
I love it
Hey. I added in a limited set of variable types. For example, if you write: Const("ints", Array(1, 2, 3)) , Var("z", Array("a", "b", "c")) , Const("y", "foo") , Var("x", 5) , It will generate: declare -r -a -i ints=(1 2 3) declare -r -a z=(a b c) declare -r y=foo declare -r -i x=5 And if you declare an array like this: val myArray: Arr[String] = Const("my_ints", Array("1", "2", "3")) You can use it in a construct that only takes in an Arr: ForArr(myArray, "i")( "echo $i" ) And it will generate: for i in ${my_ints[@]}; do echo $i done What do you think?
For the OP, you don't have to use akka to use event sourcing, and I feel ES is a very viable solution to the problem you describe. 
You will want StateT or WriterT. Those allow monadic flow while tracking state. You can then store the history of changes as a single blob in your database of choice.
Of all the things that brain power could be devoted to we're down to overloading keywords and increasing complexity to satisfy some extremely subjective sense of asthetics? What a complete waste of energy. What with the "if then" farce and now this nonsense has Odersky really gone off the deep end?
Can you give an example?
I believe the pipe syntax is limited to: enum Color { case Red | Green | Blue } for paramterized types the current allowed syntax is: enum Option[+T] { case Some[+T](x: T) case None } I just added a comment wrt to significant whitespace allowing: enum Option[+T] Some[+T](x: T) None Basically the `case` keyword could potentially be removed from the language in pattern matching blocks. There are probably reasons for why this is not possible, but if ML-style syntax were adopted I for one would be absolutely thrilled (Scala is concise but a bit noisy compared to the ML side of the fence).
Memento comes to mind. but I'm not 100% sure when it comes to FP / Scala solutions.
What's stopping you from marking it as 1.0? 
True!
Is event sourcing overkill if I can do something like below? Actor { context.become(working) def working(history: List[State]): Receive = { case State(x) =&gt; context.become(x :: history) // Make next update based on current state update(x).onComplete { result =&gt; self ! result } } } def update(state: State): Future[State] = { ... state.copy(someValue=someNewValue) } 
It only looks great until you get tabs and spaces mixed up. Then it's an invisible nightmare.
Thanks!
Scala needs yet another alternative way to express the same idea. It's nice to see them tackling the serious issues we have all been focused on. I am sure this will only speed up the already blazing compilation times.
Not a fan of this at all...
As other people also mentioned, your problem screams event sourcing and I think if you decide with going something else you'll end up with something very similiar anyway What you have in your snippet is basically ES in simple form. Going a bit further, you could persist this history however fits your use case and replay those events in case of failure ( folding your List[State] ). 
I feel this is a terribly flimsy argument against indent based scoping. Any decent text editor or IDE should be able to handle this without any difficulty, I just fail to see how this can actually be a problem, espically since it's a compiled language, so the compiler should be able to tell you exactly what went wrong and where it happened.
That's a valid point; I am just doing it as a learning exercise, so there are no business requirements at play here :)
When you want to patch this onto an existing language that's been around for a long time, you don't even need very good arguments to counter it. You need extremely good arguments to go ahead with it.
This is a terrible idea. A curly-braced block { ... } describes a sequence of imperative steps. Train your eyes to alert you that there might be intermediate values or side effects in a block. An = with no curly braced block or anything in parentheses ( ... ) describes an expression. That expression can perform side effects or be have insanely complex branching or call into functions that contain blocks or evaluate to Unit. But you know that at the level you are reading this it is an expression. Adding significant indentation like this removes that visual heuristic and makes Scala code harder to read.
I think you should use (2). Using the State Monad is a more generalized way of composing those updates. Here's an *old* example of how I model updates to a 'game' board with the State Monad https://github.com/vmarquez/purebomberman 
You could be talking about event sourcing or you could be talking about a zipper. Not sure which.
Yep. The `App` is a service/singleton and not a value.
i use coursier with this wrapper script: ~ &gt;&gt;&gt; cat bin/amm #!/bin/sh coursier launch com.lihaoyi:ammonite_2.12.1:0.9.0 -- --no-remote-logging $@ 
What's the status of IntelliJ support? Thats the main thing stopping me form using Ammonite :)
I really don't like it. Too many ways to do one simple thing. How can we send our feedback to Scala dev?
So I largely agree that if it adds complexity, then it defeats ease of learning. But largely speaking, I do think that significant whitespace is easier for novice programmers.
I disagree with that breakdown. `{...}` is an expression, just like `(...)`. But since the single expression allowed by `(...)` can call a function that can do literally anything, I think it would be unwise to describe the two syntaxes as having an imperative vs. functional duality, or anything like that.
The issue observed is that without a type annotation on `myMonoid`, the example fails to compile (which is good) while it compiles and yields null when the annotation is added (bad). The article is paper thin and does little to explain why this happens. Basically, `myMonoid` resolves to itself. That is, `Monoid[MyClass].apply` looks for an implicit value of `Monoid[MyClass]` and finds `myMonoid`! One key element that allows this to happen is the type annotation: without it, the variable declaration isn't allowed to partake in the recursive resolution of itself, which forces a compilation error. This is easier observed if `implicit def` is substituted for `implicit val`, which will trigger a runtime stack overflow exception due to calling itself until the stack is blown. 
There is an imperative vs functional intent expressed by the distinction, even if it's not enforced by the language. No different from the distinction between `def foo = ...` and `def foo() = ...`
This is excellent news. Many tasks and expecially devops related are a perfect fit for scripting and being able to use the power of Scala with the convenience of ammonite's scripting features really makes my day better. Thanks for putting a lot of effort in to this. I wish that some organisation would go in and fund this project and make it an integral part of Scala. In F# you can run scripts with shebang and fsharpi (fsi) but it is not nearly as good as Ammonite. The good thing with F#'s script support is that it is a part of the F# distribution. I would like if that was the case with ammonite.
As a library author, you may want to compile your library in Typelevel Scala, and test it in Lightbend Scala. Because your internal implementation may require some feature in TypeLevel. Is it possible?
Battling legacy play-java-akka multiple "micro"-services app. Lots of classcast exceptions. New NPEs from prod report every morning! Hundredts of DTOs in java, each several hundred LOC (equals, hashcode...). No shared repo between microservices, so copying changes between projects. Favorite pattern: catch exception, on exception return null. It's wild west out there. I want to crawl underneath some functional rock and play with cats. Yea but they claim FP is complicated, and it's only for academics not for real world, so we're good. This is how we roll. This is how we do software in 2k17 :):) 
I write a *lot* of perfectly pure, functional code that uses `{ ... }` all the time. Simply because I want to declare some `val`s in the middle of my computation: val x = { val a = blabla() val b = foobar() val c = a + b c * c } In fact, most of my code looks like that.
You can also use this to break the type-checker for all your co-workers, just put this in a nice place that gets imported often implicit def iAmSatan[A, B](a: A): B = a
For a very representative example: https://github.com/scala-js/scala-js/blob/master/tools/shared/src/main/scala/org/scalajs/core/tools/linker/backend/emitter/ClassEmitter.scala
I find your revised version significantly harder to read. Like, really hard. And that's still a very short method. Try [`genES5Constructor`](https://github.com/scala-js/scala-js/blob/master/tools/shared/src/main/scala/org/scalajs/core/tools/linker/backend/emitter/ClassEmitter.scala#L143).
I tried. It seems that sbt does not support specifying different compilers for different configurations. scalaOrganization in Compile := "org.typelevel" scalaVersion in Compile := "2.12.2-bin-typelevel-4" scalaOrganization in Test := "org.scala-lang" scalaVersion in Test := "2.12.2" 
Take a look at the approach to switching taken here: https://github.com/milessabin/tls-demo/blob/master/build.sbt.
It would be nice if people started considering the middle ground: enforced indenting. Which is really significant whitespace and braces and the compiler enforcing that they are in sync. 
Yeah -- I'm not suggesting that is not functional. For complex expressions intermediate values are most welcome! However the { } are a good indication to look out for them when quickly scanning for what is going on.
I agree that the `genStaticMembers` is easier to read with intermediate values. Mostly because you can just look at the last line to see the "tl;dr" and then if you're super curious you can look at e.g. `className` to see how that's calculated. It kinda falls in the same category as splitting up your functions into smaller functions with descriptive names. It's exactly the same with well-named intermediate values (`val`s). That said, it's always possible to overdo things. Sometimes inline'ing is way easier to read - especially if you can use named parameters instead of values with same name. Eg instead of doing: val firstName = "Foo" val lastName = "Bar" val age = 30 Person(firstName, lastName, age) it's often more obviously-no-defects to do: Person( firstName = "Foo", lastName = "Bar", age = 30 ) ^ The last example is way easier to see that it's correct, wheras the first you'll always wonder: "hmm maybe lastName is first?". Rather than saying always split into values, or always make a big expression, you'll just have to flip back and forth between inlining and intermediates to see which is clearer in each and every case. There's no golden rule here imo.
I haven't been a newcomer in a while, so your response intrigues me. Can you be more specific in how it hasn't been friendly to newcomers?
You can find the source code at [Github](https://github.com/ThoughtWorksInc/example.scala). The `@example` annotation is based on scalameta.
Good catch, this is actually a problem for me because of my work. I'm sure it's not nefarious, but it's something that would have prevented me from technically being able to use ammonite.
Always liked this idea. I dont know why it is not popular yet
You are devil!
Security by obscurity is the worst form of security. You are root on a docker container. I have an open issue for security hardening: https://github.com/scalacenter/scastie/issues/200 and one of the first advice is to run as a non root user: https://github.com/wsargent/docker-cheat-sheet#security.
I agree with that formatting as well. As long as I have good names for intermediate results I am happy. If these are the named parameters of the enclosing call, so much the better. 
What are combinators of primitives? What can I do with combinators?
If you have an important check that needs to be called, better to make that part of the type. e.g. you can ensure you can't get a result out of a database access call without being in a transaction by making all your database access operations an opaque monad, and the only way to run it is via the method that does the transactioning. And yeah, I don't know of any way to check for unused public methods.
You ask a tough question. Lets just leave the answer up to fate! *^shake ^shake ^shake* **Ask again later. I cant. I just cant deal with this right now.**
I think ScalaStyle can do this.
ReaderWriterStateT?
Sounds fishy. Is it possible that something is reassigning stdout and snarfing all your messages? Can you provide a minimal example that demonstrates the behavior?
If it happens when using a specific tool/library I would understand, but it is happening irrespective of the setup. I have tried with Scala IDE, running maven from terminal, packaging the app as a JAR and then running it. The only place println works is in my main class. There are no errors too and the app runs fine.
joshlemer's answer is spot on. In addition, the view bound construct (`&lt;%`) is deprecated and being phased out in favour of context bounds (`: `). Both are syntactic sugar for an implicit parameter list, where the view bound `A &lt;% Ordered[A]` becomes `(implicit vb: A =&gt; Ordered[A])` whereas a context bound like `A: Ordering[A]` becomes `(implicit cb: Ordering[A])`. Context bounds are more controllable as you have to define them explicitly. A method with a view bound in contrast will suck in any implicit conversion that's around and this conversion may then be applied any number of times to your input data. Strictly more powerful but also less controllable. Here's a shorter example that shows how context bounds can be used to prove that two parameters are "similar" to each other object Similarity { implicit def uniformity[A, B](implicit proof: Similarity[A, B]): Similarity[B, A] = new Similarity[B, A] { def areSimilar(b: B, a: A) = proof.areSimilar(a, b) } } trait Similarity[A, B] { def areSimilar(a: A, b: B): Boolean } implicit object IntStringSimilarity extends Similarity[Int, String] { def areSimilar(a: Int, b: String): Boolean = a.toString == b } def myFun[A, B](a: A, b: B)(implicit proof: Similarity[A, B]) = { if (proof.areSimilar(a, b)) s"$a is similar to $b" else s"$a is not similar to $b" } myFun(1, "2") // 1 is not similar to 2 myFun("1", 1) // 1 is similar to 1 Note that while the basic similarity between an Int and a String is established explicitly in `IntStringSimilarity`, there is also an implicit helper method `uniformity` that creates a mirrored proof that `Similarity[B, A]` can be created from a `Similarity[A, B]`. While this **is** an implicit conversion, it is more principled (that's what I'm arguing at least). By stowing this away in the companion object it applies to any case where the type parameters are reversed.
I'm trying to learn Scala so I started doing the 99 Problems in Scala thing. Problem 1's [solution](http://aperiodic.net/phil/scala/s-99/p01.scala) contains this code def lastRecursive[A](ls: List[A]): A = ls match { case h :: Nil =&gt; h case _ :: tail =&gt; lastRecursive(tail) case _ =&gt; throw new NoSuchElementException } I searched up the :: operator and found an SO answer that points out it's a case class defined [here](https://lampsvn.epfl.ch/trac/scala/browser/scala/trunk/src///library/scala/collection/immutable/List.scala#L312). I'm still confused on why the case class can be created with an infix operator? 
Meh, just supporting the lazy status quo. 
Slack?
Ok, thx. Sadly that it isn't as you thought üòâ Overall C++ is full of (obscure) clumsy syntax. So I am even not sure that that would make the language better... üòÖ
Agree
Discord is like slack but (at least for the time being) free-as-in-beer without having to do any funky github email shennanigans.
Methods, classes, and types can be written infix in Scala (also there's a rule that methods ending in `:` are called on the thing on the right rather than the thing on the left). `::` in this context is just a `case class` with a weird name. The code you posted is equivalent to: def lastRecursive[A](ls: List[A]): A = ls match { case ::(h, Nil) =&gt; h case ::(_, tail) =&gt; lastRecursive(tail) case _ =&gt; throw new NoSuchElementException } which makes it move obvious what's going on, though probably at the cost of looking less like an ML list pattern.
As far as I know "combinator" usually just means "higher-order function". I've never heard of "combinators of primitives".
Interesting. I find it clearer to have the code's outer-to-inner structure reflect that of the datastructure we're creating, and the vertical space saving is worth its weight in gold when it comes to keeping classes/methods down to a single page. If it's about having names for things I might use named parameters (don't know what the names are for your `js.Block`) My approach to `genES5Constructor` would be similar, though really to do this right I'd need more domain knowledge. Sometimes there really is a bundle of data that goes together (e.g. I don't like embedding these conditionals about `isJsClass`, I'd probably try to move that up into a type distinction and a polymorphic method) - one of the ways I avoid having problems with large functions is simply by not having large functions, replacing them with smaller functions and introducing more classes to represent the intermediate states. But still, to show willing, and trusting that we can handle the implicits somehow (can't open external code from here): private def makeInheritableCtorDef(ctorToMimic: js.Tree, className: String, keepFunctionExpression: Boolean) = js.Block(js.DocComment("@constructor"), envFieldDef("h", className, js.Function(Nil, js.Skip()), keepFunctionExpression), envField("h", className).prototype := ctorToMimic.prototype) private def genES5Constructor(tree: LinkedClass)(implicit globalKnowledge: GlobalKnowledge): js.Tree = { val typeVar = encodeClassVar(tree.name.name) js.Block( js.DocComment("@constructor"), envFieldDef("c", tree.name.name, if(tree.kind.isJSClass) genConstructorFunForJSClass(tree) else js.Function(Nil, js.Block( tree.superClass.fold[js.Tree] (js.Skip()) { parentIdent =&gt; js.Apply(js.DotSelect(encodeClassVar(parentIdent.name), js.Ident("call")), List(js.This())) } :: genFieldDefs(tree))), keepFunctionExpression = tree.kind.isJSClass), tree.superClass.fold[js.Tree] (js.Skip()) { parentIdent =&gt; js.Block( if(tree.kind.isJSClass) makeInheritableCtorDef(genRawJSClassConstructor(parentIdent.name), tree.name.name, tree.kind.isJSClass) else js.Skip(), typeVar.prototype := js.New(envField("h", if(tree.kind.isJSClass) className else parentIdent.name)), Nil), genAddToPrototype(className, js.StringLiteral("constructor"), typeVar))}, if (isJSClass) js.Skip() else makeInheritableCtorDef(typeVar, tree.name.name, tree.kind.isJSClass)) } Removing the `var`s enables removing other ceremony in terms of braces and so on (relying heavily on indentation, and making use of horizontal space, but we have a lot more of that than vertical space). I've ended up with a `val typeVar` - I'm not too fundamentalist, but I would probably try to push that down to a method on `LinkedClass` or some such. And now that the two `fold`s are here in the same place I wonder if they could be coalesced.
Hell no!!!!!
I would love to use a "typed analogue of Python", but because of JVM compatibility constraints and having both OOP and FP Scala is way more complex than Python. Which subset of Scala do you recommend people use?
WOW I didn't even know that Big Man Tyrone was a programmer!
In addition to what /u/m50d said here you can see that you can easily make your own case class that does the same thing: case class -:(a: Int, b: Int) -:(1,2) match { case aa -: bb =&gt; true case _ =&gt; false } // true
Thanks! 
https://github.com/allenai/openie-standalone
I don't think that it has been compromised. It loads a bunch of tracking pixels and tracking scripts, but I believe that those are related to Disqus. I believe that Disqus has been trying hard to become profitable, so they might be trying out some more aggressive tracking.
Why don't we just make the syntax user definable? Go full out on the DSL idea, let me have different syntax for all my files! :) But honestly, I love the idea of the bracket less pattern matching, don't really understand why are they there (regardless of indent). I'd also like to be able to leave off the parenthesis from my if conditions. But some parts are really bad, like the 'with' thing, is kind of insane. Two line simple expressions without a bracket look good, and feel good, but the long, deeply nested functions get even more confusing.
Try [Doobie](https://github.com/tpolecat/doobie)
That's Disqus and google-analytics. Install ublock-origin and turn on the logger. https://github.com/scala/scala.github.com/issues/744
Uh, no. You are the exact opposite of correct. Using *multiple* characters to represent a *single* indentation level is an unnecessary complication.
Why did you use an AnyVal here? Also, for my owb learning, when would you find areSimilar to be useful? My concern with it is its looseness.
Mutable classes will be slower and less efficient, if you need to keep history. Also, it will be very difficult to properly nest classes if they are mutable, since if a mutable class is returned and changed outside of it's parent's class, the encapsulation is broken, and you are effectively dealing with globals, since you cannot know where does your scope ends. Immutable classes are not slower at all, since you need a lot less checks and state tracking, it might increase GC pressure though, but I don't think it's a problem with any modern PC or even with phones. Mutability is faster if you do huge array manipulation, like a bitmap, since there immutability does not add a lot, but does have a huge performance impact. But all of the above is not that important, what is the biggest win for immutability is that is will have less bugs, and will be much easier to debug, since it's much clearer where can it change.
Thank you very much, sir.
Lol, this was supposed to be a pithy comment, not a new post, oh well.
If you're interested in concepts, try my typeclassopedia project too https://github.com/channingwalton/typeclassopedia
Thanks!!!!! :-D
This is what I see. It keeps going indefinitely: https://www.youtube.com/watch?v=CLJochN7DAY&amp;feature=youtu.be
Thank you for the tip. I had always refused to install AdBlock because I am an advertiser myself (Google AdWords), but this was the proverbial straw. I'll blacklist overzealous advertising platforms from now on.
Wow, I forgot that I've installed uBlock few days ago. After I disabled it ads come back. My ads doesn't have video like yours. By the way previous screenshot was taken about 7 month ago.
@s11 wrote an enlightening article on `AnyVal`'s - https://failex.blogspot.com/2017/04/the-high-cost-of-anyval-subclasses.html.
This isn't used as a wrapper type though: it's a proxy for adding the ~= method to a type. Users will most likely not want to instantiate it themselves
Not completely sure when you would want to compare two different types like this, but I was just answering how to do it because that was OP's question :-). I also agree about the GT / LT / EQ thing.
I design and build realtime streaming pipelines for the casino industry. I think most jobs should be streaming apps. You will have the data sooner. Enabling you to take action faster. There are tons of reasons toward having streams apps. If you are interested, I can elaborate. 
This refers to Algebraic Data types ADT. They have a precise mathematical definition and it isn't a totally different concept from what you leaned about in maths. The two most common types of ADT you will find are Product types and Sum types. A commonly seen product type is a tuple. Imagine you have a tuple ( Int, String). This type represents all possible ints combined with all possible strings. The number of possibilities is the number of possible ints times the number of possible strings. In other words, This type is the product of ints and strings. Sum types are then two sets added together instead of multiplied. A common type for this is the either type. Either[Int,String ] represents all possible Ints and All possible Strings, but not both together. It is the sum of these two types. Another example is option. Option[Int] is all possible Ints plus the single None value. When one talks about creating an algebra they are referring to creating some Algebraic Data types that define their problem space. As a simple example if you ate working with weekdays you might define a type with seven values one for each day of the week. These types have formal mathematical definitions and even formulae that describe them, but that is the general intuition. Hope this made sense. 
Wow! Seems amazing! 
I love Scala but there's no way it's more readable for most things. Ml syntax is way cleaner, just takes a little getting used to
In general, "Algebra of $things" means, that you can take two $things, combine them and get a new one. (Which may in some cases be equal to one of the things you started with, like a+0=a.) So for example, if you look at Boolean Algebra, your things are truth values, TRUE and FALSE. One of your connectors is AND. You can say A AND B and get truth value. Same thing tables in realational databases. Those are based on Relational Algebra. So tables are your things. JOIN is a connector. Table1 JOIN Table2 gives you a new table. When you functions (or functors), you your operation is composing: First do function_1, then do function_2. The word is so common because the concept of "take two things, get a new one" is so common.
If you really insist of modeling your game this way, you can try with http://www.scala-lang.org/api/current/scala/collection/BitSet.html
I don't think you need this kind of performance characteristic. I would suggest modeling your game with immutable state. `case class PlayerStats(isHiding: Boolean, isBlind: Boolean)`.
No, haven't written it yet. What do you recommend as a first pass? This post is also to help me continue learning scala.
Thanks, I have seen entity/component/system and will again read up on it. Can you give an example of how these flags might be modeled in this way? They don't necessarily have to be flags, but rather the abstract idea of True/False for a large set of game concepts.
You might want to group your booleans into smaller logically-grouped case classes, then combine the case classes at the top level. case class VisualTraits(isHiding: Boolean, isGlowing: Boolean) case class PlayerStatus(isDead: Boolean, isBleeding: Boolean) case class Player(visual: VisualTraits, status: PlayerStatus) Something like that
Thanks, this is great! Is there a popular scala library which wraps up these bitwise operations... libflag? If not, happy to roll my own. Will also read about costs of java bitwise operations vs. booleans, but any articles are appreciated.
Thanks for the example
I'm not sure that is faster, but I'd just do State as an enumerated type and give each entity a List[State]. I'm not sure that is faster, but certainly easier to read. Also you can make a hierarchy as in Blinded extends Dazzled, as it does everything Dazzled does, but more so.
Use enums for binary attributes, then each player object has a Set of active flags (when a flag is set to True, put it in the set, and remove it when it's set to False). For non-binary, same thing except keep the information in a Map. 
I like this. Like this, right: sealed abstract class Flag final case object Blind extends Flag final case object Hidden extends Flag case class MyGuy(flags: Set[Flag]) It's unclear to me how to do this for non-binary. How does this look: sealed abstract class NonBinary sealed abstract class Blind extends NonBinary // blind is now trinary final case object NotBlind extends Blind final case object SemiBlind extends Blind final case object VeryBlind extends Blind final case object Blind extends Flag final case object Hidden extends Flag case class MyGuy(nonBinaries: Map[NonBinary, NonBinary]) // ??? e.g. nonBinaries = Map((Blind, VeryBlind)) 
@s11 explains boxing if `scalaz.concurrent.Task` were to be made a value class - https://github.com/scalaz/scalaz/pull/1342#issuecomment-292692097
I'm creating some template for my future apps right now, and I decided to use scalajs-react. My only previous web experence was with typescript+angular2 and there is a HUGE difference. I had maybe one runtime error since I started working with it, and with angular at least 50% of errors showed up in runtime. Strongly recommend :)
It doesn't compile to the same thing and has been in Scala since forever.
I use scalajs-react at work, but have no experience with other technologies, so can't compare. It seems to work well though, I've had very few issues with it.
Excellent article!
Hmmmmm... I got a bit interested in seeing if I could write something up for this, partly since I have seen similar before, so I wrote the following. Buyer beware: the library part of it has some ugly type casts, but given that it is contained as such in the library, you may consider it OK. Also note that the example is both fairly verbose and a bit fragile, since users must be careful with only using the methods below when working with the `AttributeMap`; A good solution would probably be to clean up the library to both prevent library users from misusing the attribute map as well as make it much more concise to use. The solution below uses dependent typing (more specifically, Scala's path dependent typing) in addition to the type casts, which is what enables the compile-time checking of getting and inserting/updating keys. object TestApp { sealed trait AttributeKey { type Value } case object HiddenKey extends AttributeKey { type Value = HiddenValue.type } case object BlindKey extends AttributeKey { type Value = BlindValue } case object FrozenKey extends AttributeKey { type Value = FrozenValue.type } sealed trait AttributeValue case object HiddenValue extends AttributeValue sealed trait BlindValue extends AttributeValue case object SemiBlind extends BlindValue case object VeryBlind extends BlindValue case object FrozenValue extends AttributeValue type AttributeMap = Map[AttributeKey, AttributeValue] def getAttributeValue( attributeMap: AttributeMap, attributeKey: AttributeKey): Option[attributeKey.Value] = { attributeMap.get(attributeKey).asInstanceOf[Option[attributeKey.Value]] } def insertUpdateAttribute( attributeMap: AttributeMap, attributeKey: AttributeKey) (attributeValue: attributeKey.Value ): AttributeMap = { attributeMap + (attributeKey -&gt; attributeValue.asInstanceOf[AttributeValue]) } def removeAttribute(attributeMap: AttributeMap, attributeKey: AttributeKey): AttributeMap = { attributeMap - attributeKey } def emptyAttributeMap: AttributeMap = Map.empty // Do note that it is typically necessary to know the type of the attribute key when // using the library to modify or retrieve values. def main(args: Array[String]) = { println("Beginning.") println() val attributeMapInitial: AttributeMap = insertUpdateAttribute( insertUpdateAttribute( insertUpdateAttribute(emptyAttributeMap, HiddenKey)(HiddenValue), BlindKey )( VeryBlind ), FrozenKey)( FrozenValue ) val attributeMap = removeAttribute( insertUpdateAttribute(attributeMapInitial, BlindKey)(SemiBlind), FrozenKey ) // You cannot set a value for a different key, so this does not compile. //val attributeMap2 = insertUpdateAttribute(attributeMap, HiddenKey)(SemiBlind) val hidden = getAttributeValue(attributeMap, HiddenKey) // When getting for the BlindKey, you get the BlindValue type for the result, // so this does not compile. //val hidden2: Option[HiddenValue.type] = getAttributeValue(attributeMap, BlindKey) val blind = getAttributeValue(attributeMap, BlindKey) // Likewise, this does not compile. //val blind2: Option[BlindValue] = getAttributeValue(attributeMap, HiddenKey) val frozen = getAttributeValue(attributeMap, FrozenKey) println(s"Hidden: $hidden") println(s"Blind: $blind") println(s"Frozen: $frozen") println() println(blind match { case None =&gt; "Not blind." case Some(SemiBlind) =&gt; "Difficulty seeing." case Some(VeryBlind) =&gt; "Cannot see anything at all." // Type checker complains about below case. //case Some(FrozenValue) =&gt; "What." }) println() println("Ending.") } } The advantage to this approach is partly that it is type safe, and partly that you save memory if only a few attributes (among possibly hundreds of attributes) are ever in the non-default state for a given entity. One of the disadvantages is that you may end up with conflicting flags if flags are not independent. For instance, if you have a flag that indicates being poisoned, and you have another flag that indicates the unit is immune to poison, the state is inconsistent, and that could lead to more difficult maintenance and bugs. But maybe you could use approaches (maybe run-time approaches?) to resolve or handle such inconsistencies. Whatever the case, it is something to be aware of. Another issue, which I think may be relevant for your use case, and which I could imagine you have already thought of, is how permanent a given attribute is, its possible lifetime, and if it would make sense to differentiate between different kinds of attributes (like temporary attributes or "effects"). But, I imagine that stuff can be complex, so it may be better to iterate and prototype it a bit more and see what works and if it is really an issue in practice. A more straight-forward and possibly more efficient approach, but less type safe to use, would simply be to use a map of named integer constants to likewise named integer constants. I imagine that could also play nicer with other parts, like serialization and the like. That said, I could imagine that for your use case, you may work quite a bit with attributes, so maybe the above type safe solution could make sense.
Great post! Who's up for writing some pull requests. 
Great work! Though I never declare my case classes `abstract`, I think *Abstract/non-final case classes* isn't a wart. In current dotty version, you can also create a case class extends a case class.
Disqus has been a complete flop so far. Pity really the old mailing list was a good read. 
Here's a sloppy attempt at an explanation until somebody that actually knows what they're talking about comes along: &gt; Can you please describe what a primitive exactly is(with an example)? When can I call something to be a primitive? The way I understand it, a primitive in an algebra is the opposite of a composite - an operation, or a value that is not composed of other operations/values. For example, if we define an algebra for drawing lines on an infinite 2D plane, we might have: * values: Point(x: Number, y: Number) * operations: drawLine(start: Point, end: Point) Now, our primitives are any instance of Point and drawLine. Our composites would be algebraic expressions - in this case, sequences of drawLine invocations. &gt; Can you please show an example the way of how to construct a descriptions before intepreting [sic] in algebra? What is a description? A description is just a data structure (usually a tree) that contains operations and values. For example, if we want to create a calculator program, we might read the user's input (e.g. `(5-x)*(3+2)`), parse it and convert it into an algebraic expression / AST like this: `mul(sub(5, Var(x)), add(3, 2))`. Then, at some point we throw that description at an interpreter and something happens - for example the interpreter could simplify the description down to `25-6*x` or `sub(25, mul(Var(x), 6)`, or if the description contains no variables, we could throw it at an interpreter that directly calculates the expression's value. Why is this useful? I don't know all the pros/cons and when to/not to use it, but here's one small example - you could create a DB library that uses an algebra. You could then run the algebra against an actual multi-TB database in production, and you could run the algebra against a mock interpreter when testing. Here's a section of a presentation that talks about using an algebra for a DB library and shows code examples: https://youtu.be/M5MF6M7FHPo?t=258 Some other related links: * https://softwareengineering.stackexchange.com/questions/242795/what-is-the-free-monad-interpreter-pattern * http://underscore.io/blog/posts/2015/04/14/free-monads-are-simple.html
Some (e.g. tuple - parameter parity) are already in dotty
Depends on how much support you want to be available. 1600 commits and 45 contributors versus 16 commits and 1 contributor.
Sorry, too lazy to look up the docs (by the way, here's the [collections perf overview page](http://docs.scala-lang.org/overviews/collections/performance-characteristics.html)), but I couldn't resist the opportunity for some code golf: have you considered using `List.updated`[1]? E.g. `xs.indices map {xs updated(_, 7)}` EDIT: also, if this isn't purely an academic/learning exercise, do you have use cases where the performance is actually an issue? E.g. if you have very long sequences where it starts to matter, it might make sense to not create all these list variations, but instead lazily (e.g. using `Stream`) generate functions that "patch" your list - e.g. instead of returning `List(1, 2, 7, 4, ..., 1000000)`, you could return `{idx =&gt; if(idx == 2) 7 else xs(idx)}`. Or if your list is easily calculable (like your example, which boils down to `1 to 4 toList`) and you only need to query it (and not traverse it), you might skip generating an `xs` list altogether, and just use a function to return the value instead (in your example, `{i =&gt; i+1}`). Just food for thought, since I have no idea what's the surrounding context to your question. [1] http://www.scala-lang.org/api/2.12.2/scala/collection/immutable/List.html#updated(index:Int,elem:A):List[A] (reddit's Markdown flavor's link escape rules are ridiculous) 
I haven't benchmarked anything yet, so no issues, but I always am suspicious about :::, take(), drop() approaches (1 and 2 in my post). I would imagine the 3rd option is similar under the hood to List.updated. These lists will generally be quite short.
I get that, but it's more cpu instructions. I can understand bit packing when it gives you better data locality, or lets you pack state into unused parts of a pointer / id, But to do extra bitset math on each and every access of frequently accessed unrelated flags? It just doesn't fly in my head.
I started writing a reply, then decided to turn to an excellent online book that started my thinking along this path. http://gameprogrammingpatterns.com/data-locality.html The problem I see, is (in Scala specifically) how do you go about creating arrays of the components without indirect access? You would need to use value classes. http://docs.scala-lang.org/overviews/core/value-classes.html Which led me to read &gt; Allocation Summary &gt;A value class is actually instantiated when: &gt;a value class is treated as another type. &gt;**a value class is assigned to an array.** &gt;doing runtime type tests, such as pattern matching. Which... limits their usefulness somewhat, especially with the lack of pattern matching, I don't know if you can do pattern matching and avoid the type tests, and just test by value. So, bitsets / raw arrays of booleans end up not looking so bad, but then you have a lot of the raw mechanics to do yourself again.
&gt; I always am suspicious about :::, take(), drop() approaches Yep, without thinking enough about it, I'd guess O(n**2) is likely for them. &gt; I haven't benchmarked anything yet That's what I suspected. Given that the lists will be quite small, O(n**2) might not be an issue (at small values of n!). I personally try to keep a balance between "premature optimization is the root of all evil" and "kids these days are throwing around code and introducing quadratic/cubic/.../exponential behavior with nary a care in the world". &gt; These lists will generally be quite short. This reminds me that some sorting algorithm somewhere (in some language's stdlib, IIRC), would switch between a "proper" algo for normal sequences, and something seemingly silly (bubble sort? Insert sort?) for sequences with &lt;20 elements, because the "proper" algo was slower at small enough values of N. Just a cautionary example when it comes to performance and optimization - consider not only Big-O complexity, but also average and best-case complexity, as well as the hidden constants and how much each will be a factor for your performance goals in the expected use case. And as usual, don't forget to benchmark before doing any optimizations. EDIT: yup, it was Timsort [1] - "Python's standard sorting algorithm since version 2.3. It is also used to sort arrays of non-primitive type in Java SE 7,[3] on the Android platform,[4] and in GNU Octave" [1] https://en.wikipedia.org/wiki/Timsort#Minimum_size_.28minrun.29
Agree'd. I think I've extended case classes myself, and I can't see any reason not to, nor did lihaoyi propose any reason other then 'people don't use em, lol.' in this article. It confuses me why it's even mentioned.
&gt;Presence of comments affects program logic Reminds me a lot of automatic semi-colon insertion from JavaScript, just more insane.
Take a look at [FizzBuzz from Scratch]( https://github.com/MasseGuillaume/ScalaFromScratch/blob/solution/src/main/scala/Main.scala#L2)
&gt; Introducing additional rules that conflate the two forms would have undermined currying as a consistent language feature That's not a very convincing argument. Scala already conflates the two forms in a messy way: abstract class A { def foo() } class B extends A { def foo = 42 } `B::foo` has no parameter list, yet it overrides a method with one parameter list...
Universal Equality is definitely a wart. One solution would simply be to have an "isEqualTo" method that *wasn't* defined on object, and make "==" an alias for that instead of the "equals" method. 
There's actually a [good use case for abstract case classes](http://www.cakesolutions.net/teamblogs/enforcing-invariants-in-scala-datatypes). Though it's true that it would be cleaner if bare case classes would be made `final` (or at least `sealed`) by default.
This one's still nagging me: assuming this isn't a homework assignment or an unrealistically small example for an optimization discussion, why do you need to pre-generate those lists (equivalent to an NxN matrix) in the first place? Especially when they contain nothing but data that can be procedurally generated in constant time from the input - in contrast to data calculated for e.g. dynamic programming. Given your initial list `xs`, and the value `a` to place on the [0,0 .. N-1,N-1] diagonal of the matrix (0,0 being top left), you can query each point `(x,y)` in the matrix via the function `def matrix(x: Int)(y: Int) = if (x == y) a else xs(x)`. Constant time for querying (e.g. `matrix(2)(1) == 2`), and you can't get away from O(n**2) if you need to print out the entire thing anyway. The function call overhead can be removed via inlining - supposedly the JVM is quite good at that.
I'm sure this is asked all the time, but I don't see an FAQ or an answer in a cursory search, so would it be useful to learn haskell before learning scala?
In the real version of my example, the "7" being inserted is a variable value for each step forward in the indices. So I may need List(7,1,2,3), List(1,5,2,3), List(1, 2, 9, 3) ... etc. I don't need to pre-generate them all at once, but I do need to call a function on / evaluate each one and then do a comparison to find the max once all have been evaluated. Because of that I don't see a difference between generating and pre-generating, since the result is not complete until all of the evaluations terminate.
I don't know, I died inside when I saw java.util.Date ported...
&gt; Most other programming languages follow this exact behavior: Java, C#, etc. all let you compare values willy-nilly even if their types mean can never be equal Please demonstrate how Java or C# do not respect type safety for equallity. These are type safe languages, Scala included. 
I don't believe equality was ever referred to as type-unsafe. I might have missed it, but the only thing that could be considered ambiguous is when the author talks about the unsafe-ness of equals. I don't believe that means it's type unsafe, just... unsafe in general. The fact that 1 == "wat" compiles is type safe: Any.equals take an Any as an argument, and no type is violated. It's also pretty damn inconvenient, and arguably unsafe: the compiler happily validates code that is never what the author intended. Either he thought the two values he's comparing might be equal, which means he's mistaken about their types, or he knows they won't ever be, and then he should probably not write dead code.
Hi, I studied your code a bit, I have a question. I'm developing a Dominoes game for learning the language and I managed to write the game logic purely functional. I have a "Game" class with a method "playMove" that returns another "Game" immutable object, instead of making playMove with a void return type that updates var fields. My problem is creating a program that uses it. Currently, I'm using a while loop and a var variable: var game = new Game(...) while (game.hasMoreMoves()){ &lt;display board&gt; &lt;receive input&gt; game = game.playMove(...) } My question is: using the scalaz.concurrent.Task package it's possible to have an entirely functional program, even the main loop?
It's not that simple. Consider what happens in a `Map` or a `Set`, now. What governs key/member equality? It's still `==`. First-order typesafe equality is easy to fix. Higher-order is hard without some pervasive typeclasses.
List is a linked list, don't use it where you need indexing operations. Use vector instead
One thing maybe to note is that scalaz task is not great. Monix or fs2 tasks are better, and I have a branch in progress replacing scalaz with cats, and using the new IO type. The CLI module I mostly added as a proof of concept for manually driving the library
&gt; less nonsense, but still I personally consider the `for`-loop filtering worse than the `val`: at least in the case of the `val`, if you screw up you get a runtime error! With the `for`-loop you screw up and some of your data magically disappears but no error. &gt; If foo is overloaded on the type of the second parameter, the currently specified desugaring as y =&gt; foo(x, y) allows the overload to be resolved. Partial eta-expansion would not be able to do so. Would it be possible to allow partial eta-expansion in the case where `foo` is not overloaded? After all, even "full" eta-expansion doesn't work in the presence of overloading: @ def foo(i: Int) = i+1; def foo(s: String) = s+1 defined function foo defined function foo @ foo _ cmd1.sc:1: ambiguous reference to overloaded definition, both method foo in object cmd0 of type (s: String)String and method foo in object cmd0 of type (i: Int)Int match expected type ? val res1 = foo _ ^ Compilation Failed @ foo(_, _) cmd1.sc:1: missing parameter type for expanded function ((x$1: &lt;error&gt;, x$2) =&gt; foo(x$1, x$2)) val res1 = foo(_, _) ^ cmd1.sc:1: missing parameter type for expanded function ((x$1: &lt;error&gt;, x$2: &lt;error&gt;) =&gt; foo(x$1, x$2)) val res1 = foo(_, _) ^ cmd1.sc:1: overloaded method value foo with alternatives: (s: String)String &lt;and&gt; (i: Int)Int cannot be applied to (&lt;error&gt;, &lt;error&gt;) val res1 = foo(_, _) ^ Compilation Failed Since "full" eta-expansion has these limitations already, I wouldn't find it unusual that partial eta-expansion would have the same limitations. I admit, after getting into discussions with people about this, *forcing manual eta-expansion everywhere* is a valid and self-consistent worldview: "methods and functions are separate and we must convert between them", versus my "there are callable and non-callable expressions and both methods and functions are callable expressions" worldview. However, since (it appears) we've already decided to paper over the conversion in many cases with target-typing, I think it would make sense to go all the way and make it work without target typing where-ever possible &gt; It's not at all about the comments, it's about the blank lines! The comments are not meaningful. It's the blank lines that are. And the comment happens to make the line non-blank. Interesting, I never thought about it that way
In Scala, you _choose_ what you want to be reified at runtime. In your case, the function takes `x:Any` so at runtime nothing is known about the type of `x` other than its class (thanks to the JVM). I changed the body in my example because unfortunately, while Scala's pattern matching understands class tags and will use them to check an object's class (this is basically the same as how in Java you sometimes pass `MyClass.class` as an explicit argument to a function that does some `isInstance` test internally), the pattern matching implementation does not currently do anything about type tags. But in your code, you don't even reify the type of `x`, so a `TypeTag` only for `A` is useless here as you cannot access information at runtime that you haven't reified (the full type of `x`).
Huh? The example is not invalid in any way. The fact it raises a warning for some unrelated reason is completely irrelevant to the point I was making. 
not entirely accurate, list outperforms vector for small collections 
For indexing operations? That seems unusual. Can you link me to any benchmarks?
&gt; The presence of a comment in the otherwise blank line makes it so that is not blank anymore! And therefore, there are no two consecutive nl tokens that would break the statements in two. This is explicitly mentioned in Section 1.2: &gt;&gt; Normally, only a single nl token is inserted between two consecutive non-newline tokens which are on different lines, even if there are multiple lines between the two tokens. However, if two tokens are separated by at least one completely blank line (i.e a line which contains no printable characters), then two nl tokens are inserted. &gt; (emphasis mine). Clearly, a comment contains printable characters, and therefore means that the line is not blank. Are you sure this isn't Stockholm syndrome speaking? Wouldn't it be nicer to define a blank line as a line that contains only non-printable characters *or comments*?
Possibly. But then you have other weird things happening: { Foo bar /* starts here continues here ends there */ baz } Now are `bar` and `baz` separated by a "blank-or-comment" line or not? What about this: { Foo bar /* starts here ends there */ baz } ? It seems that those would be quite hard to give any meaning to if we start considering comments too much as whitespace.
Yeah it makes more sense to me that comments are treated as whitespace, so the example { Foo bar /* starts here ends there */ baz } Would count `Foo bar` and `baz` as being separated by a bunch of whitespaces and two newlines
I will probably look at adding a lib directory where by any jars placed in the lib directory are automagically included in the build and run time classpath, but I have yet to learn how scala interoperates with Java...
given: [chris@xpslaptop scalaGDX]$ ls lib/ gdx-backend-lwjgl.jar gdx-box2d.jar gdx.jar gdx-backend-lwjgl-natives.jar gdx-box2d-natives.jar gdx-natives.jar this automagically includes whatever jars happen to be in the lib folder BINd = bin/ SRCd = src/ SRCs = $(wildcard src/*.scala) CLSs = $(patsubst src/%.scala, bin/%.class, $(SRCs)) space := $(subst ,, ) LIBs = $(subst $(space),:,$(wildcard lib/*.jar)) run: $(CLSs) java -cp $(LIBs):/opt/scala-2.12.2/lib/scala-library.jar:$(BINd) DesktopStub $(BINd)%.class: $(SRCd)%.scala fsc -classpath $(LIBs) -sourcepath $(SRCd) $&lt; -d $(BINd) clean: rm -f $(BINd)*.class 
&gt; def ‚àÖ[T]: List[T] = Nil[T]() OMGWHY??
hey, those parameters are used only in the constructor, for example: class Point(x: Int, y: Int) val p = new Point(1, 3) p.x // does not compile to make these public members you have to add "val" before the parameter. So if you don't add "val" the gc will clean these up
Out of curiosity, why do you stay? That seems bad. 
- It's remote, which suits me greatly ( I hate offices, open offices even more so ) - It's much better paid than anything I'd find around where I live. - There are light moments when I get to write some Scala. - There are almost none meetings required to do by me.
Without adding val or using a case class the constructor parameters so not become fields automatically. They just live on the stack so they will disappear as soon as the constructor returns. Scala uses java call semantics so objects are passed by reference value. 
For such use-case Dotty uses a value class that wraps an Integer and gives nice API over it. See: https://github.com/lampepfl/dotty/blob/30fb662f7e68bdd7c16d35c59d967d7660900c69/compiler/src/dotty/tools/dotc/core/Flags.scala#L15 If Int\Long is not enough and you need more bytes, you can use an array. Note that Boolean arrays are stored inefficiently by HotSpot, you may consider doing a byte array instead. 
Nice video. Some comments: &gt; so I was able to leverage Make to make an ad-hoc lightweight pseudo incremental build system WAT. This sounds crazy :) Perhaps describe the issues you had setting up sbt, this gives you incremental compilation for free, and probably more correct than your hand-coded "system". &gt; bodyDef.`type` = BodyDef.BodyType.DynamicBody Note that if that becomes too annoying, you can write an extension method that forwards such call. implicit class BodyDefTpe(private val d: BodyDef) extends AnyVal { def tpe: BodyDef.BodyType = d.`type` def tpe_=(value: BodyDef.BodyType): Unit = d.`type` = value } Then you can just write bodyDef.tpe = BodyDef.BodyType.DynamicBody &gt; A minor irritation was the use of companion objects, even within the class you need to explicitly prefix the companion objects name. Note that in Scala you can always import name spaces from values if you wish: object Global { var x = 1 } trait Global { import Global._ // now you can refer to x without qualification def set(): Unit = x = 2 } &gt; it does seem that Scala is more Object Oriented with Kotlin leaning to functional programming I think what you experienced is that Scala's object system is more versatile. But in general, I would say Scala leans more to the FP side compared to Kotlin. For example, Kotlin has flow-typing `if (x is A) ...` which is more imperative/classical OOP, whereas Scala prefers pattern matching, which is normally considered a typical FP construction. 
Well the whole id is to add some compile time checks. Let's say I have the following : type IceCreamToppingId = String type PizzaToppingId = String def addTopping(toppingId : PizzaToppingId, crustId : CrustId) = ??? then the following will compile val topping : IceCreamToppingId = ??? addTopping(topping, ???) but with trait Tagged[U] type TString[U] = String with Tagged[U] trait IceCreamToppingId trait PizzaToppingId def addTopping(toppingId : TString[PizzaToppingId], crustId : TString[CrustId]) = ??? it won't compile
How could one show that x and y are garbage collected? 
I can live with \`type\` to be honest, its not like that one is used too often! but nice example work a round - thanks! I like you can import namespaces like that again thanks! what really put me off with sbt was it immediately started download boat loads of stuff and it just looks too complex to be bothered with, tbh its just preference, I've used Makefiles with alsorts of languages and not just for building (amazing how you can abuse it! ;) ) I intend a follow up article at some point (much more reading to do first!) so if you have any other idiomatic Scala tips please don't be shy! 
Can you give a bit more information about what you want exactly and why?
Hi Gawwad. Thank you for the recommedation. I used the Play deployment docs as you said. And it worked :O I have 2 questions: - with the java and tomcat app, I needed (maybe) a nginx for the images. With this Play webapp, I didn't have to install nginx, why is that? - to run the webapp,as the tutorial said, I wrote: ./myApp -Dplay.crypto.secret=changed -Dhttp.port=80 -J-Xms128M -J-Xmx410m -J-server but when I exit the console, the process terminated :S So, I run it again with: nohup ./myApp -Dplay.crypto.secret=changed -Dhttp.port=80 -J-Xms128M -J-Xmx410m -J-server &amp; Is there a "cleaner" o better way? Regards edit: format
&gt; sbt new starfleetcadet75/libgdx-sbt-project.g8 call me paranoid but who is starfleetcadet75 and what backdoor has he slipped into your new project ;) I assume with sbt you can just reference jars you place in the project rather than remote projects ? 
Of course, you should always be careful. It's as safe or unsafe as cloning someone's project and running sbt on it: https://github.com/starfleetcadet75/libgdx-sbt-project.g8 &gt; I assume with sbt you can just reference jars you place in the project rather than remote projects ? For a Scala project using Java library your `build.sbt` would look something like this: name := "my-game" scalaVersion := "2.11.11" // or 2.12.2 if you don't target Android libraryDependencies += "com.bla" % "the-library" % "the-version" Don't know what the libgdx artifact is, but I'm sure it's published somewhere publicly, so sbt can pick it up (search here: http://search.maven.org) If you download the jars manually, just place them in a directory named `lib` in the root directory of your project, and sbt will automatically add them to your classpath.
embedding a language in a Scala application: I've used beanshell and javascript as embedded languages from Java - typically in script properties for entities in a level editor, both with great results... Now I could just write Scala in a Java like way and throw Nashorn in there, but I'd far rather have something more idiomatic, the language doesn't have to be Javascript or Scala, but it should have direct access to the public bits of the applications class path... 
Why not use scala as the embedded language?
Easy: replace them with `Array[Int]`s, create a few thousand points each with `new Array[Int](1000000)`s in them, and see if you run out of memory or not. If they get GCed, the JVM can easily hold a few hundred millions small `Point`s with nothing inside. There'll be some churn and pauses from collection garbage, but the program will go on. If they don't get GCed, a few thousand and you'll be OOM EDIT: and if you don't replace them with `Array[Int]`s, `Int`s aren't objects and don't create garbage anyway. They'll just take up space on the existing `Point` objects and make each one 4 or 8 bytes bigger. If you want to see how many fields are on `Point`, you can use `javap -c` on the compiled classfile
Do you mean designing an API with algebraic data types?
You can check this presentation by Debasish Ghosh - Functional Patterns in Domain Modeling: https://www.youtube.com/watch?v=0q-w16pOuyc He also has this presentation - From Functional to Reactive - Patterns in Domain Modeling, similar but bit wider in scope: https://www.youtube.com/watch?v=TiwNrioZoTo
Case classes are meant to be immutable.
Edit: misread your first question. Some webservers serve static files too and some just respond to requests you explicitly handle. If they do, you don't need another solution for images etc. For your second question you should run the web server as a service. Most current linux distros use SystemD, which is pretty easy to use. [Here is an example service file and some environment variables](https://gist.github.com/davidkeen/66c705bae458ef337e4a69372058bde5). Here is a [DigitalOcean systemd guide](https://www.digitalocean.com/community/tutorials/systemd-essentials-working-with-services-units-and-the-journal). I just scrolled through it but DO has great guides so it's probably a great starting point.
I am reading the book FPiS and in part 2 the author shows how to design a API with algebra terms. But the examples in the book it very cluttered and maybe it has a better resources around. With algebra I mean laws etc.
Like for comprehensions? Sorry im new to scala 
For sale: baby shoes, never worn I'd be impressed if it could better that! (https://en.wikipedia.org/wiki/For_sale:_baby_shoes,_never_worn)
Then why is the `var` prefix allowed on case class constructor parameters?
Scala is fine as an embedded scripting language (it's available with JSR-whateveritis, you just pass "scala" as the language). You have to explicitly expose any variables you want the embedded script to have access to, for good reason - I don't think there's any way around that.
Backward compatibility
You need to show an example that actually produces the error before we can really help much. See if you can reproduce it on scastie and link to that.
I can't stand SBT but Maven works wonderfully with Scala (provided you don't need to cross-build against multiple Scala versions i.e. provided you're not making a library for public use). In Scala a lot of the time the idiom is to work with `case class`es which don't require `new`. The cases where `new` is used should stand out and indicated that something different is happening in that code. Of course that breaks down when using a Java library. Scala might be more OO than Kotlin but it's a lot more functional than Kotlin once you get deeper into it - all the stuff that HKT enables, properly parametric handling of absence via option.
Another excellent piece. Conflating total destructuring with partial pattern-matching is the biggest problem - making it so you can't tell locally whether the code you're looking at is safe or unsafe is really bad. Terribly, the "multiversal equality" proposal recapitulates the same error - if it's adopted, `==` will be safe most of the time, but horribly unsafe often enough to cause trouble.
I embed Scala in various desktop applications of mine, it works flawlessly (the "interpreter" is a bit slow responding compared to a real interpreted language, but is "ok"). - https://github.com/Sciss/ScalaInterpreterPane (this project is used in the other two) - http://sciss.github.io/ScalaCollider/ - http://sciss.github.io/Mellite/ 
honestly, all this does is complicate the collections library for the sole benefit of appeasing a vocal minority that likes to bash about suicide notes on stack overflow. a vocal minority that most probably doesn't like scala, doesn't understand scala, and doesn't actually use scala. `CanBuildFrom` was an elegant, powerful, and flexible solution. we can learn a lot by studying the design and rationale behind it. its only drawback was the mark it left in the method signatures, something that can easily be ignored almost all the time and even be exploited to our own benefit (see `collection.breakOut`) and now they are replacing all that elegance and power with a mess of branches on top of branches on top of overloaded methods... a sad change, imho
Note that the new design's more ad-hoc approach seems to be [less powerful](https://github.com/scala/collection-strawman/issues/44) than the old approach. In order to do things like implement `traverse`, you'll now have to rely on views and explicit builders, which you could pretty much already do before, in the old design. Also note that using `view` to replace `breakOut` as proposed in the article is likely to be less performant (trading internal iteration for external iteration). So the main thing the new design seems to achieve is: 1. remove implicits from collection operations by using overloading and a trickier class hierarchy instead; and 2. limit the scope and extensibility of old-style collection programming patterns (which were based on `CanBuildFrom`). So IMHO this proposal does not simplify much; rather, it mainly removes some advance uses. Since that will break a bunch of code with little benefits, I'm not sure I'm in favor of the proposal. At this point, I think it would make more sense to focus on some [Scala Platform](https://www.scala-lang.org/blog/2016/11/28/spp.html) third-party library that takes a saner approach at collection programming, without all of the overengineering. The stated purpose of this redesign effort, which was to come up with simpler collections that would be _mostly backward-compatible_ and with the same kind of _crazy capabilities_ as in the old design, always seemed like a long shot to me.
&gt; In order to do things like implement traverse, you'll now have to rely on views and explicit builders, which you could pretty much already do before, in the old design. Having implemented `traverse` with the old design, maybe it's possible but it's certainly not the way you're guided. I actually ended up with a subtle bug because I used `CanBuildFrom` the "obvious" way, and missed the non-explicit mutable builder, meaning my implementation broke when used with a continuation-like monad. &gt; 1. remove implicits from collection operations by using overloading and a trickier class hierarchy instead I don't think the proposed class hierarchy is trickier; it might make for more classes but those classes seem pretty clear. I agree the main difference is replacing the implicits with overloading. I suspect that's going to be simpler to use, particularly when it comes to things like error messages.
I'm struggling with the same problem. There is also React4s which is quite neat (https://github.com/Ahnfelt/react4s). But for all the abstractions and additional features I keep wondering if it's worth it. Has anybody used the simple facades from https://definitelyscala.com/ ? I like the idea of not having an additional layer of features and abstractions on top of react, but I'm also afraid that the simple facade might be a pain to use. 
but why REPL type inference only tells it's a concurrent map? for 2nd question, i'm using `TrieMap` map now. However the scaladoc seems really strange that it suggests using a java concurrentHashMap, which took me quite a long time to figure out I could use scala collections like `TrieMap`. What's the rationale for suggesting using java concurrentHashMap, which is neither *scala idiom* nor a replacement of trait *SynchronizedMap*?
hmm, so if its "wrong" for you its wrong for every one else ?
If Tomcat is being run as a Java process, and not as root, it shouldn't be able to bind to port 80 in a *nix environment.
Definitelyscala appears not to have redux. Would be interesting to see if they publish their generator. Finally, for me I'm definitely interested in native support. The initial attraction of SRI was that the project creator has figured out the steps to get scala js to work with react native.
Thanks for the the contributions! This is super exciting. I've been thinking: if sbt's gonna have a json-based dependency lock file, why not define most of our dependencies in a package.json-esque file? I think it'll be far more accessible for newcomers, who are familiar with environments that use json for dependency management. For what it's worth, I'd be open in exploring this issue in sbt‚ÄîI'm not just yelling about nice-to-have features!
As /u/teknocide describes, `A` is contravariant, so AnyRef is more specific than a tuple `(A, B)`. It may seem like making `A` contravariant is the right thing to do since `A` appears in the contravariant position. Instead I would suggest making `PrettyPrint` invariant and defining a contravariant functor for `PrettyPrint` instances instead.
Okay, I see: I should use `getClass` to see the real type. For `SynchronizedMap`, I still think the scaladoc is a bit weird: it could mention `JConcurrentMapWrapper` or `TrieMap`.
A guy in [this blog](https://blog.scalac.io/2016/05/26/simple-types-in-play.html) considers the same problem and some of possible solutions
You can use [Ammonite](http://www.lihaoyi.com/Ammonite/) quite easily to expose scripting capabilities in your Scala code: either via a REPL, or by loading scripts and running them. Ammonite deals with all the caching and classloader stuff, and you can pass in your own objects for your script to deal with and return values from your script via the `exit` builtin. Nevertheless, there are many good reasons why you wouldn't want to use Scala as a scripting language: the compiler is terribly slow, especially on first run, and doesn't really function with anything less than 300-400mb of memory (!). Caching removes both the compiler speed and memory usage problems when you run the scripts repeatedly, and Ammonite does this for you automatically, but the slowness and memory usage will always be there when you change their code. Perhaps it doesn't matter to you, but perhaps it does. If so, JRuby or Nashorn or Groovy are probably better fits
A monoid homomorphism f: M -&gt; N between monoids M and N is a function such that f(m_1)+f(m_2) = f(m_1+m_2) and f(0_M)=0_N. A monoid isomorphism is a monoid homomorphism that is both injective and surjective. Injective means that if m_1,m_2 in M and m_1 != m_2, then f(m_1) != f(m_2), roughly that different elements in M map to different elements in N. Surjective means that for every n in N, there exists some m in M such that f(m) = n, so every element of N is the result of applying f to some element of M. `Char` with concatenation is not a monoid, since for example `'a' + 'b'` isn't a `Char`. I think you mean `List[Char]` with concatenation. From here, can you prove by yourself why `String` and `List[Char]` both with concatenation, and `(false, ||)` and `(true, &amp;&amp;)` are isomorphic
I don't understand what you're doing in the second example, is there a tutorial somewhere that would explain it in detail, it look like a bit of Scala I should really know! 
doesn't help with readability, the quicker a human can scan through code, I find aids in maintenance years down the line no end... Is the language for our convenience or the compilers ?
The thing is `for` isn't really a standard loop and iterating over a range is pretty uncommon in Scala. (also, remove the `var` ;)) `for (x &lt;- something) yield x` where `something` is an instance of a type with `.map` and `.flatMap` methods is a syntactic sugar for the expression `someType.map(x =&gt; x)`. In other words its contract isn't that it iterates over sequences specifically.
I've looked at a number of solutions and you might hate me for this but by far the easiest has to be Nashorn If anyone is interested I made a quick test import javax.script.ScriptEngine import javax.script.ScriptEngineManager import javax.script.Invocable object nashorn { var script = """ var afunc = function () { var nashorn = Java.type('nashorn'); // the class/objects var result = nashorn.test('string from js'); print("in js Scala returned "+result); return 'js retured string' }; print('functions evaluated and ready!'); """ def main(args: Array[String]) { var engine: ScriptEngine = new ScriptEngineManager().getEngineByName("nashorn") engine.eval(script) var invocable: Invocable = engine.asInstanceOf[Invocable] var result: Any = invocable.invokeFunction("afunc", "a string from scala") println(result) } def test(m: String): String = { println("test (in Scala) called with "+m) "string from Scala" } } 
Do I need to understand `isomorphism` and `homomorphisms` to programming in scala?
It is like category theory. I can not prove it, why `String` and `List[Char]` are `isomorphic`. $ I do understand the theory, but do not know how to prove it. Consider following code: scala&gt; "test".toList res3: List[Char] = List(t, e, s, t) It looks like `isomorphic` right? 
("test"+"s").toList shouldBe List('t','e','s','t') ++ List('s') (List('t','e','s','t') ++ List('s')).mkString("") shouldBe ("test"+"s")
When I read the book FPiS, why the author mention it?
Ah. I have to improve my question. Do I have to understand `isomorphism` and `homomorphisms` in FP?
Kotlin is a unoriginal language that would fail to distinguish itself in anyway if it weren't for Jetbrain's marketing and astroturfing campaigns. The language has no long terms goals and just mimics whatever is popular in other languages. Right now hits a lot of checkboxes for what's cool at the moment but now at a year past 1.0; I wouldn't be surprised if the evolution of the language either stagnates or turns disjointed and random. I had a discussion about it [here](https://www.reddit.com/r/java/comments/4an7xb/kotlin_a_new_jvm_language_you_should_try/d11tspf/?context=3) a year ago on /r/java that seems to be just a relevant today.
It depends on what you want to achieve. If your wanted result is an aggregation of an operation over the range, like when summing, you want to use `range.sum` or a more generic variant like `range.foldLeft`. If you're working with say a `Seq[String]`, grabbing the indexes and then performing a lookup based on that index (like what you'd do in Java with `for (int i=0; i &lt; stringList.size(); i++) { String item = stringList.get(i); &lt;do stuff with item&gt; }`) is in most cases less efficient than simply mapping over the list like `for (item &lt;- stringList) yield doStuffWith(item)`. If you actually do want to work directly with a range, using `for (x &lt;- range)` isn't too bad, but a simple `while` loop will probably be more performant. The point being that there are reasons for not having the `for x in xs` syntax. To me it doesn't accurately represent what a for-comprehension is all about. Perhaps the syntax as it stands makes more sense if shown in a context like val as = List(1,2,3) val bs = List(4,5,6) val cross = for { a &lt;- as b &lt;- bs } yield a * b
You don't need to understand ```(iso/homo)-morphisms``` to program in Scala. It supports plain old imperative/oop style very well with lots of libraries and all the stuff you need, far far away from any algebra/category concepts. But, unlike almost every programming language, except Haskell and dependent languages, it is possible and even often useful to use these concepts. So many people do (basically the typelevel community).
What is your client doing? 
i couldn't agree more; kotlin is probably the most "me too" language i've ever seen.
Start with a homomorphism. It is a simple function `f: A =&gt; B` which preserves "some structure". This structure can be a semigroup, a monoid, a group, a ring, ..., often described in terms of the operations you can do on types `A` and `B`. Sometimes people simply write "morphism". Isomorphism means you can go back and forth: complementing your function `f: A =&gt; B`, there is another function `g: B =&gt; A` such that `g(f(a)) === a`. For example, you can go from a `String` to `Seq[Char]` and back. By doing so, you preserve the monoid structure (i.e. what is concatenation and the empty string, see rgcase answer). The types `BigInteger` and `BigInt` are also isomorphic: there are functions to convert from one to the other, and you preserve all ring operations doing so (+, -, *, the elements 0 and 1). I haven't seen much uses of these concepts in Scala. I'm starting to introduce homomorphisms in Spire for testing purposes. Start by understanding the algebraic structures in Cats/Algebra/Spire and the related laws. Use Wikipedia if you need to know a bit more about groups/rings and the like.
There are a few different teams. Some are working on one of the backend applications that manages a lot of the data (Scala), one is a team working on a new projects which will be public facing (Kotlin, I'm not allowed to reveal too much with NDAs etc), and then a variety of their web applications are in Java but looking at moving them around. 
Do you not think it will have a pickup in the android market then? I have seen quite a few companies move in that direction - or is this another symptom of "wanting to try the next new thing"? Thanks for the link to the post!
So it useful to know these concept and I will be a better programmer right?
Can appreciate hiding CBF signatures from end users, but I was under the impression that 2.13 collections overheaul was largely meant to streamline the collections library, not add more to it. On the JVM the size of existing collections library is manageable (just disk space) but in the browser and in some native targets collections should be as small as possible. Scala.js' out of the box "tax", for example, is around 160KB, roughly 50% of which is due to the collections library alone. Maybe these are just the first steps. Hoping to see deprecations and removals (where possible) in order to streamline collections to the point where browser and native targets are not saddled with unnecessary weight. That, or open the door for alternate collections implementations as [LPTK](https://www.reddit.com/r/scala/comments/6e75jc/tribulations_of_canbuildfrom/di8c3bt/) brought up.
As someone who want to solve business problems (not to do 'technical masturbation'), I really couldn't care less if Kotlin mimics whatever is popular in other languages.
It's very strongly positioned for Android, by far it's biggest strength. It's the only sane choice for not hating life on Android. Scala's too heavy/fp for Android. Kotlin's minimal "better java" approach is much better within the hardware constraints. I say this as someone that's done Scala for 7 years and finds Kotlin relatively uninspired.
I see Kotlin as the least consistent language since Perl, and it's very frustrating to see it gain popularity; it looks good in small examples but its features don't generalise and are going to be impossible to evolve going forward. I predict Kotlin 2.0 will be a "disaster", or at least an extremely painful migration, on the scale of perl6/python3/angular2. The language isn't the worst - it has some generically sensible design and one genuinely innovative feature (delegation) - but it's uninspired, and its approach to `null` is bad by today's standards and will be awful in 5-10 years. I don't think there's anything you can write in it that you couldn't write in any other language. Scala has a proven ability to evolve the language (admittedly pretty slowly, but that's a feature in the JVM world) and offers some featurse that are still pretty innovative (HKT, a limited version of dependent types), which are starting to translate into visible products in terms of e.g. Spark and Kafka. I've been working in Scala for 6-7 years now; I'd consider a job in Haskell and would actively seek out one in Idris if anyone's using that yet. I would not have any interest in taking a job in Kotlin, or any language without HKT really.
I don't know about "supposed to". A few people were pushing Swift for general-purpose programming. I don't think it'll ever catch on outside iOS though, not because there's anything particularly bad about it so much as there's no compelling reason to use it over the alternatives. And I think/hope it'll be the same for Kotlin.
I don't like the symbols but I think adding an alias would be worse at this point - bad but consistent syntax is better than inconsistent. What Milyardo said is right about the `PhysObj` thing, but if you're willing to go deeper into the purist functional world I'd point you towards the [reader monad](http://eed3si9n.com/herding-cats/Reader.html). Which is basically just an standardised version of that `Physical` type that allows you to compose `Physical` functions using `for`/`yield` syntax: def move(obj: PhysObj, force: Vector3): Reader[PhysContext, PhysObj] = Reader{ context =&gt; ...} def moveThreeObjects(obj1: PhysObj, obj2: PhysObj, obj3: PhysObj, force: Vector3): Reader[PhysContext, String] = for { newObj1 &lt;- move(obj1, force) newObj2 &lt;- move(obj2, force) newObj3 &lt;- move(obj3, force) } yield {"Moved all these objects"}
I don't see how this is any different from using Scala? Just do `getEngineByName("scala")` and write `script` in Scala rather than in javascript.
&gt; Do you not think it will have a pickup in the android market then? I think it'll pickup marketshare there if that's what you're asking. I don't know if it'll give the language a well defined mission it's currently lacking. If it does become defined by the needs of android ecosystem development, then that'll be an improvement.
I don't see what this contributes the conversation, as 'someone who solves business problems' does kotlin not having a well defined mission or business statement trouble you at least?
I assume Shapeless is going to benefit from implicit by name parameters. It seems to overlap with its Lazy typeclass.
&gt; whether the conversion preserves the "hash map" feature What does this mean, concretely? You have something that conforms to the `concurrent.Map` interface; you don't have and shouldn't need direct access to its internals (e.g.`ConcurrentHashMap` won't let you access the hash table directly).
Native support will allow shapeless to remove the `Lazy` workaround, I would guess. Which is cool and to be encouraged, but at the same time not really a game-changer.
There's nothing wrong with copying what works elsewhere (indeed my biggest issues with Kotlin are the cases where it didn't). But you should care about whether a language has a coherent design, because that's a strong indicator for how well it's going to be able to evolve going forwards. Every time I've told myself "it's ok to use this ugly misdesigned thing because it solves my business problem" the thing has ended up being more harm than good.
i mean it's *not* something like `scala.collection.mutable.TreeMap`
SBT has unreadable, unsearchable syntax. This is pretty much unfixable; breaking compatibility yet again would not be popular, adding an alternative syntax without removing the existing one would lead to even more inconsistency in build definitions. I don't know much about CBT. I stick to maven (if you really don't want to split standards you should too) and live without cross-building; if I find myself really needing it I'll have to figure out a way to add it to maven or something.
No, but they will help connect dots. 
I don't find the syntax more unsearchable than lots of other Scala syntax, with `++=` `|@|` or `&lt;&lt;=` etc. Could the same argument not be applied to avoid programming in Scala then? btw they deprecated lots of weird syntax like fishbone operators btw2 i upvoted you because i think it is a valid opinion with fair points, albait so far I disagree with.
I mean that I need assurance that the keys are actually stored according to hash function internally, there seems nonsense to argue further IMO.
Yeah, it's not great. In an ideal world, I'd prefer using s-expressions over JSON, but everybody knows JSON and the sheer breadth and reach wins out over a technically better configuration format. I say this as an OCaml/Rust user, where I've found myself longing for the familiarity of package.json-based workflows.
&gt; doesn't help with readability It's not an issue once you get used to it, say after a week. It's not like anyone as born being able to read any kind of for loop. &gt; Is the language for our convenience or the compilers ? Nice non sequitur there. :)
My body is ready.
The severe dislike most here express against Kotlin just seems ridiculous to outsiders like me. Why would I care about any mission? For me, Kotlin is just the better Java, improving it in many aspects. 
So many cool new features/improvements. I'm really looking forward to when Scala 3 is released. What can it be, 1-2 years away?
Uh, what is wrong with Kotlin's approach to null? That it's not an algebraic data type enforced by the compiler?
Makes sense. Coming here from the same thread posted on /r/Kotlin, where I can find no hospitality against Scala at all, the rather harsh critic I read here came off quite elitist though. 
&gt; and live without cross-building Do you mean cross compiling scala and java? That is easy in maven.
Scala 2.13 is next, so maybe 2019 if there aren't any major development setbacks/blockers.
but I think shapeless needs some major rewrites when type projections are removed
There aren't any medium blog posts about "Company X Abandons Kotlin", posted on /r/programming and /r/kotlin, because the language is new and in the early-adoption phase. Kotlin is not the #2 language on the JVM, so no one bothers to attack it. There have been plenty of Kotlin supporters attacking Scala, at least every month, for the last few years.
I'm certain they mean building the same codebase for multiple versions of Scala, e.g. 2.11 and 2.12
"Quite elitist"? I believe that it is a very good, healthy and beneficial thing if languages are discussed and criticized openly, especially if the participants are honest, and this is on /r/scala, not /r/programming or /r/kotlin, so it is fairly self-contained. The reason for this is that criticism and discussion can among other things help determine weaknesses and strengths of a given programming language, guide the future development and evolution of the given language, help getting greater understanding of programming languages and their properties, and guide future designs of programming languages - and of course help guide people whether investing in a programming language makes sense for them (and the cases they face) and/or in general. I think it would be beneficial to Kotlin (assuming it has potential), as well as programming in general, if the Kotlin community has at least some openness for general criticism, and not just criticism under certain (very) limited constraints. And this matters, because programming can in several regards frequently be very difficult and challenging, including for common domains and fairly typical applications, at least if you want it to have fairly basic and core properties, such as maintainability, sufficient performance, reliability, correctness, the functionality needed for the given application, security, etc. I therefore think it is potentially a bit problematic to as such argue against open and honest criticism. And I am not quite certain why you (at least to me) seem to be doing so.
Fixing thing right now ;-).https://github.com/scalacenter/scastie/issues/217 The issue is that Dotty is changing too fast for ScalaMeta :P (they reimplement the Dotty parser). I use this library to provide the worksheet mode.
The internals are encapsulated by design. Why do you care what they are? What's your actual requirement here?
&gt; Could the same argument not be applied to avoid programming in Scala then? Yes, and I would agree with it. If there were a decent language that didn't use the symbols I would switch to it. For the moment Scala has compelling advantages over every alternative; few languages have HKT and I find laziness impossible to work with. But the day I can get paid to write Idris, I'm gone. 
As /u/zzyzzyxx says, I mean building against multiple versions of Scala, e.g. building a `_2.11` and `_2.12` jar. 
&gt; the syntax problem has been fixed, years ago, in 0.13. Now you have exactly 3 operators to remember: :=, += and ++=, two of them having the same meaning as Scala collections, and the third one being standard Scala DSL for "assignment" (plus it means assignment in Pascal). False. At an absolute minimum I remember SBT 0.13 builds making extensive use of `%` and `%%`. &gt; The last time sbt significantly broke compatibility was in 0.10 wrt. 0.7. I wasn't even aware Scala existed at the time. sbt breaks compatibility less often than Scala (and maybe even than Scala.js). 0.7 -&gt; 0.10 was a much more complex and difficult migration than any post-2.8 release of Scala. If you didn't have to deal with it then lucky you. 
Oh yea.. haven't tried that in Maven. 
That all the null-handling stuff is a language-level special case that doesn't generalise at all, and when used with generics it breaks parametricity because it doesn't compose properly. Nullable ends up behaving as [almost](http://wiki.c2.com/?AlmostCorrect) a generic type. 
&gt; False. At an absolute minimum I remember SBT 0.13 builds making extensive use of % and %%. OK, fair enough. I tend not to count those.
Indeed, I understand your frustration. But I thought haskell has a lots of custom dsls... would situation not be similar with Idris?
Is there any use case for doing it in business-line-of-code? I dont see any... only for libraries ... (?)
That was meant as gentle ribbing :) scalafx is more readable than javafx by a good margin imo. 
What about `~=`? I can't even [find documentation](http://www.scala-sbt.org/0.13/docs/Combined+Pages.html) on this operator, but it seems to be the only way to filter settings.
It may work but I don't think it looks nice. There's a dangling trait and I can't see a reason for why it should be ok to mix in defs into enums but not define them directly in the body. Sure, I can work around this by defining the enum as an "enum class" accompanied by a companion object but that's what the post you responded to was talking about: it doesn't feel very ergonomic to me. 
i dunno if i've written it appropriately or not. i just tried doing it and it worked. you can tool around with it in scastie and see if you can make a better definition. that being said, the enum body doesn't seem to allow defs within
So the distinction is that .foreach, .map. .foldLeft, .collect etc are all about internal traversion: you give it a function and it applies that function to all elements of a sequence. That's key: All elements. You don't remove elements as you go along ‚Äî you probably wouldn't be able to anyway since most of the default collections are immutable. If you're using .foreach you can always skip processing of an item if it matches some criterion by using an if-expression, but you can never mutate the collection you're working over. If what you're looking for is a way to filter a collection, removing certain items, then `.filter` is your friend: List("This", "is", "a", "test") .filter(word =&gt; word.length &gt; 3) // List("This", "test"); can be shortened by using .filter(_.length &gt; 3) `.collect` can also be used and is nice if you want to do a filter and a map at the same time: def isOdd(n: Int): Boolean = n % 2 != 0 val numbers = Seq(1,2,3) // odd numbers are inverted, even numbers are removed. val res1 = numbers.collect { case n if isOdd(n) =&gt; -n } // odd numbers are inverted, even numbers are doubled. val res2 = numbers.collect { case n if isOdd(n) =&gt; -n case n =&gt; n * 2
the performance differs.
More experimentation means more ideas. SBT evolves slowly, and incrementally, and a strong competitor could mean a ton of free ideas that SBT maintainers could copy without needing to put in all the effort experimenting themselves. I think that saying "With SBT we have at least identified [the problems]" isn't accurate. There are lots of *complaints*, a lot of "obvious bugs" that should be fixed, and a lot of good research on how to improve things (like the linked work). But I think we're a long way from seeing a broad, agreed-upon consensus of what needs to be done. Lastly, there's still the chance an alternative like CBT could be "better". After all, you presumably think SBT is "better" than what came before it! Unless we've reached the [End of History](https://en.wikipedia.org/wiki/End_of_history), there's no reason to think that the current SBT tool + incremental improvements is the best we're going to get.
Notably, that's *exactly* the syntax I chose when writing nested "case classes" in my Python macro library: https://github.com/lihaoyi/macropy#case-classes @case class List(): def __len__(self): return 0 def __iter__(self): return iter([]) class Nil: pass class Cons(head, tail): def __len__(self): return 1 + len(self.tail) def __iter__(self): current = self while len(current) &gt; 0: yield current.head current = current.tail 
My team would fall under 5/6 on that list. We use a lot of projects from the typelevel project (cats, eff, http4s, doobie, circe, shapeless) and are quite happy with them most of the time. I really like how well all of those libraries compose. It is however important that the whole team is on the same page, i.e., it does not work that well if half of the team wants to do pure FP and the other half does not see the point. 
Sure. If we have one more alternative that's fine, as long as there is not explosion of tooling like in Javascript ecosystem. My point is our first assumption should not be to rewrite everything, but work on fixing stuff as well. If a competing tool emerges, that's fine.
It seems to follow the db normalization levels, where up to 3 or 4 it's really useful but after that it's completely nuts. :D
I work in a large team (hundreds of developers on the codebase); you might consider me a 6 (I maintain a scalaz/cats-like library internally that goes as far as monad transformers and free monads) or a 4 (I've never seen explicit sequencing of I/O as worth it, at least for simple operations like appending to a log).
Fair enough; in that case bear in mind that a lot of the scala collections are implemented quite inefficiently even when they theoretically should be high-performance for a given use case. But yeah in this case the result is just a wrapper that delegates to the underlying java `ConcurrentHashMap`, as the parallel thread said.
Full rebuilds in IntelliJ are fine but error highlighting isn't perfect, whereas `sbt ~compile` always works (and runs wart remover).
`~=` IMO should be deprecated. It's still convenient, and I believe that's why it was left undeprecated, but it confuses people for no good reason. Moreover, it has some limitations (it does not accept `.value` in its right-hand-side), which means one has to fallback to `:=` anyway in some cases. As far as documentation is concerned, it can be entirely defined as: someSetting in SomeScope ~= f is equivalent to someSetting in SomeScope := f((someSetting in SomeScope).value) i.e., it *transforms* the specified setting through the function `f`. Since it literally *desugars* into `:=` with only ever so much boilerplate, I would be in favor of removing it.
Sounds like a good team collaboration ! Thumbs for nice sharing culture :+1:
Maybe not better but you'll have more diverse tools in your toolbox
I think you missed the issue I'm having with actually avoiding mutability I want a singleton but the values are not known until a fair way into the apps initialisation. I'm thinking of making the fields private with only public getters, its a shame you can't control when a singleton is created and have a specific means of setting its vals when its created.... you don't always know immutable values at compile time 
what about a mutable list that actually needs to have items added and removed... you may well want to remove items as you move through a list checking for a removal criteria it seems very wasteful to create a new immutable list from a filter of an old list then throw away the old list.... and isn't recreating a whole list rather than dereferencing a node on a list, not slower too ? I'm not arguing or saying you are wrong, just trying to understand ... 
Well, an object singleton is created the first time it or one of its fields are referenced so theoretically you could have it fetch values from some other global mutable singleton but then what's the point? You'll have to mutate the global object at some point no matter. I don't think this is a shame; it's a bad solution to a problem you probably don't have in the first place. "Singleton" is a very generic term and it basically means "a single instance". If you create a single instance of something at the start of your application and then inject it where it's needed, that instance is for all practical reasons a singleton.
Out of interest what class would Akka style be ? Say i was using Akka Streaming / Event sourcing / CQRS / Akka http / Play framework. Also, say i was using Spark (typically the style from the books on Akka / Spark) what category do they fit ? 
You may want to do that ‚Äî and it's possible with a while loop, for example ‚Äî but it's not the recommended way to do it if you don't have very specific performance requirements. Immutability comes with a bunch of benefits that helps with reasoning, asynchronicity and memory reuse. You'll never have to make a defensive copy of an immutable collection in case something else would mutate it down the chain. I think at this point one realisation that's important is that Scala isn't Java, nor is it Kotlin. If you want to learn Scala you need to embrace not only the syntax of the language, but also the way the language and standard library is designed. If not you'll end up trying to force Java idioms into a shape where they may not make sense.
Is the extra `trait` necessary? Seems a bit unfortunate if so.
I hope to have one open sourced soon. Just waiting on a legal release that's taking forever. 
Advanced Cats with Scala was awesome but a bit out of date, hopefully we can start to update it and finish the use cases now that it's open
I'm not sure about that, type projections are not necessary for most of functionalities implemented in shapeless. Actually there was a change (or fix, depending of how you want to look at it) in type inference that removes the need for the `Aux`pattern. In theory all of shapeless type classes could be rewritten more concisely using path dependent types.
&gt; &gt; java-ish : scala a much better java &gt; java-ish + scala/FP : mix of OOP + FP elements - avoiding nulls, Higher order functions &gt; functional level 1: majority FP, monadic, functional error-handling, composition ) I would say between 1 to 3.
Will Dotty have structural typing system? Is it be similiar to TypeScript (the type system)? 
2.5.. perhaps better described as a Pythonic approach to Scala. I mostly got into it for Akka but stayed for the elements of OCaml and Python I like while sitting on a JVM. My use is primarily academic for my graduate work. In my day job I just sling data with SQL.
You're welcome! X)
Advanced Scala was recently updated to Cats 0.9. We sent out an email when the update came out, but not everyone saw it I guess. (I know a bunch of people sign up with invalid addresses, which is fine, but it does mean they miss out on update notifications.)
Yay community! :)
Between #2 and #3, I guess. While I have a good grasp on category theory and the like - I have a maths degree after all - I haven't found much use for it, yet.
Hm, isn't that just the Liskov substitution principle? That doesn't have anything to do with Scala in particular‚Äîthe same rules apply to Java. More generally, most of the "do this" ideas in Scala are based on standard best practices in the industry: * You use immutable objects because they are guaranteed to not silently change after being passed to a method or even from another thread that holds a reference. * You manipulate collections with higher-order functions to express what you want rather than how to do it, and to avoid things like off by one-errors. * You don't use global mutable objects because they are anything from hard to impossible to test due to race conditions and the reasons for immutability mentioned above. * You usually want functions (including methods) to return a concrete value rather than void (Unit) because that facilitates unit testing without complicating things with mocks and stubs, and it makes them composable which means you can create a bigger functions out of one or more smaller ones. * A specialisation of this is referential transparency which also adds the requirements that a function should not perform any side-effects. Side effects in this context are things like silently mutating state, or reading data from a source not included in the function arguments or otherwise directly accessible in the function scope. The goal of this is to guarantee that for some inputs `x` and `y`, the result will always yield the same `z`. The expression `1 + 1` will always yield `2` which allows us to replace the expression with its result type if we know the input parameters beforehand. * In OOP, dependencies should be injected through the constructor. To begin with this is the only proper way to initialise an immutable object (reflection doesn't count), and it clearly shows the dependencies of an object which is helpful for discoverability. There's a ton of guide-lines and opinions on what's best. Building a knowledge-base‚Äîand personal opinion‚Äîis to me all what programming is about, but I believe the ones I've listed above are generally agreed on across most languages. At times you may decide to ignore one of them as long as you are aware of the trade-offs. 
Thank you!
I personally prefer a combination of 4 and 6, but the majority of my team comes from a C# background and has some difficulty getting from 2 to 3. When I wrote something mostly in my own style I received a review comment along the lines of, "this is really clean code with pieces that are easy to reason about; I have no idea how any of it actually works". So for now I try to stick around 3 and only use 4 in library code where it's most useful. That seems to be a reasonable compromise that allows everyone to maintain something while still learning.
That's what I was thinking how this feature would be implemented! I've said earlier in this thread that I've got a preference for using JSON due to it's ubiquity. Ideally, most users shouldn't need to deal with build.sbt.
I wonder how to properly log correlationId in Scala. In Java natural way would be just to put correlationId to MDC and in Scala I saw posts that suggest the same (e.g. https://stackoverflow.com/a/28369431). I don't like this approach for two reasons: - in case of async computations custom execution context is needed, but more importantly - correlationId value is not present in the function signature and then it's taken out of thin air which does not feel good given functional programming ideas I think that passing implicit correlationId (case class) would better fit to Scala way of doing things. That would require writing custom wrapper for slf4j though (if anybody is interested in something like this, I can do it). What approach and which logging libraries do you use for things like this? 
Trivial example: `def foo[A](a: A): Boolean` can only (if it terminates) be constant `true` or `false` in (the scalazzi safe subset of) Scala, whereas a notional safe subset of Kotlin would allow (please excuse any syntax mistakes) `def foo&lt;T: Any?&gt;(t: T) = t == null`. More seriously imagine implementing safe access to some resource via something like `def acquireResource(): Option[Resource] = ...; def access[A](f: Resource =&gt; A): Option[A] = acquireResource map f map {a =&gt; releaseResource(); a }`; in Kotlin if `f` returns `null` (which is legitimate) then the resource is never released. You can say that nullable types shouldn't count for parametricity, but in that case nullable types aren't first-class and you can no longer claim to have a unified type hierarchy.
I'm part of (and run a small chunk of) a very large Scala team at Verizon, and I can say that the *best* way to write code that scales out for a large team is 5/6. Now, the vast majority of folks on our teams would not even identify themselves as functional programmers and couldn't explain what 80% of the code does in Scalaz, but it doesn't *matter*, because they can look at the types of a library and figure them out. You don't need to know the mathematical inspiration nor the clever inner workings of a particular monad to get how it can be useful. 70% of the code we write is pretty boring. Sometimes a few of the more advanced engineers come up with some very interesting abstractions, but we don't need everyone to do that or even able to. So being able to *use* pieces of Scalaz here and there has been a huge success. 
But why not both ? I don't understand why would you value more learning a "new" language as Kotlin, which just means learning new syntax, rather than learning advanced programming techniques (which can be then applied to any language). Don't get me wrong, I am not saying that everyone HAS to learn it, but on the long term it's more empowering to know category theory and how to apply it rather than just another language.
not enough time. I would rather learn crypto currency / or big data /server side (hence the Akka im looking at), things more closer to the application side. Also its very niche, and niche means fewer jobs (look at Haskell for example). i like learning new things but at the same time want to make sure those things keep me in a job, and also be able to move jobs for whatever reasons. Its good to be able to have multiple language skills these days, maybe having Kotlin + Golang + Scala , is better (job wise) than just Scala + category theory + type level. I try not to get too attached to languages, there just tools at end of the day, lots of programming out there is debugging / maintenance, if your lucky you might get to do "greenfield".
No, I am not qualified to make any comparisons since I barely know Kotlin and did not use Scala at all, yet. I cannot follow you on where I discredit arguments against Kotlin. However, one of the commenters I was referring to has now followed up with a more detailed and sincere explanation of his opinion, where he also explains why he feels strongly about Kotlin. I appreciate that. What I mean with not being able to follow you about discrediting arguments is that this was never my intention. I wanted to comment on the emotional component and tone of conversation, I don't think I criticized any specific argument against Kotlin. Maybe I did not accurately express myself, but I can assure you that my comments are quite sincere. I am very open to Scala, and definitely plan to check it out soon. What upset me and caused me to comment was the aforementioned rather harsh critic about a language that seems fairly modern and an overall improvement over what I use day-to-day. After reading a few comments, I understand that the specific comments I mentioned were influenced by a frustration about Kotlin that was caused by people not knowledgeable in Scala making uninformed claims. I can understand this frustration - when there is a better, but more radically different solution and people don't adapt it because it's different and then settle for a less-different but in general worse language, that's understandably frustrating. I believe that quite some of that frustration was clearly visible in the comments. Now, I am not leaning against believing the specific arguments that were brought up, but the hostile tone of some of the comparisons made me unsure about how much I can believe in the objectivity of the comments in general. That's why I mentioned that I don't like some of the more bold statements about Kotlin. Now, most of my concerns were addressed in future comments and reasons for the frustration with Kotlin were explained. I think you can see where I came from and that this is sincerely how I perceived it. It's debatable whether it was necessary for me to go off topic and discuss emotional aspects, but I believe it was worth so to understand the reasons behind the rather strong feelings, that the commenter then explained in detail, and to also inform you about how a few more bold comments might be perceived by people who have seen a bit of Kotlin but have not used Scala at all. 
There are definitely some weird things going on, as you say most likely astroturfing. This thread itself is a bit strange, named "Scala vs Kotlin" and started by a 2-day old account by a person claiming to be a recruiter, and its [sister thread](https://www.reddit.com/r/Kotlin/comments/6edgk9/kotlin_vs_scala_career_moves/) has some accounts that are a bit strange, like [FooBarDeveloper](http://archive.is/1kq1M) and [codingrobot](http://archive.is/ijKhe). A lot of the other discussion in that thread seems much more sincere and reasonable, and make good arguments. Especially the point regarding Google endorsing Kotlin for Android. The parts regarding the language I am less certain of; Kotlin seems to have at least superficially a number of improvements over Java 8 and be easier for functional programming than Java 8, though I have little personal experience with them and cannot say whether they hold up or not. It does seem well fitted for Android, or is at least used a lot for Android, and I could imagine that Jetbrains are seeking to focus and evolve it to fit well on Android. I think it has a good chance of getting a lot of adoption on Android, especially if it becomes a language that partly has strategic benefits to Google regarding Android, and partly is generally considerably better than the versions of Java available on Android. Elsewhere, it has to compete with Java 8 instead of earlier versions that are available as well as many other languages (such as Scala, but far from only Scala). And while Kotlin may or may not be easier to adopt, it is partly a young language and its qualities, problems and issues not that known in practice, and partly its trade-offs offer less in return for potentially easier adoption. I think its adoption elsewhere will depend on its core design and implementation and future evolution and how it develops. It may be hard to develop if it does not have good fundamentals, which there are arguments for in this thread and in links elsewhere that it may well not have. But I think only time and practical experience will really tell.
Ah, I am happy if it could help :). Cheers!
~~Fair enough.~~ In regards to Kotlin and possible astroturfing, there are these weird accounts: ([1](http://archive.is/1kq1M), [2](http://archive.is/ijKhe)) which I mention in [another (very recent) reply](https://www.reddit.com/r/scala/comments/6ee77n/scala_vs_kotlin/dibznk2/), which I think is a significant indication that there very likely is some weirdness about. ~~But as I also mention in that reply, most of the other discussion in the sister thread of this one seems sincere and at least somewhat decent.~~ &gt; I can understand this frustration - when there is a better, but more radically different solution and people don't adapt it because it's different and then settle for a less-different but in general worse language, that's understandably frustrating. ~~I think that is one perspective, but I do not share it; I think more (friendly) competition is a good thing, and that there should be less focus on competition and more focus on creating and improving languages and how they are used - and more focus on enabling certain programming paradigms where they make sense to use, such as functional programming in a considerable number of cases and domains in certain ways and parts.~~ EDIT: ~~Minor clarification regarding competition.~~ EDIT2: I get a very strong impression that you are being fully insincere given certain comments of yours. EDIT3: [Link to another relevant comment](https://www.reddit.com/r/scala/comments/6ee77n/scala_vs_kotlin/dibznk2/).
I can emphatise with that, I'd be as frustrated as you are, assuming you are right and I had knowledge in Scala - as it stands I just know a little about Kotlin and its differences to Java, but nothing about Scala at all. I'll try to form my own opinion, but the (understandable) relative hostility against Kotlin does make it hard to take your arguments without a little doubt. What I mean is that I am inclined to believe what you are saying, but the way it is said allows others to call the Kotlin community friendly and the Scala community toxic. I get why it's obviously not Kotlin advocates that would make toxic comments because they are the ones that profit, but maybe trying to be a little more neutral towards Kotlin would make you stand in a better light in outsiders views. On the other hand, being insincere would also not really work out, it might be better to clearly state what you think, but keep in mind how many will perceive it; essentially you're telling people their new shiny tool they just recently discovered is crap and yours is way better, which might be true, but not received as well as just showing off the differences of your even better tool. 
We have deployed an enterprise app using Akka Actors. We have at least half a million end users and I'm a bit ashamed to admit that our coding style is #2 with a bit of #3. How do you guys get into #4 and up? How do you come up with solutions/designs that use those functional features?
My experience is that between levels 4 and 5 one starts to encounter various painful warts in the current Scala language and/or compiler, combined with spurious errors shown in the IDE due to inconsistent behavior of the presentation compiler. Such issues can take a regular mainstream developer a completely disproportionate time to resolve unfortunately. That said, getting to level 4 is very worthwhile IMO.
I got started on the functional side using `Option` and `Seq` - learning how their `map` and `flatMap` functions worked, and then looking at how that related to the concept of `Functors` (things that have a `map` function that follows certain rules) and `Monads` (things that have a `flatMap` function that follows certain rules) It didn't click for me until I went in thinking of them as the things in parentheses there. Maybe it'll be helpful for you down the road. The actual explanations and stuff are more intricate than just `map` and `flatMap` but it at least gives you a familiar place to launch from.
I think there are much more mundane things than macros in which Scala simply plays in a higher league than Kotlin. Type classes, enabled by implicits, are a quite simple concept actually. How about path dependent types? (Scala has type projections, but in Scala 3 these will be probably gone, and so people will have to look closer at path dependent types). Does Kotlin have any of these?
&gt; Well, that's disingenuous to say, because that holds for interop of any language A with a different language B, including Scala &lt;-&gt; Java. No. Look up "platform types". In Scala if you call a Java method that returns `String` you get a `String`, in Kotlin you get a magic non-denotable type that's sort of like a mix of `String` and `String?`, so you can't e.g. factor out a common Java call without potentially changing the rest of the code. No other language does this. &gt; That's a concurrency primitive if you like, many languages have concurrency primitives. The problem is not about adding that to the language, but whether you think async/await is such a useful construction at all. It shouldn't be a primitive. It should be sugar on top of a `Future`-like primitive, the way it is in C# or Scala. I think it's really important to move as much as possible into libraries or lightweight sugar, where the wider community can generalize over them and iterate quickly on new ideas you wouldn't've thought of, rather than building the high-level constructs directly into the language as primitives.
how does Scala deal with commodification ? take this code objects.foreach({ o =&gt; o.update() val v = o.body.getPosition().asInstanceOf[DVector3] .... various other checks / operations on `o` .... if (v.length()&gt;20) { // too far away o.dispose() // get rid of graphics / remove physics from world objects-=o // WOT! no commodification :-o ! yay! } }) If you tried removing something from a list while iterating it in some other language you'd get an exception. I know there are probably better ways to iterate using functional methods but I'm interested in this specific type if iteration and how Scala handles it presumably this is very not thread safe! that aside if you did need a list that regularly and rapidly has stuff added and removed from it what "native" Scala methodology would you use? 
Yes sure, a Trabant and a Jaguar are just different cars.
Good luck on this forum with your troll attitude. Let me just say this, in 1989/90 not that many people were clinging to their Trabbis; I don't know if you've ever sat in one.
The JVM doesn't have native co-routines support, so you have to bake that into the language if you want that feature. Scala had the delimited continuations plugin, which was a transformation of the compiler. The new async in Scala is macro based, arguably that's also a change of the language. How is async in C# a sugar on top of Future?
It is better to learn haskell first?
There's also Functional Programming in Scala which is a good introduction to FP.
Try looking up FP topics in other languages like JavaScript. There's a really nice YouTube channel called FunFunFunctions which does this. I've found that it helps me understand. (: 
**Here's a sneak peek of [/r/softwaregore](https://np.reddit.com/r/softwaregore) using the [top posts](https://np.reddit.com/r/softwaregore/top/?sort=top&amp;t=year) of the year!** \#1: [He truly was ahead of his time](https://i.imgur.com/4KfdylP.jpg) | [157 comments](https://np.reddit.com/r/softwaregore/comments/5lr3l4/he_truly_was_ahead_of_his_time/) \#2: [Jesus Christ siri](http://imgur.com/JsJZ8w4) | [512 comments](https://np.reddit.com/r/softwaregore/comments/5ea0w7/jesus_christ_siri/) \#3: [My school's cafeteria survey](https://i.redd.it/e8r5wlhf23xy.jpg) | [398 comments](https://np.reddit.com/r/softwaregore/comments/6arset/my_schools_cafeteria_survey/) ---- ^^I'm ^^a ^^bot, ^^beep ^^boop ^^| ^^Downvote ^^to ^^remove ^^| [^^Contact ^^me](https://www.reddit.com/message/compose/?to=sneakpeekbot) ^^| [^^Info](https://np.reddit.com/r/sneakpeekbot/) ^^| [^^Opt-out](https://np.reddit.com/r/sneakpeekbot/comments/5lveo6/blacklist/)
Personally, yes for FP, the syntax of haskell to me is much cleaner than scalaz or cats. You can find a lot more papers that implement their ideas in Haskell. 
I'm developing [esl-auctions](https://github.com/EconomicSL/auctions), a functional API for defining various types of auction mechanisms. Intent is to use the API to experiment with various designs for future peer-to-peer electricity auctions. This is an initial release and code review, comments, and/or pull requests are very much appreciated!
Pretty much everything. Highly insecure. Fine for dev, but wouldn't do it in Prod.
The second one raises a warning if you use `-Xlint:strict-unsealed-patmat` with [Typelevel Scala 4](https://github.com/typelevel/scala/blob/typelevel-readme/notes/typelevel-4.md). scala&gt; :pa // Entering paste mode (ctrl-D to finish) val someString: String = "scaladays copenhagen" someString match { case "scaladays anywhere" =&gt; ??? } // Exiting paste mode, now interpreting. &lt;console&gt;:14: warning: match may not be exhaustive. It would fail on the following input: (x: String forSome x not in "scaladays anywhere") someString match { ^ 
You're not alone - nobody I know found it "easy". The concepts I learnt from this book are really unintuitive at first if you come from an oo background. Doing the examples is essential to understand what's going on. When you're done, you'll be happy to have done it, writing FP code is truly a form of art IMO.
Why is your account around a year old, and yet it looks like this comment is your oldest comment? [Source](http://archive.is/IlwVy#selection-1128.0-1128.1).
If you're using an immutable collection then `-=` will be equivalent to `objects = objects - o`, which creates a new collection without the element and then assigns the fresh collection to the `objects` reference. The iteration will continue on the original collection just fine as it has not changed. If you're not using an immutable collection, then it's possible the implementation of `foreach` simply doesn't check for invalidation but is implemented such that the operation completes in some fashion despite the invalidation. For example: @ val c = mutable.Buffer(1, 2, 3) c: mutable.Buffer[Int] = ArrayBuffer(1, 2, 3) @ c foreach { c -= _ } @ c res8: mutable.Buffer[Int] = ArrayBuffer(2) You can see that it didn't fail, but also didn't check the collection was modified; it just silently skipped an element. With a mutable collection it's definitely not thread safe; it's not even safe within a single thread, as demonstrated. But with an immutable one then under certain conditions this could be considered thread safe within a limited context. For instance, assuming this is a game, if all the threads are guaranteed to start and complete this section of code within a certain time (like the current frame), and all operations on each object yield the same result within that time (calling `update`/`dispose` many times is the same as calling them once), all operations themselves are thread safe (multiple threads executing `update` simultaneously doesn't matter), and they yield the same result regardless of other method calls (calling `update` again after calling `dispose` is fine), then the final observable result would be same. So from the perspective of the next time window, you get the same result regardless of thread count, and it's effectively thread safe. Of course, it would be extremely inefficient to execute this with multiple threads regardless of safety due to all the allocations and work involved in creating a bunch of collections, let alone the redundant operations on each object.
I get a very strong impression that you are seeking to manipulate and are not sincere in any way.
Multiple lies in two sentences. I encourage you to have at least a little bit of respect for yourself, and depending on various factors possibly encourage you to find a different career. EDIT: [Link to another related comment](https://www.reddit.com/r/scala/comments/6ee77n/scala_vs_kotlin/dibznk2/).
(External user here.) It generates bytecode for the JVM yes. There is also an intermediary format called TASTY which represents compiled trees. It is likely that there will be [Scala.js](https://www.scala-js.org/) and [ScalaNative](http://www.scala-native.org/en/latest/) backends as well, which generate JavaScript and native code respectively. 
I can't imagine why you would think that, I think I went into quite some detail to describe how and why I feel that there was a bit of hospitality against Kotlin and while I can see the justification for strong feelings, I'd recommend to stay a bit friendlier, if possible, in order to avoid driving away the people that you in the end may want to convince - not implying that this is anyone's primary drive or something. Now, I don't care much about how either community is perceived - I mean I don't use either language - but that's just my opinion. The guys over at Kotlin seem way friendlier, and that's not just my observation. As I said, I also see some reasons why it would be so and why a few Scala advocates would be frustrated. I tried to give an example on why I personally perceived the Scala community as more hostile. It's a good point that one should not generalize when most of the people are argumenting very objectively, but it's just that those are posts that do receive a few upvotes, so it does seem like that is the opinion that a (at least small) part of the Scala community has. I don't want to criticize that opinion, as I can see justification for it, but I tried to express how it looks hostile to people not really knowing either language in enough detail to draw their own conclusions. 
My impression that you are seeking to manipulate and are not sincere in any way is strengthened a lot by this comment. [Link](http://archive.is/ko9v5) in case comments or other things begin disappearing, which I do not expect, but one never knows. EDIT: [Link to another relevant comment](https://www.reddit.com/r/scala/comments/6ee77n/scala_vs_kotlin/dibznk2/).
&gt; Scala had the delimited continuations plugin, which was a transformation of the compiler. I always thought that was a bad idea. &gt; The new async in Scala is macro based, arguably that's also a change of the language. I think lightweight syntactic transformations that desugar into ordinary function calls are relatively OK, because if you get confused about what's going on you can always reason about the desugared version. Same reason I'm ok with `for`/`yield`. &gt; How is async in C# a sugar on top of Future? I thought it was sugar on top of `Task` which seems analogous to Scala's `Future`. Did I misunderstand?
You are not being consistent in your manipulation, but otherwise a fairly good tactic, I would say. I encourage you to have at least a little bit of respect for yourself, but that is in the end your own choice. [Link](http://archive.is/AxsWO).
That really does not help me to see what you dislike about my opinion, even if you post two more archive links to my profile. But I guess in the end we don't need to agree, if you think there is some scheme and I'm being insincere, then there hardly is anything I can say against that, I really think I typed out a full explanation of my honest opinion. I'm a bit curious about what leads you to these conclussions, but maybe it's just a radical difference in view points ¬Ø\_(„ÉÑ)_/¬Ø
Decent lies, but a bit too obvious in places. Again, it is your own choice whether you choose to have at least a little bit of respect for yourself. [And the third, or higher, link to (one of) your profile(s)](http://archive.is/8zgP3). [Link to another relevant comment](https://www.reddit.com/r/scala/comments/6ee77n/scala_vs_kotlin/dibznk2/). EDIT: Fixed minor stuff.
Is it still eclipse based? there were some talks about moving it out of eclipse platform last year. I wonder if they made any progress on that.
Stop right there. Clearly you are set on your stupid and stubborn idea that I am here for some kind of manipulation. You neglect to both describe what it is that I supposedly try to achieve and you speak of inconsistencies and lies without any kind of proof or even indication on what you mean. All you do is posting the same link to my profile over and over again, guess what: I don't have a clue what you mean. And no, the single comment that you linked three times does not tell me what you mean either, since my account is obviously not a throwaway of some Kotlin advocate. All in all I find your attitude and neglection of meaningful discussion sad. I was expecting a more insightful discussion. If you don't change your mind and discuss with me in detail what you claim to be lies or inconsistencies, I consider this discussion over. 
&gt; which creates a new collection without the element and then assigns the fresh collection to the objects reference. recreating a whole list with just one item missing seems rather inefficient ? is there anything in scala like a linked list where an item can be removed by simply unlinking it ?
Thank you so much for taking the time to do these example, it was very generous of you, sadly they didn't work either in firefox or chromium. I would have tried them locally but I assume the dom package is expecting to work inside a html domain... Sorry to seem a bit dense but this Interaction[A] =&gt; (A =&gt; Interaction[B]) =&gt; Interaction[B] is making no sense at all is it a function or a generic what does the ascii soup mean? is it a lambda or something else? def drawF: Vector2 =&gt; Interaction[Unit] = obj.drawF so whats the vector2 doing to an interaction unit generic and how does it equal a method of another object ? 
by Scala I mean whatever runtime library is providing the list code I'm not sure what you are showing with the fiddle code
I intuit its not great, but what are you supposed to do instead for example suppose you have an array of 1000 boolean values and you only need to match 6 or so that a spread through the 1000
could you make it easier to dowload the books? the sequence of forms is a little annoying, specially when oen wants to download them all at once. edit: "essential-play" is even missing the "download all" button
Surely the compiler could see that the case class contains a non-self typed string and deduce that the case is incomplete?
I most definitely did. Very useful and they already have 4.6.1 RC-1 out for the next version of Play that supports Scala 2.12 when it finally gets released
Yes, its official name is the Scala IDE for Eclipse. I haven't used Eclipse in a while, but I've heard nice reviews of the latest versions.
&gt; Thank you so much for taking the time to do these example, it was very generous of you, sadly they didn't work either in firefox or chromium. I don't how it wouldn't. There should be a small black square rendered in the right pane. It's not animated in a visible way if that's what you're expecting. You can edit the code in the left pane and rerun it on that site and see result updated live. &gt; Interaction[A] =&gt; (A =&gt; Interaction[B]) =&gt; Interaction[B] It's a type signature explaining the operation we want to do. We start with an `Interaction[A]`. We want to get `A` out of that interaction and create a new `Interaction[B]` by applying a function. We then want to end with a `Interaction[B]` as our result. If we for example look at [flatMap on Option](http://www.scala-lang.org/api/2.12.2/scala/Option.html#flatMap[B](f:A=&gt;Option[B]\):Option[B]), it signature is: final def flatMap[B](f: (A) ‚áí Option[B]): Option[B] We start with an `Option[A]` we then call `flatMap` which takes in a function `A =&gt; Option[B]` and end with `Option[B]`. So we would describe the `flatMap` on `Option` as: Option[A] =&gt; (A =&gt; Option[B]) =&gt; Option[B] Another example would be `map`. `map`'s signature is: Option[A] =&gt; (A =&gt; B) =&gt; Option[B] A few more examples would be: Option[A] =&gt; B =&gt; (A =&gt; B) =&gt; B //fold Option[A] =&gt; Option[B] =&gt; Option[(A, B)] //zip Option[A] =&gt; (A =&gt; Boolean) =&gt; Option[A] //filter, filterNot, or find &gt; def drawF: Vector2 =&gt; Interaction[Unit] = obj.drawF &gt; so whats the vector2 doing to an interaction unit generic and how does it equal a method of another object ? `drawF` is a function from when fully expanded looks like this: drawF: Vector2 =&gt; (PhysicsContext =&gt; Unit) That is `drawF` is a function that returns another function once you give it a `Vector2` representing the current position of the physics object. In the translate method, we want to create a new physics object, that uses the same draw function as the given object, however we want to update the function to use a new position. This is why we define the `Interaction` in terms a `Vector2` which has not been given yet. If we defined the original Interaction in `rect` to use use `this.pos` when making a copy of that interaction the position would never change.
We'll make it easier soon. Just didn't have time before Scala Days to do better.
I recently joined a company that uses a lot of Scala, and this is also my first exposure to Scala, so I'm still fairly new to the language. From what I've seen, most of the code I've seen is a mix of "styles" 1 and 2, but mostly closer to 2. Prior to learning Scala, I've had some exposure to Haskell, so I often feel compelled to incorporate more from styles 3 and 5 from your list. But that's not always possible, usually because a) I need to maintain compatibility/consistency with existing code, or b) my project requires working with some pretty poorly-designed Java APIs (as in, even for Java, they're pretty bad. To be clear: These APIs were not developed at my company :P)
&gt; recreating a whole list with just one item missing seems rather inefficient ? It's the nature of immutable collections: once you have them they never change. That comes with a lot of nice properties, like being able to share them across threads trivially. But you're right, it's a lot more work to create a slightly different version compared to the same modification with a mutable collection. &gt; is there anything in scala like a linked list where an item can be removed by simply unlinking it ? Sure - the [mutable `ListBuffer`](http://www.scala-lang.org/api/current/scala/collection/mutable/ListBuffer.html). But if you care about efficient operations in general you probably want something other than a linked list. The things that they're bad at are usually the common operations (e.g. iteration/searching) and the things they're good at are done about as well and sometimes better by other data structures (e.g. appending/prepending).
Annotate the Java types externally, and by-pass the platform types altogether? Does that relieve your concern? https://kotlinlang.org/docs/reference/java-interop.html#nullability-annotations
A lot of other folks in the thread have expressed similar thoughts: it's nice to use a [simple](http://underscore.io/blog/posts/2015/07/21/simple-isnt-easy.html), flexible language with [few, orthogonal features](https://youtu.be/iobC5yGRWoo?t=3m32s) that offer [consistent ways](https://philipnilsson.github.io/Badness10k/posts/2017-05-07-escaping-hell-with-monads.html) for libraries to handle various use cases instead of continually bolting on various [inflexible ad hoc language-level solutions](https://stackoverflow.com/questions/31291129/pep-0492-python-3-5-async-keyword), and allows me to model a complex domain with complex data transformations, and to [preclude a large class of invalid states](http://fsharpforfunandprofit.com/posts/designing-with-types-making-illegal-states-unrepresentable/). It promotes [a principled approach](http://mergeconflict.com/coupling-in-object-oriented-programming/) that results in code that's [far easier to reason about, extend, and maintain,](http://www.falkoriemenschneider.de/a__2014-09-17__Programming-without-objects.html) at the (upfront) cost of newcomers having to learn some unfamiliar, more powerful constructs, which, if our goal is to comfortably get things done *well* (after ramping up), I believe is worth it.
mutable ListBuffer from the api only seem to have overridden operators how can I be sure this isn't recreating the list every addition, deletion? not sure why you think linked list is slow to iterate ? all you're doing is looking up a reference to the next node, I'm not sure how an immutable list could do this any faster or if it isn't in effect doing the same ??
I honestly have difficulty telling if you are a shill or a genuine Kotlin fan (I do not think you are giving an accurate picture of things in this reply or in other replies in this thread), but if you will, I would like to hear your opinion on [this comment](https://www.reddit.com/r/scala/comments/6ee77n/scala_vs_kotlin/dibznk2/) I made previously, especially in regards to the weirdness of this thread, the sister thread, and some of the various posters in here (and that comment does not mention all the weird things). Do you really not see a lot of weirdness about from various posters that on the surface are in some ways favorable to Kotlin? And do you not consider it weird that a throw-away from a supposed recruiter makes a (/two) "Scala vs Kotlin" thread(s)? In regards to dialogue, I also made [this comment](https://www.reddit.com/r/programming/comments/6elim6/announcing_dotty_012rc1_a_major_step_towards/didio7m/) in another thread altogether. I do not consider myself concerned about whether people consider me a "fanatic" or not; I think it is obvious if you dig into things that I am not, so why should I waste energy on it, or be baited into wasting time and energy on it? But again, I do not know if you are genuine or not (if genuine, a bit to somewhat unfair, but that is what it is).
Many thanks, a great contribution! Just a note, I found the PDF of the *Advanced Scala with Cats* seems to render in a somewhat grainy and low-resolution way (on Windows 7-64) - the E-Pub and HTML are perfect.
It's not a question of what you do so much as what other people do in the codebase you're working on. Eliminating platform types across a codebase would be great, though I don't trust annotations either; my experience in Typescript and Java-with-checker is that "external" annotations always have errors, and then you get "impossible" errors in your own code because something non-nullable is null.
The untyped and non-monadic nature of the current Akka Actors means they don't map well into FP (there is an experimental Typed Actors initiative). One approach to progress FP is to start to use some FP components, e.g. Validation, Doobie for DB access; there are many others. It helps to have onboard an experienced FP evangelist (not a fundamentalist!) who really knows the area and tools, and who can diplomatically assist the transition.
&gt; what is interaction? `Interaction` is a type alias defined on the third line of the above snippets: type Interaction[A] = PhysicsContext =&gt; A Anywhere you see `Interaction` you can substitute the body. `Interaction[PhysicsObject]` expands to `PhysicsContext =&gt; PhysicsObject`. `Interaction[Unit]` expands to `PhysicsContext =&gt; Unit`. Here's a few more examples: //Example 1 type ListOfStrings = List[String] def printStrings(stringList: ListOfStrings) = ... printStrings(List("Hello World", "Goodbye World")) //Example 2 case class Data(...) type DataMap[Key] = Map[Key, Data] val byId: DataMap[Long] = Map(1234L -&gt; someData) val byName: DataMap[String] = Map("SomeData" -&gt; someData) &gt; what do you mean by get A out of it? what is A (a generic type stand in?) Yes `A` is a parameter that represents a type to be applied. In the case of `draw` and `clear`, `A` is `Unit`. In the case of `rect` and `translate`, `A` is a `PhysicsObject`. &gt; how, I don't see anything that would indicate this, and even fully expanded it just seems you are passing a vector to a physicscontext which its then using to pass onto a unit - so it does nothing ? You're associating function application in the wrong direction. You first apply a `Vector2` and get back a function. This function still requires a `PhysicsContext`. When you apply the PhysicsContext the side effect of drawing the rectangle is performed and `Unit` is returned. val drawWithPosition: Vector2 =&gt; (PhysicsContext =&gt; Unit) = ... val drawWithPhysicsContext: PhysicsContext =&gt; Unit = drawWithPosition(somePosition) val discardedSideEffect: Unit = drawWithPhysicsContext(someContext) //draws the rectangle with somePosition and someContext. This form of partial function application is called Currying. 
Few comments by me, a Haskell developer now; Scala developer in the past: http://oleg.fi/gists/posts/2017-06-03-comments-on-whats-different-in-dotty.html
yeah... but its far away....
There's the whole pointer indirection thing that the JVM hides from you. Where using a collection that is array based, could at least hold all references in cache. Ofc this is mostly speculation, without writing actual tests. Additionally, if you need fast searching or seeing if an object is in a set, anything that hashes will speed that up considerably. 
EDIT: There is a long [Wikipedia-page](https://en.wikipedia.org/wiki/Lattice_(order\)) on the subject, but a short and informal explanation is that a partial order is like a total order, except not every element can be compared ([example image](https://en.wikipedia.org/wiki/File:Hasse_diagram_of_powerset_of_3.svg)). For instance, a simple relation which is a total order on integers is `&lt;=`. In contrast, a partial order could for instance be pairs of some apples and some oranges. Because apples and oranges cannot be compared directly, if you have a pair of 3 apples and 0 oranges (denoted `(3, 0)`), and a pair of 1 apple and 4 oranges (denoted `(1, 4)`), you cannot compare these pairs directly. However, both pairs can be compared to the pair `(0, 0)` (ie. no apples or oranges), which they clearly are both greater than. And likewise, they are both smaller than the pair `(10, 15)` (ie. 10 apples and 15 oranges). The subtyping lattice above likewise shows elements that cannot be compared, namely the types `T`and `U` (one could give arrows to show the direction of the relation, but I assume that the vertical levels indicate this instead). In contrast, `T &amp; U` gives more information than either `T` and `U`, and `T | U` gives less information (I am not certain that "more information" and "less information" are the right definition or the definition used, but I think that is descriptive enough for a superficial understanding). Partial orders occur rarely in programming, but sometimes occur in languages that has subtyping (for instance, if you have a type that is a subtype of two or more other types (like if in Java you have `extends [something] implements` or in Scala you have `extends [something] with`, and those types are not directly subtypes of each other but each are a subtype of some common supertype). You may also use it as a way of modelling if you find it convenient and a good fit. For instance: sealed trait JavaExpression sealed trait JavaBlockStatement case class IntegerLiteral(x: Int) extends JavaExpression case class FunctionCall(functionName: String, arguments: List[JavaExpression]) extends JavaExpression with JavaBlockStatement case class VariableDeclaration(variableName: String, variableType: VariableType) extends JavaBlockStatement This models that in Java, integer literals are not valid as a statement in a block, while function calls are, and they are both expressions. Variable declarations are not valid expressions, but are valid block statements. Do note that this is an example I came up with, so I don't know if it would make sense for actual modelling in something like a Java compiler, but I think it could be useful; I have used similar a few times before.
Does anyone know why Scala was removed from https://benchmarksgame.alioth.debian.org/ ?
&gt; ListBuffer from the api only seem to have overridden operators That's due to the extensive trait hierarchy Scala has for its collections. Among the concrete collections there are very few methods that aren't overrides of some trait method. &gt; how can I be sure this isn't recreating the list every addition, deletion? You could look at the source (follow the source link [here](http://www.scala-lang.org/api/current/scala/collection/mutable/ListBuffer.html)), or you can trust that modifying the collection in place is the main purpose of the mutable collections and rely on the fact that they do just that. &gt; not sure why you think linked list is slow to iterate ? all you're doing is looking up a reference to the next node It's precisely because it requires following a reference to the next node that makes the iteration relatively slow compared to other data structures, particularly `Vector` and `Array`/`ArrayBuffer`, but also anything else using chunks of contiguous memory. On current hardware those perform much better because of how they interact with the processor's cache and prefetcher. There are other factors that go into it too, like allocation patterns, but this kind of performance talk is a deep rabbit hole filled with caveats and exceptions. &gt; I'm not sure how an immutable list could do this any faster or if it isn't in effect doing the same ?? An immutable linked list definitely can't do that faster - it is still a linked list. When I said you want something other than a linked list, I meant an entirely different data structure like the ones just mentioned; I wasn't talking about mutable vs immutable at that point.
Knowledge of abstract algebra is always an advantage but not enough big for this days! I highly recommend you to start with J.Lurie - Higher Algebra as a first step into functional programming. Hope you will enjoy it.
I think type classes are a little too high in the hierarchy. They're very useful way before monads and functional error handling. Note that there already are typeclasses for very basic things in the standard library, e.g. `Ordering`.
Yeah, that's probably a better (and much more concise) answer than mine :).
Why would one use this over play?
Not sure if this fits your case but you can use [shapeless HMap](https://www.scala-exercises.org/shapeless/HMap)
Scala has had structural typing for a long time already. Not used much though as most prefer proper types and it uses reflection. https://twitter.github.io/scala_school/advanced-types.html#structural
That is true. I read a [recent blog post](https://jacquesmattheij.com/improving-a-legacy-codebase) and [Hacker News thread](https://news.ycombinator.com/item?id=14444914) that began discussing this, where especially in the Hacker News thread they came up with examples on how to argue for your case, including instrumentation, measuring and letting managers take the decisions (and informing the managers, partly so that they can better make decisions themselves, and partly so that they have arguments they can use for their decisions with others). Sometimes a quick and dirty solution can make sense, at least if you schedule fixing it later so that its damage later on will be prevented (or, the quick and dirty solution can be accepted if its potential negative impact is very limited in scope and effects).
Yes that's why. Keep wondering.
Hi. Want to keep playing?
I'm fine. Seriously, the incoherence was deliberate. It's simply and example of "let's be a dick head, but only slightly less so than you." The issue still ongoing because stains like Lars Hupel ring my employer. While we all have a laugh about it, I resent having wasted the 20 seconds on having to care. Get these fuck wits out of my life, out of my code, and the game stops.
&gt; Many people going after him and abusing him, someone even supposedly calling him a rapist, having the projects he was involved with captured or similar... Correct. If you are going to fuck with me, if you are going to make those the rules of the game, then let's play. Don't complain when you lose. Why is this such a surprise?
&gt; [...] stains like Lars Hupel ring my employer. [...] What the heck? And this is even recent?? Would it be OK with you if I link to this comment of yours if Typelevel or Typelevel-related stuff is discussed on this sub-reddit? I have little influence over things, but I think Typelevel has a responsibility in regards to stopping this stuff when it comes from their core members (1), and this is stuff that they should have figured out a very long time ago, so calling them out on it when Typelevel comes up and potentially hurting their reputation is as far as I can see more than fine and OK, because really, this should not have happened in the first place and should have stopped long ago. There gotta be leeway and the like and what not, but harassing others at their place of work is far, far beyond the limits. I will not link the comment if it is not OK with you. (I mean, what the heck?) (1): According to what I believe is the [GitHub page](http://archive.is/Q4o3r) and [Twitter page](http://archive.is/5Yohv) of Lars Hupel, Lars Hupel is "@typelevel cofounder &amp; community representative at the Scala Center Advisory Board".
It will never stop. This issue is nearly 12 years old. It will never stop. I can only disempower it, at a penalty that I long ago accepted. Yes it is relatively recent. It's not even a big deal in the greater scheme of things. The greater scheme of things may just blow your mind to pieces actually. The information dissemination of a criminal, political organisation like Typelevel is well calculated. Take caution. I mean it.
Yeah, well exactly mentality is why i have to program in PHP at my day job.
Thank you for the warning. I am not quite convinced, but there are definitely a lot more stuff and the like than most people would like to admit or think about (though the vast majority of them do tend to be very small in scope and importance).
One of the biggest benefits is that it makes refactoring much safer, because you can reason about what changes are equivalent and which aren't. For example say you have some code that, after getting past all the noise, boils down to the pattern x.map(f).map(g). That is, it's calling map on something with one function and then subsequently mapping it again with another function. Can you replace it with x.map(xx =&gt; g(f(xx))) or not? That depends on these kinds of properties of the code like substitutability. In other words, by having restrictions on our code, we get more guarantees and safe assumptions to make about our code, which enable us to make informed decisions.
What will happen with Shapeless after dotty? Will all shapeless dependant libraries break?
I switched from Eclipse (to IntelliJ) some time ago because the IDE would hang constantly on saves. Has this situation improved?
Someone told me that they'll be removing typed projections and that it's critical for shapeless.
You're welcome :)
It's just the politics of programming. If you want nice things you must first create the economical environment to keep it that way. 
You have the wrong bit. The snippet above is just for re-exports so you can do `import shapeless.lens._` and import `shapeless.prism._` , and you will have the equivalent of `import OpticDefns._` which contains the typeclasses/macros to generate lenses and prisms for a given data type. if you go to https://github.com/milessabin/shapeless/blob/ab081796c183530efdd8b29dab8fee1fee7c61f9/core/src/main/scala/shapeless/lenses.scala you'll also see the definitions you expect. As a minor nitpick, your definition of lenses and prism is only _one_ of many you could have (the one we are most likely stuck with in Scala due to various limitations). However, there are more general definitions that allow you to compose prisms, lenses and traversals with only one operator (function composition!) instead of the `composeLens` `composePrism`etc. in monocle: among other, Van Laarhoven lenses and Profunctor lenses.
Stay out of my code.
Why would I want to touch your code?
The power of an amortized O(1) operation, versus the old worst-case O(n) one. Sometimes complexity theory really, really matters in practice.
sure, but your function needs to return something, you can wrap the result in an Option or disjunction.
From the article, at the bottom: Or to enroll in each course independently (for free, but without a certificate), you can visit each course‚Äôs landing page: Functional Programming Principles in Scala Functional Program Design in Scala Parallel Programming
I don't understand the following part (emphasize mine): &gt; Literally one shell command will set everything you need up. &gt; rustup for managing your Rust toolbelts (different versions/channels of Rust) &gt; cargo for managing your build and for publishing to crates.io, which includes, among other things: &gt; A test subcommand for running tests &gt; A bench subcommand for running benchmarks &gt; rustfmt for formatting your code (runs on cargo projects via cargo fmt) &gt; rustdoc for generating beautiful documentation websites. &gt; This tool supports doc tests with zero additional configuration/setup (runs as part of cargo test) &gt; **Coming from Scala, having all of this set up with no fuss right out of the gate is a breath of fresh air and feels like a big win for productivity.** Aren't these mostly handled by SBT in a similarly easy way?
I really don't understand the need for this - if I read it right, it's nothing more than a static lexical import of another file with no post-processing. This literally gives you no advantage over importing a symbol from another compilation unit. I see a *lot* of danger in this - the potential for indecipherable compiler errors and warnings is way too high for me to ever use this in a project. If it was doing some sort of templating, it might be useful for the special case of reducing boilerplate, but the right way to do that is to use macros. 
I get what you're doing, but you're *much* better served by creating a new scala source file, copy the contents of your .sc file to the clipboard, and do the following package foo.bar object UsedToBeSnippet { // paste snippet here } It takes all of 10 seconds, and produces much more maintainable, safe and performant code. In general, I really avoid the use of compiler plugins under almost all circumstances if possible. It's a deprecated mechanism, it's not well understood and now makes the actual build of your source files non standard. Not to mention the fact that IntelliJ/Scala IDE/Ensime or any other tool you use will barf and likely not work well with any file that you use this syntax in. Also - if you're using a static lexical import like you are here, you'll essentially have multiple copies of the same code in memory at runtime, each of which individually goes through its own JIT optimization. You'll be using more memory and your code will be slower. If you want to go down this route, and I don't think you should, this really should be a macro that loads the .sc file using the regular scala IO classes at compile time and expands it directly into source using quasiquotes.
&gt; package foo.bar &gt; object UsedToBeSnippet { // paste snippet here } but can it load something dynamically from the web? /s i came here to ask the same thing; it's just a case of [NIH](https://en.wikipedia.org/wiki/Not_invented_here) 
Here's the thing, though - you're not actually sharing code. You're sharing the mechanism to import a static, unversioned text string into into a target source file, and this unversioned file must already exist on the machine running the build. If you don't want to go through the process of properly packaging this up and publishing the results to an ivy/maven repo, sbt already has built in behavior for you to use this - git imports. Create a git repo that contains two files: your .sc snippet pasted into a wrapper object like I showed above, and a single minimal build.sbt file. Any project that wants to use this can create an sbt project reference to the git URL for this project. 30 seconds of work and you have a much more robust solution.
Then Godspeed to you. It's your project and you can do it however you want. I can tell you that this would not make it past code review under any circumstance in my organization.
The Kotlin devs gave the question "how do we get our language into users' hands -- especially those users which aren't actively looking for Kotlin" some serious thought and had plans for each platform. Their efforts on Gradle and Spring on the JVM are no coincidence, it's the same basic idea which turned out to be extremely successful on Android. It will be interesting to see how they implement their strategy on JS and Native. Scala has nothing to compete against this.
That's actually the bad news on a JVM. 4 pointers is definitely more expensive than any primitive value construct.
Yeah, and `fastOptJS` is *really* fast now as well. Epic bug fix release ;-) Now if we could just speed up scalac and sbt...
Personally, I found that talk to be very tedious and only serving to prove the common wisdom of that field. If you want to verify programs, use Coq or Idris. Verifying a program that has "large state spaces" is computationally infeasible in the same way that brute forcing AES is.
Primitive types in collection isn't that simple on JVM. Not sure whether Scala's current `Map` is @specialized to `Long` (seems it will be 2.13). I'd strongly suggest "use two maps": build on top of provided collections, and let the test result show if it's enough or not. You are prematurely optimising if you aren't trying that. More sophisticated approaches are - for sure - more code which is harder to show correct. The "naive" approach should already show some improvement in time, otherwise it's a wasted effort to begin with.
Yes building in eclipse otherwise I find Eclipse's model drifts from reality.
Same to you, or I will force it.
Eclipse will build incrementally after the initial full compile, or at least it used to so I don't know why it would be slower - I'm not disagreeing with you, just curious as I don't use Eclipse anymore. In intellij, I don't find any difference in compile times between incremental SBT builds and IntelliJ incremental builds, but as you say, it can present spurious errors, although its getting much better (and I need to keep reporting those errors).
Haha, how are you going to "force" anything, exactly?
Same way I forced the Typelevel scabs out of my code. It's not a puzzle.
Yes
You're right to think an implicit would be better - that speaks to good instincts. Better still would be a reader monad or perhaps a more general monad that would propagate the secondary information where you need it. I avoid using libraries for logging, because I think logging should be a lot more structured than they tend to support. So I will do my logging into a structured datastore via conventional libraries for ORM/what-have-you. But if you want to do it on top of slf4j I can't help thinking it would be a ouple of lines? By all means release the library if you get it working, but it sounds like the sort of thing that should be pretty straightforward and lightweight (of course that's easy to say when I'm not actually writing it).
Tanks for these links!
Currently I consume a lot of small events as stream from Kafka using Akka Streams, process them and then send (0 .. N) events to other topics depending on the message. I distribute those events with Kafka partitions(every machine is the same, no akka cluster or anything). Do you think my use case could benefit from switching to fs2 or even Spark (I guess that could be overkill) ?
Actually there isn't, and I think that /u/zackline is actually being genuine in his attitude. What seems to be happening here is that people disagree with /u/zackline point of view, and this is being manipulated into something nefarious when that isn't the case
I'll give it another try. 
Nothing. Keep it that way. Piss off.
If you're not going to force anything, why did you make a threat? You really are an impotent little online bully, aren't you?
There isn't??? The account [FooBarDeveloper](http://archive.is/1kq1M) is not strange to you? And [codingrobot](http://archive.is/ijKhe), a 7 year old account with 6 comments in total? The thread being made by a throw-away account by a supposed recruiter, naming the thread "Scala vs Kotlin"? And yet another account named [derekqw](http://archive.is/IlwVy), a 1 year old account only with comments in this thread (and now deleted)? And this is not including /u/zackline and other stuff. I would much appreciate an explanation of these examples and how they overall do not indicate a lot of weirdness. As a side-note, /u/zackline was very late in coming with arguments regarding the debate itself and focusing on it, and you should have noticed that (EDIT: there were also a number of other things, but these are considerably less obvious; the weird focus that /u/zackline had is far from sufficient on its own). From what I have read of your posts in the past, I am convinced that you are at least fairly intelligent and more than capable of seeing and figuring these things out. EDIT: Minor addition.
&gt; yes I will force it. What are you going to force? Oh right, yes, "nothing". You're strutting around trying to sound threatening, but you can't silence me with your attempted threats and bullying. &gt; If you not do same as you first commanded (piss off), then yes I will force it. Great. Let's see what you've got.
I fully agree with you that these are throwaways, making their comments quite shady. I'm not sure about the recruiter though. Did he not only create the thread in the Kotlin community until someone recommended he also considers /r/scala 's opinion? I found the interaction between us very weird and I still have no idea where your accusations came from when all I did was tell my honest opinion. All in all it seems to me like you view this entire thread as some sort of conspiracy.. And here you use this "I think you are intelligent, so you need to jump to the same conclusions as I do" attitude again, that you also used on me, at the beginning of our conversation. Personally I consider this a bit manipulative.
Mhm you're not the sharpest bulb in the box are ya? Stick to Scala. 
What's that? You've got nothing? Come on, you *promised* you would force it. Was that just impotent bluster? Or are you a man that means what he says?
&gt;&gt;&gt;&gt; [notenoughstuff]: [...] Besides, you do agree that there is a lot of weirdness in this thread, right? &gt;&gt;&gt; &gt;&gt;&gt; [mdedetrich]: [...] Actually there isn't, and I think that /u/zackline is actually being genuine in his attitude. &gt;&gt; &gt;&gt; [notenoughstuff]: There isn't??? [...] &gt; &gt; [mdedetrich]: Sure that is definitely suspicious, but its also off topic [...] Off topic?? And you denied that it was so, and then I argued for it, and then you claim that it is off topic. Really? I argue against one of your claims, and you write it off as off topic. Why not acknowledge it then or not argue against it, if you consider it off topic? And how could it not be on topic? Really, mdedetrich?
&gt; And people will deal with it fine unless its done really badly, i.e. Python 3 (and even then, the worst case is that people will use the previous major for longer than anticipated). Python had a lot of momentum (and largely for good reason) so it didn't vanish overnight but its migration problems have hurt it a lot. Similarly Perl - people forget how huge it was. Java looked almost dead 5 years ago, but being able to make new releases that remain compatible with existing code turns out to be really good for a language. &gt; In any case, this is a "good" problem to have I think programming languages are the rare exception where long-term scalability really does matter. Day-to-day application code, probably no-one's going to be using it in 10 years anyway. Even libraries you can probably afford to rewrite every 10 years. But switching languages every 10 years is more costly. &gt; Scala's type inference is still so complicated that a lot of IDE's have issues integrating Scala to provide a seamless user experience (I still have problems with IntelliJ using huge chunks of memory + performance issues with non trivial code bases, and incorrect syntax/highlighting). At this point you might say "don't use IntelliJ or IDE's", the thing is that a majority of users rely a lot on IDE's. IntelliJ's Scala support is indeed substandard (another reason I mistrust Kotlin, since it's made by the same people). Eclipse/scala-ide doesn't have any such problem though, and gets the scala typing perfect. Also note that any code you could write in Kotlin will not have any of these issues when written in Scala, even in IntelliJ. When you have complex problems you're choosing between doing it with maybe some IDE issues or simply not having the language permit it at all; I know which I prefer. &gt; There is also the fact that the main build tool, while being featureful and expressive, has very serious performance problems and issues with understandability. Yeah, SBT is awful and I have no idea why people keep pushing it. Sorry :(. &gt; it was very difficult to integrate with their current build system (maven) and that was because of Scala's insanely high compile times and maven not having incremental compilation. Kotlin doesn't have this problem. Integrating Scala and Maven is trivial, I do it all the time. Yeah you don't get incremental compilation (though there are ways to work around this, and I've never really understood the desire for incremental compilation on the command line in the first place since as you say the majority of users rely on IDEs - incremental compilation in Eclipse/scala-ide works fine). Again the high compile times are something you only get when doing things that would be impossible in Kotlin. &gt; Java8 is also doomed to fail in this regard because they don't have HKT, and so working with Optional in Java8 is going to be really painful compared to Scala At least what Java's doing is fixable though - ultimately it will be possible to add HKT to Java and make their Optional usable. Kotlin have nailed themselves to `null` even as Java is moving away from it, and their current semantics won't allow them to replace nullables with a proper type without breaking existing code.
You're missing the topic. No one is arguing with you on the weirdness of the comments you listed. What is being discussed is the relation of those comments to my opinion and statements that you so objectively (/s) discuss.
&gt; [...] No one is arguing with you on the weirdness of the comments you listed. [...] mdedetrich were claiming in a previous comment that I was wrong on that very point, so this is blatantly false. EDIT: Clarifications.
yes, op is obsessed with reimplementing the c preprocessor in scala: https://github.com/ThoughtWorksInc/enableIf.scala
Yes, in a previous comment. And with his next comment he clarified that he meant that in regard to this conversation and that it has no relevance to my comments and POV that you deliberately failed to discuss for the last ten to twenty comments and instead derailed with these unrelated allegations that you project on me. 
Ah, it was a mistake of mine to begin discussing with you here, you continue to lie (despite the lies being fairly obvious), which shouldn't come as a surprise to me. EDIT: "here" as in [this specific comment](https://www.reddit.com/r/scala/comments/6ee77n/scala_vs_kotlin/dihaula/) (the one starting with "You're missing the topic. [...]").
And C++ https://github.com/ThoughtWorksInc/template.scala
And you continue with the insincerity. [Link](http://archive.is/jiYC2) while I remember. A correction of my previous comment: I meant that I should have simply replied to [this comment](https://www.reddit.com/r/scala/comments/6ee77n/scala_vs_kotlin/dihaula/) starting with "You're missing the topic. [...]", not begun discussing with that comment and user, for discussing with shills and trolls should generally not be done (though that does not mean that they should not be engaged with, so to say; that depends on various factors whether that should be done and not, and if so, in which ways). [Link to another relevant comment](https://www.reddit.com/r/scala/comments/6ee77n/scala_vs_kotlin/dibznk2/).
My guess is that nobody was willing to take the time to upkeep the code and there is very little chance that a properly tuned code will perform better then Java (you usually have to write your Scala code to look like Java once you start to optimise stuff)
`case class Fold(name: Field.Name.type =&gt; Field.Name.Value)` is a neat pattern, the receiver just needs to supply `this` and voila, typed access to receiver's attributes without having to import anything. It's nice to be able to write something like, `def canAccess(_.ADMIN, expires)`, concise and to the point.
Decent tactic you are using, and pursued somewhat well, I would say. However, your lies are still far too obvious, and the usage of tactics are likewise (though to a lesser degree) a bit obvious.
NP, happy that you could use them.
Oh, the tactics thing again, haha. Ah, and don't forget the lies too, very funny.
Yes, I also think so. We sure do like to have the last word. I don't think this leads somewhere either, so let's call it a day.
Yeah, I think we can agree on that.
i spent most of Saturday working on this blog post about using EitherT using Scalaz or Hamsters. Most of the time was spent figuring out how to do things in Jekyll because I haven't posted in a while http://justinhj.github.io/2017/06/02/future-either-and-monad-transformers.html
The article has an example of statically "obvious" type-correctness not propagating into a `match`/`case`.
seriously ? :) they're just humans, engineers, just like you and me. Why are you so weirded about it ? :) But nice job! Even better if it fuel your motivation!
I mean this: $ echo test-project | sbt new sbt/scala-seed.g8 $ sbt run test doc Auto-formatting can be added with a single line in the `build.sbt` file. Similarly for benchmarks, etc. I mean, I can see why it's _marginally_ easier when some tools like the auto-formatter and benchmarks are built into the build tool, but I fail to see the "big win for productivity" he's talking about.
Sure, that's probably what the author means by "a breath of fresh air", but coming from a Scala developer of 5 years (not a newcomer), it sounded a bit weird to me.
Is it really such a small subset? It feels like most, maybe even all the functionality of "true" dependent types is available in Scala, admittedly via a rather clunky encoding.
Actively tackling the remaining action items for Scala.js 1.0.0-M1: https://github.com/scala-js/scala-js/milestone/20
You aren't comparing apples to apples. Out of the box, cargo lets you do stuff like this: https://doc.rust-lang.org/book/documentation.html#documentation-as-tests Only thing sort of comparable I'm aware of for scala is tut Also note that having testing built in eliminates a lot of friction, e.g. lack of standardization around what testing framework / what syntax variant of that library you want to use.
I gave eclipse a very long chance and I was always, always running into issues of spurious errors being displayed. Maybe its just a windows thing, but they never managed to fix it even after years. The indexer doesn't seem to work as well as IntelliJ either, f3 wouldn't work many times.
&gt;&gt; def foo(i: Int): Try[String] Why will you return a Try from a function. (maybe I am missing something). Usually the Return type will be an Either and the Try will be inside the code. Depending upon the Success or Failure you will return a Right or a Left. 
Returning try allows you to return application versus infrastructure failures. At some point you need to convert to something else, but as late as possible. 
I'm primarily a c++ programmer, and I gotta say that's pretty gross.
Your approach will lead you right to the mess which try catch blocks had created. You can easily differentiate between infra and app errors by using a sealed trait on the left hand side and then app/infra specializations.
My god, the horror.
Can we all just take a minute to slow-clap for this blog post title?
Somewhat related, albeit from late 2015 - http://engineering.monsanto.com/2015/09/24/better-spray-metrics-with-kamon/
Hi, sorry, I meant a code example on how to construct a syntax tree with the unified approach, not the FP-style or OOP-style approach. Edit: The point being, it's only unified if it supports both use cases.
https://gist.github.com/ms-tg/6222775 might be relevant as well when using `Try` in a for-comprehension.
Agreed with the comments on actors / objects being a poor man's closure, and closures being a poor man's object system. (Though these comments have disappeared---did you edit them out?) This reminds me that SICP has a section on this IIRC. That is probably where I first read it, now I think about it, and yeah, it's been known in academia for a long time. As for the Church encoding I address that in another comment here and in the post. Depending on how pedantic you are what I have presented is or is not either a Church encoding.
You definitely do not need to be comfortable with Java before starting with Scala. It would come in handy because you may find yourself interacting with a lot of Java libraries, but definitely not necessary and you'll pick it up as you go. I usually recommend following checking out the [Coursera cource taught by the creator of Scala (Martin Odersky)](https://www.coursera.org/learn/progfun1) to beginners, and to do all the exercises. I would recommend using the IntelliJ + Scala plugin, just because that's my favourite, and probably the most commonly used programming environment in Scala. A lot of people would disagree with me but the only real beginner pitfall that comes to mind is that sometimes I've seen beginners start out with "Functional Programming in Scala" (aka "The Red Book") and become highly discouraged because it is a very difficult book (although excellent!) and really jumps right into pure functional programming principles without spending a lot of time getting you familiar with the language first. In fact probably more than half of people who attempt to go through the book don't make it past chapter 6 or so. Martin's course gives a very gentle (IMO) introduction to the language and functional programming, hand in hand.
I recommend the books from underscore.io. I think they were just open sourced. Everyone has their own way of learning, but I found these to be exceptional. Edit: here is a link. http://underscore.io/blog/posts/2017/05/29/why-we-open-sourced-our-books.html 
Ah, fair enough :)
Well, he mentioned it the second paragraph. The reaction to PRs heavily depends on the _type_ of humans who are reviewing them. It's probably not a pleasure if someone like Torvalds hates your PR. But luckily I haven't yet seen anyone like him in the Scala community. /u/tabdulradi: Saw your talk last week and it was great! You could easily see that it really means a lot to you.
Methods are much more expressive. - Methods can have overloads, functions can't. - Methods need not have an argument list, functions must have one. - Methods can have type parameters, functions can't. (This is the big one.) - Methods can have implicit parameters, functions can't. - Methods can have sequence parameters ("varargs"), functions can't. - Methods can have named and default arguments, functions can't. - You can turn a method into a function via [eta-expansion](http://tpolecat.github.io/2014/06/09/methods-functions.html) but you can't go the other way around. Functions are values with "normal" types, which can be useful. - You can abstract over functions because they have types you can talk about in the language. - You can compose functions. Normally the expressiveness of methods wins, so as a rule of thumb I use methods unless I have a specific reason not to.
I really like this introduction to Scala, especially when you are not new to programming [https://www.youtube.com/watch?v=grvvKURwGNg](https://www.youtube.com/watch?v=grvvKURwGNg) don't get discouraged by it's length, that man knows how to keep viewers attention.
IIRC I asked this question before and there's no standard apart from "implementation defined". The implementation changes too; lots of things are different between 2.11 and 2.12, for example, a nested lambda like this: scala&gt; (() =&gt; () =&gt; ())().getClass.getName res7: String = $anonfun$1$$anonfun$apply$1 Is now mangled into this scala&gt; (() =&gt; () =&gt; ())().getClass.getName res7: String = ammonite.$sess.cmd0$$$Lambda$2020/506775047 Travis Brown has written a bunch of stuff about how "Scala from Java" looks like; not just name mangling but companion objects, implicits, default values, etc. - https://github.com/travisbrown/scala-java-interop/blob/master/src/main/java/demo/UsingScala.java#L8 Lastly, if you have a REPL handy `scala.reflect.NameTransformer` is the complete (?) algorithm that name mangles Scala identifiers to Java identifiers. scala&gt; scala.reflect.NameTransformer.encode("::") res10: String = $colon$colon scala&gt; scala.reflect.NameTransformer.encode("&lt;i am a cow&gt;") res11: String = $lessi$u0020am$u0020a$u0020cow$greater You can find it's source code on Github: - https://github.com/scala/scala/blob/2.12.x/src/library/scala/reflect/NameTransformer.scala Or if you're using the [Ammonite REPL](http://www.lihaoyi.com/Ammonite/#Ammonite-REPL), you can just run the command `source(scala.reflect.NameTransformer)` to peek at it's source code
Here's a few more: Functions have fixed arity; where-as methods have a weird "empty param lists are optional" thing @ def foo()()() = 1 defined function foo @ foo res10: Int = 1 @ foo() res11: Int = 1 @ foo()()() res12: Int = 1 @ val bar = () =&gt; () =&gt; () =&gt; 1 bar: () =&gt; () =&gt; () =&gt; Int = ammonite.$sess.cmd13$$$Lambda$2113/1955947481@62a6001b @ bar res14: () =&gt; () =&gt; () =&gt; Int = ammonite.$sess.cmd13$$$Lambda$2113/1955947481@62a6001b @ bar() res15: () =&gt; () =&gt; Int = ammonite.$sess.cmd13$$$Lambda$2118/453478710@2c278e35 @ bar()()() res16: Int = 1 Methods don't take up memory; a `def` method on a class doesn't take up memory per instance of that class, while a `val` function takes up 4 bits for pointer + 16 bits for function object header + more for any variables captured. Sometimes doesn't matter, but if you have millions of small objects you probably don't want to have all of them holding on to random 20-byte function objects if a method will do! 
People are just sending me `jar` files I don't _necessarily_ have access to the source code :| its uhh complex --- Thank you for the links!
thank you!
Red book have really bad design It jumps from repetitive noob shit to advanced topics in no time. As i said it is because author did not have teaching practice.
those https://www.scala-js.org/libraries/skeletons.html look interesting. odersky and wampler books good as references. mastering akka or reactive web applications (and their github repos) more hands on. you can start Scala from scratch, pitfalls might be getting to sucked into fp world. At the end of the Red Book the author states "we've only just scratched the surface of fp". So as a beginner in Scala it can feel its a never ending road to learning it if you go down the fp path. It's worth doing though if you want to learn all the new concepts, just be aware it can take long time. 
One might add that in Dotty functions can have implicit parameters. One of the cool new features.
I didn't like Odersky's Coursera course at all when I just starting learning Scala. It is good, but not for beginner. Silly question about - Newton's method. I'd never heard about it before. Sorry, I don't have math background, I came just to learn Scala. "Scala for impatient" was really good for me. And a lot of practice. Also I'd suggest [The Neophyte's Guide to Scala](http://danielwestheide.com/scala/neophytes.html). After gaining more experience "Functional Programming in Scala" was really cool. I loved that book. Now underscore.io's books could be really good too.
you should ask the mods to include it in the sidebar
I'll add it when at a computer :-) Edit: Added!
&gt; Methods don't take up memory I know what you were getting at from the rest of the paragraph but this isn't correct. The method takes up memory, just in metaspace rather than heap.
At that point, why not use Akka HTTP?
What kind of space does it take up? Just a constant amount per class whereas functions would be once per instance right? AKA: class A { // each instance of A allocates new f val f: Int =&gt; String = (i: Int) =&gt; i.toString } // constant space for arbitrary # of Bs Class B { def f(i: Int) = i.toString } 
Well, one simple but somewhat ugly way would be to simply have a tuple, where the first part is the head of the sequence, and the second part is the tail. A less ugly way, which I haven't tried personally, may be found in [Scalaz](https://github.com/scalaz/scalaz): [NonEmptyList](https://github.com/scalaz/scalaz/blob/series/7.3.x/core/src/main/scala/scalaz/NonEmptyList.scala). I believe there are also other libraries that have similar abstractions.
[This](https://github.com/tarao/nonempty-scala) looks good but I only saw it recently and haven't tried it out. Cats also has NonEmptyList and NonEmptyVector (http://typelevel.org/cats/api/?search=NonEmpty) 
Shapeless has a "sized" representation that gives you [type-safe size for collections](https://github.com/milessabin/shapeless/blob/master/examples/src/main/scala/shapeless/examples/sized.scala) Edit : wording Edit2 : You can also use [refined](https://github.com/fthomas/refined) which lets you enforce invariants at compile time. It contains a bunch of pre-defined invariants, among which are some useful ones for your case. 
That is not true actually, else they would be equal, here's a code sample: class A { val f: Int =&gt; String = _.toString } val aa = new A val bb = new A aa.f == bb.f // false
Did you watch the excellent macros vs shapeless talk?
* Methods can't be passed as a parameter (eta-expansion does help, but it's effectively creating a new object on the fly), functions can. 
Can you provide a link?
Thanks! 
Might want to check out the Typelevel conference videos as well, as those projects are in their ecosystem of Scala libraries.
Read a few chapters of [Programming in Scala](https://www.artima.com/shop/programming_in_scala_3ed) and start using Scala [as a scripting language](http://www.lihaoyi.com/Ammonite/).
I'm using this [Scala Logging](https://github.com/typesafehub/scalalogging) library and I'd like to "push" a parameter into the logs, so each line is prefixed with the requestId from an http4s request. Anyone know how to approach this please?
Do companies still give time off to study ? Most should be happy to buy a few books for you. My old company did training which was ridiculously expensive, ok when they were making tonnes of money, but that stopped when the money dried up. I would not let it bother you if they don't offer these things, just learn on the job and any spare time you have. Having commercial Scala experience is good for your CV so your company is already doing you a favour.
https://vimeo.com/217863345
Thank you!
Just to be clear that I'm not complaining about anything. I just wanted to give a bit of context to my question, but you can ignore the first sentence. Also, I'm personally a fan of self-study and invest a lot of time in it, but I don't think it should be expected of everyone. Certain activities can benefit a company's image if done well, too (OSS, blogs, etc.). &gt; Do companies still give time off to study? This was just an example and not something I would reasonably expect, though I do know someone with such a benefit. 
One of the best explanations I've read: https://tpolecat.github.io/2014/06/09/methods-functions.html
I'm thinking at a higher level. If you genuinely need access to the previous and the new values of a structure, then a mutable structure would make your program incorrect; if you're using a structure in a one-writer-or-many-readers-at-a-time way then there's no reason what you're doing can't be implemented as in-place mutation.
Recently found out about Ammonite. Downloaded the REPL. Definitely not switching back to stock REPL. :) 
I'm still migrating from my previous laptop, and part of that is scanning for any files in my development directory that haven't been checked into GitHub. I wrote a tiny tool for that: https://github.com/Sciss/GitSync - and I just added an extra check to list files in `.gitignore` that I might have overlooked in my backup.
&gt; I've never found any of that stuff helped What trainings/educational programs have you experienced in a corporate setting? I'm asking to learn more about the low value you or your colleagues enjoyed from such programs. 
`counter += 1`
At various jobs: books, internal training sessions, access to a (local) conference they were sponsoring, regular internal talks, internal study group, assigned mentor.
We take every evening on thursday from 4pm till 9pm usually and throw ourselves a little code retreat, where we Do Simple Things In A Complex Way TM.
Ah, I see: the `"credit" :: "charge" :: Nil` is a pattern that what's extracted by the `Seg` (the `List[String]` in the case where it returns `Some`) is matched against. Same as you could do: val myOptionListString: Option[List[String]] = ... myOptionListString match { case Some("foo" :: "bar" :: Nil) =&gt; ... case Some("baz" :: Nil) =&gt; ... case Some(xs: _*) =&gt; ... case None =&gt; ... }
I hope these aren't all of them, since there are presentations missing.
In general, yes. Right now, probably not.
Questions tend to be very specific, relating to a problem the developer is facing right at the time they ask the question. E.g. how do I use this API? Why am I getting this compiler error? The task of the mentor is to spot the underlying patterns and then teach the missing concepts they identify. E.g. if someone is struggling to use flatMap in different contexts it's probably a good idea to talk about monads and doing algebra with types.
Have you ever been asked "why use Scala"? Or that never comes up as, like you mentioned, questions tend to be very specific to the task at hand?
Evidenced by the use of mutable variables ;) 
Yes :( lol
Maybe they provide beer?
Oh man! What's the average age of the employees there? I actually work for a startup and I'm one of the older people there, I can't imagine being at work on Thursday night! 
Having lead a few training sessions, I prefer a combination of the following when onboarding new developers: 1. periodic brown bag lunch sessions, with **small chunks** of **very focused** topics as part of routine training. It doesn't interfere w/ work and it's fairly casual. 2. Periodic pair programming for first couple of X weeks and especially during the first 2 or so features a new employee will work on. 3. Take careful attention between explaining and differentiating concepts, high-level design, mid level components, vs low level details. 4. Avoid jargon early on unless new employees are well versed in the particular domain/tech 5. Provide a recently added feature that serves as a good guideline in terms of coding practices, design, etc. 6. Most importantly, if there is someone who's going to be actively involved in training in any way, that person should be patient and have the ability to communicate clearly. I've met too many condescending aholes in my experience. New employees and existing ones should not have to feel stressed when joining a new job, or struggling to learn something new( especially when they have the capacity to learn but the process fails). if they are it could be a strong indicator they may not stay with the company, and employee churn is a big expense.
how about this? sealed trait AtLeastOne[A] case class One[A](a:A) extends AtLeastOne[A] case class ConsAtLeastOne(head:A, tail:AtLeastOne[A]) extends AtLeastOne[A] You'd need to implement map and flatMap in it, and honestly, I think you'd be better off with scalaz http://eed3si9n.com/learning-scalaz/Validation.html#NonEmptyList
Well, people are not forced to stay, but wrapping your head around takes time. And it is fun, and we do provide drinks :) However alcohol is not very popular here, so we stopped buying that.
Around 25ish. I personally believe that you should learn outside your day job, and everyone just agreed on that time for learning.
why ? I came to Scala because of its links with Big Data (Spark) initially. I got a bit lost (felt a bit directionless, too much diversity, time to learn it) with the FP side of it. Maybe some came to Scala because of its backend (Akka) ?. Does anyone know why the people interested in FP jumped on board, and why not go with Haskell ? I'm just curious that's all. By the way i like the FP side of it (i'll learn it gradually), but i prefer more pragmatic to theory. 
funny story :). Maybe there needs to be a new Scala book called "Functional Pragmatic Scala" :)
I'm part of a Scala team in a company with a history of Rails. I started as a team of one and we've grown to a team of four. We tend toward the functional side of the spectrum. Our on-boarding process starts with the Specialization: Functional Programming in Scala Coursera series. The company pays for the course, and while most people chose to work on it after-hours we wouldn't have an issue is a new hire were to use some of their work hours on it. We tend to supplement Coursera with some youtube videos on Scala syntax basics. Since people often find it easier to learn when solving a concrete problem, we make ourselves available to answering all types of questions when new hires start using Scala. The companies book budget is FAIAP unlimited, but there's an understanding that employees are reading the books rather than just hoarding them so it's never been an issue. Paid time skill improvements have been bringing in language and library experts to answer questions in the group setting for a couple of days at a time. Outside of work hours, I tend to be the one watching Scala conference videos and sharing relevant talks on the team's Slack channel. I suppose it's supported in the same way that making anyone more knowledgeable or productive is. Compared to some of the other responses it sounds like we're ahead of the curve which seems a bit strange because none of us have programmed Scala before.
In this context, is lift really dead? I'm just learning to use it.
Are the slides anywhere?
Wait, what's wrong with throwing an exception containing the actual typed data you need? Sometimes I don't want to clutter up my return types with `Either`. An exception can be just as much a part of the return type contract of a method as `Either`, if it's handled carefully. Also, I didn't follow your chain of thought from using exceptions to low velocity. I mean, I know that's just a general example, but I feel by the same token it's glossing over a lot.
A lot of what you're doing sounds great. I'd really like to facilitate sharing and collaboration between teams more than anything, and it seems like you've found some good ways of doing that. Thanks for the input. 
Sam Halliday is working on something like that I think. Early days though.
The problem with exceptions, is that they can't be checked by the compiler and they WILL get lost as your code being used. I hate when i get an exception from the bottom of a library, but i have no idea that it could happen, and i have no idea why. I'd rather spend that time developing, than debugging someone else's code. Either (or even Option or Try) forces error handling, and clearly signals your intent, and let's the compiler validate that what you are doing right, and uncaught runtime errors will be produced. In that sense, exceptions cannot be type of the contract, because nothing forces you to document it, and nothing will checked if the are handled. Although i think that exceptions still have a place, but only for system level, unrecoverable errors, like out of memory error and such.
That's not really true, since shapeless uses a lot of macros. It's nice that you don't have to write it yourself though.
There is Ensime, but it's still a little too green for VSC though.
https://github.com/dragos/dragos-vscode-scala - it based on ensime, but has only basic features 
I'm not so sure this is an FP vs OO style thing as opposed to just a Church encoding thing. In the "classic" style (by which I mean whatever I think is taught in school), we model variants using algebraic data types in FP and class hierarchy in OO, and we model operations using functions in FP and methods in OO. As you note, the styles differ on which axis (variant/operation) is the easy one to extend along while the opposite axis is the clumsy one. But in either style, as long as your operations are "decomposable" (depends only on the results of operations on subtrees, without having to directly interact with the actual terms/objects), you can Church encode and save on creating a bunch of terms/objects. This is analogous to modelling variants as overloaded functions/methods and then modelling operations as choosing a particular implementation via records/instances. As far as FP vs OO goes: FP functions compute by pattern matching on data (built-in), which translates to OO visitors visiting (clunky). OO methods compute by dynamic dispatch (built-in), which translates to FP records-of-closures-and-adapter-functions (clunky). I think the real unifier would be having multimethods (for the first case) and extensible records (for the second).
Glad to read that. I have met people where I thought "how did they even become senior developers with their ability", but most of the time I meet people or look at libraries online I think that these people are much better developers than I am.
Check Dunning Kruger effect
Glad to hear that they're replacing that old clunky gc! Fast startup, low latency and manual memory management are what most miss from the JVM.
Am I understanding it correctly that GC beats no GC in some cases? Is it because of better locality or something similar, or am I misreading?
Isn't the Hotspot GC one of the most advanced and performant ones available?
&gt; The only use case of # projections in Shapeless is to model type lambdas, like when in cats you do something like ({type L[A] = Either[Throwable,A]})#L [...] These will be illegal in Dotty (they use # projections) No, this is still allowed in Dotty (you can try it in Scastie!) because L is a type alias and not an abstract type, so there's no possible type soundness issue: http://dotty.epfl.ch/docs/reference/dropped/type-projection.html
Many items in *Effective Java* are logical consequences of functional programming: minimize mutability, minimize inheritance (and favor composition), favor generic methods, use type parameters where possible, avoid nulls, use exceptions for exceptional situations. I think *Functional Programming in Scala* is an excellent primer on both how and why to do functional programming.
Not directly related, but maybe helpful on your reddit journeys. You can insert preformatted code by prefixing each line with four spaces to get: sealed trait Tree Trait LogicalTerm extends Tree { def op: LogocalOp } case class SimpleTerm(op: LogicalOp, ids: Seq[Int]) extends LogicalTerm case class ComplexTerm(op: LogicalOp, subTerms: Seq[Term]) extends LogicalTerm And you can make inline preformatted text by surrounding it with \`\` like `Tree`. \*\* around text gives *italics*, \*\*\*\* gives **bold**, \*\*\*\*\*\* gives ***bold italics*** and you can escape a character so reddit doesn't interpret it at all with \\ (backslash) before the character like \\* for a literal \* instead of starting italics.
Very helpful! Thanks for taking the time
Without looking at your code I can only guess but you probably want an accumulator value instead of directly returning your tree from your recursive calls. Check this article: http://blog.emielhollander.nl/tail-recursion-and-the-accumulator-in-scala/ But if you get stuck post your code, it's easier to help that way.
You need a stack to traverse a tree (e.g. inorder), and tail recursion removes the stack from recursive functions. So, you'll need an explicit stack instead.
The [2.12 release](http://www.scala-lang.org/news/2.12.0) had some notable new features you might want to check out. There were some nice improvements to `Future`, `Either` and higher-order type inference.
Some projects that are 2 yrs old or less: Akka Streams / Reactive Streams http://doc.akka.io/docs/akka/current/scala/stream/index.html Lagom https://www.lagomframework.com Cats - http://typelevel.org/cats/ 
&gt; Why a writer returned? Writer[Vector[String], Store] has more noises than Store, has any way to avoid the boilerplate code and remain the no-side-effect? Generally you'd use a monad transformer to combine both effects, i.e. `Kleisli[WriterT[Future, Vector[String], ?], Config, Store]` or some such. Once this gets cumbersome you can look to either free coproducts or final tagless encoding - I don't quite understand how you're using `Kleisli` here, but the general idea is you'd use `for`/`yield` and separate the effectful calls (`tell("bla bla bla...")`) from `yield`ing the final value. &gt; Write log is not ad-hoc! I should build a vector of String to hold the message, using :+ or ++ operation to add log. I think it's not ad-hoc logging, just like write log.info(...) anywhere. The point of `Writer` is that it handles composition for you. You do have to create the single-element `Vector` yourself but you can define a helper method to do that; you should never be having to `:+` or `++` "manually", that gets handled by the `for`/`yield` composition.
It might be worth noting that Future isn't functional since constructing one is a side effect. Might be better to use one of the Task or IO implementations
Yes but will the new GC be better than the JVM one in that aspect? If not latencies will still be suffering (unless you go unmanaged of course, but then it doesn't matter)
&gt; fiddle with the graph at runtime So, with SBT you make a program inside a program to add complexity and slow down performance. Basically, definition of FP :D
`Future#recover` gives you the exact exception in your handler function.
`recover` allows you to handle a specific exception, but nothing tracks whether those exceptions you `recover` aligns with those exceptions you `throw`.