Thank you!
In TeamCity you can define the build in Kotlin DSL, if that's what you're looking for. The build itself is best to describe as part of the build system that you use (Maven, Gradle, MSBuild, etc) and then call the corresponding build actions from the CI server - that's a pretty widely accepted practice and doesn't really differ whatever CI server you use. And this exactly matches the goal that you've mentioned - reproducing the build locally. What matters is the integration for the build tool in the CI server as the CI server could provide extra insight to the process if it can provide the integration.
"Third-party" is kind of a fuzzy concept: it is now a .Net Foundation library and the primary developer is a Microsoft employee.
Would they also flag Visual Studio, since it's also using that library?
Sure, but when the answer given is "hover over it and see" I'm giving a scenario where that is not a good answer.
Also, Core 2.2 changed from 2.1 and identity is now in a razor library, one could make a project and not see it at all in the files. I came from MVC 5 and it took me a while to figure out how to use the new identity.
I'm sure this will be reiterated below, but JNK is working on the new MS JSON serialiser. [JSON.NET](https://JSON.NET) is an amazing library, but there are a bunch of issues if you're using it in legacy code. First impressions of the new MS serialiser are positive. Apparently it's mostly backward compatible with [JSON.NET](https://JSON.NET) (Probably a Hanselman post, I can't remember). &amp;#x200B; Still, this is a good article and kinda expands on some of my legacy concerns :) &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B;
Did you use [RequireHttps] in your login-controller while IIS isn't set up for SSL/HTTPS maybe?
In vs studio, Ctrl + shift + space
Some's suggestions would be; \- Without sounding simple have you cleared your browser cache? 301 are hard cached by the browser. \- Check your config files or any referenced ones for URL rewrites \- Any redirects in code that is referencing the URL? Hopefully these help, these are the usual ones that catch me
It's no secret that project references in .net framework really suck when working with lots of projects and team members. I wrote this tool at my last job to iterate a directory structure and update the package.config and csproj files to use a single package. It might be useful to you. https://github.com/codenesium/NugetPackageUpdater
Exactly
Doesn't that argument apply to everything? "If something makes you easy to shoot yourself in the foot, then don't do it."
I hit that same hurdle having to scaffold all my asp.identity pages, then wrapping my head around the PageModel class.
&gt; have a bunch of rows that calculate a running profit/loss and the amount to stake on the next row So it sounds like the logic for that can or will be different between staking plans. I'd be looking at how much logic might be shared between different staking plans, and then in a larger context of my application - is that model the right place for that logic.. where else is it used, for example. It wouldn't be terrible if that logic lived in another class hierarchy that was connected or passed into the models for use. It is fairly subjective, imo, and something you get a better feel for with experience. I think that's why a general guideline like prefer composition is helpful. Usually either way will work out alright, but there's more of a chance to paint yourself into a weird corner with inheritance.
The login is built to work on [ASP.NET](https://ASP.NET) Identity so I'm not sure. It's an [ASP.NET](https://ASP.NET) Web Forms app so no controllers
Are you talking about NHibernate?
&gt; Is it possible the version of IIS that I'm using is too outdated for this project template? No. What I notice hitting your login url is that IIS is reporting the StaticFile handler cannot locate the file to serve. There's a fair chance that means your IIS is not configured correctly to pass extensionless urls off to the ASP.Net handler. It's been a while since I've dealt with an issue like that, so I'll just link you to a possibly relevant SO post. You probably want to look at the first answer. https://stackoverflow.com/questions/9703090/http-404-page-not-found-in-web-api-hosted-in-iis-7-5
Might be.. I couldn't hear properly.. assuming that it indeed was NHibernate.. what exactly is it?
&gt;have you cleared your browser cache? 301 are hard cached by the browser. Yes, no change. &gt; Check your config files or any referenced ones for URL rewrites Nothing that I can see in my config though I don't know what the other modules to do with optimization are doing (they come built in standard with the project template) [https://pastebin.com/cqKkH4D2](https://pastebin.com/cqKkH4D2) &gt; Any redirects in code that is referencing the URL? If the user isn't authenticated, the landing page on the site will redirect to the login page. This is by design: if (!User.Identity.IsAuthenticated) Response.Redirect("~/Account/Login.aspx"); Adding the `.aspx` file extension to the redirect doesn't fix this behavior
I've done both. I am a lead that sees over a multitude of flavors for applications. I can tell you, with certainty, that the apps that have a separate UI package, using an ngnx proxy or some other configuration with distributed repos, take longer to checkout and sign off. Only one team supports them and there are 3-4 times as many packages involved. The other team that has a more traditional SOA architecture and a coupled client and web server repo, and 1 separate SOA service is deployed, signed off, and offline within a couple hours. Ironically, the second team has a larger user base as well. They spiked out 1 service for the authentication and profile stuff that needs to scale, but everything else is in a traditional "monolith" format. It is extremely performant and sees release as many as 5 times a week (for small features) or monthly for larger features. Again, it's about trade off. It's easier for 1 team to manage a few resources than it is 20. As long as the code is written well and follows a good pattern, it can handle load and be fairly agile. When they found a need for a "microservice" they fleshed it out and built it, but not everything. In this case, there is no need to separate the client code from the web server, as they are tightly coupled and will always live that way. I'm not saying a separate client repo and a separate web api are wrong, just that many times it's not necessary. Additionally, you can write your front end to feel that way while still maintaining the same repo. Heck, the dotnet core react template sets you up exactly like this. 
lol, it's like network latency isn't a real thing or something...
I think I prefer this solution. I tried using var for a while but I ended up not being able to tell what type a variable was declared as at a glance. Becomes super annoying when working with APIs you're not too familiar with and aren't sure what types they return. I do like being able to just type "var type = blah" and then "correct' it to the specific type but otherwise I don't use var. This is nice though since you keep the type with the variable name but just indicate you want to construct a new instance. If the constructor is separate from the variable declaration this could still result in some readability issues so I might not use it there.
Agreed, in this case I don't think I'd use it. Hopefully VS2019 will have a code stye rule "only allow implicit constructor type name with explicit variable type declaration".
So much this. This is what I was hoping for when asking. You saw and understood what I didn‚Äôt and now I can proceed on it. Thanks so much. At this point it‚Äôs looking like something that was hot fixed so I figure as much as I hate it, windows update is the way to go. 
To the link you provided, it looks like the handler mapping is already there both on the website in IIS and on the web server itself: [https://imgur.com/a/F6coQ2P](https://imgur.com/a/F6coQ2P)
AutoMapper is fine for projections as long as you use ProjectTo in the IQueryable chain. `IQueryable&lt;BusinessObject&gt; BusinessObjects = GetQuery(); // query is not run yet, and it may have Where/Group/Join conditions etc at this point` `IQueryable&lt;SomeDto&gt; DtoQuery = BusinessObjects.ProjectTo&lt;SomeDto&gt;(); // still not queried yet.` `var names = await` [`DtoQuery.Select`](https://DtoQuery.Select)`(x =&gt; new{ x.Name }).ToListAsync(); // will select only the Name column from the database.` Useful for keeping db objects out of other layers but still supporting IQueryable
bin and obj should be ignored. obj are temporary/cache files generated as part of the build process (and possibly used for stuff like incremental builds IIRC). bin contains your final builds, as well as the default location for publishes. You don't want to commit either of those since they are not useful from a version control perspective, and anyone who checks them out can easily regenerate them with the proper tools. If someone without the proper tools with access to version control wants a build I will typically put an extra folder in version control and manually drop a build in there as needed.
So I put only this into the config file and it fixed the problem: &lt;modules runAllManagedModulesForAllRequests="true" /&gt; But then I read further to find this is a bad solution for the problem and instead the UrlRoutingModule is the thing people recommend: &lt;remove name="UrlRoutingModule-4.0" /&gt; &lt;add name="UrlRoutingModule-4.0" type="System.Web.Routing.UrlRoutingModule" preCondition="" /&gt; Unfortunately, when I use this, my master page file now errors with a NullReferenceException (object reference not set to an instance of an object) on this line: ViewState[AntiXsrfUserNameKey] = Context.User.Identity.Name ?? String.Empty; Not sure how to proceed from here except to go back to the fix that worked...
Nice. Will investigate :)
Well I just don't agree that ability to configure several build steps is somehow "shooting yourself in the foot". Maybe if a number of steps is significant, then it can indicate a problem. But otherwise, this point of view sounds too restrictive to me. But I am TeamCity developer, so what else could I say? ;) &amp;#x200B; Anyway, if you don't need any benefits from your CI system or plan to migrate from a specific CI to some other, then it probably makes sense (although all CI servers these days try to make you dependent on them with help of proprietary yaml files). But with this approach a CI server is nothing more than a dumb distributed cron, and if it's a paid CI then what's the point? &amp;#x200B; In case of TeamCity, telling the server a bit more about your build process has benefits. It can save significant amount of developers time later, when they'll try to understand why some build started to fail and what actually failed there. But for this to work TeamCity needs to know how you run your tests or what type of build system do you use. It's not enough to just start some script.
Configuring PerfView to monitor a running app has always been complex to me. Is there any recommended guide on setting it to monitor dotnet core apps (memory, tcp sockets, cpu usage)? 
You can emit specially crafted strings which can tell TeamCity about your build process. This is embedded in both Cake and NUnit. When not running in TeamCity context, you just output normally to console, otherwise you output the TeamCity way. The best on both worlds, and not too much dependency on TeamCity and all disadvantages that come with it. One command to execute, and it all goes automatically. 
I'm the mod over on /r/fsharp and I just found a post by you about this that had been removed. Just wanted to let you know that I've approved your post and commented (but I'm in the same boat as you) and asked the community for advice. 
&gt; But then I read further to find this is a bad solution for the problem It causes requests that otherwise would not have to enter the ASP.Net handler pipeline - primarily requests for static files - to still enter the ASP.Net handler pipeline. Realistically, it's not much of an issue for lots of sites as they just don't have the traffic for it to matter, and static file assets should almost always have high client cache times and served via CDN, further reducing the impact of that setting. &gt; ViewState[AntiXsrfUserNameKey] = Context.User.Identity.Name ?? String.Empty; .User and/or .Identity is likely null there. Whether or not that indicates a different root issue I couldn't say, but you should be able to at least avoid the null ref with `ViewState[AntiXsrfUserNameKey] = Context.User?.Identity?.Name ?? String.Empty;` And I suppose perhaps Context itself could be null.. but I think offhand that would always have an object. Could be wrong.
Just a side note, I'd recommend working with, and when asking for help posting, the .config files rather than the UI.
Thanks
Fair enough. I don‚Äôt see any of this stuff in the web.config for the site though so I thought it must be in some other config file but I don‚Äôt know where that file is unfortunately
Is this basically an OS from scratch that only prints "Hello" to the screen? I'd say that's a neat demonstration, but still about as useful as most other "Hello World" programs. 
You can use hot reloading, eg. https://docs.microsoft.com/en-us/aspnet/core/client-side/spa/react &gt; spa.UseProxyToSpaDevelopmentServer("http://localhost:3000")
Sure, but we're kind of lucky that NUnit team allowed to add TeamCity service messages to NUnit at some point. This is not the case in 99%. NUnit is just an exception here.
I can‚Äôt tell if you are being sarcastic or completely missed the point of the demo. Maybe I‚Äôm being to harsh. How many OS from scratch have you written?
Maybe tomorrow's "Linux" might be written by today's C# developers 
Of course this code is useless, but you are missing the point. This code is showing you Efi programming with C# insted of a non managed language. Its a good starting point for "noobs" in bare metal programing
Yes and yes visual studio will remove the transient ones for you (you have a confirmation screen).
Thanks for the explanation! Yes, my comment is a bit tongue in cheek, I was hoping the true experts would explain it. Thanks! 
I've discovered the files in question aren't making it to the web app service to begin with. They are showing up in DevOps, just not getting through the pipeline.
not possible really.. if we gonna re-develop a better "linux" someday, if it isn't c/c++ again, it'll be for sure rust-lang based.
Once you‚Äôve changed the build property to Content and copy always on the files, did that help them get copied over? With your release, make sure you‚Äôre grabbing it from artifact directory. Are you using a straight copy * to get all files from your staging directory to artifact directory?
[removed]
A library OS / unikernel built on .NET would be pretty rad. 
so boot sector virii then? lol
EFI virii rather
Thank you. I'll check that out. I see it's MIT licensed so that means my company should approve its use without balking too much. 
Except the code in this demo isn't managed either.
Ive never bothered to fiddle with boot loader in C#(becassue why basically)... but I have written several OSes from scratch. It is a basic thing you do in any comp sci or engineering course? Are there people who havent?
Wasn't that the goal of project Midori in the past if I recall? A fully managed OS. Was an interesting project, though I recall it got abandoned.
Thank you, I really appreciate your help and brain power. You are right the logic will be different between staking plans. There is very little logic shared between the staking plans. It is mostly a case where each Staking Plan will have a lot of the same properties but then some extras that are unique to a particular plan. The logic that gets or sets the properties will be very different between staking plans.... I gather that would indicate that I won't gain much advantage from inheritance? Basically all I get is reuse of the base StakingPlan's properties/database table.....which is not really what inheritance is for? Thank you I am super grateful for your time. 
The strength of .net has always been simplicity of creating LOB applications. So there are many programmers to come from various background, like business or myself from science, without a CS degree. I also know of many successful developer who have no formal training outside of high school at all. At the same time I know of people who have masters in CS who build programs that look like a dogs breakfast. So I‚Äôm sure there are a lot of people in the .net community who haven‚Äôt played around with writing OSes. 
ahh ic! Makes sense now lol :) Thanks heaps for your thoughts, I think I have architectural problems with my app as I don't really have domain models yet...everythings jammed into my EF models.... But that's a different rabbit warren to deal with for now :)
Composition allows you to do much more interesting OO type stuff, especially relating to polymorphism, especially for many of the Gang of Four (GoF) design patterns. Composition generally leads to less coupled higher cohesive code, whereas inheritance tends to couple things more tightly together. Inheritance chains are also harder to understand for people who have to come along and maintain your code. That being said, you're always going to have to use inheritance at some point (interface driven programming), and inheritance makes sense in plenty of places. Google "is a, has a" inheritance and composition for an overview on when to use each. In OO, if something "is a" use inheritance. If it "has a" then use composition. But again, virtually all of the major design patterns use composition, and modern design paradigms such as inversion of control and dependency injection also use composition.
**Singularity OS is typing ...*
https://en.wikipedia.org/wiki/Singularity_(operating_system)
https://en.wikipedia.org/wiki/Singularity_(operating_system) Really cool concept. Since everything is managed code and JIT'd, you don't need virtual memory since everything is already safe. Everything can just run in Ring 0 without context switching, and device drivers can be written in C#.
Just started learning ASP.NET core, was looking into cheap or free hosting options before I got this email. $200 credit would be great but not very useful to me if it disappeared in a month.. I'd have very low traffic if any at all.
If you want cheap digital ocean or AWS lightsail are both super cheap. They will require a little move deployment work.
I can speak for myself. I've managed a pretty good developer career with .NET for the past 15 years, with good feedback from bosses, co-workers and even a successful side project without a CS degree nor writing OSes. I do lack some stuff here and there from a formal CS education, but I compensate on research. The daily basis work doesn't always require that.
I finally got it to work. I pulled the solution up on my laptop, renamed the files I'd been trying to add and added them to the solution on that build. Then pushed it up to DevOps and was able to get it to work. There was an error in the log that a file was missing, not sure exactly why though.
You can check if the dynamic variable is null or not before assigning it to your local variable.
Very cool, thanks for sharing!
You can run [ASP.NET](https://ASP.NET) core apps on Heroku for free using docker. I used [this](https://codingblast.com/hosting-asp-net-core-on-heroku-with-dockercircleci-for-free/) article to get started.
I usually use the non-generic version of DeserializeObject, which will return a JObject. JObject has a method "HasKey" that you can query about the existence of properties.
The only time I bother defining the lefthand side is if I dont instanciate it right away. Otherwise it's just a waste.
I'd you're going down that path you're likely to want to use the OAuth 2, code authorization flow. Once you exchange the code for the access token, you can use the details in there to log someone in. How you log them in though is still up to you, if you're looking at SPA and Mobile I'd recommend using something like a JWT
This is currently not supported (as of ASP.NET Core 2.2) in a template. The basic excuse I've read is, ASP.NET Core Identity uses Cookies to perform auth and doing OpenIdConnect and Cookies together is a bad idea. Especially for something like a SP. It is coming in [ASP.NET Core 3.0](https://github.com/aspnet/AspNetCore/issues/5833), however via direct IdentityServer4 integration. Until then, you can [host IdentityServer inside your Web API app](https://github.com/brockallen/IdentityServerAndApi/tree/master/IdentityServerHost) and it does have [ASP.NET Core Identity integration](http://docs.identityserver.io/en/latest/quickstarts/8_aspnet_identity.html).
*jitting method '\_\_respond\_on\_message\_recv' ...*
I believe you can have up to ten web apps for free even after that deal expires. 
Yes, you have 30 days to use that credit on premium services. You have to understand that, even though they support the noob dev community, they're an enterprise services company at their core. They want you to build a product, become dependent upon their services, and then commit your business to them. Now, don't get me wrong, I'm a .NET developer by trade and I absolutely love Azure. If I was you I'd create a throw away email address, create an Azure account, build your project, then once it's done move it into your actual preferred account after the fact. The 12 months free tier products is honestly a really good deal and should be more than enough for you to build a kick arse project if you're that way inclined (I'm currently using three 12 month thing on a throw away account for some personal projects).
That's no different from passing a variable or any other non-`new` (and non-literal) expression to the function. 
[Sitetriks](https://sitetriks) Before unveiling Sitetriks, the team had worked for years with the top Enterprise level .Net based content management systems, building websites for the enterprises. The lack of quality, functionalities and simplicity of extending and using the systems pushed the team to create a superior, modular and modern system based on .Net 2.2 Sitetriks pledges to always keep up with the latest technologies in order to provide speed and up to date experience. Just as a quick example of the performance and simplicity of use could be seen here - unparalleled Sitesync experience. P.S. Modules are added to the system in just 3 steps (one of them being optional. 
[Relesae Date 02.April 2019](https://visualstudio.microsoft.com/de/vs2019-launch/)
Good article. I've used Automapper on a few projects and it's really useful. 
The only problem I have with automapper is the the author introduced breaking changes quite a few times in the past when releasing a new version. Also certain behaviors where changed in newer versions to code behavior changed when updating automapper to the latest version. It was very frustrating to chase these down... 
Breaking changes in minor/patch version bumps?
Just use https://marketplace.visualstudio.com/items?itemName=54748ff9-45fc-43c2-8ec5-cf7912bc3b84.mappinggenerator. It's fast and explicit.
If you start a new project, I highly recommend using Razor Pages. It's just have a much better development experience. RazorPages can do whatever MVC can do. RazorPages was introduced in version 2.0 so it's pretty new. All new projects in my firm uses RazorPages. 
That's for Visual Studio, not C# 8. Last I heard they are not going to be released at the same time. 
Its fun to read the rationale for Automapper. Esp the whole convention based approach. No wonder I hate AutoMapper. It's barely an object mapper at all.
Okay I'm glad I clicked on this, I'm gonna kick it around tomorrow. Thanks!!
Thank you for the info! do you have any official link for this information? please post it here if you have!
Yep, the process has started already ... &amp;#x200B; [https://www.redox-os.org/](https://www.redox-os.org/)
Jan, 1, 2080. https://github.com/dotnet/csharplang/milestone/8 Seriously though, I've not heard anything official but rumor is late this year.
If you want to have Auto then it must have conventions.
No but I used to be much worse about upgrade guides about behavior changes. Now every major version includes breaking changes etc.
Ah nuts I forgot to write about why we explicitly avoided any kind of codegen. It was definitely something we looked at but decided against it.
It's a refactoring tool, not a code gen.
But I think, it will be still possible to test the C# 8 features by enabling them like in the preview version? [feature release](https://devblogs.microsoft.com/dotnet/take-c-8-0-for-a-spin/) and [https://devblogs.microsoft.com/dotnet/take-c-8-0-for-a-spin/](https://devblogs.microsoft.com/dotnet/take-c-8-0-for-a-spin/)
Yep
the feature of the tool is called generate mapping code.. how's that not code gen?
You right click on your constructor, etc and it generates the mapping code in your editor directly. There is no "code generation" process.
Razor pages is MVC with server side rendered views that you can use your server side generated model inside. The template is generally @{yourVar} etc to run actual server side code inline within your template. It's considered easier as you don't have to have a Javsacript framework such as Angular / React to learn and program http calls back / forth between your client and server side code. The disadvantage is every interaction in general is a page post and refresh compared to single page application frameworks such as React that provide an arguably better user experience. Most people nowadays would learn a little Razor MVC with WebApi before progressing to an SPA Javascript framework.
I think generally, a "codegen tool" is something that generates code as part of a build process, often times not necessarily human readable, to respond to some changing circumstances out of the dev teams control. While this tool does generate code, it's more of an ad-hoc tool where the generated code may be modified over time. It's all semantics.
I appreciate the input. Glad to know it is capable. I will have to give it a shot on my next project.
Automapper works well enough, but one word of caution: don't use it to clone objects. I've seen this done on too many projects and it's just not what AutoMapper is meant to do. Use another library for clonning objects. 
RazorPages looks like a new rendition of WebForms.. View and logic kind of intertwined. A lot of the browser is abstracted away so much that it's easier to just learn front-end than learn the RazorPages tooling.
It's not. It's a better model for page creation than MVC. Try it out. There is no "A lot of the browser is abstracted away".
That makes sense. I messed around with the razor syntax a little and liked it. I followed along with a API + angular course and make my own app beside it. It was obviously very cool and I enjoyed typescript well enough but there are a lot of moving parts. Thanks for your time.
The sentiment among most .NET devs that were around the time when WebForms were popular is that this is a more modern version of it. The very reason people ditched WebForms for MVC is because of the view/logic coupling - a common anti-pattern. MVC on .NET framework does indeed have more boiler-plate, but not ASP.NET Core MVC. RazorPages is offering the same pudding that WebForms offered - "build more with less work". Which is an approach that's very viable for trivial applications but never for anything enterprise - which is where 90% of .NET's market share comes from.
How is that not code generation and if it is not what is it then?
I've developed using WebForms before. I know how it works. The problem with WebForm is that it wants to be WinForms for the web. Everything is serialized into a blob in ViewState and everything is POST. RazorPages is nothing like WebForm. To suggest otherwise is FUD.
Code generation is a broad term. If you use "extract method" refactoring for example, it will extract your code and create you a method with default name. It generates a bit of code, but you wouldn't call that "code generation", wouldn't you. With this tool, public class A { A (B obj) { } } With this tool, you just right click and it will generate all this.prop = object.prop; codes for you at the constructor. So it just saves you loads of typing. That is all.
That‚Äôs just not true. Every bit of documentation disagrees with you. 
You can download ready to run Razor Pages sample here and see it for yourself. https://github.com/dodyg/practical-aspnetcore/tree/master/projects/mvc/razor-pages-basic 
This is correct. C# 8 will be in beta when VS 2019 ships. It will RTM at the same time as .NET Core 3.0. 
I‚Äôve used it before, but Razor pages are meant for incredibly simple apps. MVC is to be used for anything above templating a site (if you‚Äôre not using a proper client side solution)
&gt; It generates a bit of code, but you wouldn't call that "code generation", wouldn't you. Yes, I would call that "Code Generation". For me it doesn't matter if the code gen is triggered by a human or by a build process. &gt; So it just saves you loads of typing. That is all. This is the goal of all code gen tools
The guy is actually delusional. All documentation will tell you not to use it for anything above a simple server. It‚Äôs capable for small and neat static sites, and it is interesting, but it‚Äôs no competitor to MVC. 
thank you too for the info I have correct the title!
That's not true either. The Razor Page model actually more suitable for complex forms than MVC. Imagine a complex form with tons of select list, choices, etc. You have to stuff the data for those select lists, choices at your ViewModel as well as your Input or you put them at ViewBag (which most people recommend against). With Razor Pages, each of those data for your select list, will just be a property. Your ViewModel will be another property. Everything is clean and separated. Razor Pages routing can rival any MVC routing capability (https://docs.microsoft.com/en-us/aspnet/core/razor-pages/razor-pages-conventions?view=aspnetcore-2.2) 
Again, I‚Äôm sorry, but all of Microsoft‚Äôs own documentation says you‚Äôre absolutely wrong. It isn‚Äôt more suitable for complex sites. Realistically, you can just pass all form data via names fields, and it will auto map the form entries to an object on the server, no issue at all, though it should be done via Ajax anyways. 
&gt;Again, I‚Äôm sorry, but all of Microsoft‚Äôs own documentation says you‚Äôre absolutely wrong. It isn‚Äôt more suitable for complex sites. Then you should be able to provide me with a link no? Because I really miss that part.
Yes, I would do this in this case. If you want to deal with JavaScript data types and all their oddities (arbitrary property names and so forth) you may have to deal with the same limitations (no compile time checking).
I don't think that matters. dynamic means the compiler should not verify any accesses of members of an object, as the type is determined at runtime. In this case, the type has no Weight property which I assume is what is generating the exception (OP does not give us the exact line). All members you access on a dynamic type MUST exist at runtime or you get an exception. At least that is my understanding, I've only had to use them once or twice and otherwise avoid them.
I've written apps from classic asp, webforms, mvc and razorpages. While it's true MVC is what MS is recommending as the pattern of choice for enterprise apps, we're not all starting huge enterprise apps. They've given a lot of love to Razorpages. I recently started writing in Razorpages and love it. It brings the model much closer to the view without combining them. I've written several apps so far with it that were moderately complex and ran into no issues with Razorpages. In fact, there was less boilerplate and easy to read. &amp;#x200B; Besides, it's not an either or. Your app can be razor pages for some pages, and MVC or MVVM for others. &amp;#x200B; If you are writing a web app of simple to moderate complexity, I highly recommend razorpages. 
You keep citing documentation but haven't provided any. Have you used Razorpages yet? It's very flexible. Although MVC is it's big brother, there is a time a place to use specific frameworks. Since [ASP.Net](https://ASP.Net) allows both patterns to be used, you can use them together to get the best of both worlds. They work well together. MVC isn't the hammer for every nail.. &amp;#x200B;
I'm just getting into c#, and it's good to hear that using methods liberally isn't a bad habit. Like the article said, it just makes reading and maintaining code easier.
you can use the ? to avoid NullReferenceException. string Weight = decoded_JSON?.Weight; Read more [here](https://docs.microsoft.com/dotnet/csharp/language-reference/operators/null-conditional-operators). 
I'd more worry about learning to program then worrying about hosting :) 
It did remind me of the webforms stuff I have worked on. That is, sadly, the only professional .NET experience I have so far.
RazorPages looks great for smaller applications. But for anything non-trivial I'd still recommend ASP.NET Core MVC/WebAPI.
Assuming the author is using [Semantic Versioning](https://semver.org/) breaking changes are not only expected in major version updates, but are typically the reason for it.
The main reason I try not to use AutoMapper is that all the problems occur at runtime not compile time. I think the overhead of manually mapping properties is worth it given the risk of runtime errors.
You can always ignore bin and obj. Those are the build output and build process dust folders, respectively. You can also add pubxml.user files to the list if you're using a vs toolchain.
It's mvc.
I like where all this going. Great üëç 
Looks like Razorpages is offering the MVVM option here, the opposite of view/logic coupling. Coming from WPF, this sounds like the ideal option here.
Good point. You can also use a unit test that calls AssertConfigurationIsValid
I will try it and I am sure I will learn a lot but it seems like MVC experience is much more relevant. Even if MS came out with some super framework today, MVC will be out there for a long, long time.
Link was dead but looks like there are other similar tutorials/articles online. This is really interesting because I have access to a two year hobby dyno with Heroku. Just wondering (since idk much about docker), am I still deploying to a Linux environment when using docker on Heroku or am I able to deploy to a windows one too?
Hosting in windows environments look really expensive. The Linux environments look a lot cheaper, but digital ocean seems to be a lot cheaper for that unless I go with azure's low priority hosting. AWS lightsail seems to have the cheapest windows hosting but is still a fair bit more than Linux hosting. Are there any benefits to using azure hosting over some of those cheaper options? I plan to build my projects on some sort of free hosting then moving them to cheap hosting so I wanted to explore some options here.
That's a weird jump there. From WPF I'd make comparisons against other desktop frameworks, not web. Which is why I mentioned WebForms - the web framework that made desktop devs feel like they're web devs. [Here's the general sentiment regards RazorPages expressed in a GitHub discussion.](https://github.com/aspnet/Docs/issues/6146)
Solved
That's a very good point. You can learn RazorPages but if you're going to need MVC anyway (because of its prevalence in web apis) you might as well prioritize that. MVC is relevant in both web and cloud applications (where you don't exactly know whether your client app is desktop, web, or mobile). Its versatility is what made it popular in the first place.
Coolest thing I've seen all week. The other commenter said evaluate for null (which does work) but my code of if (decoded_JSON.Weight != null) { string Weight = decoded_JSON.Weight} sucks! I love this solution you have, thanks so much never seen an evaluator like that!
Same, but developers are a finicky bunch. Give us two ways to do something, and you've just created a religious crisis.
Tip: Every time you read an article saying "you should usually do X" keep in mind the conspicuously missing "when not to do X". Always remember, principles (SOLID, etc.), patterns (OOP, etc.), best practices (TDD, etc.), etc. are meant to BUY you something. Splitting something up into tons of methods and classes seems like an obvious Good Thing at first, until things are SO abstracted and split up that no one can figure out where anything is happening. Ask "What does designing it this way buy me?" and answer it about YOUR CODE not in general "the article says this promotes X Good Thing". There is ALWAYS a balance, and you should never blindly apply anything. Anything.
No, it‚Äôs codegen. It generates one time mapping code. If anything changes you have to run the tool again. There are benefits and drawbacks to such an approach but having used codegen more broadly we decided against this for a variety of reasons. For example we looked at T4 templates but again this did nothing to help the testing situation, we‚Äôd still need 100s and 100s of unit tests.
Fair point 
AutoMapper existed before semantic versioning but I tried to follow it for breaking API changes. I just didn‚Äôt document the behavior changes too well and yes people rightly complained when I broke their stuff :)
It's a fair criticism. I'm seeing 3 major version releases over the past 2 years alone. Usually a major version introduces a large amount of breaking changes all at once, but if you're regularly releasing major version breaking changes that cause significant refactoring every 9 months, that's an issue. A great example is Newtonsoft.Json, whose breaking changes are minor at best even on its 12th major version. Or Even [ASP.NET](https://ASP.NET) Core, which did all the breaking changes at once, and future versions only did minor breaking changes when necessary. Just because you upgrade the major version doesn't mean it's not bad user experience to be doing significant breaking changes on a regular basis.
Agreed. My goto is just using newtonsoft to serialize and deserialize, and to add an explicit clone method if performance is an issue.
Ok, thanks for the opposite side. I dont think I over abstract things, but I just write in a way you can clearly follow. 
Open the the solution, build in release mode and the just point IIS at that folder
Does it need to be Windows hosting? I'm running dotnet core on Linux hosting for pretty cheap in Azure. For me and my business partner, it was the usability of Azure over AWS et al. that caused us to select Azure. Cost mattered, but in the end, we didn't want to have PhD's in cloud technologies to launch our business. We just wanted to write the code and have it hosted somewhere with little effort on the hosting side.
No problem, and not accusing. Its a right of passage to go through a phase of believing you know everything because of some early success blindly applying things you read. Most developers come through that with a healthy skepticism about "best practices". :-)
It‚Äôs been a while since I wrote an MVC app with layers that required mapping objects all the time. I remember working on a ‚ÄúDDD‚Äù project that had domain models, DTOs, viewmodels and persistence models and we were basically mapping the same data over and over. I remember hating Automapper but I would hate it more if I coded all that boilerplate. I don‚Äôt know what I would do now in a similar project but I really hate mapping objects for design purity. 
Problem is I get like 50 errors when building it in VS community edition. Because it's the latest version I'm guessing if I can build it in an older VS version it will work (because the source code was given to us to deploy), but I'm not sure how to find which version of VS to use. 
Tbh you shouldn‚Äôt really be getting build errors just because you are using a newer version, what are build errors?
You can use a free tier of App Service and pay absolutely nothing! 
That's pretty much my goto as well, works well if all the types involved are setislizable and/or have a serialization constructor.
From what I understood, asp.net core runs faster in windows environments, but of course if it's more expensive so this probably doesn't make much of a different since you could just pay for faster Linux hosting at around the same or less cost. Just curious, how was it easier to deploy on Azure over AWS?
Shrug, no big deal.. people can decide the best way they want to do it. I don't care about the arguments. Fact is it saves time and rewriting code.. most of the time this isn't an issue, but when you are making funky things like Dictionaries Dictionary&lt;int, Dictionary&lt;(String a, Double b), Double&gt;&gt; q = new (); Being able to just put the = new() would be great, like we would do this now var q = new Dictionary&lt;int, Dictionary&lt;(String a, Double b), Double&gt;&gt;(); They are just adding symmetry. The reason the above is so helpful is I often times will have some kind of crazy dicts, but then I'm changing them up, and it's annoying to have to change two things. So let people argue, but this is just symmetry in letting people define one side or the other. 
Heroku only runs on Linux, but you don't really have access to the machine, anyway. You can technically, but the next time you deploy it's to a new machine and the old one is deleted. Also, heroku can decide to move your app (behind the scenes) to a new machine at will.
AWS seemed to require you to have some previous knowledge on how their platform worked. Menus weren't intuitive (to us). We often found things running after we were *sure* we'd stopped them or destroyed them. With Azure, we could select some pre-built images that were sorted by cost. So we could much more easily predict our monthly costs. After a couple of months of surprise bills from AWS, we started hunting for something easier to manage. &amp;#x200B; Ultimately for us, we found that simply spinning up a VM with some basic specs and using git to checkout our code onto the VM was what we wanted to start with. AWS wanted us to go through so many steps to get there that Azure just didn't have. Maybe we're idiots and just couldn't get AWS to click for us (our wives often joke that we're idiots, so who knows? :) ). I suppose it depends on what you're trying to do. YMMV.
Only reason I'm asking is because it's happened to me long ago when I used visual 2008 to build a C++ program and then when I imported it into 2012 it had a ton of type errors and it required adding a bunch of new type configurations to the code or whatever. This app is built and they gave it too us strictly to host so it would boggle my mind if they expected us to fix the code as well, we're not programmers.
Oh if you don‚Äôt have to build it just point iis at that folder 
Totally, and thanks for the advice :)
Where would I go to in IIS to do that? And which folder, from the (very poor) documentation it says it has 3 components: 1) CAPP.Web(UI project) 2) CAPP.WebAPIService(REST Service) 3) CAPP.NotificationWindowsService(Windows service) These are 3 of the many folders in the src folder. 
Great initiative! I am keen to what those code reviews, where i would be able to watch? 
The basic settings on a site, the you can give it a path, should be the folder you have shown in the screenshot
Thank you! You can find me at: https://www.twitch.tv/kaisinnel
Yes, there are free tier app services along with other free perks. If you sign up for the $200 credit offer and start utilizing paid services once you hit your 30 days mark it will start charging you. I started with the free credits but now use the basic tier for most things which is really cheap. The free tier has some major limitations if you're utilizing an SQL database (32mb limit in some cases). The basic SQL tier is only $4.99 per month and has a 2GB limit. As for running on other platforms like AWS etc, I have tried them all and Azure is by far the easiest. AWS isn't that difficult but you need to know which service you need for your website or application. S3 is common for static websites. Heroku is nice if you plan to dockerize your application but you could always self-host if you have the hardware. I don't work for Microsoft and I have no affiliation with them but if you shoot them an email they can tell you what tiers will work best for you. If you are a student I highly suggest you sign up for the free student account since it offers a lot of perks.
There should be a bin folder
Yes there is in each of these folders. When I go to IIS and right click on default website -&gt; add application and point to the bin folder, and open up the site in IE, it just says "The Web server is configured to not list the contents of this directory."
What are the specific problems with razor? At first glance, my impression is that it's less complicated than your proposed template language, but maybe that's just because I'm a programmer.
C++ is different, it requires upgrading the toolchain or having an earlier one installed. No such issue with C#. Open it with visual studio 2017 and show us a screenshot of the list of errors, then we can help you
https://docs.microsoft.com/en-us/aspnet/core/mvc/views/tag-helpers/authoring?view=aspnetcore-2.2 This way you can create exactly what you want and how you want.
Yep, I create a test asserting the configuration and others for custom resolvers.
Well, okay, that might handle the custom tag part of the requirements, but what about *ad-hoc* creation of new templates and the inclusion of sub-templates and conditionally nested templates? Many Razor errors create global compile-time errors, which we wish to avoid. In other words, ideally no mistake whatsoever by the web designers (template users) should "crash" no more than the template itself (page or sub-page level).
Exactly, you are a programmer. Many graphic designers are used to HTML, CSS, XML, etc. They may know light JavaScript, but are not expected to debug C# etc.
Can you post your Main constructor?
AFAIK there is a tag helper called &lt;partial&gt; that is exactly meant for including sub templates. You can even pass a model as Param. If you set razor to be compiled at runtime it will throw only when used. In my personal opinion I believe catching errors at compile time or even earlier with VisualStudio intellisense and syntax/type can is much better than handling them during execution. If you code tag helpers right with proper error handling you can fool proof templates. Razor was created specifically to be templating engine. Many PDF/report generators use it as a templating engine (see for example JsReport) The example code you gave in your initial post is very easy to handle with pure C# (if and foreach). I believe C# instead of tags would be even easier to read. I read your post from 2 months ago complaining about Razor. Frankly I don't understand. My thought replying to your post was that tag helpers will make it easier for people familiar with markup who don't want to learn the conditional and loop in C#. Just tried to help. We used to use handlebars for HTML reports templating but eventually switched to razor because it is so much easier. Even design people are happy with Razor because, after short weekend training on simple code basics, it allows them to have full control over templates even under complex conditions.
&gt; In my personal opinion I believe catching errors at compile time or even earlier with VisualStudio intellisense and syntax/type can is much better than handling them during execution. Most designers want to use Adobe products for their IDE because they are familiar with them. &gt; Razor was created specifically to be templating engine. Yes, but it seems to prefer a "static" view of the world. I haven't been able to get the dynamic features I need from it. It may be possible, but it seems to be more difficult to get dynamism than other templating stacks I'm used to. &gt; Even design people are happy with Razor because, after short weekend training ... Weekends? I don't want to be the one to break the news to our designers.
I understand some designers wish to sketch/paint only but unless someone builds an art to code converter, someone has to the dirty work. Good luck with your quest. 
Many post 2000 designers know HTML/CSS fairly well; it's part of their typical education. 
Only one way to find out 
I've extensively worked with ASP WebForms, ASP MVC 5 and ASP COre Razor Pages and here are my 2 cents: It's anything like webforms. Webforms had a complete lifecycle and was like an emulation of WinForms in the browser. Everytime you clicked a button in webforms, the html state was redirected at server side, to generate onclick events and so on. To achieve this, the whole page was wrapped in a fom. Razor Pages is anything like that, you should see it more like syntactic sugar on top of MVC which tries to solve the problem of of god controllers and passing too much stuff using ViewData. I must stress that Razor Pages is anything
I disagree, Razor Pages prevents programmers from creating 5000 line god controllers and discourages reusing viewmodels where they shouldn't be. Also it's a better fit with dependency Injection.
Of course SPA's are unusable with razor pages as they need a REST API server side. You should stick with MVC if you are only developing a REST API. For other apps I would recommend a combination of both controllers and Razor Pages.
Way to read only half the statement, captain obvious. 
Does it have all the features that SQL has on Windows?
Sorry, I mean in a lang that can be managed
I work a lot with DDD and I know exactly what you mean. Without AutoMapper mapping these different layers would be hellish. But trying to turn your EF models into domain models is a horrific idea. Generally I end up using the same property names in each layer so at least the mappings are relatively easy because AutoMapper pretty much maps everything by itself when the names are the same. I‚Äôm also a fan of CQRS and regularly use Mediatr as well. It‚Äôs astounding that two of the most commonly used architectural packages are both developed by Jimmy Bogard. https://github.com/jbogard
Lazy loading controls using ContentControl as a wrapper, separate xaml screens or big components so they don't choke the parser, feed it what you need on events like visibility changed. Another technique is to feed it xaml after initial screen is usable to improve rendering of future screens 
Why do Microsoft stack developer question "production readiness" so frequently when evaluating new software? It just seems like an excuse to not learn and keep up to date with new features. If there is a feature, or bug that impacts you and prevents adoption then so be it bit there really is no absolute answer for all projects or teams. Heck, I rolled out a project using AspNetCore 1.0 Beta 5 to production using EF Core beta and that all went flawlessly and with only mild turbulance keeping HTTP Platform Handler 1.2 functional after AspCoreModule got released. Sometimes risks are worth it bc now we have that application running in docker on Alpine Linux. So we enabled technical currency on a greenfield app by forward targeting.
Maybe because people don't want to toil with bleeding edge technology and instead focus on things that are proven to work. Yeah you can learn new things, but you can also bootstrap easier if you don't have to debug beta products along the way. Nothing wrong with focusing on new technology, but there's a cost associated with it. If we are talking about the definition of production-ready, you're thinking about redundancy, and scalability in mind. When the context is database related those are very important factors to consider. Like all things in tech, just because you can doesn't mean you should. Everything has a cost associated with it. 
Don't use one of those cheap shared hosts. I know the price is appealing but the product always seems to be garbage. I wrote [a blog post](https://mking.net/blog/cheap-and-easy-aspnet-core-hosting) that I often copy/paste into threads like this. The general advice is as follows: [Azure](https://azure.microsoft.com) is your best bet - it's easy to use, and has the full weight of Microsoft behind it. Deploying can be as simple as a `git push`. There is a [free tier](https://azure.microsoft.com/free/) for 12 months. After that, you can get 'free forever' Azure App Service instances that have a few minor drawbacks (shared hosting, no custom domains, etc.), or you could pay for some of the cheaper shared instances. If you want more functionality, moving up to the other paid plans is definitely worth it, there are some great features there. Scott Hanselman has a great post - [Penny Pinching in the Cloud](https://www.hanselman.com/blog/PennyPinchingInTheCloudRunningAndManagingLOTSOfWebAppsOnASingleAzureAppService.aspx) - that covers the best way to get a good bang-for-your-buck from Azure App Service hosting. The next best bet is to host on a [DigitalOcean VM](https://www.digitalocean.com/). You can use [Dokku](https://github.com/dokku/dokku) to get your own mini-Heroku PaaS, or manage the VM yourself ([following Microsoft's documentation](https://docs.microsoft.com/en-us/aspnet/core/host-and-deploy/linux-nginx?view=aspnetcore-2.1)). You can get anywhere from $10 to $100 in credit from a [referral link](https://m.do.co/c/aac4e1b54a04) - this will last you a year and a half with a small VM. [Heroku](https://www.heroku.com/) is another good option. Their product is rock solid, easy to use, and has a wide variety of pricing tiers (including a free tier and an inexpensive hobby tier). You can deploy ASP.NET Core apps using a [.NET Core buildpack](https://github.com/jincod/dotnetcore-buildpack), or using their [Docker](https://devcenter.heroku.com/categories/deploying-with-docker) functionality. In conclusion, for your specific scenario, I'd probably recommend DigitalOcean if you're comfortable manually setting up a virtual machine (installing dotnet core, configuring nginx, etc.) or Azure if you just want PaaS. Both of these options are cheap at the low end, but will leave you room to grow if you need to. 
In my experience you choose SPA and Web API or MVC.
I agree but still find myself using a mapper (Mapster rather than AutoMapper). It is so easy to introduce runtime errors, but if you narrowly unit test your mapping you essentially lose all the benefit of auto mapping. We try to make sure broader service tests cover mapping implicitly, but it's still easy to miss coverage and make changes that inadvertently and silently affect mapping.
Usually you decouple the API and the front end (MVC in your case) so that you can replace parts as needed. Build them as separate projects within the same solution. If it's a really simple app, you can combine them but it's better to use best practices almost always. 
Thanks! I looked at Azure a while back and it seemed overkill at the time. However, you bring up a lot of points that has me planning on doing a second look. I haven't looked at Heroku (yet)! But I will be looking over all of the services you recommended.
You can combine them into 1 code base if you want, it's personal preference. I'm sure a lot of people on here will argue for one way or the other, but both ways are valid approaches depending on your project. 
Interesting. So could you set everything to collapsed and as the .cs file has completed loading set the items to visible? Am I reading into that right? 
I hope not. Do you really want to expose a WS-* endpoint from your database?
&gt; If there is a feature, or bug that impacts you and prevents adoption then so be it I'd like to know that *before* I invest my clients time and money. 
The api is specifically used by the user. The application is simple CRUD
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/sqlserver] [Is mssql on linux production ready?](https://www.reddit.com/r/SQLServer/comments/b5x2jl/is_mssql_on_linux_production_ready/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
Because we have shit to get done. I love learning new technology that is stable and well documented. Spending a day trying to figure out how to work around a bug in some trendy bleeding edge framework is not a fun or productive use of my time when there are other stable and mature options that solve the problem just as well. 
You can totally combine them. Many will recommend that you go with a SPA based on a JavaScript framework. However depending on the Ned this may be overkill. The other reason that will be sited is the dreaded post back. But again depending on the audience and need this may be acceptable. Best of luck.
There is already a few answers but I want to emphasize that you should not use dynamic in c# especially for deserializing a json.
The App won't be an SPA. It's simple CRUD. The api is consumed by the user. 
Then I think it‚Äôs a good candidate for just using MVC as your front end. If I may offer a suggestion I would try to adhere to SOLID and TDD as much as you can so you have good maintainable app.
Hold my beer...
We actually pulled automapper out. It gave us a small performance issue. We mapped from Entity to DTO to Model. We saw a 15% performance gain when we wrote our own mapping files. Essentially we created extension methods that would turn a Model to DTO, then to an Entity, and all the way back down. I would suggest if you are relying on Automapper pretty heavily to do some benchmarking with, and without Automapper and see if it is causing you minor performance issues as well.
The API performance is crucial. Is there any disadvantage on building the api portion within mvc? Instead of separating it out using web API?
There is a separation of concerns issues. It‚Äôs an easy mistake to have your Data Access, Business Logic, and UI code get all jumbled up when you do it in a single app. But purely from a performance perspective it is a bit faster but much less scalable. What are you using for data storage?
Data Storage is either MySQL or postgres
Whoever this is has done a bad job. You shouldn't need the src folder at all. They should be able to provide an installer, like just a powershell script to add applications and app pools. Especially the windows service I'd expect to come with something like that. It might be working. Maybe if you hit /foo/home/index or something else that exists it would work
What are you referring to?
Multi-layer architecture is your friend here, IMO. One project for biz logic, one for data, then one each for the WebApi and MVC projects. Since doing this, every other codebase I work on looks shabby in comparison.
Who were you asking that question to? Did you further ask to clarify the 10 files? That seems like an odd number. What sort of answer do you usually get from this? Even if they answer a low number, does it really give you any insight? If you have to write a plain SQL migration and email it to the DBA, it's still 1 file, compared to writing a code-based migration.
Bit of a weird question. It entirely depends on the architecture and any possible migrations needed.
The thing you need to realise with Azure is that if you're using their languages, frameworks and IDEs you're going to have a really slick end to end dev experience. I am biased as I said before, but I'll never go back because I value dev time much higher than time spent chasing config issues, Azure is just too good. AWS, while awesome, doesn't have control over the entire ecosystem like Microsoft does in its humongous suite of products and services. I saw you ask before why choose it. In a nutshell, seamless dev, deployments and scaling are hands down the things I value the most on Azure. Ymmv of course because there's not really any wrong answer, just more difficult ones.
I asked the person doing the phone screen, a technical lead at the company. I know they use some kind of messaging like msmq. I didn't mean SQL Migrations. I meant how many code files do you have to edit. I updated the post.
I updated the post. I meant code files, not script or migration files.
Did you make that clear to the interviewer? What answer were you looking for? I wouldn't really know what to answer if someone asked me that. You may have the migration file, an entity class, if they follow the data mapper, you may have to update the mapping file. If you have various DTOs that the field needs to be a part of, you may have those for handling requests, responses, or domain events. Then you haven't even gotten into any actual business logic the field modifies, what's the purpose of the field?
I got a chuckle out of that
It still depends on the architecture. Absolute best case is one file, where the webpage generation and the database read are done in the same file. Separate the webpage and the data access and it's 2 files. Abstract the data access and you could have 3 files. Perform x amount of manipulations to the data and you potentially have x more code files modified. The question doesn't have an objective answer.
It is not a difficult question. In my job the answer would be between two and six depending on the application. Ideally, I'd like the answer to be 3-4. Like a model, DTO, ViewModel? In the last 10-15 years any application that I have worked on which had more than five code files needed just to add a checkbox to a web page was difficult to work with and not fun.
I don't think I would enjoy working on a system that requires modifying six or more files to add a checkbox to web page with a bit field in the database. That is all I was getting at. I enjoy creating new features and I like simple coding.
I'm trying to think how they can get to 10. This is all I could come up with assuming EF and a model. 1. Poco 2. Config (if they use fluent api) 3. model (class) 4. Mapper from poco to model 5. Mapper from model to poco That's as far as I got.
Well they use some kind of Messaging like MSMQ. Maybe there is a publication class and subscription class. I'm right with you! Five is about the max that I could imagine being productive with.
And why would it be bad? I count at least 10 places I our app. Client model, typing file, service layer, data layer, server view model, server service layer, server data layer and the model itself. Yes its large enterprise app.. 
You don't ever have mapping files or more than one DTO? You may have one DTO for internal systems and another DTO for the public API. Do they use an MVVM type architecture? If not, then you're example isn't really applicable. 
Isn't it hard to be productive when simple tasks take that much work?
What's a lot of work? It takes 10 minutes maybe, and if you think your schema changes through you can do them in 1 go. Besides adding fields to the database is definitly not something that gets done on a daily base, more like once a sprint.
I guess I haven't really work on Enterprise stuff in a long time. I have been at a small company for six years and I get to do simple coding. It isn't that modifying that many files is a lot of work, but it is a lot to wrap your head around when working on an application. It is nice to work on simple applications that are easy to code and debug. So if you are stepping through a post to the database it is nice to only have to debug a few class files.
So how many active users do you think you will service in a given day or hour? Also what ORM framework are you going to use. This is where you are going to see a lot of performance usage.
Honestly, more files doesn't mean it isn't simple. On a desktop application I work on, adding a checkbox to the config window involves: 1. Add checkbox to view. 2. Add property to view model. 3. Add property to model interface. 4. Add property to model class. 5. Updating model unit test. 6. Updating view model unit test. 7. Add config version migration if applicable. It's all well laid out and I know exactly where to go because I'm comfortable with the project. The above would take 15 minutes max to do.
&gt;Isn't it hard to be productive when simple tasks take that much work? I would argue when it's too easy to add new fields in a development workflow, you'll eventually end up with an unmaintainable overload of fields. Eventually, it becomes harder to be productive when you have too many fields and have to consider the side effect that each field could cause. A few years down the line, you have 50 fields which 95% of your users don't touch but you still have to maintain. Adding a new field outside of the original design should be done under scrutiny, not something done on a whim.
That doesn‚Äôt sound to bad. You really only do four. Two is Unit Test and one is config version. Not sure I get why you need steps 5 and 6, but still that‚Äôs not a red flag.
So 10 files is not a red flag, in your opinion?
So 10 files is not a red flag to you?
Because when you work in industry you need to stick to certain processes, not just to make your life easier but the life of your team. Keeping unit tests up to date will save you in future.
10 files doesn't *mean* anything to me. It's the contents of those files, what had to be changed, how readable it is, and how easy to find the files were.
I really can't say without context. I would have to know what the files were, I would have asked for clarification before declaring it a red flag.
Yeah, it does. I ‚ù§Ô∏è unit tests.
I didn‚Äôt declare it a red flag, that‚Äôs why I am asking the question on here if it is a red flag or not.
I can see 10, possibly more. Ef model updates, possible domain/service layer POCO updates, web model updates, any messaging interface updates (usually resulting in new versions of the message being created), database project table definitions, migrations for existing installs, if the property is used in our common grid/detail framework we may have metadata definitions to abstract away the crud operations on the object... If the property is used across domain verticals we may create interfaces to abstract the property for usage across verticals resulting in a multiplicative factor of changes. Although, I‚Äôm slowly moving our group towards micro services and break out of the monolith for many reasons as you could imagine. All can vary based on how/what the change is of course. IDEs really makes all this fairly trivial changes. Is it a lot? Maybe, but we are doing a lot of things. 
That might be the most Enterprise comment in the history of r/dotnet. üëè 
Haha thanks. Come to think of it, I even forgot the mapping definitions for the properties for all those mappings. There‚Äôs plenty more but I think I get the point across ;)
That's a stupid way to choose an employer. You're telling me that if the offer comes back and they're giving you 15% more than you wanted, 401K match, unlimited PTO, and 8-10% bonuses, you're gonna be like "gotta change 10 files? Nah thanks bruh, I only do 9, tops. Catch you later..."? Wtf. Maybe you're right, and their shits fucked up. That's an opprontunity for you to have an impact and look like a rock star. So, your question should be revised to: "let's say I had some ideas on making changes to the data access layer that would make code changes more effecient, how receptive would the team be to those ideas?"
Enterprise can mean many things of course, but by posting in dotnet you're often attracting an audience who is more "enterprise" minded than for example node or PHP. Debugging is nice for sure, but seperations of concern and clean code in a large application with over 100k LOC is even nicer!
That's a feature of SQL Server, from 2005 if I'm not mistaken. Thankfully everyone agreed that it was a bloody stupid idea.
That is kind of a visceral reaction. I get your point. But I‚Äôm coming more from the p.o.v. of worrying about what I may be getting myself into. My current position is pretty good, it‚Äôs just been six years so I am seeing what else is out there. I don‚Äôt want to become responsible for some over complicated system that someone else designed. Been there done that, don‚Äôt want to do it again.
Good points.
Got it thanks!
That's why you test on your own time to be able to charge more for being an authority rather than asking reddit.
Check out css. See what you can do with that. JavaScript is the next step.
Oh ok. Well I was more thinking about like SQL Server 2016. Would he amazing if a full instance could run on Linux
&gt;I don‚Äôt want to become responsible for some over complicated system that someone else designed. Then build your own application and start your own business because that's the only way that's going to happen. The reason so many companies are hiring software engineers is precisely because they need someone who knows how to fix, maintain, and improve overly complicated systems designed by someone else. No matter where you go, you're going to be building on code written by others, and parts of it (if not all of it) will be afflicted by scope creep, spaghetti code, shit comments and documentation, or just plain bad implementation.
What exactly are you doing? What are your requirements?
Thanks BinaryDichotomy, ok I've been sold on composition I think its the way to go for this case. My thoughts are currently: A portfolio has-a staking plan. A staking plan has-a collection of TransactionRows. So composition makes sense there. The TransactionRows is-a type of row. I.e. A MartindaleTransactionRow or a KellyCritereonRow. So I could use inheritance there, but....I dont see that I am going to get much code reuse so not sure its worth inheriting the rows from a base class. So I figure the way to go is to just have seperate row type classes that implement an interface. Then I will assign a collection of that interface to the StakingPlan class... Does that make sense to anyone out there?
I have a web based application that people create an item on. The only usage of the web based application is account management and creating items. &amp;#x200B; The entire rest of the application is API based. 10k+ requests per second. These can be GET, PUT, POST, etc. This is a constant flow of data depending on the clients usage of the API.
I have been at the same job for six years. Why start all over again then?
do people actually enjoy debugging framework issues in prod? i only want to use software that has been through the ringer already. no .net core 1.x for me. really should have waited for 2.1 in hindsight. using unproven software can work. but I'm not going to sign up to be support. 
Just put it in a reputable cloud ( Azure, AWS, GCP). 
&gt;are meant to BUY you something well said. 
&gt; but it seems more difficult to get practical dynamism than other templating stacks I'm used to Why not just use one of the many popular JS client-side templaters? Just feed the front end your template text and json data.
Razor Pages vs MVC is basically just MVVM vs MVC. Neither is "meant for incredibly simple apps" or "to be used for anything above templating a site". That's some cargo-cult level explanation.
I didn't mind it when I was young and ignorant, my mistakes didn't potentially cost my company millions of dollars, and a team of developers weren't dependent on the decisions I made. Those were simple times. 
Were you thinking of doing codegen at runtime or at design time? I'm interested in whether you thought about doing caching of generated mapping methods (at runtime) for performance, like [dapper.net](https://samsaffron.com/archive/2011/03/30/How+I+learned+to+stop+worrying+and+write+my+own+ORM).
In my experience the more one relies on JavaScript, the more maintenance headaches one has. New browser versions come out and bleep just brakes. Often it's because a JS/DOM security fix is added, but the fix has side-effects. There may be exceptions, but I don't want to be the guinea pig. It's not my call anyhow, I can only recommend.
Even 2016 is going to have some legacy cruft you really don't want to use. 
That sounds incredibly inefficient. I get paid for knowing things, not how I learned it. 
I miss those days. 
2017 in full release. 3019 is in CTP release. 2017 is production ready. Unsupported Windows features are listed here: https://docs.microsoft.com/en-us/sql/linux/sql-server-linux-release-notes?view=sql-server-2017#Unsupported 
&gt; If anything changes you have to run the tool again. Why would that be a problem? These are mapping code. You map object A properties to object B properties. Just because object A adds more properties doesn't mean B needs to change because it serves different purposes. Anything else the type system will take care of it. I don't know why you will need unit tests for these.
https://docs.microsoft.com/en-us/sql/linux/sql-server-linux-release-notes?view=sql-server-2017 Mostly things like replication / AD related stuff and distributed things are missing. Also you can only have single instances. 
This sounds more like a design problem with poor patterns and practices. I‚Äôd also argue that dynamic languages allow more bugs into production that could Have been found earlier - like at compile time.
Sounds like you were more happy working solo without a team in a highly coupled mess. A big team can divide and conquer if it‚Äôs designed right.
This is also null evaluation but it's my favourite way of checking for nulls.
Docker and containers is the main reason you‚Äôd want MSSQL on Linux. Not sure if that‚Äôs how I‚Äôd run it in prod but definitely local environment I run it like that a lot. And if you can run it in the same way across environments that‚Äôs a win in itself. Haven‚Äôt tried though. 
True. Development wise this sounds like a good idea. 
Use a repository pattern to share the underlying data and domain between separate projects (‚Äúdomain‚Äù != website url). I typically use the repository pattern if I need to have a public website under www but a secured portal under a subdomain. Because each of those are in a separate project, having a repository pattern allows them to share the same database structure and business logic.
&gt; Not sure if that‚Äôs how I‚Äôd run it in prod but definitely local environment I run it like that a lot Fair enough, but it doesn't need to be "production ready" for this.
For example https://aws.amazon.com/lightsail/
Assuming your local environment is Windows, why do you prefer that, instead of Windows containers?
I use A2hosting for my test server, but i'd never use it for a live server, because it's complete garbage. I'm always running into different errors, and the support sucks. &amp;#x200B; I use Azure for live servers.
Bunch of reasons. We run for example Redis that has no official Windows image. With Linux containers especially the Alpine versions you also get a footprint that‚Äôs ~1/10 of a Windows container. Everything is so much faster with that. And faster = shorter feedback loop = happier developers. There is also a tooling issue with Docker, hard to combine Linux and Windows container builds on the same machine. It‚Äôs possible with the experimental flag but it‚Äôs a lot of fiddling to get that stable. So we just run Linux containers all the way. Currently everyone‚Äôs on Windows but this opens up the possibility for people to use the OS they prefer locally as well. 
I am having a similar problem, but my use case is an Outlook plugin that host usercontrols on an elementhost. The first time a usercontrol is used locks up outlook for 10 to 15 seconds while all of the WPF assemblies are loaded. Can the be loaded ahead of time in parallel so they are ready when the user firsts visit the UI?
Then your payment scheme is broken.
MS‚Äôs own documentation says Razor Pages is meant for simplistic apps. 
So you're not using ASP.NET then? Codegen is everywhere. Hell, even your C# compiler generates code. See code generation as a way to avoid you having to type shit in over and over again, and this time without errors, and in a fraction of a second. What's not to like about that? You want to avoid all that.... why? If the argument is: "we want to avoid unnecessary magic", sure, but then don't use a platform that uses IL to begin with, or a language which generates statemachines behind the scenes for every async method you're using. I mean, you can try to avoid it, with the downside that you have to do a lot of manual labor others don't do, or you can embrace it and generate code you otherwise have to write manually and do other things in the time you safe. 
Run it in a container in AWS fargate, so cheap. 
Aws
Lol
Unless you do something special I/O will be 98% of your performance bottleneck in a CRUD API backed by a RDS. Sure, you can switch to a faster serializer instead of the built in NewtonSoft and remove some routing rules and middleware to gain 3-4ms per request. But adding the correct indexes and writing efficient SQL queries will in most cases be much better invested time. Better yet, don‚Äôt hit the DB at all, use read-through or write-through caches. But don‚Äôt start with that unless you need to. Just prepare for it with good separation of concerns.
Not everyone, you can do the same in Oracle and PostgreSQL.
Haha this is very true :) My comment is mostly out of frustration with junior developers or developers in business roles making small applications or processes for business that still use VB and refuse to learn newer technology stacks. I feel like we give them too many excuses and make them skeptical about adoption by not having confidence ourselves as senior developers and architects. Docker for example has so many benefits over running in IIS, and an Alpine build on mvc core is very fast, scalable, easy, and repeatable that to me it's almost a no brainier, but it's just a hurdle to push others through.
Please don't CSV line.Split(",") and database reader.GetValue(index)... that's not how you should CSV and database.
Absolutely. I've been using it in production for about 2 years with no problems at all.
I did not say codegen was bad. I said I looked at codegen for solving this problem and decided against it. Codegen usually refers to ‚Äúdesign time‚Äù codegen. I don‚Äôt really hear it used outside that context.
Design time. I don‚Äôt hear ‚Äúcodegen‚Äù really applied in other contexts.
B adds more properties. You run the tool again. And of course you‚Äôd need tests! It‚Äôs code that you wrote, even if assisted by a tool, and code anyone can change or mess up.
But that test has nothing to do with your objection of using a tool for mapping code. 
I should clarify ‚Äúdesign time codegen to solve our problems‚Äù. Using a tool would solve none of the problems I laid out, and introduce new ones without any solutions, so I decided against it.
It was a trade off for sure. When we get a runtime error, it usually means we‚Äôre doing something complicated and then don‚Äôt use it. Luckily it‚Äôs pretty easy to take out for a complex request.
Take a look at LINQ projections - these will perform better than the code you wrote (unless you also are doing LINQ Select projections).
We don‚Äôt have all those layers, but we still separate view models from persistence models. Persistence models (domain, EF, whatever) make for horrible view models or API models.
LINQ operates on a list. If I am mapping a single DTO to a single Model is there a way to use projection? I know with our extension methods we can do something like this. &amp;#x200B; myModels.Select(x =&gt; x.ToDto()); &amp;#x200B; That will turn a list of models into a list of dtos, but I don't know how you would use linq to change this statement. &amp;#x200B; var myDto = myModel.ToDto(); &amp;#x200B;
How should you? const string wrapChar = "\""; var valueSeparator = System.Globalization.CultureInfo.CurrentUICulture.TextInfo.ListSeparator; string WrapValue(object value) =&gt; string.IsNullOrEmpty(value?.ToString()) ? null : string.Concat(wrapChar, value, wrapChar); string WrapRow(DataRow row) =&gt; string.Join(valueSeparator, row.ItemArray?.Select(WrapValue)); string Headers(DataTable table) =&gt; string.Join(valueSeparator, table.Columns.OfType&lt;DataColumn&gt;().Select(c =&gt; WrapValue(c.ColumnName))); var lines = dataTable.AsEnumerable().Select(WrapRow); var headers = Headers(dataTable); var sb = new StringBuilder(); sb.AppendLine(headers); foreach (var line in lines) sb.AppendLine(line); var csv = sb.ToString(); &amp;#x200B;
Your post I replied to reads as a blanket anti-codegen bigot statement, hence my reply. "We explicitly avoided any kind of codegen". I never really get those statements. 
Sounds like they can live in the same project so you can deploy them to the same application. You can always migrate the mvc part out later if you want. However you‚Äôll need to create redirects if you do. Right now it is pretty common to have mvc parts to a web api. If you look at the dotnetcore template with a spa, you‚Äôll find that the spa is served with an action result while the rest of the application serves data to the spa with webapi. 
Most of the errors are dll's not found yet they are in the exact folder it says they cannot find them. 
Yes, with enforced conventions I only need one test. Two birds and all, enforced conventions and a single test.
Yep, Select.SingleOrDefault. You‚Äôd use this directly on an IQueryable, which directly translates SQL to a DTO.
Yes, but what about DTO to Model. &amp;#x200B; I think you are not understanding the application of how I am mapping. Entity -&gt; DTO -&gt; Model. Sure from EF to DTO projecting will work, but are you saying to write a manual mapping for every projection. That is what I was saying by creating an extension method you can use the select with your extension method that turns an Entity into a DTO. 
Your reading process is broken. His suggestion was to do the work on my own time, which is the opposite of charging for it.
Are the users developers?
That doesn‚Äôt help us help you, show us the actual error list in a screenshot
No - but we have a public api, which is why I'm using generic types to ensure the types will convert correct. The field and values are used for automation for the user, for instance, they can create a text field (DataField&lt;string&gt;) in the user interface, where text will be put in, or a DataField&lt;Person&gt; where a person can be selected. This is one of the problems, I can't just go from object -&gt; json, because it would put the entire Person object into the database, I want to somehow make sure if the type is Person, then it inserts [Person.Id](https://Person.Id), or something like that
I understood the suggestion, and on the surface it's an interesting one. My main point is that, in this context, it seems that using unmanaged code is a requirement. So I don't understand why the language supporting managed code is a benefit in this situation.
There are a few approaches you could take: 1. Generate an image to go behind the text and buttons to show what you want. For best results you can create an SVG which is an XML based format so .NET can easily generate one dynamically with the XML classes it has, it's just up to you to learn the SVG format and figure out how to generate the shapes you want. 2. You can generate a bitmap image (PNG for best quality with what you're doing) for the background instead. You can use the System.Drawing namespace to generate such an image. This is a bit easier since there's built in support for drawing all the different shapes directly in the Graphics class. 3. You can generate simple shapes using HTMl elements, CSS, and JavaScript. 4. If your layout is static you could do any of the above methods but hardcoded into an image file or HTML/CSS files, without needing to use any code. I did something similar to what you describe with buttons and lines between them generated from a configuration file. I chose approach #3 mainly because I wanted a dynamically resizable layout where the buttons would fill the available screen space, and CSS allowed me to specify coordinates in percentages which made this easy.
[removed]
I don't think expecting them to debug your custom templating language is better.
The argument over dynamic versus compiled is often long and involved. I'd argue the net benefits depend on the personality of the programmers and type of project. 
Ok. EF does not support generics in the way you are hoping. If you use generics, you have to make DataField&lt;T&gt; an abstract class that Person inherits from: class Person : DataField&lt;Person&gt;. At which point you might as well have DataField just be an abstract class with no generics that Person inherits from. At the end of the day, SQL needs a POCO yo save to the DB and you need to know the type you want to get when querying the DB.
It depends how one defines "custom". For example, an generic XML processor would hopefully be part of the system or kit, not custom built. However, a given shop may have common UI patterns, conventions, or styles that they want to simplify the use of. Going back to ColdFusion, it has out-of-the-box tags for typical and common templating activities. These may be "good enough" for most tasks, but are not a close fit to the shop's specific patterns, conventions, and prefered styles. Thus, one can make custom tags to better fit these. This can greatly simplify the shop's tasks.
any suggestions what i can do better?
nice. I'll have a look can do web apps and rest api but haven't touched mvc yet. 
If a stack is designed right, you don't need big teams for ordinary applications; only big applications. It's appalling how some "big team" stacks replicate schema-related info all over the place. Mass DRY sin. If you add a database column, you have to visit several places in the code in the name of "separation of concerns", BUT you didn't separate schema concerns, you duplicated schema concerns, thus the SOC claim is a lie: you duplicated concern A to seperate concern B. It only SOC'd one issue, not all issues. And if one tunes the stack to the org's convention, it has less parts and less code and is thus less code to read and less code to fix. Most developers like working with less code and having to type less to get stuff done. RSI injuries also go down.
Only big factor is that it's can't do replication, which for a lot of enterprise production environments, it's a big deal. But if you just have a single use for it and HA isn't a goal, then yeah it's fine. Also, the full cost of the licensing still applies.
Best reason for MSSQL on Linux is there are a lot of legacy applications that need a MSSQL server, and a lot of companies have a full windows install just for running SQL! This allows you to ditch the windows license and put the SQL server in Linux and better manage with less overhead. Did it for an application that was written in 1995, and it works happy with MSSQL on Linux.
Good for you for taking some of your own time to explore a technology of interest. I just briefly looked things over on mobile on my lunch break but here are some things i noticed: youre returning raw models to views in some cases rather than using viewmodels (was looking at CommentController) its generally best practice to always map to a viewmodel even if they're the same because they generally end up being different. You could separate data I/O into a data layer/project in the solution and create a service layer/project to handle any business logic- note that for your small application this is probably completely unnecessary but its very valuable for large complex applications- i generally like to see very "thin" controllers with not much in them (ilf youre interested, read up on n-tier or onion architecture). Add unit tests! This would be easier with separate business logic/data layers. As a small style note, im a bigggg fan of organization but its way overkill to have a region surrounding each one of your controller actions
Why are you using virtual keyword for entities? Was that not changed so virtual is no longer needed? 
thanks for your advice! &amp;#x200B; you mean something like an backend service for all the database stuff? (maybe a asp.net core api) &amp;#x200B;
You might not actually want to use reddits assets even if it's open source, I guess? You might want to use some CSS Preprocessor (like SASS or LESS) It's not really a Problem for your current codebase but almost all CSS you use is nested, so it be a bit easier to write for you. Also Bunding appears to be missing. But these things are not really necessary if you are only investigating the server side of things. Beside that it looks pretty solid.
Overall this looks really good for someone who is just learning! Important stuff: * I don't know if it has a proper name, but next try to separate all of your business logic into a service layer, and all of your database logic into a database or data access layer. This will help increase separate of concerns and since you're already using dependency injection, should be very straightforward. * In your `Profil` method, grabbing all of the data could be tremendously expensive for a user (e.g., Gallowboob). Try limiting what you grab by `Select`ing into a ViewModel and grabbing the Top 10 items in each property Nitpicky stuff: * FYI `async Main` is available as of C#7 * There is a `UseMvcWithDefaultRoute` extension available so you don't need to manually declare the Home/Index route
i know its not necessary but it worked good with my autoincluder and i can easy see what is a relationship and what not
 I'll take a look at the open source reddit assets thanks for the advice!
It doesnt necessarily need to be an api. At this point id actually recommend against that since you've already built an mvc app. Im more talking about a separate project in the solution that handles all database interactions/web requests/anything data i/o related. Your current web project would have a reference to the data project and call classes/methods from the data project to interact with data. The same concept applies for the service layer. Your web project calls the service layer which performs some business logic then interacts with the data layer for crud operations which then returns data to the service layer which again performs some business logic then returns needed data to the controller/web project that called it. There are a bunch of articles put there on n tier/onion architecture that explains this concept better than i am :) hope that helps
thanks im learning programming intensive since 2019 &amp;#x200B; the Important stuff is the next step of the project &amp;#x200B; &amp;#x200B;
yes it helps i take a look at this concept! thanks :)
If I find anything useful I'll let you know
Thanks Mazz - I'm really a beginner as far as webforms are concerned so bear with me. I was hoping that there was a method that would provide a tool in my VS toolbox but that may be asking too much. I tried adding system.drawing reference in solution explorer but now I don't know how to access that. I'm not trying to become an expert or anything but would like to stay with VS2017. Do you know of any online service where I could pay someone to walk me through some of these steps. Thanks again. 
Most software engineering jobs do gravitate around server work, as that‚Äôs where the majority of the workload comes from. Most languages are like that now. That‚Äôs not to say you can‚Äôt do other great things with the language, but in this time where every company needs an interactive website, the majority of the jobs will be related to web frameworks. 
I learned WPF first, got told all companies wanted web, switched to web, taught WPF in the company that hired me and migrated internal apps to it. Sadly the culture is really strong on ¬´ everything must be web ¬ª and the very very very vast majority of jobs will be web based, i would advise you to learn asp.net core even if you want a windows app job down the line
You‚Äôve preferably need to implement identity and have users login. Then show them a list of their adverts. When they add an advert you‚Äôd want to show the appropriate Angular view and then save the advert in a typical crud fashion via the API from your Angular app including the picture as a IFormFile. Then show the payment part as a separate Angular view. You‚Äôd then offer them a couple of options to enter payment information, i.e. Stripe or PayPal and then the user would be redirected to the payment processor. The payment processor would then call your registered callback and the transaction would be completed. From the list of adverts the user could manage the advert, changing the data in anther Angular view and posting back to a different API endpoint. 
I have been working on a Xamarin project in the last 4 months. It's amazing with the exception of XAML preview not working on Xamarin projects, and couldn't find a live preview for it. So I launch from VS when I need to design UI on the spot. All coding/tests/git commits are done on Rider flawlessly and better. There were few bugs after a major release and I reported one or two on their support website, they were fixed pretty quickly in their upcoming patches. One of them was critical, it got fixed in a week with a patch. All my other work is also done on Rider, I maintain an API at work, all worked inside Rider with tests. There's a desktop app I work on in WinForms. All UI is done on Visual Studio designer, and coding done on Rider. I work with both IDEs side by side for that project, similar to the Xamarin work. There are few things related to MSBuild that VS handles better, rarely VS update Nuget packages better without errors (not always the case though) but if you have both IDEs open, you can build with either when needed.
If you're interested in seeing another """reddit-inspired""" website, also running on [ASP.NET](https://ASP.NET), you can look at Voat ([https://voat.co/](https://voat.co/)) - it's also open source. Though it wasn't originally built on [ASP.NET](https://ASP.NET) Core, it's currently being ported. [https://github.com/voat/voat](https://github.com/voat/voat) 
Thanks for peek in how it works, looks like I will need to learn ASP.NET even before properly experiencing WPF since I need a job. It's kind of sad that everyone focuses on this single framework when .NET has so much to offer.
For me, the Rider search with CTRL+SHIRT+F (Find in path) was the best thing ever invented for an IDE with it's fast search and live code preview underneath with code editing functionality on that preview window.. Even Re-Sharper doesn't have that.
Who you callin rednet? 
Unfortunately no I tend to learn by experimentation so I've never used such services.
nice i have a look at it later
I work as a backend developer in .NET Core for around a year now, I got no clue yet how to use MVC/RazorPages, just never got time or will to get to it. Doesn't matter what order you learn, you need thing A now, go learn thing A, you'll have plenty of time to get to B.
r/ProgrammingLanguages
Just use a repository pattern to keep your API project in the same solution as the front end project.
Have you thought about using JSON? You can store the value in the db as a string and in code you could convert it to an object of type. You could structure your table like: Field, Value, ValueType. And then in code create the object based off the value type. 
Dude, sick. I'm beginning to work on identity/authentication for my own website and this is a great example for that. My website itself though is just HTML and JS with Jquery - I'm not using ASP.NET, but my server is dotnet core. I'm not versed in cshtml, could you tell me where your HTTP call that's linked to the submit button on the login page is located? I'm trying to emulate something like that on a button click in my JS.
look at the forms there is a asp-controller and asp-action there are the posts &amp;#x200B; example at the Post/New View there is the controller PostController.cs and there is the Action New() &amp;#x200B; and cshtml is normal html but you can use c# and the taghelpers inside
why are this many down votes??
Ohhh okay, I got you on the asp-controller and asp-action. Thank you! Nice work.
thanks, sry for my bad english &amp;#x200B; english is not may native language
With this comes the nightmare of maintaining data that is not relational. I'd rather deal with the impedance mismatch. 
I'm going through the same learning process as you, and I just finished reading an ebook about 3 minutes ago on the subject. Take a look at this: [https://github.com/dotnet-architecture/eShopOnWeb](https://github.com/dotnet-architecture/eShopOnWeb) There is a link there for the pdf of that ebook that talks all about this, and the eShopOnWeb application is a good example of how to implement what the ebook (and always\_anoniumus) talks about.
Would be great if Microsoft made an official Vue template with auth. 
I haven't looked much into AutoMapper, but could a VS Diagnostic cover some of the potential runtime issues when it finds them?
Just spend one day learning MVC, and you should be fine. You should at least have basic understanding of .NET MVC
i saw the eshoponweb project 2 hours ago its really clean &amp;#x200B; is it worth reading the ebook?
Your example isn‚Äôt reflective of actual problems and solutions - it‚Äôs like you‚Äôve picked an imaginary solution to prove your point.your talking about basic decomposition of a problem into smaller parts which is part of any designed system. It also is fair to say that those same arguments and strengths you are talking about can apply to c# and you are kinda off the post topic for whatever reason, and on a bandwagon against strongly typed languages. Your point is a basic one, less code is easier to comprehend - up till a point - then it‚Äôs complexity out weighs its extendability and maintain ability by someone else.
[I believe this is the EAV model](https://en.wikipedia.org/wiki/Entity%E2%80%93attribute%E2%80%93value_model) 
Not a suggestion on what you can do better, but a feature request: API! There are surprisingly few open source forums that have a decent API (particularly if you don't want PHP/MySQL). I'm currently using self-hosted Discourse as the "backend" for an app I'm working on but the API is a mess. This is cool though, I'm definitely going to bookmark and keep an eye on it. Thanks for sharing.
I would say the most important chapters to read are "Architectural Principles" and "Common Web Application Architectures." Might as well read the "Introduction" and "Characteristics of Modern Web Applications" as well since it's only 6 more pages.
Voat has had an open ticket to clarify their license for nearly a year now with no updates. This is the license file in their current (and recent) branches: Copyright(c) Voat, Inc. All Rights Reserved. Voat will soon update it's license agreement in full I wouldn't go anywhere near an open source project that can't be bothered to post a clear license.
Look at this [Workflow Server](https://workflowengine.io/server/). It's a commercial product, but you can purchase a license with source code.
i actually have already a API but its no that big and has no subblogs [https://github.com/cetoxx/BlogCoreAPI](https://github.com/cetoxx/BlogCoreAPI) 
You know, less pointers and casts to void* 
The power of C comes with some problems, so its interesting to see "alternatives", even if they are not as powerfull as doing the same in C
The power of C comes with some problems, so its interesting to see "alternatives", even if they are not as powerfull as doing the same in C
reddit and dotnet concatenation I guess
If you are hosting a .net core app, Azure is probably the best service. Your tech stack will always be a first class citizen with the latest and greatest goodies from Microsoft. There's a free tier that should be sufficient for small apps while you are still building/growing. 
Sorry for slow reply. Check your csproj and ensure that the old files aren't still showing up in there (possibly as None). Good job on catching the Include in project to ensure that they show up in the solution - you'll see these in the above file. My guess on the error is a rogue entry in the csproj of the project.
This feels like a stretch, but based on responses I've seen you give to various comments, it seems like HTML5 templates do what you want. You may or may not want to check out Polymer. Keep in mind I say this still feeling a little confused on why existing solutions aren't doing the job for you, so I won't be shocked if this isn't good either. &amp;#x200B; [https://www.polymer-project.org](https://www.polymer-project.org)
Let me try again. I see most productivity gains when a stack is well-tuned for the environment it's used in. That is org conventions and shop conventions, including dev team task divisions/specialties, etc. (Conway's Law at both org level and dev team level.) And dynamic stacks are more tunable in my experience because you don't have to deal with layers of type-based interfaces. Perhaps there is a way to do such in C#, but it's not obvious and not documented well in my observation and personal experience. I realize "obvious" may be relative to person, which gets back to my point about personality fit. C# seem to use big do-it-all helpers/assisters that try to cover every possibility: they throw features at the problem instead of trimming at it. Trimming works better in my opinion.
I'd probably have to create roughly 5 pages of a requirements document to explain it better.
Nice! I'll look at it in more detail in a bit. Out of curiousity, how much time did you spend on this?
Looks like the project is dead
nice
Very cool
This is exactly what you need https://github.com/lunet-io/scriban 
Thanks üôÇ unfortunately others don't seem to think so at least in this subreddit üôÉ
&gt; I don't know if it has a proper name, but next try to separate all of your business logic into a service layer, and all of your database logic into a database or data access layer. This will help increase separate of concerns and since you're already using dependency injection, should be very straightforward. Basically that's the single responsibility principle.
I'd use the following structure for a project such as this: * MyProject.Web: the web front end. * MyProject.Api: the API site. * MyProject.Tests: your unit tests. * MyProject.Core: all the shared functionality (services, repositories, query objects, command objects etc). I would keep the MVC app and the API separate for security reasons. If it's an admin site you'll probably want to have it on a different subnet from your API so that you can lock it down. On the other hand, I would not split up MyProject.Core into separate assemblies for business logic and data access logic, as many people do. There's no benefit whatsoever to doing so and it just makes things difficult for yourself further on down the road. Assemblies are a unit of deployment, not a unit of organisation.
4 weeks i learn since 2019
thank you [/u/shanselman](https://www.reddit.com/u/shanselman) for the gold award!
Damn, there are over 30 features there small and big.
You don't "use" a pattern, you "apply" a pattern. There isn't something like "THE PATTERN" that can be used, rather parts of a pattern can be APPLIED to code/while writing code. &amp;#x200B; "Use a repository pattern" sounds like you have a few to choose from, but in reality there are **N** repository patterns out there, because everyone can apply/implement it however they feel it's right
Is there any reason why you won't start on ASP.NET Core?
What happened to the follow-up article(s)? ;) This is a good solid article to get a dev started. I would mention (at least as a link), `Interlocked` functionality, as in many cases that avoids the lock use completely, and concurrent collections.
I think it just due to a legacy code base, and some teams I think are just older and scared to move to .NET Core. As far as at home learning goes and project ideas, if I built anything I would use [ASP.NET](https://ASP.NET) Core. There are some teams at the company using [ASP.NET](https://ASP.NET) Core, but leadership at the company either don't want to, or have a reason why we can't do all new projects with Core... &amp;#x200B;
The import things it missed: `Interlocked` static class `SpinLock` class `Sephamore` class `Thread` static methods, like `MemoryBarrier()` `volatile` keyword `Volatile` static class
Perhaps? I haven‚Äôt needed anything like it, though. The unit test for validating the convention is plenty.
I don‚Äôt really go the other direction. It‚Äôs usually more complex, so I can‚Äôt assume any conventions.
Not all of those are actually in c# 8. I find that this list is more accurate. https://github.com/dotnet/roslyn/blob/master/docs/Language%20Feature%20Status.md
Lol only a reasonable 17
I have a second one with concurrent collections already I will post it tomorrow, and I am in the process of writing more. I am obviously not an expert as you can see from the comments on my posts, by I try my best to express and share my knowledge 
&gt; I have a second one with concurrent collections already I will post it tomorrow, and I am in the process of writing more. I am obviously not an expert as you can see from the comments on my posts, by I try my best to express and share my knowledge 
Still a lot though. They've been working on this since before 7.2 was finalized.
None of those are concurrent collections
I wonder what's in store for 8.1 or 8.2. There are a lot of speculations regarding Records getting implemented in the 8.x versions but we shall see.
I would love records for my ORM. Being able to declare a DTO with a single line would match nicely with the way it works. 
Interesting, thanks!
It would be helpful to see what your entity models look like - Donation, Book, BookAuthor, Author. At least the relevant parts of them, such as the primary key, foreign key, and navigation properties. I'll assume a Donation has one Book, and a Book can have multiple Authors, using the BookAuthor as a relationship table. database.Donations .Include(d =&gt; d.Book.BookAuthors) .ThenInclude(ba =&gt; ba.Author) .ToList(); .ThenInclude() is only available in EF Core. If you are using EF 6, you would write it like this: database.Donations .Include(d =&gt; d.Book.BookAuthors.Select(ba =&gt; ba.Author)) .ToList(); That may be off a bit, as I haven't used EF 6 for a couple years, but it at least shows the concept.
My suggestion is to update your original blog post instead of splitting it into multiple posts. Cross-thread synchronization is a kind of topic that needs to be covered comprehensively. Leaving important puzzle pieces may do more harm than good when some junior developer stumbles upon your article in google and starts locking everywhere needlessly. You often post very short articles on your blog here but please remember that one great article is worth more than ten incomplete posts.
Quite often, the best way to learn something in-depth is to write about it, as that forces you to test and try things outside your comfort zone. Also - I really could do with a really good overview of locking performance in .NET Core (hint! hint!). In the full framework, lock can be quite costly on hot-path, SpinLock and SpinWait have been quite a bit better for me.
Hmm, will keep that in mind. Thanks
I know, I said I have one with concurrent collections, and I write more with what you asked
I may have created something useful, and the results are very favorable. I wrote a simple Assembly Loader that runs in parallel to the main thread and itself uses tasks to load the assemblies. It is driven off of a list of file definitions such that "ABC.dll" would be loaded individually, but "ABC\*.dll" would be a pattern search and would load all assemblies matching the pattern. You can chain them by separating them with commas and place a '!' in front to denote an exclusion wildcard such as "!ABC\*E.dll" which would load all assemblies starting with "ABC" and do not end with 'E' as the last character of the name. [AssemblyLoader.cs](https://gist.github.com/sharpninja/9b7bdad64a63af18deba1ee32cc06169)
So is a code snippet considered code generation?
I'm not sure why that would be a deterrent - it's something to look at.
This was posted yesterday
Not sure exactly why you need those custom types or what you're using them for. I assume these custom fields are meant to be for a particular object which I assume already has its own table. I would have that table contain the standard fields (no user-made fields). For user-made fields, I would define two tables probably: UserFields Id - autoincrementing primary key Name - string property name Type - enum which has the possible field types such as bool. int, double, string, etc. And: Id - autoincrementing primary key ObjectId - foreign key referencing record in very first table PropertyId - foreign key referencing record in table bove Value - BLOB of value. or a NVARCHAR if you want to e "stringly typed" Field CRUD affects first table. Assigning field values to records affects second table.
I wouldn't personally call Windows containers production ready. There are still a lot of bugs with them, like packets just being dropped.
[I always send people back to this](http://www.albahari.com/threading/) because it's a great grounding. It would be worth having a read to see what you've missed before you skip onto concurrent collections. 
Why?
Sessions should not reset with each request but they depend on cookies being stored on the client. Without cookies all you really have is the IP address which will stay the same in the short term but in the long term. In addition multiple people may share an IP (especially schools and businesses).
 Maybe I am doing something wrong, is there any tutorial that explains how to accomplish this? 
[Is it just me? :(](https://i.imgur.com/usx3J7E.png)
I am not sure, I never really needed a tutorial for this. Sessions should just work unless the browser is blocking your cookies.
No disrespect to OP but I found following article very meaning full. If the goal is to achieve concurrency, do we really need to learn manual threading? &amp;#x200B; [https://smartbear.com/blog/test-and-monitor/why-johnny-cant-write-multithreaded-programs/](https://smartbear.com/blog/test-and-monitor/why-johnny-cant-write-multithreaded-programs/) 
&gt; I dug into the source to find some other interesting things such as the library pulling individual code files from another repo via paket. &gt; &gt; it has since been re built and most, if not all of the paket code file pulling has been removed, most of those dependencies were related to its fsharp features and have been moved to a seperate library 
it is recommended in the docs to use this only for simple apps , and to use the api for larger and more complex apps , including subcomands 
Good to know, but shame it was in there in the first place. To bill your library as "no dependencies" yet having shady stuff like pulling individual files from other repos in. I don't know if I'll give it a second shot, but thanks for the update.
I‚Äôm pretty sure Applicant Insights can get close to the count you want, there‚Äôs some additional JavaScript you can add when setting it up to track authenticated &amp; anonymous visitors per page. Application Insights will then give you a flowchart of where visitors went from there.
The thing is it is required to be self made so there is 100% control over the code. Everything wirks fine when using with Razor pages, but fails to work with angular
IP address might just be the way to go. You may be able to make it more unique by added a few other elements to the fingerprint maybe? Like client information. But that can potentially add duplicates as well.
I wonder if this will get much use outside of gaming for other low level use cases. I‚Äôm thinking of load balancer and databases etc 
Why not session an anonymous user? Write a middleware When the anonymous user visits the site, check for a session. If one doesn‚Äôt not exists, create a new ClaimPrincipal and log them in. (They are not authenticated. Just have a session.) You can now track the anonymous user.
Out of interest why is this? Application Insights provides exactly what you need. It is free to a point and the time spent developing a custom solution will likely cost a lot more.
Few things: 1. It would help to see your entities 2. Navigational properties need to be marked virtual in EF 3. Are you using attributes or fluent entity configuration to relate a foreign key to a related entity? Or are you relying on configuration?
Even if it's collapsed the parser has to parse the markup, so it's best to create separate XamlControl.xaml control files, which you would loaded programatically. For example this pattern using a property won't break your code and lazy loads the xaml instead of on startup: Markup: &lt;ContentControl x:Name="ucLoginWrapper" Panel.ZIndex="50" Visibility="{Binding ShowLogin, Converter=local:BoolToVisibleConverter}, FallbackValue=Hidden}" IsTabStop="False" d:IsHidden="True"&gt; Code: private LoginControl _ucLogin; public LoginControl ucLogin { get { if (_ucLogin == null) { _ucLogin = new LoginControl(); ucLoginWrapper.Content = _ucLogin; } return _ucLogin; } } 
Thanks for posting this. As someone trying to learn, I find it helpful to see working examples and pick them apart.
Strange ... I've always seen .net jobs ... never actually seen a laravel job. I know both pretty well, and I'd much rather go .net Where are you seeking employment?
Dublin, Ireland. &amp;#x200B; I'm getting no responses, but PHP people are actively seeking me out. 
Yea, life requires money, so you're going to have to do whatever you have to do. I tend to see .net as - not only being easier to work on - but also more powerful. Not to say laravel isn't great. I've enjoyed working with it, but the hobby apps I built with it ... I eventually moved to .net
There's no reason you can't continue using and learning dotnet on your own. Thinking that you need to be actively employed in a technology to be able to learn it is not really good for a long term career.
I know. But I need a job at the moment, and I'm pretty good at Laravel. I will continue learning on my own, I just need a job for now. 
TIL not only that Laravel exists but also that PHP is still a thing.
Are you on active directory?
It's kind of always been that way. I've been working in .NET for almost 20 years at this point and it's always been the case that 'some other framework' seems to have more positions available. However it's not the same framework / language. It used to be C++, Java then Ruby and now JavaScript. I actually teach a JavaScript new web dev class for exaclty that reason; there's just more junior roles in JavaScript )pl;us it's easier to teach a single Lagrangian for client, server and even DB to some degree). However...I'm glad I chose to make my career in C# &amp; .NET...it's given me a living for two decades; something no other framework could really have done. I cannot imagine using Java nowadays...
Lol I‚Äôm waiting for the day where I only ever need to use c#. 
I think the problem is because you are trying to access the context inside task.run . Task.run could run on a different thread than the thread with the current httpContext.
Yes. I should've mentioned it's an internal application and everyone is in Active Directory
I'm Astrid my the time we get there it's gonna be Javascript and not C#. 
Does anything else depend on LibA and/or LibB? If ApplicationA is the only thing consuming them, and there are no plans for anything else to, then: monorepo, one sln.
Have you seen blazor and web assembly? Blazor is going to make javascript unnecessary. I‚Äôm super excited for the new developments coming down the pipe for web technology. 
They are shared with other projects. For instance, they contain some utility methods which are useful just about everywhere ala SWAN. Some other contain packet definitions and such that are shared amongst server and client applications.
From the sound of your architecture requirements, I believe it would make sense to have a separate repository for each of the libraries and applications. Since the libraries are shared across your stack, you can deploy them and reference them independently as nuget packages, giving them their own SDLC and set you up for a clean CI/CD pipeline across all of your applications and libraries. 
Depending on your situation, you could use system.directoryservices to get the information from the user using user.identity. System.directoryservices.accountmanagement has a lot of classes built around getting AD information. I use it to add claims to users. 
Keep getting paid, and keep setting aside time, while they're paying you, to learn other stuff. I've worked a long string of ".Net" jobs, but I've always made sure to constantly learn new/competing technologies along the way. The last few jobs I've had, I've actually mainly done JS/Node work, but at previously .Net-centric shops. They hired me because I had experience with both technology stacks, and could easily switch between them. PHP is absolutely the worst. But, nobody hates a language that isn't in use. There are tons of places doing PHP still, and even more that have PHP legacy/third party stuff that needs a hero to maintain. What your are doing is hardly ever a hindrance to what you want to be doing.
Have you considered referencing your libraries as nuget packages and developing them somewhat independently of your applications? By doing it that way, your libraries features can be engineered, tested, and deployed independently of your consuming applications setting you up for a great CI/CD pipeline for both your shared libraries and your applications. Also, gives you smaller and better defined program structures with focused code bases. This method would have you separating your libraries and applications into individual repos and your apps would be referencing a NuGet stream rather than class libraries directly. 
this will work but I caution against doing it every time you need to auto for performance reasons. in my experience a caching mechanism for querying AD is needed
Sounds like this approach wouldn't allow you to do development on the libraries at the same time as the main app
The very loose rules we follow at my team are: * Libraries that are only going to be used by one solution / project are stored in the same repo / solution that uses them. * Libraries that only contain DTOs are stored in the same repo / solution that generates them (most likely the receiver of those DTOs). They are packed and pushed to NuGet feed. * Rest are put on their own repository, packed and pushed to NuGet feed. &amp;#x200B; These are in order of cost for future maintenance for a reason: If you're in doubt, pick the cheaper option. It's easier to maintain and "upgrade" if necessary to another solution than to go backwards. &amp;#x200B;
Can your frontend create a guid on initialization then pass that value when retrieving a post? I think all of the posts here may be relying too much on the backend and not considering the frontend.
Hell yes Jon Skeet and Phil Haack both got chosen :)
Usually, it‚Äôs because this is either a kid with homework, or the result of a manager that doesn‚Äôt understand that outside code can be good to use. 
&gt; You don't "use" a pattern, you "apply" a pattern. Correct, but pedantic. The vagaries of the English language allow patterns to be used as easily as they are applied. But then again, I trend toward pedantism with certain subjects as well, so here‚Äôs an upvote in understanding. I stand corrected.
/u/ben_a_adams congratulations! :D
Given that Jon Skeet specifically did not want to be elected, should his seat be withdrawn in favour of the next highest score?
I do one repo per solution. Solution usually being one app or library set. The repo sets the version of the output. 
Laravel is actually really nice to work with. You can implement modern design patterns with PHP too!
I advise against this approach as the data should be owned by a single application; this prevents validation logic from 1 app differing from another and ending up with invalid data. &amp;#x200B; Also when you share a project containing a dbcontext between both applications you have to deploy both simultaneously when there is a migration. I went down this path and it became a nightmare; eventually we went full microservices architecture and made each app own its context and made calls to other application for data instead of accessing the database directly. 
Could you provide a use case? For me it just created a new claim for each request.
&gt; I advise against this approach as the data should be owned by a single application; this prevents validation logic from 1 app differing from another and ending up with invalid data. *Excuse me??* A repository pattern *solves this exact problem*. With a repository pattern, I can put my business logic (including the validation logic) into a separate project within the solution, and have the other projects draw from that common solution, thereby ensuring that the same models, validators, and business logic appeared everywhere and was available everywhere. That way, all projects within the solution have the same validation logic; change it in the common project, and it changes everywhere at the same time.
Well, given that my name is John, no disrespect at all :) 
AutoResetEvent
Before .NET Core 1.0 was released they showed support for exactly this... You could just clone the repository of a NuGet package or add the path to a global configuration file and it would use the source instead of the NuGet package, without having to adjust anything else in your project. They showed this once in a preview presentation. Then they scrapped that feature silently and ignored requests for it ever since. A pity.
Three out of seven are women, that's quite something. Good to see Beth Massi among those chosen.
I'd have a look at Marten, it's a SQL / JSON hybrid model and you can query both. I've used it, it's excellent ... [http://jasperfx.github.io/marten/](http://jasperfx.github.io/marten/)
Best wishes to you, and I hope everything works out :)
For the record, she wasn't elected, she was chosen by Microsoft to be their unelected board member.
&gt; Given that Jon Skeet specifically did not want to be elected, should his seat be withdrawn in favour of the next highest score? I don't think that's the case. If he didn't want to be elected, he wouldn't be a candidate in the first place. Though he didn't want the board to consist just of white men or of "famous names".
And catch your COM exceptions... The ad stuff in .net is error prone
&gt;I'm just afraid the time we get there it's gonna be Javascript and not C#. I will have a fucking tag on my toe before I become a full stack JavaScript developer.
Getting the user inside a task is unreliable at best. This is because (as other replies have noted) the threaded behaviour of it. Your http context or principals can be cleaned by another thread. But you should not use task.run... especially with disposable objects in a synchronous runtime. Are your API actions Async? If so you can remove the task run and it will be fine. If your API is synchronous, don't use task run. A good thing to remember is that if your API is Async then you can run Async and synchronous code. If your API is synchronous you can only run synchronous code. Task run has no benefit of calling synchronous stuff inside it, only headaches.
I was thinking the same. 
Here is the project. https://github.com/Palmer11/anonymous-session // This will remember(use) the information(auth) app.UseAuthentication();
Thank you. I will check it out now.
I know people that left their C# job to go to where Javascript was the entire stack. 
Still the same thing. Can you take a look at my code here: [https://github.com/rmirzojonov/VotingAndPageVisitorCounter](https://github.com/rmirzojonov/VotingAndPageVisitorCounter). &amp;#x200B; It is in PostController inside api folder.
I didn‚Äôt know this was possible. Thanks for sharing.
Does that matter to you that? 
Fair enough.
If you read my comment you will see it's no more than an observation but it seems to have triggered something.
&gt;a blog post I'm using Linode as an alternative to DigitalOcean. Vultr is also another good one. Both are cheaper and just as good imo, Vultr even does Windows vms.
https://github.com/rmirzojonov/VotingAndPageVisitorCounter/blob/master/VotingAndPageVisitor/Startup.cs#L78 Remember your Startup order matters. You must apply the middleware implementation after initialization of .UseAuth...() You can view in the example I gave you the token will update if you apply it before as you have in yours. // Persistant // app.UseAuthorization(); app.UseAuthentication(); app.UseMiddleware&lt;Middlewares.AnonymousSessionMiddleware&gt;(); // Not persistant // app.UseAuthorization(); app.UseMiddleware&lt;Middlewares.AnonymousSessionMiddleware&gt;(); app.UseAuthentication();
I tried doing that too
I could not imagine so incredible success but [**70-486 Dumps**](https://www.realexamdumps.com/microsoft/70-486-practice-test.html) made it possible and I am thankful for it. It compels me to wonder over the work done by experts. They organized all the information in the form of questions and answers and used easy language so there remains no confusions. After the completion of 70-486 Dumps PDF I was clear about all the ideas and concepts and was able to solve full paper in the final. But I took advantage from the opportunity and practiced on online practice test which enhanced my confidence and corrected my faults. I suggest you to take help from [Realexamdumps.com](https://Realexamdumps.com) because think there is no better source for preparation. 
Weird. How is your login persisted if you can‚Äôt hold anything? Your controller looks fine. It shouldn‚Äôt be the issue.
This is cool. Although, not sure what the practical application would be with something like this. 
Try moving the AddAuth in ConfigureServices to the bottom of the method. The order applies here too. 
I do have to pay each month at least a little if I have apps running.
[This has already been posted few days ago.](https://www.reddit.com/r/dotnet/comments/b5fjjz/c_hello_world_running_without_os_or_runtime_by/)
I tried something like that towards the end of my post. I'm saving a local principal based on the main thread's Thread.CurrentPrincipal. When I get to the part that I need to use it, it seems I have the username as expected but I get the Safe Handle has been closed exception after a couple of calls
Put the username or whatever you need in a string variable before you create any tasks. You can‚Äôt use the Identity stuff inside tasks.
That's where I'm stuck, how could I reliably cache the username in a Thread Safe manner. I thought about having some sort of static variable with the \[ThreadStatic\] decorator that gets set from the controller (the [ApiController.User.Identity.Name](https://ApiController.User.Identity.Name) is always correct) but not sure if that is a good idea.
Well, right now we only call [Task.Run](https://Task.Run) when the code inside takes a long time to run and has no return. So let's say as an example on the code I added on my post, there's a very complex calculation that needs to return something but at the same time there's another complex calculation which only needs to save 2 values on the server (the user doesn't have to wait for it). So because of the [Task.Run](https://Task.Run) the overall method is taking 3-5 seconds instead of 10 seconds to run. Not sure if this is best practice but it is definitely working to help the performance of that method and having the data accurately saved..
I find it ironic that this is posted on /r/dotnet when the code is explicitly not using .NET.
it always seems so weird to me that people outside of my country are switching *away* from .net to get work, instead of the other way around.
In that case you should queue a background task. Off the top of my head it is something like HostingEnvironment.RunBackgroundTask but feel free to correct me that will queue a long running task that does not have a return value and will not encumber your wait time.
Don't try to reason with an identitarian.
Awesome, that is a good tip! After reading some more ( [https://stackoverflow.com/questions/29938522/difference-between-task-run-and-queuebackgroundworkitem-in-asp-net](https://stackoverflow.com/questions/29938522/difference-between-task-run-and-queuebackgroundworkitem-in-asp-net) ) it seems the HostingEnvironment.QueueBackgroundWorkItem has some advantages for what I'm doing. BUT I think my main issue remains the same about how to get the username inside those methods.
I hope once egalitarians and left/right identitarians are done, we get the Enlightenment values of individual merit back.
the original owner ghosted, and got picked up by the community during the shift to dotnet standard 2.0
Look at me. I am .NET now.
The more I read into this the more I think there's no good way to do it. I think I'll revert my code back into getting the username from the HTTPContext and try to pass a local variable for asynchronous (background) code.
If all you need is the username as a string then just set the string outside of the task and then use the string to get whatever inside the task.. strings don't get disposed.
I already do #1, but am going to do some research on #2 and #3. I've never used NuGet feed... it may be just what I need to keep things organized. Thanks!
Good read. Coincidentally, this is exactly what I was doing today along with nodemon to automatically compile the scss. My version works but was no where near as clean though. Saved for later.
‚Äùmaking sure it‚Äôll be a dependency of the project instead of a part of the project. So our project tree will no longer be cluttered with a bunch of minified JS and MAP files.‚Äù This is how a default vs-project should look like in 2019. Thank you!
Dublin is the headquarters of Ion Investment Group which owns Fidessa. As is Bloomberg PolarLake operations staff. Both are predominantly Java but probably will pay better than Laravel.
That's great. One of the major reasons I don't use .NET Core as often as I would is that I write a lot of Windows services.
You could start taking notes, and you'll begin to see areas of importance/interest -- and just work tangentially from those topics. I wouldn't say it's a start-to-finish sort of thing. But also ... just building little pieces of functionality with it will show you the areas you need to learn. 
You could already write Windows services using .net core 2.x, see for example https://stackoverflow.com/questions/53837763/how-to-make-a-windows-service-from-net-core-2-1-2-2
What problem with Net Core app as Windows service I'm missing? Because I have some web API servers for Xamarin Forms apps running as Windows services and I don't need special project template for doing it.
Ok, so why do we need this new template?
I'm not sure either what the difference is between these Worker Services in 3.0 and the HostedService in 2.x
Wow that's such a coincident. I want to also start using multi threading but I found manually (actually using keywords thread, lock) it's hard way doing it. Majority windows app I maintain uses creating thread and using it. I would like to move toward async and await. How did you found the article?
Do you mean kind of like [this](https://gw2efficiency.com/)? Short and general answer is yes. It's more if a specific approach to the problem works or is viable rather than if it's possible. 
Someone asks the question in the comments of the article and the response is that they are basically the same thing, The author of the article mentions that this new worker service is needed to work with the windows service systems (start/stop) so maybe this simplifies the integration.
Well since you are coding for your first time I would suggest making a python application first because you still have a lot to learn if it's your first time ever coding. But for the idea of you project I would say yes but no, if there are api's for the game you are trying to get info from you will be able to do this project, but if there Is no api's for the game it will be a real challenge because you will need to find the memory address to get the data which you will need a program to find and get them (cheat engine is a program you can use.) Also you may never find the right addresses you are looking for. Overall if you are looking to do this you will be looking at hours of trying to find the right memory addresses and get them to actually work in your code. Highly not recommend for your first time coding But I would not complete through the idea out.
Yes that is sort of what I had in my. Do you know of any other way that is more viable than using dotnet?
I was the one who asked the question üòâ
The game's publisher is very active with the community, and the APIs I would need are freely available. Now that you know this, do you still think the project is out of arm's reach?
Lol, nice. It‚Äôs a good question
Not saying .NET is not viable, meant your plan to implement it \*may\* not be suitable for your goal. Though before you start trying to do it I recommend you to do some other, small scale, projects to help you get to know the language or framework you end up choosing. There are a lot of ways for you to approach the problem but to know them, and to know which one is best for you, you need knowledge. You can also divide your goal into much smaller goals so that you can work on this project at the same time as your learning about programming, say how to format the data into something you want (which when practicing could be how to print some local test data, maybe a a text file, into a readable and nicely displayed text). As for resources you might need; [Microsoft Azure](https://azure.microsoft.com/en-us/) (Actually has a lot of services which you might find interesting but what you're looking for is a web service), [node.js](https://nodejs.org/en/) and [ASP.NET](https://dotnet.microsoft.com/apps/aspnet) are a few that come to the top of my head. For questions you can post and find answers on; [Stackoverflow](https://stackoverflow.com/), here and /r/ASPNET for .NET or ASP.NET questions, and /r/cpp, /r/csharp, /r/fsharp, /r/visualbasic for the .NET languages (which may or may not accept the questions based on the question at hand)\* &amp;#x200B; \*.NET is a framework (a collection of classes and services that contain commonly used code) and a runtime (what the compiled program uses, basically) that multiple languages from Microsoft use &amp;#x200B; A lot of this might seem overwhelming at first, it is because you have chosen a big project, but as they say; Rome wasn't built in a day.
it would be a challenge but if you are up for it I don't see why not to try it out. you are are a new coder so using a advanced language like c#/c++ would be difficult challenge for your first project. really you can try but with little experience I would try to learn something easier like making a few small console games so you have some experience before you start this project. in conclusion if you are determined and ready to go through hell then go for it.
I assume you already use [NuGet.org](https://NuGet.org) (since it's pretty much mandatory) to get public libraries and stuff. You can set up private nuget feeds and use them exactly the same.
If you think that reading it once you wont have to read it in the future... I don't agree. I tend to check (not reading from start to finish) the docs every time I do something to see if the "standard" changed or what's the new deal.
Nay
Can this worker service be loaded as a linux daemon also or is it purely for windows?
I've never tried to do this from the client directly. Usually I make my own API endpoint to proxy the calls to azure so that I don't have to worry about key security. This post looks like it has the info you would need though https://stackoverflow.com/questions/35456197/upload-file-directly-to-azure-blob-storage-with-sas-using-dropzone-js
Thank you so much on your feedback and tips. I will definitely take this into consideration!
I'm willing to put in the work. It's for Path of Exile :).
Yes, thanks for the response. I have referenced that post a few times, but didn‚Äôt quite understand how it all worked. After spending some time fiddling with the HTTP request in Fiddler, I think I get what they‚Äôre doing and it should work for me as well! Thanks for the help! 
The writer commented on this in the blogs comment section: &gt; I plan to do a post about that next, short story is that with something like systemd you create a service config file and it runs fine. But there are a bunch of interesting details to dig into. So yep, it can be used on Linux.
Would love to see how you stream the data from your proxy to Azure Storage.
Roughly this code public async Task&lt;HttpResponseMessage&gt; Post() { if (!Request.Content.IsMimeMultipartContent()) { return Request.CreateResponse(HttpStatusCode.BadRequest, "Missing file content"); } var provider = new MultipartFormDataByteArrayProvider(); await Request.Content.ReadAsMultipartAsync(provider); var account = CloudStorageAccount.Parse(ConfigurationManager.AppSettings["azure_storage_con"]); var client = account.CreateCloudBlobClient(); var container = client.GetContainerReference("foo"); foreach (var item in provider.ByteArrays) { var data = item.Value; var blob = container.GetBlockBlobReference("some-generated-file-id"); blob.UploadFromByteArrayAsync(data, 0, data.Length); } return Request.CreateResponse(HttpStatusCode.OK); }
Does that ByteArrayProvider stream data or is it all loaded into memory and then written to Azure in the foreach loop? We have large files that we want to store in Azure and use token credentials. Our app provides tokens to users and then users hit the Azure Storage endpoints using the js SDK (and tokens for authorization). We landed on this solution because we couldn‚Äôt find a way to stream data through the server easily.
For my use I don't have to worry about the file being in memory, but I believe you can use streams to avoid this. https://stackoverflow.com/questions/30031452/how-to-i-pass-a-stream-from-web-api-to-azure-blob-storage-without-temp-files Or do it clientside like OP
Nothing wrong with dotnet, the scope is just too ambitious for a first time programmer. It requires experience with accessing apis, web development and a bit of hosting... Also when choosing platform you first have to check what kind of api interface the game offers. Since it is a Windows game there is a chance that dotnet is the best fit
I usually handle such things with a semi-structured (xml or json) column in the db. That allows a fixed/stable DB schema while allowing freedom to add arbitrary associations and keep everything together in one place.
Thanks! Do you have an online example? Repo?
Nothing public I'm afraid
Use Azure with the self contained option (copies framework files to eliminate server dependencies) With it you can literally achieve one-click-deployment from VS. Use free tier to experiment. You also get a one month 200$ credit to try their paid services. 
IMO such documentation is more like encyclopedia - you just look for desired piece of information when needed. Depending on the documentation type (I myself recognize "use-case friendly docs with examples" vs "very precise scientific-language docs") you may find it more useful to rely on tutorials and courses and only reference official docs when there is no other option. Hope that helps.
You might want to check out git submodules: https://git-scm.com/book/en/v2/Git-Tools-Submodules
Not sure why you'd pay $300 for this when you can use [GraphQL .NET](https://graphql-dotnet.github.io/) for free?
Such an MVP. 
What does this post have to do with .NET?
[Prisma](https://www.prisma.io/) is both free and open source and does pretty much this. 
Pretty sure there is an SDK or library for uploading to azure storage. That‚Äôs what I use.
Create a "LookupAttributes" table in your database, which is basically just a list of your arbitrary behaviors, with a many-many relationship to "LookupItems".
If all you want to do is get [https://www.pathofexile.com/developer/docs/api-resources](this) data and "organize" and display it in a web page, and you've also never programmed before, I would not consider a C# application. I would recommend that you just make a pure web page and get the api data with javascript. It's going to be very difficult to get started with even a very basic C# web application and there's nothing C#/ASP.net gives you that you really need from what you've mentioned that justifies the extra effort. Hosting your site become far more difficult as well once you involve C#. It sounds like you don't need any kind of "back end" at all. 
Am I missing something or does it not have GraphQL server in .NET? I'm only seeing TypeScript/Flow/JS and Go
It looks like it uses this in its implementation and uses 2 other libraries to make the generation of the schematic and data query faster. What I would love is an equivalent of Postgraphile for a MS SQL database. 
How would it know what the table looks like without a connection string?
So far I have not been impressed with GraphQL .NET's code quality or documentation. And its not a complete solution. You can't just use GraphQL .NET, you have to stitch it together with 3rd party libraries to get anything done.
correct
Entity models are just code. You can always update them yourself. 
I think the point is that you specified the connection string already, yet you still have to re-specify it when updating the models, even if it has not changed. You can't say something simple like "update context", you have to provide the entire Scaffold-DbContext command. The move to Core has cost us a lot of useful UI tooling.
add-migration change1 update-database
What is the problem with the projects code quality if I may ask? Personally I do think that the modular architecture is the amazing part of the library. It is incredibly easy to implement against almost any back-end, but these are just my 2 cents.
Seems like your market may not have that many entry level .net positions right now. Keep learning / progressing good software principles with your work today. Continue to learn .net or research your market to understand what companies in that market do and adapt accordingly if needed. Best of luck. 
1. Are these drop down values user definable (i.e., when user adds new one, they need to choose behavior its selection drives on this page)? 2. Does this dropdown value drive anything besides UI? Validation, business rules, etc.? If its not going to be use definable, I wouldn't get hung up on what you need to update when they change. That means your team is fully in control of that and whatever you pick is in your control. Its when pesky users have to be involved that it takes thought. If these are static between releases, I'd consider just using an enum and hard coding reactions in code unless you're talking about having dozens of these. If it was going to be highly configurable, like dozens of options that could interact, I think I'd agree with one of the other comments here, go ahead and use a lookup table, but don't put the attributes driving things on that table, put em in a join table. Also, DON'T tie those attributes to visual states (i.e., showFieldX) make them definitional instead of behavioral, i.e., "when this is selected the thing we are editing is in mode X or Y", and drive what fields to show off the state of the overall thing you're editing. It'll be less brittle in the long run.
Last time I looked... * Inconsistent capitalization on public members * Mispelled method names * Clearly internal classes and methods marked as public * Lead developer flatly refused to consider turning on static analysis I also have a lot of subjective concerns about the code, but there should be no debate about the objective rules like using correct spelling. Maybe it's changed since then, but looking at the documentation I'm not hopeful.
Scott Allen fasho, also Bob Tabor on https://devu.com
Wow, that's a lot of cool stuff. I never thought I would see Windows Forms on a web page or .NET on a microcontroller.
Git submodules is what you want here. You've got application-specific code, but you also want to fold in shared, common-use code. The easiest and simplest way to do that is with a Git submodule. With a submodule, shared code lives in its own repo, but can be pulled into separate applications as desired. You can create different branches within the submodule where you need to modify it for specific applications, and then you can merge things back to the main branch of the submodule if you want to include them in the common core.
I prefer the classes for DTOs/POCOs/Models in separate files just to follow the pattern that all other classes/interfaces follow within our established patterns on the projects I work on. Following that, it prevents the guessing or hunting that may happen and less likely to introduce tribal knowledge on the project. 
Well it's still under active development and we've got two production servers running it so it might be worth another look. 
Huh, this actually sounds really useful. When I read a book about Git, it didn't cover submodules. Just Git from a single project perspective. I'll definitely look into this on Monday. Thanks!
I was introduced to [submodules](https://git-scm.com/book/en/v2/Git-Tools-Submodules) in my last job, and they're amazingly useful! I think the ideal use case is when you're developing multiple applications where code developed for one could be useful for other applications. You can build up your submodules into a whole library of code that's useful for all sorts of things! When it comes to NuGet packages vs. submodules, I'm not an expert on NuGet, but from my understanding: submodules are probably more useful for code under active development, whereas NuGet packages are probably better if you have code that's already been through a development cycle.
Another great talk by this guy!
That gave me a good hearty laugh. "Winforms is dead! It *lives in the browser!*"
Man, .net on a microcontroller gives me the willies. That's super exciting.
What a great time to be a developer!
Why not just regenerate the whole model? I like to keep the database in sync with the model and it's easier if it just always looks like the database without making hacky changes in the code. 
I use fluent validation for validation then I map the EF objects to my view models. I don't use automapper but you can. It would be good if you rewrite this post with a bullet point list of concise questions. Makes it a lot easier to answer without having to read stream of consciousness. 
Besides a really cool demo, that guys is a freaking comic genius 
I'd separate them. I'd also use resharper to do it or the built in refactor tools. https://www.google.com/amp/s/windowsdebugging.wordpress.com/2017/03/18/vs2017-moving-class-into-file/amp/
Non Google Amp link 1: [here](https://windowsdebugging.wordpress.com/2017/03/18/vs2017-moving-class-into-file/) --- ^^I ^^am ^^a ^^bot. ^^Please ^^send ^^me ^^a ^^message ^^if ^^I ^^am ^^acting ^^up. ^^Click ^^[here](https://medium.com/@danbuben/why-amp-is-bad-for-your-site-and-for-the-web-e4d060a4ff31) ^^to ^^read ^^more ^^about ^^why ^^this ^^bot ^^exists.
Thank you for your thoughts, I think your enum solution is encouraging.
"I don't need your pity applause!" "I type 100 words per minute but 90 of them are backspace."
I will definitely at some point, but right now I don't need GraphQL.
I definitely agree with this. To add some more points to this. Almost no source code comments, some very strange architecture design decisions (most around OOP, inheritance, etc.) and Field API is not consistent with invoking the Field Builder. We are using it in production, most of the API is abstracted away and turned some stuff upside down.
Is there anyone more interesting to read/listen to than Scott? I love this guy,
Damn. I really wish you came back with "that was last year, it's better now". I thought about starting over from scratch, but the GraphQL spec is ridiculously complicated. Way more functionality than what is actually needed and I don't know how to deal with it all. 
Will the format ever change? I leave it on one file, usually, so I can update it as needed by repasting. 
If we didn't have the abstraction I would look at alternatives. Maybe a slim API Gateway with the more mature node.js implementations makes the most sense and have the backend written in C# with gRPC and communicate this way. Nevertheless, we do use GraphQL every time if we get to write the backend and is surely a great worthwhile time investment. Make sure that you support batch loading via a data loader from the start to avoid n+1.
It is, if not the best, one of the best IDEs. 
That last point is why I'm concerned. If you do it wrong you can easily kill performance. 
Asp.Net core + DotNetify + Vue (or React)
I find giving more context brings better answers. Frankly, it seems it's hard to even ask for advice in this industry. I've never heard of fluent validation, I'll give it a look. thanks.
The closets to MVVM. 
XD LOL you said willies.... Ok ill stop, goodness sake you all sound like my wife.
Hi headyyeti, can u find a solution to this? I'm having the same issue but pipelines and filters does not work :(
I found the solution. If you want to use custom pipelines for MediatR u need to set up your MVC application to suppress validation filters. &amp;#x200B; `services.Configure&lt;ApiBehaviorOptions&gt;(options =&gt;` `{` `options.SuppressModelStateInvalidFilter = true;` `});` 
Yes.
I really like seeing these types of blog posts, the tech factor always gets me. Plus I get to know other platforms, orms, frameworks etc. I have no idea what Tortuga Chain is, other than an orm that (possibly) complies with .net Standard. Do you use it?
I wouldn't recommend connecting directly to Azure functions at all in all honesty. I would want something at the front of it, whether that be an API backend, API Gateway or (when it comes out) Azure Front door. The only real pro I can think of when connecting straight to HTTP Functions would just be that it's very easy to do, but then you have to deal with the fact they are incredibly simple and anybody could see the URL. As soon as you want to do anything with something like middleware, shared auth etc., you're going to find yourself annoyed you used functions to do it if you're just using functions and nothing else. 
I think OP is referring to database first. I have minimal experience with code first from models, but I believe that's the scenario for your solution.
I didn't know there is database first in .net core 
It's still there but MS pushes people to code first from models now. With database first, you no longer get any UI, as .edmx files were not implemented. For database first, you have to issue a command like this to scaffold the models: `Scaffold-DbContext "data source=ip\SqlServerInstance,port;initial catalog=databaseName;persist security info=True;user id=user;password=password;multipleactiveresultsets=True;" Microsoft.EntityFrameworkCore.SqlServer -OutputDir Models` To update the models, you have to run the entire thing again with " -Force" at (or near?) the end.
oh i see. after scaffolding the models, is it not possible to enable migrations? 
You can probably use your generated models for code-first after that point, but if you want to keep doing database first, I don't believe so.
Depends. What‚Äôs your use case?
Chain is based on the idea that you should look at the database schema when generating SQL. Rather than just assuming that the class matches the table or dealing with lengthy config files, you ask. This lets you do things like add properties to a class and have them automatically take part in queries once the table or view is updated to match. You can also update multiple tables with the same object because it knows which properties apply to which table. Chain doesn't support deep object graphs. It expects you to create views, not just suck down every column of every table joined together. This is good for performance, bad for developer experience. Chain does support things most other ORMs lack such as: * Automatic handling of soft deletes * Automatic merging of user data (e.g. LastModifiedByKey) on insert/update * Upsert * Batch insert using table parameters in SQL Server * Bulk insert (SQL Server only, eventually all databases) * No using statements (except transactions) are needed * Random row sampling * Multiple result set stored procs (even in PostgreSQL, which is a pain) * Return the row that was updated or deleted * Return data as lists of scalars when desired, you don't always need objects At this point there is no technical reason to prefer Dapper over Chain. Chain does all of the same things with comparable performance and less code. Against something like EF, Chain makes more sense if you want to take advantage of database specific functionality or have a database not designed for ORMs. For example, EF hates multiple column primary keys and missing foreign keys. Again, EF beats Chain if you are dealing with deep object graphs on a regular basis. 
https://github.com/docevaad/Chain/wiki/A-Chain-comparison-to-Dapper
I know most people here are probably rolling their eyes on the mention of dreaded Web Forms. I would bet money though there are far more Asp.Net Web Forms in production than AspNetCore at the moment. I will take that bet a step further to say most of that code implements Factories or Duplicate code or Singleton patterns of yesteryear... and thats if it was a good library - which my experience would dictate that is not the case. All of them would greatly benefit from the ability to have an IoC container... This was a major feature with the release .NET 4.7.2 that I don't think most people were aware of.
In the new version of FV this doesn't work anymore. There is a suppression option on the UseFluentValidation extension. 
WHAT YEAR IS IT?
Sigh, I know.
&gt;These tokens DO however have Sha256 encrypted signatures. Hashing != Encryption 
Hey dude, are you spying me? Because that's exactly what I was reading on.
Could these have been a single post or something? Feels weird to drop 3 submissions on the same subject
This is something I‚Äôm working on. I‚Äôd love to see refresh tokens implementation too (especially the middleware usage)!
I will see about writing another guide about that soon.
Sharing your private key on any website seems like a horrible idea. At least use a throw away key that you never use again if you're just exploring. 
Which is why I did not do that. I shared the private key I generated and explained how to generate your own and then informed the reader to do the same.
Thank you for the catch, comment should be fixed.
I kind of hate that this gets said all the time. Its a cryptographic hash function. Its still encryption, its just one way encryption. That said I do understand why people say it, because its important for developers to understand the difference between one way and two way encryption. I'm just a hopeless pedantic stickler.
You missed the point. You should add a warning about pasting a private key into jwt.io. You're posting a how-to article, warning about PHI and such in a jwt, but not really pointing out how it's a bad idea to be pasting your private key into some website you shouldn't be trusting such things with. I don't care what YOU did, I care about what all the readers here on reddit might do. 
The term "one way encryption" doesn't really make any sense in the context of modern encryption and cryptography and software. It's confusing and misleading, and is worth getting called out every time. Call it what it is, a cryptographic hash. Use the terms hash and encrypt separately to avoid confusion. It's not difficult. 
I feel like you are coming from a helpful place, so I am just going to point out the following. This is on [JWT.io](https://i.imgur.com/GGReSsw.png) right up front before you do anything. This is on [PasswordsGenerator.net](https://i.imgur.com/JQ9J5Nk.png) as an option.
What would you expect it to do if they were members of both roles? I don't think what you're are wanting is directly possible, but you'd probably be able to write a middleware that redirected according to policies. Or you could do it directly in the controller for the methods that you want to handle in this way?
Depends on your implementation. * Use subdomain or even separate domain if you need non-trivial localization (e.g. branding, 3rd party integration, ecommerce workflow changes) * Use sub-path if it can be done entirely by the engineering/design team (e.g. copy changes, logo, formating, minor styling changes). 
I would go with A from an architectural standpoint. Functions are meant to be simple API triggers, and should logically be considered part of your front end architecture. You can do B, but that seems redundant to me. Functions calling into other WebAPI's makes more sense from a design standpoint. As other posters have said, you absolutely want some sort of API gateway in front of it, and the ApiGateway in Azure works great with Functions. We use functions as Http triggers, and that's it, and this has vastly simplified our architecture as we can group a lot of front end functionality together into a logical partition, which also helps with securing everything. It's allowed us to position our WebAPI's right behind the Function layer, which also makes security a lot easier.
Encryption is by definition reversible. This goes all the way back to the Caesar Cipher. Without a "solution" it isn't encryption. Hashing is just a "function" (one kind of trapdoor function, although public key crypto is a trapdoor function that's *also* encryption)
For your app to communicate FROM Azure to DigitalOcean, your database on DO needs to allow connections from Azure over HTTP. I likely wouldnt do this, since it opens up some major security issues, and would likely try hosting everything on DO (especially since you're using .NET Core).
How is this typically implemented? Is this a solo project running as its own web and other webs redirect to it to get a token to auth against or do you set this up in each web you make? 
Yeah, that is preferred at this point. You cannot beat those $5 droplets. I just need to figure out what is going wrong.
Just fyi the demo never opened for me in the iOS reddit app built in browser. Kept doing the loading animation
If the site is running port 5000 in DO, make sure that port is either opened through the firewall, or mapped from outside on port 80. My linux knowledge isnt great though, and its been a while since I used DO (before .NET Core came out, at this point) Good luck!
Thanks! I had it redirected to 5000 from 80 but I had my doubts so I opened 5000. I get the same error from the redirect as from the direct 5000 call so I am beginning to think it is a problem with the app/http headers.
If you have the resources to implement as a solo identity server, this a common practice to run as a separate App in it's own AppPool or even separate box/VM. It isnt the end of the world to leave it internally. Authentication resources and verification can just be it's own isolated domain. If you have a shared userbase on a platform it is best to isolate it off. I would host in a solitary app only if it's not really shared with other apps or it's never going to be a large scale. There is also IdentityServer4 too which houses Identity management for you.
I might be wrong but the earliest definition I can find for encryption is "to change (information) from one form to another especially to hide its meaning", which to me doesn't imply an ability to reverse that process.
I said in my original reply I understand why people use the terms the way they do. But I also think that not acknowledging that it is just completely irreversible, and not a form of encryption is detrimental. Flawed cryptographic hash algorithms have been reversed in the past. By the very definition of what they are, they are just encryption algorithms that are very hard to reverse. To my knowledge there has never been a cryptographic hashing algorithm proven to be irreversible. Once again, I'm just a programmer who works with and has read about encryption. Please enlighten me if I'm just fundamentally wrong.
That doesn't have much to do with the nomenclature concern iso3200 brought up to start this thread. Not sure what your point is and why you're shifting the subject. We can start another thread about your concerns, I'm not going to muddy up this thread with that discussion. 
nice
I think existentially I was hoping I'd never see winforms on a webpage &gt;&lt;
Not trying to shift the subject. Like I said in my original reply I'm just a pedantic stickler and this is one of the common ones that bugs me.
He has a website/blog [here](https://www.hanselman.com/)
I'm trying to avoid doing it directly in the controllers but I also think I might be overengineering it.
I don't have a way to test on iOS. On android the reddit internal browser is working just fine. I guess they're using a diferent version of browser for iOS app.
Really old thread, but make sure you are creating the gRPC Channel only once during the client's lifetime. Channels are expensive to create, but can be shared across multiple threads and requests. Reference: https://github.com/grpc/grpc-java/issues/3268#issuecomment-317484178
We sadly went through that and now we're in the process of writing proxies for all AF in our backend. \- If AF need some kind of authorization, roles, permissions, you're doubling down the logic in both AF and backend \- If AF need some data from the backend, it either connects directly to the database(bad way), shoots a HTTP request to the backend to get those(better way). If you use db directly, prepare for random bugs and problems furing development due to schema changes that weren't passed onto AF models. If you request data from the backend, then there's really nothing to be gained when compared to shooting backend first, and providing the data ready to be processed when it triggers AF.
I'd advise doing it as a simple if statement in the controller. It would be less lines of code and in this case abstraction would just lead to confusion and hide what's happening. 
Its not bytecode
Shit, yeah it's IL code. My bad
Be aware that you need to pay for traffic leaving the Azure network (the communication between your backend and the database on the external hoster).
Just finished deploying a similar scenario and ended up going from DO-droplets to Amazon AWS. Their free tier basically gives you everything you need for free for 12 months. I‚Äôm using a EC2-droplet and a managed Postgres-database. AWS is a lot messier then digital ocean but it‚Äôs hard to beat free, if you just want to try stuff out. Opening a database up public is a big security risk. At least whitelist ip.
Yes, and XAML.
Are they not just different terms for the same thing? 
This is also why I'm happy with .Net. There is so many enterprise jobs in Chicago area for C# and .NET. I don't have to switch to a new JS flavor of the week. &amp;#x200B; Now, I'm making a switch from MVC 5 to MVC core and to be honest it is not too bad. Generally, I can spot where the improvements were made. I might take a few more days to get up to good speed with it but the general idea is the same.
lol web forms
React doesnt care about .net version, so just create a .net app that suits you and use react cli to create a react app
I feel like article glosses over the actual difference. The article briefly mentions that you can pass an uninitialized variable to an `out` parameter (but is not explicit that the same is not true for `ref` parameters). The article also indicates a method can use the input value of a `ref` parameter (but is not explicit that the same is not true for `out` parameters). The article doesn't specify the reason for those two facts: an `out` parameter is guaranteed to be initialized by the implementation of the method; a `ref` parameter is not. I would also disagree with the assertion that `out` is syntactic sugar. `out` has language enforced guarantees that can not be expressed with any other syntax in the language.
I'll be able to use the created react app only in VS Code isn't it. so I'll have to work with two different solutions in two different IDEs. Where as opening in VS2017 lets you work on both withing it itself 
out is usually used to return multiple values from a function. For example, .TryParse functions usually return a boolean for success, while an out parameter stores the actual result if successful. out parameters are not usable on async functions for whatever reason. In this case I usually will use a tuple (which is also an alternative for out parameters in general).
Maybe certain regions tend to have certain preferences. If company X has a lot of Y developers, then nearby company Z will feel more comfortable selecting platform Y also: the Network Effect.
Huh, no VS / VS Code has NOTHING to do with what you can and cannot work on. The structure of your project DOES. VS Code has a perfectly good workflow for React (as does VS 2019 with the React template) [https://docs.microsoft.com/en-us/aspnet/core/client-side/spa/react?view=aspnetcore-2.2](https://docs.microsoft.com/en-us/aspnet/core/client-side/spa/react?view=aspnetcore-2.2) 
CIL is listed as an example of bytecode on [the bytecode Wikipedia page](https://en.wikipedia.org/wiki/Bytecode) and is frequently referred to as bytecode at least across the internet. Is there some distinction that you would care to elaborate on?
Yeah, gateway is what I'm after, thanks.
Very informative comment. Take my upvote.
Pretty much. ‚ÄúIL‚Äù is a more general term. The concrete language here is called MSIL. 
I like to wrap my tryparse in an if: &amp;#x200B; \`\`\` if(int.TryParse(item, out var test){ print(test); } \`\`\` &amp;#x200B; I think that syntax is kind've handy as opposed to nullable: \`\`\` var test = item as string; if (!string.IsNullOrWhiteSpace(test)){ print(test); } \`\`\` &amp;#x200B; Obviously this is just a contrived example but it's something that I use quite a bit. I personally like the syntax of TryParse better than if it would have just shoved a null object in there.
Yeah declaring the out variable inline is definitely nice. Of course that was not possible back when the TryParse APIs were created, so they would not have considered that I would think.
I guess the usual question with these bundles is: can anyone who has read any of the books verify the value in this bundle? 
I mean, Pro C# 7 is pretty great but the rest seem really specific to domains.
Outside of bots they're pretty much in line with the work we're doing at the bank I work for. 
Why do you want to use VS2013?
Seems like a great deal. Many areas that interests me and most of the books are new enough. 
It is syntactic sugar in the sense that at the IL level there is no difference between `out` and `ref`.
The "Progressive Apps" description sounds like it was written by marketing people: "easy, fast, shiny, quick, no learning curve, reads users minds..." &amp;#x200B; As usually, there are trade-offs. It's very difficult to optimize for both small screens and big screens and finger screens and mice screens at the same time. Either you live with a lowest common denominator, or are one of the few Sheldon Cooper types who can master the arcane details of coding client-side formatting correctly for all 4.
Run the react app separate in vs code. Run the API in VS. Unless you have a good reason not to you should be using VS 2017 and .NET Core for you API.
Can I hook complex methods into this ? 
Good timing! I just interviewed for a C# position two weeks ago and had a follow up just on Friday.
BLOCKCHAIN BABY!
Of course Visual Studio 2019 comes out tomorrow with C# 8 and Core 3, but these books should still be good, I don't think any books are ever released until many months after a new version is released. I just got Jon Skeets C# in depth that cover C# 6 and 7 and it was just printed weeks ago. 
I wasn't aware of this, I thought it was just related to Java. Thanks for the info 
&gt; Of course Visual Studio 2019 comes out tomorrow with C# 8 and Core 3 [Nope:](https://devblogs.microsoft.com/dotnet/announcing-net-core-3-preview-3/) &gt; We plan to ship .NET Core 3.0 in the second half of 2019. We will announce the ship date at the Build 2019 conference.
Everything in tech comes full circle just renamed and rebranded. Razor pages are web form code behind pages minus all of the events Tag helpers are web form controls but just not built out yet. Wait for Blazor and you will see the plug and play components.
O well I stand correct, thanks for being there and ready to point out my mistake.
Oh yeah I know ... I follow his blog religiously.
How does a "revenue generating web app" differ from a non-revenue-generating web app?
Well, the nosql one for MongoDB devs was a bit over specific.
Honestly the docs are pretty good and they contain some sample apps showcasing a lot of the common functionality across apps. https://docs.microsoft.com/en-us/xamarin/ Xamarin.Forms seems to be doing really well lately and I've also started porting over our current app at work since maintaining the native apps has been too much of a pain/not enough resources.
Pretty sure they're talking about building a website that users pay to use (ie. it generates revenue for the developer).
I'd probably throw in something about learning how to use your tooling. For example, how to use VS / debugger / etc. effectively. Particularly if your goal is to push something out really quickly, it's important to know how to get around your code efficiently and use your IDE to the fullest potential.
I think it looks ok. The only comment I have is I don't think you want to call Dispose in the StopAsync... I remember I used to do that and stopped for some reason. As I recall you just need to bind a Singleton instance of the IHostedService when running it as a background process on an existing WebHost. The AddHostedService syntactic sugar is new. You're welcome to look at https://github.com/i8beef/HomeAutio.Mqtt.GoogleHome/blob/master/src/HomeAutio.Mqtt.GoogleHome/Startup.cs#L88 I know this at least works.
Every time this comes around, I look at the books and feel like 70% of them are outmoded except ones having to do with unix/linux. This year I just bit the bullet and plopped down the $400 for an unlimited books service. I calculated that if I looked at 13 books or more in the whole year I would break even, and after 4 months, I have already looked at about 10 of them to various levels of completion. That's $300 if I would have bought all those books. Literally any topic I'm curious about there is usually a book on there and I can read it for a day or two to see if I still am interested.
Xamarin has been a very frustrating experience for me. Requires a very specific environment. Building/emulation can be very slow if you don‚Äôt have an Intel processor configured with HAXM. Things will compile one moment and throw vague errors the next, even if you didn‚Äôt change anything. Sometimes you need to restart your computer. Other times you need to rebuild. Sometimes neither of those things work and you need to factory restore your Android emulator. Also you‚Äôll need an on-network Mac Mini to build iOS remotely, which is a nightmare as well. When your build isn‚Äôt permanently frozen, you‚Äôll be pulling your hair out trying to wrangle provisioning profiles. I spent days at a time going down google rabbit holes and you probably will too. Xamarin is useful once you get comfortable with it, but there‚Äôs a very steep learning curve. I don‚Äôt haven‚Äôt experimented much with alternatives, but it sounds like React Native and Flutter provide better tooling and a more enjoyable experience. Maybe do the whole thing in a SPA JavaScript framework and use Xamarin to display it in a web view. 
&gt;[ASP.NET](https://ASP.NET) core 3 is out We're still a few months away from that. 2.1 is the latest major stable release.
[removed]
Yes! I ran it on some messy async methods and it did great.
I learnt pretty much everything from the docs. Just be aware that if you work with Xamarin Forms, you should be prepared for bugs. I encountered several show-stoppers (crashes, sometimes constant), most of which I could resolve as the source code is available on GitHub. I made several bug reports to Xamarin Forms and they solved their issues eventually, but source code access allowed me to deploy my own fork as a stop-gap solution. I was working on a macOS target which was unfortunately so unstable that I couldn't release it, and due to my limited macOS experience, I couldn't work out how to fix the source on that target. Pretty annoying because I worked hard on the app, but it seems that there's a serious stability problem with Xamarin.Mac. Xamarin Forms denied that the issue was on their end.
2.2 actually.
You are quite right. 
I think the best solution is the one you mentioned. If you want to do this, I think the best bet would be to get all users to request some base method, e.g. GetBase. Within GetBase, make a manual check and execute code in GetX and GetY as required. It is possible to do what you are asking. You can intercept requests of this type using AuthorizeAttribute. Make a custom one for the class or method. Within that attribute, you can check the Authorization and re-route to specific methods. You're still going to need some kind of check on the role, like and "if" or switch. It's just a case of putting that in the attribute or the action. You can pass roles into the AuthorizeAttribute, but if you only pass one role, you will exclude the other. You could tell users from X and Y to hit GetX and GetY, and restrict those actions with \[Authorize("X")\] and \[Authorize("Y")\].
Thanks! Appreciate your feedback :)
lol
2.1 is the long term support (LTS) release though. It will be supported for 3 years. So if you don't want to be doing a major version upgrade every 6 months or so that's the one to use
Yep this is the question... &amp;#x200B; What's blocking you from using a newer version of VS? 
I wonder how you're practically going to approach learning all these? &amp;#x200B; This is a good list of "technology stuff" to learn. My observation would be that learning all this stuff might be a bit dry without some purpose/context holiding it all together. &amp;#x200B; My hunch is that learning how to pragmatically and reliably build features is the key skill; all the specific technology details are a means to this end, rather than the end itself. &amp;#x200B; So I wonder if it would be of benefit to flesh out your ideas for an actual app to build, then break your focus areas down by each feature that you want/need to build. &amp;#x200B; My guess is you'll need to learn some of the things from your list to get your features built (which is also how real-world development tends to work, learning just enough as you go to be able to reliably build what you need to build.) but perhaps not the entire list just yet.
I really didn‚Äôt experience any show stopping bugs for my xamarin project. I felt the platform was pretty straight forward and yea there were some quirks we found that were platform specific but we were able to work them through by extending functionality on the problematic platform with the extensibility the framework provided. The one thing that we abandoned was the ability to move the focused textbox into view when the onscreen keyboard became visible. It was definitely not idea for UX but we shipped v1 to the App stores anyway. I‚Äôm curious if it‚Äôs improved within the last 2 years through the updates. 
Spa JavaScript framework: So essentially doing a Cordova project? We evaluated xamarin vs react native and opted for xamarin due to the c# experience the team currently had. I still wish we gave react native a shot with an in depth poc. 
Gotcha. In that case, it might be worth the extra effort to do Xamarin native instead of forms. I wasn‚Äôt thinking specifically Cordova but yes, something like that. 
Kind of. It's CosmosDB which is the Azure noSQL offering. It's a little different from Mongo, and given Mongo's popularity I don't think it's much of a stretch to offer a transition. FWIW we're pushing Cosmos pretty hard at work with great results. 
You can pass configuration through command line (edit web.config). Also look into the launch.json in the properties folder. You can specify instant specific command line variables there. Or you can host the whole thing in docker
Here is an article on using command line args for environment in ASP net core: https://andrewlock.net/how-to-set-the-hosting-environment-in-asp-net-core/ Combine this with your IIS configuration to accomplish while hosted in IIS: https://stackoverflow.com/a/40750166
This doesn‚Äôt help OP for IIS, check my comment above if you‚Äôre interested
The on-network Mac is an Apple EULA issue, not a Xamarin one. I‚Äôd agree there is a learning curve, the occasional workflow hiccup can be a time suck during that interim - but otherwise the workflow is leagues ahead of developing multiple apps natively and C# often outperforms Java / Swift and is on par with Objective-C (from last benchmarks I saw and real-world experience, been around since the MonoDevelop days...). Incomparable to cross-platform JS tech IMO (has a FT job doing that as well) with Xamarin also coming out ahead. Of course this all depends on what you‚Äôre building.
Thank you. I will give this a try.
* You could publish different appsettings.json files to publish for each environment (annoying, but there are many ways to accomplish this depending on which tools you are using for CI and deployment). Something like Octopus deploy used to make this kind of thing pretty easy, but I haven't used it since moving to .net core. * Look into the [ASP.NET](https://ASP.NET) Core configuration APIs. You can make your own configuration sources. Maybe the paradigm of appsettings.json files is limiting you. I know that the change from [ASP.NET](https://ASP.NET) configuration and web.config files to [ASP.NET](https://ASP.NET) Core configuration APIs really opened my eyes to how much simpler and powerful things could be. * Check the folder you are running from in Startup.cs and supplement your environment decisions with this information (hacky, but it is trivial to implement and should always work). You could make a machine wide config that would relate environments to install folders to make it more palatable than hard coding rules in startup code, but this kind of approach should always make you feel dirty. * Run the two environments inside of different docker containers on the server (feels like overkill to me, but might be a good option if you plan to run many apps and environments on each server anyways). * Run them as Windows Services instead of in IIS (probably overkill for this one issue, and won't let you use the same port for environments, but you can pass in environment variables in the startup command for the service which could solve your issue) &amp;#x200B; I'm sure there are many other ways to solve this issue. I think using the deployment tools to modify the appsettings.json file (deploy a different one by environment) is probably the direct solution most developers would reach for first, but it doesn't seem like a perfect fit either.
Actually we have different .json files. I will check the folder in start up and use a different configuration file based on that. That seems very easy to implement. Thanks.
[üéâ](https://cultofthepartyparrot.com/parrots/hd/parrot.gif)
You've taken my worst, but simplest suggestion. I don't know you, but I think I'm proud of you.
I know Microsoft might not agree, but simplest is almost always best. I‚Äôll post me code when done.
I implemented the easiest and simplest solution. I updated the asppSettings.json to include a DeployementFolders section with the names of the folders where the application will be running. I removed config.json and added four new files config\_dev.json, config\_test.json, config\_stage.json and config\_productions.json. &amp;#x200B; "DeploymentFolders": { "Test": "C:\\inetpub\\wwwroot\\Test\\RetrievalTeam", "Stage": "C:\\inetpub\\wwwroot\\Stage\\RetrievalTeam", "Production": "D:\\inetpub\\Apps\\RetrievalTeam" } public sealed class Config { private static Config _configItemsInstance = null; public static Config GetConfiguration() { if (_configItemsInstance == null) { _configItemsInstance = new Config(); } return _configItemsInstance; } private static IConfigurationRoot _configurationRoot; /// &lt;summary&gt; /// Gets the configuration file name based off the current directory and the appSettings /// &lt;/summary&gt; /// &lt;returns&gt;&lt;/returns&gt; private string GetConfigFileName() { var deploymentFoldersSection = new ConfigurationBuilder() .SetBasePath(Directory.GetCurrentDirectory()) .AddJsonFile("appsettings.json", optional: false, reloadOnChange: false) .Build().GetSection("DeploymentFolders"); var currentFolder = Directory.GetCurrentDirectory(); if (string.Equals(currentFolder, GetValue&lt;string&gt;(deploymentFoldersSection, "Test"), StringComparison.CurrentCultureIgnoreCase)) return "config_test.json"; if (string.Equals(currentFolder, GetValue&lt;string&gt;(deploymentFoldersSection, "Stage"), StringComparison.CurrentCultureIgnoreCase)) return "config_stage.json"; if (string.Equals(currentFolder, GetValue&lt;string&gt;(deploymentFoldersSection, "Stage"), StringComparison.CurrentCultureIgnoreCase)) return "config_production.json"; //Default to the dev version of the configuration return "config_dev.json"; } private Config() { _configurationRoot = new ConfigurationBuilder() .SetBasePath(Directory.GetCurrentDirectory()) .AddJsonFile(GetConfigFileName(), optional: true, reloadOnChange: true) .Build(); } public IConfigurationSection GetSection(string section) { return _configurationRoot.GetSection(section); } public T GetValue&lt;T&gt;(IConfigurationSection section, string key) { return section.GetValue&lt;T&gt;(key); } public string SqlConnectionString(string connectionString) =&gt; _configurationRoot.GetConnectionString(connectionString); } &amp;#x200B;
It seems there's gonna be a stream on [youtube](https://www.youtube.com/watch?v=Hg0tKNAQ1UQ) as well.
This. i.e. - software as a service.
I already have a list of web application ideas that I'd like to build. In fact, I already started building out the data model in EF Core for one particular application. However, I'd like to take a step back before I get too deep into it and actually reevaluate how I learn new technologies to build things. Just to give you guys some context, I'm already a professional software developer, but up to this point my learning process has been kind of haphazard. So I started taking a course in "learning how to learn" (don't want to drop the link because I don't want to get banned). I'm trying to adopt a beginner's mindset, pretend that I'm approaching this as a complete newbie. So that's why I'm reaching out to other experienced developers. Really great feedback so far, thanks guys!
What's stopping you from having different environment variables in IIS, exactly? [https://imgur.com/mLwo5A6](https://imgur.com/mLwo5A6)
&gt;solution seems best. I wasn't aware you could set environment variables by IIS instance. That's a much better approach, but some are commenting that setting the environment variable in that way gets wiped out everytime you deploy (maybe someone can confirm?) I don't know. I posted what I implemented. It is working in Test and Stage. I can publish right from Visual Studio, I just created new publish profiles for Test and Stage and the only difference is the destination. The only downside is if we decide to move it to Azure I will need to change it to use the Environment Variables. Added bonus is all the configuration files are now in source control, right in the project. Downside is if we change hosting to not use IIS, but that should be easy to accommodate if needed.
Wouldn't the web.config get overridden every time I publish? Do .net core sites use that for Environment variables?
The concept of null has plagued programming languages for decades. When I first learned F# I loved Option because it avoids the mess entirely. Idiomatically, I don't think a functional language should encourage the use of null as anything semantically meaningful. It goes against the foundations of functional programming IMO. My opinion is that they should leave the nullable reference types to C# and focus on what makes F# great--being able to elegantly solve complex problems in few lines of code.
But without C# style nullable reference types, interopt code can (more easily) leak nulls into F#.
Channel9 as well I expect.
This is the first time I see F# 5. Can anyone provide with me link to its features list? Does it have release date?
This is where it should be, but I don't see a roadmap yet: https://github.com/fsharp/fslang-design F# 5 should coincide with .NET Core 3.0 and C# 8.0 later this year.
This is great. Also, interesting thumbnail they chose 
It doesn't start until 9:00 am pacific time or 12:00 pm eastern time.
A host of videos just went up too on YouTube talking about the major features: [https://www.youtube.com/user/VisualStudio/videos](https://www.youtube.com/user/VisualStudio/videos) 
Definitely worth the money. I still reference old books as most non-tech companies don't move as fast.
Here's the 4.6 release in case you're interested. https://devblogs.microsoft.com/dotnet/announcing-f-4-6/
You could say he was merciless.
I can see that there are a lot of great features and enhancments, but damn, the video quality is janky. Is that twitch's fault or is that azure's fault?
Just a note, they released 2019 with C# 8.0 in preview/beta.
Your fault look like. I don't have any issue.
I like my VS very heavy (Reasharper, a lot of extensions, Just Mock, etc). Cpu does not need compared with other specs. RAM and Hard Drive speeds its more important.
If you host in Azure and use Azure App Services then you can have dedicated deployment slots for each environment. It works out really well from what I've tried so far, but Azure App Services cost more than VMs for equivalent horsepower.
One cool feature I noticed: CodeLens is now part of Community
Here's one possible bug I noticed right off the bat. If you goto Tools -&gt; Options -&gt; Environment -&gt; Fonds and colors and show settings for Environment and set the font to 14, it breaks a bunch of stuff like the "Search Visual Studio" search results are unreadable.
I have a MacBook Pro, probably the worst thing I‚Äôve ever bought for web app development in visual studio. I didn‚Äôt buy it for .net mind, but if I‚Äôm developing on it I have to remote into my windows pc :/
I use visual studio in a windows 10 VM. I have had no problems so far with that. What issues have you had?
It‚Äôs not necessarily issues, I just find it a huge pain lol
It‚Äôs not necessarily issues, I just find it a huge pain lol
Also, think of the perf problems of having your backend and DB not in the same regional network.
I installed VS2019 Preview back in January. Today I updated to 16.0.0 Preview 5.0. Correct me if I'm wrong but I'm running full VS2019 version released today, "Preview" means that I'm testing and running features not yet released to everyone. 
I think that's right, the Previews after release are kind of like betas, eg. https://devblogs.microsoft.com/visualstudio/visual-studio-2017-version-15-9-preview-2-2/
Interesting. We're using a 3rd party API gateway, so maybe that's mitigating a lot of those problems for us? I'll keep this in mind though for sure, but so far we're having great success (that being said, Azure is almost all greenfield projects for us, or complete rewrites of existing apps). We're all .Net with some legacy AS/400 and Oracle stuff, but those are all long wrapped with .Net facades with great API's (most of them REST at this point, thank god).
Where'd the video go?
Weird. My preview updated to the full version today
Are talking about server side rendering? There are frameworks out there for this I think next.js might be what you talking about. However I‚Äôm just starting in the react world so I could be wrong. Check out r/reactjs also and you might get mor answers. 
It was in community for 2015, it was just taken out for 2017
For those interested in using C# 8 in VS 2019 [https://www.dotnetcurry.com/csharp/1489/csharp-8-visual-studio-2019](https://www.dotnetcurry.com/csharp/1489/csharp-8-visual-studio-2019)
Good to know.
[I just want to see something like this again](https://www.youtube.com/watch?v=I14b-C67EXY&amp;t=1m25s)
Is it too early to start planning for C# 8 features in brand new asp.net projects? I really want to take advantage of non-nullable reference types and I think it'd be hard to enable this after the project is mostly written.
Well maybe at Build this year. Who of the major speakers would you say is likely to be the one to bring it out?
modern problems require modern solutions
What a problem to have. 
What a problem to have! 
This may sound crazy but I have two personal laptops, a work laptop and an iPad. I use the iPad for playing games / watching videos while traveling or exercising on the elliptical. I use my MacBook Air for browsing reddit, paying bills, using One Note and general computing. I have an HP Laptop with W10 that use for any programming / learning of coding / tech stuff not related to work. When traveling for work, I take the iPad and work laptop with me and that's it. None of my laptops are super high end. I love the MacBook, iPad, iPhone, Apple Watch and Apple TV. When you own all of these things it is f'n magical how they interact. However, they are not good for .net coding. I code on windows computers. My windows laptops are barely ever used undocked, honestly.
No one has mentioned this.... But; your production environment should be identical to your test environment. e.g. you need to put each environment on a separate server. Don't take short cuts with this, it's not worth it.
I agree. Except that I work for a small company with &lt; 30M in revenue and a small IT budget. In my case, maybe it is worth it to save them a server?
Can you show me an example of this with an object 
I worked for a 1 man team with a &lt;1M in turnover, I had 2 servers...
Good to know. I‚Äôll think about this, you may have changed my mind.
I chose ApplicationHost.config instead of web.config as you can see on the screenshot. That one doesn't get overwritten. You can also instruct webdeploy to skip web.config if you call it directly from the console. The screenshot is from one of my company's double-purpose servers by the way. It hosts both the test and the staging versions of the same project deployed via msdeploy/webdeploy using a simple script. 
well this private static readonly ConcurrentDictionary&lt;SomeComparableClass, SomeDifferentClass&gt; \_myConcDict = new ConcurrentDictionary&lt;SomeComparableClass, SomeDifferentClass&gt;(); &amp;#x200B; in C# 8 will become this &amp;#x200B; private static readonly ConcurrentDictionary&lt;SomeComparableClass, SomeDifferentClass&gt; \_myConcDict = new();
There‚Äôs only GET and POST, no DELETE, PATCH, PUT. With quick look it seems it returns the result as a string and if there is a problem it returns errors also as a string with no mention that there actually was an error and the result isn‚Äôt actually the data you wanted. Uses WebRequest which is not recommended to be used these days. So I wouldn‚Äôt really start using this anywhere, but I‚Äôm sure it was a good exercise. 
Whatever happened to ‚ÄúMicrosoft ‚ù§Ô∏è Linux‚Äù? üòï
Good points. Yeah I had more error handling code but removed it as it was too specific for my company. But the basic get / post methods handle all of the web service interactions my project needed. Really this is a way to treat a REST API like it's soap.
wow. I'm really liking these changes. 
I started Xamarin forms like 2 weeks ago. It certainly doesn't have the maturity of other .NET technologies like ASP .NET Core. &amp;#x200B; What I can recommend as a first introductory step is to take this video course from Mosh Hamedani: [https://www.udemy.com/xamarin-forms-course/](https://www.udemy.com/xamarin-forms-course/) Its a mere 7,5 hours, on the point, and thankfully doesnt try to teach .NET or C# as part of Xamarin forms. Its full useful stuff. &amp;#x200B; I found the Microsoft Documentation up to date and useful, **except** the free Xamarin book from 2016 you can download from their homepage. That book is dated and doesn't give XAML priority over code behind when talking about UI. &amp;#x200B; To recap, I recommend to take the 7,5hrs course from Hamedani, that will be a good introduction wit a lot of hands on and after that you will get a feeling of how you would like to continue, what topics a book should contain etc. &amp;#x200B; &amp;#x200B; &amp;#x200B;
vs-code :)
So you have no idea what RESTful means.
Thanks ill check it out
I haven't learnt .net core. Can I still follow through this? 
Thank you so much. It's because of people like you who put in so much effort to make free videos and answer questions on forums like stack overflow flow that programming has such a thriving community
If you know. NET you should be fine (maybe except the ASP. NET Core Startup part), also a lot of topics is very generic :). 
Thank you! We all enjoy sharing and e.g. using other people code and packages, so it's our small contribution :). 
I have a new pet project and I enabled new nullability and C#8 features. I like them so far but it's hard to change the mindset. Also IDE has some minor problems with displaying errors that were turned from warnings. I changed warnings related to nullability into errors on project basis to enforce new nullability in the system. Visual Studio highlights classes instead of particular properties that need initialization, often they're highlited as warnings even though in build output they're clearly errors etc. other than that I like it. And yes, I do agree it's gonna be hard after the project's written. I made a base template for the project with the stuff I need and then enabled nullability. It took me about an hour to convert and fix stuff in a sensible manner(not just using ? everywhere but where it matters).
Just out of interest, at what scale do people think micro services make sense? &amp;#x200B; We manage small sites, with less than 10 million page views each month. From ecommerce to article/blog based stuff. &amp;#x200B; At what point does it make sense to go microservce? &amp;#x200B; Or have I got it wrong and microservice should be 'the way' to go these days? &amp;#x200B; &amp;#x200B;
I think when you want to horizontally scale your apps, make parts of your domain to be autonomous in terms of development and deployment it makes sense to think about distributed systems. 
How quickly do you feel your recorded steps go out of date? I've been feeling that with the speed of .net core, something that was ok 2 months ago feels suddenly dated. Is that just me? Just reading to keep up with core has felt like a part time job. 
A lot of the concepts have been there for many years now, also the tooling related e.g. to service discovery, metrics, monitoring and so on. With .NET Core you just write a code for the services and make use of these tools that are not really going anywhere in the next few years :).
Your organizational structure is also a big factor you should consider when deciding whether to do microservices or not. If you have separate teams working on relatively isolated "sections" of the same overall product, a microservice architecture can help your teams be more flexible without stepping on each other's toes. 
It‚Äôs VB and you expect knowledge?! 
I am completely fan of the video series, Thanks guys.
Really nice project. Some things I would have loved to have seen included: MeditatR - to remove the command/query/notification boilerplate. Also simplify ability to implement cross cutting concerns via pipeline decorators. FluentValidation - self explanatory really IdentityServer - maybe not by default but support would be good 
You're welcome! :)
Hey, thanks for the feedback. You're correct, these libraries would be quite useful to use, and it's easy to do so. One of the reasons we did it the way we did, was to show e.g. how the message pattern works in general (which can be easily replaced by MediatR or Brighter). Identity Server - yeah, but the same story with JWT in general :).
Linux Server gets all the love, the Desktop not so much :-(
here's a copy that still works (no idea for how long) https://www.youtube.com/watch?v=HUN1j9G1Py8 
This I would agree with. But i would argue with correct caching and performance optimisations, 90% of websites out there don't run into this problem. &amp;#x200B; There is always the 'what if it does', but doesn't it make sense to develop and host a websites at a third (i'm guessing) the cost make far more sense and deal with scaling when it becomes a problem? Because when it becomes a problem you have success, and therefore money. I know this is out the realms of dev really, but I think its important we discuss it as developers. Businesses, especially SMEs will ~~always~~ most of the time go for the cheaper route initially - and I don't think thats a bad idea.
You're totally right, building the microservices is a technical challenge (actually, quite complex and demanding). We, being the developers like such challenges, however quite often it might make not sense at all for the business that we work with to use such architecture, however that's a topic for a different discussion :).
Correct, that's also a valid point, and always beware of Conway's law :).
I recall hearing Banq Nationale talking about 2-300 developers, at which point I can see the point of microservices/containerization. 99% of cases would better served with a monolith (or similar "basic" architecture)
I think the second time you grreenfield a new system it's much easier to think distributed. However, it's often better to slap everything in and get something working and then scale vertically at first. &amp;#x200B; You need a bit of insight into your domain and infrastructure to get off the ground, so it might be better to explore the domain by getting something concrete into which the sponsors/users can get involved with. &amp;#x200B; As usual, you decide based on your needs, but it's an option that should be assessed. Pro's: The users get something to complain about sooner. Con's: Duplication of effort. &amp;#x200B; If you do follow the prototypal, vertically scaled model, the key is to isolate the knowledge parts from the infrastructure parts, this makes it pretty simple (simpler) to move towards a distributed system. 
Speaking of the insight, I think modelling techniques such as Event Storming might be very helpful here.
Modular monolith is a great starting point before getting into the distributed apps :).
These have all been pretty big deals for me: [https://github.com/search?q=is:issue+author:Liam2349](https://github.com/search?q=is:issue+author:Liam2349) There are one or two others that were opened by others and I commented on.
Shouldn't the DPI Awareness deal with 4K and fonts, or do you not use display scaling for your monitor? &amp;#x200B; Just asking
&gt;CodeLens is now part of Community technically it wasn't. It was (probably by accident) deployed with certain other Packages which could be installed. &amp;#x200B; Glad that Community now has it :)
Yep, definitely helps. There's still a learning curve for the domain experts and historically it has been hard to tease out some innovation rather than just Conway Twitty it. It reminds me of some of the Event Sourcing guidelines about granularity and how too fine vs too coarse affect a system over time. I'm advocating for it to be considered rather than advocating for it as a preference. I might even be advocating against big up front design by providing one option to help mitigate that. Even if you follow the "chuck it all together and scale up instead of out" idea, you can still adopt distributed techniques from day one, even if that's as simple as exposing a few WebAPI endpoints or slapping in a basic bus. Docker is changing some of this, but even there you still might benefit from focusing on functionality over infrastructure while the domain settles and brings up an important distinction. Scaling up these days doesn't have to mean everything running on a single machine, it's more to do with scaling on a single node. If you've exposed a WebAPI endpoint, do you need to load balance that this early in the development cycle? Could the developer/devops guy spend that time more effectively shaping the domain? Like everything it's a YMMV situation which depends on team size and skill set and day one expectations. If you need to scale to millions of users on day one, this should probably be a core part of your project strategy. &amp;#x200B; You're spot on though. Involving the stake holders, domain experts and end users is critical and one of those things enterprises still screw up. Stake holders might be available, domain experts are usually valuable so you get the domain expert who is least valuable to that team at the time. And end users are often entirely ignored until way too late. Finally requirements change, so get as much of the change out of the way at the front of the project as possible. None of these situations should exist, but they do and you need mitigation strategies. &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B;
Wow. I am learning but tli am working a company that has three different "shared" libraries to interact with rest, all of them require many lines of code to use, my solution makes the whole interation one line, and passes and receives complex objects. No appreatiom for simplicity?
Wow. I have worked for many companies that use C# and VB. Currently I work in finance so VB is more common. But I can tell you there are plenty of C# programmers that write terrible code. 
Why not use RestSharp? It does far more and is crazy simple to use
Decent developers won‚Äôt touch VB for good reason. Sorry that your last place of employment uses it. 
How are "microservices" different than "regular" services? In other words I've worked in companies where we had dozens of "SOA" SOAP services that performed different tasks. One would perform order entry/maintenance, one shipping, etc. They were isolated services hosted on their own servers, calling into each other if needed. From the very little reading I've done on Microservices it almost seemed like the difference was that each MS was a single method, so one "legacy" trade entry/maintenance service with 50 methods becomes 50 microservices. This honestly never made any sense to me.
Anywhere I can find out the difference between community vs professional? https://visualstudio.microsoft.com/vs/compare/ doesn't really tell you much.
Thanks so much! 
I'll check it out, although the example n their site shows multiple lines of code to achieve what this does in one line. But maybe their is a way to do it if I test it.
Does it matter? There are cases where building something that reflects Fielding's original (2000) proposals will be brilliant, but 99.9% of APIs work perfectly well without HATEOAS or PUT, PATCH and DELETE because the API doesn't reflect CRUD. In many modern use cases, if the client knows enough about an entity to know whether to PATCH or PUT, it probably knows too much.
I've only seen a few limited usages of [VB.NET](https://VB.NET) in the wild, but (mostly) ignore /u/TheWrongen &amp;#x200B; [VB.NET](https://VB.NET) was originally created to woo VB6 developers over to .NET. It also had a bunch of features like optional parameters that made it a good fit for Office development. I'm half guessing that's where you're seeing a lot of its use? &amp;#x200B; Since then C# now has a better feature set. It also looks like every C shaped language, so it's easier for C/C++/Java/Javascript etc developers to understand almost immediately. Nearly every example on the internet uses C# rather than [VB.NET](https://VB.NET), although Microsoft are good at providing examples in both. &amp;#x200B; I never really engaged with it. After leaving VB6, I still had to know VBA for Excel, but really didn't want my .NET knowledge to be polluted by my VB6 knowledge. So making a clean break to C# made more sense. &amp;#x200B; With that all said, [VB.NET](https://VB.NET) is a .NET language and no less capable. So ignore the troll. &amp;#x200B;
I couldn't use RestSharp recently, so wrote my own generic client. It works differently and is more complicated because of how I wanted to define operations, but you get a tick for simplicity being good :)
I use an air but I use VMWare Fusion to connect to a rack server where my windows 10 machine is. It's hard to beat 20 cores and 60 GB ram on an SSD. Just have to have a decent internet connection for the VPN and it's like you're running it locally. If you're not doing anything too heavy you can run a windows 10 machine in Fusion locally and it's fine. 
For us, the decision to use a microservices architecture (ours may actually be more appropriately called mesoservices since some of them don't fit the traditional definition of "micro") was due in large part to the fact that we knew our application (a B2B SaaS) was going to continue to grow in features and complexity well beyond what we originally needed and could plan for. While we had some ideas about what direction it would grow and how fast, hedging our bets by keeping the entire system extremely modular seemed like (and has proven to be) worth the cost in complexity.
Since this is built on Web framework, you get all the wired up HostBuilder that you get with web. That is valuable
You might need to uninstall, then reinstall from the regular URL.
I don't think there's a difference. It's just that if you have &gt;5 employees or &gt;$1M in revenue annually, you have to pay for professional and can't use community.
So I was a VB6 developer oddly enough at Microsoft when .NET was released. We converted our project at the time over to [VB.NET](https://VB.NET), last I heard Microsoft was still using it. It's just an internal testing tool that validates windows installs (mainly it makes sure all the right default registry settings are present and that the right files are in the windows directory). Since then I have worked at several companies spearheading their VB6 to .NET conversions. Some C# some [VB.NET](https://VB.NET), but currently I work at a Finance company, and they have a doozy of an accounting system all written in VB6. So we are converting it all over to mainly [VB.NET](https://VB.NET) and some C# when we can break things out into different projects. Personally I like VB, I started in BASIC when I was a kid playing on a VIC 20, C# has too many semi-colons for my taste.
The same way you would any other but i susepect you will need the char code for the symbols eg: **U+1F310** &amp;#x200B; loop through the hive and print out the character string names of each one, see what it looks like?
You can develop desktop applications in .Net just fine, but the whole world is moving towards Web applications. Even an application that only runs internally is easier to maintain as a Web application (on an intranet). No installation issues, central management. It's just easier all around. There are downsides of course: browser applications are much more powerful than they used to be but you can still do more in a desktop application. But if you don't need desktop-like features, it just makes more sense to build a web app. 
[removed]
In my experience, .NET jobs are mostly about business CRUD apps that can either be on the desktop or in a "web app" using ASP. I guess there's some C# jobs around in the gaming industry because of Unity too, but probably not a ton. If you're really interested in graphics programming, C++ is where it's at. The games and 3d graphics industries are mostly C++ focused, I'm sure there's some that use C but that's probably the minority
It‚Äôs not easier at all, but it do is the trend. I‚Äôve migrated from web to wpf for internal application and saw huge gains everywhere (productivity, support, user satisfaction etc). Like everything it‚Äôs a tradeoff (no cross platform etx) but it‚Äôs definitely not just better or worse.
80% of apps i've been building with .NET are background services, communicating with rest of the system through HTTP or Queues, and some REST API and MVC apps taking other 20%. WebApps are just thin layer on top of bunch of back-office stuff. 
what are the specs for ram and HD speed for the laptop you are using?
Lenovo Y50 i7 (2014), 16 GB DDR Kingston Hyper Fury, 1TB SSD Kingston, 
I wasn't clear - "easier" referred to application installation and distribution, not development. In general, web apps "just work" on almost everybody's PC. Obviously if they have a really old version of a browser, or they block JavaScript, or they have an add-on that interferes with your app then it can be an issue. But you don't have to implement some kind of auto-update feature and you don't have to build an installer. Neither of those are rocket science, but it's a lot nicer to just be able to update the server and have everybody magically get the latest version on the next refresh. I develop web and desktop and there are pluses and minuses on both sides. The hardest thing for me is mentally switching modes between the two. Something I can easily do with a line of CSS on the web side is painful on the desktop side. Then something I can easily do on the desktop side in C# requires me to write a bunch of ugly JavaScript on the web side. The one advantage desktop apps still have is security. No matter how secure you think your web app is, if it's on the internet then there could be millions of people trying to hack it. I don't think that's as prevalent with desktop apps. The #1 advantage of a web app is it's pretty much impossible to pirate it :)
I sort of guessed :) &amp;#x200B; I liked VB6. I wouldn't want to go back, but we did some amazing things with it. I did a couple of weeks at MS assessing their automatic VB6 - [VB.NET](https://VB.NET) tool. Nice people, nice offices, great canteen :) &amp;#x200B; I can deal with c# semicolons. You sort of press the button in the same way you'd hit return after a while. Javascript goes a bit nuts because semicolons are semi optional. Semi being because there are plenty of cases where your code suddenly starts world war 3 if you miss one in one of the half dozen edge cases :) &amp;#x200B; But, if we're going to fight, I'll snub my nose at your VIC 20 in favour of my rubber keyed Spectrun ;) 
Try searching for Unity instead of C#. Unity is a game engine that uses C# and it's pretty popular. That said, there's definitely more companies by orders of magnitude making web apps with C# than doing graphics things. 
https://docs.microsoft.com/en-us/dotnet/api/microsoft.win32.registrykey.deletesubkeytree?view=netframework-4.7.2
First, you must se if you are able to reach registry path. A console application, windows services, iis site, don't use the same system user authentication.
i disagree with deployment, clickonce makes deployment and updates trivial, no need to roll your own auto update nor installer there. 
&gt; I do not see anything or anyone wanting a graphics programmer You are probably searching by the wrong terms. A search for Unity (leading game engine which uses C#) brings 6,000 plus results from indeed. "3D game' brings in 2,000 (no doubt some overlap because Unity is pretty big in 3d games).
Agreed. Sure there's a web front end, but it's pretty much always just the tip of the iceberg. For example OP, imagine how much back end infrastructure is needed to support Google's search engine or Amazon's website.
What exactly are you looking to do? Find that exact item by name and remove it? Or look for entries using unicode-only names? Or what? Also that looks like Explorer, not the Registry. The process will be different for either. You're giving us the solution you've chosen without the context of the problem you're trying to fix. I think we need to start with what exactly you're trying to accomplish. Then we can help you not only figure out how to do what you're trying to do, but also advise if there is a better way.
This. This is always the correct answer. The only real difference between a modular monolith and microservices should be all the trade offs that come with a distributed system. Go in to your modular monolith and add random delays, failed function calls, and dlls that randomly disappear and move around. Now ask yourself if all of that added complexity is worth the benefits. In many most cases, the answer is no.
If you have one solution hosting these two services, I suppose, you will always deploy these services together. In that case I would rather exchange the data in-process, since it's more performant. You will mostly use a service facade when implementing services, which means, that the actual logic is not the in WebAPI controller itself, but some controller class behind that one. If you organize your code like that, You could have the backend components talk to each other in-process saving you any network roundtrips.
&gt; 90% of websites out there don't run into this problem I serve a billion+ dynamic requests a month and we're doing just dandy with your standard monolith and spattering of misc utility apps, web apps, background job processors, a bit of mobile, etc. We're far more likely to create a separate "service" than a "microservice", and in fact that's what we do when it makes sense to make part of our overall system more independent. But it almost certainly shares a database, and probably a redis cluster or 2, and it uses a bunch of shared library code from nuget packages published out of the monolith, so it isn't "micro". We do deal with some similar complications, having some data that is eventually consistent, and interacting with dozens of external, 3rd party services (10's of millions calls per day).
Thank you for your answer. Apologies I did not mention this, but right now I have two services in one solution. However, the idea is to have two separate solutions for the two services.
Ooo a Spectrun. Have to admit I had to look that up, but it looks pretty cool for the time. Yeah that VB6 to [VB.NET](https://VB.NET) conversion tool was terrible, but guess that's what has kept be paid all these years. VB is more common then people think, just not used in high tech companies. Lots of companies out there have a system that started as as simple VB6 CRUD and evolved into systems that they depend on. I've seen VB systems in Manufacturing, Finance, Retail, and Warehouse / Inventory Management.
theres a sizeable amount of Unity jobs out there, but in the end what .NET is used for is business infrastructure - sifting data around in real-time, loading it, presenting it, and the infrastructure behind all of that. 
Some do say that MS has greatly improved installation and updating of dot-net desktop apps. One group at our shop has switched back to desktop apps because procuring new servers is a paper-work pain here. I miss not having to deal with buggy JavaScript libraries to get regular GUI behavior. I was hoping the industry would invent a GUI Markup standard by now, but we are still stuck with fat-client JavaScript libraries. Bummer.
And web may be moving fast but it‚Äôs taking forever to move in the right direction, i was doing wpf 10 years ago and for the web i was doing JS + WCF instead of pre mvc asp.net. We had to go through 10 years more untill it finally became mainstream to do client side apps and only data between client and server instead of whole ui redownloads
&gt;Something I can easily do with a line of CSS on the web side is painful on the desktop side. What's an example?
You'll need to save the state of the variable on postback, check out session variables.
Not at all, you have gaming (Unity, Godot, Xenko, MonoGame). Then many UIs in medical devices, factory control panels are actually running Windows with a .NET based frontend. For example, https://lifesciences.tecan.com/software-overview https://www.biotek.com/products/software-robotics-software/gen5-microplate-reader-and-imager-software/ https://openautomationsoftware.com/knowledge-base/overview-wpf-hmi-dashboard/ 
Please fix (stop) whatever it is you're doing with the scroll bar.
That does not look like registry keys though. 
In that case you could go ahead and call services in cascaded via http. However the drawback here is, that you may get into timeouts, when someone calls the outer service, because they sum up in time it takes to answer the whole request. If this is a problem for you depends on the execution time of the individual service calls as well as the network connection in between the services and the scale of your system. You should also consider, what happens if service 1 cannot reach service 2. The problem is, that if you do retries, these will add to the runtime of service one hence increasing the possibility of timeouts. Sometimes failing fast is better here. There is a great library called polly, which I can recommend for this stuff. I would just start off this way, if you step into issues later on, you can still decide, whether you want to have more complicated solutions like messaging or http callbacks. 
Cant' agree more with what you've said. Microservices are a technical challenge, and quite often it doesn't make much sense to use them (and developers might be unaware of the challenges related to them), the key is (and will always be) proper understanding of the business people and domain experts.
It may not be integrated with VS for Mac until the final release. I know vS for Windows support is not yet complete. You can try starting with .NET Core 2.2 and modifying the project settings or the .csproj file itself to change the .NET Core version used to see if that works.
I've tried installing the .NET Corer 3.0 preview2 now.. And I can see that version. So it seems like the preview3 just isn't compatible. I'll try and check if i can modify anything in the .csproj file, thanks a lot! :-) 
Exactly! I spit out some technical stuff, but it's useless if you're not solving the problem you went in to solve. That's always people :) 
It depends where you look. In my experience mostly focused purely on web or all rounders. Tho most common currently are web, desktop apps and games
Have you looked at a BPM/Workflow solution? Something that has Rest APIs to interface with the rest of your product. Are you using a Service Bus?
You need to be more specific. There's currently 4 or 5 different things that fall under that umbrella. ASP.NET WebForms, MVC, API, SPA, and the ASP.NET Core versions of those things. They are all similar in that they fall under the ASP.NET Libraries, but they vary substantially.
The Spectrum was amazing, but at the time I can't remember having an argument about whether, ... no actually we did have discussions about whether Z80 vs 6502 had a better instruction set. I have literally been irritating my entire life :) &amp;#x200B; I totally get it. Software grows, technology grows faster. strapping a rocket and training wheels to the old is an art form :)
Where I work we use .net to build desktop apps that get installed on factory machines. No online components at all.
ASP.NET WEBFORMS &amp; MVC
A good alternative to a giant manager class is to break it up into several smaller command and query classes. Start looking down the path of CQRS with tools like Mediatr. You can essentially set up a pipeline so you can hand off all these tasks and configure the ordering and dependencies between each. A good starter article to get you on the right path is [Jimmy Bogard's CQRS post found here.](https://lostechies.com/jimmybogard/2015/05/05/cqrs-with-mediatr-and-automapper/)
&gt; Your organizational structure is also a big factor you should consider when deciding whether to do microservices or not. Conway's Law cannot be denied! Your software architecture *will* reflect the communication patterns of your teams, so it's a good idea to be ready to rearrange your teems for better architecture, too.
More than just being aware of it, be prepared to restructure your teams to match the desired architecture rather than always making the architecture based on the existing team structure.
The NuGet client caches HTTP responses for 30 minutes. I wonder if you're trying to restore the package before it's available on Azure DevOps? Do you see anything suspicious when you restore with `nuget restore -Verbosity detailed`
I'm at home now, but will check this tomorrow when I'm in the office and report back. Thanks for the suggestion!
Shudder 
By ‚Äúeasier ‚Äú he means for deployment. WPF is definitely easier for the developers.
I use MassTransit.
Been using it since RC 2, no complaints. Still using ReSharper for code navigation purposes.
The RC was fine, so I upgraded. Going to try replacing resharper with roslynator and codemaid, and see how it goes
I have it installed (upgraded from RC) along side VS 2017. I'm using Roslynator in both and haven't had any issues yet. I haven't used a whole lot of 2019 yet though, just a little app I put together to try out .NET Core.
If you remember, please post back with an update on how that goes for you.
I installed it as soon as it was available. Already using it daily. I dont use resharper. 
will there any videos related to fetching data from multiple microservices (BFF)? also topics like eventual consistency in a microservice world
For those that install new versions of VS do you leave the previous version of VS on you desktops? 
I installed today the vs2019. Used for 3-4 hours. Never used the 2019 before in any preview, just saw a quick video that md made about the features. My opinion is that it seems a bit faster on almost every task that vs does, non related to compiling, the design is better imo. So far I liked it, will be using as my main ide this week on my job and will see. Ps: using the enterprise version
When I see that it‚Äôs stable enough, I always delete 
Udemy has a bunch of free courses. Coursera has some if I‚Äôm not mistaken. And of course, YouTube always have decent content
Have been using at home since RC2 (removed 2017 after 2019 install), will be installing alongside 17 at work though, esp since work is airgapped and a mild pain to get stuff installed on. Hopefully I can get the installers and everything for work this week or next
Already installed it with Preview 1.0. Only Preview 2.1 crashed on json-files (which was quickly corrected with Preview 2.2). Other than that no problems for me. I'm working on a team with 2 other developers that stayed with VS2017, never had problems with working on the same code/solution (WebApi on .Net Core 2.2).
I've watched a lot of your videos already. I've been learning a lot about different parts of microservices in isolation, but your videos help me understand why they're needed and how they fit together. Thank you!
This should have been the first thing you discussed in your talk... &amp;#x200B; When should I use Microservices? Pretty much never, if you think you need it chances are you are wrong and your just jumping on the latest catch phrase band wagon. Go re-align your chi and read some Dilbert until your cynical enough to continue in the wonderful world of IT. &amp;#x200B;
I'm mainly in the IT Admin business but am learning C#/ASP.NET CORE. I use an in house Remote Monitoring Management system that's totally built on .NET for the server infrastructure as an instalable system and all system agents for remote checking in and sending commands etc as well as the web interface which is build on .NET. So I'd say yep :) 
They are boasting a 70% increase in performance as shown in this video from the launch event. https://channel9.msdn.com/Events/Visual-Studio/Visual-Studio-2019-Launch-Event/Write-beautiful-code-faster
A coworker of mine was describing how resharper totally kills the performance of vs. such a shame. 
Your coworker is absolutely correct. For decent sized projects ReSharper routenly adds around 15-20 sends initial loading delay 
Ouch! Most of his solutions are 1-3 projects per. He‚Äôs not on our core SAAS team either with some of our monolithic codebases. Can‚Äôt imagine the load time on some of the 80+ project solutions we have. 
Deployment is not harder, you‚Äôve got to deploy your website too and with clickonce deployment and updated is actually publishing a website
I just ran code analysis on one of our solution. It's only 12 projects with around 100000 lines of code, biggest project being around 45000 lines of code and this is the solution where ReSharper adds around 15-20 seconds of delay (VS warning about delay in loading) 
I've been using it for a while now. About the only extension that doesn't work for me is "Automatic Versions 1" which I used for asp.net core websites. Still trying to find a trivial method to do incrementing builds and dated builds that doesn't feel hacky.
Insert multi platform environment...... aaaaaannnnnddddd go
Which is a big issue, was reported to them, and ignored for almost 3 years (still not fixed): https://github.com/NuGet/Home/issues/3116
How much time would you say you've spent on the course? I'm tipping it's not a *small* contribution after all :)
Starting using it on release day. Tried to ditch Resharper, but realized my fingers know all of the shortcuts, so I reinstalled it. 2019 seems faster and has already improved a few Xamarin debugging sessions. 
Been on it since the RC.
I already mentioned you lose multiplatform with that. it‚Äôs a tradeoff. Ib many companies with an AD and a windows dev/support team it‚Äôs windows everywhere, no reason to get the slower/less rich dev environment of the web when you can go avoid it.
waiting. I spent in inordinate amount of time getting the CUDA extension to work with VS 2017, and I don't want to go through that again.
We have a couple people trying it out, the reduced ram usage is pretty nice. Probably will upgrade once we're sure there aren't any issues.
Try one of the wrappers of [https://github.com/topics/wkhtmltopdf?l=c%23](https://github.com/topics/wkhtmltopdf?l=c%23)
I saw this article while frantically searching for a solution. But why does it only seem to affect packages generated for .net framework assemblies and not .net standard and .net core assemblies? Very odd.
Installed 2019 and [Resharper 2019.1 EAP](https://www.jetbrains.com/resharper/eap/). Seems good so far. Maybe a bit peppier than VS 2017 for medium sized dotnet core projects.
This! :)
True that, but then we would need to create a course about domain modelling and so on - instead, we discussed how many technical challenges is there, and it might be scary (and probably should be) for some developers.
Great to hear it, and thank you :).
Maybe in the ones about Saga and CQRS, cause it's always the question how to deal with data, increase resiliency and decrease the temporal coupling - do you want to integrate asynchronously via integration events and keep all of the data in your local storage (same goes to the read models), or do you want API Gateway to aggretate DTO from multiple microservices.
Nahh, just do a presentation on how to combine a whole bunch of Microservices into a single monolithic application. It will be all the rage in a few years :)...
What do you mean?
We started working on it a year ago - we already had some existing code, but we needed to create all of the services, utilities and so on, so basically a few months of work after hours. Then, we started recording videos, we already have some experience in that area, thus it was just recording and rendering (and not too much of editing), but I think you could assume a few hours of work per video, since you also need to think of its topic and a flow :).
It probably will :D. Most likely, in the upcoming years we will hear people speaking about "microservices disasted" and getting back into monoliths. Anyways, I'd say the best starting point is the modular monolith and once you're not afraid of replacing some of its parts, try extracting them and see if that works for you :).
My C# course at university uses 2017 (exams and tests are carried out in the PC labs and occasionally homework solutions are submitted from our own laptops), should I wait for the course to finish before I switch to 2019 on my laptop? Some people still use 2015 and they seem to be fine. 
Planning to do it over the weekend on my own systems. At work we are staying with 2017, customers don't pay for downtime due to our own issues, in case something goes wrong. Never liked Reshaper and the slowdowns it introduces.
Check out Tim Corey on YouTube. He has great introductory tutorials for web API and MVC. 
I found JSReport to be a memory hog which kept causing the app pool to recycle, giving 30-second PDF generations. I switched to using Chrome directly with PuppeteerSharp which worked much faster and leaner.
Very common to have 3 separate classes for the above scenario. It allows your trigger to not know anything about the things it is triggering, allowing you to subscribe to that event and trigger your api call. Part of this is there are many libraries that help you with doing things like the TimerTrigger. Libraries like Azure WebJobs SDK / HangFire / Quartz all have their own versions of a timer trigger. Readability/maintainability is the biggest thing though - throw it together even in pseudocode and see what your code looks like when you keep it together.
been using from preview 1 in production environment. had a few hangs and had to manually make my extension compatible, but no real issues. the (navigation to decompiled sources)[https://docs.microsoft.com/en-us/visualstudio/ide/go-to-and-peek-definition#view-decompiled-source-definitions-instead-of-metadata-c] functionalities is a blast, but you cannot yet insert debug break, when this features will be activate i'll uninstall resharper. 
2019 has better refactoring tools over 2017. Also, I dropped reshaper for speed. VS reacts almost instantly now :)
How does it compare to the framework's `LinkedList&lt;T&gt;`? Is the performance similar? It would be great to add some benchmarks :)
I can assure you that it also affects packages for .net core/standard. In your case, it might just be a coincidence.
&gt;instalable system and all system agents for remote checking in and sending commands etc as well as the web interface I'm currently working as IT admin as wel maybe you have some ideas to improve our system with .net ?
I'm waiting ‚úåÔ∏è
You can have both installed
Reinstalled Windows for a clean start recently and VS2019 Preview was the only version I installed. Only encountered one bug during preview due to launching multiple startup projects, which has been fixed and was easy to work around. I'm normally a ReSharper user but I haven't installed it this time around. Each new version of VS reduces my need for ReSharper. It's still missing a couple of things like initializing DI fields in constructors, but I'll deal with it for now. 
I did the same. ReSharper refactoring is still stronger, but without resharper, things are noticeably faster.
It feels like you're trying to force smooth scrolling
Probably some issue with the template (a purchased one). 
Did the same thing 2 years ago an never looked back.
What are some useful ReSharper navigation tools that VS still lacks?
I'm using preview version 5
I use VS2017 + Resharper for refactoring, code cleanup and unit testing. I use VS2019 without Resharper for getting stuff done.
I ditched Resharper too. The one I still miss is the Resharper "find references" results window. This shows whether each reference is a read or write reference and you can filter by that.
I've been using the preview and installed the release one asap. I'm half tempted to switch out Resharper, but I can't be bothered to figure out if any bits I use frequently are present or missing. 
I use it for C# 8.0. Other than that, the bloody thing still crashes from time to time for me.
https://docs.microsoft.com/en-us/aspnet/core/?view=aspnetcore-2.2 https://github.com/dodyg/practical-aspnetcore And if you have questions, just ask on this reddit.
Have you managed to succeed? I only got this after changing target to 3.0 *Error: The version of the .NET Core SDK currently installed (/usr/local/share/dotnet/sdk/3.0.100-preview3-010431/Sdks) is not supported and continuing to use it may result in a broken tooling experience.* &amp;#x200B; Though VS2019 itself finds the SDK installed in VS Preferences :) Oh well, just have to be patient (or use Win for a bit :D)
On my work computer I wait. But on my own computer for hobby project's, I have installed it and it's working great. Resharper has not been a pat of my tools for a while now. To many performance issues. Specially on large projects. I use Roslynator instead.
Thanks to all of you who answered! 
Oh jeez, having used ReSharper for the past 4 years, there are a lot of features I assumed VS had implemented in 2017 and that it was almost about time to ditch RS for performance gains. But man, are they still playing catch up on some core features. Always good to see base VS improve though.
That's in 2019 too? https://stackoverflow.com/a/53734123
We have team presentation this afternoon, will see afterwards
Already installed it in all of my workstations. Our team has been using the preview version till now. 
https://twitter.com/scottgu/status/1113715562272546816 Scott Guthrie shared on his twitter, what a nice recognition :) It's really a nice content, thanks for the time that you invested on sharing knowledge.
I can live with one-time startup delays but it's how it slows everything else down too that drives me to despair. I get terribly typing lag with resharper that makes me long for the days of MSVS 5 running on a pentium! &amp;#x200B; I am enjoying rider which lets me use linux though.
I did some bench marking with 50,000 random elements. The comparisons were for LinkedArray, LinkedList, List, and ArrayList. You can see the results here: [https://1drv.ms/x/s!At7D0T4Uz1vyiNpl3sgdCIADmRFAcA](https://1drv.ms/x/s!At7D0T4Uz1vyiNpl3sgdCIADmRFAcA) &amp;#x200B;
That's just awesome, thank you!
Installed it today. Uninstalled 2017 and resharper. It‚Äôs noticeably faster. Refactorings are good. Had some issues that it suggested c# 8 refactoring but all up I‚Äôm happy. Search is nice. Searching in your local variables while debugging is great
Been using it since day 0. Apart from the laggy UX due to using Resharper, it's truly an awesome piece of kit. I get around the Resharper issue by suspending it when I'm not using it. I did have to go to IT Admins to get anti-virus exclusions given how new VS2019 is, but all in all, despite the radically different start page, VS2019 is the same as VS2017, just wayyy smoother. Also, Visual Studio code is a pain to get used of (given how it lacks many of VS2017's useful features like debugging), but it's a great addition to the developer's toolbelt for things like frontend design or working on compact units of code.
There's one thing I'm missing from ReSharper is the better formatted intellisense and code de-ordering. 
I installed it on launch day although I didn't plan it. I just happened to see the launch on YouTube and thought why not... I mean, it can live alongside VS 2017 if things go to hell. We have a major C++ project using ancient MFC libs etc, so I just ensured I added these and the VS 2017 toolchain and runtimes as "additional components", so that we can migrate and check any issues when we have time.
I've looked at the implemention a bit and have done some mental static code analysis (haven't benchmarks it). Note, both removing and inserting is not implemented so that cannot be compared. Comparing it to a C# LinkedList wouldn't be the proper comparison. Discontinuous indexing is the focus of this collection. Indexing of any sort is not encouraged for LinkedList. The best comparison would be to a List (circular List if you have negative indexes) or a Dictionary where the key is an int. Get Indexing performance depends on the number of LinkedArray nodes it needs to traverse. A List is equivalent to just having one node. If the index needs to traverse more than one node, you're already slower than a List. Indexing into a Dictionary would be slower than indexing into a LinkedArray until you need to traverse several nodes. Set indexing performance follows the same logic as above except when expansion is needed. For List and Dictionary, expansion requires a new internal array to be allocated and all items in the old array be copied into the new. This LinkedArray doesn't require that. Instead, it just allocates a new array for the higher or lower indexes to be filled in. Memory efficiency is also a mixed bag. The aim of it is to provide a List that allows gaps in a memory efficient layout. While the Lazy array initialization is nice, it is only effective under limited circumstances versus a List because it still has to fully initialize the LinkedArray node that contains the discounted index, and peppering can cause every LinkedArray node to be fully initialized. I don't expect it to actually be reliably more efficient in most real world circumstances than the alternatives. Also, the multiple nodes can result in reduced help from caching. A Dictionary would be most efficient when there are large gaps. There are faster SortedDictionary implementations than what .NET has built in if sorted enumeration is needed. 
Uninstalled 2017, installed 2019 yesterday. Worked noticeable faster. Rebooted my machine today and I've veen looking at the windows 10 loading circle for 4 minutes now. That's "always a good sign". FML. 
You know the ctrl t file search? The resharper one is much snappier. You can also use a shortcut then type a word/sentence and it will find it anywhere in the project and display it in a dropdown, without having to do initiate the search - much faster than the default search where you have to type it then hit enter.
I don't see much reason to wait. Since you can have both versions installed at the same time, if you have any issues with 2019, you can easily switch back to 2017.
What kind of machine so you have to work with this?
It's pentium 7 with 16gb Ram. Even at home, I got 32 gb ram. I installed vs2019 and I got message on vs start up that ReSharper added 10 sec delay 
Well... that's why the performance of Resharper is so low. It is snappy because it does heavy indexing before.
Yep. That ability is in VS 2019. https://channel9.msdn.com/Events/Visual-Studio/Visual-Studio-2019-Launch-Event/Squash-bugs-and-improve-code-quality
ASAP, I'm waiting for my company to sort out the licensing. We might even get the Ultimate edition (sucks that Code Coverage is not included in Professional).
As with others used it since the first RC and I upgraded my machine specifically so I can keep using R# (the latest EAP fixes a few issues). 19 still has a few annoyances (not being able to remove the 'send feedback' button being my big one) but i's a lo faster with big solutions.
I worked with VS2019 all day yesterday without Resharper. I started up this morning with it. And now I'm like, "eww." But yes, I like the quick code ordering and the sugar sprinkled all over. I just wish it was more performant. Also, it came with a new error, along with the banner at the top saying, "Visual Studio stopped responding for 12 years. Disabling the extension JetBrains ReSharper might help."
I‚Äôve used Aspose before on a few projects before. https://docs.aspose.com/display/pdfnet/Feature+List
I installed. A colleague had been using previews without much trouble. I am attempting to ditch resharper finally. So far it is good (with a few keyboard shortcut customizations). Roslinator helps. Things I am missing from resharper are, Move Class, unit test runner but mostly resharper build (VS still builds things unnessarily even despite my best efforts). I think this time though it will be enough to cut the cord with resharper.
I find assigning ctrl-t to the VS 2019 Go to all command is a more than adequate replacement.
ctrl-k ctrl-r is default key stroke in VS 2019
You know you can assign keyboard shortcuts in VS right? For example I assigned Go to all to ctrl-t to mimic resharper behaviour.
This becomes even more important when relying on time based executions of any sort. Your business code to call the API and save data should not have timing code of their own, otherwise they'll become painful to unit test.
I wish ReSharper was perhaps more modular and therefore more light on the system. 
I installed it immediately. I ran into a couple of bugs and reported them. Let's hope they start rolling out fixes soon.
[ABCpdf ](https://www.websupergoo.com/abcpdf-5.aspx) 
You could try side by side installs, I've had 4 different versions of vs installed for a while now with no problems
https://github.com/ArgusMagnus/PDFiumSharp is a .NET wrapper around pdf library used in google chrome. I use it in a combination with ImageSharp to convert pages to png images.
You can try changing the update channel to beta.
&gt;initializing DI fields in constructors 2017 had this? I use it all the time 
Hmm, don't remember that. Not at a computer to check atm. 
This! So much this. There's some bits I love, some bits I don't use however because I'm forced to take an all or nothing approach I've opted for nothing 
I installed 2019, but I am keeping 2017 on my machine for now.
&gt;you can add a constructor parameter and have it generate the field for you yeah, that's what I meant. the opposite would be nice too. 
I can only guess SSRS isn't available yet, and WPF (XAML) will still leak and crash my machine.
So I've ran into this multiple times, and there are several ways to do this: 1. Change your `-OutputDir` to something other than your *existing* `Models` directory, like `ModelsNew` and then migrate the changes across manually, updating the namespaces in the models and adding in any changes to your `DbContext` (including `DbSet` references). 2. Overwrite your `Models` directory, go to your `Error` window and fix any errors, run unit tests against existing API endpoints to ensure they work correctly. 3. Manually update the `DbContext` (and all references) and add in the models to boot, without re-scaffolding to a new directory. In order, here are the scenarios I use to choose which one: 1. If I've added a new table, with a `FK` to an existing one, or made more than 2 changes to an existing table. 2. Never, I'm not suicidal. 3. If I add in a missing column to a table that already exists, and won't require more than 30 seconds of manual input to update the ORM classes.
Same command works. You can also use the force option to ensure it overwrites
I just started messing around with it next week. Already made a decent web app to replace a desktop wpf app I had lying around. Now waiting for .net 3.0 support on azure to publish... it‚Äôs a great tool!
Blazor.net has been great