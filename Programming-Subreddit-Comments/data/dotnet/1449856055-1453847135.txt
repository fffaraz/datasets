Package by random 3 party guy. You properly want the package from the creators of the different projects. Just looking at the download page for react: https://facebook.github.io/react/downloads.html They say how you can download it with NPM and Bower, so I would suggest using them :)
Well, MVC is simply HTTP POST requests no? So there is still a secure "API" between the web browser and application. It isn't like a windows program has direct access to the DB. The only reason I see to have an API is if multiple applications are using it, or you want live data and not require refreshes to get it.
Here's the repo if you're intersted https://github.com/StackExchange/StackExchange.Redis Just started looking at Redis and it's pretty interesting. Got Redis up and running very easily with Vagrant and https://github.com/ServiceStack/redis-windows
Are these projects anti-NuGet or something? Lots of people use NuGet, why not make NuGet packages in addition to NPM and Bower?
https://developer.xamarin.com/guides/cross-platform/game_development/ http://www.gamedev.net/page/resources/_/technical/game-programming/cross-platform-game-development-with-xamarin-and-monogame-r3253 Here are a couple links to get you started on the right path. Forewarning, I have never used Xamarin for game development, so I have no first hand experience. However, it is possible. Edit: also I imagine your experience building apps with Xamarin would definitely be of use, but it will be different.
Yes they prefer to have the service be it's own solution, and have it sit on the 'services' server. They say the main concern is they don't want apps talking directly to the database. I don't know if this is a WPF thing, or what. As for embracing angular, I did a couple but I really don't care for it. I know JS has become very powerful, but I don't like to give it so much responsibility. I prefer to have my models and controllers server side, do all my work there, then shoot it to the view for display, and let JS do some cool stuff for button clicks, etc. I assume this whole 'push the work to the client side" came about to reduce cost when using cloud services. All our servers are internal, no cloud. Is there another reason for it? As for career, I don't plan to make it out of here alive.
The bug is by doing a GET request and providing a non-zero Content-Length, asp.net sits there and waits and eventually a socket timeout exception will occur. My guess is by providing the Content-Length, asp.net is waiting for a request body to be received. However since one isn't provided it just hangs. As I said above, you can see the bug when issuing the curl request above.
I'm running IIS10 on my dev computer and I just tested that curl command on my localhost, I got a timeout! It definitely looks like a bug in IIS or ASP.Net (unsure where exactly in the pipeline this error happens). The process is definitely hanging while waiting for the request body to come in. If you add a body, the error doesn't happen : curl http://httpstat.us/303 -X GET -H "Content-Length: 17" -d "some fake content" I can't find a way to configure filters in IIS that could prevent this from happening. Are you running behind a reverse proxy or a load balancer? Perhaps you could rewrite the requests to drop "Content-Length" headers for all GET requests and that would fix your current problem. You could also report it (but I don't know where to report it) EDIT : I tested the same thing on another website running on my localhost that's an older ASP.Net Web Forms project. This one doesn't timeout when requesting an invalid Content-Length. I can only reproduce the timeout when doing a request against an ASP.Net MVC 5 website. 
Even though a body in a GET request (usually) shouldn't exist, it still seems it's valid (http://stackoverflow.com/a/983458/3189844). Therefore, I'd say it's not strange that the server waits for the body to be sent, since the headers specifically state that the body will have content.
It's an invalid request, yes. It shouldn't cause a timeout. This could \*possibly\* (maybe not) be used to cause an easy DOS on any ASP.Net website (by using up all the threads, waiting on requests with no content). I tested the same invalid request on google, to see what happens. curl http://www.google.com -X GET -H "Content-Length: 30" -v I get a 400 Bad Request instantly. I believe this is the correct behaviour in this case. Unsurprisingly, trying the same request on bing.com gives you a timeout :P At least now we know Microsoft uses its own stack to host Bing! 
I can't speak to Phonegap but I'll comment on Xamarin (Specifically their Xamarin.Forms product). It's a daunting experience that I would hesitate to recommend to anyone. I've been using the software for a little over a year. The stability is the major issue I've had: Xamarin installers now working correctly forcing you to manually configure several sdks packages and environment variables, 9 out of 10 updates will break your current project introducing new bugs or resurfacing old bugs, and like other have mentioned the Visual Studio support leaves a lot to want. Having reviewed other methods of providing cross-platform solutions for mobile apps I suspect that the Xamarin approach is the best. It's aiming to get things down into native code, which is incredibly difficult and commendable. However the actual execution of this task is sub-par. You end up paying a significant amount of money to beta test their products without being able to reliably work with the software (avoiding their updates provides longer stretches of valuable work time). They just released the new Xamarin 4 or 2 or whatever. Very disheartening because people on the forum are already claiming they can't run their apps with the new update. It feels very much like a marketing update but not a developer update. I've had a long day working with it today... on a completely indulgent and sentimental note: the software bums me out more so than anything else I've ever experienced. I rarely feel like I'm making progress while constantly trying got avoid the pitfalls of the xamarin platform. 
Have you read the link I referenced? Roy Fielding (somewhat of an expert I believe) says it's valid. Even though it's very unlikely that it's useful and can likely be ignored, it's still part of the HTTP spec. The fact that Google ignores it is likely because they don't want to use it themselves, but IIS may be used by web applications that do want to use it, so there's more motivation to support it. I'm not sure if this does open a window for a DOS attack, but I'm guessing this will already have been considered (educated guess obviously, so feel free to prove me wrong). Either way, I agree it's quite counter-intuitive, and should be avoided unless you have a very specific use case.
Is that a bug in IIS, though? The client announces that content is coming, so the server waits for content. I'm not sure what the spec says about what should happen to GET bodies.
I'm not sure whether to call it a bug either, but I would think that ideally IIS would wait a certain amount of time and/or return a HTTP 400. As @StevenGilligan mentioned, this could potentially be used as a DOS attack. I think in an ideal world it would be nice to at least have IIS configuration parameters to control this behavior. 
But why? Why do I need an api? Why can't I just add an edmx to my mvc app? As for using angular, I don't care for it.
No, no. No SPA, no angular. Just a regular MVC app, so I'm just going to do regular razor front end, talking to controller, which interacts with EF. No api needed.
But I want to stay with Windows. 
I was a bit sceptical. Thanks for the validation.
No prob. What do you mean by media info?
Looking to find / create some library that will aide in returning artist, length, resolution, other attributes of audio and video media types. In Windows specifically, when looking at details of a file, these details may or may not be listed. I want to know if there is a library built in to .net that already exists to capture this information, say after getting a FileInfo, or casting to some other type. I hope this isn't too vague.
I may be experiencing the same problem. I have an Asp.Net MVC 5 project with WebApi and I'm calling the api functions with angular. Sometimes request fails or responds very slowly on Win10 IIS with Firefox (other browsers work OK). If I run rthe site with IIS Express bundled with Visual Studio 2015 everything seems OK. So maybe Firefox sends 'wrong' get requests? Right now I know of the problem and I'm ignoring it, because the production server is Win Server 2012 and it seems like it's working there. TL;DR; IIS 10 hangs and Firefox sends this kind of GET requests, other servers are probably fine, also other browsers are probably fine too 
Sorry about the link, I just can't get them to work right on my phone, but this should be helpful. https://msdn.microsoft.com/en-us/library/windows/desktop/ff384862(v=vs.85).aspx
That's not what webapi is for. And mvc isn't for posting http only. Lots of stuff to explain my points, but I'm on mobile atm. Best advice I can give is to read up more on mvc and webapi, and do some more tutorials. It should be stated that webapi and mvc are merging in the next version of mvc.
Ah yes, very helpful! Thanks
Does that HTTP library do the same thing if it encounters a 302 as it is doing with the 303? 
Could you try a different redirect type like 301 or 302? If the root problem is with Android and 303, can you see if android doesn't change your request type with different redirect types? 
That's a good one. I wrote a library for that and then discovered Google already did it. A search for c#image meta data library should find it. It was a great learning exercise for me though and would recommend it.
I can't say why they don't want to package for NuGet, but my guess would be that since all other frontend package are on the other platforms. The people who use the package are properly not .NET people so it has to work on a Mac, and NuGet don't (I think) 
If you are only backend or WPF/WinForms, these tools aren't for you.
Two tips: 1. Set a maximum memory limit, or Redis will happily take up all memory on the system. During writes, it will double its (real) memory usage to take a snapshot, so keep that in mind when choosing a max. 2. By default there is no security turned on, and you can absolutely take over a whole system through an unsecured Redis instance. I disagree with the authors fundamentally on this, but they claim its "easier" for developers this way. You will want to set a global password (Really?!) and limit connections at the firewall to only those things that need to talk to it. Even better, don't expose it at all, as the security story is a joke.
Thanks for the tips :) 
I pretty much use Newtonsoft's JSON library for anything JSON these days. Might check it out http://www.newtonsoft.com/json
It does the same thing for HTTP 300, 301, 303, and 307. Here's a link to the [code](https://android.googlesource.com/platform/libcore/+/jb-mr2-release/luni/src/main/java/libcore/net/http/HttpURLConnectionImpl.java) ln 319.
I agree that this is a problem with the library; however, it is the default and preferred library for all devices pre-kitkat (which is a large number of devices). Also, there is no way to add a listener on re-direct events to remove the Content-Length. So unless we switched to a new http library (which we can't at the moment) the Android dev's hands are tied. So that is why I seeing if there is a IIS/asp.net workaround.
First off....you should shame your teacher for teaching you webforms. Now that that's out of the way. the sqldatasource is capable of creating the connection. In fact, that's one of the purposes of it. It contains all the connection info, opens and closes the connection and manages binding. You shouldn't have to use code behind for any of that. You can pick the table and columns you need. [like this](http://www.codeproject.com/Tips/604815/Using-the-ASP-NET-SQLDATASOURCE) Also, you should look into using a repeater for the thumbnails, you can bind it directly to the sqldatasource and pull whatever data you need from the columns. The benefit of a repeater is that you're essentially creating a template that will be repeated for each returned row. Because the repeater doesn't have a set template, you can use whatever you want and have whatever flow you want. [Here's an example of a repeater with sqldatasource](http://www.beansoftware.com/ASP.NET-Tutorials/Repeater-Control.aspx)
Thank you so much for your help! Now I have questions about the repeater: From what I gather, I bind the repeater to the sqldatasource, construct a template with whatever markup I please, and it loops through each row returned by my query. Once it reaches the point in my image source that needs to change each loop, I can use this inline code to insert the current row?: &lt;%#DataBinder.Eval(Container.DataItem, "BOOK_CODE")%&gt; Also, what's wrong with webforms?
I think the main purpose is to have an easy to use distributed cache for extremely performance critical data. It's pretty cool. But I scratch my head wondering what I should actually use it for, in actual work. Normal caching on Web servers for example works just fine. Maybe if you have a database query that must be reused in many settings simultaneously that doesn't change its data much? 
It worked perfectly. Oh cool, not only am I learning .NET 4.0, but I'm also wasting hours and hours of my time on a dead framework. Please tell me there's something out there that is genuinely HTML5 compliant and doesn't automatically style elements.
oh im so sorry.. updated my post
TypeScript makes JS bearable. I've heard that Aurelia seems very promising, as it's by one of the authors of Angular who disagreed with the course Angular 2.0 was taken. So it might be worth investigating Aurelia.
You want Unity, not Xamarin. Unity is free for indie devs, and there is lots of tutorials etc on their website, and plenty of books out there too. Good luck!
&gt; wwwroot is locked down - you may need to run gulp as administrator to be able to write to wwwroot. Uhm.. No. Why would that be the case? It's definitely not "locked down".
I see your point... We just would like to collect events/initiatives where women can feel comfortable to share experience with others (men and women). 
Yes, [yes it is.](http://i.imgur.com/sRryUUd.png) Notice the blue/yellow admin shield when trying to write to the folder. Normal users [do not have write access to inetpub/wwwroot](https://support.microsoft.com/en-us/kb/981949). 
I am using Visual Studio! I add them, and they don't build half of the time because I don't have the right version of Typescript on my computer. I have the most recent version installed, and right now if I create a new MVC project, add Typescript and add AngularJS' definitely typed library, it doesn't build. Edit: [Screenshot](http://i.imgur.com/bbWcERQ.png)
If you feel like you're wasting your time working with asp.net, spend 10 minutes checking up on razor, which is used for dynamic html in asp.net mvc apps. You have exactly the control you need, and if you have experience with c# it instantly makes sense.
Glad it worked. While webforms is a lost cause, you're good with learning .net 4.0 All the versions of .net build off of each other, and the core framework works with any flavor of asp.net. Whether it's webforms, mvc, webapi, etc. That knowledge you can definitely bring with you. As others have mentioned. You can look into MVC. What's hot right now is service oriented architecture. Which is what I use at work, using web api and angular.
That's pretty surprising. You would think that anything that Anders Hejlsberg is involved with would be awesome, because, well, it's Anders Hejlsberg!!
I think you should try and set up your project in something slicker, like VS Code and handle the build/transpile of TypeScript files manually (with for ex gulp). In that SS it looks like your trying to build the d.ts files, they are there for referencing and should not even be in the scripts folder, cause they shouldn't be served to a browser. TypeScript is bliss in large JS projects, when you get it working :)
Nps, just glad if any one can get a better TypeScript dev experience going :) There's actually a post about setting up VS Code, MVC 6 and TypeScript at the same site that this post above is from. It's written in Aug when ASP.NET 5 was in beta6 so a little dated, but it's comprehensive and will make setting stuff up quite easy.
Here is something from the Windows 10 Github samples. If you don't mind digging through their file structure you'll see the answers to your questions here. The short version is you need to use the HttpClient class. This won't give you step by step, but a group of you should be able to figure it out from here, good luck! https://github.com/Microsoft/Windows-universal-samples/tree/master/Samples/HttpClient
When I was trying authentication, I aimed to use oAuth. You log in and get a token from the web service and use that in your web requests to authenticate the user. Which I'm guessing does not fit your current authentication schema.
I am not disputing what you are saying. Or trying to make a new definition. I think it's more of a practical standpoint. Sure I have a license to make a production product, but if the code base keeps changing I'm not going spend the time or resources until I know it stops (to a point). Typically, again maybe not the definition of RTM, most people would agree if a product is RTM its development cycle for major code changes have slowed down to the point they might make the investment in the new version. For sure this is a layman's view and not a Wikipedia editorial view.
oops. CRUD 
Create, Read, Update, Sayonara
No, by far not.
Yup, I did the same. That tutorial is pretty good.
So you can't use C# unless you get the paid version?
That seems pretty tight.. I was thinking get a 32 inch and learn the keyboard shortcuts to have browser on one side and code on the other.. though if I can keyboard shortcut my way around really well it could be like many monitors.. what I mean is in the end what is the difference between turning your head to look at another screen vs. alt-tab back and forth? 
so you turn your head left and right but never look in the middle ? 
I work from home, and was never happy with Synergy's performance, especially when my network is being kind of shitty, so I ended up buying (and deducting from my taxes) a nice two display KVM to get native mouse/kb performance on both computers. And I guess I overstated the "goofiness" its just a couple key/button presses. The "goofiness" is the fact that I use several items (mouse, headset) on the shared usb port so when I switch I have to wait 2-3 seconds for them to be recognized on the other computer. 
I generally rock 2 screens, Visual Studio on one ~~Stack Overflow~~ documentation, trello, Spotify, putty and team communication on the other.
&gt; I have a USB keyboard/mouse sharing hardware switch... Yup, that's what I meant by KVM. &gt; however I don't like the delay after pressing the button Yup. That's exactly what I'm talking about too. But it's the best solution for me because it lets me use two displays for work or three displays for play.
When you create a ASP.NET 5 web application, select Web API checkbox and inspect the defautl ValueController. That is your CRUD template. Oh wait, UWP. Search for CRUD Entity Framework repository and you will find what you need. Include SQLite for bonus points.
[newforms](https://github.com/insin/newforms) with webpack. Look at the ReactJS.NET Sample.Webpack demo for more details on using webpack with MVC.
I have two Acer 27" WQHD (2560x1440) displays daisy chained with DisplayPort. Works beautifully with both my Mac and Lenovo laptops. At 27" and bigger, 1920x1080 is just a ridiculously low resolution (Rant: why are so many "computer monitors" pinned to 1080p? I don't want a TV). Normally priced around $400, try and wait for a deal. I got them for $300 each. When using just a single display, virtual desktops are key. OSX does this great. I haven't tried Windows 10 yet. *Edit: typo
I have switched to [Samsung 34" 21:9](http://www.amazon.com/Samsung-34-Inch-LED-Lit-Monitor-S34E790C/dp/B00Q7VCSGU/ref=sr_1_1?ie=UTF8&amp;qid=1450180474&amp;sr=8-1&amp;keywords=S34E790C) monitor recently and let me tell you - it's worth every penny. It feels much more productive than having multiple smaller displays. I've tried double 27", but I couldn't use them effectively, basically I worked on one and used the other for media player and other stuff you don't actually need to see and could as well be on other virtual desktop or minified.
Does being curved make that big of a difference?
There a specific uwp crud app?
No, being curved is just something that's more "cool" than useful on this size, but 21:9 ratio is the important part - my old 27" 16:9 screen feels like an old crt in comparison.
Your head is moving left to right alot on that single monitor?
A bit, but it doesn't feel unnatural, it's very slight movement which is much less than what it was with two screen setup. I recommend finding a store where they've got something similar on display and play with it for a bit, I think you'll be impressed. 
I'm wondering if 4k is important .. At first it was a must but if I am not doing video/gfx work maybe it is a waste of money
I think that comes purely to personal preference and whether you've got the hardware and software to support it. For instance I believe MacOS is pretty well prepared for 4k, but windows are still having issues with bigger resolutions - since I have to work with both OS, I went with non 4k monitor. I think there are also 4k 21:9 monitors already, but it's one of those things you have to see for yourself first.
I went to a 34" ultra wide and it is so much nicer than the multi setup I had previously. I added a mount to line up my laptop with it, I don't know if I could go back. http://i.imgur.com/mChplzX.png
For me, having two monitors and begin able to see the code and the results of the code at the same time improved my productivity enormously. (I do c# web development). I can also pull up 2 (or 3 or 4) code pages and look at them all at once. It really does make a difference.
I would be careful suggesting that Auditing should be implemented by the web application. I'd much rather place that in control of the database transaction layer, which in your case sounds like it would be Entity Framework. This is a much more flexible and secure approach. You can override the SaveChanges method in your custom DbContext. Combine that with interfaces and reflection in C# and you have a fairly easy way of tracking changes to your desired models. Take a look at [this StackOverflow answer](http://stackoverflow.com/a/26357308/2323423) and I have also seen some good concepts and practices in [ASP.NET Boilerplace](http://aspnetboilerplate.com/) See: * [aspnetboilerplate - Audit Logging](http://aspnetboilerplate.com/Pages/Documents/Audit-Logging) * [aspnetboilerplate - Entities](http://aspnetboilerplate.com/Pages/Documents/Entities) * [aspnetboilerplate - AbpDbContext.cs](https://github.com/aspnetboilerplate/aspnetboilerplate/blob/master/src/Abp.EntityFramework/EntityFramework/AbpDbContext.cs#L162) Hope that helps.
Bingo - database layer makes perfect sense. Thanks very much for the links!
I brought in my 32inch HP Envy. I can use shortcuts for move windows left/right but is seems if I can master the alt-tab ctrl-tab win-number key I will be better off
I use that library at work all the time. At the time I was doing research into which library to use (about 2 years ago), that seemed to be the clear winner, and I don't know of one better at the moment. Yes the website looks sketchy, but that is the correct website for that library. There is a .NET wrapper that works pretty well too.
There is a way to share you re# settings, but the implementation is barely working and I wouldn't recommend using it.
Hmm i was excited:/
Ive seen the things like a Scaffold that creates the CRUD controller. I mean a more full featured app.. Like the MVC Music store is a complete app 
This looks very interesting. I'll have to run some tests but it looks very promising. Thanks!
 Agreed, while technically sound information broken/wrong wording can take away from the article. Keep up the work though.
AWS and google cloud have been working with Java since they were released and using Java with them is cheaper and has better integration than .NET. Azure maybe not, but I expect it is more expensive? Fair point re libraries, .NET has some extremely high quality libraries such as those that MS produces. It's more when you are not using MS produced libraries, such as integrating with some 3rd party db or whatever that the Java library is likely to be better developed. Java 8 greatly closes the gap between Java and C#. I don't think the language itself is a great competitive advantage anymore. C# is mostly more succinct and not particularly more powerful.
This is the correct answer.
Are you hosting the site in IIS locally or in the VS web server? If you are not in IIS you might want to try that.
Contact a recruiter. And then be prepared to spend an enormous amount of time vetting people.
What is the goal of having an in house employee vs a freelancer or contractor?
Get a monitor mount, that way you can have the space and the monitors. I have one now that holds my 3 about 6 in above my desk, pretty slick.
That is a good idea. I never used before. do all monitors support them ? 
You can absolutely use Code First with an existing database. Create a DbContext class with a simplified model from one of your tables. The model will need the primary key to work. The DbContext's database initializer should be set to null to prevent EF from attempting to create your database. Launch your application, you can query that table now. Takes about 15 minutes to get a basic proof-of-concept going. Code First is a bit of a misnomer.
Also, where are you located? We can recommend recruiters to find an employee for you. But it's best if we know the general area so we can recommend local ones. I have a couple in mind, but they're only in Texas.
If you're using Visual Studio you can create a code first model from an existing database. Add &gt; New Item &gt; Data &gt; ADO.Net Entity Data Model &gt; Code First From Database
Your company should really take the time to understand what it means to do in house development before taking this step. Managing an in house software development project can be very expensive and time consuming. It's not as simple as hiring a developer and saying, "Go write some code." [This article](http://www.accella.net/advice/should-i-develop-in-house-or-outsource/) should give you an idea of the pros and cons involved with in-house development.
I agree. Don't do it. I've been working on a project that uses code first and it's just been a pain in the ass the whole time.
Makes pragmatic hexagonal architecture/ DDD/ version control/ SOLID much much more natural to adhere to. You get mapping classes that explicitly tell you how each of your entities are related in code. You can avoid anemic models and achieve fantastic behavior and encapsulation with your core models if you are so inclined
I don't even want to go over it. I won't use EF7 if I can't do DB first. I'll just use a different ORM. I don't want my data access code changing my data store. I don't even understand why anyone would prefer that way of doing things. It really doesn't make sense.
You would have it easier to make the code changes and let it generate the script, but if that's not an option you may have to add a property or change a map file rarely. However no one will hate you when you commit a bunch of db changes and don't wreck the edmx. http://stackoverflow.com/questions/6618587/entity-framework-code-first-how-to-manually-update-the-database This post may give you more info, however you never have to use any type of code based migration or anything other than "well I added an int to the table so now I need to add that int to my class." I personally treat the database is the second class citizen and the working software as Priority one. Luckily there are tons of ways to go about this so I completely understand your position. 
That sounds like an awful way to use a simple js library. Does it work if you run without debugging?
It works fine on the live site, just not when I build and run it through VS
Ironic seeing this here. I just got done reducing my setup to 1 monitor after about 2 years with a dual setup. I plan on upgrading the size of the monitor to a 32", and maybe a laptop stand in addition. My reasons were mainly due to avoid distracting myself and I'm just trying to down-size on stuff in general. But, I never used the other screen much for productivity purposes anyhow other than watching pluralsight lessons on one monitor, which I can easily replicate using my tablet or laptop.
It's certainly interesting, I was watching a tutorial on plural sight on how to make applications more scalable and the addition of asynchronous seemed to massively improve the throughput of the website on account of all the io blocks on the limited IIS threads. We're talking a factor of about 10x On my production web servers I'm not sure I'd see the benefit as I've mostly got low thread queues and high cpu usage. That said the theory of its usage is sound.
If you haven't set it yourself and just press run you'll be using the VS web server. I know it had (or has) some problems with handlers and things like that. The easiest way to be sure is looking at the url. if it has a port number (eg localhost:5488 or something like that) you're most likely running the VS web server IIS is part of windows and can be installed via windows components: http://www.iis.net/learn/install/installing-iis-7/installing-iis-on-windows-vista-and-windows-7
&gt; This is probably the single best piece of writing I've seen related to ASPNET5. Wow. You're too kind. I was just putting out my learning :) &gt; And awesome. Anyone actually using ASPNET5 on Linux would run into this. I would have hit it... Saturday, maybe sometime mid-next week.... whenever I get there. Yup. That's exactly what happened to me too. &gt; The RC1 label scares me, as it's not like the stuff you were doing was crazy complicated. And that was just mostly contained within Kestrel. ASPNET5 and CoreCLR has a lot more complexity than just that....... You're spot on. RC1 CoreFX also had an issue which rendered it unusable with Postgres DBs via CoreCLR. I've written about that too over [here](http://www.shrayas.com/asp-net-5-npgsql-linux-mono-4-2.html). On the bright side however, things seem to be converging. Thats a good sign :) 
No it has not! EDMX files are gone, DB first is not! [ASP.NET 5 Application to Existing Database (Database First)](http://docs.efproject.net/en/latest/getting-started/aspnet5/existing-db.html)
Good thing it ain't gone then. [ASP.NET 5 Application to Existing Database (Database First)](http://docs.efproject.net/en/latest/getting-started/aspnet5/existing-db.html)
True, they are for frontend development, like stated.
Do you need to have your own comments section? Why not use something like Disqus?
Get your ducks in a row first. Is your workflow documented? Probably not. Is the future work documented and thought out with respect to the current workflow? Probably not. Before you pick up a developer, hire a BA to document your use cases, workflow, and future changes. This will make the developers life 100% easier, will provide the basis for test cases with whatever QA team you have, will be a framework for discussion around future updates, and will be a framework for more detailed documentation (like application architecture or api).
https://www.jetbrains.com/dotcover/ JetBrains just updated their licensing terms this year, I believe you can get their entire suite for relatively cheap these days (and ReSharper is a god send for developers IMHO). That said, dotCover, one of the products in the tool suite, will do exactly what you want it to do, and is what we use internally. You may want to check out dotTrace as well. Its also compatible with pretty much any unit testing framework: &gt;Execute and debug unit tests and run coverage analysis of unit tests in Visual Studio or using the command-line utility. dotCover supports many unit testing frameworks including MSTest, NUnit, xUnit, and MSpec. 
My idea is just have a separate computer to the side for unrelated things like that and chat.. though sometimes I need to cut and paste something from the other computer.. I enjoy the look of one big monitor.. I spent some time reviewing shortcuts for Win10/Edge/VS
Sure about that? Considering all the costs of an employee? Benefits, taxes, office space, equipment, management overhead, holidays, lower productivity, etc?
Oh, forgot to mention the recruiting costs which are relevant right now. Plus the risk that you hire someone shitty (90+% of devs) and you'll have crap that you'll have to rebuild in 6 months. 
Yes for certain workloads, especially asp.net iis hosted, async await can substantially increase throughput. Throughput is not faster. That's one of the most interesting things about scale. Increasing throughput usually involves slowing things down as counter intutive as that is. Throttling is another technique that can substantial increase throughput even though you are intentionally making some requests wait. Async await tends to work great with asp.net because the common workload is http request -&gt; database call. Since the entire duration of the call is spent waiting for IO using async allows you to leave many many more threads for iis to receive requests, to avoid having iis threads sitting there doing nothing. The async calls allow it to use io threads to wait which are separate.
What I means is, *Debug* &gt; *Start Without Debugging* or CTRL + F5.
If you have the Enterprise version of Visual Studio 2015, it's built in. I forget which "offerings" for previous versions of Visual Studio that had it in. But if you have it, just go to Test-&gt;Analyze Code Coverage. Also, you may be interested in the following items if you're looking for issues with your code base: The Analyze menu in Visual Studio has the "Run Code Analysis" option as well as "Analyze Solution for Code Clones". Also if you go to a class, you can right click on it and there is an option for "Create IntelliTest". Assuming you use asserts, etc. it will generate a suite of tests that it thinks might be problem areas for you. If you don't use Code Contracts, or asserts, or anything like that it will be less useful. You may also be interested in the extension "Refactoring Essentials for Visual Studio". Has the potential for helping you find a number of potential issues with your code and gives you easy fixes for them.
I love these kinds of posts.
Thank you :) Appreciate it.
I was going to post that I wouldn't touch this job for less than $200K and you already posted it. I would add, I would want an additional $30K budget to pay for various tools and build infrastructure.
Sharp Develop? If that's still a thing...
Good point. That sort of audit could help in diagnosis of issues. Maybe more suitable for a file log , though, since it doesn't need storing permanently.
There's always [MonoDevelop](http://www.monodevelop.com/) I've not had a chance to try it; but, it is an open source, cross platform .Net development IDE.
Why don't you just fix your computer (or pay someone to) so that you can maintain consistency? It is likely going to be more difficult for you to switch back and forth between dev environments while trying to learn the language.
Worth noting the dotnet team in their github corefx repo, uses OpenCover too. It works specially well if your tests are Xunit.
This is done using code first.
Depends what the product is. If it's for internal use, then you'd want to integrate with existing IT support, as a first level. Whatever tools they are using for documentation access: make sure your stuff is in it. They should have their existing help ticket system, if not, you gotta build that infrastructure, too. If there is no internal IT help, put together that team. Depending on the specifics of that, you would start adding some front level QA people to your development team. These people would be assigned issues out of the IT support queue and determine how they apply to the actual code base. They might be able to answer them, or they might generate new user stories, issues or various other development priorities. Those hit your devops stuff, eventually somebody figures out the answer, or the new feature hits a release, and the resulting issue chain gets closed. If it's for external use, you start building a customer support infrastructure for it. Call center. Techs on the phones. A ticketing system. The rest after that remains about the same. I tend to do whatever needs to be done. If somebody wants me to build an IT infrastructure, I do that. If there are existing resources, I figure out how to integrate into them. The last place I worked for was a 25 person company who had nothing. I built their product from the ground up. Built their IT infrastructure: AD, desktop deployment, all of it. Exchange, SQL, System Center. Racked servers. Built a server closet. Picked AC units. Built switches and network infrastructure. Phone system. Even pulled network cables when we were expanding offices. Then started to hire additional programmers and IT resources. Built a ticketing system. Then developed their product. Then we sold the business, and I made sure to get a healthy portion of that.
Interesting. I have to say I've found writing .NET for Linux a bit frustrating, anyone jumping in expecting it to be a smooth as their Windows experience is in for a surprise. I can get by without a full powered IDE like Visual Studio but the lack of a decent debugger has been the biggest pain. Xamarin Studio doesn't really cut it - it's okay but the debugger is patchy and you can't evaluate runtime variables or navigate the object hierarchy the way you can with VS (I assumed because Xamarin are a big company their IDE would be much better but it seems they're focus is making Visual Studio users happy). Despite the hype and some great engineering efforts developing on POSIX with .NET still has a way to go and Linux is still the second class citizen in .NET land.
If you build through tfs then you can get a code coverage report when building. You need to install vs on the build server so it does cost a license.
oooo, your extensions are quite extensive. I wonder how compatible that is with my dnx 5.0 project - I haven't tried crossing anything between .net versions yet. re: the AddRange, I was trying some stuff with adding lists where the type is unknown. See these tests: https://github.com/NullVoxPopuli/csharp-extensions/blob/master/tests/Extensions/IEnumerableExtensions/AddRange.cs 
It looks like you're letting EF build your database for you. I think all you're missing is that like the navigation property Movie is marked virtual, so to must the navigation property Comments. public virtual ICollection&lt;Comment&gt; Comments {get; set;}
Agreed. I wonder why the author didn't use the official aspnet 1.0.0-rc1-final image (https://github.com/aspnet/aspnet-docker/blob/master/1.0.0-rc1-final-coreclr/Dockerfile) rather than building his own?
Yeah it's not flawless but it is a real and nuanced framework. http://blog.oneunicorn.com/2014/02/15/ef-6-1-creating-indexes-with-indexattribute/ Shows how you can define indexes using attributes. Personally the only real reason to avoid this is if you're not trying to have a dependency on EF in your core application (kind of recommend this but I also prefer to just handle the database using linqpad/ its API/ studio if I'm doing SQL)
I wish it didn't have so many bugs on Windows though. Tried to use it a couple of times on windows 10 but every time got some error somewhere
Thanks for you reply. I'm in a similar job and we support all our products ourselves by utilizing client's HelpDesk ticket system and it's becoming a mess. By a mess I mean there's a lot of products piled up and we're losing time on that instead of putting time in to new development. I guess we should rethink our post golive support and you gave me a few clues on how to approach this.
&gt; **Using Visual Studio on the Build Server** &gt; &gt; If you have one or more licensed users of Visual Studio Enterprise with MSDN, Visual Studio Professional with MSDN, or &gt; any Visual Studio cloud subscription then you may also install the Visual Studio software as part of Team Foundation &gt; Server 2015 Build Services. This way, you do not need to purchase a Visual Studio license to cover the running of Visual &gt; Studio on the build server for each person whose actions initiate a build
You need to specifz a logger in your Startup.cs. the default is IMHO the consolelogger. If you start with the command *web* instead of IISExpress, you should see the output in the Console
Thanks I will look into that.
Set your target framework to 2.0. 4.5 apps will be able to use it.
That is the case. I can get a specific value (or set of values) using **var section = Configuration.GetSubKey("DataAccess:DefaultConnection")**. That gives me a dictionary-like object that I can get specific values from like this **section["DatabaseType"]**, not including nested children. I think maybe my question wasn't clear - I'm trying to use the automatic mapping to strongly typed options objects. The only way I can get that to work right now is if everything is top level in the config files - e.g. { "DefaultConnection": { "DatabaseType": "MsSqlServer", "ConnectionString": "Connection string here" }, "GooglApiSetting1": "some setting value" } That's not ideal in the case I have two config options for separate parts of code that share the same key. I could prefix all the option names with a namespace separator, but that's uglier than I'd hope. Thanks though!
Your could create a nuget package and compile your app for every .net version you want to target
Now, keep in mind, this would be an exercise in making a nuget package. There are simpler methods to solve the exact problem you have. Two (well, 3, but the other one's too hard) ways to create a nuget package: * https://docs.nuget.org/create/creating-and-publishing-a-package * https://docs.nuget.org/create/using-a-gui-to-build-packages
So I figured it out: private string postXMLData(string destinationUrl, string requestXml) { HttpWebRequest request = (HttpWebRequest)WebRequest.Create(destinationUrl); byte[] bytes; bytes = System.Text.Encoding.UTF8.GetBytes(HttpUtility.UrlPathEncode("cXML-urlencoded=" + requestXml)); request.ContentType = "application/x-www-form-urlencoded; charset=ISO-8859-1"; request.ContentLength = bytes.Length; request.Method = "POST"; Stream requestStream = request.GetRequestStream(); requestStream.Write(bytes, 0, bytes.Length); requestStream.Close(); HttpWebResponse response; response = (HttpWebResponse)request.GetResponse(); if (response.StatusCode == HttpStatusCode.OK) { Stream responseStream = response.GetResponseStream(); string responseStr = new StreamReader(responseStream).ReadToEnd(); return responseStr; } return null; } the important part: bytes = System.Text.Encoding.UTF8.GetBytes(HttpUtility.UrlPathEncode("cXML-urlencoded=" + requestXml)); request.ContentType = "application/x-www-form-urlencoded; charset=ISO-8859-1"; 
g.Key will the the LOCK_STATUS. g is also enumerable, so g.First() would be the first item in the group etc.
You can make the .Net 2.0 application run in a higher runtime with a change to the exe.config (assuming it's forwards compatible and you're not running on an unpatched XP machine). Based on [this](https://en.wikipedia.org/wiki/.NET_Framework#Versions), Windows 7 comes with .Net 3.5 by default so I would aim for *at least* supporting that version. Also of note is that .Net 2.0 is no longer supported by Microsoft. BUT as others have mentioned, you can simply target 2.0 and it will work as a reference to a 4.6 project, although you won't have any new features available (including LINQ!)
Can't you just migrate the .NET 2.0 application to at least .NET 3.5? You're going to miss out *a lot* if you don't target a more recent framework. it might be much more painful in the long run to stick to an outdated, unsupported framework rather than migrating a single application.
I maintain and further develop a website made with asp.net and I agree, dotnet is great but I can't agree on moving over to Windows. I run windows on my Mac through virtualbox, not the best but all I need. 
Conceptually, what is a group (in SQL)? It's a dictionary where the key is "what" you grouped on and the value is the list of elements within the group. TBH this throws me for a loop sometimes too, but in LINQ `g.Key` is the key (what was grouped on, LOCK_STATUS) and `g`, *the object itself*, is the list of values, an IEnumerable.
If you do go through a recruiter please do not trust them to vet your candidates for technical proficiency. Recruiters only try to match up the skills you're looking for with what is shown on a candidate's resume. In general they also try to find people that ask for the lowest rates so they can take the highest cut. They do not know anything about software development or what makes a good developer. When I "interview" with a recruiter it's more about sensing how well I would do in an interview, not about my knowledge. That makes sense as they have no development background themselves. If you don't have anyone that is technical, perhaps you can vet them based on the work they have done. You should only be looking for developers that have created a project themselves and can show you the end working result. This way you can see if what they have built matches up with what you are expecting in terms of a projects output. If a developer hasn't built anything they can demonstrate then it would be tough to know if they have the skills you require. Overall though, as mentioned by other people here, you might not want to move development in-house. It's more than just hiring one developer. It's also about setting up the infrastructure, tools, and development practices. That one developer you hire would need to be more than someone that just writes code ,and you might need more than one developer depending on your requirements. You might also need a project manager, business analysts, testers etc. You're taking on a lot more responsibility than you might think. With a 3rd party company you can set specific contract terms and if they don't meet those terms then you can set penalties. If you do it in-house and your developers don't meet the deadlines you take on that cost.
Exactly what SeitzDev said - you need to plug in logging providers. Out of the box you can hook up the Debug window, Console, as well as Serilog, or ELMAH.IO. I talked about how to hook up log4net to write to a log file here: http://dotnetliberty.com/index.php/2015/11/09/asp-net-5-logging-with-log4net/, which might be the most familiar to people like me who's used to using log4net in previous projects.
I think it's a great idea to take a look at the .NET stack nowadays, especially since the new .NET core is cross platform (Windows/Linux/Mac), plus the new slimmed down editor VS Code is also cross platform. You might want to look at signing up for the free Visual Studio dev essentials: https://www.visualstudio.com/en-us/products/visual-studio-dev-essentials-vs.aspx This has resources for setting up the new .NET core on your system, plus gives you 6 months FREE access to Pluralsight - thats a $180 value. There's a course on there by Shawn Wildermuth about ASP.NET 5 (the new cross platform web stack) which is pretty decent.
You're using the group clause: https://msdn.microsoft.com/en-us/library/bb384063.aspx This says it returns `IGrouping&lt;TKey, TElement&gt;`: https://msdn.microsoft.com/en-us/library/bb344977.aspx This says it provides a `Key` property and it inherits from `IEnumerable&lt;TElement&gt;`. The page on the group clause even has multiple examples, including what you want. You just need to read it.
Yea currently i have planned this approach. Was curious to know if there was a better way, hence the question ðŸ˜Š 
I think it also sounds reasonable that we should be able to tell the server to *not* be permissive, but we were hoping for a bit more than that. IIS allows you to strip out or blacklist headers on the response; we were hoping to find the same feature for requests, which I also find to be a reasonable expectation. :/
Agreed.
Hey buddy, Looks like you forgot to hit publish on the post and shared the preview link instead. Might want to publish and resubmit the correct link, I'd like to give it a read :)
Thanks for the link and advice.
&gt;whats the point of this post? To share an experience and first impression. Mostly first impression. Sorry if that offends. &gt;&gt;I'm loathed to say it but I'm impressed &gt;why are you loathed to say it? Because I'm really not a Microsoft fan. I've actively avoided their products for a while now. Whilst I don't consider myself a fanboi of any platform or vendor, I've really disliked how Microsoft has behaved in the past more than most companies.
Oddly enough, I'm thinking of having MacOS in a virtual machine and installing Windows as the main OS. Given it's a physical Apple machine I'm installing onto, I think it's one of the few times Apple "allows" it. I only need xcode on the Mac side. Everything else I do has Windows equivalent tools.
I wouldn't go that low. I'd stop at version 3.5.
I believe 3.5 is receiving LTS which is another plus
Is there much to migrate? Wouldn't a recompile bring it up to 4.5?
Some nice updates, I actually was looking for a multiple search capability the other day. Been using this exclusively now, and we rely heavily on tail for our log monitoring. it's really nice app. Thanks
Hi friend, Thanks, sry for that.. I had re-submitted the post http://dotnet-helpers.com/2013/06/18/difference-between-html-renderpartial-vs-html-partial-and-html-renderaction-vs-html-action-in-mvc/
Repost: https://www.reddit.com/r/dotnet/comments/3x6myc/difference_between_htmlrenderpartial_vs/
I am very pleased to hear you are already a Tail Blazer user and even more delighted that the updates fulfil further needs. The next release should have custom highlighting so that's something else to look forward to
And for the most part you should avoid all of them them unless you really know what you're doing
Great suggestions, some of which are new and some of which are on their way. The others I will make note of
I get why avoid the others, but why would you avoid `RenderPartial`?
IIRC, the Partial methods take a view name and a model, and will render the view according to that model. The Action methods first pass via the controller. It's expected that that controller method will be responsible for calling the needed (partial) View and pass its model to it. So the question is, do you need to pass via the Controller? If yes, use Action. If no (meaning you already have your model), use Partial. **edit** Apologies, I thought the question was about the Action/Patrial differences, I misread.
Hi, yes, u are correct. But main purpose of using Action Partial is to load Dynamic content. It will render/redirect to different view. EG : @Html.Partial(â€œ_testpartialNameâ€, model) Render Partial is used to render static content to the partial view. That calling(_testpartialName) partial will be render in the calling view.
Apologies, I thought your question was about the Action/Patrial differences, I misread.
Thanks for this! I needed the in-place searching two days ago.
Seems to be about "when to use" rather than any details about the differences.
It's usually pretty indicative of violating the SRP and that you're getting to a "god object" page. It's not that they should never be used it's that they're usually more of a crutch. Many usages of them would be better suited to using focused layout pages if the purpose of them is for "DRY" Acceptable uses are highly resuable widgets like calendar / graph widgets that take in their model and construct dynamic output as opposed to something like LoginWidget which really should be contained by a layout.
&gt; Webpack this should not have any downvotes.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/csharp] [LogWizard - a Log Viewer that is easy and fun to use (x-post from dotnet)](https://np.reddit.com/r/csharp/comments/3xdgyq/logwizard_a_log_viewer_that_is_easy_and_fun_to/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
Woah. Nope. I can't deal with the "What's up" main menu that expands out to become more levels of menus. I can't deal with everything being a hotkey, hidden, disabled, etc. There's not enough common ground for me to pick this up and run with it. That user interface needs a fresh coat of good level design. http://www.1up.com/features/learning-level-design-mario 
Thanks for the feedback! 1. I've edited the post to show that I've written about it on codeproject. 2. You're probably right about the UI: - the "What's up" will be renamed as "Action" - the thing about the UI is that it has had gradual changes that brought it up to here. It may be a bit daunting for someone using it for the first time, hopefully the first article on [codeproject](http://www.codeproject.com/Articles/1023815/LogWizard-a-Log-Viewer-that-is-easy-and-fun-to-use) will shed some light. - I wanted the UI would be easy and straightforward. I'm sure that is not the case. Does the article on [codeproject](http://www.codeproject.com/Articles/1023815/LogWizard-a-Log-Viewer-that-is-easy-and-fun-to-use) clear things up a bit? As said, the UI has evolved a LOT since the first version (which I released about 4 months ago). - As a side-note, I want to update the article and bring it up-to-date, especially since I will soon allow for viewing Windows Event Logs, and DebugPrint as well :) Having said the above, I've packed up a lot of features in LW, and it's sure hard to present them in an easy way. I'd love to have an offline talk with you about using LW (if you have the time, of course :)), and how I can improve it. Best, John
Actually the worst thing that can happen is it compiles fine but then you get unexplained .NET runtime errors that crash your app pool several times a day due to some obscure incompatibility between LINQ2SQL and .NET 4.5. That was a fun week. And no, I wouldn't be using LINQ2SQL if I had any involvement with that project other than helping them fix the production issue.
Looks nice! Will try it at work for sure! May I ask why you use win32 api win32.WaitForSingleObject? You can use the WaitHandle class for this.
I get what you mean by throughput but ultimately from a consumers point of view if their request is sitting in a queue waiting then higher throughout often equals faster processing, provided there is a bottleneck on the threads in the first place. I've actually wondered whether just increasing the thread count would resolve the issue rather than what often needs to be a heavy re-write of your application?
serilog + seq seq isnt free but it is worth every cent
Seems interesting. What's the downside?
We use dotCover at work, but have looked at nCrunch too. nCrunch has the added benefit of real time.
I recommend Serilog+Loggly personally, but Seq is also a great program. I think Logentries is also making some better inroads into the space. I've pumped multiple hundred gigabytes into loggly in a fairly short amount of time and their service handled it like a champ (and they definitely warned me about my out of control process, which turned out to be intentional...just needed to turn off logging for it for that particular scenario).
Yo dawg, I heard you like repositories, so we put a repository around your repository! Why wrap the EF repository in another repository?
Remember, some consulting companies like when you offer a job to their employees. Usually it means a payday for the agency.
I'm mastering the art of windows keyboard shortcuts win-number alt-tab ctrl-tab...
Oh.. I really hoped this would be the way to build your own amazing asp:TreeView,but I guess without nesting, that's out... Sadly I'm still on WebForms, so all of this mvc looks a bit rocket-sciency.. Not my fault if the boss thinks the answer to every problem is a stored procedure.. Try building a Model with that... 
Eh, stored procedures are pretty powerful, a lot better than marshaling data in and out of the database sometimes. But just because you're using stored procedures doesn't mean you can't use MVC. The bigger reason to stay on WebForms is if a lot of your existing code base is already there, it is very costly to do a rewrite.
Why code project?
That's the site I chose at that time to publish my articles on. Why not? :) Best, John
&gt;My ONLY reason for a repo over EF is to avoid EF dependencies in all my projects Why is this a goal? Once there was a very convincing argument, one that I made myself no less, that since the EF team had foolishly not exposed an interface that it was difficult to properly unit test dependent code. That's no longer the case and hasn't been for some time. That truth is that the EF dependency is still there, both in the transitive sense and in the sense that your repo is a reflection of the EF API.. or rather some limited functionality subset of it. What's the point for this additional complexity? You've paid an implementation cost, what did those hours buy? &gt;Those drivers are very out of date but now updating will require tremendous work in testing and validation. I'm reworking it now to sit behind a repo and so now there's only a single project dependency. If you change this driver you still need that testing and validation work. Whether the implementation detail is abstracted or not doesn't change that. 
I get that you chose it. I wanted to know *why* you chose it. It's inferior to other choices like Github and Bitbucket.
About codeproject: I published 3 articles about LW there. The project itself is hosted on [Github](https://github.com/jtorjo/logwizard) (I totally love github :)). Best, John
ELI5 how this works?
I don't think it does, it just uses Vector but in a way I am unfamiliar with. https://github.com/IllyriadGames/ByteArrayExtensions/blob/master/src/IllyriadGames.ByteArrayExtensions/VectorizedCopyExtension.cs
I see... Couldn't you just give them access to a directory where the log files are written? Or copy the log files to a shared network directory? Best, John
Learn ASP.NET 4 now. That is what is out now, that is what is used and will still be used for years to come. Adaption of asp.net 5 will start slowly next year. The main framework you will learn "ASP.NET MVC" is mostly the same in both environments.
And what are you doing that the performance of a byte[] copy of less than 1024 bytes it THAT critical to your performance?
ASP.NET 5 if you don't want to be working on legacy systems - the release candidate is out and it's 1.0 release is imminent. However ASP.NET 5 is a big jump from previous releases (in fact there is some controversy about the name as it's a completely different stack and many feel it should have been called something different) and I imagine most large companies won't be making a jump onto ASP.NET 5 soon. Most jobs - certainly with larger companies - will be using ASP.NET 4 for the foreseeable future.
In your App_Start you should have a RouteConfig.cs or something similar. Inside there you will find your route configuration. Most likely it will contain a section for {controller}/{action} or other various routs. First, do you have a controller called Tools with an action called Chargen? Second, do you have an [HttpGet] attribute on that action? Third, does that action take a set of parameters? (If so you will have to pass those via the query string). 
With software development, there's always something new right around the corner. If you keep waiting for the next thing to be released before you start learning, you'll never get anywhere. Also, there's no reason you can't learn ASP.Net and JS, they compliment each other nicely, and there are a lot of high paying jobs that will require you to know both. And has been stated by others, ASP.Net 4 will be in demand for quite a while.
Someone else's.
It isn't my site. I don't have an app_start or know what it is.
Well, last week (or was it two?) a security update (automatic windows update) broke a deployed website, so sitting still isn't a guarantee for stability either (unless you're mildly insane and skip security updates on internet-facing machines). Stories like that are possible - but they are rare. Most likely, updating from 2.0 to 4.6 will cause no issues whatsoever, or if they do it'll be restricted to errors you can catch compile time (Due to api changes) or if you're unlucky type-load time (due to availability of legacy apis).
Also, I'd argue the transition from 4 to 5 won't be *that* crazy. 4 will be around and used for a while, moving to 5 should be natural enough.
What are some good blogs? I managed to find one or two but they are not very active.
ASP.NET versions aren't a big deal. The biggest jump I found was going from web forms to MVC. Are you going to do a front-end at all? Learn JS. In fact, learn Javascript if you're going to do any type of web development. I do full stack so my projects split between TSQL, C# and Javascript. You'll understand web development much better if you understand all 3.
Oh, absolutely. I'll always update to the latest .NET framework shortly after its release, I was just pointing out the literal worst case scenario based on past experience :)
If you ever decide to get a job working in the .NET industry you will encounter legacy code at some point. So it will be very helpful to know. Also in ASP.NET 4 I see lots of the details abstracted away from the developer. This is great because it makes our jobs easier; but then when you have to think to come up with a solution that's not ready out of the box I find many candidates to be lacking. 
Seriously. You learn one MVC framework and they all tend to feel the same after that. 
Just make a program and look at the files it generates. There's your guide. You can programmatically add and position the controls without using a designer. But it's really a lot easier to just use the IDE.
Web Forms you can. I wouldn't do it with Windows Forms.
You should be using Visual Studio and the designer view. Sorry. If you _really_ want to design your program without using an IDE, use html with something like nodejs instead, or if you're dead set on .NET, something like http://www.awesomium.com/ In reality though, using an IDE is faster than designing any kind of GUI by hand, and having Visual Studio split things up into 3 files instead of 1 is a good thing, trying to read UI code mixed with business logic is just an awful experience
I wrote swing by hand and I was hoping .NET would have something comparable.
The aspnet5 Kestrel web server https://github.com/aspnet/KestrelHttpServer/graphs/contributors and Age of Ascent a Massively Multiplayer space game http://www.ageofascent.com/ designed to cope with tens of thousands of players in a single battle
Winforms can certainly be programmed by hand and arguably should be as the code generated by the designer quickly becomes a maintenance nightmare. The MVP pattern works very nicely on win forms and allows your view ( the form) to contain only the layout and style of the controls. Any events just call a method on the presenter. If you dont have a strong reason for using winforms you really should look at WPF which is much nicer to work with and can very easily be 100% code with all the layout declared in Xaml. Either way you want to use visual studio even if you dont need the designer.
Why do it by hand? 
I think this exam will be available sometime in March / April. http://www.amazon.com/Exam-70-486-Developing-ASP-NET-Applications/dp/1509300929/ 
The reason you're not finding much is the code for winforms layouts is in the designer files and it's not quite like creating an HTML/CSS layout. It's significantly simpler to just use the IDE. Especially if you're only working on a small program. Maybe you just need to spend some more time getting used to Visual Studio. Even with small winforms programs I find I spend trivial amounts tweaking UI compared to writing real code.
Just posted: https://www.reddit.com/r/programming/comments/3xu7aj/making_a_net_windows_app_without_using_visual/
The API is not stable. There are still changes, as you can see in the Announcements repository. They target to have a frozen API with Release Candidate 2 (which was not even part of the initial road map). And honestly, they are still far from being ready. The drastic tooling change (dnx/dnu -&gt; dotnet) between RC1 and RC2 is a clear sign for that. They want to release RC2 somewhere in February, but still want to release final in Q1. Marketing said they must release in Q1, so they rush everything to make that happen.
Can you please elaborate
Its about another 100k requests a second taking it to 2.1 million RPS
Certifications that a prospective employee has are only meaningful to an organization if it will help the organization increase its Microsoft Partner status. Many organizations are not MS partners and don't care to become MS partners, hence your certifications mean nothing to them during the hiring process.
I think this depends on where you want to work and where you drew in your career. Certs can be good for the start of your career and working for ms partners/consultants or the government. For people with experience that don't work in those areas there isn't much value. 
I can't officially say how my employer looks at certs. However, I can tell you when I interview I don't even look at the resume until after the interview. I don't give any weight to certs. I once had them myself and wouldn't spend money on them now.
Perhaps. I know people who work at most of the big companies (FB, Google, Microsoft, Valve, Apple, etc) in Seattle and everyone says they just scan over the certs section of a resume.
My career up until recently was in .NET/C#. I started in 2004 and not once has anyone ever cared that I had a cert. My first job they wanted to see that I could code over whether or not I took some exam that I could study for.
Yeah those are excluded from what I said. At that point they are looking for the top rated developers. Those don't need certifications. They don't even need education as long as they pop on the radar (rarer). They are looking for certain type of people and will not hesitate to relocate you to get you. So yeah... No certifications will get you in with the big guys.
Sorry, I didn't intend to sound pissy. I simply didn't understand what question you think you were answering. IMO, there never was any question to begin with... And your "answer" seemed unhelpful and counterproductive to any discussions regarding the actual content and goal of the article. You seem to think that nginx is the end-all be-all answer to all questions regarding stactic file hosting, regardless of what platform you are currently on, whatever requirements you might be facing, and no matter the situation. Well ok, but I don't see it that way.
You are stampeding the dotnet forum today with lots of angry replies. It's childish. 
That's a fair point.
Yes, but to do so would involve exposing your SQL Server to the web, to allow the Azure-hosted site to connect to it. Probably not advisable unless you *really* know what you're doing. A much better idea would be to use a SQL Server hosted by Azure, and let MS take care of the security. 
.Net Core and EF 7 have release candidates out. They are not in "early beta".
https://github.com/aspnet/Home/wiki/Roadmap They are at RC1, which means no more bleeding/cutting edge technologies. Internally they will fix bugs and optimize everything but for the developer there shouldn't change much (although it is possible) Edit: https://github.com/aspnet/EntityFramework/wiki/Roadmap
You can us VS Code and write .net in Linux. This is something that I myself want to try at some point but for the more traditional experience why not kick the tires and take it for a test drive w/ free parallels along with a bunch of other freebies: https://www.visualstudio.com/en-us/products/visual-studio-dev-essentials-vs.aspx
There are multiple ways, depending on your application and needs. If you have direct access to the server, the easiest way for non-production environments is to simply copy the web application directory to the server and point IIS to it. If you do not have access to the server directly, you will need to learn [Web Deploy](http://www.iis.net/downloads/microsoft/web-deploy). The default location for websites is C:\inetpub\wwwroot\ on the server. Make a folder called MyApplication and copy the \bin\ directory of your project output into that folder. Then follow the instructions [here](https://technet.microsoft.com/en-us/library/cc772350.aspx) to add a website to IIS and set the bindings. There are a few other things you will need to check: check your config files and make sure they are correctly configured for the server, make sure the server has any libraries needed installed and available, make sure the server has access to external resources as required, and make sure to set the application pool to the correct target framework. *Edit: Fixed link.*
Yes, but I will admit that I haven't messed with Web Deploy in years, so I'm not sure how well it works.
I feel as though dev and hosting of ASP has dropped significantly in the last few years with Microsoft having so many low volume free licenses and platforms. It is going to get even more cost efficient as ASP 5 core services get rolled out because they are designed from the get go to run on Linux and osx so no windows or iis required for hosting. As this becomes more adopted and a few patches come out it will drive prices further towards 0. 
I'm a .NET dev. My friend is a sysadmin who's pretty much devoted to all things *nix. I told him that I wanted to write a quick webapp for something. He said something to the effect of "Write it in something that's cross platform". I can't explain the joy I got when I smiled and responded "Oh, I am. I'm gonna write it in .NET!"
If you are not on Windows, I don't think it's worth changing over just for developing. And while I wouldn't be able to suggest anything over Azure at a moment's notice, I don't think it's free tier is worth much. I might be saying this cos I've been on the C# side of the world all my professional career, but I'd delve into some client-side development. Earn some JS chops. Only worry about data as far as the service endpoint goes, not caring wither the other end is nodejs, .net, php or what have you. Ever since Azure's free tier lost it's free SQL instance, I nuked all my "pet" projects from there. Also you need a full course on how to use their web interface. I'm sure it's a wonderful platform if you are running a business off it, but for toying around... nah. Visual Studio is wonderful, source control integration is very nice (Git, TFVC), debugging works as always, the language is very good to work with.
If bandwidth isn't a problem and they are available, downloading VMs and checking them might be easier as you won't have to install anything. Older Visual Studio versions seem to take ages to install.... Maybe the community can help. If you are looking for the version on the devenv.exe file. Here's what I got: VS 2015 Pro - 14.0.24720.0 VS 2013 Pro - 12.0.40629.0 Good luck!
You can host a Windows stack on Amazon or google engine no?
And, don't forget to give permissions to the app pool identity on the folder you're deploying too.
I find webdeploy to be far easier to use than copying files manually, I'd go with it.
On Amazon I'm sure you can, but I don't know if you need to buy an entire VM to host Windows. On Azure you can just host the website in App Services which is cheaper than getting a whole VM (up to a certain point). Plus you don't need to worry about maintaining the VM with updates, App Services are maintained by MS.
So I did the Web deploy and worked. But now I have to change the database. I was using the local db... Now I have to use SQL express. It's enough to change the connection string or it's necessary to change anything else? 
Make it without any UI, then reuse your code to make it a console app, then we'll see if you're ready to go the WPF way. Alternatively, just go ahead and use WPF like a fancier variety of WinForms, but don't say you know WPF after that.
I'm surprised that you've manually unrolled the loops. I'd think that the JIT can handle doing that if necessary, but it looks like you'd have profiled that. Cool stuff.
Since you have limited time, stick with what you know. You still have hurdles to overcome. But, in general, new desktop development is mostly done in WPF now.
I've been using WinForm for years. I recently started learning WPF - it's a steeper learning curve, but it is so much more flexible. You can make apps which adjust size and resolution based on the resolution of the machine it runs on. There are some differences to learn - if you used a form timer to update the form, you'll need to learn about the dispatcher. 
And they work best with MVVM. You can do MVVM in a win forms app too but it's not as smooth. 
[removed]
WPF allows for some pretty awesome separation of View and Model. The binding model has a steep learning curve but is super powerful. Just about everything I set out to do on the view side I could do in a declarative way.
Ok, it's done. But if I try to access the site, I get a 403 - Access is denied error. Anyone knows how to resolve this? After the web deploy, the site shouldn't be ready to go?
Seeing as you are so far along, I would stick with WinForms for now, but definitely take the time to learn WPF at some point, its much better.
That is most likely the causes are: - The app pool not having sufficient privileges to the root directory of the website. If your webapp's folder is not in the default root folder (C:\inetpub\wwwroot\), you need to make sure that the IIS processes are given full permission to the folder where you put your app. - You did not specify a default page in your application or your routing table does not correctly specify a default page. IIS looks for a file called index with the extensions htm/html/php, a file called iisstart.htm, or a file called default with the extensions asp/aspx. If none of those are your default landing page, you need to open IIS and specify a default page as shown [here](http://www.iis.net/learn/web-hosting/web-server-for-shared-hosting/default-documents).
Something in your configuration is denying access. You're going to need to read the webserver logs; by default, these are stored in %SYSTEMDIR%\LogFiles\ What you're looking for is the error line that shows the specific HTTP 403.xx error that the server is returning. One other thing to check is to make sure your site bindings are correctly configured so that the server knows which interface it is using to respond to the requests.
From my experience, Win Forms is awful in comparison to WPF. It looks bad and isn't scalable/adaptable to different screen resolutions. WPF is a very powerful tool. That said, there are a lot of things that are way too complicated in WPF that is super simple in other frameworks. Still like it better than win forms though. In the short term: keep using win forms if you can. Seems silly to rewrite a good chunk of the project if you aren't going to be maintaining it for years afterwards. 
Yeah Thank you, But where can I learn WPF, I cant find any tutorials on youtube especially on the good one that focuses on UI :(
This site is ok: http://wpftutorial.net/Home.html WPF by Adam Nathan is the best book out there: http://www.amazon.com/WPF-4-5-Unleashed-Adam-Nathan/dp/0672336979/ref=sr_1_1?ie=UTF8&amp;qid=1450973915&amp;sr=8-1&amp;keywords=wpf
Agreed
Is the custom ui part of the project? If not then I don't think you should design custom ui. It is bad practice to not use the OS conventions. Users like consistency so they don't have to relearn a new ui for every application they use.
For the nitty gritty on the xaml side, I picked up a lot from Dr. WPF. 
Sure legacy technologies can be easier, and wpf will give a nice interface, but I imagine a library system will run on multiple machines, and even remotely offsite. Get with the way tech is moving rather than mastering stuff from the past. 
Thanks. Confirmed this with two using(var rng = new RNGCryptoServiceProvider("taco")) The output is First Set 20 154 17 243 69 56 195 175 233 145 Second Set 35 151 208 124 104 37 34 125 233 52
Legacy? Web development predates WPF by a decade. It just feels new because it continues to suck. The only reason that web development is ever justified is that you need its zero-install deployment model. 
At least in the current MS implementation, those constructors [don't do anything](http://referencesource.microsoft.com/#mscorlib/system/security/cryptography/rngcryptoserviceprovider.cs,43) anyway.
Use a singleton but... just a warning: the Random class is not thread-safe. Wrap it in a class that locks access to it or preferably, for performance reasons, make it thread-local (with a different seed per thread!). RNGCryptoServiceProvider is thread-safe so just make it a static readonly somewhere and use it freely.
Don't switch right now if you're a student. You can learn either webdev or WPF/UWP later. The latter two have a similar UI paradigm.
The most common causes I've seen for TypeLoadExceptions are when the system can't find a compiled type dependency at runtime, or when there's a static constructor that fails. The second isn't terribly likely with a system type, but the first... The first would be that you compiled against a library, but when running it, the application couldn't find that library. You're building it locally, but since it's a Windows Phone app, you might be running it on the phone or a device emulator. It might not find that DLL in the device environment, or the DLL might not contain that type. [This StackOverflow link](http://stackoverflow.com/questions/31888429/settingspane-not-found-in-windows-10-build) suggests that the SettingsPane is being deprecated, so it might not be found in certain OS versions. So if the proper DLL dependencies have been deployed to the runtime environment but it's still not finding the type, it could be related to this. Manual type/assembly resolution could also cause this if it doesn't resolve all the types properly. Raymond Chen left a note there that you can get past the resolution with an extra reference, but that the type won't actually do anything. Not sure if any of this is relevant, since I moved away from mobile apps a while back, but maybe the fresh perspective will help.
I would go with inlining them in the csharp code because it's easier to follow and make changes when parameters and SQL are declared side by side. Even if I used SQL script files I would never go and edit files without recompiling. I believe that the whole app should be packaged on a build server and never modified after that. Focus on making deployments quick and completely automated instead. Edit: For the sake of readability I usually format inline SQL with the @ modifier so that you can include line breaks without any fuzz. For example (pseudo code, I don't remember the exact Dapper interface right now): var sql = @" SELECT Id, Name, Email FROM Users WHERE Id = @id "; var result = conn.ExecuteQuery&lt;User&gt;(sql, new { id = userId });
Haven't seen a decent data grid on the web yet
First off, I'd recommend to use Generics. Make the model of your tables, then use a query builder, something like private string BuildQuery (QueryType queryType, Type recType, string whereClause) { var tableName = typeof(TableNameAttribute).GetProperty("TableName").GetValue(recType.GetCustomAttributes(true).FirstOrDefault()); string query = ""; switch (queryType) { case QueryType.Select: query = string.Format("select * from {0} t where {1}", tableName, whereClause); break; case QueryType.Delete: query = string.Format("delete from {0} t where {1}", tableName, whereClause); break; } return query; } Then, declare your operations something like public bool Delete&lt;T&gt;(string whereClause) where T : BaseRec { using (var context = new DatabaseContext&lt;T&gt;()) { return context.Database.ExecuteSqlCommand(BuildQuery(QueryType.Delete, typeof(T), whereClause)) &gt; 0 ? true : false; } } Note: this is with EntityFramework, but the same principles can be applied to Dapper.
Because the methods I've made are limited to **only** doing the database interaction, they are simple to test, and all the logic is still in the controller where you would expect it. It basically combines the data access layer directly into the model class it would be manipulating Also sorry I'm on mobile, but basically it also allows you to change the model and the dal at the same time if need be instead of multiple places to add a new field
If it makes sense to you, that's cool. It pretty obviously violates the single responsibility principle, so it's not the way I'd advise anyone to go. It's a lot less painful to deal with a type that defines what it contains and another class that understands how to populate objects of that type from your persistence layer. Source: I wrote code for an app like that a decade ago and discovered how much more painful it is to deal with supporting an app built on top of God-y model types. 
It's not something I'd do for like a reusable library, or dll of any sort. I've only tried it on a couple pet projects that I've been working on. What type of issues did you run into? The model class always seems wasted to me as I dint usually need to override much unless I'm doing custom comparers or serialization etc. 
When you get in the habit of adding just one more small thing to a class, you end up with a class composed of a whole lot of small things that, when you take a step back, don't necessarily make a whole lot of sense together. If you go the other way and have a model class that just exposes the properties that the table behind the scenes holds, then farm the interesting things you can do with it out to other classes (and I include constructing it if it's more than simple instantiation to build one up or retrieve from the database), then reasoning about what you have becomes a whole lot easier. If you're seeing strangeness in what you're getting back from the database, you'll have an easy time locating it. If you have database retrieval in its own project, you'll be able to examine retrievers together and see what repeated code can be shared between them. Lots of classes that do lots of simple things is easier to test and support than a small number of big classes that do a lot of magic under the covers. 
Hm.. somewhat of a repository pattern actually.. 
As soon as you call `String.Format` on a SQL-like template alarm bells should immediately start going off.
Still preview: https://github.com/aspnet-contrib/ Those packages target the latest dev version, so if you use them you will run into plenty of breaking changes. Especially since the API of ASP.NET 5 is not yet stable.
Oh neat. Would you happen to know the relationship between these contrib middleware to IdentityServer? I'm not attached to any particular solution, though I'd like to have an idea of where things are headed for oauth on ASP.net 5.
I could definitely see/know how for more complex classes it can get a little more difficult to find which model you put the code in for that. But what I've done to alleviate it (and again, these are small side projects, nothing large) is that the SQL to fill an object goes in the top level of that object. Basically if I have a model with an array of subclasses, the "container" model will have the code to fill itself. This will cause issues if you need to update it in multiple places if you change the sub model though. I know it breaks some aspects of code separation etc, but I've found it works pretty well for newer projects, or at least smaller projects, as I find it a little quicker to implement and not hard to abstract that database logic out into a true data layer at a later time.
Seems to work fine. I didn't set it up though, so no clue on the intricacies involved.
Make your product free and i will actually read this articles. ReSharper or GTFO
Again, EDMX != DB First. It was a ways to visualize the DB. If you read the links, from the EF team, you can see that.
How then, do you create an edmx without a "Db First" approach?
True dat
I wanted to share this template here because it is probably **the best** documented template I've ever come across, for any project. Along with this, the author (not myself) is very active in helping others with their issues as well. The project can also be found [here](https://visualstudiogallery.msdn.microsoft.com/559ec6fc-feef-4077-b6d5-5a99408a6681) at the Visual Studio gallery. Check it out, it also uses the excellent [AdminLTE theme](https://almsaeedstudio.com/preview) created by Abdullah Almsaeed.
Yes, you can do that. I do that.
Good talk!
So, you're telling me that I shouldn't try making user authorization on my own... Do you know any good docs/tutorials about making user authorization in asp.net 5 webapi? While it is [[something]](https://docs.asp.net/en/latest/security/authentication/introduction-to-aspnet-identity.html) about asp.net mvc 5 identity, there isn't anything about how to make it for web api. Can you recommend me something?
bingo
The latter is how I'd expect you to find controls in the Form. Using Visual Studio and setting up a new form in the designer, you'd get a separate source file (a partial class) with all of the form controls defined, and then assembled as you've shown below in a method called `InitializeComponent()`. `Controls.Find()` is -- in my experience -- very rarely used. If you've got the name of the element, anywhere in the code (non-static methods) you've generally got a reference to the form: just say `this.timerTextBox` and lo, there it is. The only time `Controls.Find()` is really used is when a form is assembled dynamically, and the layout isn't known until runtime. (Generally *this* is a red flag of bad code design as well.) (small nit: TextBox.`Text` wouldn't return an `int`).
D'oh! Just pretend there is a ToString function in there somewhere. Cool, looks like I will be doing it that way now. I started messing around with windows forms in Powershell first, and a big pile of global variables in a script can make things pretty messy. So, I defined them all in one function and the used find to find them from the main control to avoid that. Since I am building them in C# that shouldn't be a problem then since it is all wrapped up in a class. Thanks for the answer!
It looks like [this](http://www.asp.net/web-api/overview/security/individual-accounts-in-web-api) is what you're looking for - this is made using OAuth 2.0 and features built-in in the Web Api 2.
If you're just experimenting, try playing with WPF for real data binding
https://github.com/IdentityServer/IdentityServer3 This is an awesome project that provides what you're looking for.
You don't need the EDMX, that was the point of saying, EDMX != DB First. From the [EF blog:](http://blogs.msdn.com/b/adonet/archive/2014/10/21/ef7-what-does-code-first-only-really-mean.aspx) *the EF Designer provides a boxes-and-lines representation of a model that is stored in an xml-based .edmx file* and *Another way to sum this up is that rather than a third alternative to Database &amp; Model First, Code First is really an alternative to the EDMX file format. Conceptually, Code First supports both the Database First and Model First workflows.*
Using a general cause exception block for flow control.... Very elegant code. ðŸ‘Ž
Angular 2 is built for it but angular 1 isn't. I guess you can use it but it's not as built in as in 2. I don't care, do what you want. You just remind me of all the times I worked on projects and my company had me implement new stuff with old technology. Like creating a report generator in .net 2 when .net 4 was out. The they'd complain about browser support when .net 2's report viewer looked bad in anything but old IE. I just think that if the technology is out and you're starting from scratch, you should use the version that makes the most sense and if it's angular with TS then you should use use v2.
Can you elaborate please? - Angular 2 is still preview, therefor it can't be used for many line-of-business applications yet. - TypeScript is a very valid option for Angular 1, to get typing support.
Also, Angular 2 is such a departure from Angular 1 that there's a significant chance that it will go the way of Python 3.
No... This method is used to handle 1) To render view even when corresponding action does not exit 2) the redundant action method in the controller
100% correct as well. 
Stupid rdlc...
This looks pretty efficient to me. No nested if statements, etc. If you repeat this exact validation multiple times (on the user object), you could refactor this out to its own method (maybe a Validation class or interface). This method could return one or multiple errors so that you can display multiple validation problems at one time (you currently can only do one at a time and that could be by design). **Validation Model** public class ValidationResponseModel{ public bool IsValid{ get{ return !Errors.Any(); } } public IEnumerable&lt;string&gt; Errors {get;set;} } **Validator class** public static class Validator{ public static ValidationResponseModel ValidateUser(User user){ var results = new List&lt;string&gt;(); if (user == null){ //no user, no reason to check the other properties. results.Add("User with Email could not be found"); } else{ //found a user, lets check his properties. More than one validation error could occur. if (user.Status == Status.Inactive){ results.Add("User with Email has been deactivated"); } if (!user.EmailConfirmed){ results.Add("User Email has not been confirmed"); } } return new ValidationResponseModel { Errors = results; } } } **Potential Usage** var user = await _userManager.FindByEmailAsync(model.Email); var validationResponse = Validator.ValidateUser(user); if(!validationResponse.IsValid){ foreach(var error in validationResponse.Errors){ ModelState.AddModelError("", error ); } return View(); } *Note - this is pseudo code and probably won't compile if you copy/paste. Rather, this is to give you a general idea of how to make a resuable validation class.*
Too many devs get caught up on writing 'efficient' , 'clever', or 'elegant' code. What you have here is what I like to deal with. Simple and easy to read. This is code that a junior developer can easily troubleshoot if needed, and that is way more valuable than saving a few lines of code here and there. 
Rdlc... Hmm.. Try rdl with a Report Server, that pos MDX query generator, RSClientPrint.cab,Delivery Extensions, anonymous access to Report Manager... All across all versions from 2005 to 2014...You name, I've seen it... I hate SSRS with a passion... 
If you subscribe to the S bit of SOLID (single responsability), then you should have a method per check so you'd end up with something like : public ActionResult Index() { var user = await _userManager.FindByEmailAsync(model.Email); AddUserNullError(user); AddEmailDeactivatedError(user); AddEmailNotConfirmedError(user); return View(model); } private void AddUserNullError(Object user) { if (user == null) { ModelState.AddModelError("", "User with Email could not be found"); } } private void AddEmailDeactivatedError(Object user) { if (user != null) { if (user.Status == Status.Inactive) { ModelState.AddModelError("", "User with Email has been deactivated"); } } } private void AddEmailNotConfirmedError(Object user) { if (user != null) { if (!user.EmailConfirmed) { ModelState.AddModelError("", "User Email has not been confirmed"); } } } Doing it that way will also give you a way to break it out to a validator class as bigrubberduck shows. Up to you though
Did this happen? Wouldn't mind taking a look!
The upgrade path looks horrific Don't get me wrong, I think Angular2 looks great, but I think that attempting to *upgrade* from 1.x is a massive mistake. You end up loading both libraries side by side, plus other scripts to bridge and then your app. I think what will happen a lot is, people will start to upgrade, reach a point where they are using some 1.x library with no 2.x equivalent, and then leave their apps in limbo, with a massive footprint to boot. I'll be using Angular 2 for new stuff, but no way in hell am I upgrading my 1.x apps to 2.
If you're going the static route I'd take it the .5 step further and make it an extension method for the user object itself that invokes the validation subroutines and returns the IsValid bool
Yeah, it could definitely be improved upon. I was trying to keep it at the c# 101 level :) 
No, use IValidatabeObject. 
Don't do it this way. [IValidatabeObject](https://msdn.microsoft.com/en-us/library/system.componentmodel.dataannotations.ivalidatableobject.validate.aspx) is the right way. Edit: added link
The error message should be pretty self-explanatory. Both expressions of the conditional operator must return the same type, and there is no conversion between `DBNull` and `int`. You can fix this by explicitly casting to `object`.
This has been answered more elegantly than I ever could so I'll just leave this here (accepted answer): http://stackoverflow.com/questions/18260528/type-of-conditional-expression-cannot-be-determined-because-there-is-no-implicit Cheers
Huh. Well, now. Thanks for that link. This is the first time I have used a ternary where the values are indeed different types, and where no implicit type conversion exists. Up until now I have only been dealing with like types.
Agreed. I don't do reports any more. I hacked rdlc so i could use objects and generate .rdlc files dynamically. 
Interesting, dynamic rdlc is clearly doable, but I doubt anything like that could handle the absurd requests some users have... Plus the xml schema is highly version dependant... Still, I wouldn't mind seeing some code just to understand the approach.. For example I'm really curious about a query valued parameter's selection UI.. 
I believe /u/jeyoung was referring to your _userManager class as the 'backend' when he should have said *business layer* or *business tier*. I tend to agree with /u/jeyoung however it may just be personal preference. The _userManager class should perform the validations and the User object it returns can have an Errors property. Then you take the Errors property and map them into your AddModelError(). This pushes the business logic into the business layer which gives you the ability to expose this same functionality in another presentation layer. For instance, if you need an API for a customer something like WebApi REST service. Then the consumer of your REST service will receive the same validations/error messages at no extra cost to your development team. However, that is just nit picky. All in all your solution is clean and fits your needs. There is very little performance to be gained from your implementation and since it is clean and easy to understand I'd recommend just sticking with it unless you envision an API exposing the same functionality somewhere else.
Not yet - svper, fancy setting up a github repo, perhaps use the Northwind database? We can jump on once you've got the basic project up and running.
I'll start playing around here with VS :)
As /u/AbstractLogic says. I used "back end" because different methodologies have different levels of abstraction and different nomenclature for these layers. 
I've never used resharper before is it worth looking into?
I think so personally. It identifies dead code, language opportunities (better ways to do things), potential pitfalls in your code, etc. They have a 30 day free trial, download it and run the code inspection tool on one of your projects just for kicks!
Just out of curiosity... Why are you storing database parameter information in an object array? I am assuming the array is of type **object** considering the naming convention (*objPara*) that you are using...
You could just disable, or reduce the inspection severity of that particular rule.
I agree with gidikh the most. But I also have an unnatural hatred for repetition. I think a simple method would be the best solution here. Call it something straightforward like HandleError(string message) and make it call AddModelError("", message) and return View(model). So your code will just look like if() return HandleError(...) if() return HandleError(...) if() return HandleError(...) Sorry for brevity, coding on mobile is hard. :) Also, forgot to mention a point, so editing it in. You probably mean succinct and not efficient. Efficient generally implies that there is a performance problem.
Just installed the trial. Thanks.
Just installed the trial. Thanks.
I believe we're saying the same thing with different words
Seconding this. Seen a very similar thing done in ps.
Powershell. Also, sounds like you are re-implementing [scom](https://technet.microsoft.com/en-us/library/hh205987.aspx). Might be easier to buy that.
Thanks for all your suggestion. i will accept with you. I had updated the post.
Cool. Let me know what you think - I'm not affiliated with them in any way, I just like to know feedback on tools and if you have seen/used better ones!
&gt; you should be using String.IsNullOrEmpty Point taken. This is inherited code, not my own. Iâ€™m just trying to clean it up a bit.
[removed]
In Automapper, there is a command for that : &gt;.AfterMap((src, dest) =&gt; dest.PasswordHash = _userManager.PasswordHasher.HashPassword(src.Password)));
My mapping configuration is in a bootstrapper class and _userManager is being injected in controllers. Are you suggesting that I also initialize a UserManager in the bootstrapper class?
You could go the route of JWT's, where it will check just once on the initial request, and then assign your user a token (if they pass validation) and then permissions will be checked against the token instead of against the application, which is usually stored client-side somehow (session, local storage, etc).
There should be permissions stored somewhere against the token I just replied the client with right? 
I can override AuthorizeAttriebute to do things my way. But that will require accessing database from the Attribute and checking against the records. Is that good practice?
You will want to use a custom Automapper resolver since UserManager is getting injected. So your resolver might look something like this: public class PasswordHashResolver : ValueResolver&lt;string, string&gt; { private readonly IUserManager _userManager; public PasswordHashResolver(IUserManager userManager) { _userManager = userManager; } protected override string ResolveCore(string source) { return _userManager.PasswordHasher.HashPassword(source); } } And your mapping would look something like this: Mapper.CreateMap&lt;RegistrationViewModel, ApplicationUser&gt;() .ForMember(dest =&gt; dest.PasswordHash, opts =&gt; opts.ResolveUsing&lt;PasswordHashResolver&gt;()); There is some wiring up you'll have to do with Automapper, your resolver, and the IoC container that you're using which is pretty straightforward. Here's how to do that with Autofac, but any IoC container should be fairly similar in setup. http://tacticalnuclearstrike.com/2014/07/automapper-and-autofac/
I use almost solely wpf, because to me, xaml is a very concise way to express code. If you're really into WinForms, I think that is fine. People say winforms is old and outdated, and it is to a degree, but you can still do great things with it. I would recommend using WPF, mostly because I think that xaml is the future of GUI development. Even Android uses an XML based markup language to make GUIs. But in the end, choose what you're comfortable and competent in.
i use this approach for x-domain service operations when deploying from our TFS server residing in an untrusted domain to other domains. 
I would recommend against using sessions. Sessions lock you into only having one web server and are lost whenever the application pool recycles. I would suggest creating a custom implementation of the claims identity factory and configure the identity UserManager to use that. You could then add any custom claims from the database and it only gets called when the user initially logs in or when the cookie expires and identity renews it. Alternatively you could use claims to store more explicit permissions. 
I took that advice and regretted it. Productivity decreases significantly using WPF. There's all sorts of rumours about WinForms being replaced but I don't see that happening anytime soon - too many companies have invested too much. If you know WinForms and just want to build a functional business app I'd stick with what you know.
Sound advice. Cheers dude. As for them not dropping it I wouldn't be so sure. I use .Net CF at work and I'm stuck using vs2008, even though the windows ce 5/6 devices are still so heavily used. But I agree I doubt they will actually drop it in the foreseeable future.
You can't because every time you access a UI component, it has to be on the UI thread. Why would enabled a bunch of controls be slow? How many controls are you talking about? This can also be a good sign that something is smelly about the design. Maybe you need a different way to "disable" user input rather than enabling/disabling all the controls. That seems really unmaintainable.
&gt;is far simpler to get started with than WPF. But WPF also supports drag and drop in a way that is very similar to WinForms. I mean, yes XAML, MVVM and bindings are difficult. But you can build a WPF app completely using drag and drop and treat it like a winforms app. Is the difficulty in layout? because with drag and drop you can use absolute positioning like winforms. For me, I wouldn't use winforms unless I have to and if a team member doesn't understand the advanced concepts of wpf, they can just pretend it's winforms to get started and learn it along the way. Not trying to bag on winforms, just trying to see if there is something I'm missing since you can just treat WPF as a drag and drop environment like winforms (at least in the beginning).
it's a winForms app. Thanks for your response
I agree with this. I'm using OAuth implicit flow with a jwt token to transfer the necessary data.
Invoke will just execute on the GUI thread again, bringing you back to square one, just with more synchronization overhead. Just to be clear: when talking about "enabling", you literally mean changing the `Enabled`property and not any sort of creation, initialization, data binding or anything else of the sort (either directly or indirectly through events), yes?
I think I've dug through that a few times, but I'll go through it again in case I missed something, thanks for the reply.
Thanks. This makes sense. Any idea how this can be done using something like TinyMapper instead of AutoMapper?
Isn't this nearly always when adapting to a new technology? It just takes time to learn. But in my opinion, once you know the gist of WPF you start to be more productive. Much easier to maintain a GUI in WPF than in WinForms as well in my opinion due to more split up logic (which is basicly thanks to MVVM). 
http://benfoster.io/blog/aspnet-identity-stripped-bare-mvc-part-2 is a pretty good resource for understanding what identity does behind the scenes. There is a small section on creating your own claims identity factory. The gist of it is that you inherit from the ClaimsIdentityFactory with your user model and primary key type and override the CreateAsync method. Here you can add any additional claims needed. The sample shows how you can add the user's country to the claim cookie. Re-reading your OP, this might be a little overkill for what you are trying to do. Using `[Authorize(Role="...")]` attributes with checks in your views using `User.IsInRole("...")` you should be able to dynamically show/hide things based on a user's role and enforce the permissions server-side. 
Seriously, how many sockpuppets do you guys have?
The site shows a benchmark that says its faster than AutoMapper
I would highly recommend researching the claims-based resource/action authorization. A user is nothing more than a set of claims. A claim could be a role they are in, a permission bit (read,edit,delete,full, etc.), an e-mail address, or some derived ones like "IsReadOnly" that you can transform when they login (see Claims Authorization, Claims Transformation, etc.) Now, when they try to execute a piece of protected code, you don't check roles or permissions or even claims directly. You would do something like ClaimsExtensions.Demand(resources, action). It is then the job of the ClaimsAuthorization class to look at the resources and the action/access level (read, edit, delete, etc..), then determine if the current claims principal has the claims necessary to satisfy the demand. This way there is a clear separation between things we are authorizing and the security constructs that make up our app. Instead of IsInRole(Admin) OR IsInRole(Accountant), its Demand("Employees", Edit). For example, I demand "Edit" access on "Employees"....my ClaimsAuthorization flow might look like the following: 1) If user has claim Role:Administrator, don't bother checking anything else, just return true 2) If access level is greater than "read" and user has claim IsReadOnly:True, don't check anything else just return false 3) If user has claim Permission\Employees:"&lt;security bit&gt;", and the value of &lt;security bit&gt; is greater than or equal to "Edit", return true, otherwise return false. Hopefully that flow will demonstrate how authorization might consider roles, permissions, or other constructs to determine if they have access or not. Imagine checking all of those different things for every piece of protected code....it wouldn't be feasible. Now you might be thinking "but this is going to turn into a big if statement around each resource", but if you structure your claims and permissions properly, you can fit some pretty robust authorization logic in a handful of lines of code. EDIT: I HIGHLY recommend looking over this library in detail: [thinktecture identity library](https://github.com/IdentityModel/Thinktecture.IdentityModel.45). The concepts in that library are directly applicable to the pattern I just described. They have already written a lot of the code that you would use to facilitate the above, like ClaimsExtensions.Demand. 
Can't I just ignore it somehow?
I had a similar issue with items in "content" paths. Bundle paths get some different treatment when in release mode vs debug. Step through your bundle construction and verify all artifacts are gen'd correctly. Also you may have an issue with min files. Release mode uses minified files; it may be trying to use the jqueryui.min.js file and you may not have it, hence the 404.
Thank you so much for the reply! I really really appreciate it. I use the minified jquery ui css in my bundle config, and I know it bundles correctly since it actually tries to load the icons in production, but returns 404 on the icons themselves. My Content directory looks like * images/example_jqueryui_icon_file.png * jquery-ui.min.css and in the jquery-ui.min.css it looks for them from the relative path like background-image:url("images/ui-icons_222222_256x240.png") So when it gets deployed to the release build it must re arrange where the content directory is relative to the css file or something...just pouring my thoughts to the keyboard right now, thanks for the help! Any ideas?
Can you post a screenshot of what you got? I am not sure what you were looking for, but it sounds interesting.
I have pulled this off by implementing OWIN OAUTH middle ware. Please note that the last I looked there is no plans of Microsoft porting it to ASP.NET 5 if that is on your roadmap. You might want to double check this to see if it has changed. It took me longer then I want to admit to fully implement it. I ended up using Redis to store all the tokens I had to generate as well which worked out well as you can set TTL to the tokens easily. * you enable OAuthBearer in your WebAPI 2.0 services and have the same machinekey in web.config as the auth server * you enable OAuthBearer in your MVC website again with same machinekey * you enable cookieauthenication to redirect unauthorized users to AuthController * you create an AuthController on mvc website that handles that redirect and create a state token (authcode) that you can use to verify the request on the redirect back to website * the authcontroller will then redirect to you authserver passing ClientId, ResponseType, Scope, State, and RedirectUrl * the auth server with the owin oauth implementation will receive the request * it can validate the clientid and validate the returnurl (make sure it is allowed for the given clientid) * if the clientid is from an internal service I just ask the user to login * if the clientid is from an external service I ask the user for permission based on the scope that was passed * validate the credentials and the authserver will redirect back to the returnurl with an authorizationcode * the mvc website then needs to request a refreshtoken and accesscode (bearer token) from the authserver using the authorizationcode that was returned and its clientid and clientsecret * the refreshtoken has a long life and should be treated with care * the accesscode (bearer token) has a short life and is sent with request header to website and webapi 2.0 calls I am not sure if I would do all of this again. It gives you a deep understanding of OAUTH and you get your own implementation. Maybe that IdentityServer3 mentioned has everything you need out of the box. If you want to see my implementation in action send me a PM and I will provide you a link. Another note, you mentioned supporting java, I recall there being issues getting the decryption of the bearer token to work across platforms as the default implementation on .net using the machine key was not compatible with Java (ie you can't use the same key). I do recall that there is a way around this, just want to give you a heads up to make sure you research this as well and not run into an uh oh moment down the road. 
There is also the ability to enable the Application Warm-Up Module. This will hit your site with a request and if you configure it correctly will not kill your application pool after 20 min. Another trick is to use a ping service that hits your site every 5 min. I usually make a special page that makes sure everything is JITed nicely. I look forward to the day when this is no longer a problem...
What we really need is the equivalent to the MEAN stack for .NET. MongoDB, Web API, Angular, IIS / Katana / OWIN 
I like the flow you just described. I am going through the library you linked to but not seeing anything like it.
Oh this is good info thanks, As to Java, I am using JWT's in my web service layer, and that should work I think. 
Would you prefer to store instances of each type in their own database table? You'd have more tables then, but no Discriminator column. http://weblogs.asp.net/manavi/inheritance-mapping-strategies-with-entity-framework-code-first-ctp5-part-2-table-per-type-tpt
It seems like the blur isn't captured in a screenshot which is weird but I can try to explain it. If you look at the taskbar in Windows 10, it is transparent and only has a tint to it. Things like the startscreen though have a blur effect on it. The wpf window blurs everything behind in a way very similar to the start screen blur. By putting it under the taskbar, it gives the illusion that the task bar is blurring everything instead of just tinting it. Recently, I realized that classic shell can do this exact effect while keeping the windows 10 menu so I have decided to use that instead. I also realized that the wpf window will jump back on top if something is minimized from the taskbar.
Ah, thanks!
The reason I ask is that what it sounds like you need is an Identity Server (Single SignOn). Either you write one yourself, or you use something like OpenSSO, ADFS, Ping Identity, write your own with IdentityServer3 or some other tech, etc. While a lot of identity servers will might allow multiple identity sources (Like AD), if you have a mixed identity environment, then I would go the IdentityServer3 route and write your own. You can actually get one going in a surprisingly small amount of code, but you'll have to gussy it up a little to make it production ready.
For some reason (maybe an IIS setting?), I've found that a server doesn't interpret relative paths predictably. I've had some success placing "../" as opposed to "~/" at the start of the URL. Maybe: image:url("../images/ui-...etc.).
You should be writing tests. Imagine finding and fixing a bug before you even commit the code. As opposed to finding it days/weeks later during the UAT process.
The biggest struggle I see among beginners is just how to begin writing tests. There are a lot of guides on how to use the software and frameworks made for it, but not much that I've seen yet on the philosophy and best practices behind it, especially platform-independent. 
You should be writing tests because they force you to decide in explicit, specific detail, what *exactly* constitutes correct behavior. UAT can let things, especially minor things, through because humans are fallible. Computers aren't; they'll catch off-by-one errors and minor pixel offsets every time, period. Additionally, UAT is only really good at finding bugs at a macro level ("Does the final product work correctly?"), while you can write tests to test individual components, or pieces of components, at a very low architectural level. You'll catch bugs faster, and have pinpoint locations of exactly where your code broke. 
Your development situation is unlikely to be the same as anyone else's and applying their solutions in your context is unlikely to be optimal. What you need to do is to
I've been in the exact situation as you, what I'd suggest is just write some tests now, simple ones. Some tests are better than no tests, and you'll have framework to add more to over time. Keep adding tests at the same rate you write feature code, and your code will become better and more dependable over time. Don't get stuck over thinking things.
As of the time I'm writing this comment you are literally the only one in this thread that mentioned TDD. Writing automated tests != TDD. If I were to MS Paint a Venn diagram of it for you, automated tests would be one big circle and TDD would be a small circle inside it. It is not necessary to use TDD at all to realize the benefits of having automated tests. The fact that you conflate the 2 leads me to believe you don't have much experience with automated testing. Given that, it's not surprising that you can't see the benefits. As somebody who was a successful developer for a decade before I discovered automated testing 5 or 6 years ago, I'm not saying you've been doing it wrong for 14 years but it's very likely that you could have been doing it much better for the last 14 years. I don't get the attitude of "we didn't do it and we were fine". When I was a teen I used to feel that way about seatbelts. The first several years I drove I didn't wear a seatbelt and I didn't die. Luckily I realized just how ridiculous that line of thinking was.
Perhaps I phrased in a way that made it seem that TDD is the only thing I referred to. For a year I worked with a team that stressed code coverage. It had nothing to do with TDD. You could go ahead and code your stuff and after write unit tests to cover as much code as possible. We even went to idiotic lengths as to create automated reflection based testers that will test properties of skinny objects like entities etc. to increase the code coverage. Surely some of those tests were useful, others were complete garbage. I am not saying using a unit testing framework is useless. I am saying that the original poster is right, it's up to your team to decide what works best for them. Modern trends in development is to embrace unit testing, no one disputes that. For my team we decided not to for the most part, with very good results.
Keep it simple. Each test should be "Given this input, I expect this output or behavior". Start small, no input or invalid inputs, check that it fails correctly (negative tests). Then check the minimal inputs. Then add on more complex combinations of inputs. Yes, its as important to validate it fails in expected ways as it is to validate it does things correctly. This way you know it's not just silently passing everything. As you get bug reports that somethings does not work as expected, each should be reproduced using a test(*), and then fixed. Same goes for new features: add the tests, then go implement. (*) there should be few scenarios where unit tests can't capture expected behavior: environmental issues (low memory for instance), and race conditions are the two big ones. Everything else should be isolatable if your classes are correctly built. 
That's what *Find All References* is for... I mean I totally get the idea of unit tests and personally love them, but that said on my own internal MVC projects I've not written unit tests because I can find all references and visually inspect behavior. But then that's not on *huge* projects by any means, which is where I'm sure a robust suite of tests would shine. Since I'm almost exclusively a sole developer on my projects I can get away with that. If I were on a team and a teammate broke something on checkin and I had to figure it out and clean it up I'd be super pissed, and unit tests would help avoid that.
Personally I found the ruby and rails community to be invaluable in terms of the "philosophy" of proper coding, especially MVC and testing. But like /u/xbattlestation said basic unit tests that work for the 80% of cases or even 50% is better than waiting for perfection and having 0% until then. And yes I completely contradicted my other comment but that's ok this is freedomland. I fully appreciate the benefit of unit tests even as I don't write them myself most of the time.
Sorry my phone crashed when it wrote my first post. Why don't you try creating some automated tests for the parts of your system that are the easiest to write them for, and where you are most anxious about bugs? What are the key issues you are facing that you? One key to good software practice is to have good antenna for issues and opportunities. If you can't find useful automated tests after looking then don't bang your head against a wall trying.
Find all references only tells you what's using that class/method, it doesn't tell you anything about how it's being used (Correctly or not), or the edge cases that Unit Tests are particularly good at dealing with. Besides, even if you only have say 5 references using that class, the time it takes you to visually inspect all 5 is about the same time it would take to write one test. The whole sort of "It's only small, I don't need them" or "I am the only developer, I don't need to do anything fancy" mentality is a terrible one to have. All big projects start off as small projects, small projects have a habit of growing and the problem with thinking "I don't need Unit tests" is that it's really hard to know when a bug you later encounter would have actually been picked up by one. It's absolutely worth setting up your test project from the get-go and writing tests as you go along.
Now you know what to test, but with unit tests you could make the change and actually see what breaks and fix it instead of checking it all manually.
Completely agree, my projects are usually small enough though that its not a big deal. But that's not true for everyone so unit tests are very appropriate. But they aren't necessary for everyone in all cases either.
Definitely agree with what you are saying, don't get me wrong. I'm just pointing out that there are viable workarounds that get you through without putting up unit tests. That said, when I have done TDD myself it has been a *huge* safety net and stress relief to have them, so I can certainly advocate *for* them even if I don't personally use them *right now*. :) *Edit* I think part of the problem I have with using unit tests is my work is all MVC and I don't see the point (so far) in testing controllers and views. And the code in domain repositories is generally not that complex and was ported from a legacy product whose queries were thoroughly tested anyway. Plus it is pulling data from a legacy Oracle database and in some cases merging data from another legacy SQL Server database, so writing unit tests for all that would just take a lot of time to validate that it does something it already did well anyway. And I have a fantastic working relationship with my stakeholders who are also the power users and they are very quick to test and give feedback, and we have a very loose and quick dev/release cycle so issues are patched quickly anyway. Like I said its not the same situation everywhere, and this kind of behavior would not fly in a larger team environment. But it does have the unfortunate side effect of reinforcing bad habits. :(
Wrong tools for the job. You want to use something akin to Uservoice. Log4net is for logging messages and information about the process of your application's lifecycle, rather than messages that get logged into a log file. Creative way of using log4net? Yes. Actual benefits to using it this way? None.
Considering how fast MSSQL Server is, I highly doubt that would be the bottleneck. Perhaps create some views in the DB for some of the more complex things you'll need info for. You can pass them to through the controller to the view and use something like D3 to create various graphs and stuff like that. Disclaimer: I've never worked on a heavy stats sites, just throwing out what I would do.
If we're talking strict MVC, then business logic technically shouldn't exist within the controller. It should exist at the model layer (which the controller then calls/passes to the view).
I think ***may be*** being the key words. I am not here to argue, just pointing it out.
writing tests is important - especially if you ever want to go back and refactor any of your code. You want to make sure the program is still working as intended and your unit tests are one of the easiest ways to accomplish this. EDIT: lol, there is someone in here who doesn't like unit tests that is downvoting everyone :p
The "may be" was for "much". It's definitely more expensive. The extent is what's variable. You need to break out of the "this is how we've always done it" mindset. It's a crippling way to think. I've been in the field for over a decade, and I've seen it destroy careers. 
The entire point is that it's up to the team, management, etc. to decide. So ultimately I agree with the original poster. 
No I agree it's a bad idea and people should learn xaml ( I know I had to). Just saying that drag and drop can be a way for people to get easier start (initially). Today people go winforms because they don't want to learn xaml, I'm saying drag and drop in WPF and learn xaml along the way.
Been using AutoMapper for a while. Those benchmark numbers are quite interesting.
If the stats are only for the group of 10 then I would do them real time in the client. Now if you want to scale to a million users some day then you need to start storing the calculated stats as we dont want to query a million picks all the time. This could be as simple as inc a counter for teamA when picked for game x during week y, and inc a total counter for number of picks, then you could easily pull all the counters for the games that week and calculate % in real time. Everytime you store a pick you would inc the counter keeping it up to date, so not batch processing etc... if there is a ton of logic you could queue a message and process them in the background. { gameweek: 1, teama: 5, teamb: 8, teamc: 3, total: 16 } Obviously the above is too simple to cover everything but gives an idea how you can inc or dec counters in realtime and pull those counters in a quick query to calc all stats on client side. Just need to sit down and come up with a nice model. Also I use MongoDB for similar idea, allows for a well structured document that can easily be incremented.
Feedback is relatively simple, all you need is a form that gets the user's feedback and perhaps some contact info, and dumps them into a database, emails them somewhere, or whatever. Allowing users to edit the content of the page without modifying the razor page directly... that's quite a bit more complex. Not a project I'd be eager to take on.
Dynamically Text on Image in ASP.NET C#
You should be able to use the same dependency injection framework. Just like you don't create controllers yourself, you don't create your repository. You set it up as a service, and then inject it to your controllers. The IoC container takes care of resolving the dependencies.
I agree, those benchmark numbers seem almost too good to be true. I might have to run the bench marking code myself to see if I get the same results. I mean this tool is actually faster than handwritten mapping for large objects that is pretty amazing.
I know I am late to the thread, and the existing comments are, almost without exception, excellent advice. That said, I want to directly address something hinted at but not made explicit by other commenters, at least not in the way I'm going to do now: You speak of your "fairly robust UAT process." Would it not be more robust, more consistent, quicker to execute, more frequently-executable, etc. if some portion of it were automated? Your job as a software engineer largely revolves around the automation of repetitive human processes, so why not UAT? Why have a human manually testing, over and over with each tested version, things which a computer could test, sparing the human's time and talent for testing only the kinds of things not well-suited to test automation? One of my absolute favorite projects of the last few years was the one where the development team took test automation so seriously that it resulted in our UAT process amounting to the QA manager reading our test automation report and directing his team to run a few ad-hoc and combinatorial tests, mostly revolving around making sure the app still "felt" right (primarily where related to smooth animation, general UI responsiveness, etc. for which test automation is difficult/expensive in disproportion to having a human spend a bit of time with the app.) Shipping quality was higher, dev was faster and more confident, QA cycles were shorter and the staff far happier, all because we extended the concept of business automation _into_ the development process.
Anyone still using Razor?
Tag helpers are Razor.
And use what instead?
Azure Websites (now App Service) is free with some constraints (no custom Domain/SSL Certs, minimal SQL) up to 10 for a sub last I checked. They go along way for a lightly used app or for dev/test.
Yes you can ignore everything in configuration. Here is an example: protected override void OnModelCreating(ModelBuilder builder) { base.OnModelCreating(builder); // Customize the ASP.NET Identity model and override the defaults if needed. // For example, you can rename the ASP.NET Identity table names and more. // Add your customizations after calling base.OnModelCreating(builder); builder.Entity&lt;Identity&gt;(b =&gt; { b.Ignore(i =&gt; i.AccessFailedCount); b.Ignore(i =&gt; i.ConcurrencyStamp); b.Ignore(i =&gt; i.LockoutEnabled); b.Ignore(i =&gt; i.EmailConfirmed); b.Ignore(i =&gt; i.LockoutEnd); b.Ignore(i =&gt; i.NormalizedUserName); b.Ignore(i =&gt; i.NormalizedEmail); b.Ignore(i =&gt; i.PhoneNumber); b.Ignore(i =&gt; i.PhoneNumberConfirmed); b.Ignore(i =&gt; i.SecurityStamp); b.Ignore(i =&gt; i.TwoFactorEnabled); b.Ignore(i =&gt; i.UserName); b.Ignore(i =&gt; i.Email); b.Property(p =&gt; p.Created).ValueGeneratedOnAdd(); b.Property(p =&gt; p.LastLogin).ValueGeneratedOnAddOrUpdate(); b.HasKey(k =&gt; k.Id); b.ToTable("Identity"); }); }
IBMs Bluemix can host it and it is linux. It is experimental and I think they require Docker, but they configure all of it for you.
Fair enough. A noble quest. Visual studio to azure is so easy though. Then its so easy to scale the server and the geo location. You also get to use azure storage and sql azure. Most of my apps are based on Meteor now and I really miss it.
Complete, working code as follows: public class Product { public int ProductId { get; set; } public string Name { get; set; } public virtual ICollection&lt;Order&gt; Orders { get; set; } public virtual Order MostRecentOrder { get; set; } } public class Order { public int OrderId { get; set; } public virtual Customer Customer { get; set; } public virtual Product Product { get; set; } } public class Customer { public int CustomerId { get; set; } public string Name { get; set; } public virtual ICollection&lt;Order&gt; Orders { get; set; } } and, in the ApplicationDbContext class: protected override void OnModelCreating(DbModelBuilder modelBuilder) { modelBuilder .Entity&lt;Order&gt;() .HasRequired(x =&gt; x.Product) .WithMany(x =&gt; x.Orders); modelBuilder .Entity&lt;Product&gt;() .HasOptional(x =&gt; x.MostRecentOrder); base.OnModelCreating(modelBuilder); } 
I would remove the entity type attributes on the classes and instead explicitly map all of that stuff using the model builder. This separates your entities from knowledge of the data layer. You may also want to look into using [EntityTypeConfigurations](http://www.codeproject.com/Articles/561584/Repository-Pattern-with-Entity-Framework-using). 
even without bizspark using dev essentials gets you $25/month in azure credits so you could get a custom domain and a very small SQL store. https://www.visualstudio.com/en-us/products/visual-studio-dev-essentials-vs.aspx
Sorry, the library I linked doesn't do what I described directly, it's more of a support library (like E.F. to a data access layer)...specifically the claims/permission logic. There is stuff in there you probably won't need, like the more detailed certificate logic, but it is an excellent library to look over even if you don't use some of it . This is the heart of the [claims authorization call](http://www.brainthud.com/cards/5218/5016/explain-the-usage-of-the-claimsauthorizationmanager-class) 
There is something to that. After 20 years of cutting code, my initial reaction to EF was "wow! Awesome!". My first cut of the system I'm writing had a bunch of DB scripts (first thing I wrote). I'm still liking it, but I am becoming aware that my code is now at risk of doing something else on the next version of Visual Studio. And that's not great... But the sheer power of the attribute model is amazing. So little code to cut for basic forms. Even if I had to jump though a couple of hoops to get the text internationalised...
I'm on the tail end of launching a medium sized internal order management app using EF and WebApi. When I started prototyping the app I was amazed at how easy EF made things! When the model was small and simple, it was simply painless. But then I began implementing more complicated business logic, the model and relationships grew in complexity and the edge cases showed EF's true colors. Migrations are a key complaint, especially in a team environment. Using a soft-delete pattern can be a real hassle. But, it sure beats hand writing sql or ORM patterns.
It's not a bait and switch at all. It's an extended (3 year) trial. And it has more or less the same lock in issues you'd have with any cloud provider (e.g. AWS). 
What about a CMS like sitecore? Is it ok for sitecore to create the database while I've got a slick api to work with?
Not true. It's free to use the licenses after graduation. I've managed two companies that have graduated after 3 years. You're even offered to continue on with the Plus level after graduation.
Ah, sorry. Comment prior to OP's is about App Service. My bad.
In his OP, he wanted options like Heroku or OpenShift, of which App Services would be the most closely related Azure service. Linux and Docker weren't mentioned until another comment (which I've now read).
I wouldnt do it yet for production apps.
What the fuck is your problem? Asshole.
I am hearing more about Docker than ASP.NET 5 itself. So I know ASP.NET 5 and Docker go nicely. /u/whooyeah seems to get what I wanted to know. My main goal is not get my ASP.NET 5 app up on the net rather how I can get it up using non-windows and non-MS platform or services to test its openness, cross-platform capabilities and how well it plays with other cloud services out there.
Very good point and it gets confusing when you read stuff saying you don't need to test everything - what do you then leave out? Obviously some things are more important than others, how do you prioritise? And some frameworks lend themselves better to testing than others. One of the great things about Ruby on Rails is testing is heavily baked into the framework so that it seems seamless yet with other times I've felt I'm fighting against the framework when introducing testing and the drop in productivity has me questioning whether it's worth the effort.
* Should we allow job postings? No
Yeah dude people don't pay $16k + for the cms on their shiny new websites if they suck performance wise. 
I take it you've never heard of a little company called SAP? Or another one called Oracle?
For small applications, this will work fine. As your app grows in size, you will find that there is a constant need to keep the registry of resources in sync with your claims issuer and the claims issued tend to be application specific. It is also difficult to test permissions with a unit testing framework when implemented as actions on a controller. I think the thinktecture guys do a good job working around these challenges in their identity model library http://leastprivilege.com/2014/06/24/resourceaction-based-authorization-for-owin-and-mvc-and-web-api/ You may also want to implement something about the method being requested, for example read/write ~ GET/POST.
What did you do to make them consistent? 
Still haven't done that, but I have successfully switched it from a release only problem, to a debug only problem lol. I moved the jqueryui css in the same directory as the icons and then made a style bundle with the value of "~/Content/jqueryui" rather than "~/bundles/jqueryui"
Having your bundle names the same as actual paths can cause other problems (sorry, I can't think of what they are off the top of my head).
ReSharper should NOT be just blindly followed. It simply shows you logically equivalent code transformations. The developer still has to use some kind of judgement and skill in writing their code. I personally got pretty damn good at LINQ by letting it transform all my codes, understanding the transform, undoing it, and trying to write it a little more elegantly by hand if the transform was even close to valid.
That is a great point and one that I did not emphasize in my post, rather I just sort of implied it. By stating that I ignore some of the 'more clever' recommendations it makes because I can't understand the code transformation, it implies that I read/understand/can apply myself most of the suggestions except those edge cases. :) I learned the hard way not to trust its suggestions blindly, I ran to analyzer and told it fix all it for the first time 5 years ago on one of my projects and it never compiled correctly again (another reason for source control even if a solo dev kiddos!!). NEVER USE FIX ALL - EVALUATE EACH RECOMMENDATION ONE AT A TIME! 
You can swap out your session provider and use something like Redis cache. This gives you a session server which eliminates both of the problems you mention; and then you can use the the regular session class in code. 
I've found it pretty difficult to make EF use an existing DB. Can't say I'm an expert at that however. I'd just hand-build (or generate) models to match the DB and use LINQ queries on those models.
Ok, after many days away from this I had to return and try to finish this. My error is still the same...I can access my application inside my server but, outside, I can't. I mean, if I activate the directory browsing in my site, I can access the directiory of my site but only that. I can't see my site running. The error I get, if the directory browsing is not enabled, is HTTP 403.14. I looked it up and none of the "solutions" worked. So, if someone knows how to solve this, help me please. :) EDIT: Can someone explain me how the bindings work? I think the problem might be there...since everthing else seems fine.
Any idea dude?
Am I mistaken; isn't OAuth a pattern and JWT is just a token format (just like SWT is a format)? You can use OAuth with a JWToken.
Same with every other task. Break it down into smaller sub-tasks (create QR code image, display image, read webcam image, parse QR image from image). Then concentrate on one task after another and look up information on the specific task.
Controllers aren't front end though. That's still backend. Might want to do some more reading because these aren't competing technologies (with the exception of node as for backend). I'm a C# dev that has been doing single page applications with angularjs frontend and Web API/MVC backend.
Javascript (meaning NodeJS) became alternative framework to ASP.NET MVC, its growing, it has big and vibrant community. But MS almost released the new web stack (.net core) that will move forward the whole platform, and align it with other stacks (node, ruby, python). I think nobody can say if nodeJs will completely replace asp.net, and if that happens, it will be in 5-10y. So, ASP.NET is still viable choice, but only with the .net core. There's a really small possibility that community will not accept the new programming model, but I really think that will not happen since is so much better for web and cloud. And for desktop/xamarin, c# is here to stay. Investing time in learning that is quite safe, since for win desktop dev there's basically not alternative. And xamarin, well, anything can happen there, but knowledge learned building droid/ios stuff can be re-used since xamarin is not an abstraction, but more just c# wrapper to native concepts - much better if you want to switch to swift/java. Also, in the brave new microservices/cloud world, you would build front end with angular/node, backend with .net/corefx, mobile with xamarin or even phonegap. Meaning, use the best tool for the job. With that, c# covers many platforms, so I would say it has a good ROI:) You can't go wrong with either for these platforms! 
&gt; I think it'll be a while before it replaces C# or Java in the enterprises. I think it'll be never.
&gt; a fad. It's useful, but overhyped. As we Not necessary, with ES6/ES7/Typescript, bigger and more complex projects can be delivered. But, the philosophy of JS is different than what we usually see in .NET - ppl are building smaller apps (microservices/soa) and they are easier to write, maintain and deploy, compared to VS solution with 50 projects and thousands of lines of the code, which is quite usual in .net. Corefx is also going into that direction. Btw, ES7 look almost like c#. I would even say, the strongest selling point of JS/Node is not the language, but the whole platform and community. Just take a look at number of OSS projects/middlewares in node!
Not to this extent as we've seen the last 2 years. I hoped you understood this implicitly, unless you are trolling.
Yes maybe some common claims could be created that can authorize multiple actions. But resource based authorization is also same I believe.
i just tested it: Tools-&gt; Options -&gt; Fonts and Colors -&gt; OverviewBackground 
I don't know what trolling means anymore.
For the big three: - **XSS** - The Razor view engine escapes any output by default unless you use `Html.Raw()` - **CSRF** - You can decorate actions with the `ValidateAntiForgeryTokenAttribute` and use `Html.AntiForgeryToken()` in your views for automatic CSRF protection - **SQL Injection** - If you're using an ORM like Entity Framework this is taken care of for you, but otherwise the usual protections exist such as [named parameters](https://msdn.microsoft.com/en-us/library/yy6y35y8\(v=vs.110\).aspx).
Basically yes.
I am glad I found this post, and I am glad that you commented, because I removed that same update and lo and behold my website started working. A question for you if you don't mind: Has this problem re-occurred for you or did your problem remain solved? I am concerned that the next update will bring down the website again.
Unless you count TypeScript as JavaScript, we're actually going away of Javascript and will use TypeScript in the future. 
Fuck no.
Ever been forced to use Websphere on Bluemix? The node.js option starts looking pretty good.
But isn't getting the tool to auto-generate the HelloWorld program for you actually cheating? &gt; You can "dotnet new" and get hello world. Surely the whole point of HelloWorld was always that it was the first program / source code you write when learning a new programming language.
My guess is the code was originally written before covariance and contravariance was added to C#. Set the solution to compile in .Net 2.0 and it should fix the issue. Don't hold me to it but I can look into it more tomorrow. The ambiguous reference is because the compiler doesn't know what method to link up. Type DBRecordCallback inherits from type object so the calling code matches both methods. Hopefully that helps you out a little.
The reason you write it is to learn. You don't learn it just to write it. 
Thanks! Not sure it's 2.0 because it requires linq, and I don't seem to be able to add a reference to any linq assemblies when the project is set to 2.0.
Linq was added in .net 3.5 so try that version.
I'll take a look at it in the morning and see if I can help you out.
This code produces the error in the post above: public object[] ExecuteReadEach(string sqltext, DBRecordCallback populator) { return ExecuteReadEach(sqltext, populator, null); } It doesn't know whether to use the `DBOnErrorCallback` parameter or the `DBContextRecordCallback`. I can cast the null to fix the error... but I'm not sure what was intended. I guess the compiler must have changed at some point. Maybe I'm not setting the compiler version correctly, I'll have to look at it later.
Look at what that second function is doing, and what it's called.
Each method with an ambiguous reference should call its own overload. Why .net doesnt recognize this is beyond me. Resharper does, so here is my fix: https://gist.github.com/Jogai/b2a68f347efe12e76c47/revisions?diff=unified (Just done the fixes with resharper)
I don't think this post adds much value over the original Hanselman post. 
Avoid TempData like the plague.
1. Can you profile the database to see if it's actually being queried when the old data is returned? Maybe your code (or a library) adds a cache that isn't being invalidated. 2. Are you using the `.Find` method? It seems to use a form of caching and you may want to try using `.Where` instead, which doesn't cache. https://msdn.microsoft.com/en-us/data/hh949853.aspx#3
I'm sorry I did not get that. I am new to Unity.
/u/AbstractLogic makes a good point. From what I can gather in the [Unity docs](https://msdn.microsoft.com/en-us/library/ff660872(v=pandp.20\).aspx) a "container controlled" lifetime means it exists until your UnityContainer is disposed (which is probably never). `TransientLifetimeManager` seems to be what you're looking for. To be honest, though, you should be able to reuse the repository and still get new data from the database (unless your repo does extra caching on top of EF).
I dont have anything that can add Cache. But I will try to profile the database though.
Lifetimes are very important to understand with IoC. I recommend reading up on them [here ](https://msdn.microsoft.com/en-us/library/ff660872(v=pandp.20).aspx) Real quick question. Can you show me your repository? I can probably tell you exactly what's happening after I see that code.
Here you go: public class BaseRepository&lt;TEntity&gt; : IRepository&lt;TEntity&gt; where TEntity : class { internal ApplicationDbContext Context; internal DbSet&lt;TEntity&gt; DbSet; public BaseRepository() { Context = new ApplicationDbContext(); DbSet = Context.Set&lt;TEntity&gt;(); } public virtual void Insert(TEntity entity) { DbSet.Add(entity); } public virtual void Update(TEntity entityToUpdate) { DbSet.Attach(entityToUpdate); Context.Entry(entityToUpdate).State = EntityState.Modified; } public virtual void Delete(object id) { var entityToDelete = DbSet.Find(id); Delete(entityToDelete); } public virtual void Delete(TEntity entityToDelete) { if (Context.Entry(entityToDelete).State == EntityState.Detached) { DbSet.Attach(entityToDelete); } DbSet.Remove(entityToDelete); } public virtual void DeleteAll(Expression&lt;Func&lt;TEntity, bool&gt;&gt; predicate) { var entityListToDelete = DbSet.Where(predicate); foreach (var entityToDelete in entityListToDelete) { Delete(entityToDelete); } } public virtual void Save() { Context.SaveChanges(); } public virtual TEntity Find(Expression&lt;Func&lt;TEntity, bool&gt;&gt; predicate) { return DbSet.Where(predicate).FirstOrDefault(); } public virtual TEntity FindById(object id) { return DbSet.Find(id); } public virtual IQueryable&lt;TEntity&gt; FindAll() { return DbSet; } public virtual IQueryable&lt;TEntity&gt; Table { get { return this.DbSet; } } public virtual IQueryable&lt;TEntity&gt; FindAll(Expression&lt;Func&lt;TEntity, bool&gt;&gt; predicate) { return DbSet.Where(predicate); } public virtual IQueryable&lt;TEntity&gt; FindAllIncluding(params Expression&lt;Func&lt;TEntity, object&gt;&gt;[] includeProperties) { return includeProperties.Aggregate&lt;Expression&lt;Func&lt;TEntity, object&gt;&gt;, IQueryable&lt;TEntity&gt;&gt;(DbSet, (current, property) =&gt; current.Include(property)); } #region IDisposable public void Dispose() { this.Dispose(true); GC.SuppressFinalize(this); } public virtual void Dispose(bool disposing) { if (disposing) { Context.Dispose(); Context = null; } } #endregion } Then I have entity specific repositories like below: public class OrganizationRepository : BaseRepository&lt;Organization&gt;, IOrganizationRepository { }
Is there a better alternative? 
&gt; you're suggesting c# is not a front end tool C# is not a tool, and definitely not a front-end language.
I thought C# was a multi-paradigm programming language for backend like windows desktop programs, database, backend server etc why this guy is saying it's a front end tool and things like that ? 
Can you show my a small class that uses this repository? I have theory formed now and a good number of notes for you. I just need this last little bit to confirm my suspicion.
Some interesting stuff and some interesting problems!! I'd like to just give you some notes I have first then try to explain exactly what the issue is. * Your container is alive for the entire duration of your application. (This is common). * The ContainerControlled lifetime manager forces any object in the container to live for duration of the container. This creates a Singleton of those objects. In other words, any request to your container for that dependency will return *the exact same instance* of that dependency. If multiple users are on your website at the same time and each sends a requests to you'r Controller (assuming MVC) both users will get *the exact same instance of the object*. You have essentially made ever dependency Static or a Singleton which can cause multi threading issues if you are not careful! * Most people use a PerResolveLifetimeManager if they are doing a WebService (REST or MVC). This means that every *Request* to you'r controller will *new* an instance and that instance will be disposed when the request is finished. Anything within the scope of a request that requires a dependency will get the same instance of that object. (Basically only one instance of the object ever exists for a single request but with multiple requests you will have multiple instances). * Because you have newed up your Context inside a class that is a Singleton your entire application only ever has a single context to interact with. **This is bad** because a Context is not thread safe and you have set it up in such a way as to cause multi-threaded access to the Context. Like *realllly bad*. The Context will never get disposed and your application will run out of memory as well as causing multi-threading issues such as table locks and disposed connections. * I see that you are using .Find off the context. Did you know that this will search your *local context memory* first and then perform a database hit? It can be good for performance reasons but can cause unusual bugs if you are not aware of it. OK, So whats going wrong? My guess is that you have two repositories working, RepoA and RepoB. You are doing something like RepoA.Find(id); RepoB.Update(id); RepoA.Find(id);. Because the Find will search internal memory first THEN hit the database it is finding the object pre-update. But that is a guess. 
Well, with Node.js, it's more like Javascript being on the backend, than C# being on the front. JS is a language, not just a front-end technology. A language can be made to run anywhere by someone sufficiently motivated.
because the visual designer sucks terribly. Once you start seriously playing with 3rd party controls and offline data sources the designer view gets pretty much useless without a bunch of careful hand-holding. Get used to the XAML it is the way to go when making pretty much any adjustment. As a note when you start pulling your hair out. All UI systems suck pretty hard, human machine interaction is not easy to get right and requires a lot of "mushyness" because well....people. That said, as much as XAML and WPF sucks, other systems are even worse versions of hell for UI in many cases (but everyone sucks in different ways so we can argue forever about what is really better). Good luck and pick a good text color-scheme and font, it will help immensely. 
Check margins, etc. But yeah, the visual designer is weak. Expression Blend is better, imo, but there is still no substitution for knowing xaml firsthand.
Expression Blend is better, even though it has its own weaknesses. And as you pointed out - it's very helpful to have a firm understanding on managing the design-time stuff to maximize utility of the editors. But ultimately there really is no substitute for working with XAML directly.
Well shoot, that might have just finally made me agree that this was a good design change...
EF had a built in second level cache. It will try to load from its cache first before going to db. If you aren't disposing your context at the end of a request, or detaching all tracked entities I suppose, though if never do that, then it won't ever go back to the db. Ergo, a repo with an application lifetime scope, as I believe op has written here, will only ever pull from the db the first time.
Bingo. You want a transient scope by default (new instance every time one is requested), and you want to explicitly make your EF context have a Web Request scoped lifetime most likely.
I think I get it now. So, all I had to do was change my unity config to this: container.RegisterTypes(appDataAssembly.GetTypes(), WithMappings.FromMatchingInterface, WithName.Default); Then by default TransientLifeTimeManager would be used.
Both your blog posts are so tiny, why not just put them in one? Also, great to see that you are **only** posting your own stuff!
Both your blog posts are so tiny, why not just put them in one? Also, great to see that you are **only** posting your own stuff!
I post just links here to promote my blog a little bit and to have my contents on a single place only. I also want to share the contents here to have another platform to discuss the topics. Hope that's OK :)
I post just links here to promote my blog a little bit and to have my contents on a single place only. I also want to share the contents here to have another platform to discuss the topics. Hope that's OK :)
You wrote all of that, now you're giving up?! POOR SHAME EFFORT! Does Twitch require SSL? I have only connected to Twitch maybe once with an actual IRC client, but can't remember how it works. I don't really know C# but I'd be happy to help you out with the IRC RFC / issues you're having
Ahh I get what you're rambling on about, that's a standard IRCLib and you're looking for one that works with Twitch. Well, in that case I can't help you! .. Well, I probably could, if you wanted to not use a library and just create it yourself. I'm sure the difference on a Twitch server will only affect an IRC Client if it looks for too much detail from the server. For example, in this case, the IRCLib was hunting for the start of a channel, but Twitch doesn't provide detail on that (probably because it doesn't care and it's always the same)
[IRC.NET](https://alexreg.github.io/IrcDotNet/) They even have a Twitch client as one of the samples.
that right there used to be called "blogspam". And back when I joined Reddit, it was a paddlin'
Posting your own stuff is not bad. **Only** posting your own stuff is. Don't use Reddit as a cheap self-promotion platform. Instead become part of the community!
Admittedly this is self-promotion. But I wanted to share it with the community and see if the content is interesting enough for discussion or debate.
I've used ChatSharp for Twitch IRC in the past. I might have had to make some very minor changes, if you debug and look at the messages going back and forth on initial connection it should help you out. On the connection complete event make sure you join the channel. It really doesn't take much, just debug step through the logical pieces to see what you need to change if you want to use ChatSharp.
Blocked meaning?
I cannot access the website because I am behind a corporate firewall.
I followed [this doc](https://github.com/SonarSource/sonar-.net-documentation/releases/download/1.2.0/SonarQube-Setup-Guide-For-Net-Users-v-1-2-0.pdf) and had success. Page 18 has the details for setting up the MSBuild runner. The caveat here is that it's targeting TFS 2013+. Shouldn't be terribly different for 2012, but your process template might have some nuances. The trickiest stuff I had was java and NetFx4.5.2 related. The MSBuild runner likes that version. Otherwise, you shouldn't need to dig in to your process template. I used the default 2013 template. Just applied the Pre-Build and Post-Test commands &amp; args.
Our network guys would get a gazzillion angry emails if reddit was blocked.
You can download [NancyFX Succinctly](https://www.syncfusion.com/resources/techportal/ebookconfirm/nancyfx/sitevisitors) here
First off, if you are using npm, don't use gulp, grunt, bower or Cassette. Use webpack. between npm and webpack, you can do 99% what you need. Take a look at [this](http://blogs.taiga.nl/martijn/2015/12/10/develop-reactjs-asp-net-web-api-apps-in-visual-studio-2015/) and see how simple it is (ignore the react stuff and do your normal views as you normally do) Then install [NPM Scripts task runner](https://visualstudiogallery.msdn.microsoft.com/8f2f2cbc-4da5-43ba-9de2-c9d08ade4941) to use "scripts" commands to do your deployment as "after build" tasks. For example, in my package.json for the VSReact.Web project: "build-release": "webpack -p --config webpack.prod.config.js --progress --colors &amp;&amp; cp web.config c:/inetpub/wwwroot/VSReact.Web &amp;&amp; cd release &amp;&amp; cp * c:/inetpub/wwwroot/VSReact.Web" If you use git, you have a .gitignore file which handles what doesn't get checked in.
[Suave](https://suave.io/) is on my list of things to try out (not to mention F#) when I have some free time. Which seems to be never these days...
Did you intend to post the method bodies? Can't see any switch statements here.
Done. See the edit.
Yeah, thanks. That is what I ended up doing.
Asp.net has languished in recent years... This is why MS "scrapped it" in the newest version (ASP.NET 5). The new version and its tooling VS / VSCode are first rate and are worth looking into. MS has integrated a lot of the great Node tools (NPM, task runners etc) into visual studio now. If you like c# stick with asp.net, if you really like javascript (type, dart...) go with node. It's really more about what makes you most productive.
I think it is mostly a religious war. Personal, I write C# on my front ends (Unity / Xamarin) and enjoy the code reuse of having C# on my back end. Ive had to used PHP and other 'untyped' back ends in the past, and it has been painful. Ints and Strings, Strings as bools, Json inside Json inside Json. Another key thing to keep in mind is the data layer. the 'MEAN' stack advocates monogo... which again is a storage system for untyped data. Great for prototyping, but, harder to use in the long run than typed and relational SQL. As far as performance, it is my understanding that Node.JS is single threaded. It has a 'coroutine' system for concurrency, but, it is not a true multi-threaded environment. I am not how much of a penalty this is. As far as being 'open source', both are open source. Both can (now) run on linux. In the end of the day, go with what you are comfortable. I know there is nothing I can not achieve with a C# back end (at least up to a StackOverflow), so, I will stick with that. I have dabbled in node.js applications and while I found many analogous features I am not going to worry myself with a new API and battling unknowns when I can spin up a prototype up in an hour or two with C#.
Superior in what way? As far as performance, not even close. Node.js is an Interpreted language (sorta) and .NET is a JITed language. JITed/Compiled languages will always beat an interpreted language in raw performance (not 100% true as you could write shitty C# code that runs slow). There are a huge number of performance benefits if you compile your language and Microsoft keeps improving the speed of the JITer. Node.JS's big selling point was it supports Non blocking requests (basically if there is a long lineup of people requesting pages on your website all at once if the current page being loaded has a long running operation like a database call Node.JS can start working on another web request while it waits for the database to respond in a previous request). This has been supported in .NET for a while now, C# has native language support for doing stuff like this with its async/await keywords and Node.JS uses a bit of an ugly callback passing pattern (some node.js libraries make it better but not all). However, I've worked on a ton of Web Apps and lots of companies are not yet using async/await effectively in C# yet were in Node.js your forced to. That being said, if someone asked me what language to learn if they were just getting into web development I'd say start with Node.Js. Javascript is used heavy on the client side and if your new to web development learning CSS/HTML/Javascript and C# might be enough to scare you away. I think for this reason a lot of web designers are using Node.Js as they already know javascript and have no desire to learn something like C#. It also makes your solution cleaner with all code being the same language, and if your developing a really simple web app (which is the case in almost all of the Node.JS apps created) your Node.Js code is more of a WebAPI like layer and there is not a ton of logic. C# also has the advantage of being able to do a ton more then just web apps where Node.js is primarily used in Web Apps. I would say whether one technology is superior to another all depends on the problem your trying to solve.
Wow. Quarter-century doing websites, and almost all of the entire orange front-end stuff is completely foreign to me. On the surface, it just looks like a bunch of â€˜make-doâ€™ and â€˜quote-enhancingâ€™ stuff meant to plump up the accounts receivable line item on the company financials to the detriment of the clientâ€™s pocketbook. Does all that crap really speed things up or enhance things more than doing it raw? His comment on ASP.NET -- wait, what?? What is he smoking, and can I have some? You work in any large company that has to integrate web content with desktop content over databases, and youâ€™re working with ASP.NET and MSSQL 9 times out of 10. It also holds up under stress a hell of a lot better than PHP, Ruby or a few others I donâ€™t care to mention. The only other platform that can whip ASP.NETâ€™s arse in stressful situations would be Java.
It seems a great resource! Thank you! ;)
I don't get it. Why do you keep spamming the same questions over and over? https://www.reddit.com/user/kevinmarenger
I've played about with Node a bit and used it in production my only issue is that it uses JavaScript which I can't get on with and feels a backward step after working with C#. That said it's adoption has exploded and it's now seriously challenging the existing established enterprise Java and .NET VMs. Others have commented that it's primarily used for web apps but it's being used everywhere now - Visual Studio Code is a Node app for example. In fact (controversial statement here) I'd suggest Node will be more important to MS than .NET over the coming years which is why MS forked it's own version and has been investing in it heavily.
I disagree with all 3 solutions. I would propose the following: - Move the code from the `default` case to the `FailureCase`. - Throw an `ArgumentOutOfRangeException` in the default case. The enumeration has only four different values, for each he has a distinct use case. If there would be another value inside, then this would be completely exceptional and unexpected.
aspnet5 is much more lightweight
Its much more modular, if you build for coreclr x64 you only need to include the features you want (including the .net framework) - its cross platform (windows, mac, linux) and can be up to x20 faster. Though it is quite different to aspnet4.5 Might want to watch https://channel9.msdn.com/Events/Visual-Studio/Connect-event-2015/100 (15mins)
Yeah I noticed.
Thank you.
Thank you for your response. I've been away from this project for a bit. Sorry to take so long to reply. I guess what I was thinking is if I had a Help Model that could be referenced within other models (Appointments, Notes, Students, etc.) I could pull up these related rows for the different Views for these other models, but is there a way to reference a view? UPDATE: In doing a quick search for MVC View Helper, I found this [SO post](https://stackoverflow.com/questions/24291466/net-mvc-5-view-helper-function-returning-boolean) that touches on what I was thinking. Or am I misunderstanding what the user Mediator is saying about "You can create extension for System.Web.Mvc.WebViewPage and call it in a view like @this.CompareModelIdAndUserID();"
My guess is that you just switched to VS 2015? I had this same issue with an MVC web project. My solution? I had to keep using VS 2013 for the project. I can still use VS 2015 for it, but I can't use it for the razor code parts. I don't recall the direct issue but it was something to do with MVC support in VS 2015 for older versions.
Try cleaning the solution from Build drop-down menu and re-build after. 
Node is event based and therefore non blocking unlike IIS so it's a lot quicker for socket based applications. And since this is the trend for modern web apps Node lends itself better to this sort of thing than traditional web stacks such as IIS and Apache. That said the king of them all for event programming is the Erlang VM which powers about 90 per cent of the world's phones and is lightening quick (if you're interested in that sort of thing). The problem with Erlang is the language is even worse than JavaScript so it hasn't been a pretty productive platform to work with (whereas Node wins because everyone working with web apps knows at least a little JavaScript). However there's a new kid on the block for the Erlang VM - Elixir - and I'm highly impressed from what I've seen. The language is probably best described as functional Ruby (the syntax is almost exactly the same). I've been looking at the Elixir web framework Phoenix and it looks a lot more fun to work with than Node.
If it builds correctly then that means that the designer is referencing the wrong dll, but it gets corrected on the build. I have seen this happen when you update visual studio on your computer. The first thing to do is to make sure that the versions in your web.config files (both root and in the Views folder(s)) are correct and match what your project is referencing. If that is all correct then you might need to clear your user settings. This is done from the command line, but i don't have the command in front of me.
I will try this, thanks.
Still, you should move things together. How do you even source control something that's spread out on two disks?
Apologies, quite right I meant traditional ASP.NET apps. Although as you say newer versions do now have async which improves the situation (and the benchmarks I've seen suggest performance is close to that of Node in this area).
As I amended in my OP, I created a second (dummy) project exactly where VS2015 wanted it, and left it there. It exhibited the exact same issues, despite being all together in one spot.
Yes it is. Look in the System.IO namespace for info on how to interact with the file system. Be aware though that if you store files on the web server, this will make it difficult to scale the application over multiple servers, unless you are storing the files on a network share. 
What happened when you tried it?
Nothing he's hoping you finish his homework. 
This is how security breaches happen. Do not take a folder name as unfiltered user input and then blindly trust it to construct a path to the local filesystem (which I'm sure you're trying to do here). Create a lookup table to present the client with IDs, then on the server end use the lookup table to turn it into a real path.
Do you have a class or view named "System" in your code. If yes try renaming it.
I saw that... But I also saw an example of downloading files through http requests. What's the better approach? 
Yeah, you're right. I'm going to change that.
 System.Web.HttpResponse response = System.Web.HttpContext.Current.Response; response.ClearContent(); response.Clear(); response.ContentType = "text/plain"; response.AddHeader("Content-Disposition", "attachment; filename="" + ";"); response.TransmitFile(System.Web.HttpContext.Current.Server.MapPath("file.txt")); response.Flush(); response.End(); I found this code to download a file. In this, where do I need to declare the path to the file? I tried in the transmiteFile but it doesn't. Any help? EDIT: The web api needs to be deployed in the server, for this to work? 
Is this using .NET Native to build that dll? I thought .net native was only working on Windows Phone apps right now
Because most people don't write small methods or classes. Your classes should do very little. A unit test should test one thing and one thing only. Integration tests tests whole portions of a system. That's why beginners fuck up. Also a lot of people don't understand the importance of the Solid Principles.
What is the significance of returning a status code rather than void? As far as I'm aware, the C# entry point should be a `void Main` method -- what makes this work if it's against the specification?
console apps can also return int. https://msdn.microsoft.com/en-us/library/0fwzzxz2.aspx
Sure, why not? 
Try this out: http://dotnetify.net/
If your clients have Windows 7 I'd stay with Windows 7. Don't play with your working environment. Use a VM or buy another cheap box.
&gt; Why is Kestrel package mandatory since WebApplication type is dependent on it? It is not mandatory. The WebApplication type is in the `Microsoft.AspNet.Hosting` package, which has no dependency on Kestrel. It is actually the other way around. However, you need a server to actually host your application, which usually is Kestrel. &gt; Why does "web" command gets added automatically even when I delete it from project.json? This is likely the doing of Visual Studio. Why does it bother you? You need a command to start your application (for now), and the standard is to use `web`. &gt; What is the minimum IIS version required to host ASP.NET 5 apps? The officical minimum version is IIS 8. However, the IIS itself does **not** host the ASP.NET 5 apps. Instead you use the `HttpPlatformHandler` which will listen for requests, then **forward** them to the actual hosting mechanism (usually Kestrel). So the IIS is actually just a proxy. See also: https://azure.microsoft.com/en-us/blog/announcing-the-release-of-the-httpplatformhandler-module-for-iis-8/ &gt; Dot net cli is being developed so will that replace current dnx and dnu? Yes, the dotnet CLI will replace the current dnx and dnu tools. In fact, most of the code was copied from dnx and dnu. ASP.NET 5 RC2 will be using the new CLI. See also the road map: https://github.com/aspnet/Home/wiki/Roadmap#rc2---move-to-net-cli
MVC has a very specific way of defining lists in form models, I would suggest you use the Html.TextFor etc helpers to get this right. It's easy to mimic (something like "list[0]__Id" in you name/id fields) but I'd just use the helpers to be sure.
thank you - I was not aware of the helpers. I will look into them.
unfortunately for you VB went out of style 10 years ago. Most recent books out there will be getting existing VB developers up to speed with new, more advanced features because I don't think you'll find many people advocating starting with Visual Basic anymore. Assuming you can't get out of it and go with C# instead, the learn in 24 hours books typically get updated with each new release and will probably be sufficient to the purposes. 
Disclaimer: I haven't actually used MVC 6 yet, so there's a possibility some of this could be different from 5.2. First off, why are you pulling the items from ViewData, instead of just using the strongly typed model? You've already declared the model, so `foreach (var item in Model)`is the same as what you posted. You should use the helpers, as other comments have mentioned, but that alone won't fix your problem. With the manual foreach loop, you'll end up with entries like `@Html.EditorFor(modelItem =&gt; item.Pct)`, and the problem with this is that every item in the model will end up with a name like `item.Pct`, so the collection won't bind correctly. For binding to work, the items need to have an array index, like `item[0].Pct`, `item[1].Pct`, etc. The ideal way to do this is to make an editor template for your model item. If the model is just for this controller, create the editor template razor file in `Views/{ControllerName}/EditorTemplates`. If it's shared between controllers you can place it in `Views/Shared/EditorTemplates`. The name of the view should match the name of the model class. Now give it a model `@model todoy6.Models.ToDoListItems` and stick the contents of the foreach (the tr and everything in it) in the file, after switching them to use the helpers. Now back in your main View, replace the foreach loop with `@Html.EditorForModel()`. MVC will take care of iterating the collection and naming everything properly for binding. Now, last step, your Action needs to change to `ActionResult Index(ICollection&lt;ToDoListItems items)` and of course the code needs to handle looping over the collection and saving everything. This all works great, as long as you don't need to change the order of the items in the collection, or dynamically add/remove.
FWIW, the way I handled this was to setup each item as it's own HTML form with it's own place to POST to. This pretty much eliminated any client-side issues screwing up postbacks. This upgrades nicely with ajax too since all the endpoints are independent.
Don't sully your brain with it.
Does each record have its own Save button this way? I would like one Save button to save the entire page of records.
How exactly is that hacky? The term I'd use is "works with web standards and isn't dependent upon javascript for basic functionality." 
Yup -- each would have it's own save button. I didn't know one large save is a requirement, if that is the case then you can do what /u/Merad suggests.
He's on MVC6 and using tag helpers. They should be functionally equivalent, right?
Ah, fair enough then. Sorry I misread your post.
Here is what I have done. The model class name is ToDoListItems 1. add folder to Views: \ToDoListsController 2. add folder to #1: \EditorTemplates 3. add View to #2: ToDoListItems.cshtml 4. modify #3 with: @model todoy6.Models.ToDoListItems and the contents of @foreach loop (&lt;tr&gt;...&lt;/tr&gt;) but not the @foreach itself 5. replace @foreach in View with @Html.EditorForModel Helpers are written like this: { &lt;tr&gt; &lt;td&gt; @Html.DisplayFor(modelItem =&gt; Model.ID) &lt;/td&gt; It looks like the View does not know where to find the EditorForModel ToDoListItems.cshtml Does the View know how to find it by the use of the controllername for the folder in Views? 
You've been downvoted by others and I'll explain why. VB.Net is a fine language. It compiles into the CLR exactly the same as C#. There is nothing you can do in C# that you can't do in VB. You might have to do some things slightly differently. But you can still do them. I use C#. Most .Net developers do. But none of us look down on VB.Net. Hell, us old guys used to write VB before the .Net part even existed. There is nothing wrong with using VB today. If someone prefers it then power to them. I agree it's not fashionable. And most samples and examples are C# today. But if someone wants to use it then so be it. Especially if it helps them get into .Net. 
Unless something has changed in MVC6 you should have already had a folder under Views matching the first part of the controller name, where your Index.cshtml file is located. E.g. `FooController` would have `Views/Foo/Index.cshtml`. So for you it would be `Views/ToDoLists/EditorTemplates/` `EditorForModel` and `EditorFor` will automatically look for templates matching the name of the class you pass to them in an EditorTemplates folder under the controller or shared view folders. DisplayFor works the same with display templates, except they go in a DisplayTemplates folder. 
TBH - I genuinely don't believe that VB.NET has really surpassed JavaScript but I'm at a loss to explain the numbers
Okay I will check that out. Thank you for your help it is very much appreciated.
And here is my biggest problem with SO, you'll likely see no answers and if somebody does take the time to write out a well educated answer he will get max 5 upvotes. Meanwhile my answer on "How do you do checkbox" has over 1000 upvotes.
Agree, I think it shows how unreliable these things can be. VB.NET almost has legacy status now.
As far as I know, they literally just google "x programming" and count the results, and "visual basic .net programming" does indeed have about twice as many results as "javascript programming". That's also why COBOL is supposedly five times as popular as Bash, no one searches "bash programming". My guess is that javascript has more varied keywords, e.g. "js", "jquery", "node", and arguably the various transpiled languages.
My apologies - this is MVC 5. I have edited the original post.
You can return image URL from the view-model and set this URL as image source. Make a common Web API(or specific to entity, whatever meets your requirement) method to serve images. This way your view-model will become light weight.
Did you install the latest ASP.NET 5 tooling? It does not come with VS2015.
Microsoft Virtual Academy (https://mva.microsoft.com/) is also really nice. It's free and it has a section for beginners... It's not as good as PluralSight though :)
I would suggest you check out the JSON.NET library (http://www.newtonsoft.com/json). This makes it simple to serialize various .Net types to JSON, including string arrays. They have a bunch of code samples, here : http://www.newtonsoft.com/json/help/html/Samples.htm Hope that helps. Enjoy! 
I agree with most of these points, actually. A couple of additions: - VS2015 finally has Extract Method for VB - Option Explicit is on by default (thank God). Option Strict is not, sadly. I'm not sure exactly what you mean by name spacing being more confusing. Are you referring to Modules being "auto-imported" and thus often polluting namespaces? I think that's actually a stealth feature, because it's trivial to wrap a Module in a Namespace, but in C# it's *not* trivial to make a static classic automatically imported if you so desire. Also, I think case insensitiveness is great and that's actually one of the few things I dislike about F#. But I know I'm in the minority there.
I am on ASP.NET 5 -_-
Agree with the commenters here, if you're starting from scratch I'd forget VB.NET, it almost has a legacy status now. I'm not a VB.NET hater at all but from a practical point of view you'll find most tutorials and open source software uses C#. Moreover C# is party of the 'C' family and as you become a more experienced programmer you'll find it easier switching to other languages. I come from a VB6 / VBA background and was a bit daunted by C# at first but it didn't take me too long to get up to speed - in fact the jump from VB6 to .NET I found much harder.
It might be worth either chaining the calls together (post the data, then on success post the image to a separate endpoint) or create a more task-based UI that pushes the user down the path of uploading the image in isolation.
Right, my bad. Anyways, my view imports looks like this: @addTagHelper "*, Microsoft.AspNet.Mvc.TagHelpers" But still no IntelliSense.
The goal was to move away from the bloated "you-get-everything-under-the-sun" model of System.Web and replacing it with an a la carte pick-what-you-want model through multiple NuGet packages: http://docs.asp.net/en/latest/conceptual-overview/aspnet.html
Do you have resharper installed? I have found that resharper's intellisense can conflict with 2015 when using asp.net 5. If you are using it make sure you are using the latest version 10.0.2 I believe. Also you might want to clear the resharper cache and suspend/restore it to see if that helps.
System.Web is part of the IIS. So as long as you have a dependency to System.Web you also have a dependency to the IIS. And the target is to support multi platform (Linux/Mac) as well as multi hosting platform (Kestrel).
No resharper only VS 2015 Community.
Few more questions I have after proceeding further: 5. When I run the application where is it run from? Inside artifacts, bin and debug folders seem to be empty. 6. How can I package core with my app for deployment?
If you are looking for something free you can always try this. https://learnxinyminutes.com/docs/csharp/ Might not be the best, but should get you started.
Haha, yeah it caught me out a while back when I started messing with tag helpers. None of the tutorials ever seemed to mention it.
So, for now Kestrel is the only hosted instance there is to serve ASP.NET 5 apps? Where can I find more information on this? Any links?
I am surprised as to how a NuGet package can add/remove support to VS capabilities!
I guess I'm less familiar with download functionality than I thought. I'm not sure I fully understand what exactly a stream is. would downloading the file from FTP to my webserver mean I would have to be able to store every accessible file on my webserver? -- After further thinking, it might be possible and maybe easier to just send the user to the ftp page where the file is located. I would have to have my app pass the credentials to the ftp site, though, since the user won't know them. 
There was a post on here on how to get 6 mo. of Pluralsight for free. On mobile so can't find the link at the moment. Edit: Oops, looks like this was already answered. But I thought it was 6 mo. 3 months is still awesome.
I'll try this option and also try converting to base65. Personally, I like your solution a little bit better though. Thanks!
Ok, I think I can work with that. Thanks for your help!
I would first check the Request.Form collection to see what names and values have been posted.
If you are trying to do it from next page, then it's already another request which doesn't have the same variables. You could put a hidden form field (input type="hidden") with same name and put request also into its value then it will be preserved to next request. Add to the second page something like this &lt;input type="hidden" name="HadoopComments" value="&lt;%=Request("HadoopComments") %&gt; /&gt;
It's hard to tell, but you could use developer tools in your favorite browser to see what is actually sent to server when navigating between pages. And see if your variable is there. It kind of should work if you put it on 3rd page (maybe check if it's inside form?).
When you try to send the email, you are Requesting from a form that doesn't exist. Your REQUEST object points to the second page, the one that works , but this page isn't a form. Its just a table. We can't really debug any further for you without seeing a lot more code. Remember that the web is stateless. Whatever happens from page 1 to 2 is completely forgotten when you go from page 2 to 3. Once page2 is drawn, all request variables are clear.
Which version, and for which platform?
SaveFileDialog is for WinForms Apps and Maybe WPF apps. To download to the users location via the browser you will need to server the correct MIME type via the response object and you will need to write to an output buffer and then use JS to redirect to a "Download Page". http://stackoverflow.com/questions/8897458/asp-net-download-file-to-client-browser http://geekswithblogs.net/Frez/archive/2011/03/23/streaming-files-for-more-secure-downloads-in-asp.net.aspx I would use an ashx in ASP.NET as I am a bit oldschool but the same could should be able to be translated to MVC style controller.
For the transition from the 3rd to the 4th page, is the button/link which initiates that transition a form submission button? (as in, input type=submit, or a link with some javascript that submits the form?) If it is not, then the hidden input field you added won't do anything. My recommendation would be to either turn that button/link into a form submission (probably easiest), or use some other means of temporarily storing that variable. Session is probably the best way to do that, or if you didn't want to use session, there are ways to persist the viewstate from one page to the next, and you could do it that way.
Maybe there are two checkboxes with the same name and different values? Although I agree, the code as posted will never work.
[6 month of free pluralsight](https://absolute-sharepoint.com/2015/12/free-pluralsight-6-month-subscription.html)
I was going to write "didn't read a word, but I bet something outside of code is causing the problem". YUP. Using IIS. Might as well call it ISIS.
February. https://github.com/aspnet/Home/wiki/Roadmap
No problem. Let me know how it goes.
thanks!
Why are you requesting a different variables when sending the email. Why wouldn't you be using the "comments" variable in the email text. 
Are there other rewrite rules that could be interfering, such as one that forces https to http? Maybe uninstall rewriting and try just the code. Are the IIS site bindings configured properly, particularly in terms of IP/domain? 
If your HTML markup is like this: &lt;asp:checkbox id="checkboxname" runat="server"/&gt; You read the value in code like this: if(checkboxname.checked) {grade++;} 
I got it using the convert to base64. This was the easiest solution using [this fancy library](https://github.com/adonespitogo/angular-base64-upload) since I am uploading from angular. I create an ImageVM that contains base64, filename, and filetype and then uploaded them into my Azure Blob uploadImage method. I return a Url to be attached to the object VM, which is then uploaded into the database. Below is my code - public string UploadImage(string base64, string fileName, string fileType) { byte[] bytes = Convert.FromBase64String(base64); if (bytes.Length &gt; 0 &amp;&amp; fileName != "") { string imageName = string.Format("{0}{1}", Convert.ToBase64String(Guid.NewGuid().ToByteArray()), Path.GetExtension(fileName)); imageName = imageName.Replace("==", ""); imageName = imageName.Replace("/", ""); imageName = imageName.Replace("+", ""); CloudBlockBlob blob = container.GetBlockBlobReference(imageName.ToLower()); blob.Properties.ContentType = fileType; blob.UploadFromByteArray(bytes, 0, bytes.Length); return blob.Uri.ToString(); } return null; }
so it is impossible to check if both of the checkboxes are selected if they have the same name ?
When it redirects infinitely, are you *absolutely positive* that `strPath` is what you think it is? Additionally: 1. You can't use `strPath.IndexOf`, the URL `http://example.com/test?bypass=https://test.com` is legal and will bypass your redirect test. Use the following instead: var uri = new Uri("http://example.com/test?bypass=https://test.com"); if (uri.Scheme == "http") { var redirect = new UriBuilder(uri) { Scheme = "https" }; Response.RedirectPermanent(redirect.Uri); } 2. Note how I use `Response.RedirectPermanent`. You want any spider crawling your site to know not to use `http` anymore.
Turn on tracing on the highest level. Do you get any error messages then?
I am new to Ubuntu. Could you please elaborate what you mean by tracing?
Would have to guess that plesk is the problem here. Stick with IIS if you can You're going to have to go for low-tech debugging Just make a page that dumps all of your test conditions onto a page Index of https: &lt;%= (strPath.IndexOf("https://"))%&gt; Etc Turn the redirect OFF until you can see which test isn't giving the result you expect. Its possible that its something silly. For example, you have a config error and the error page is served over http, hitting the redirect, and then erroring. Hard to tell until you actually turn the redirect off and see what your tests are actually giving By far the easiest way of doing all this is to install the IIS urlrewrite plugin, add a rule for canonical urls , and set the require ssl flag to true. 
No problem dude. This is the sort of thing you need to get used to. People will give you a throwaway comment or instruction like you've been given. Part of the job once you get experience is to think about it first, foresee the problems, and say "this will cause problems here, here and here, can I do this instead?" Maybe there's a specific reason why it has to be done in their way, maybe you've just saved the project. But you should identify, and suggest solutions for, the problems. And you shouldn't be telling junior staff/interns to do silly things like that WITHOUT doing those re-thinking steps yourself first.
This guide of pluralsight got me into asp 5 mvc 6 and ef 7 pretty well: https://app.pluralsight.com/library/courses/aspdotnet-5-ef7-bootstrap-angular-web-app Explains it very slowly and starts from the beginning which most guides lack.
They are still supporting 4.5.2.
Here's a good article Scott Hanselman did on the new unified "dotnet" CLI. http://www.hanselman.com/blog/ExploringTheNewNETDotnetCommandLineInterfaceCLI.aspx
I've been looking for something like this! Thanks for the link, I'll check it out.
my teacher has asked me to find this is it good enough xD ?
Oh, I see. Actually VB projects have a root namespace, it just appears in the project properties rather than in the code itself, and is enforced as an automatic prefix to all namespaces / members within the project. I think you can leave it blank to effectively emulate C#'s behaviour if you want. Modules are static classes, with the only quirk that their members are placed in the global namespace by default. So if you want qualified access, which is normally the case except for utility or otherwise "core" modules, you just wrap the module in a namespace. I won't go on a long rant about case sensitivity, but I suspect the particular Web issue you're highlighting is to blame on magic strings more than on case insensitivity. (Or equivalently, on having some features be case-ins and other be case-sens.) Hence why the *nameof* operator is easily my favourite feature from VS2015.
&gt; 1.Equip your server types you want in TypeScript with TsClass, TsInterface or TsEnum attribute. Why not use DataContract/DataMember? 
Oh man I know this isn't going to be much help, but we had a similar problem with Web forms moving to https causing an infinite loop . It's an issue with deep linking and we ultimately had to remove most of the manual redirects because IIS handled most of it by itself. If I remember it was in the global asax and we just emptied the application redirect methods. I honestly forget which one, but it was because we were manually redirecting when IIS did it for us. 
You know you don't need an html element to just display text, right? If you just output the value it will show up. Don't get hung up on the tag helpers, in the end it's just html you're working with.
That makes sense. I will try it out. 
Either what /u/angrycat said, or you're not `using` the assembly that includes the interface that defines the extension method SaveChanges() or something of that sort. I see this a lot with ASPNET development, especially in the newest stuff in development because of how "modular" it's become.
Late night attempt at trying to fix it. I might have really messed up things but I'm not sure yet. It does compile though. I'm still trying to get this Interface and dependency injection stuff figured out. I'll let you know how it goes in the morning when I run my unit tests and figure out what the heck is happening with the DI
They don't seem to give a shit. I've tried reporting it multiple times. You have to use a nearly two year old distribution if you want support. You **MUST** use 14.04. Which is why 99.9% of developers will be running DNX from a docker container. Oh, also, you're in for a world of hurt when ASP.NET 5 RC2 comes out. You might be better off moving to dotnet-cli and rc2 in a month or two if you can wait that long. Although they target the same version of Ubuntu.
DataContract defines what is being sent over the wire. It has to match your attributes exactly or you'll get subtle bugs.
&gt; Also assigning any additional behavior to DataContract/DataMember by default might to be rude Single Responsibility Principle violation. Never cite SRP as a justification. It makes it sound like you don't actually have any reason. 
The problem was Ubuntu version. Everything is working fine as expected on 14.04
Need using nuget.lucene too. Might give this a shot to see how well it works. Don't feel like the lucene port is going to be supporting v3 of the protocol so I'm not sure how long term it'll be https://github.com/themotleyfool/NuGet.Lucene/issues/27
MSDN is a primary source. [Richter's presentation](https://www.wintellectnow.com/Videos/Watch/performing-i-o-bound-asynchronous-operations?videoId=performing-i-o-bound-asynchronous-operations) is also pretty good.
Perhaps not what you're looking for as this isn't an internet source, but I found the sections in [C# 5.0 in a Nutshell](http://www.amazon.com/C-5-0-Nutshell-Definitive-Reference/dp/1449320104/ref=sr_1_1?ie=UTF8&amp;qid=1452784471&amp;sr=8-1&amp;keywords=c+5+in+a+nutshell) on concurrent programming were especially good at explaining this stuff to a non-genius like myself. 
https://channel9.msdn.com/Events/Build/2012/3-011
Seriously though, SRP is meaningless "principle". Citing it never helps an argument, at best it just changes the discussion to arguing about what it actually is.
Why have a class in C# and the same class in TypeScript and not think about how objects go from the server to browser and back?
Stephen Cleary has written a lot of good articles on Async/await, a good starting point being http://blog.stephencleary.com/2012/02/async-and-await.html depending on how much experience you already have. 
The fuck place does this have to do with highschool? Concurrent programming is one of the most advanced topics in existence of software. Concurrency also has absolutely nothing to do with async/await they are completely orthogonal. You're really set up for failure on this one.
&gt; Is your dbContext class inheriting DbContext? This is what it turned out to be. Last night I tried to add : DbContext to the interface but it didn't work. I eventually figured out that the interface wasn't seeing the concrete class from that direction. That got me to try changing the type on the variable.
What are you so upset about? I'm attending a upper secondary technical school (don't know if that exists in the US) and I have to prepare some topics since they might come up in finals this June. That being said, I'm not familiar with both topics, that's why I'm asking. 
Tell that to people that have already fallen into pitfall of using ActiveRecors (which is obvious SRP violation) with complex projects ;) And the cause is exactly SRP violation.
Well, my ViewModels are circulating from server to client without DataContract/DataMember attributes since JsonResult as well as Json.NET does not require these attributes. I use DataContract/DataMember when involving some third-party web services declaring their own DTO and being lazy to move this usage to separate library. But I obviously do not need this stuff in TypeScript. Therefore I can make an assumption that not all DataContract/DataMember-ed classes needed in TS code. Therefore DataContract/DataMember does not denotes DTO itself (only in few cases). Therefore it is better to have separate attributes for TypeScript glue code to avoid misreading/misunderstanding. And also - how would you override fields names/types and codegenerators with DataMember attribute for C# class property? You will have to use special attribute. So every time your model changes - you will have to remove DataMember attribute and use TsProperty attribtue instead. Then after few iterations your code will consist of mix of Data* attributes and Ts* attributes. That is misleading and does not seem neat. So it is better to do not mix up attributes with different purposes. But if you want - you can still do that using few lines of code I wrote you above. I cannot deny you to shoot your leg :)
I'm upset that there's some level of expectation of you understanding a topic that requires years if not literally decades to understand.
&gt; I won't go on a long rant about case sensitivity, but I suspect the particular Web issue you're highlighting is to blame on magic strings more than on case insensitivity. (Or equivalently, on having some features be case-ins and other be case-sens.) Hence why the nameof operator is easily my favourite feature from VS2015. It was due to a typo on control in WebForms and how FindControl worked. It wasted me a lot of time and if it was case sensitive (Everything was XHTML and had to be case sensitive) It would have been obvious immediately what the problem was. These weird things that are default in VB is why a lot of developers especially from C# where things are **consistent out of the box** see VB as some sort of penance before being given a real project. So while my initial post on this topic was kinda trite, After dealing with all the VB legacy, time wasting *features* and the *average* VB programmers code (at no point doesn't anyone seem to follow the DRY principle) I feel kinda justified by it.
"What will the licensing model be? While itâ€™s too early right now to comment on the specific details, the licensing model will be inline with our other products from the JetBrains Toolbox. We will take into account the many usage scenarios that might occur, when establishing pricing, such as someone wanting to use both tools, etc. We hope to have the pricing information soon." Mmmhmm..
I'm using 2015 and have been since it's release I'm lucky enough that I've either been working for smaller places where I get to have a say in what we use, or at larger firms who understand the importance of staying up to date
We had 2015 bug switched back to 2013 again, 2010 is really coming on it's end though.
Work finally upgraded to 2013 from 2010. Use 2015 at home.
2015 Professional.
2015 community
2015 Ultimate. It's pretty darn stable unlike the early versions of 2013 which caused me to rollback to 2010.
I had a rough time with 2015 until update 1 came out.
It's a good entry-level language though. Shouldn't ever be used for corporate level development... but a scary amount of apps are written in it.
2015 professional. if my employer doesnt give me a msdn license i purchase it myself. i ask if an employer provides it in the interview and if they don't, negotiate a higher wage to pay for it 
All of them. But seriously, I run 2015, 2012, and 2008 for working with different projects.
2015 Professional Update 1. Like other people, it was a bit rough around the edges until Update 1. 
2015 Pro My client uses a ton of Microsoft stuff so I'm lucky enough to get a MSDN license 
2012 - 2013 at work (the difference not worth the update time so some machines are still 2012). We had serious issues with 2015 so not using it for now. 2015 Community at home.
2015 Ultimate/Enterprise what ever its called now. 
2013, I dont think we are missing out on anything super exciting.
What 2015 bug did you have? 
TypeScript support is unbearable, random freezes, the annoying meddling of solution analysis with Re#, and some other just annoying things.
we're still at 2010... upgrading to 2012 soon. haha!
2015
Why won't you upgrade directly to 2015 ?
2015 Community.
You must not have msdn licenses then. Same cost regardless of version.
2015 Enterprise. I have an MSDN Ultimate account :-)
There's nothing at all wrong with VB.Net. It's not nearly as commonly used, but it can do everything that C# does. VB6 is a streaming pile of shit now, although it did have its place back in the day.
2013 Ultimate and 2015 Enterprise. using 2013 until we get resharper licenses that work with 2015
Sorry, I seriously mean it's easier to get use to then someone who jumps right into C# or C++, ect. Not saying it's a language for dummies.
&gt; the day I need to override the + operator to mean - Is this a hyperbole or does this happen? 
Why shouldn't it?
Solved. See edit.
The problem is not necesarily VB but the patterns cargo culted over from Winforms/Web Forms. You can do pretty much don anything you can do in C# in VB as long as its valid in the framework. I personally prefer C#.
Just upgraded from 2010 to 2013
Work - 2013 Pro Home - 2015 Pro
Actually after today, going through a bit of debugging hell, I came back to point out that the new exception settings in VS 2015 are plain strange. By default, if you have any kind of global exception handler (like .NET MVC's customError's) set, VS won't break on an exception. So, you have to enable breaking on all CLR exceptions. Of which, in any MVC site, there is plenty that get thrown for good reasons in a debug environment. Or, configure your project in such a way that exception handlers are turned off in debug and on in production. Basically, it's a bit more of a PITA; no idea why it was change from 2013 to this.
We run 2015 Enterprise, with the latest update(s). Old place used 2010, and you had to have a specific business need for 2012. 2013 or 2015 weren't even a possibility.. But then again they were 200+ devs deep, and that many licenses is a large chunk of money. 
VS2008 for SSIS on SQL 2008 R2. VS2012 for SSRS reports on SQL 2008/2012. VS2015 for most everything else.
It's still out there in droves in legacy software. For a long time, it was the easiest path to Windows business applications because C++ was overkill and too hard to learn for the legions of business developers. Sure, you had a good amount of Delphi mixed in, but VB was pushed by Microsoft in a huge way.
I started with vb.net as well, but am glad I moved on, if for no other reason than to not have to constantly overcome objections from people pushing c#. 
That works for smaller employers with smaller code bases.
Every so often I get a req for vb.net, which I'll just just fine. Apparently other developers turn their noses up at it. More work for me
2015 Professional, convincing the boss to switch was a little tricky but, of all things, multiline string literals finally won him in :D
I believe he was talking about .NET framework not ANSI C
I would definitely go this route if I could. But, we don't have an MSDN subscription. Execs are balking at the cost of buying all the new licenses. We're trying to argue for a subscription, though.
2015 Enterprise with SP1 R# 10 Windows 10 Writing software for Windows Server 2012 R2, Windows 7-10 and ASP.NET WebAPI 2!
Yup - it attracts all the 'tards from Accounts who did some VBA back in the day.
Everything that safe C# does.
I on the other hand think it's great he's in an environment like that.
:( Here's to hoping you can eventually end of life those legacy servers and get your projects upgraded.
We are planning to upgrade all the databases to 2014 this year, so the nightmare can end for now. 
2015
I disagree. It's no different than them expecting him to discuss proper system architecture in software. I only get architecture right from: ~~college~~, 10 years of real world experience, and several hundred hours of ultra advanced industry learning workshops. It's just impossible. They might as well ask him to flap his arms and fly. Edit: college was actually meaningless for architecture
The job I had last year was VS2003, which worked with .NET framework 1.1 and only 1.1 and the company made the decision that it would never ever move beyond 1.1...though they paid an obscene amount of money to DevExpress for continued support for an unused component. The new job is VS2010 for much the same reasons, but this time arbitrarily sticking to .NET 3.5 and 4 is the client's decision, not ours. Though I have used VS2012 and VS2015, as long as I have ReSharper holding my hand in 2010 I don't miss the newer ones.
If I was deploying to the cloud right now, I'd build my app into a Docker container. Microsoft has published multiple variants of the aspnet container that either use the CoreCLR or full CLR (which uses mono on Linux/Docker) So either with or without mono should be easy to run - the host just needs to support Docker. I'd try to target core CLR until you need some library that only supports the full framework, at which point you need mono.
I think that is a nice suggestion. I cannot make it clear from the docs but do you think OpenShift supports Docker containers on their free-tier?
No. Installing libicu52 in 15.10 won't work. There's either a newer version in 15.10 that dotnet isn't compatible with or something else.
So get the Hobby package. It's $7/month. Sheesh.
Thank you for correcting me. I mean it. I don't and never will know all the flavors of C, but would like to be right about what I think I know!
Sorry, I was on mobile before and couldn't find the link. Check this out: https://github.com/aspnet/dnx/issues/3059
I'm am hardly the world's most sophisticated programmer. I have no idea why one would need to do this. If you ever wish to share a piece of code that shows operator overloading in practical use, I'd be fascinated. Thanks for the correction!
Thanks. This might actually work.
What software are you using to validate the response? Does it give any error messages, exceptions or lines in a log file? Any hints to why it fails? There is no timeout as such on validating the signature (how would that work exactly?), but there can be NotBefore and NotOnOrAfter fields in the assertion. 
&gt;Use CoreCLR. Why use Mono? Because you can't use nuget packages that aren't built for CoreCLR maybe?
They sign with their private, you validate with their public (the one they have in the metadata file they gave you). Similarly, when you send a message back, you'd sign with YOUR private, and they'd validate with your public key which you will have exchanged, likely in a similar metadata file, to them. Not sure what you are doing exactly, but if you want to see how to decrypt a response, check the signatures, validate all of the assertion rules, etc., I'd start in the "HandleResponse" method of the following link and then trace the calls through this project. https://saml2.codeplex.com/SourceControl/latest#src/SAML2/Protocol/Saml20SignonHandler.cs Shameless plug: I was the original fork maintainer of this project, but have moved on and don't have the infrastructure to maintain it (or rather, test my changes). So while it is still completely functional and I'm willing to help people get it working, the project is open for new maintainers.
Solved. See edit.
isn't the point of ASP.NET identity that you can just replace the storage provider and not need to update anything else? The fact that it appears that you can't customize a user without rebuilding the repository makes me think that Dapper isn't a great choice for a library like this.
What?
You could have a function that attempts to convert the data string into a given data type and catch the results if it fails. If it succeeds then that is the correct data type. Just be aware of the order since int would pass the double test too. The msdn example has something very similar to this https://msdn.microsoft.com/en-us/library/zh1hkw6k%28v=vs.110%29.aspx 
1. The language. Prototype inheritance? Shit type system? 2. The ecosystem. A two line npm pacakge to "make a directory"? npm's nested dependency problems. the "resolution" to the nested dependency problem that is going to break people's code. What is there to like about JS? The ONLY thing I've heard is that it comes preinstalled in every browser and it's easy to start playing with...
Please stop posting the same questions across multiple subreddits -especially questions that aren't relevant. If you do it again you will be banned from our subreddit.
ASPNET 5 is a bit daunting for me now. I am sure this will come in handy in the future, thanks for sharing.
Definitely sounds like Selenium is the right tool. Sure some web requests can be faked using other tools, but having to go through a setup wizard really sounds like something that needs to be automated at the UI level.
ASP.NET identity still feels very spread out, got any other resources for getting a better understanding of its design. i.e IUserSecurityStampStore
Where's part 1?
Indeed interesting. I'm also handling inventory and withdrawals, but your approach is more sophisticated. Fortunately, I can meet the needs of my customers. Thanks for the explanation!
Unfortunately that hasn't been shared. Even though this video builds upon Part 1 I still think it has value. https://channel9.msdn.com/Events/DEVintersection/DEVintersection-2015/Azure-App-Service-Architecture
Seriously? Go to the Selenium home page so kindly linked for you above. Click the download link. Click the C# version. Or just install it with NuGet. On second thought, you're right, Selenium is too complicated for you.
Not sure I exactly follow you, but if all the constructor parameter types are registered with the DI container you don't have to do anything special. If you have other things like strings or something, like this: public interface IA {} public interface IB {} public class A : IA { private string _param; private IB _b; public B(IB b, string param) { _b = b; _param = param; } } public class B : IB {} Then you can register A like this: public void ConfigureServices(IServiceCollection services) { services.AddTransient&lt;IB, B&gt;(); services.AddTransient&lt;IA, A&gt;(provider =&gt; new A(provider.GetService&lt;IB&gt;(), "yourString")); } 
Did you find a definite answer? I'm considering getting this certification as well. I'm doing it for a few reasons: 1. My employer will pay for training, exam costs and will provide $300 for passing the exam. 2. I've mainly been a webforms guy in my asp.net career. I'd like to get some exposure to mvc.
As /u/Thornsten said, click the download link, then the C# link. I just tested it, and it downloads a zip file with DLLs etc,
Womp womp. This is a great video none the less! 
Not angry, just puzzled why people like you aren't interested in putting in even a little effort to figure things out for yourself. Somebody even gave you a link to the product page, which itself has a link to the download page, but you want to be spoon fed even more. Seriously, if you can't figure out how to download the C# Selenium packages then programming is most certainly not for you.
I meant what I said Thornsten, you're obviously a very unhappy individual.
You can mean it all you want, doesn't make it true. You're a very lazy individual, that is indisputable.
case in point /u/g2petter, this hostility is unreasonable for a simple question. 
I guess when you've been coddled your entire life honesty sounds hostile.
I wish the VB had pointers too. =)
Hah, it's an accepted answer on SO no less! On my phone right now but will dig out the link.
If you're using Visual Studio, don't download dlls from the site. Right click your project, click "Manage NuGet Packages", search for Selenium, and install the one of the packages. If you want the program to actually pop up IE, get the IE package. Get the PhantomJS package if you want to use a headless (invisible) browser. Then you'll need to use the site for documentation on how to use the package. 
Oh, maybe I was mistaken. I was under the impression that the new ASP.NET 5 OOTB DI only worked with a single parameter in the constructor. I'll have to try it out and report back.
Why are you writing a string as raw bytes in the first place?
You can have as many as you want! When you (or the framework) call `GetService&lt;T&gt;` the DI container looks at the constructor arguments for `T`. For each of them it basically calls `GetService&lt;TParam&gt;`, and if `TParam` has any constructor arguments it does the same for all of them and so on until the complete object graph is constructed. So if all the constructor parameter types have a corresponding service registration in the DI container then you can just register the service without a lambda. 
im a novice and a link i provided was one of the few that actually did what i wanted. 
well i get nullreference exception, but only after i try to iterate trough this List&lt;Restaurant&gt; ResList = await Restaurant.FileToRestaurantList(); Also i can provide gihhub if anyone is interested
yes, it's for automated VPS deployment. This particular software is FusionReactor (for ColdFusion 10/11 installs). It does feature a silent install, which I have working. The issue is that after the installation there's a setup step that does the actual integration into the CF instance. Basically I have a choice between examining the files to figure out what needs to be created/copied/etc, or simulating the setup. I figured simulating the setup would be easier and less fragile as time moves on. Which brought me here :) If you have any other suggestions I'm all ears. At the end of the day I can get it done by other means, it's more about the path of least resistance/least fragile approach.
Awesome, thank you! Do you have to use the [FromServices] attribute for each method parameter? 
I suspect that you are getting another exception which the debugger doesn't break upon, because it is handled by the try-catch clause. Have you tried setting a breakpoint on the line in *ReadFileContentsAsync* that says: return string.Empty; If you hit that breakpoint you can hover over *Exception* above to see what happened. Edit: Oh, wait you might have to modify the line: catch (Exception) to catch (Exception ex) to see what's the actual exception is. 
No, you don't need to do anything to the classes you are registering. They don't know anything about the DI container. Here's a simplified example: public interface IA {} public class A : IA {} public interface IB {} public class B : IB { private IA _a; public B (IA a) { _a = a; } } public interface IC {} public class C : IC { private IA _a; private IB _b; public C(IA a, IB b) { _a = a; _b = b; } } Now you can register them like: services.AddTransient&lt;IA, A&gt;(); services.AddTransient&lt;IB, B&gt;(); services.AddTransient&lt;IC, C&gt;(); Then if your controller needs an IC, its constructor would simply be: public YourController(IC c) { _c = c; } 
You're calling streamReader.ReadToEnd() twice. The first time you log it to the Debug stream, the second is what you actually use as a result. The method moves the file pointer to the end everytime it's called and by the second time there's nothing to read. Also consider using file.ReadAllText() instead as it'll be easier/more to the point.
Not sure on specific OSX issues. I can tell you that dnx-watch is going away in RC2 when the new dotnet cli tools are released. Also, "production" mode is the default, you need to opt into dev mode (typically by setting an environment variable on your dev box).
Can dotnet cli be used on OS X at the moment?
Thanks again for all your help. I'm thankful to remove those attributes from my code base. Last stupid question.. I'm trying to inject AutoMapper's `Mapping.Engine` for `IMappingEngine`, but I can't figure out the syntax. I typically call `services.AddScoped&lt;IProjectService, ProjectService&gt;()`, just like in your above examples, but I'm struggling to find the syntax. I thought it might be something like `services.AddSingleton&lt;IMappingEngine&gt;(Mapper.Engine)`, but that's obviously not compiling. Any idea?
It hasn't had a "stable" release yet (due in Feb with RC2), however the repo indicates that current OSX is building: https://github.com/dotnet/cli Depends if you're OK with moving further towards the bleeding edge.
I am using a propriatory API which returns xml for the dataset, and accepts the same dataset format for CRUD operations.
Use ex.message 
32-bit?
uf i didnt notice that when i pasted it, but it was already changed to utf-8 must have been ctrl+z that made this happen. Also how come is nott done asnyc? im still trying to get a grasp on this so any pointer would be apreciated
A better title would be: "Error installing 4.6.1 Framework." 
Not the first article I've read pushing npm scripts over Gulp/Grunt. I personally prefer Gulp to Grunt, but might try pure npm in one of my next few articles.
Maybe this helps? http://stackoverflow.com/questions/18376313/setting-up-a-common-nuget-packages-folder-for-all-solutions-when-some-projects-a
Cool thanks for sharing. By the way, I heard that FromServices attribute is being deprecated, can't find a source though. Anybody have a link?
I use [Feedly](http://feedly.com/) - and if you start liking some of the good .NET blogs like Scott Hanselman's, Herding Code, .NET Rocks, and others then it'll begin recommending material from similar sites. That's how I've found some good ones lately!
Disclaimer: I'm one of the co-founders of Akka.NET But I would recommend looking at Akka.NET for this - we even have a sample lesson in our [Akka.NET bootcamp](https://github.com/petabridge/akka-bootcamp) that shows you how to build a local version of resource monitor. That same technique with actors also applies to web applications.
I've seen folks on here or /r/csharp mention it's being deprecated, but no source. [This issue](https://github.com/aspnet/Announcements/issues/28) says &gt;About [FromServices] &gt;This is something we invented when revisiting model binding, and really grew independently of [Activate]. We've heard feedback in the context of the [Activate]/@inject discussion that [FromServices] is a bit awkward and oddball. We're still listening, but have chosen to do nothing for this release. But it's 8 months old, don't know if anything's changed since.
Point taken. 
2013
I use webpack for that.
So I've gotten to look a little further into PhantomJS and I think it's exactly what I'm looking for. They distribute binaries so it's just a matter of handing the bin a path to a javascript file. Simple and easy to maintain. Unless I run into a roadblock I think I'm going to forgo selenium entirely, the only advantage I can see to using it is being able to script in powershell instead of javascript, but that's a non-issue as far as I'm concerned. This project already spans windows, .net, powershell, CSS, javascript, *nix, bash, ruby, etc. Adding in simple js scripts isn't going to throw anyone for a loop. It also has the added advantage of being cross platform, so in theory that same javascript file can be used for linux installations as well (in theory...). I'm probably going to start converting some of our existing installers over to using phantomJS. In other words, I'm super happy with PhantomJS, thank you so much for recommending it.
Please note that DNU and DNX will be removed with RC2 and will be replaced with the "dotnet" CLI. Also the commands like "web" will be removed and there is no known replacement yet.
I have used anything since google reader.. I already have my twitter feed and reddit (trying to keep my life simple) .. but Ill try it
That's more than I think I should need, and I don't think you understand my question. (Or maybe I'm the one who doesn't understand it.) The test client application has no need to call a handler. It creates a TcpClient object and gets a NetworkStream object from the client. It writes a message out through the stream. It gets a message in from the stream. One minute later it sends another message out through the stream, and no matter what I try it crashes. Is a TcpClient object used up after a single message, and I have to dispose of it and create a completely new one with all the overhead of re-establishing the connection to the server? That seems ridiculous to me. Can't I just reset the TcpClient or the NetworkStream somehow to prepare it to send out a second message?
You are closing the stream. That terminates the connection. You should not re-use a tcp client after the connection ended.
is the server maybe killing the connection? change your client.connect line to this if (!client.Connected) { client = new TcpClient(); client.Connect("192.168.1.7", 5599); } and see if that helps
doing it now. it involves hard work, time and patience.
There is distressingly little information about ef.audit (like, a single page with marketing-ease and zero technical instructions) but it does look like what I am needing.
If you're not using EF or nhibernate (which has event hooks too), other options that come to mind: Db triggers, copy the old row to a different table or the same table with an inactive field (indexed!) before any update or delete. Row also has a last modified by and last modified date. Not a great solution since it's not super easy to use if you need to roll back. Modify your entity classes so that every (at least every public) property setter has functionality to check if you're actually changing the value and then set a dirty flag. When you would write the entity to the data store, if it's dirty, you can back up the old record first. One thing to consider with any solution is child collections, which may mean you need to set the parent dirty / back it up too depending on what you did (add/delete/reorder likely count as a new version of the parent, but just editing a small non key field in the child may not). You could just expose two collections (one that's a dictionary or lookup of {version, children} and one that's just current children. And now as I think about this, you may even want to just have a many to many table for [parent id , child id, version id] so if the same child is used across many versions (likely) you don't have to clone it over and over again.
ASP.NET docs mention use of [FromServices] in their latest docs. I don't think so its deprecated
Lowercase would not be enough. A strategy for separating words is required, eg underscore.
That's fine, if you can still choose the underlying hosting platform with program arguments. Otherwise it is a step back. Also, it was worth mentioning because arguments like "ef" (to call the EntityFramework tooling) is also not available anymore.
But I keep getting exceptions when I do. Can you explain why I am getting exceptions? Can you provide sample code that will send two consecutive messages through a client?
This is precisely what I want to avoid, and what the entire purpose of this thread is. Say I'm sending a hundred messages a second. Maybe it takes a tenth of a second to establish the connection. Obviously I won't keep up. I should be able to connect to a server and send messages to it to my heart's content, without having to reconnect. Why can't I?
Versioned content is a common feature of content management systems, you could have a look to see if there are any free or open source ones that have the kind of version support you need. It might be possible to do it with Sharepoint and source control integration but it would probably require some paid versions... and its Sharepoint :S
Sure its possible, but the amount of effort depends on the details of the service. For example, If the WCF and WPF were developed together, you may have service methods that were well suited to the original UI but that don't make much sense for a web-based one. As for how: If I were you, I would create the web app and then take a couple days to see if I could get some basic elements working.
Build is a good time but last time I went it was just a 3 day advertisement for azure. It's super difficult to figure out what sessions are worthwhile and which ones are just showcasing things. I'd prefer if it were more directly focused on development than tool offerings.
I mean the sessions are streamed anyways. do you actually get any value out of actually being there? I would think the networking might be the most valuable part of going to the build conferences.
I was surprised how quickly the tickets went this year, I didn't even know they were on sale until after they were sold out. Looks like an in town for the after parties event this year! I do know they give a few tickets to big companies but I also believe that a majority are paid attendees. Events sell out instantly these days. I'm sure you can find a scalper selling tickets outside Moscone later today.
Was about to post that I enjoyed being able to stream and look at archives from this year's build.
The networking is nice, the best part of Build is usually the swag. They hand out better stuff than any other conference I've been to but I suppose that comes with the price tag.
The frustrating thing for me is that I don't find out if I get my press pass or not for a couple more weeks. So if they say no, I can't go back and buy a pass.
Without seeing the code, it's hard to know for sure. If you're using IdentitySamples 2.1.0-a1, I bet the application context is inheriting from IdentityDbContext which creates the AspNet* tables. When you trigger a login, the tables are created if they do not already exist.
This year Microsoft decided to not give away any hardware swag for Build. They will forgo hardware "in favor of delivering a deeper technical experience for developers." 
Are there any advantages to using Firebird over SQL Server?
I'm not sure I really understand what your question is. User.IsInRole is checking if the user belongs to the specified role. That sample inherits from RoleManager&lt;IdentityRole&gt; which uses EntityFramework. In this case it's checking the Roles table which has been deleted.
Yes, but the Roles table should never even exist if you are making use of Identity 2.2.1 -- the Roles table is a Membership table. I donâ€™t want to use Membership. I want to use Identity exclusively, and to not have permanently empty Membership tables cluttering up the DB. FYI, I have solved the issue. Please see the second edit in the OP.
Ah gotcha. Sorry, I misread your post earlier. Didn't realize you had both types of tables. Do you have multiple contexts? I'm not familiar with Membership unfortunately.
most IT guys go there for the whores. lots of whores giving out event tickets. go at night to "party" aka get free food and "talk about IT".
&gt; Hey managers, we want to use AwesomeNewFramework 1.0 to build our new project. vs. &gt; Hey managers, we want to use the new lightweight version of ASP.NET for our new project. I'm all for the ASP.NET branding :)
Because they couldn't afford to do both /s
Those docs are quite outdated and I think they reflect much of the design decisions made around beta8/rc1. There are still API changes happening now in RC2 that invalidate some parts of the documentation.
&gt;It is awkward enough to type "ASP" with shift, but then I have to release the shift to type ".", as if that was not enough, now back to shift again to type "NET". This is adorable, like seriously.
You can consider asphostportal.com. They fully support asp.net in their hosting environment.
Did you hear about the kidnapping at school? Its ok, he woke up.
Does it work on Raspberry Pi?
Please change the name on asp.net on github!
Why would you search for "ASP.NET Core 1" rather than "ASP.NET Core", isn't like there are currently other versions. Equally a lot of the "ASP.NET 5" stuff is outdated as it has evolved so much since it first appeared, so it probably better doing it now so most of the information matches the RTM version.
I'm all in favour of a name change - as a complete rewrite it makes sense. But I can't say I'm sold on 'Core' for the following reasons: 1. As someone pointed out under Hanselman's post, Core suggests basic. Core used in other frameworks and technologies refers to the kernel / chassis (think Rails Core). If I think of 'Core' I do not visualise a framework with everything I need to build rich web applications. I think I will need to add on the bits that are included with Core. 2. ASP.NET already preserved the 'ASP' even though it's a completely different stack and now with Microsoft's third generation web framework we're still calling it Active Server Pages. 3. Related to point 2. searching for ASP.NET as opposed to ASP.NET or even ASP will be confusing and likely turn up some unwanted search results. 4. ASP.NET Core is a bit of a mouthful and sounds rubbish and is just the sort of designed by committee boring corporate name Microsoft excel at. What do you work on? Rails? Go? Node? No, "I work on ASP.NET Core" doesn't really cut it for me. That's my rant over :-)
This is an excellent tutorial, very well written with good examples. And it's refreshing to see something outside the Windows world for us *nix based folks :-)
Can you clarify what you mean by the hub's query? How have you configured it to run every 60 seconds?
Throwing this out there. Do you have a "QueryRunning" bit where you're making sure you don't get two running at the same time? That and what u/Thornsten said.
However, having too many cases in your switch actually gets compiled to a Dictionary, if I'm not mistaken.
The minifier shouldn't break your scripts. I can only assume the aggregation of all your script files in to a single file is causing the issue. Perhaps one of your script files isn't bracketed properly or something like that, meaning the next file in the bundle is 'continuing' the previous script file. In Angular you can wrap up every distinct part of script (e.g. a controller, a directive) in an IIFE, that should at least carve up your script in to discrete chunks that can be aggregated together without issue.
That totally helped, thanks for the suggestion. Everything works now. I have all of my scripts bundled and minified now.
/r/badcode is probably what you're looking for!
Yea. I'll do that. 
Can you guide me through how that can be done ? 
Not to be a dick, but as others pointed out this isn't something that is a push button solution Steps are going to look like 1. Learn ASP.NET 2. Probably will want a rich up so learn something like AngularJS 3. Pray the wcf app has decent architecture 4. Rebuild the ui in html / css 5. Rewrite the presentation layer in asp.net 6. Make the rich ui in angular Given I assume you starting with zero knowledge I suspect for a simple app two or three screen app you might be looking at 6 -9 months of work 
Also that one deaf programmer isn't going to be able to read your lips when you say it. It's very aspirated. Asperaty?
I've come to appreciate .NET more recently, but .NET shops have a disturbing tendency to pump out the code equivalent of war crimes. 
I feel your pain. I've seen something similar and worse, where additional data was encoded as a Javascript object inside a &lt;script&gt;&lt;/script&gt; tag in the HTML. Glad I don't work there anymore.
Since this is homework no direct answers but think about and look into a csv file.
I figured it out. as every 6th line was a name to load in to the combobox, i loaded the first entry and then skipped 5 lines, looping until .peek reached the end of the file. i did something along the same lines for filling the textboxes - i had totally forgot that i could use combobox.selectedindex. multiplying this value by 6 gives me the amount of .readline() items to pass before getting to the entry of interest. so, thanks i guess. i could delete this thread but i feel all goodlike after figuring this one out.
limited to .txt - we havent touched on csv i'll be ecstatic once we start using filetypes of actual use
Core. Just "Core" 
WUBBA LUBBA DUB DUB.NET
.Core has a nice ring to it. 
'dotnet' seems good to me
If their goal is to eventually retire ASP.NET as we know it, they should just call it ASP.NET 5. It seems like they're choosing a name to make the transition-phase easier, but at the same time suggesting that these two things might live side-by-side for a long time. When .NET Core and ASP.NET Core were announced, one of the complaints was that it was going to further fragment the .NET landscape instead of bring things together. This new naming scheme makes me think those people might be right. There's yesterday (before ASP.NET Core existed) where things were easy. Hopefully in a not-too-distant tomorrow, there will only be this new ASP.NET Core and everything will be based on that. This naming scheme seems to be chosen for today (where both frameworks have to live together), but I think it just adds confusion and withdraws a feeling of urgency from library authors to support the new thing. And that's going to mean it takes longer to get to tomorrow. A coworker also mentioned that Microsoft in general seems to struggle naming things. I know it's a huge company and vastly different teams, but the XBox, XBox 360, XBox One is a perfect example, there is no logic to that.
I personally like the name. I think it's quite clear on what it is and sets up the whole .net Core infrastructure really well. ASP.net 5 wasn't the only thing that was going to cause confusion, the whole .net core ecosystem is effectively going to balloon at this point, so making a clear distinction between what works on the Framework and what works on the core (and what works on both) is pretty important.
Katana worked. Dunno why they can't keep it.
I wonder if it would make sense to drop the ".NET" moniker, and really focus on building a totally separate cross-platform runtime and framework. Especially since this "Core" framework so far seems to be only focusing on applications that respond to HTTP requests. Does it even include a desktop UI library? Yeah this may make all of .NET become *legacy*. But maybe that's okay? The same way classic VB is (still) slowly going away.
The problem with ASP 5 is that it is *not* a continuation of ASP.Net in the same way that 2 -&gt; 3 -&gt; 4. Where each one of the previous versions was built upon the last with Core 1.0 they ripped out the foundation and built a new platform. IE: They changed the name because there is no direct or simple upgrade path.
Core.Net 1.0
That first one gives you all the code. Nothing says you have to use a NuGet package for this, just create your own small library. Especially with an API, how you are going to communicate the current page, size, total count, etc. back is all undefined, so you are going to have to define it in some way anyway. Honestly, I'd recommend just finding some examples you like and writing it. It isn't a complicated problem, but is an ill defined problem, so you're better off just implementing it yourself.
Not everthing from the .Net Framework is working in .Net Core Get the dotnet CLI, http://dotnet.github.io/getting-started/ Basic command line instructions, https://github.com/dotnet/cli Here are some examples, https://github.com/dotnet/core/tree/master/samples
Yes, I attempted to use the first one, but the filters that are used require MVC 5, not 4. [RoutePrefix("Paged")] &lt;---- Issue: Requires WebApi 2 [PagedListActionFilter] // TODO Register this globally! public class PagedController : ApiController { [Route] &lt;--- issue The errors occured when I tried this: Install-Package Microsoft.AspNet.WebApi.WebHost **Error:** Install-Package : Could not install package 'Microsoft.AspNet.WebApi.Client 5.2.3'. You are trying to install this package into a project that targets '.NETFramework,Version=v4.0', but the package does not contain any assembly references or content files that are compatible with that framework. For more information, contact the package author. At line:1 char:16 + Install-Package &lt;&lt;&lt;&lt; Microsoft.AspNet.WebApi.WebHost + CategoryInfo : NotSpecified: (:) [Install-Package], InvalidOperationException + FullyQualifiedErrorId : NuGetCmdletUnhandledException,NuGet.PowerShell.Commands.InstallPackageCommand Like I said, I am fairly new to Asp .Net, but this looks as though I am not able to use this solution. Thanks for the help though.
I'm glad you guys were not in charge of naming this :D ASP.NET Core makes perfect sense to me.
Given their move to the task runners and front end I think I could get behind this. 
Are you wanting to use the '.Net Core' or '.Net Framework'? They are 2 different compilation targets. In the future it looks like everything is moving towards the Core, which does have Microsoft endorsed Linux support. Right now most existing code is still built on the Framework. The 'dotnet cli' stuff is for .Net Core. If you want to run Framework code on Linux, the 'mono' project is a mostly complete reimplementation of the .Net Framework. http://www.mono-project.com/docs/getting-started/install/linux/ In that case you'll need to install 'mono-complete' and any dependencies on your Linux flavor of choice. Then you can compile your project as usual on windows under VS. Take the executable 'example.exe' and any needed 'library.dll' libraries. Put them all in a directory on the Linux machine '/opt/example/'. Then you should be able to run your code with the command 'mono /opt/example/example.exe'
Someone else pointed out that having just "Core", even as a suffix, is going to be hell for searching, though. I like ASP.Core...
THÌ˜EÍ„Ì‰Í– Í PÌ¯ÍÌ­OÌšâ€‹NÌYÌ¡ HÍ¨ÍŠÌ½Ì…Ì¾ÌŽÌ¡Ì¸ÌªÌ¯EÌ¾Í›ÍªÍ„Ì€ÌÌ§Í˜Ì¬Ì© Í§Ì¾Í¬Ì§Ì¶Ì¨Ì±Ì¹Ì­Ì¯CÍ­ÌÍ¥Í®ÍŸÌ·Ì™Ì²ÌÍ–OÍ®ÍÌ®ÌªÌÍMÍŠÌ’ÌšÍªÍ©Í¬ÌšÍœÌ²Ì–EÌ‘Í©ÍŒÍÌ´ÌŸÌŸÍ™ÌžSÍ¯Ì¿Ì”Ì¨Í€Ì¥Í…Ì«ÍŽÌ­.NET
Ah, didn't realize you were a noob (no offense intended). I'll be more specific. The RoutePrefix stuff is just attribute based routing. You don't need those. You can register your routes in the global.asax (guessing for webapi 1, in 2, it's more likely that the global.asax calls a static class in the App_Start folder of your app to set up the routes). Basically when IIS answers the call, it sends the entire request to your app without trying to interpret the entire URL. Then your APP reads that URL and compares it to the configured routes to determine what Controller Action Method it is going to call to answer the request. In WebAPI 2 they added an OPTION to configure those routes via attribute, rather than globally in the global.asax, but both options for route configuration are still viable. For your needs, you can ignore those two Route* attributes.
Aaaand I just found my next library name. Now I just have to come up with something that the name would fit...
Apple Core
I work with Mono (.NET on Linux) daily and am currently documenting my experiences. Here's a simple tutorial for just setting up Mono and running executables ... http://coderscoffeehouse.com/tech/2015/12/09/mono-linux-setup.html I haven't got round to including anything for .NET Core because it's a moving target and also you needed to install Mono even to get .NET Core running (I'm not sure if this is still the case) so my focus has been on Mono / ASP.NET MVC 5 which is what I'm using in production (I'll have the tutorial for this up in the next day or two).
Just like Spartan was way better than edge :-/
Neigh
Dotnet^2
Sphincter? 
&gt; Why aren't you just using linq? Because I don't know how to do that without lots of code. 
Two of the same class.
Doesn't that mean I have to override and write an Equals method on each of my model classes?
yep but it's really not that much work unless you have hundreds of classes you could probably have implemented it through your entire system in far less time than you've been waiting for suggestions on reddit. plus your system will perform better than adding a whole other external library to do the same job in what will turn out to be only 2 or 3 fewer lines of code if you couldn't give a crap about performance, maintainability, stability, security, etc... and just want the laziest coding method, then look for something else...i always stick with the built-in option where possible. as you said, it's primarily just an override for an equals method. you're not going to find anything psychic that just magically knows instinctively which fields are the ones to compare....that's why the interface exists....so at SOME point - whichever method you follow - you're going to have to specify the fields Name, Value, Sequence, whatever....and probably the field in [objectB] to compare against....you've already pretty much written the equality method you would have needed..... then you're going to have to include the new library in the class file. of course, this is after you've found it in nuget or whatever, added it to the references, made sure your project compiles.... how much code and time do you think you're going to save? Really?
System.Core.Web as both the name and the root namespace of all of the current aspnet stuff that is going to be a part of this (hard break on compatibility with everything intended). Alternatives? MossWeb, NCore, Web.NET, katana, Core.NET
You no longer need Mono. .NET Core builds ELF binaries by itself. Both as an ELF stub that runs IL DLLs and as a work in progress native compiled ELF binaries.
Don't be a dick dude. The guy could do more Google searching, but our industry doesn't need hostility towards people trying to learn either. Before the dotnet CLI, the .NET Core project was a hodgepodge of acronyms that were hard for newer devs to get started with. Either be kind to new people or at least ignore their comments and posts and let the more patient people help them out.
Fairly recent yes. I have Mono in production too. This isn't quite on that level yet. But it does now run on its own. I'm looking forward to when the native binary compilation reaches maturity. It literally builds as if it is a C++ app, and you can debug with gdb.
Try a tool like [Fluent Migrator](https://github.com/schambers/fluentmigrator). The kind of magic that EF uses will always screw up eventually.
They should have kept it vnxt. Core sounds silly IMO.
I've ran into issues like this before - when I got the "can't delete because we can't find the object" stuff I created a table in the SQL database (using regular t-SQL) just so the migration had something to do delete. I had to keep making objects (tables, columns, indexes) until it eventually cleared all the errors. It wasn't fun. I did this all on my local dev - would e terrifying if this happened in production.
Resharper has a little wizard to help out with generating the gethashcode and lithe requirements. Gotta know your objects but it helps with the boilerplate code 
C++ / Native doesn't automatically mean high performance. I really wish this misconception would fade.
There are 2 immediate performance improvements with native code (C++ and native are not synonymous). The first is that there is no JIT delay. The second is that loading executable images into memory is faster. This is all you get compiling to native in .Net. You could do the same thing by running NGEN on the assemblies, which produces ahead-of-time JIT compiled (e.g. native) code. Now, onto C++. C++ differs in 3 fundamental ways from JIT compiled managed code: 1) no GC, 2) careful memory allocation, and 3) better use of the hardware. Now, all this sounds wonderful, but if you are doing things like data access to a database or making calls to a remote network server, know that these operations dominate the overall performance characteristics of the application. Handling your memory more carefully or using the hardware more specifically will give you a perf boost, but it is likely only a small or even unnoticeable percentage of the overall performance of any given execution path*. Further, you now have to manage all your own memory. There are good C++ practices (RAII) which allow scoping to take care of memory allocations, but you have to code to it - it's not just some magical switch you turn on. It's effort. All worthwhile performance is effort. The misconception is that C++ / native automatically makes a slow app fast or gives you an amazing speed boost is just fantasy perpetuated by devs who don't understand managed code or C++ and think there's a world of difference between them in all cases. * I know there's gonna be nitpickers - yes, in certain cases, on certain classes of devices, in certain domains, C++ is really provably better. Also if a dev is already a good C++ developer, the costs to code C++ are less. I code in both, and still prefer managed code because 90% or more of the time, the perf difference is negligible, and C# is an easier language to get right.
No, `IEquatable&lt;T&gt;`
ASP.NET Core is open source as well
Can you be more specific what you mean? ASP.NET Core and .NET core are both open source.
What do you mean by "the open source stack"? There a lots of ways to put together open source parts into a full stack. If you mean a LAMP stack then I'd say the two big advantages are that required amount of sys-admin work is less in Windows than with Linux, but mostly that PHP is an awful language and C# is a great one.
it's not a legit question. just glance at his post history and you'll understand
If it's a small enough project you could use SQL Express?
Thanks, I was not aware of that option. Would it only run in Windows?
SQL Server Express is free and more than enough to power any project you are likely to write. SQL Server and SQLite are just about as far apart as two databases can be with regard to what they'd be used for. What kind of project are you writing?
It's a small project. I was planning to take advantage of the new cross platform asp.net core and host everything on linux, either Google Cloud or AWS. But it does not seem that this is viable with SQL Server Express, is it?
Windows only as far as I'm aware unless you try using with something like wine. Has limitations in terms of database size/cores/ram etc but certainly worth a look for small projects etc
Nope. I don't get this new obsession with trying to run .NET code on non-Windows machines? There are zero advantages and dozens of disadvantages. There are many fine programming and database tools designed to run on Linux. Why not just use those? Or, if you want to use .NET, why not just do it on Windows? Visual Studio is one of the best parts of the .NET environment, why miss out on that? You can run pretty significant programs in the AWS free Windows tier.
I work with Mono daily and it's not an obsession just the fact I have over 10 years of .NET experience which seems a waste to throw away. It's not without its problems but I've made the assumption it's easier to work around these than dive into a framework I know nothing about.
Rest assured there will be support for MySQL. MySQL is still the world's biggest free RDBMS and if it doesn't get supported then there really isn't any point in EF7 being an open source framework.
Oh dear.
Well spotted.
I'm happy to, I enjoy learning new things. I have production code running under Python, Ruby and Node but at the end of the day .NET is the one I know really well and for the big projects I'm working on it doesn't make sense to commit to a framework I'm only partially familiar with when .NET code runs perfectly well on Linux. I did consider moving away over a longer period but now MS officially supports Linux I don't think it's necessary.
Is it because I plugged PHP? I know, I was surprized to hear myself do that. Sometimes you gotta call a spade a spade, PHP is non-worthless. I feel trashy now, like I need to wash my hands.
`SpecialEqualityComparer : IEqualityComparer&lt;T&gt;` for comparing two types by a non-default equality comparison and `ThisType : IEquatable&lt;ThisType&gt;` for default comparisons. I have a few ways to generate the former in our production code (stuff like a comparing by a single property). Just today I was playing with expression trees (for something else entirely) and decided to make a thing: https://gist.github.com/bbarry/d4be83785e57e2088496 
NHibernate is alive and well. It is easy to use and connects to just about everything. I would use that. [edit] Oh, and Postgres is pretty solid for an open-source DB.
OP here, love how Postgres got resurrected all the way from the 60s. It's all fine and dandy and everything, no need to sell me. But what about the connector? Is it anywhere close to production ready? How reliable is the community driven project? Does it only depend on a single dude who might leave us hanging?
The "counter point" to that, and the biggest argument *for* Dapper (or PetaPoco, or any lightweight ORM) IMO, is that all that hand rolled SQL will map everything your app is doing, you'll be able to abuse SQL for all its worth, and depending on your use case/tech the automapping can be a lot more portable than EF will be... Not to mention being able to innovate faster. Glue is bad, but SQL glue is easy sauce... Hitting EF roadblocks? Not being able to support any and all customer DBs? Thats something else... Oh, heard about that cloud thing? DynamoDB, MongoDB, DocumentDB: a good mini ORM will let you switch between, and support in parallel, the best and cheapest you can handle :) 
Would Dapper work out of the box with asp.net core features, such as Identity (https://github.com/aspnet/Identity)? If not, we would lose many benefits of asp.net core.
Well... I think the point is to start by not thinking of it as 'optimised' at all. The assumption that a specific part of your data management should dictate domain logic is widely held, but loads of mature systems disprove it. Numerous cross db-platform apps based on ORMs are out there... Persistent ignorance, combined clean intentional access patterns, and cache enabled logical system components (especially second level caching for heavier ORMs), remove almost all points of domain compromise. That leads to standardized access of data, which enables easier datasource integration, which leads to a plurality of data sources. That plurality is the water that erodes the ties to a particular backend, leaving clean abstract access patterns. Now portability: portability has very little to do with "migrating" in that sense... though the Enterprise space at any given point is prolly 18% those exact kind of jobs with legacy systems, but that's beside the point. Firstly it's plurality of datasources. HTML, JSON, XML, CSV, XLS, PDF, DOCX, TXT, INI... Loads of ass boring LOB programs have all these formats as data sources, and more. The assumption that every thing *must* be a DB is a bad marketing hangover. It's just entirely coincidentally how major database providers train developers in their marketing, I mean, "coursing" material always seem to push that approach... But on the side of aggressive development, it's not about swapping backends. It's about accepting multiple new backends with no changes to domain logic. Plugging in a remote REST service, a MongoDB backend, a DynamoDB backend, a Postgres backend, an Oracle backend, and a secure memory based backend can, and should, look identical to the application. Using an ORM that encourages sanitary access patterns and separation of responsibilities is the first step.
I won't disagree that Java is a better choice than PHP. Herpes is a better choice than PHP ;) I was responding to your post both as an independent statement, and in context. Alone: C# devs have C# code and C# libraries that can come with them to Linux. Unless there's some massive linguistic advantage to Java (and it's the other way around, TBH), changing platform is no reason to throw out those assets. In context: &gt; *I don't get this new obsession with trying to run .NET code on non-Windows machines... -- I'd rather name it credit card protection... -- Or use MySQL and PHP on Linux... -- a better choice on Linux would be java.* The original complaint was answered by the correct answer: cost management and hardware maximization. This is the entire reason .Net is getting open sourced and Docker is being pulled in, MS just can't compete in some big Enterprise spaces without cannibalising their licensing model. Linux is just much cheaper and generally better in the cloud, that matters a lot to the orgs that have most of the money. That suggestion was met with something that kinda denies the premise. Moving existing .Net code to Linux for .Net orgs and developers is about using existing assets and knowledge to leverage cost savings. Moving to another stack with fundamentally different roles and capabilities is the opposite of what they're after. Changing to Java on top of that makes it less uneconomical, not profitable. And MySQL is a waste of time. Use Postgres if you're sql-serious, or any of the alternative "No" and "New" sql DBs. 
Is [this](https://msdn.microsoft.com/en-us/library/ms243748.aspx) what you're aiming for?
MySQL doesn't support EF6 right now! There's still 2 year old bugs like joining with booleans sometimes break deserialization or dynamic group by's selecting non-existing columns. 
Depending on your other requirements, MongoDB could be a good choice. Easy to set up, no need to map classes to tables, no EF. The official c# driver is great.
Holy shit.
And for lots of serious issues, second level caching lets say, NHibernate has been streets ahead of EF for a decade or something... It's not always the answer, but somehow they've managed to be 'right' this entire time *without* breaking backwards compatability... what... 3, 4 times? Short lived software with bad assumptions isn't what I want in an ORM...
Npgsql. I use it in production ready codenfor postgre now. It works great. 
Postgres + Npoco.
&gt; Postgres + Npoco. Why NPoco over Dapper?
Oh yeah, also web api 2.
According to the roadmap they do not support asp.net 5 , yet. Do they? https://github.com/CollaboratingPlatypus/PetaPoco/wiki/Roadmap
&gt; But if you think your site's going to be huge, why are you even using ASP.NET? That makes me confused. 1. What is your alternative suggestion for sites that might be huge? 2. Why not asp.net for huge sites? Isn't Stackoverflow huge enough? 3. I sincerely hope one day your rocket gets to Uranus.
Yet...
If for some reason you can't look at the installed programs on the server you can tell from looking at the properties of the clr.dll as described here: http://blogs.msdn.com/b/rodneyviana/archive/2014/12/23/identifying-the-net-version-you-are-running-2-0-4-5-4-5-1-or-4-5-2.aspx 
This may or may not work depending on how the server is configured but try this in a command prompt: curl example.com -I This will return a http response header for the specified domain - it may contain the ASP.NET version under the X-AspNet-Version field. (Note: you will need cURL installed for this to work) 
MySQL is far from the only choice and just a little less further from the right choice.
EDIT disregad this. I'm talking rubbish. ~~If you aren't moving from 2.0-&gt;3.0, then it should just be:~~ ~~Install new .net framework on the host if it isn't already. Then recompile and redeploy your application, targetting the new version. This can be deployed the same as any code change~~ ~~Installing 4.6 on the server should change nothing (there are a few edge cases listed on the "whats new in the .net framework" pages on msdn). Retargetting your application is scarier, again the whats new pages list breaking changes.~~ ~~Moving to 3.0 (or 1.1 :P) is a lot bigger change, hopefully that's not relevent to you.~~
Colleagues of mine wrote a postgresql connector for EF7 so it is possible to extend it. If I heard correctly it was released or added to EF. I'm not sure about that. Still that must mean support for more databases will be coming.
I'm not aware of any breaking changes between 3.5 and 4.6 Start by installing the framework and making sure that nothing got borked in the process (highly unlikely). Then upgrade the app locally to make sure it runs. Then promote it to test/production.
No, but try posting your DB design then maybe people can help there.
After I get a working beta I plan to throw it on GitHub, still far from being ready for that though.
Alpha or release candidate 2? 
Checkout firebase with the angularjs bindings
Yeah I remember going through a how to with Firebase but was expensive at the time. Didn't Google recently buy them? 
Such an awesome concept, but when I tried it out, I had a lot of trouble getting security right without a server in the middle, which kinda defeats the coolest point. I guess my requirements were unusual, but it wasn't something that would be at all difficult to write if I had a complete language to write the rules in.
I use mongo and am pretty happy with it on a fairly large system (10's of terabytes). If you run a replica set you just have to consider on queries if you need to be consistent or eventually consistent (reading a secondary that may have a replica lag depending on your load and throughput). DynamoDb has fairly bad support and has quirks like on certain queries it can only return a certain amount of results and you may be throttled on inserts as well. I've heard good things about RavenDB but have had no experience. 
Grow up dude. Maybe try reading what I said instead of being a condescending asshole.
Currently it's RC1, RC2 will be next month. We can argue about the quality and whether it shouldn't be called "beta", but these are official numbers.
If you have relational data I'd stay away from pure NoSQL solutions. The serialization, deserialization load is pretty light weight, so no real need to change. 
Have they fixed the pricing on documentDB? It's way too expensive from a startup perspective, even with bizspark. Also every time I've ever looked at the official samples they don't work with the latest API. Even when someone from the docDB team did an AMA, I shared as much. The bad samples were removed but new ones weren't put in their place.
Has anyone played with rethinkDB? That's the database that really has me excited. I really love the realtime notification support built in. I imagine realtime master systems engaging with mdm solutions that just keep disparate systems in sync. From an enterprise perspective that's huge. I can't wait till the product matures a bit more.
Most of my existing stuff simply uses SQL Server (typically on Azure) with simple transforms via micro ORMs (I'm partial to Dapper and Simple.Data). I prefer NancyFx, as I'm a bit old school and mix and match JSON vs html views as needed. All that said, I've been meaning to dive deeper into PostgreSQL as an alternative. It has a native JSON data type, but obviously it's also a traditional relational data store so you can mix and match as needed.
[SQL Server 2016 supports JSON](https://msdn.microsoft.com/en-us/library/dn921897.aspx)
That UML Diagram is hard to look at on mobile but that looks exactly like what I was looking for! Thanks
Your point is valid, I'm still abit gun shy to put this mess on GitHub, it's more of a POC then anything right now, some parts in MVC, some in API, half Angular half Razor, whole controllers commented out....thing of beauty
You can use Dapper even if some parts of your stack indirectly use EF. Sure, you lose some startup perf since you load the EF model regardless, but small EF models aren't that expensive. Even if you use EF extensively, it may be wise to use Dapper for specifically tuned queries simply because it's easier to tune a query if you can write the sql - and there's not much reason not to.
Why wouldn't you use sqlite? It's almost certainly more reliable than postgres in practice (due to its relative simplicity and convincing testing story), so if anything, you'd need "balls of steel" to use postgres in production. Both are robust enough that you don't need to worry. 
Json is not ideal for a data store. Your main requirements for a database are usually indexability, searchability, compression, security and programmability Json gives you none of these. Yes, its human-readable , that's the only advantage. Its also a security risk.
**Open Source:** For sessions =&gt; Redis Multiprocess =&gt; Postgres Singleprocess =&gt; SQLite More power / specific use case =&gt; NoSQL
This is true too! There are some areas JIT can shine! I imagine the benefit isn't as useful on Linux where applications are usually compiled at install time.
Interesting concept, talking about your users being testers..
Honestly that's okay. It doesn't even have to run. People aren't going to look at your project and dismiss you because the project is a mess. Someone may come by and think its a cool idea. Maybe even offer pointers on ways to make it better. From a job prospect when I evaluate potential candidates for work I usually go back and look at the commits. I wanna see the messy disorganized work. That way when I go back and look at it in its current state I can appreciate the hard work. Plus git has saved my ass more than once. I had a hdd fail on me. I've made changes that broke code in ways I couldn't solve so I just reverted to a working commit. That's the end of my rant. But good luck!
No problem. Please allow me to clear up your confusion and tell you exactly why I said that. Keep in mind that I'm not saying to avoid ASP.NET entirely - I'm saying to use it if you want (I use it myself). This might sound a little insulting, but I'm letting you into my personal thought process and opinions here so... * Stackoverflow is the one and only site that people ever bring up in order to defend their position. (That position usually being "I only really know ASP.NET - what wrong with that?" I *myself* have been in this position before and then I stepped out of my comfort zone and learned some new things. Now I don't have that problem anymore. Now I can do my huge web apps with purely static HTML if I want via Knockout, Angular or React with various Amazon web services or I can make a custom Node.js/Express server or use hapi or lots of other things!) * The argument relies solely on the existence of an outlier. **"Neil Armstrong went to the moon, so can I."** Also, look closely at StackOverflow, they're now using a lot of Linux based technology around their core ASP.NET/**SQL Server** stack like Redis and other things. So, you're going to be getting out of your own comfort zone whether you like it or not anyway. * I generally feel like if you're going to do something you should try to do it "right", where "right" is defined as the generally accepted, de facto standard way of doing things. That's just me though and I break this rule whenever I want so really - don't even listen to me! :) Also, while there is no *single* de facto standard in web server frameworks for huge sites - there *are* things that people do a lot of and things that people don't do a lot of... * Other people say just use what you know and whatever you'll be productive in. That's good advice too and I've actually tried to follow that before but it was too late for me - I had gotten my first taste of the sweet JS + Node.js + Express nectar (plus all the high quality third party libraries for Node) and I was hooked on it's apparent simplicity over ASP.NET. Here are my other responses: 1. Alternative suggestions are: A purely static site with a third party Identity service like Amazon Cognito. You'll need Angular, React or Knockout. (*Pick Knockout if you want to get up to speed really, really quickly.*) If you can't do your site with all static pages, then do mostly static pages and some dynamic pages. If you can't do that, do all dynamic pages. For dynamic pages for a huge site, I would use Node and Express. Really easy to use, runs on any OS and you can automate the shit out of deployments and testing it with npm tasks, gulp, karma, etc, etc, etc (which the ASP.NET is now copying or trying to integrate into ASP.NET...) 2. Oh, I answered this one above basically. 3. Thank you! EDIT: I also can't emphasize enough that "just using what you already know" is really good advice if you can just do that. Just build your app and worry about the scaling part later. Most people who use statically typed languages though can't do things without planning ahead though, so you might have a problem there. I couldn't do it - I wanted to know that any work I put into my site wasn't going to waste. But none of the sites I ever built became huge so it essentially hasn't mattered yet for me. That's the gamble. I always win though because I love learning new things and that's why my side projects are basically never failures :) Anyway - whatever you choose, you can always change it later.
So you would advice using Mono over .NET Core? Do they both support setting up a Web Api?
The renaming to ASP.NET Core is something **still in progress**. The latest stable version (which you are retrieving here) is still **DNX RC1**. You can either wait for RC2, scheduled for February, or venture into the world of unstable. But I think even the latest unstable is still named DNX and using the DNX tool.
Just ignore this user. He is just a troll who likes to cause controversy. Keeps doing that across all programming related subs.
I tried installing the new "dotnet" on a fresh ubuntu install. Didn't go too well, it used to work with a few tweaks and pinned package versions, now it just goes YOU ARE NOT USING UBUNTU 14.04 and fails to run anything. Any chance we could see some support for the current LTS version? Or just a --i-know-what-im-doing-ignore-os-version flag or something? Sheesh.
That haacked article has an interesting approach by adding a hidden *indexer* for each group. I suppose I could just have a random 5 digit integer to ensure the (max) 25~ish ingredients don't have a clashing index. I'll have to give it a try.
Other random responses: I also looked at the new dotnet "DNX" stuff and yeah - it's way too new and I'm good on that for now. Haven't used enough Go yet to know how I feel about it fully. I think I get why they didn't do generics, but it's a little annoying to people who don't care about their core values. I don't worry about who maintains Express or other Node.js libs because I can maintain all the ones that I use. Express is really simple, it's nothing to fix if you have a problem. It doesn't even do that much so I don't think it needs to keep changing. It's widely enough used that if there's a security bug you'll hear about it and it will be fixed...but mainly, I pick Node.js libs that are small and focused and don't have a lot of dependencies.
It is clear that the author has no idea what he's actually doing. Just awful.
believe you can use random guids for the index too with a bit of effort http://www.joe-stevens.com/2011/06/06/editing-and-binding-nested-lists-with-asp-net-mvc-2/ 
Try using cuid for the indexer, its available both in JS and .net: https://github.com/moonpyk/ncuid
I assume that you're doing a HTTP POST operation? Have look at what's actually going over the http request. The data that you send should be in the POST body. Also verify the content type header to see what format the content is expected to be. If you use JS to do the post then you can [send JSON data and bind to that](http://codeforcoffee.org/asp-net-mvc-intro-to-mvc-using-binding-json-objects-to-models/) otherwise it will be of [Form data](https://www.ietf.org/rfc/rfc2388.txt) and AFAIK then they need to [look like indexed array for ASP](http://haacked.com/archive/2008/10/23/model-binding-to-a-list.aspx/).
Full disclosure, I didn't read the entirety of your post. I did a very quick search and it looks like UE supports C# you could make your own C# wrapper around UE and just call it from your vb code.
Those method naming conventions... 
You could definitely do this with WPF. WPF certainly works just fine with VB though you're right that your not going to find nearly as much educational material geared towards VB. VB.net and C# are for the most part completely interchangeable as they both compile down to the same IL code. There's one or two things VB does that c# doesn't and maybe a dozen of the other way around but they're not likely to be things you'll need for this project. I really suggest you get yourself competent at reading C# code at the very least. There's definitely a lot more stuff out there written in it and it's not really as different from VB.net as you think it is. The structure is very similar, it just uses different keywords and symbols to do the same things. Basically it's a lot more compact. The only downside from transitioning from winforms to WPF is that you're going to want to change the entire structure of your program. In winforms you're directly accessing the controls and telling them what to do. While you can do this WPF, you'll be fighting the architecture the whole way and it makes for very messy code. You'll want to look into the MVVM pattern. Basically you write your code that does things almost completely agnostic of the UI (save for implementing IPropertyChanged) and then UI watches for changes in the state of that code to change it's state. Doing custom graphics and stuff gets a little more involved but it's not going to be nearly as daunting as using a full blown game engine.
there shouldn't even be a need for a wrapper since UE can't tell the difference in intermediate code, whether it came from C# or any other .net language.
you can do the effect in the video just by using VB.Net's GDI+ capabilities (or some GDI blitting for that extra speed if needed at all). No extra engine needed. However it might not be the prettiest code in the end.
I think this is far more complicated than what is actually needed.
Yes, a POST when the recipe is filled out by the user. However, this is an issue with the ASP.NET MVC model binder not being able to pick up an array of complex objects without some tweaking. I'm not sure converting the submitted data to JSON is really necessary.
You could run grunt in a cmd window and have it watching files that change then moving them over. That's basically how task runners work on Windows outside of VS. Not sure if you can build a .net project with it but you could definitely handle everything that doesn't require .net compilation like sass, typescript, minification and copying files.
Doesn't have to involve AJAX, but client-side tracking of the list items seems neater (re-ordering hidden indexes before submitting feels a little hack-y). If the UI allows significant changes, up to deleting the entire list and replacing it with completely different items, then model binding doesn't seem like a good fit. Have you looked into client-side viewmodels? I've used knockout a bit, where each item is "observable", tracking its own changes, then when all is done ko can generate a JSON representation to submit to the server (yes, normally via AJAX!) http://learn.knockoutjs.com/#/?tutorial=collections http://learn.knockoutjs.com/#/?tutorial=loadingsaving
I'm currently doing the same thing. Also a junior developer. Let me know if you know of a better solution.
I will do! It feels awkward doing it that way and there are horror stories around the company about when the process went wrong.
Yeah, the solution from the haacked article were rather simple and really only added a few lines of JS code to the entire page.
I have not touched any of the Knockout or React stuff as I've never really needed them. I didn't want to make repeated calls to the server (AJAX) and adding an hidden indexing field + ~4 lines of extra JS code solved the issue I was having with my previous code.
You're using code first instead of database first. Either you generate tables from classes or vice versa. You don't make the model classes by hand if you've got the db already though. If you're using the template from VS and then you need to track down where it drops and rebuilds the db then comment it out or remove the code. I can't remember exactly where it is but a little googling might help. Here's a link for a tutorial of db first. The 2nd page shows how generate the models. https://www.asp.net/mvc/overview/getting-started/database-first-development/setting-up-database 
He wasn't asking about dapper. You dapper guys are just like the Linux people, every time there's a question on how to do something you pop up to promote your favorite software.
It's not well explained in the article, but to use parameter injection from a DI container to an ASP.NET MVC Controller (at least with the ones I've used like Unity and Ninject) you need a custom controller factory. (You don't end up hard coding the dependency resolution of course.) Granted, parameter injection isn't the only way to go.
Web Expression 4. I'm sure i could install Visual Studio though
I have never used it before, but I believe it should be ok. 
Sorry for trying to help! I won't do it again, I promise. 
CI with teamcity or similar and deployment via Octopus Deploy. That's been the best setup I've seen so far.
Its using WebFormViewEngine instead of razor I think.
Not sure if you meant to but it's ***Model*** not modal. I'm not trying to be a dick, it's just I kept thinking of the overlays on web pages instead of C# classes. Aside from that nice explanation. 
Because they are not implemented yet. It was also like that when they released the current portal (the "new" one is the third portal version).
The new portal is entirely built around Resource Groups. All the features that haven't yet been migrated to RGs are not available in the new portal
This is an option I think for software but what I am trying to distribute is a developer tool and I was wondering whether same eco-system exists for .NET Core apps like npm. Also I read somewhere that even executable application can be packages as NuGet.
I've used DevExpress' DevExtreme for a large SPA. It gave me a framework and some UI elements to write a mobile site but I ended up hacking things enough that I can't upgrade to the newer versions. Perhaps I extended it incorrectly and, with deadlines, had to make some bad decisions, but I have since moved to React/React Native stack and don't regret it. I kept the WebAPI/EF stack for the backend.
I have been using Devexpress tools for many years on my internal facing web sites and will not look back. I don't make externally facing sites any more, so i cant speak to that. I can create grids with full excel export functionality with a few lines of code or reporting that is second to none. Not just about the architecture but the features you get from the components themselves. The grid and features in the devexpress suite are amazing, and contain a lot of features that the builtin tools simply do not have without extensive programming done to mimic those features. While I cant speculate to the financial stability of Devexpress, but I don't think they are going out of business anytime soon, so there should be no worry about longevity of support or ability to get assistance. As far as the community goes, Devexpress has a lot of customers, a lot! Everyone gets excited about open source and cutting edge platforms, but if you work for a corporation, one that is a publicly traded company, you will find that cutting edge is frowned upon and typically avoided. In fact I have found that companies like devexpress where i can get support contacts is actually a good thing as it keeps them on the hook for support. I use bootstrap and a few other jscript library's and webapi's within my internal sites that communicate with external api's including a internal AX site. All using devexpress components. Best of luck!
What are the pros/cons to --native?
My team and I have been spending the last 2 years ripping out DevExpress controls from our enterprise application. I have at least another 2 years to go. It sucks. I normally don't go on rants about tech products but devexpress has a special place in my heart. We only used the webforms controls so take this with a grain of salt if you use their other products. 1. Cost - so high for what they give you. 2. Performance - Slow. Everything they give you just makes the site slower. 3. Page weight - talk about bloat. 4. "It just wasn't designed for that, sorry." - Heard it many times from their support about basic things. For example we needed to put a devexpress page within an iframe. 5. Viewstate is massive. I mean really really massive. 6. Upgrading from one version to the next is a huge PITA. 7. Creating semantic html is almost impossible. Try styling with their pre-generated styles is crazy hard. 8. Responsive controls? Forget about it. Sorry for the rant, but it has to be said. DevExpress isn't for everyone and i'm sure they've improved over the years but in my experience that pain and suffering wasn't worth any productivity gain. 
That's actually a GREAT read and thanks for that. I knew they were related/similar but not that much.
Yes Nuget and the Nuget Package Manager are what you wanting. Even the Nuget CLI app is distributed this way - https://www.nuget.org/packages/NuGet.CommandLine You can include powershell scripts to run on install if you need to register with visual studio.
It seems MSFTs priority is to grow and build new services and the admin experience hasn't kept up. I thought when the preview portal went live they would transition in 30-90 days and shut the old one down. It's weird they've kept them both alive. It makes me wonder if they got negative feedback and their headed back to the drawing board.
I haven't gone to that extreme yet, but have to admit they're making it harder for me to recommend for .net devs. I'll probably look to migrate a small project as R&amp;D to a linux vm using the new "core", as that's a nice inexpensive alternative that can also scale up or out.