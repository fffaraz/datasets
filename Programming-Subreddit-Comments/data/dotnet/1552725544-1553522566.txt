https://github.com/Tyrrrz/CliWrap/blob/master/CliWrap/CliWrap.csproj#L4
Cool!
.NET Core yes but UWP has some restrictions. 
Thank you for the concern. My hosting (a2hosting) suspended my account yesterday night for reasons they specified as "abuse" without warning or proper explanation. They still haven't answered me so probably a good time to find an alternative.
I don't think UWP implements .net std 2.0, so probably not.
Of course!
Thanks. I've forgotten structs can be readonly now. There are so much new stuffs.
Well it’s mostly an annotation like static classes, that doesn’t do much in itself. As in: you could achieve this already. 
So yeah then use Xamarin. It is cross platform ( iOS and Android), but for some reason not popular . Kotlin should be easy to pick up though. Also you miss out on all the nice front end stuff if you skip. JS is also cross platform. Blazer is C# but not yet popular. 
You should try blazor/razor components. Yes you still have to write html with css but you can stick with c# both on the front and backend, and can reuse a lot of code
Pcpartspicker is pretty good for getting a rough idea of how much a build will cost. If a business does the build for you add a bit extra (worth it IMO)
Looks useful. Will it work if the exe is 32-bit and my process is 64-bit?
Also Bridge Technology typically vanished. Webforms for windows forms programmers: gone. GWT for Java programmers: gone. VB.NET for VB6 programmers: no one learns it anymore 
what about WebSharper ?
While blazor will probably be a fully functioning release at some point it doesn't make sense to recommend it right now. 
CSS isn't a nightmare if you know what you're doing. Vue.js is a very easy to learn library for front end development and there are a lot of great component libraries to make building out features quick and easy. You can focus all you want on the back end but if you skip putting good work into the ui your users will hate the site. 
Well, full blazor not, but I think Razor components would. If you think of razor components as the new version of razor pages then it is just a new version of an already used framework that has a sizeable user base. Also there is CSHTML5 going open source. Although I don't really like it if you want to use xaml on the web it is usable and they claim companies use it in production. 
&gt;Yes I do totally agree regarding the nice UI, I will tune it later on once I finish with back-end, thx for suggestion, will check it. &amp;#x200B;
Thx, but it seems that they indeed still underdevelopment, and there is still little help resources for it. &amp;#x200B;
This one seems the most complete one till now, thx for the suggestion.
Yes use C# Core. ON THE SERVER
It shouldn't matter.
I would do a regular ASP.Net Core site. I would use [Bootstrap](https://getbootstrap.com/2.3.2/) 
It has performance benefits when used in readonly-fields or in-parameters. More precisely, a defensive copy won’t be made on access. 
Can you please advice in short the difference between bootstrap and WebSharper?
Consider learning (and using) angular, react or vue. Your users will love it and it will be good for your career/marketability. 
I have switched to using dotnetcore 2.1 with vue.js and veutify. Go look uo veutify and if you like the material design it’s very easy to work with. 
What is the difference between this and just having private setters on a public struct? I’m still learning...
Private setters means that it can be set from a method internally
Slightly related, I have an XPS 15, and I also have had terrible experiences with the graphics drivers. I don’t think I would get another dell. Do other people have these problems?
Albaharis free ebook explains things very well http://www.albahari.com/threading/
I have not used WebSharper. Bootstrap is just adding css classes for styling. Very very easy. It also has a grid system for responsive design layout.
I have used Infragistics and Syncfusion components and they all have their headaches and learning curve. I don't have a real suggestion for what front end framework you should use, but as you get into the front end make sure your Javascript tooling is in place before starting. Grunt/Gulp + ESLint + Webpack will go a long way to making your JS coding experience less constantly-throwing-keyboards-because-javascript-is-weird.
Great. Thanks.
Correct, but if the constructor is the only internal method setting the properties, then what is the difference? Wouldn't that mean that once the struct is made it is immutable and you'd have to make a new one to have different values?
I think it's relevant, because this machine was a very populare .NET developer choice for a while and is still out in the field. It's successor also exhibits many performance issues, slowdowns, and graphic problems that would especially plague 4K users who like to keep a higher resolution to put more dev things on the screen. Just to comment, in the past year or so since I've had the machine, I've seen and experienced some of the following (XPS 15/9650, 512gb/32gb) 1. **4k Lag** - people report 4k scaled at up to 200% causes lag. At 1920x1080, scaled 100%, things work just fine. 2. **Hybrid Switching/Freezes** Intermittent 3-4 second "freezes," where the cursor stops and then resumes. This is thought to be when the integrated graphics switch to discrete and is fairly unpredictable. **You can't turn off integrated graphics**, so you're stuck configuring the **NVidia Control Panel** to explicitly handle certain applications. There's a report that this is less pronounced on Win 10 rev1803, but I haven't confirmed this. This is pas (https://forums.intel.com/s/question/0D50P0000490OBLSA2/dgpu-switch-and-freeze-problem?language=en_US) as is thought to be a factor of incompatibility with their HD integrated adapter. 3. **Heat/Performance Throttling/Fan Noise** people have found their heat sinks to be improperly or sloppily pasted and for the heat dissipation to be generally inadequate. There are elaborate instructions for adding thermal paste and other modifications to reduce the heat with apparent substantial results. This allows some overclocking or underclocking to reduce heat and increase performance. [Fan Noise](https://visser.io/2017/08/fixing-the-loud-cpu-fan-on-the-dell-xps-15-9550-2016/) is addressed here. 4. **Maxx Audio Causing Lag** with poor drivers; Dell may have a solution, but it's also recommended to install stock Realtek Drivers. 5. **NVidia comes preconfigured with 'lag** by defaulting to a *Share* option, analagous to recording game clips. This configuration setting is found in the **GeForce Experience App* 6. **Power Configurations** that come stock may throttle, even on AC. There are ways within Windows to unlock more power settings, and the general approach, on AC power anyway, is to prevent anything from going into standby mode, period. 
What are the use cases for read only structs?
[Ding ding ding](https://codeblog.jonskeet.uk/2014/07/16/micro-optimization-the-surprising-inefficiency-of-readonly-fields/). Making `Int256` a `readonly struct` in that post should eliminate the slowdown.
I just implemented it in a MVC project I can fit the code together in a repo tomorrow. I do agree that the examples of stripe for dotnet are quiet sparse.
I believe I get how to make the bank account and link it to the Connect Account...I suppose I should use Elements and stripe.js for any and all forms I need. That's just something I'd like to have 110% understanding of, since it's so important. Definitely don't want to get someone's bank info stolen.
1. If they are only set by the constructor, you do not need a setter. 2. Readobly on the struct is both telling thw developer and the conpiler what the struct is, the developer to show intent and the compiler so it knows when to optimize etc
ok, thanks for the clarification!
What do you mean? Many places you would need a readonly struct. What are the use cases of anything being readonly really?
Agree but not Angular, it's dying and on the way out. It's way too opinionated and complex. 
So it has not something like ready to use UI components?
Well, those are commercial products, not for me... Yeah I am familiar with JS, I actually hate front-end more due to it than CSS)), but thx anyway.
But what are the use cases for a readonly struct?
I don't think Angular will die any time soon... I think OP should do a little research on the three, spend a couple hours doing tutorials in each one. [https://www.codeinwp.com/blog/angular-vs-vue-vs-react/](https://www.codeinwp.com/blog/angular-vs-vue-vs-react/)
Neat.
Nice article, thx.
thanks, do you have any good resources on sql performance tuning? I'm making this post because im going to have to fix a lot of nasty queries in a postgres EF core app. 
choose 1 of 3. vue, react or angular as a back end, you can be a jack of all trades with FE but never an expert. i chose angular and the framework is massive. i had a similar question which was "best". there isn't just preference. I would say that vue is much easier to get started with than angular and less verbose in code bloat. react i dont have experience with. i did read that with all these frameworks the hello world crud app you find in tutorials is never enough, youll still reach pain points all the way with either frame work.
Passing lots of light-weight data structures around in code, without allocations, and now with readonly, without local copies. Efficiency for calculations like in games.
Nice! Thanks. 
Generally immutable data is faster. This is why some newer languages like Swift double down on declaring things \`let\` (immutable) instead of \`var\`. No doubt the C# compiler can extract extra performance out of it as well.
&gt; Correct, but if the constructor is the only internal method setting the properties, then what is the difference? Practically, yes, but making them readonly has a few extra guarantees: 1. The compiler prevents you from accidentally mutating the properties (maybe another dev comes along and doesn't realize the properties aren't supposed to be used outside the constructor) 2. Properties are just syntax sugar for Getter and Setter methods on top of a compiler-generated field (kind of like Java, but in Java you have to type all the code yourself). With readonly properties (no private set method), the compiler can make the backing fields `readonly` which allows the compiler/runtime to perform additional optimizations. When you have a private setter the field cannot be `readonly`.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/latexandloaf] [What architecture\/pattern do you follow for creating your Web APIs?](https://www.reddit.com/r/LatexAndLoaf/comments/b1xb88/what_architecturepattern_do_you_follow_for/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/latexandloaf] [Building Microservices On .NET Core - Part 4 Building API Gateways With Ocelot](https://www.reddit.com/r/LatexAndLoaf/comments/b1xb8h/building_microservices_on_net_core_part_4/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
I see. Thanks!
I use Angular from where I work, it acts like C# and Asp.net wherein it's pretty opinionated on how to do things which can be a pro or con depending on the developer / team. The easiest out of the big 3 (react, angular, vue) imo would be Vue.js, though if you're a fan of C# I suggest using Typescript for any of the 3 front-ends (though Typescript is required for Angular either-way). As for usable components, you'll have to decide depending what framework you choose (each with a lot to choose from) though for Angular we usually use `angular-material` which has a good set of components to work with.
You will never receive bank account information. You will only receive tokens that can be used with your API key to make payments
https://topswagcode.com/2019/03/03/Serverless-payment-with-AWS-Lambda-and-Stripe-Guide/
I have two of the LG - 27UD69P-W 27" IPS LED 4K UHD monitors. Been using just one since that is all I need. My video card is the Nvidia GeForce GTX 1050 with 4GB of RAM. It may not be enough card to run both. It was like $250 and the monitors were $550 each. If you want full screen 4K video playback, get a lot of video card or the video will studder. My workflow view has Visual Studio on one 1/2 side of the monitor and a browser on the other side or multiple VS instances 50/50. Having documentation and your code windows up without having to move your head or alt+tab is awesome. Then there is Vivaldi (Chrome) browser that lets you split tabs so there are two web pages within one view split down the middle. Using Vivaldi will give you two windows for specs/API docs on one side of the monitor and VS on the other. Having 3 windows in view works incredibly well for productivity. The big gotcha with NVIDIA is to disable their automatic driver upgrades. Same with Windows Updates. Keep a known good copy of a driver package so when you do decide to upgrade Windows and the driver doesn't work, you can have a fallback. Then re-disable NVIDI's driver updates since they have been known to deploy shit drivers bypassing WU. The other situation to fix is scaling. Windows will want to scale the font by default, turn that off (set to 100%). On a mac scaling works incredibly well. Windows, not so much.
#2 is a problem that I have on a desktop running Win10. It is from a Windows Update. My desktop was flawless since I blocked WU and NVIDIA updates for about 7 months. Then I decided to update and now when watching video on occasion, the playback stops, the mouse won't appear, task manager is unresponsive. It is definitely a bug in Windows.
Very cool.
Thank you for the tips! Vivaldi going on ASAP!
Vue. It's probably the closest to XAML you'll get.
Did the visualizer work against a .NET core app using the DLLs you compiled? Or did you have to change the target framework to .NET Standard? I know there is some part of the visualizer DLL that gets injected into the target assembly; I would be interested to know if the injected part comes from an assembly targeting .NET Framework, and yet it can still be injected into a .NET Core assembly.
Doubt it. Aks is built from nodes (VMs) and there you don’t pay based in traffic. Look at how much you pay total per month, divide that by 3 (3 nodes in your AKS cluster) and see which size of VM you can buy for that. ( there are other costs, like storage as well, so dividing by 5 is probably more reasonable)
I’ll look more closely when I’m back at my desk tomorrow, but off the top of my head: When testing a .NET Core app, I used the same DLLs I had compiled before for testing a .NET Framework app. After downloading that visualizer solution I never changed (or checked TBH) the target type. That’s an interesting point about injecting the visualizers into the assembly to be debugged. I’m not surprised that what I said earlier (“more like a plug-in to Visual Studio”) turns out to be quite oversimplified. 
Well, I am not a noobe in programming)) I just asking for the most productive and easier one for the mentioned task... Thx for your reply, and can you please advice any reason to use this three over bootstrap? Thx.
To the point, thx.
i realise i just mentioned SPAs. you can just use regular mvc with bootstrap, youll probably be much more productive in finishing it. So i presume thats why you said why i didnt suggest to use bootstrap? I still use bootstrap with angular. I use angular for my side projects even though i could use mvc core; so that i can keep my skills up to date. 
Yeah)) thx. But how you use angular with bootstrap? Aren't both front end frameworks of the same perpose? Or I'm missing something?
they complement each other and serve different purposes. bootstrap is for providing a basic css grid layout and styles for common html inputs and customised ones like date pickers. Angular is an application, its code which controls how the website behaves, its almost analogous to how web forms or mvc works but its executed in the client side browser. so it looks like the page never reloads hence the name single page application. routing is done in the javascript and all data to the backend is retrieved / sent via web api. so you can use bootstrap with mvc or angular 
Aha got it, thank you very much for help.
If you set up your context factory correctly link works great. I just read the API docs, you know... instead of just following others blindly. You should try it. 
Should work fine. Might get the occasional timeout due to latencies.
I would definitely steer away from Angular. It's not a very good framework. I have good experiences with ReactJS (+ TypeScript), and I have heard good things about VueJS.
Looks nice and clean. I'm not sure how it will hold up once an app has more than the Todo data type, the base controller and data layer implementations are probably going to be too generic and so a real project might see a lot of complexity added by the forced abstractions. Also not sure what benefit the sealed keyword adds?
CSS isn't really that difficult. With flexbox, you can lay things out without too much effort. Look for a primer on css-tricks. You may also find Bootstrap to be helpful, which you should probably start with as it comes with quite decent styles. For working with data, I recently started learning AngularJS, which I'm quite enjoying. It's surprised me because I generally have a negative view of JavaScript-. This predates Angular, and I started learning it because I recently started learning Umbraco, and I think AngularJS is a great framework. It's simple to use, and works as small components on your webpages, whereas the big focus right now seems to be on SPAs which I don't really agree with unless the website exists as a tool, rather like the Umbraco backoffice. Too many websites these days are just monolithic SPAs with ridiculous loading times. The back end doesn't really have any connection to the front end, so PHP or .NET backend won't affect your front-end technologies.
It’s possible with SQL authentication. If you’re using Windows authentication now, I doubt you could get integrated AAD authentication working (no way to get Access to generate the access token), but username/password AAD might be possible if Access has a way to prompt the user for credentials for the connection.
My example was primarily focused on the backend, but the most important when using Stripe elements is to use a limited API\_KEY for your safety. As kiksen1987 is saying you only get a token back, so no data of personal character is on your form submit. I might write an article on it instead, will keep you updated.
&gt; Looks nice and clean. Thank you :) &gt; I'm not sure how it will hold up once an app has more than the Todo data type, the base controller and data layer implementations are probably going to be too generic and so a real project might see a lot of complexity added by the forced abstractions. Its intention is not to entirely replace a software developer, but rather give developers a _"head start"_. But once you think about it, everything that goes into a relational database is simply CRUD; Create/insert, Read/select, Update/update and Delete/delete. HTTP is also arguably simple CRUD operations, Create/PUT, Read/GET, Update/POST, Delete/DELETE. A typical application (for me personally), is for instance a CRM, duplicating something like Sugar CRM, which if you study you realize is roughly 80% CRUD. My own industry (FinTech/ForEx/Trading) could probably replace roughly 80% of their code with something like this, which is my own (qualified) guesswork though. Also realize that every single service method is virtual, and can be overridden. Here is one example from my own apps, which is the service implementation for deleting an _"EmailAccount"_. Notice how it still calls its base class implementation, to keep my code DRY without repeating myself :) using System; using System.IO; using log4net; using NHibernate; using poetry.model.email; using poetry.contracts.email; using poetry.services.common; namespace poetry.services.email { public sealed class EmailAccountService : CrudService&lt;EmailAccount&gt;, IEmailAccountService { public EmailAccountService(ISession session) : base(session, LogManager.GetLogger(typeof(EmailAccountService))) { } #region [ -- Overrides -- ] public override void Delete(Guid id) { var attachments = Session.CreateQuery($"select Path from EmailAttachment where Email.EmailAccount.Id = :id"); attachments.SetParameter("id", id); foreach (var idx in attachments.Enumerable&lt;string&gt;()) { if (File.Exists(idx)) File.Delete(idx); } var deleteEmails = Session.CreateQuery("delete from Email where EmailAccount.Id = :id"); deleteEmails.SetParameter("id", id); deleteEmails.ExecuteUpdate(); base.Delete(id); } #endregion } } The idea with the above code obviously, is to make sure I physically delete all email attachments on disc, as an email account is being deleted (email account ==&gt; POP3 account) &gt; Also not sure what benefit the sealed keyword adds? Oops! That is a _very good point_. Thank you :) Let me know if you want to be mentioned in my _"credits"_ section :D
BTW, a lot of its value is also that it automatically wires up Ninject, dynamically loads controller assemblies, gives you a nice folder structure, give you _"dependency injection"_ out of the box, applies DDD to your solution structure, etc. These are things that noobs struggles with according to my experience. So hence, to a noob, it becomes a _"pre-defined good and sound architectural starting point"_ to hopefully avoid creating more legacy code with bad architecture we seniors have to maintain 5 years down the road ... :S
It implements .net standard 2.0, it just has a lot of OS-level restrictions on launching random executables
Try looking at the Access-Control-Allow-Origin http header. Not totally sure, but I know it relates to cross domain content loading. What is the specific error? Are there any clues in it? I think the references you will find to CSP are just stating that with a strong CSP policy the X-XSS header isn't protecting against anything and is redundant. 
I would be okay with the idea, if the only only allowed behavior for defaults would be to do something like throw a NotImplementedException, until you actually implement it yourself. 
I just read that `System.Diagnostics.Process` is not supported in UWP so that means it won't work.
Yes, it does. Buttons, jumbotrons, drop-down menu, etc. Look at getbootstrap.com. Whether or not you are going to use a SPA framework, you should know about bootstrap. You can even set it up with bootswatch or similar to have modular themes for your whole site.
I would add another Route before the one you have now, like this routes.MapRoute( name: "HelpRoute", url: "Support/Help/{action}/{id}", defaults: new { controller = "Support", action = "Help", id = UrlParameter.Optional } ); //Your Routes
I'm getting the following error: "Internet explorer has modified this page to prevent cross site scripting" And visually I get a white page we a '#' on the top left side (weird and took me a long time to figure it out). &amp;#x200B;
&gt;Access-Control-Allow-Origin is it possible to put something like this: &lt;add name="Access-Control-Allow-Origin" value="\*.google.com"/&gt; ?
I think you can something like that. Check https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Access-Control-Allow-Origin 
You could you slow cheetah which has transforms for different environments where. WebConfigQa.config
Assuming that this is a web application where are you hosting the app? Does that host offer database hosting? The would be the easiest solution. If not, maybe look into what is available through Azure. 
I suppose hosting hasn’t been decided yet. I would need to host the app as well. 
If your client is paying for it, then just you azure, it is so easy. Log on the portal. Create a database and you get a connection string you can use over the internet. Make a web site and it will give you a publish profile you can use in Visual Studio. They really make it simple for you.
Thank you. I will look into azure. 
I agree with this. It is much easy this way. If you like to looks at other hosting options. Check this out https://dotnet.microsoft.com/apps/aspnet/hosting
Thanks, very interesting series 
What makes this better than squirrel?
I have used SQLite with .NET Core and I can confirm all this. Microsoft's library works fine, the official one will work on Windows but if you try and run it on Linux/Mac it won't run. So stick to the Microsoft one.
The exact question I had as well. It doesn’t mean this shouldn’t exist, but I’m wondering if there is a reason that I should stop using Squirrel in favor of his.
This is pretty basic stuff no offense. You can also query by dbContext.set&lt;T&gt; T can be an entity not even defined as a dbset so long as the generic propties match. Not advised though 
Slightly more specific question ... what is the Stripe Elements for routing number and account number? Like this: `var iban = elements.create('iban', {` `style: style,` `supportedCountries: ['SEPA'],` `});` &amp;#x200B; and then you can: `iban.mount('#iban-element');` &amp;#x200B; But I need routing number, account number, account name stripe elements. Can't find them...
VS 2019 is disappointing. Feels like someone took 2017, and slapped some stickers on it, then made posts trying to convince us these stickers are helpful, even though we need to work around them now. All the good parts of 2019 could of just been added as 2017 extensions.
So, that’s all about making vs2017 incompatible with Core 3.0? 
They claimed to fix some git branch change issues that freeze the app. Sometimes the fixes are underneath and not very visual.
Bug fixes are nice, but when the top two new features that are being show off for the version change are a new icon, and a popup window its not very exciting. 2017 was a big improvement over 2015, but 2019 feels meh.
Hey, Tried installing from the Windows Store and downloading the ZIP file, in both cases couldnt get it to work. I get an error message on startup that 'Method not found: 'Void RoslyPad.ExecutionPlatform..ctor(System.String, System.String, SystemCollection.Generic.IReadOnlyList`1&lt;RoslyPad.PlatformVersion&gt;, System.Runtime.InteropServices.Architecture, System.String, System.String, Boolean)' Any advice? 
This[package](https://www.exltech.in/dot-net-training.html) is meant for developers that need to port existing .NET Framework code to .NET Core. But before you start porting, you should understand what you want to accomplish with the migration. Just porting to .NET Core because it’s a new .NET implementation isn’t a good enough reason
I don't like saying "what's better", so I'll just say "what's different", because for some people it might be better, for some it might be worse. 1. Squirrel takes of more than just updating, it also enforces the whole installation process. With squirrel your app is installed in appdata, updates are installed side-by-side without overwriting, and a special executable is taking care of launching the correct version of the app as well as updating it. Onova doesn't care where or how your app is installed, in fact it was primarily designed for apps with no installers at all. It downloads an update to a temporary directory, extracts a special executable from embedded resources (which means it's not visible to the user), and instructs it to overwrite program files after the application exits. 2. Onova is really easy to extend with custom package resolvers and extractors. Even out of the box it has support for more sources than Squirrel. 3. Squirrel uses a special file to version your application. This allows it to use full semantic versioning, but makes it so there's an additional version you need to be aware of. Onova simply uses your Assembly version. 4. Onova doesn't require any special deployment steps. If you already have a project on GitHub and distribute new releases there using zip archives, you don't have to do anything to your CI/CD process. You just need to configure Onova to target your repository in code. With squirrel you have to use the CLI to make new releases and also provide additional Squirrel-specific files as downloadable assets. 5. Squirrel is tightly integrated with nuget packages, forcing your app inside of them. Onova can use any archive format in theory and comes with support for ZIP and nuget packages out of the box. Overall, when using Onova, you just add a single package and it handles everything for you. Whereas Squirrel is more like a framework that manages the entire lifecycle of your app. Onova's goal is too be as unobtrusive as possible.
By specifying the tag. You can see the "Full Tag Listing" here - https://hub.docker.com/_/microsoft-dotnet-core-sdk/ docker pull mcr.microsoft.com/dotnet/core/sdk:2.2-nanoserver Will get you the Windows Server container.
yes i use the in memory provider. i do know the basics of sql, id say im intermediate. but i lack abilities in performance tuning at the sql level e.g. looking at query execution plans, identifying problems and how to resolve them. i can create a db schema thats normalised and uses suitable indexes / keys clustered and non clustered when required.
How does it compare to Linqpad these days? I only remember RP being oddly slow and having an unappealing interface, *but* Linqpad's crippleware and its pricing structure is really starting to annoy me.
That feeling is following me since 2013. All versions after 2012 were just slapping some shit on the same codebase, which made it a bloated crap. Open 2012 today, even with some old resharper and you’ll be amazed how it flies. Sure some things were really cool, but others - not so much.
Have they fixed the autocomplete brackets? I love this app but it's incredibly irritating. 
Thanks - I'll try and update when I'll have conclusive results.
So yeah, SQL performance tuning it is. ;)
Yeah, the price is getting a bit too high. I remember buying my first keys (3 PC's) for 25$ (Premium edition !!!) - those cost 95$ today Though it's still worth the money given i use it all the time. 
I use it heavily too, but just have the Pro license and am not planning on going Premium. The only thing I'm missing is NuGet integration that doesn't suck ass, and paying for the whole next license tier for something that *should* be a *basic* feature is not gonna happen. If the license expires at some point (or more likely doesn't apply to the next version) I'm unlikely to get another one.
I second this. Really good author.
It's partly to make life miserable for JetBrains. The more I read about it, the more it becomes clear. Especially the extensions menu is terrible. I don't know any extension developer (including myself) who hates it and wants it to change back. the nonsense coming from MS that it's based on 'telemetry' and people are apparently confused of having a menu of an extension in the top menu bar (really!? I've never met anyone who had that problem). It does make things like Resharper harder to use and more distinct from looking like a real part of VS. 
and at the same time making life hard for extension developers. I mean, I could reasonably easily port my extension over to 2017, but 2019 breaks things fundamentally. While at the same time they still didn't invest a lot of time making things easy for extension developers like, oh I don't know... documentation that actually helps you instead of just lists the undocumented COM properties. Frankly I'm done integrating with vs. 
Oh God please kill this 'feature'
All I want is a Visual Studio that does not have a bug that affects my daily workflow. I have not had that in years. *cries*
Windows only :-(
In addition to the "rEsHarPeR iS sLoW bY 6 sEcOnDs" message I get every time I open VS (even though I've clicked "Don't show this message again" ever damn time), the fact that they've obsoleted static code analysis in favor of pushing roselyn and fxcop, and now this it's plain as day that MS is trying to push JetBrains out. 
You can use shorter tags (e.g. microsoft/dotnet:sdk-2.2) and it will resolve automatically whether to use linux or windows image depending on the platform you're running it on. (on Docker for windows, if you're using experimental features, you can specify platform with --platform option)
I got more beef with undocumented exceptions that a lot of APIs throw honestly.
Yep, add that to the list. 19/03/19 11:50:11 - AndysApi threw a NotTuesdayThe18thException
https://nbarbettini.gitbooks.io/little-asp-net-core-book/content/
Great. When they make the vs test runner as nice as the one in dotcover and include code coverage without requiring an Enterprise license I'll uninstall it.
Quite interesting. I'll look into your framework closer to release of my project.
ReSharper sucks anyway. Learn to code and refactor without it.
How is this anything other than typical consideration in using a 3rd party library and dealing with changes? What specifically is the problem with attributes?
They all look and feel the same to me. It's just an iDE. Why would you want it to change drastically anyway?
Why no support for core?
Thanks Elisa. We have a few older systems with historical dependencies of stuff that exude Attributes. We're then tied to the libraries that rely on them. It gets more complicated because the serialisation behaviour (For libraries that serialise). 
/r/gatekeeping 
I can’t recommend a book but I can say that I felt exactly the same about reading his material on MVC about 1-2 years ago. Now that I’ve built a website and leveraged a lot of the things he talked about, it does make more sense. I’ve been reading that same book lately and find it easy to understand now. 
MyLib - DependsOn: SomeLib v3 How the hell would someone be able to "slip you" MyLib without SomeLib v3? Okay, you're using SomeLib v2, and binding redirect in the config doesn't work? Then the MyLib download should just say "what the fuck?" and so should the manager in code reviews.
I don’t want it to change drastically. It is my favorite IDE, and I use it every day. Im just disappointed, because I want features that improve the programming experience, and not features a marketing department came up with. Just compare these two https://docs.microsoft.com/en-us/visualstudio/ide/whats-new-visual-studio-2019 https://docs.microsoft.com/en-us/visualstudio/ide/whats-new-visual-studio-2017
So, I just went through this book last week and got stuck on identity. private readonly UserManager&lt;ApplicationUser&gt; _userManager; The type or namespace name 'ApplicationUser' could not be found. This is not created anywhere else. Someone has raised the issue but no answer. Any ideas?
I just want to add that I have found that the best approach is to read about on framework/language to get a general idea of how things should be done or what approaches someone more experienced takes. Then do some work. After working on stuff go back to the same text and as you have said things will be much easier and stuff will just click.
I can code and refactor without ReSharper. But why should I, when it makes me more efficient?
Thanks a lot for your response.
Great tip thanks.
Real coders only use notepad. 
Do you have a source on this? I can't find anything mentioning it - currently in the middle of studying for 70-483 so it would be good to know
Still not that useful, but you can finally disable it
It has unstabe support for Linux/MacOS. Try it out [https://github.com/aelij/RoslynPad/releases](https://github.com/aelij/RoslynPad/releases) (RoslynPadNetCore.zip) If you find bugs, raise an Issue
Because the updater executable that overwrites files is compiled as a Windows executable. If I added a net core target, the executable would have to be runnable on any system that net core supports. Also, I'm not sure, but I believe that Windows the only system that has write locks on running executables, which is the only reason this library uses an external executable that overwrites program files.
[https://www.microsoft.com/en-us/learning/mcsd-app-builder-certification.aspx](The official page) has removed it from step 2 "Pass one of the following exams." Last week, this was the text at the top of that page. https://filestore.community.support.microsoft.com/api/images/ff6a114e-806f-4312-ace3-7ee1be6eac21?upload=true &gt;If you have satisfied Step 1 – Skills by earning an MCSA: Web Applications certification, you will need to take an exam other than 70-480 or 70-483 to earn your MCSD: App Builder certification.
It is the way they sell it, like if it was a real big deal.
You're right, but we're talking about accretion over years. Attributes don't survive the test of time in the same way a DTO does. And you sod; that clip always make me laugh :) I'm really snappy right now. I'm trying to rip out a cancerous PoS and every which way I go I'm doing pointless mapping exercises, weird feats of isolation and somasualts while I figure out what a particular attribute actually does. I apologies to anyone I've shouted at, this is really really annoying and I don't mean to crap on you. x 
Well that's better than nothing haha
Visual studio sucks anyway. Learn to code and refactor without it.
They've been making a bunch of changes to these lately. The last time I looked (a few weeks ago), getting the MCSD was listed with *nothing* in step 1, and "pass *one* of the following" in step 2, with a list of 5 exams. Now, it looks like if you pass 70-483 and 70-486, you get the MCSA:Web Applications and then the MCSD:App Builder should be automatic (because you already passed 70-486). So I'd bet there's another round of changes coming. They're not gonna let a freebie like that stand.
https://www.merriam-webster.com/dictionary/eponymous (because I looked it up, so others will too)
It should be quick to get going ASP.NET MVC and stand up a few API endpoints.
How many years of ivory tower training does that require?
Real coders use butterflies. https://www.xkcd.com/378/
They already mentioned that an exam couldn't satisfy two conditions. Then they added that if you had a choice to take an exam previously, even if you didn't complete it, you cant choose it later. Though, this was all done in random forum posts instead of clearly explained on the exam page 
Look into [https://aspnetboilerplate.com](ASP.NET Boilerplate). You can define a data model and let the framework automatically generate CRUD REST endpoints. Read the docs to get the picture of all features.
Then use VS2017.
It seems that individual pivot items content size are being effected by the height of other pivot items content. 
It's actually a common misconception, but it's actually not true. You can have a .Net Core target and only support Windows regardless (for the best developer experience, just throw "`NotSupportedException`" ASAP). The reason you'd want to support .Net Core (or .Net Standard) is so that a developer can use your framework on their Windows .Net Core Apps (which is going to be more and more preferable in the future as features like `Span` are added, which are only going to be supported in .Net Core in the future, and as .Net Framework is gradually sunsetted). See: [Will .NET Core 2.1's Span-based APIs be made available on the .NET Framework? If so, when?](https://github.com/Microsoft/dotnet/issues/770) Note in particular the closing comment: &gt;Closing this, as I guess my question has been sufficiently answered: "Span APIs won't come to the .NET Framework because it'll soon be put to rest." If I have misunderstood, feel free to correct me. &amp;#x200B;
Would be solved if more packages start to adapt a functional style. Unfortunately most are written in C#, and C# users rarely use functional style beyond LINQ.
Old VS versions rarely support new framework and language versions.
&gt;For those keeping track at home, we are now at 3 sudden unannounced requirement changes to MCSD requirements in 3 months. Well done Microsoft. LoL ... I haven't bothered with certs in years (since I worked for a big consulting company that paid for them) but I'm glad to see they haven't changed much in their approach to "restructuring" them. 
&gt;ApplicationUser check this: [https://docs.microsoft.com/en-us/aspnet/core/migration/identity?view=aspnetcore-2.2](https://docs.microsoft.com/en-us/aspnet/core/migration/identity?view=aspnetcore-2.2)
ReSharper is just a crutch for developers, much like IntelliSense, only worse. I have co-workers who follow absolutely every "suggestion" given by ReSharper... "You can refactor this to... click here to change". If you learn *why* and *when* to make something static, for example, instead of relying on an extension to tell you, then you'll be a much better and more capable programmer in the long run. Plus, it's invasive and slow. 
Visual Studio is just a crutch for developers, much like IntelliSense, only worse. I have co-workers who follow absolutely every "suggestion" given by Visual Studio... "You can refactor this to... click here to change". Plus, it's invasive and slow. If everyone just used notepad like me instead, developers would be better for it
This screws me a bit as I was already studying for 70-480... Does anyone know if these changes affect how certs are granted globally? I live in South Africa.
These seem like pretty small potatoes, at least. I wish they would focus more on the wonky things that really affect usability. Like they recently added support for a bajillion code style options in .editorconfig, but they still don't respect `end_of_line`, which is really bizzare. And they added multi-caret, but VS Code's implementation is much better, like it doesn't cancel if you press Home or End, which is mega useful.
I'm surprised someone has seemingly gone overboard with custom attributes. It's hard enough as it is with the built-in ComponentModel namespace, and Configuration.DataAnnotations which have anything you'd ever need or want. You're saying they made their own yarn of barbed wire?
Where can I download the podcast?
Thanks for the shout-out! Much better sound quality!
I have been taking the functional approach, due to my C++, MASM32 days, I have been looking into tools like PostSharp to reduce my boiler plate code that I need to include in my function first design approach. Is it a bad idea to continue this path if using attributes and throwing exceptions is a bad idea, due to people not wanting to see a argumentNotNullException?
That's a good point. Do you know if there are any guidelines regarding this, e.g. how to identify the system, where to throw an exception, etc? It would be nice if you could somehow specify a target platform somehow rather than have runtime checks, but I guess that's not possible.
Btt: I neither like roslynpad's nor vs code's bracket completion, they always screw me over. I really appreciate the new optional completion mode for roslynpad
Aside from 3.0 windows only wpf/wf, people can use Onova for some crossplat GUI frameworks like Avalonia.
Yeah, exactly. Thanks for agreeing with me, bro. Why don't you use VIM instead? Amateur.
Sorry, I'm new to C#, but this looks interesting! How exactly does this improve upon RestHttpClient (I've been working with it a lot so I might be eager to give this a try :D)?
The reasoning whether it is enough or not it purely subjective. I will be happy to convert it 
Nice to see my mentor's article here)
Azure Cloud Functions allow you to develop using C# and easily set up http endpoints or pub/sub events. They're pretty much "scale" in a box. It's been a hot minute since I've used them, but I believe you can deploy/configure them with scripts, so it's fairly easy to set up new environments.
Well if compared to raw HttpClient we have a huge improvement for REST access, since HttpClient doesn't do **serialization, deserialization, authentication or easy error handling**. This is all done by libs like **RestHttpClient **or **RestSharp**. Two main points I've built RestHttpClient upon is **simplicity and flexibility**. I've just extended HttpClient's functionality, following its API patterns and making the library** easy to learn, read, and to be familiar** to HttpClient's users. RestHttpClient is also very flexible and carries virtually everything that the raw HttpClient has, and so I believe it covers 100% of use cases.
Hi! I'll ask the next step of that question. Why use your lib over RestSharp? Looks great btw. 
Step aside, I’m certified. But seriously, these certs seem to be nothing more than a money making operation.
Oh thanks! Well by looking at the samples it seems more simple than RestSharp and also more flexible, since it exposes several overloads for the RestSendAsync method (REST counterpart for plain HttpClient's SendAsync). It also exposes 100% of HttpClient's API since it extends from it, and so RestHttpClient will never get in your way to get your task done. Going back to simplicity, it's also easier to learn since it follows HttpClient's patterns, and so Rest-specific calls will look extremely familiar.
Makes sense! I'll definitely be giving it a try later. 
I have a code generation product that might be an option for you. https://www.codenesium.com GitHub samples https://github.com/codenesium/samples
Awesome! I'll be glad to help and improve it. 
Any benefit over flurl?
Well flurl is really awesome, but I'd say the benefits of RestHttpClient over Flurl are almost the same as over RestSharp: simplicity (depending on the scenario) and flexibility (easilly extensible, while on Flurl we are limited to what is implemented by flurl). RestGetAsync was a kind of annoying decision, but had to be done to make it clearly distinct than GetAsync from HttpClient, which is also available on RestHttpClient, because it in fact is a sub class of HttpClient ;) 
I can't believe the hate that the new extensions menu is getting. Get over it! Its just a menu. This is getting to the level of obsessiveness. 
What am I missing? I just always use HttpClient. It has always seemed super easy. I guess I’m confused as to the benefits of using abthird party library.
Agreed. I care not one damn about any of the changes in OP's article, I just want the fucking settings that I set to actually do the thing they say they do. Also, fix the damn settings bug in SSDT where all the check boxes become unclickable after you're forced to re-run a schema compare. That's been a thing since 2015.
I’m pretty sure that site is maintained by the work experience kid. They will be back up when he realises what he screwed up.
What inspired you to do this? 
It's EOL Dec 31st 2019, which is really frustrating. I had my MCSD from 2014 with 70-487 and 70-486, and when they changed in 2016, they said I lost my MCSD and couldn't take either of those again. So I was planning on taking 70-532, which then at the beginning of this year they retired (moving all those exams to the new Azure track, independent of MCSD), and now, as confirmed today by an MCP support ticket, my only option to get my MCSD again is to study for and take an exam for a platform Microsoft themselves has published is being completely sunset this year (https://support.microsoft.com/en-us/help/4485197/windows-10-mobile-end-of-support-faq). Needless to say I am frustrated and furious with the current state of the Microsoft certification program, at least on the dev side, it's an absolute joke.
Lets say you perform a SELECT and then a DELETE in the same batch. Before this fix was added, it would reorder the operations so the DELETE happened first. I found it because my ORM had the option of returning the newly deleted records. 
You wrote an ORM? The SQLite thing is cool and all (I actually thought that they'd stopped development on it to be honest), but I'd like to hear more about that.
Are you joking or new around here? Most people tell me to shut up about it. *** But yea, I have a couple ORMs. The first one I recently publicly is MicroORM. Literally the first micro-orm and at 160 lines of code it is still the smallest. But it's mostly a toy meant to demonstrate dynamic typing in .NET 4.0. My current project is Tortuga Chain. Unlike other ORMs, this one uses runtime database introspection (a.k.a. reflection) to generate the SQL. To understand what that means, think about EF. If you add a new property to an EF Entity, you MUST add a matching column to the database. If they don't exactly match, boom. With Chain, the ORM looks at the table's schema at runtime. So when it sees that you have a new property on the class without a matching column in the database, it just ignores that property. And you SQL call continues to work. Once you update the database to match, the ORM detects the new column and starts generating SQL that uses it. Basically the new property "lights up" when the database is ready, making deployments much easier. *** But wait, there's more. What if you want to do soft deletes (i.e. a IsDeleted column)? With Chain, you can tell it the name of your soft delete column(s). Then whenever you do a DELETE operation, it automatically detects when it should change that into an UPDATE SET IsDeleted=1 operation instead. Likewise all SELECT operations automatically include "AND IsDeleted = 0" so you don't accidentally read a deleted row. Following this same logic, it can be configured to automatically detect and set CreatedDate/UpdatedDate/DeletedDate columns as appropriate. *** Do you use stored procedures? If so, do you use ones that return multiple recordsets? With Chain that's supported. Look around, I bet you can't find any other ORM that handles multiple recordset returns from SQL Server and PostgreSQL. (And if you do, let me know. PostgreSQL is a bit weird and I want to know if they did it the same way as me.) *** My current work is focused on code generators. Right now Chain can tell you all about the columns a table or view returns, but nothing about the foreign key constraints. This is needed if you want to generate classes from the database. And by classes I don't mean just entities. I want you to be able to generate a whole REST server just by pointing it to a database and picking which ORM you want. (Yes, I know that even if you use Chain for code generation you may not want to use it at runtime.)
who says httpclient doesn't do serialisation, deserialisation and authentication? 
That sounds pretty cool, lots of unique features. When do you think you'll have a release? Also, are you using the Smo libraries to manage the SQL connection operations? They expose an FK constraint collection on the table objects. 
Are you sure? it looks like they're (well the 483 at any rate) still in the MCSA page [https://www.microsoft.com/en-us/learning/mcsa-web-applications-certification.aspx#cp-section3-head](https://www.microsoft.com/en-us/learning/mcsa-web-applications-certification.aspx#cp-section3-head) 
I think making a reusable httpclient that handles auth and serialization and deserialization with error handling built in. It sounds handy as I feel like I am always doing these things
Have you considered making it as a static class with extension methods or seeing if a partial class setup would work? That way users don't need to change objects in existing code but just add functionality to what is there.
Looks good. I've been using flurl but will definitely try this on my next project.
Can't speak for this library, but I love the fluent syntax of Flurl, and it has has great testing features
Looks ok but I'd never use it because the test coverage is too small. Updates could break previous functionality too easily. 
Lol, and sorry if I was getting wound up. Entity Framework (Specifically 4 in this example), JSON.NET (some ancient version) and some custom attributes that live in a ball of mud a different team shat into nuget. There are various reasons I can't just replace the old version with a newer or different library. One is the dependency graph that glues them all together like one of those "Separate these chain links" puzzles. But they still pop up in other places too. I caught someone using an AutoMapper attribute extension a while back :/
Nope. The SMO libraries are too much of a pain to deploy so I just query the system views directly. Besides, there isn't an SMO equivalent for the other databases I support. 
&gt; When do you think you'll have a release? It's actually been in production with Nuget packages for several years now. Unfortunately I can't talk too much about where it's used because of NDAs, but one application was developed for the NBA's game scheduling system. The new code generation support is still a couple months out I fear. The hard part is figuring out the best way to expose it (exe, PowerShell, .NET Core tool, VS extension).
Could the mods lock this? Let's keep the streak going.
Well that is news to me. Could you show me some example?
Thanks! I'm looking forward for your feedback.
And THAT is what inspired me to do this!
Well is was mainly because of what MaximusNeo701 said: I was always doing these things over and over, and differently in each project. Then I thought: why not make this stuff as a lib and make it available to everyone?
Well right now it is completely compatible with Flurl's url building feature. Now that you mentioned it, I have plans to add some fluent APIs to this project in the future =)
maybe I'm not getting you, but you can do ReadAsAsync&lt;ClassName&gt;() and also do JsonConvert.DeserializeObject&lt;ClassName&gt;()
It seems Refit takes this one step forward by letting you specify an interface. What would be interesting however is a library that let's you do everything inline and doesn't require a custom type, so instead of the `Todo` class in your example I could define an anonymous type as a shape (similarly to Newtonsoft Json): ``` var todo = new { Title = "", UserId = 0 }; var todoVal = await client.RestGetAnonymousAsync("todos/1", todo); ```
Well that ReadAsAsync is news to me, and in fact it's an extension method from this package: [https://www.nuget.org/packages/Microsoft.AspNet.WebApi.Client/](https://www.nuget.org/packages/Microsoft.AspNet.WebApi.Client/) Well in fact that is a way of doing it, but it still requires extra work and is not so customizable. RestHttpClient takes care of that by making things more simple, from request call to error handling. On authentication, in fact RestHttpClient uses base HttpClient's auth capabilities, which are extended by events and listeners.
Does it make use of conditional requests, i.e. ETags, If-None-Match, etc? What's the benefit over using default HttpClient with extension methods to deserialize JSON from response content?
I have made an very simmelar client once. You should defenitely check out the source. Maybe there is something usefull you can use. If I recall correctly it also has support for following redirects (with loop-detection). https://github.com/AndreasFurster/lisa.common/blob/master/Lisa.Common/Lisa.Common/Access/Proxy.cs Some small things I noticed about you're examples in the readme; I think prefixing each method with "Rest" is not very usefull. You already have an RestHttpClient instance. And maybe specifing the type on initialisation might be cleaner. Most of the time you use an HttpClient fore one request or for multiple requests with the same type.
Yes I have considered making it as extension methods, but these would lack customization (which wouldn't impossible to do but would at least be more difficult). HttpClient isn't a partial class and so that is a no-go. What you can do, although, is to replace yous HttpClient instance by a RestHttpClient instance and gradually replace your code with RestHttpClient-specific calls. Well I haven't ever used Polly but I can't see how it would be an issue to use it with this lib.
What about Refit?
Thanks for the feedback. Yes, there are very few tests because this lib is a work in progress and so I've just wrote some very few test cases. &gt;JSON converting to and from strings just to throw the strings away, why? Why not use streams so it can be used for larger responses? I've wrote like that for debugging purposes but you're definitely right, it shouldn't go into production like this and so I will change it. &gt;Also can't use the HttpClientFactory with it so you still have all the issues around socket exceptions and DNS changes. HttpClientFactory is from [ASP.NET](https://ASP.NET) Core, but the focus of the project right now is to use it with desktop and mobile apps. &amp;#x200B; These comments would be even more useful if they were also sent as issues on GitHut. I'm also counting with people to fix/write stuff and send PRs, so let's wait to see what happens.
yes, you need an extension method to use ReadAsAsync . which authentication are you referring to? I've never had to use any other client apart from httpClient 
I just don't get the name, ORM doesn't make me think of pirates. I don't see how it would be google-able.
How does your lib compare to [RestSharp](https://github.com/restsharp/RestSharp)?
So i should stop studying for 70-483??
What might be a use case for this? I use LinqPad when I need to try something out real quick: * see if some pattern or class structure might work. * isolate a piece of code from my code base and boil it down to its bare essentials to determine why it doesn't work. * see IL out of curiosity.
That second example doesn't involve HttpClient doing the deserialization.... that's just you doing it yourself afterwards
&gt;HttpClientFactory is from ASP.NET Core, but the focus of the project right now is to use it with desktop and mobile apps. Shouldn't prevent multitargeting or providing some code to fix the issues the factory was designed to fix. &gt;there are very few tests because this lib is a work in progress But why implement features without a unit test to ensure they stay working? I can't depend on any of those features because they might break in future releases due to bugs. You need tests as you're adding features. The test should really come first. 
This is about the MCSD requirements (after doing your MCSA). Nothing has changed in regards to the MCSA requirements.
If you already have a MCSA and are trying to do an elective for the MCSD, then yes.
That's awesome. I look forward to using it in a personal project this weekend. Thank you for your time and effort!
RestSharp is my goto for this kind of thing. It's been around for a while and is well supported. I looked at OPs library and I don't really see anything that is so different that it would make want to switch. Plus RestSharp supports NTLM/Kerberos challenge/response authentication :) 
This sounds a lot like "change is BAD". If you want VS2017 so badly, use VS2017. Nobody is stopping you. All of the changes here are not "breaking changes". They are tradeoffs with pros and cons but the devs thought the pros were worth it: 1. You can now select a project on startup faster than before without waiting for the whole IDE to load first. Overall I'd call that an improvement. If you don't like it you can skip the window by configuring it in Options. I would imagine extensions could provide their own Start screens, surely? 2. This change makes sense to prevent extension menus from crowding out the menu bar if you have a lot of extensions with menus. 3. They have said this was done to create more room in the UI for content. There is still nothing to keep you from dragging the title bar, there's just a little less room to do so. You can see right in the screenshot provided you can still see whether 2019 is run as admin or not! And in fact it looks like in the screenshot the window has been artificially resized smaller to hide the UI gains you'd normally get from the revamped titlebar UI. I would say the size shown is unusable, at least for me. 4. So it sounds like the complaint here is that VS loads faster, which is bad. So extension loading is moved to the background. Is it slower overall? Who knows, there are no measurements made here. 5. I don't use this feature so I can't say anything about it. But it sounds like this is more of a feature only extensions could leverage which could still probably be worked around with time, I would imagine. 
I would be surprised if someone wasn't able to get the build tools working with VS2017. But you will get none of the additional IDE support such as the .NET Core 3.0 WinForms/WPF designers.
I have not used Resharper so I can't say if that message is typical. But messages like that are meant to pressure the extension developer into fixing their slow code, as it looks unprofessional and can push users to look for better performing alternate extensions. If you get it often, or it shows up for core features of VS, it's probably time for a PC upgrade. But it should go away forever when you tell it to. It has for me so that's odd. As I said I've never used Resharper but if their tools are pushing MS to improve their own toolset I think that is a good thing. We are the winners in such a scenario as we get better tools regardless of who makes them.
It is a really cool looking lib very easy to use and intuitive, great work. I tried to use it recently - I ran into issues where I couldn't work around certificate issues, adjust timeouts and had not way to handle web errors such as error 500's etc. Would be lovely if you exposed some of the lower level stuff, as at least for me that is a common issue I run into when building rest api clients.
Thanks and please try to update to version 0.3.0 as I've already addressed some of the issues that you've reported. For lower level stuff, please use the existing API from HttpClient, which if 100% present in RestHttpClient. Please feel free to report issues and ask for specific stuff at GitHub =)
Thanks for your feedback
Ok thanks for the response. &gt;Shouldn't prevent multitargeting or providing some code to fix the issues the factory was designed to fix. I will think about it. About unit tests yeah, it is just like you said: at this time I can only guarantee that stuff on unit test is working. You will use the rest at your own risk (or maybe write some unit tests and push them to the repo, would be a great help ;)
It might be helpful for you to point out what version of .net are you using (.net core, .net framework, etc.), the version of EF you are using (ef core, 5x, 6x), and the type of project (razor pages, MVC). 
Sure thing! :) \- .Net Framework; \- EF 6; \- using MVC Arquitecture and razor view pages &amp;#x200B;
Yea I wouldn't see why ASP.NET MVC would be a problem. Start a solution with an ASP.NET MVC project, add an ASP.NET API project, and use Entity Framework for your data layer.
Originally it was called "Wildfire Data", but my employer claimed that trademark (and subsequently pissed it away). Then we tried Chain because it uses a fluent API rather than a LINQ style to chain together the insert/update operation with the results and caching. But Chain alone is well used and we were really into pirates that year. But search for "tortuga chain" and we appear in the results so no problem there. 
In general, it is not the best idea to use your domain models in your Views directly. Instead, you should create *ViewModels* that house the information required for your View, and collect the information submitted by the user. In your case, I'd probably create a ViewModel such as the following: public class CreateProjectViewModel { public int ProjectID { get; set; } [Required] public string Title { get; set; } [MaxLength(255)] public string Description { get; set; } public int[] SelectedSectors { get; set; } public List&lt;Sector&gt; AllSectors { get; set; } } Then, in your controller, you would have two actions; one to display the "Create Project" page, and another to process the input from the form on the "Create Project" page. Here's what they might look like: // this action shows the "Create Project" page public ActionResult Create() { var allSectors = db.Sectors.ToList(); // do whatever you need to do to grab a list of all of your Sectors var vm = new CreateProjectViewModel { AllSectors = allSectors, ProjectID = -1 // so you can tell it's a new project }; return View(vm); // your view must consume a model of type CreateProjectViewModel } // this action processes the input from the "Create Project" form [HttpPost] // required so that this action will only be used for a POST request, ie. a form submission public ActionResult Create(CreateProjectViewModel model) { if (Model.IsValid) { // checks if the validations are all correct var newProject = new Project { Title = model.Title, Description = model.Description }; // store the new project to the database here, so that it gets an autogenerated project ID // we're going to loop through and create new "ProjectSector" entries for each sector the user selected foreach (var id in model.SelectedSectors) { var ps = new ProjectSector { ProjectID = newProject.ProjectID, SectorID = id }; db.ProjectSectors.Add(ps); } db.SaveChanges(); // everything worked, so take the user to the new project page return Action("View", new { id = newProject.ProjectID} ); } // uh-oh, validation failed. show the form again // but first, we have to get all the sectors again model.AllSectors = db.Sectors.ToList(); return View(model); } That's how I'd do it if I were you.
This was SOOO helpful, thank you so much!! I trully appreciate the details! Thank you!
&gt; But search for "tortuga chain" and we appear in the results so no problem there. but what about ".net orm" or "ef alternative"?
No problem. Glad it was helpful. :)
You can do everything you want with the TFS version you have. About 2 years ago, I built out a pipeline using the same version that built a dotnet core/SQL server backend and an Angular 2 front end. It ran unit tests as part of the build, ran smoke tests after the DEV and QA deployments, and was gated so only the proper people could approve a prod release. We even deployed DB changes using DACPACs, so we didn't need a DBA to intervene in our automated process. You will need a build server to house the TFS agent. This will also have the tools you need to build your application. There are lots of new features in newer versions of TFS and Azure DevOps that will make life easier, but you can do it with what you have right now. &amp;#x200B; Let me know if you would like more info or have more detailed questions and I'll try to help.
I'm only allowed to do so much. For example, that first search returns the article titled "ORMs for .NET Core" hosted by InfoQ. I wrote that article, but due to journalistic concerns I wasn't allowed to mention my own ORM.
don't ask this question. you are stroking him off
Octopus Deploy. was a much more important product back in 2012-2015. Now that Microsoft has had a few versions to flesh out Release Management, and integrated it into TFS, its value proposition isn’t nearly as much. The fact that it’s fully API driven is nice for us but probably not necessary for most teams. At the time Octopus Deploy was a godsend, but if I were starting from scratch I’d try going with raw TFS. It should do all that you need it to.
Thanks, we actually already have some kind of CI, but only to the UAT environment. We run all unit tests after check-ins for example, and automated deployment to uat also. We don't have access to production environments. Gated deployment looks interesting, and that's what we need also I think. we won't be able to use Dacpacs I think, because we dont have an ORM system, all db related stuff are done using manually created sql scripts.
There is one thing that I don't know how to do; Rollback if deployed version contains a bug. 
Create a new release based on the previous build (that contains no bug) and deploy that release. Also the previous version should be your previous release. So if you click that and press redeploy your code rollback should be done. 
So a rollback should be as simple as rerunning the product deployment for the older release. So they’d just need those permissions for the release pipeline (to use current ADO terminology). Depending on how you handle database changes, that simple of a rollback may or may not be viable. But that’s generally the starting point. If you’re in a CI/CD world it might be easier to just fix it and push it out quickly, though!
It's not possible to fix it asap because in big teams it could be that the developer is on vacation.
You don't need an ORM for Dacpacs. With SSDT and Dacpacs, what you get is essentially "Schema as Code" checked into source. Dacpacs are just the build/deploy artifact that gets applied to the target database. You can even get them to output a report on diffs to the prod DB for sign-off, if you need a safety net before things go full auto. 
If you can, try to push for fix forward releases, it makes to process much simpler. But a roll back strategy could be as simple as redeploying the last known good release (just make sure you have your artifact retention policy set properly). You can do scripted back ups or blue green deployments, but blue-green can be quite hard to setup on premise depending on your infrastructure, and what you can access via API/script. But fix forward and known-good roll back should be sufficient for 90% of changes. If you need an absolute fix-all-the-wrongs, try looking at scripting a VM snapshot or run DB backup etc, then have a manual roll back process for when everything is dead. What most people what to see is that there's a plan and a process if you provide these you'll be fine.
Doh! I just spent the last hour trying to help you on your post in r/csharp + making an example project. I hope mine is helpful too 😅
Please, can you share it? Dont throw it to waste! I'll put it to use in some way or another for sure! I'm still looking for the best practices of coding in .NET, SPECIALLY when it comes to create views with multiple models/arguments/objects. Please, don't throw it to waste! I really appreciate your dedication on trying to help! Thank you trully from the deep of my heart!
I'm reading it now in r/csharp. I will leave an answer in that subreddit. And close one of them meanwhile so that people dont overcommit on it! 
I posted it on your post in r/csharp. It's on my GitHub at github.com/sander1095 :) If you have discord or some means to chat, I could tell ya some tips sometimes on how to improve. (Not now though) 
Of course! Bloodsinc#8029 , add me whenever you have time. I will answer to your post once I finish reading it. Thank you, once again, for putting so much effort!
There have been a number of updates to the CI/CD pipeline since 2015 Update 3. Would your employer be up for upgrading to the latest on-prem version before you invest all your time creating pipelines?
We can, we are in process of making an improvement in this. But we need to be able to clarify what the latest on-prem version can provide which the version we now have can't.
For sure, that's good news. Plenty of release notes available. That's the great thing with Microsoft products recently, they've really improved the UX and documentation. 
With latest on prem version you mean azure devops server then?
First you need to gather the [functional](https://en.m.wikipedia.org/wiki/Functional_requirement) and [non-functional (NFRs)](https://en.m.wikipedia.org/wiki/Non-functional_requirement) requirements from the stakeholders. The non-functional requirements will drive the architecture and technical design that is appropriate for your system. For each architectural choice you should [analyze alternatives](https://en.m.wikipedia.org/wiki/Requirements_analysis), weighing them against the NFRs to decide.
We've not upgraded to Azure Devops on prem yet for one of my workplaces. We're still on 2017. We went from 2012 to 2015 and then 17. Each upgrade was well worth it. In my other place of work we use Azure Devops (cloud), which is superb. You'll get a very very similar experience with on-prem 
My employer won't accept a cloud solution imo because we are a financial company.
It's worth talking to Microsoft direct regarding their security. They'd be happy to have a call with your cyber security team, infrastructure staff, developers and management. 
What is the if (!signup) doing? It's executing the exact same code!
And the name confusion sets in... Azure DevOps server 2019 was released on March 5th. Name is terrible since that is the on prem version and everyone immediately goes “Azure == cloud, right?” Such a bad name... Anyway, I just went through the exercise of upgrading the on prem 2015 tfs to it this past weekend and it went pretty seamlessly. Minor hiccups revolved around changes to the work item process as we were converting from cmmi to agile. There were also things that were deprecated like XAML builds and test labs. We were not using those features so it didn’t matter. Not sure what you are using for builds, but dropping xaml support was a big issue for a number of people out there. If you’re headed towards a similar work item transition let me know and I can point you in the right direction. 
That is exactly what I want instead of Octopus Deploy that my colleague is talking about. But there will be a difference in pricing I guess?
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/latexandloaf] [Memory and Span pt.1](https://www.reddit.com/r/LatexAndLoaf/comments/b3357m/memory_and_span_pt1/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
Minimum required tools? .NET and an operating system to run it on. You can create your own build and deployment server with fairly minimal effort. That's not necessarily the correct choice, but it's not hard and is a good learning experience.
It's not a problem JetBrains can fix is the issue. Visual Studio runs all extensions in memory, and visual studio is only a 32 bit application. That means there is a very limited extra memory space that can be used, and indexing files and doing analysis all in memory (since that's all VS allows) is well.... expensive. It is Microsofts problem they are slow, not theirs. &amp;#x200B; However, yes Resharper definitely helped to make VS better over the years. A lot of its features are slowly being consumed into VS.
Sounds like you need to fix your workflow if you're seriously having a bug that affects you that often.
The best solution there is to simply uninstall the Directory Browsing feature from IIS. The default behavior will return a 403. It seems odd you would want to return a 404 for a directory that exists and for which files nested in it would be valid. &amp;#x200B; [https://docs.microsoft.com/en-us/iis/configuration/system.webserver/directorybrowse](https://docs.microsoft.com/en-us/iis/configuration/system.webserver/directorybrowse) &amp;#x200B;
TFS can do what you need it to do. There may be other solutions that are better at some things but I'd recommend sticking with Microsoft tech if you're already using it and building it out there. If you find you have other needs after you get into it, that's another story, but might as well use what you have until then. I would recommend upgrading to Azure DevOps Server though, as TFS 2015 is outdated and a pain to work with sometimes. There are newer features available that will make your life easier, especially with Git (pull requests), Deployment groups, etc. The cloud version is easiest to utilize but if you already have the build server set up, just upgrade and continue from there. Get your devs to build out better test suites and stuff too if they haven't already. Also TFS 2015 doesn't have built in .NET Core build support so you have to do command line builds.
What is the correct choice then? A deployment server = tfs?
It sounds like the problem is if directory browsing is enabled at all, an attacker can see listings of files and folders and access them (and of course they can, that's the whole point of enabling it!) Turning it off should be sufficient. I am not sure why the returned error code matters. First of all like the other guy said, if the folder is in your wwwroot/webroot, presumably the files inside of it you want to serve, in which case it's obvious the folder that hides the files exists. If the attacker already knows the folder name and is requesting it, there's nothing to be gained by returning a 404. A 403 is the proper error code to return and will let a legitimate user know directory browsing is not allowed, or otherwise that they can't view the page but that it does exist. Furthermore it may not be compliant with the HTTP standard to return a 404 for a folder which obviously exists since it was used to serve a file, or at least it might confuse some tools or browsers if you do it.
I am not familiar with WebForms but one thing I see is you are subscribing to the event every time you call SetUpControls even if you were subscribed before. You should be clearing out the old event handlers once you are done with the controls. I would suggest setting up the event handlers and the controls in the constructor, and adding/removing them from the page in your setupcontrols function. Not sure if that will have any effect but it will simplify things. Also you do not need to explicitly reference EventHandler to assign an event. For `example butSignUp.Click += nbutSignUp_Click;` should work fine without the constructor.
Love the show so far! Sound quality is way better indeed. +1 for the unpopular tech opinion segment!
If you hit either the signin button or signup button , it inverts the state of the signup variable from false to true and back accordingly. 
I agree but i really am getting no where with what it could even be. I appreciate this point but the original design had the buttons created with events assigned when the form loaded. It made no difference unfortunately. It does keep the text though, which means the buttons keep the properties first assigned. It loses the forms code on the event function. Yeah, I think I had it this way before but someone had it on a forum post somewhere so it was something desperate that I tried. 
Nope, just a normal Windows Service that kicks off a batch script and monitors the output. The reason that it seems like there are so many choices is that it's so easy to make one. You could literally make your own from scratch over the weekend. You asked for the "minimum required tools". Which is the best option is a far more difficult question. 
This isn’t true - ReSharper can run out of process, or have multiple processes like various Roslyn services. In fact, that work has started: https://blog.jetbrains.com/dotnet/2018/05/29/taking-resharper-process-resharper-performance-series/ ReSharper was not originally built this way, so it’s obviously not easy to have it run out of process. But it’s not a Visual Studio limitation.
Oh, thanks too and you're welcome! 
Thanks for the contribution and in fact it is now implemented in version 0.5. It was you that registered these issues and PRs, right? 
Well you can use one of the RestSendAsync overloads with an HttpRequestMessage object, and there you can include the headers you want, including these for conditional requests. 
I can understand why extension methods might be hard; and agree with the partial class idea being a no go. I also think Polly would work but I'm not sure. Looks like a useful tool, I will have a look at it. Thanks for your efforts
Exceptions are not bad, but meaningful names and exception text go a long ways. Also add some comments to it I hate commenting things as much as the next guy, but for some things like building your own framework or extending exceptions it's necessary.
Nice job with this article; it is one of the better breakdowns I've seen for `Span&lt;T&gt;`.
Azure has some transient fault issues when servers resize themselves or shift on their end. So be ready address that, if you can add some handling you will be happy with it
I am not super familiar with worker roles but I have moved over to webjobs and I think it could fill your need. They share resources with app services so they are included in your existing plan. Azure functions can do the same as a webjob without the host setup as well.
That's good news, especially given it was someone else :)
I think there are online editors you can use. Or even if you want rent a virtual pc from anywhere. 
These "breaking changes" are more like personal preference then anything else. 1. Nothing to add 2. Could be useful to have a setting to move some extensions to the main bar 3. The place where they display the info is a dragable space and it's always there. The top above the menubar is also dragable, so unless you really, REALLY want to grab it in the middle, you don't have to change anything 4. So instead of waiting until VS becomes responsive, you can now browse around for a minute until the extension is loaded, big whoop. This is a better change because the UI stays responsive 5. From the issue (the author even linked), it sorta indicates that this was unintended. Besides, this behavior can be replicated by dragging and dropping the window in the same dock well. These things are hardly breaking changes at all. Only 1 of them seems to be an actual issue. So on a scale of "clickbait" to "actually breaking changes", this falls very much under clickbait if you ask me
&gt; What might be a use case for this? It's free a free alternative.
You can publish with --self-contained
I don't think I fully understand your problem but these two things may be of help: &amp;#x200B; 1. [https://docs.microsoft.com/en-us/dotnet/core/tools/dotnet-publish?tabs=netcore21](https://docs.microsoft.com/en-us/dotnet/core/tools/dotnet-publish?tabs=netcore21) &amp;#x200B; 1. specify a -runtime command line argument when you do dotnet publish which will make it create a self contained package 2. create a nuget.config 
I think that only works for windows, no?
I've used it on Windows, osx, and Ubuntu. Work really well
dotnet pack is for making nuget packages. dotnet publish sounds like it should do what you want it to do.
The more complete answer is here - https://stackoverflow.com/a/43841481 - using ‘CopyLocalLockFileAssemblies’ tag in csproj, you nuget dlls will be copied to output dir during each build, not only when you are publishing your app. This is useful when you have impľemented hour own afterbuild targets. 
this is why i dont touch anything unless its been out for a while, especially true of .net core. i only really got into it once 2.0 got released. people running on bleeding edge RC releases are just asking for pain, and there is no one on stack overflow to help you
Would be very interested in this if it exists!
As a dba who has to deal with ef; just learn sql properly. If you must use an orm only bind to objects you already created. EF is frontpage for databases and causes far more issues than it solves. 
&gt;If you must use an orm Every non-trivial app will need an ORM. Not using EntityFramework (or another off the shelf ORM) is the equivalent of telling developers to roll their own, which is terrible advice for most people. Care to explain how you would use something like the specification pattern with a robust ORM?
No, every non trivial app getting rushed requires an orm. But taking shortcuts in software development is nearly always longer in the long run. It really is not that much code to connect to a database an execute a procedure if thats too much work for you then use something lightweight like dapper. Learn to use sql properly or keep away from the database. EF codefirst is one of the easiest ways to create a terribly designed database. You OO developers love your funky orms but you will really struggle to find a dba or sql developer who thinks much of it. 
It depends how well they know EF. If they know it well, and the underlying tech, then they won't run into massive problems. 
Nice. Completely ignore my question about using the specification pattern without an ORM. Tells me you probably don't know much about building software and like to sit in your ivory SQL tower instead. Let me get more specific. Say you have a simple ecommerce site and want to allow searching through millions of products with various optional filters. With an ORM like EF, I can do something like: `var result = respository.Find(specFactory.ProductIsActive().And(ProductAgeBetween(0, 5)).Or(...));` How would I build something like this doing it your way? How would my repository be able to follow the open/closed principal if SQL was constantly changing to meet filtering/query requirements?
\`dotnet publish\` will include all dlls not shipped as part of the dotnet core runtime. You then copy the contents of bin/publish to your server and run it with \`dotnet exec Project.dll\` \`dotnet publish --self-contained\` will copy all dlls and create an executable file you can double click/execute directly. You will need to specify a platform (e.g. win7, win10-x64, linux, etc.) with -r or specify one or more platforms in your project file.
I cant say as i much care for the opinion of dba's or sql developers.
I agree its useful in the hands of someone very skilled but you need to be DBA level on the sql side and very knowledgeable on EF to get there. It has an extremely low entry point skill requirement compared to what is required to use it effectively and thats the issue I have with it. If you really know what you are doing go for it but I would bet my annual salary that 90% of people who use EF do not. 
VS sucks anyway. Learn to code and refactor by flipping bits in using x-rays.
Vim? what a noob a real programmer flips bits using x-rays
I guess it depends what you mean by DBA level. To me that is really understanding stuff like availability mechanisms, partitioning, transaction log magic, handling multiple different code bases hitting the server. That kind of stuff. I agree about the low entry requirements, but that is just modern programming. We've created abstractions for many applications they are great, but they [Leaky Abstractions](https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-abstractions/) and much like Joel wrote there when the abstraction works, it's great, but as soon as it doesn't the knowledge required is extreme. Now as to how much EF allows you to "code yourself into a corner" to use a phrase I love in code reviews, it depends on how it's used. So long as people don't use the model objects all over the application (because then they are tying their model schema to all their code) fixing the odd little oddity of a massively inefficient query isn't too hard. I have faith in my mid and upwards level devs to be able to play with LinqPad and the query execution analyzer. However, people do still need to understand the world of data modelling. Honestly I don't think that is unique of people using ORMs, I've seen far worse data modelling in pure SQL, I guess mostly because of the ages of those code bases. 
&gt; How would I build something like this doing it your way? Are really asking how you would write a stored procedure that performs that sort of search then call the stored procedure from .Net either via a lightweight ORM like dapper or old school System.Data.SqlClient ? You would be shown the door in an interview at my workplace if any of these were an issue for you.
My example was for an e-commerce site. Filtering products could require dozens of optional filters. Are you seriously going to create a proc with dozens of optional parameters and build the worlds ugliest looking proc to do that? And you would still end up violating open/closed principal which is part of SOLID. Again, sounds like you don’t know shit about building complex software.
&gt; But taking shortcuts in software development is nearly always longer in the long run. Not a big fan of DRY either, I take it?
&gt;Filtering products could require dozens of optional filters Yes and you can 'short circuit' where clauses. The code must be written somewhere, just do it in the database where its getting run anyway. I can tune a procedure fairly easily, I cannot tune a load of generated SQL code fired out of a web app without making changes to the front end code. As a DBA I don't want to be firing up and running an entire website solution just to fix your code for you. FYI I work in a software training company that trains both software developers and DBAs and our customer base includes plenty of companies that you have heard of.
Sounds like you have no business training anybody. You’re essentially stating that business rules should be put in stored procedures, that it is ok to violate SOLID principals to make some idiot dba have an easier time, and you apparently think that specifications would be stored in the front end instead of a service layer. Do you not know what the specification pattern is? Are you not familiar with SOLID? What happens when you start using things like GraphQL or need to share specifications between different services with different databases? I have way too much experience pulling business logic out of SQL, it’s a fucking nightmare.
//copy and paste this into production code /s public interface IHasId{ public int Id {get;} } public static class EFExtensions { public static T GetLast&lt;T&gt;(this DbContext context) where T : IHasId { T result; for(int i = 0; i&lt;20000; i++) { result = context.Set(typeof(T)).FirstOrDefault(p=&gt;[p.Id](https://p.id) == i); context.SaveChanges();//for good measure } return result; } }
Your opinion is, and I don't take these words lightly, worse than a 100 9/11's. 
you can save it the database and a session while the user is logged in &amp;#x200B;
On the flip side, I've seen larger ORMs cause issues when used in high throughput situations when applications get large as it's much harder to optimise the SQL plans. I usually just use Dapper and that's far enough, never had an issue even in larger applications.
Octopus will definitely be an additional cost to TFS/AzDO presuming you already have some form of MSDN like subscription which includes those products. In my organization, we have two TFS servers for two different teams. One is the aforementioned Azure DevOps Server 2019 that I migrated this past weekend. The second is a TFS 2018 server that I've had up and running for the past year. &amp;#x200B; I'll speak to experiences with the 2018 server since I've only had 2019 running for three days now and it was only officially released 15 days ago. Anyway, on the 2018 server I have been doing builds and deployments across multiple environments for a long time now without need for any other tools. Utilizing a deployment pipeline I have set up tasks to be run on the target environment to download the application installer and run it. In case you're wondering, my product still has an installer for customers and part of the pipeline is testing to make sure the generated installer actually works. If your particular product is a web site deployed on an internally hosted site you should be able to get away with using a simple Command Line task to perform an XCopy to the correct location on the target server. You mentioned having a UAT environment where deployments are currently occurring so I imagine looking into how that is done will give you a sense of what to replicate into your Dev/Prod environments. &amp;#x200B; Now for one of your larger questions. Roll backs. \*shudder\* As others have indicated, you should be striving for Roll Forward fixes since going backward can turn into an absolute nightmare very quickly. Especially when a database is involved. If you deploy something, run it for a few days, then discover a bug and want to roll back that could potentially mean rolling the Database back to before the upgrade. Wiping out all the data that may have come in during that time. Super duper bad scene and not something you want to be dealing with if at all possible. &amp;#x200B; Now that I have sufficiently scared you away from that idea, the thing you're missing is the concept of Feature Flags. It's a very simple concept that can be difficult to implement depending upon how your application code is structured. Basically the idea is to make your code so that it has a Flag/Toggle around modifications so that you can quickly turn things ON or OFF as needed. So pretend you have the following method &amp;#x200B; Private int CalculateTotal(int firstNumber, int secondNumber) { Return firstNumber + secondNumber; } Pretty simple method that adds two numbers together. Now pretend that there is a new requirement that comes down indicating that the numbers are supposed to be multiplied. You could change the + to \* and be done with it, or you could use a feature flag like this ​ Private int CalculateTotal(int firstNumber, int secondNumber) { if (CalculateNewWayFlag()) { Return firstNumber * secondNumber; } else { Return firstNumber + secondNumber; } } Now you have the new code and old code living side by side. If you deploy this and after a few days someone comes screaming into the office that the numbers are being calculated wrong all you need to do is flip CalculateNewWayFlag to false and you're back to adding the numbers again. Just like it was before you deployed the new code. &amp;#x200B; This is of course a gross oversimplification, but hopefully it serves as a straightforward example of what can be done. If you want to learn more about how Feature flags are implemented and managed, I would suggest you take a look at [Launch Darkly](https://launchdarkly.com/feature-management/) They do a good job of going over the concept for multiple scenarios as well as providing a product that allows you to centrally manage the state of the flags. &amp;#x200B;
I am not sure if this is achievable on an MVC app, but I store the received token at SessionStorage. Works well when I need to provide a refresh token after expiration.
Tested on Core2.2.0: struct Int256\_1 is 400ms faster on my machine than Int256. readonly struct makes no difference here, Int256 performance never changes &amp;#x200B; Compiled and tested on x64 release build public /*readonly*/ struct Int256_1 { public readonly long Bits0; public readonly long Bits1; public readonly long Bits2; public readonly long Bits3; public Int256_1(long bits0, long bits1, long bits2, long bits3) { this.Bits0 = bits0; this.Bits1 = bits1; this.Bits2 = bits2; this.Bits3 = bits3; } } /* get_TotalValue() IL_0000: ldarg.0 IL_0001: ldflda valuetype Program/Int256_1 Program/Test::'value' IL_0006: ldfld int64 Program/Int256_1::Bits0 IL_000b: ldarg.0 IL_000c: ldflda valuetype Program/Int256_1 Program/Test::'value' IL_0011: ldfld int64 Program/Int256_1::Bits1 IL_0016: add IL_0017: ldarg.0 IL_0018: ldflda valuetype Program/Int256_1 Program/Test::'value' IL_001d: ldfld int64 Program/Int256_1::Bits2 IL_0022: add IL_0023: ldarg.0 IL_0024: ldflda valuetype Program/Int256_1 Program/Test::'value' IL_0029: ldfld int64 Program/Int256_1::Bits3 IL_002e: add IL_002f: ret */ &amp;#x200B; public /*readonly*/ struct Int256 { private readonly long bits0; private readonly long bits1; private readonly long bits2; private readonly long bits3; public long Bits0 =&gt; bits0; public long Bits1 =&gt; bits1; public long Bits2 =&gt; bits2; public long Bits3 =&gt; bits3; public Int256(long bits0, long bits1, long bits2, long bits3) { this.bits0 = bits0; this.bits1 = bits1; this.bits2 = bits2; this.bits3 = bits3; } } /* get_TotalValue() IL_0000: ldarg.0 IL_0001: ldfld valuetype Program/Int256 Program/Test::'value' IL_0006: stloc.0 IL_0007: ldloca.s V_0 IL_0009: call instance int64 Program/Int256::get_Bits0() IL_000e: ldarg.0 IL_000f: ldfld valuetype Program/Int256 Program/Test::'value' IL_0014: stloc.0 IL_0015: ldloca.s V_0 IL_0017: call instance int64 Program/Int256::get_Bits1() IL_001c: add IL_001d: ldarg.0 IL_001e: ldfld valuetype Program/Int256 Program/Test::'value' IL_0023: stloc.0 IL_0024: ldloca.s V_0 IL_0026: call instance int64 Program/Int256::get_Bits2() IL_002b: add IL_002c: ldarg.0 IL_002d: ldfld valuetype Program/Int256 Program/Test::'value' IL_0032: stloc.0 IL_0033: ldloca.s V_0 IL_0035: call instance int64 Program/Int256::get_Bits3() IL_003a: add IL_003b: ret */ &amp;#x200B;
And you'd be shown the door at mine for being such an arsehole to people asking questions about something you know about.
i agree that EF is a nightmare but it's what companies hire for because it's trendy and there's no shame in using it because your company told you to imo, gotta pay those bills. outside of personal projects there's often no time to do things "properly" because some guy who has never even seen the inside of your office has already pulled a deadline out of his ass and there's probably already a low chance of delivering by then even with all the shitty shortcuts in the world. i'm only slightly jaded, i swear.
I really hope you can re-read your comment and see why it was uncalled for.
Local storage or in a cookie are usually the recommended methods for storing a JWT on the client. I personally prefer to store it in a cookie since that's a tad more secure. Typically, you want to avoid storing them in session since JWTs are meant to be stateless and session storage defeats that purpose.
r/shitongithub 
Perhaps but I got my job based on my SQL skills and the fact that within my workplace in a team of 30 or so techies if there is some slow SQL code anywhere it comes to me to fix. I don't understand how anyone who calls themselves a .Net developer would struggle to call a stored procedure or need a code example of how to do so. That would be about day 2 or 3 on an introduction to web development course. I spend far more time in SSMS and Sentry one plan explorer than I do in visual studio and I can write that code off the top of my head without google. If I can do that then everyone else here should be able to. It's not the size of the asshole that counts, its how much shit comes out of it.
Talks, github and the blog of Domanick Baier is what you want to check - &gt; https://leastprivilege.com/2019/01/14/automatic-oauth-2-0-token-management-in-asp-net-core/
Honestly from your comments you have no idea what you’re talking about outside of your little bubble. You know the buzzwords to rattle off but there’s so many holes in what you’re saying it’s unreal. If everything is as easy as you make it out to be, start your own software company and be a one man band. You’ll make more money than your junior salary, and you won’t be surrounded by “idiots”. 
Nice! I'll check out your other project too, we have some legacy IIS apps that would benefit from hosting in Service Fabric.
Thanks! I'll look into it.
Cool, I'll try it out...
The users authentication cookie is the "normal" way to do this. If you have OWIN configured in the MVC application (which you should), then you would follow the typical implementation of the logon workflow, inserting the bearer token API call in where it makes sense logically, and then let OWIN built the cookie using that. There is plenty of info out there on the specifics, but you can also look at the example OIDC code that is scaffolded by Visual Studio when you choose choose "Individual User Accounts" (i.e. Microsoft Identity Framework) in a new MVC app. There is a pre-made API/Webapp out there to do exactly this called IdentityServer 4. It is an ASP.NET core application that works as an Open ID Connect (OIDC) authentication server. The MVC client subscribes to IS4 as its authentication authority, and the OIDC and JWT configuration handlers (via the clients Startup.cs) let you specify how to handles the tokens post authentication. If you choose Cookie, for example, you don't need to do anything else and the OWIN auth pipeline will handle the redirect to the login API, store the cookie, and of course expose that to your client app via HttpContext.User. Check out: http://docs.identityserver.io/en/latest/ 
Thanks for the insight! I'm leaning towards using cookies too.
Aweome resource, thanks for that!
Could you elaborate on issues followed by storing the token in session storage? In my humble opinion, it makes sense to dismiss the token after session ended.
This is easily achievable in an MVC app. 
Thank you, that is what I needed. I got it working and all last night and I read over microsoft article but couldn't figure out self contained. You should submit that to their manual section (;
Thanks, that one didn't seem to work. but I am going to try it again as I would prefer visual studio community does it for me when I press build. I am a crap developer and end having to test after almost every 10 lines of code or so, so it sure would be nice to avoid running dotnet publish over and over before testing!
Yes, I've just read your answer - thank you!
I forgot to mention that I'm using .Net Core for everything, and the current default template doesn't provide any good info. I'll certainly look into IdentityServer4, but the thing is that I don't wanna roll a whole identity system for this app as this is a small side project and the only project that will ever use the said API.
No worries, I only mention it as it solves the same problem and would be a good model for how the API should handle its business. Googling .NET Core OIDC authentication (or JWT) will get you some clear examples.
I think the issue is that if you use session storage, the token will be lost once the user closes the tab and the user will have to generate a new token everytime by passing the credentials which in return I'll pass to the API. Now if I'm passing the credentials to the API everytime then there is no point in creating a new token as the API has the creds and can verify the user using that creds. Also it'll need to verify the user against the db everytime as we are not reusing the token so that's one extra db call. localStorage might be a good alternative though.
Yes, I've heard a lot of good things about IS4, I might even try it with my next project as it will be a good learning experience. Thanks!
We use umbraco at my workplace, though orchard appears to be farther along with .Net Core support.
Its pretty cool, especially for setting up single sign on across your apps. But yeah, for a small 1-off use case, its definitely overkill.
&gt; Sounds like you have no business training anybody This seems like unreasonably harsh language. Stored procedures were mentioned, but most of the benefits mentioned work if you just put the query in your code somewhere -- just make sure to properly sanitize your inputs. &gt; to make some idiot dba have an easier time More unnecessary harsh language -- why? &gt; I have way too much experience pulling business logic out of SQL, it’s a fucking nightmare. Totally agree here. But you can avoid overweight ORMs and still not put your logic in SQL. He's not wrong about any of the points he's made, and you're not totally incorrect about the points you make. Maybe we can all agree that we should strive to foster more kind discussions? Here's my 10cents: "large" ORMs (like EF) discourage developers from thinking about things in a SQL point of view. This seems great -- a lower ramp. But it really hides the truth from them. You're sending a query to a database for processing. There's a single perfect language to handle that -- SQL. If we always pass SQL to the database then we can know exactly what it's doing, we can tune its performance characteristics very finely. We can isolate queries for performance analysis. Yes -- lots of tools in various DMBS will provide these for you, but by writing SQL you bind yourself to a particular set of abstractions which are insanely good at getting data out of a database. ORMs often try to mimic these qualities, and great developers understand their tools well enough to get great results with an ORM. I still personally avoid EF. But I really dig Dapper.
Is there a reason you can't use a DataTable for this purpose?
https://github.com/OrchardCMS/OrchardCore/ You can use it as traditional CMS or decoupled or headless. 
I know of the following: - SiteCore - Umbraco - DNN - Kentico All of which are .NET framework and a fair few years old. They lend themselves to monolithic solutions as the CMSs try to do everything within itself (load balancing, caching, user management, page optimization / bundling) and exceeds at none of them. Another couple of paradigms I would look at are - Distributed CMSs - I believe Orchard Core is doing this in .NET Core - Headless CMS - no major .NET player in this I believe, other than bolt-ons to existing CMSs. But it all depends on your project and what you want to achieve and how fast you want to build it and how much maintenance you / your client are going to want to do on it.
&gt; source DataTable You mean a template? Tbh I haven't thought about it, I'm quite a scrub when it comes to UI.
Yup, totally agree.
No I mean a DataTable; it allows you to store data in a backend table and bind a UI component to it. You can then make changes to the DataTable without actually modifying the UI and it'll update appropriately. For (a rough) example: //Assume DG is a UI DataGrid DataTable DT = new DataTable(); DT.Columns.Add("Book Title"); DT.Columns.Add("Page Count"); DT.Columns.Add("Author"); DT.Rows.Add("Science Book","200","Einstein") DG.DataContext = DT; You could then remove / add rows / columns while keeping the binding in place, and make changes. Every change you make to the DataTable will update in the DataGrid. Does this make sense? &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B;
I think you need to learn the basics of SQL itself. SQL (the language) will help you understand what is happening behind entity framework queries.
I know MySQL
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/aspnetcore] [C# dataframes and data science libraries](https://www.reddit.com/r/aspnetcore/comments/b3comw/c_dataframes_and_data_science_libraries/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
Thank you!
Thank you!
While you are not wrong about EF sometimes being more trouble than it's worth, the solution you propose is a non starter for most IT professionals, myself included. I'm not going to spend hundreds of hours learning sql (even one flavour) to be able to do all the things you listed. I need it like once every 6 month, there are much more productive things to do. I feel that your reply is a bit dismissive, lacks awareness and empathy; that's why you got the responses that you got. And the thing that /u/Neophyte- is looking for would be cool to have. It's also a cool idea for a personal project. With support for multiple EF versions and different DB servers.
Well MySQL, MSSQL etc. all use the same SQL basically. So other than knowing the management studios there isn't much anything crazy to learn. Which I would at least get familiar with if you are using it. Shouldn't take you long.
You'll be fine then
We use Orchard CMS (the old non core version due to legacy) in my work place, we have around 50 custom develoled widgets all working together on around 30 tenants
Umbraco is really the king, but really I recommend static generators nowadays; they cover 90% of the use cases, are far cheaper to host &amp; have ZERO security issues by their basic nature. Look at Wyam for a .NET one [https://wyam.io/](https://wyam.io/)
Thanks for all that info. I think I'll just leave it to a Textbox column and check for the string true/false. This feels overcomplicating. 
Take a look at the Visual Studio SPA template, it stores JWT tokens in sessions storage but it also uses cookies.
If you have no need for any sort of high availability, then that's all well and fine but at that point there's really no reason to use a JWT. The main purpose of a JWT is to authenticate a client's identity to the server in a stateless manner. Since it's hashed and signed using a symmetric key, the JWT can be stored client side and any tampering will completely change the hash, so it's integrity can always be verified by the server. Basically, using a JWT with session storage can be fine, but then you aren't really taking advantage of the features of a JWT. You're basically using a hammer when a smaller chisel will suffice.
What do you think of this? http://bluemountaincapital.github.io/Deedle/index.html
No worries; I would definitely recommend learning DataTables at some point tho! :)
You must be a joy to work with. At my previous company, the enterprise-grade software we developed was architected by a DBA/database guru. It used tens of thousands of stored procedures. This SQL code was a nightmare to maintain, upgrade, and debug. Worse, we ran into huge performance issues because it didn't make use of C# features like async/parallel processing. The C# code was subordinate to the SQL and this is backwards. Stored procs are useful when performance really requires it, but having the abstraction be at the code level in EF makes debugging and maintenance much easier. EF isn't perfect, but it's being improved all the time and fits the bill for most common uses. 
&gt; If any of this goes over your head then EF is above your skill and knowledge level. Period. Same thing applies if you need google to answer any of these. Needing intimate knowledge of SQL is what **DBAs are for, not software engineers (necessarily)**. The reason you have a job in the first place is to answer these questions, and to support the people querying data out of the database using code. Expecting everyone to know how to do your job is a sure fire way to either sour relationships with everyone you work with, get yourself worked out of a job or be as bitter as you are in the comment section here. People are having issues with you because you meet questions with condesention, while answering the questions with other questions and statements like the one above. People Google answers to problems all day every day, nobody can hold everything they need for software engineering in their head at any given time. The expectation for someone trained in a different, but related, field to know how to do your job is ridiculous because then you *wouldn't have a job*.
Dude, he said he's a DBA.
I've seen shit like this before from shops that just have terrible devs. DBAs pick up the slack and most stuff is done by stored procedure.
That makes sense, but then coming into a global forum and making sweeping statements *(as a junior DBA)* because you've got a single, edge case experience is ridiculous. Following that up with a victim routine is equally as frustrating.
Yes I did, thanks for pointing that out, and it's really weird, I signed-in using that template and it stored the accessToken in session storage. The weird part is that it survived even when I restarted the browser. However I think that it has something to do with Cookie Auth which it uses for MVC side of the app, though I didn't dive into the code so I might be completely off. I still think that session storage will defeat the purpose of JWT in my case as I mentioned because I didn't want to pass the creds before every session.
Yeah, i agree. When I'd talk to those dbas about building apps they were absolutely lost on how modern development works. They'd tell me i was doing things wrong and should always use stored procedures. I just let them talk, not worth arguing. A bit like platos cave.
I'm actually a SQL guy from way back, but I've been using EF Core for the past year and I only use SQL because I want to (to check data, occasionally update some stuff for testing, etc.). And that's only because I'm good at SQL and it's natural for me to use it. It's never been actually required. If you understand the concept of joins that's all you really need - you can work entirely in C# (LINQ) and never pay any attention to the database itself.
Jeesh, it's a joke I stole from Bojack horsemen. 
&gt; Jeesh, it's a joke I stole from Bojack horsemen.
I was searching it for such a loooong. My theory is that no one talks about that because is impossible to found. Every tutorial or article that was present has been moved so many times that looking for that was a matter of internet archaeology 
explain more
The T-Sql syntax is close enough that you're probably fine getting started. I'd actually recommend spending more time understanding what EF is going to do to your database (via migrations, etc, if you plan to use code first migrations). Most people assume that EF is going to just magically manage your database correctly, and that is not true in any way shape or form. They typically dont realize this until the app starts misbehaving, and then they notice that their database is a huge wad of spaghetti because they added navigation properties and circular references everywhere, creating outer join chaos in the database.
Why NInject instead of ‘default’ DI?
We are looking for something that's kind of a kit of parts that one can mix and match and ignore/swap-out as needed. A good HTML templating system with conditionals, conditional and nested template includes, and loops would also be nice so that the graphic designers don't have to be programmers. Compiled languages often have a hard time having good and tunable templating engines in my experience.
Also, checkout this thread where a [Microsoft Agent is telling people to take the wrong exam](https://trainingsupport.microsoft.com/en-us/mcp/forum/all/mcsd-app-builder-confusing-requirements/4b78a363-2791-44ba-914f-3248941817c2) and is [now acting like there's no issue](https://trainingsupport.microsoft.com/en-us/mcp/forum/all/are-you-kidding-another-mcsd-requirement-change-70/0838fa48-be10-4736-a40e-515cb90e51a6) since the "final" update has been made.
You'll be fine. The new stuff is just better implementation of the old stuff. If you understand what you did in VB, you will understand why MVC is better. You're going in the better direction - going the other way (new to old) is painful.
VB to C# will be easy. It is still the .Net Framework, which takes the longest to learn. WebForms to MVC will take a while. WebForms does a lot of things for you (even if badly), and you will have to learn to do things a different way. That said, you will have a much better understanding of how the web works, and what your code is doing, once you are done. The good thing is that you are doing this way after the fact. E-Learning sites like PluralSite have tons of content to help people learn MVC.
Umbraco is great. 
Umbraco is rolling out Umbraco Headless on their cloud solution. 
You're talking WebForms which means you are also referring to [VB.NET](https://VB.NET) as opposed to VB6. Believe it or not, such applications still exist and you'd be in rougher shape if you were still doing things in that language. Anyway, you're not in for that rough of a ride. If you want to start with things you know I would suggest going a bit unconventional route and look into a decompiler such as [justDecompile](https://www.telerik.com/products/decompiler.aspx). What this would allow you to do is take a DLL from your existing work written in [VB.Net](https://VB.Net) and convert it to C#. That way you could look at something you are already familiar with and see how the same thing would be accomplished in C#. I'll warn you that it isn't picture perfect when it comes to making code that is easily readable, but it should allow you to cover the basics like variable declaration, conditionals, etc. LINQ for example won't translate at all and will instead come out as a For Each loop. &amp;#x200B; Sounds like your next challenge is MVC. MVC as a design pattern is old (mid 70's) and there is nothing that says you couldn't have implemented that pattern in your web form work. I certainly did long before MS announced [ASP.NET](https://ASP.NET) MVC and people suddenly started paying attention to how their code was put together. WebForms get a bad rap because they made it so easy to just through everything behind events in the code behind and off you went. leading to a great many poorly thought out and executed code bases full of spaghetti. There was never anything stopping anyone from treating the .aspx.\* as a View that was purely responsible for taking in information from a Model and then utilizing a Controller to perform actions that modified the Model. It just took time and for a lot of people maintainability wasn't really what they cared about. I'd look into how that pattern works regardless of the language prior to worrying too much about which one you plan on using. &amp;#x200B;
[removed]
I'm still doing that, piecemeal. Started about 2-3 years ago and do a form once in a while when time allows. Should be done in a month or so. It's taken so long because it has been interspersed with other dev. &amp;#x200B; We host the main site as MVC and that overlays the webforms site. To make it work we created symlinks from the MVC folder to the ASPX files in the webforms folder and delete them as we get each page done. &amp;#x200B; It's nice to put some of the logic into action filters (such as checking for an empty basket, authorisation etc.). &amp;#x200B; Ping me any questions if you want.
Agreed, unlearning webforms will be the bigger challenge of the two. That said, do it as fast as possible. Once you get your feet under you, you’ll realize how god-awful webforms has been treating you all these years, and you’ll be amazed how much faster your development efforts become. As a bonus you’ll never have to write “runat=server” again. 
Feature flagging can be useful indeed, especially if dependency injection is used. Based on flags, specific implementations can be injected. With rollback I actually meant only rolling back the dlls for a short time period until a bugfix is delivered. Our UAT indeed uses the xCopy task to copy/paste dlls to the right place. I need to extend this that it first runs the unit tests, integration tests and if it's successful it should automatically deploy. I suppose it's pretty simple by just adding the tasks sequentially. For release deployment, I found that I can create Release Definitions. Deployment to release should be done manually anyway in our company. Because on UAT, the changes have to be confirmed first, after a go, we can deploy to release with one click in tfs if I'm right. What makes me think is actually that there are so many types of tasks like cmake, gradle or msbuild. I am a little clueless after seeing all these possibilities. I don't know which one to use. I just want to achieve build, test, deploy (with automated merges hopefully without conflicts). And to release: deployment can be done manually by running a build definition.
Use a DatagridTemplateColumn with the combo box and textbox inside it's datatemplate, then handle the visibility of those based on the type value. You will have to use binding (+mvvm).
&gt;EF codefirst is one of the easiest ways to create a terribly designed database. There are a couple cases where I've found EF Core lacking but overall you're greatly over exaggerating. Yes you should know SQL and DB design because for the most part, those same principles apply to EF Code First. Bad code is bad code, and it's not the tool's fault. Using EF is *not* a shortcut. And stating that it'll end up taking more time in the long run is laughable. I work in an environment where one of our main constraints is time. Our projects are often underfunded and the requirements are poorly laid out. EF (along with a number of other tools) allows us to write easy to maintain and deploy applications in a fraction of the time. It allows us to focus our time on UX, data integrity, security, and easily track changes to the schema for easy review. I'd love to hear actual examples you've run into, though. Your post just sounds like claiming hammers are a terrible tool because one time you hit your thumb.
Cool! Yeah. It's nice. The other project just fires up IIS as a console app. Like any other program. From there you gotta get it running in SF. And you do still need part of IIS installed on the SF node: the IIS Hosted Core. Which is a native library you can use to run IIS in process. But, no w3c service needs to be running on the box. I've tried to make the API so it looks sorta like [ASP.Net](https://ASP.Net) Core. Fluent startup. I deal with a lot of COM objects. So, running those on SF in isolation (no machine wide installs) required me to take ownership of the IIS process, so I can set up COM activation contexts. Hence, that was built. Coupled with the local state server, it all works quite swimmingly.
The technology is moving towards headless. https://www.hanselman.com/blog/HeadlessCMSAndDecoupledCMSInNETCore.aspx
Don't know it I'm missing the mark here but entity framework doesnt require SQL Server. You can use many databases, including MySql https://docs.microsoft.com/en-us/ef/core/providers/ If you stick to the database basics (no views, no stored procedures, no custom database features) then Entity Framework can do everything you need. If you need special stuff, are working with an existing database, or have a database used across multiple (non-entity framework) projects, you are likely to run into something entity framework doesnt completely handle and you will probably need to write some SQL of some sort for that.
EF is just a tool. Like any tool if it's used properly it makes work easier, when used incorrectly it makes for a mess. Stating no one should ever use EF is like saying no one should ever use a hammer - they should just use a rock. Your laundry list of SQL trivia is not impressive. These are questions I would expect every DBA to be able to answer quite early in their career. Being a DBA is about far more than query tuning, which is something software is getting better at doing all the time. Your condescending attitude reeks of insecurity. I find it common in this field for people with little experience and confidence to feel the need to talk down to people, to make themselves look better by making others look worse. Once you have a bit more confidence, you don't need to do that - you prove you're good by being good. You can explain why you're right without having to be insulting to those you're explaining it to. You become someone people look to for answers, instead of someone people roll their eyes at. You seem to know a little bit about sql queries. That's great - there are tons of pretty bad queries out there that can use some help. You don't seem to know much about software development outside that area, however - so I would limit what advice I give to the areas I am knowledgeable on. &gt;EF is frontpage for databases and causes far more issues than it solves. This is completely incorrect. EF is a tool and has a place. Used correctly it greatly reduces development time. &gt;Theres no reason to get nasty over it. You need to take a long look at how you come across to people. &gt;If any of this goes over your head then EF is above your skill and knowledge level. If every junior dev I employee needs to have in depth knowledge on query tuning - why do I need you? Your job is to help the devs create well performing queries. I agree most devs should have some understanding of underlying structure, but if I'm going to require them to go in depth, I no longer need an expert who's entire job that is. &gt; You can disagree with my opinion but please lets keep it civil and if you think I am alone in my views on EF within the DBA communities I am afraid you are very wrong. If you're insinuating that disagreeing with your statements is wrong, you're no longer representing said statements as opinions - but facts. 
I used to work with Composite C1 CMS (Now C1 CMS by Orckestra) and was pretty happy with it. https://github.com/Orckestra/C1-CMS-Foundation 
There is more to an ORM than just connecting to a database and running a stored procedure. While different ORMs have their own list of features, the vast majority do quite a bit more than that. &gt;You OO developers love your funky orms but you will really struggle to find a dba or sql developer who thinks much of it. The DBA here doesn't have a foul attitude towards ORMs. The vast majority of queries written will perform perfectly fine even if not optimized. In the instances where the DBA notices a poor performing query, he works with the devs to tune it. If that proves to be difficult to do via code, he moves things to stored procedures and then that gets called from EF. What he doesn't do is take a holier-than-thou attitude with the developers. 
Thanks for the shoutout. Your episodes are shorter enough for my commute, you guys sound great and I get all the relevant .NET news without opening reddit, hn, and individual blogs and other apps. What more can I ask? Wish you a great success for a long time to come.
Thanks for the shoutout. Your episodes are shorter enough for my commute, you guys sound great and I get all the relevant .NET news without opening reddit, hn, and individual blogs and other apps. What more can I ask? Wish you a great success for a long time to come. _removed this reply from the old post and added it here._
That doesn't really say anything. Maybe you're the best query developer that business has ever seen, but has only ever seen subpar query developers. The least bad person at something isn't necessarily any good. &gt;I don't understand how anyone who calls themselves a .Net developer would struggle to call a stored procedure or need a code example of how to do so. You need to understand there is more to software development that sql queries. I understand that's the one part of this whole process that you're familiar with, but there is quite a bit more going into to than just that. Most software developers could write you a method that calls a stored procedure in a database. If that was all that mattered, we'd be done - but that isn't the end of the line. What happens if the connection fails? What happens if the transaction fails? What if I need to make the same call, but with 1 parameter different? Do I make a different method for each variable parameter? What if I need to make this same call somewhere else? Is this testable? &gt;It's not the size of the asshole that counts, its how much shit comes out of it. If you're going to plead with people not to get nasty, please refrain from doing so yourself. 
&gt; Yes and you can 'short circuit' where clauses. Very long, short circuiting methods or clauses are a code smell. They're hard to maintain, hard to debug and hard to read. You want your code to convey what is trying to do easily, and having 20 clauses in your where clause goes against that. I'm not saying you should never rely on short circuiting where clauses, just that over using that tactic will make your code harder to maintain. &gt;I cannot tune a load of generated SQL code fired out of a web app without making changes to the front end code. What's the problem with this? Do you sit in your cube all day and never interact with anyone? Most DBA's I've known will pull up a chair next to a developer if an issue with queries come up. They work together to solve the problem. Sometimes that means tuning the code, sometimes that means moving logic to the DB. &gt; As a DBA I don't want to be firing up and running an entire website solution just to fix your code for you. That is...not how a development team should work. &gt;FYI I work in a software training company that trains both software developers and DBAs and our customer base includes plenty of companies that you have heard of. This doesn't actually mean anything or add anything to the conversation. 
Any tool, when used improperly, can cause problems. Dismissing the tool because some people don't know how to use it seems like over kill. I'd rather train the people to use it. 
Was joke. When I happened across the post it had been up for some time but no one has commented.
Looks interesting
Which for me also includes knowing when EF is and isn't a good idea. A lot of people use EF because they have no desire to learn how to correctly use SQL because it's "not their job".
Sure. I'd agree that "Always use EF" is just as bad a statement as "Never use EF".
Core will not work with VB. Even MVC will not work well with VB. Move to C# first, then jump into Core, as MVC is now no longer being developed. Even I’m making the jump to Core, despite being in love with MVC. I just have to find the right repository pattern that works well for me, as I typically build platforms with more than one interface/portal. You need a repository pattern if you’re doing that, especially if you’re doing Code First with migrations.
You will be fine! I have migrated a ASP.NET Web Forms projecto in VB to MVC in C# less than a year ago. I think that VB to C# is easy since the code, structure wise is very similar. Of course, you will need to learn how MVC works. In the end you will see that the code will be better organized comparing to the mess that Web Forms sometimes is. 
Is the transition easier having done classic asp? Razor seems similar 
They are called snippets yes. Don't know the answer the main question though, sorry 
Typing `fore` + tab will do the job in VS Code in a .cs file. Yes, they are called snippets. You can read more about snippets in VS Code here: https://code.visualstudio.com/docs/editor/userdefinedsnippets
You’re good with EF core, the only thing you’ll need to know about the server of your choice (mysql postgresql, sql server or whatever other server that has ef core compatibility) is how to install it once basically and eventually grants rights to user (create database etc). You won’t need to use any SQL unless you want too.
You don't even need EF, let alone SQL Server specifically. Nothing's to stop you from interacting with a database however you'd like, as long as it has a Core compatible wrapper or whatever, or you want to build one yourself.
Same question for you then. Can you give me examples of the specification pattern or a repository that follows open/closed principal using Dapper? I gave 3 pretty good things that OP was clearly wrong about in the first paragraph. Unit testing Dapper is also a PITA compared to EF.
Thank you very much! Going to take a closer look at Orchard and Umbraco :)
Wow! Thanks! I didn’t know about headless cms :)
&gt; Agreed, unlearning webforms will be the bigger challenge of the two. ++ If you were a unicorn and used proper practices and separation of concerns and all your UI logic is nicely separate from your business logic, then it won't be so hard. But I don't know *anybody* who used WebForms back in the day who did that. And certainly nobody who used VB who did that. I'm not a fan of "throw it out and rewrite", but I don't think a piecemeal transition from VB.NET to C# + MVC + modern web dev with some JS framework like Angular/React is going to be realistic.
Just too add to the conversation. Bootstrap is easy and it will standardize your website. Many designers moan about bootstrap being generic but your users will be familiar with it since many websites are built with it. &amp;#x200B; You should try creating a new project in VS, MVC 5 or Core and bootstrap 3 is added by default. You can then run the website and you will have bare bones setup with navigation. Bootstrap makes it easy to support mobile devices too. Then you make changes as needed and look up the stuff you need. You can make a really well looking site with little front-end knowledge. Bootstrap also has decent documentation and example of all components, Javascript, and styles. 
What's your approach for migrating user controls that need to be 'shared' between the webforms and mvc pages while you have both? For example, header, footer, menu's, etc. &amp;#x200B; &amp;#x200B;
I adore C#. Built my career off of it. There are tools relating to it -- at each and every level. And, I find ... those that use it are pretty good at it. It isn't a fad, so the people building with it are usually solid.
Checkout the idataview aspect of ml.net. https://github.com/dotnet/machinelearning/blob/master/docs/code/IDataViewDesignPrinciples.md
Sitecore supports headless CMS.
Since OP was using WebForms, it is safe to assume they meant VB.Net and not VB6. VB.Net is a valid language for .Net Core.
Just do it and stop thinking about it. Make a new MVC C# application and learn as you go.
Are you migrating an existing app or just learning the skills to do new development? Either would be great ways to learn. You may consider going the .net core/c#/razor pages route though. This is a great resource for learning that: https://www.learnrazorpages.com/ Either way, the switch from VB.net to c# will be the easiest part. 
Combine it with the R type provider and you've got a powerful set of tools for data science, in an easy to use wrapper :)
ascx (user controls) can't be accessed within MVC layouts so we duplicated those. I may be wrong on that, I have a vague memory of Scott doing something like that ( [https://www.hanselman.com/blog/IntegratingASPNETMVC3IntoExistingUpgradedASPNET4WebFormsApplications.aspx](https://www.hanselman.com/blog/IntegratingASPNETMVC3IntoExistingUpgradedASPNET4WebFormsApplications.aspx) ). As for master pages / layout those were also duplicated as well and just need to be kept in sync. It's mostly because of the different markup syntax between Razor and WebForms. Other points, use attribute routing to replace the old webforms urls (/page.aspx) with your new controller actions one at a time so you don't need to change the front end routes / SEO. &amp;#x200B;
I understand there is a need to get a better grasp at the db level. i admit i dont know a lot of those terms. could you point me to a good book on performance tuning queries and getting into the meat of sql server on more advanced concepts like you mentioned. as a full stack dev, its hard to be ontop of .net core / angular and sql. as in to have advanced to knowledge in all those 3 areas. and there is more to being a dev, knowing how hte internet works is very important, how does http work at a fundamental level for example.
That's what I've seen as well, but wanted to ask and confirm in case you found another way. Thank you for your response.
Awesome thanks
you would be wasting a HUGE amount of time doing this especially as requirements change and that sp becomes a huge mess of conditions
My first language was VB.net, because I was teaching myself and only had some VBA experience prior. So I was of a similar mindset - VB was easier and made more sense to me all around. A few months later I was basically forced to learn C# because I had to work on an app that was created by someone else. It was daunting at first, but after just a couple days things started to click. Three years later, even though I have written much, much more VB.net than C#, I feel more comfortable with C# and consider it to be my primary language. It's more intuitive, easier to write and read, etc. Long story short - you'll be fine. Just commit yourself to doing it, and you'll probably end up being surprised by how straightforward it is. You may even end up preferring it.
Something like [this](https://github.com/qccoders/QCVOC/blob/dedb4a31cbbef6a73df24083561cb9408d442bf0/api/QCVOC.Api/Veterans/Data/Repository/VeteranRepository.cs#L151) is a bit of an in-between solution using Dapper and the associated `SqlBuilder` class to dynamically build query predicates. Dapper is technically an ORM though, so I'm not sure where the battle lines are drawn on the subject.
I think if M$ hadn't made the cost of VS so high and gimped the community editions so much that there would've been a lot higher adoption rate of .NET development/developers. A number of my dev friends went into JAVA / PHP or w/e because they couldn't fork the money over to give it a go. 
I totally did that!!!! ::narrator voice:: he didn't.
Accord.NET?
class.... no, we don't speak of such things.
&gt;Doesn't VS Code solve this in many ways? 
No problem. If your site is simple enough then headless CMS would be my personal preference on the way to go. Have a look at the JAM stack, it's basically any headless CMS backing a statically generated JavaScript application. You can use a front-end JavaScript Frameworks like React or Vue for your client-side interactivity with the bonus that you're only serving Html, CSS and JavaScript files to your users, which is pretty performant. Some of them support eager loading of linked pages so that users dont have to wait between clicking and loading.
I think you might be intertwining a few concepts and that is what is causing you some confusion. The first thing you need to do is establish a dedicated Build server. From some of your other comments it sounds like you may not have one. Nothing really too special about it, just a machine with visual studio installed as well as a [TFS build agent](https://docs.microsoft.com/en-us/azure/devops/pipelines/agents/agents?view=tfs-2015). You can get away with just the MS build components, but if you're starting out then the full VS install makes it easier to figure out what is wrong when something breaks. &amp;#x200B; Second thing you need to do is establish a regular build of your code to produce some sort of artifact (.EXE, .DLL, etc;) . You start with a [Visual Studio build task](https://docs.microsoft.com/en-us/azure/devops/pipelines/tasks/build/visual-studio-build?view=azure-devops) and give it the name of your solution. You don't even need to be that precise if you don't want. Leaving the default \*\*\\\*.sln will pick up any solution file that has been download during the Get Source phase. Presuming you're following standard operations that will place the compiled work into the bin\\release folder. You then use the[Publish Build Artifacts](https://docs.microsoft.com/en-us/azure/devops/pipelines/tasks/utility/publish-build-artifacts?view=tfs-2015) task to bring those assemblies into TFS and associate them with the build. You'll see the importance of this in a moment. &amp;#x200B; Third thing is to create a [release pipeline](https://docs.microsoft.com/en-us/azure/devops/pipelines/release/?view=azure-devops). Here you will define the environment(s) where the application is deployed. You start by telling the pipeline which build definition to use as a trigger for starting the pipeline. In other words, the build definition you established in step 2. Each environment will automatically download those assemblies and from there you can tell the environment to place them into the correct location for your application to run. That covers your deployment. Testing it is simply another Task in the environment and you can then chain it all together so that same initial artifact can go from Dev to UAT to Production. all of which will short circuit in the event that something goes wrong. If the tests on DEV go badly, no automatic deployment to UAT or production beyond. there are also decision gates that you can put in place to require approval from people even if everything passes. &amp;#x200B; Once you have all that and presuming you really do just want to 'roll back' the DLLs then all you really need to do is go back to the previous release whcih was done using an earlier build and 'Redeploy' that build. &amp;#x200B; &amp;#x200B; &amp;#x200B;
nowadays yea though Code/VS have different use cases.. with VS community edition being pretty good to start for someone wanting to plunge. I'm talking prior where there was either express which was terribly gimped and you had to buy professional / enterprise or whatever it was. A non gimped visual studio was expensive and a gate to the .NET world (in addition to a server for IIS) if you were a small shop / hobbyist trying to do anything serious. 
What’s missing in the Community edition that you feel makes it too “gimped” to code with? (I’ve built a very lucrative career off the Community version.)
Exactly, I don't even know what community doesn't have that the other versions do
&gt;Every non-trivial app will need an ORM. i see you’ve never worked for most of the companies i’ve worked for 🤢
It's been a while since I've used Community. Does it have the same refactoring tools as Professional? (code formatting suggestions, break lines out to separate method, change method signature, rename variable/method/class, etc) If it can do all that then the only thing I care about that it doesn't have is CodeLens. I know it isn't the most popular feature, but I love being able to see references at a glance.
You and me both friend. Back in like 97 98, all my .com bubble friends laughed at me for going with ASP Classic. 20+ years later, here I am. So glad I didnt go Cold fusion or java servletes from back then. 
CodeLens is coming in VS2019 I think.
https://visualstudio.microsoft.com/vs/compare/ According to that page, the differences between Community and Professional begin and end with CodeLens. There are certainly some niceties only available on Enterprise, but to be honest I'm not even sure if I could count the times I've needed them on one hand.
Refactoring is the same. https://visualstudio.microsoft.com/vs/compare/
This is no longer true. VS Community and VS Professional are basically identical except for CodeLens.
I absolutely have, that’s how I learned that lesson. Nothing like spending months pulling business logic out of stores procs...
ugh please don’t remind me lmao
actually I would wait for 3.0 to migrate an app, because razor components might help when coming from webforms, well basically it uses websockets when hosted inside a server which can be a performance hit, however i guess for webforms people its way harder to write javascript.
&gt; niceties only available on Enterprise In-IDE code coverage for .NET Core is the only must-have that I've found and that gap will hopefully be closed with a free third party extension soon.
VS Code is nowhere near reaching feature parity with Visual Studio. I love it for any language other than C#, though.
So, I started with a BS is Cybersecurity. Got my first "big boy" job about 6 years ago. Working in IT for about the first 3 or 4 years. Taught myself powershell and it just wasnt enough, I needed something more. I looked at python, ruby, java, none really stood out to me like c#. Possibly because I was so used to powershell it felt like it just came naturally. So here I am, almost 6 years later from that start in IT and I was able to build my own API (aspnet core) and frontend (though that's in angular) which some of our customers use. On top of that, a couple months ago, I was transitioned into development, where I get to learn more and really grow! C# really kept my interest where other languages just couldn't. I'm happy it exists.
idk, im almost thinking i should skip it and go straight to the Angular/React/Node JS trio
Dreamspark was nice 
Perfect. I'm going to read this very carefully again when I'm near my pc.
That's certainly much better than 90% of what I see in the wild. I would still argue that isn't flexible enough for complex systems. Those are going to want to only select certain fields, join with other tables, group by, etc. You can do all of that with Dapper, your repository just ends up 500 lines of code that a junior dev will have a lot of trouble understanding. Sometimes that is probably needed, but there are usually ways around it.
[Squidex](https://github.com/Squidex/squidex) would be a non-bolt-on .NET headless CMS
Currently using [TickSpec](https://github.com/fsprojects/TickSpec) for the nice F# support, but also has a C# API.
This looks very promising! Thanks, will give it a go now :)
I used to maintain software written using xmotif. Don't laugh. I tried applying to other jobs and quickly learned about the whole experience thing. But I managed to stumble into a C# maintenance job that turned into a whole lot of asp.net stuff. I stayed here to launder my resume. This is a good platform to hitch your wagon to. 
Note that the 2017 link includes content from subsequent updates; i.e., up to 1.5 years' worth of features _after_ the initial release of vs2017
Community edition is the exact same as professional just with different licensing.
It's possible, yes. There's a webpack middleware for .NET core. Check this out: [https://docs.microsoft.com/en-us/aspnet/core/client-side/spa-services?view=aspnetcore-2.2](https://docs.microsoft.com/en-us/aspnet/core/client-side/spa-services?view=aspnetcore-2.2) &amp;#x200B; You will need to call app.UseWebpackDevMiddleware(new WebpackDevMiddlewareOptions { HotModuleReplacement = true }); in your startup and install the npm packages aspnet-webpack and webpack-hot-middlerware (for hot reload). Bye using the middleware webpack loaded in memory and will do on-the-fly recompiles while your app is running with dotnet watch run or dotnet run. &amp;#x200B;
Also now with Azure I you can run your own servers for free for testing as long as they don't get more then X amount of hits within x amount of time. Then when you get a paying client you have an entire server or server less Eco system you can use and get billed only for what you use.
I have used your library in the past, has worked out well. Will also check out in the future!
As a C# developer, seeing these posts almost makes me cry of joy.
Glad to hear it :)
&gt; Ill never forget a friend of mine using Cold Fusion telling me I would be wasting my talent on some "fad" language made by microsoft. on the other hand your friend had no way of seeing Adobe buying macromedia - the beginning of the end for coldfusion. 
Do we really have to vote down the truth? I would think old timers being at this for two decades as some claim would know this use to be the case.. You used to have to shell out $700 plus for VS. Plus startups had compelling cost reasons to not develop .net - windows only servers
I'd love more people to lean your way, but there are convincing reasons people get away from .Net at the moment. Past the bandwagon curse for Microsoft stack, Ms didn't really commit to important fields. My domain is AI, not the least, and here is a [recent review](https://www.reddit.com/r/artificial/comments/9xsxe3/teaching_ai_in_net_a_review_and_a_rant/) I made of the .Net AI landscape. While Ms has put some efforts on their Azure and Python offering, .Net suffered the divestment. The fact that my [crosspost](https://www.reddit.com/r/dotnet/comments/9y5omd/teaching_ai_in_net_a_review_and_a_rant/) to this sub got no attention tells a bit. A couple localized efforts would completely change that landscape : * [Iron Python](https://ironpython.net/) is pretty close to production * [IKVM](https://www.ikvm.net/) or a similar library to keep the bridge to Java libraries * [Keras Sharp](https://github.com/cesarsouza/keras-sharp), divesting CNTK's effort to providing the best deep learning .Net bindings. * [Moebius](https://github.com/Microsoft/Mobius) for a strong Big Data API * Add .NetRDF bindings to [Graph Engine](https://www.graphengine.io/) for semantic web * [c# notebooks](https://github.com/tlinnet/csharp-notebook) That and maybe a couple more, making sure for instance ML.Net and Infer.Net get all the attention they need, would make c# a reasonable choice for AI.
&gt;That's true. I had no idea I was making the right decision. I was just doing ASP because I found a good tutorial and mentor on a mIRC developer chat if were being honest. 
I don't think it was ever the cost of and IDE that kept people away from .NET.
I wouldn't blame the cost of an IDE. For me, the reason I always stayed away from C# was basically everything else. The non-cross platform support; the vendor lock-in to a company with a shady past; the lack of traditional tooling (read: command-line); the lack of library options where other languages would have dozens of open source options...
I remember when there were zero free editions of visual studio. They first came out with the Express editions and they were language specific and holy hell were those gimped.
Agreed, it falls apart with compound predicates such as those using `OR`, `AND`, etc. When you start down this path you inevitably end up with repository methods like `GetAllForFooWhereBarAndBaz()` which are not great but trade verbosity and repetition for complexity. As with all things i think a combination of things is usually the best approach; queries like the ones in my example that are more or less raw SQL are ideal for high volume/frequency use cases, where an ORM is best with high complexity examples. Keeping in mind that you need to be checking the SQL generated by your ORM for sanity. I think a lot of people neglect that fact and it generates a lot of hate. 
Cool tip, I'll have to look into that one. Seems like an interesting attempt at the problem.
Same boat. And oddly enough, I just went on 20 years myself!
We should probably separate what's best for ones wallet versus what is most *personally* satisfying. I won't address the money issue here. Personally I prefer dynamic programming languages. They are more WYSIWYG in terms of debugging internal content and structures, and it's easier to reshape most dynamic language framework to fit shop conventions and/or personal conventions. Everything seems more malleable. Static-language frameworks just seem more stiff. You have to **battle a giant pile of persnickety nested types** to change anything. That may be their selling point: they keep the herd of average or bored programmers from wandering off the proverbial ranch, but I personally find it stifling. I'm far more productive when I can tune the stack, and I miss dynamic languages. I'd rather be doing PHP or Python. *Come back, oh darling!* ❤ A caveat is that I've been using dynamic languages much longer such that once I master C#/dot-net I might have a different opinion. But as of now, it looks stiff. &amp;#x200B; &amp;#x200B;
&gt;Keeping in mind that you need to be checking the SQL generated by your ORM for sanity. I think a lot of people neglect that fact and it generates a lot of hate. I think this is what most people don't get. Any decent ORM will implement logging of the generated SQL that it is using. Performance profiling should be in place such that issues are automatically created when database calls take too long. These can then be reviewed by developers (or DBAs) to see what the best fix is. ORMs are a leaky abstraction (they have to be) and should be treated as such. 
Webforms is just fine if you your project is relatively small and doesn't care about esthetics. Too much reliance on Javascript UI gizmos typical in MVC shops turns an app into a maintenance headache as new browser brands/versions break stuff. Doing more on the server reduces dependence on browser change. JavaScript is just a maintenance drain. If you want fine control over UI and Javascript fanciness, then MVC is probably better, but if you just want to **git-er-done** for internal or very niche applications without UI maintenance headaches, Webforms is perfectly okay despite not being "in style". Done let the Style Dogs scare you away.
It sounds to me like you haven’t done a whole lot of development in MVC,. Views are much easier to both code and maintain, and the server is still where nearly all of the real work happens. Razor is literally a server side templating language for those views, so you can even use C# to build your page elements. You could write an entire mvc app, fully featured, with 0 JavaScript if you so desire. Are you confusing Angular and React with Asp.NET MVC ? Cause that’s what it sounds like. MVC is better at everything than webforms, and it isn’t even close. 
I've seen better ways to do it. It's hard to explain here without thousands of lines of text, but MVC/Razor is verbose and sucks in my opinion. 
The .NET ecosystem is about as solid as it gets imo. 
More verbose and repetitious than webforms!?? Holy shit that's got to be a joke. We actually still have a large webforms application in production, and no developer on staff wants to work on it for the exact opposite reason of what you just said. Razor can do in 4 concise, easy to read lines what webforms does in 40, or 400. You just need to spend more time using it apparently, cause you are living in the stone age. 
Yeah and it keeps getting better. .Net Core is great. GIT is awesome sauce compared to TFS. All the kids using VSCode are like Beta Testers for Visual Studio. I also love TypeScript. What’s not too like about ASP.Net and C#?
You do know that C# has a dynamic type right? 
Yes, but many frameworks are not designed to work well with them.
Maybe they are bad Webforms developers. Bad software can be written in any stack. I cannot comment without seeing it.
I don’t know what that means. 
Cut my professional teeth on VB5 and VBA then moved over to C# in 2003 and haven't looked back. I've augmented that with near mandatory javascript + my favourite front end framework. I'm never out of work and am often getting "harassed" by recruiters. The .NET ecosystem is great and work at companies small through to enterprise/government is plentiful.
Someone moved your cheese and you refuse to be a part of this new-fangled web or something. Not one thing you pointed out as a flaw in MVC is even remotely accurate. The routing engine takes 0 configuration, period. You never need touch it unless you want to do something custom. No idea how you got such bad instruction on how it works. In fact, the only takeaway I can see from this conversation is that you have no training or real experience in MVC. And yes, you're right, they are bad webforms developers, because there is no good way to use that antique piece of garbage except badly. You're stuck in the past man, I hate that you have to find out this way.
The frameworks/API's typically either don't accept them, or lose (ignore/bypass) a lot of features if you do use them. They are simply not built with dynamic types in mind; I don't know how else to say it. Frameworks built with dynamic types/data in mind are typically designed different than those built for static typing. Without experience seeing them it's hard to explain. I'll ponder it and see if I can come up with a good example that doesn't take a long time to explain the context or intent.
I get it. Most of the .Net APIs do not accept the dynamic type as an argument. I actually use it most to work with Json without creating a class to serialize it to. 
Yeah, cause pure javascript will solve all those pesky problems /s
Are you rewriting them into partials? That's the MVC analog, but yeah, you can't host ascx in views, they are emitted as plain HTML5.
&gt;The routing engine takes 0 configuration Like I said, only if everything is set up right. If something is wrong, it gives very poor or zero clues as to why. If you stick with plane-jane simple stuff, sure it's easy to solve. Doing anything a little creative, and *Kablam*: Organic Quantum Debug Day. And yes, you're right, they are bad webforms developers, because there is no good way to use that antique piece of garbage except badly. The Webform developers in our shop are twice as productive as our MVC team. I almost want to request to join them, they go home on time. The only places that actually seem happy with MVC are technically-specialized with fairly large teams, like I already described: they each focus on specific things like UI, database, middleware, etc. The org can hire a plug-and-play routing expert who knows how to fix that evil *thing.*
No dude, not just plain-simple stuff. You keep repeating yourself and you're wrong about every single bullet point. We have no specialized developer, no UI people, no routing (wtf?!) people. We are a team of 12 devs with 5 large, very complex enterprise applications, dozens of WebApi apps, WCF services, 2 .NET Core apps... all running the systems of a 200 million dollar revenue company. I started life as a Windows services developer and to this day I am not a fan of web UI development, but technology has advanced to the point that its very simple for me to do so, and so I do, and so does every member of my team as well. The problems you are describing are self inflicted at best. If you think that MVC development is harder that webforms, you're 100% doing it wrong, end of story.
Yeah.. but by not using the API don’t you risk a blacklist ban from google EULA?
No, it just dumps the problems into the poor UI guy ☺
maybe I should stick to Web API and SQL then
No tests...
Other people have come to similar conclusions I have. I don't disagree that MVC shops *can* run smoothly, it just takes more things to go right, or a long learning curve.
So... That's just black box programming on top of the black box programming that MS did to enable server side controls. Neat. @Html.InputFor(m =&gt; m.middle_name, new{ @class = "col-md-3"}) Literally describes everything that it is going to emit. Yours pretty much says nothing except a field name string. But listen man, you do you. I'm not going to change your mind and you sure as fuck are going to sell me on a busted, 30 year old, unsupported web UI technology. You keep on keeping on. I bet webforms will make a comeback any day now. 
&gt; Every non-trivial app will need an ORM That's ridiculous
It didnt exist when .net came out. It was released like 5 years ago. 
&gt; With an ORM like EF, I can do something like: &gt; &gt; var result = respository.Find(specFactory.ProductIsActive().And(ProductAgeBetween(0, 5)) lol, dude, building up a query from expressions is not rocket science. What do you think we did 20+ years ago when ORM's weren't a thing? It's telling that you're so flabbergasted by the prospect of using the specification pattern without EF.
Congratulations, you completely missed the point. The point is that those specifications need to be built in code. Anyone who has dealt with applications with business logic in SQL will tell you what a nightmare it is. At this point, you are using an existing ORM solution or you are building your own. Unless you have a team of developers devoted to building a solution, you should use an out of the box solution and extend it where needed. I've dealt with at least one company who built their own 'ORM'. For 95% of queries, it was pulling down the entire dataset and then doing everything in code. Talk about performance problems. I certainly don't think there is anything amazing about EF, I just think it is stupid for most people to not use an ORM at all because they will end up with business logic in SQL (bad) or building their own ORM (almost always bad).
Any particular reason you want to use SpecFlow? I've used it before at a previous job and wasn't a fan. In fact, we decided to move away from it entirely as it was taking too much developer time in assisting the test team. My current organisation is looking to do the same. I can't provide any input to your question as to using it in .net core environments. I would be interested to see what others suggest here though.
I'm certainly open to being proven wrong. Care to give a few counter examples? I'm sure saying 'every' is incorrect but I think 'most' or 'almost every' is pretty accurate.
Yes, but with mine, I wrote it, I know exactly what it does, I can change it if I don't like, it and it's 1/20th the framework code such that it's also easier for *others* to read/debug/change/smile. Win win win win. I thought I made that clear. I don't like to repeat myself, but it didn't sink in the first time for unknown reasons. 
Yeah they are called snippets Both VS IDE and VS Code allow custom snippets If you are not getting them, then there is probably some extensions that you can install to get them, or if you really want you could make your own snippets 
&gt;I wouldn't blame the cost of an IDE.....he non-cross platform support; the vendor lock-in to a company with a shady past; the lack of traditional tooling (read: command-line); the lack of library options where other languages would have dozens of open source options... Yeah its a little of a lot of stuff like that which went with MS but we are talking about newbies. So in one corner you had PHP and python you could get started for free building anything you want or in the other corner closing in on a thousand dollars. Lets not forget the whole ecosystem followed that ecosystem. Plugins, components. Free was a word you seldom heard for ANYTHING in .net world. C# I have always loved. The MS ecosystem not that much. 
Its been amazing watching Azure grow
Lol. It’s not sinking in cause it’s bullshit built on top of bullshit. In fact, it’s the reason Microsoft moved on to a different pattern. Just like winforms and wpf. Winforms is still there if you refuse to learn wpf, but it’s never getting any meaningful updates, just like webforms. Anyway, I’m out of this conversation, nothing constructive is going to come of it. 
Also went form Microsoft Virtual Academy to MS Docs, has everything I am getting as much as I can for free and learning. [https://docs.microsoft.com/en-us/](https://docs.microsoft.com/en-us/)
[https://docs.microsoft.com/en-us/](https://docs.microsoft.com/en-us/)
Projection. Microsoft hopped on the Ruby-on-Rails fad bandwagon by (poorly) cloning it and calling it MVC. If their market moves to X, they clone X. They clone first and ask questions later to avoid losing market share.
Ctrl + Alt + E Uncheck CLR Exceptions (2nd from the top)
Gréât ! Thanks !
&gt; all my .com bubble friends laughed at me for going with ASP Classic. 20+ years later, here I am... Ill never forget a friend of mine using Cold Fusion telling me I would be wasting my talent on some "fad" language made by microsoft. To be fair to your friends, actually *both* ASP Classic and ColdFusion are essentially dead. You both "lost". ASP.net is quite different from ASP classic. &amp;#x200B;
I know this is an old comment, but which extensions do you use?
My experience is that dynamic languages don't produce as solid code and are a lot harder to read. They're good for small projects, but more than 4 people and a quarter-million lines of code and productivity drops.
Thanks for the feedback - what approach did you guys end up taking in the end after moving away from specflow? What tools did your test team use instead or did you just let the devs author all of the tests?
IMO you don't have to force yourself to learn MVC right off the bat. Learn how to write a plain HTML+JS page and have it make AJAX calls to A WebAPI. Familiarizing yourself with Controllers for API use is a huge first step, well before trying to fully adapt to MVC.
They decided to move away from it just as I was leaving the orgabisation, but I believe they wanted to just use NUnit tests instead 🤷🏻‍♂️. We were finding that SpecFlow was a mess for the fact that it wasn't good at being indempotent. It required a lot of set up and shared state that would often get all screwed up when tests could run out of order. It required a lot of C# to get going properly, and became a mess when you get to the point of hundreds of similar, but different, tests when written by several people. This could all have just been bad set up, planning, and a lack of knowledge in the team though. Your milage may vary. In my current job I am not sure what QA use for their integration and acceptance tests except that it's no longer going to be SpecFlow on new projects.
I'm not sure for you mean by " ban from Google EULA"
Having learned Java in school, then moved on to C# for my first (and current job), I really have to scratch my head at the "sexy language" thing. Python, Java? Really? I mean, I know it's all subjective, but I don't know anyone who knows C# and prefers any of those languages to it. Java is the type of language that gets C# features that existed 5 years ago, so companies start making things like Scala and Kotlin to compensate. Python is just ugly syntax wise (yeah I know, subjective, sue me).
In terms of books sorry cant help other than googling for you but subscribe to /r/sql /r/sqlserver and check out Brent Ozars website, he has some excellent resources there. Main thing is to stop thinking in dot net object oriented ways as employing the same style of code will lead to performance issues. For example you want to avoid loops (or cursors) in sql. 
Well.... it didn't work The site had "Access-Control-Allow-Origin" both in the web.config and in the html meta tag and still the user got errors. Either I didn't wrote it as it should or I don't know :(
I agree about Java, though I miss one thing from it. 'throws X' in functions. In Java you'll instantly know what a method can throw and that you should catch possible exception when using someone's API. In C3 most people don't even care enough to put possible Exceptions into a summary. But yeah, Java is far from sexy, or even good looking language. Kotlin is amazing though.
VS has a small bloat problem, aside from that is it probably the best all-around IDE &amp;#x200B; If I'm doing a plain-as-dirt website then I'll use something like VSCode or Atom, for everything else it's VS
I think the downvotes are because it isn't the truth anymore. The current VS Community Edition does not really feel gimped at all
I'm really heartened by how positive that post was. Going into it I was fully expecting a lot of people to bash C# or rather Microsoft in particular. I feel like just a few years ago there would have been a much different reaction. &amp;#x200B; dotnet and C# have been my goto since the early 2000's. I've learned many other languages and frameworks since then but I think C# will always be my comfort zone.
Ah yes, enforcement of exception declarations is something I do miss from Java. It forces you to think about them and handle them appropriately.
I once had to do some goofy shit with PowerShell and Analysis Services in order to orchestrate a red-blue database load balancing scenario. I don't remember having to download any packages from nuget to make it work, because I'm pretty sure the necessary assemblies were already there. If I can remember, I'll check when I get in to work today.
Yep, work with C# and yeah plenty jobs around my area in the UK and constantly getting messages from recruiters. I feel it has the best IDE and tools when I compare it to other coding languages + with .Net core not being stuck with windows is now a thing. 
Got it, thank you)
You can maybe take a look at this project as an example on how to bundle your files. It uses Vue, but you can bundle what ever you want in the webpack.config.js GitHub: [https://github.com/danijelh/aspnetcore-vue-typescript-template](https://github.com/danijelh/aspnetcore-vue-typescript-template)
&gt;nowadays yea though Code/VS have different use cases.. with VS community edition being pretty good to start for someone wanting to plunge. I'm talking prior where there was either express which was terribly gimped or you had to buy professional / enterprise. A non gimped visual studio was expensive and a gate to the .NET world (in addition to a server for IIS) if you were a small shop / hobbyist trying to do anything serious. i misspoke on this comment and later on mentioned i meant Express. Community is great, had they released it like that 10 years ago I think there would've been more .Net developers. 
Section 5,5.1,L of the YouTube Terms of Service states the following: &gt;\[Y\]ou agree not to access Content for any reason other than your personal, non-commercial use solely as intended through and permitted by the normal functionality of the Service, and solely for Streaming. "Streaming" means a contemporaneous digital transmission of the material by YouTube via the Internet to a user operated Internet enabled device in such a manner that the data is intended for real-time viewing and not intended to be downloaded (either permanently or temporarily), copied, stored, or redistributed by the user. This Library can be used to break this clause in the Terms of Service and commit digital piracy, so Google might go after it. Be careful I guess is what we're trying to say.
Hi, it's difficult to know exactly what would work best for you but I remember moving from VB.NET to C#.NET and it was fairly straightforward. Moving in this direction has the advantage that nearly all the examples/tutorials etc. you'll find online are written using C# so finding answers to your questions gets easier. As for WebForms to MVC, the biggest difference is that WebForms has its own, very specific abstractions, which hide the standard moving parts of a web application (primarily HTML, CSS and web requests e.g. GETS/POSTS). MVC brings those a little closer, putting you in control of the HTML, CSS etc. I wonder if your best bet might be to spin up a new MVC C# project and set yourself the task of creating those first few simple features. Even just starting with showing some information on the screen, perhaps using hard-coded data as a starting point. public class CustomerSummaryController : Controller { public IActionResult Get(){ var summaryViewModel = new CustomerSummary { FirstName = "Bob", LastName = "Smith", Age = 21 }; return View(summaryViewModel); } } This way you can start to get a feel for showing and handling data, without getting bogged down (immediately) in all the other "stuff" that comes along for the ride (like EF Core etc.) (Incidentally, it's generally a good idea to move code like that out of the controller, but starting here will get you going and leaves the door open to refactoring this code somewhere else once you've got something up and running). I suspect, once you get a few features under your belt you'll start to get a sense of what else you need to learn and where the gaps in your knowledge/understanding might be, which will help you decide if you're on the right path. In case it helps, I wrote about [moving from WebForms to MVC here](https://jonhilton.net/from-webforms-to-mvc/) and also offered some [practical tips for getting started with MVC here](https://jonhilton.net/2018/01/11/8-practical-tips-for-learning-asp.net-core-mvc/).
Learned a bit of python but only after starting to learn C# and .NET do I feel actually comfortable with saying I know how to developer software (at a very basic level). Now might be starting an internship using C# for cyber with PowerShell. Yay for C# jump starting my dev career!
Something about using only their prepared methods to access the data on the site. I assume so they can cross reference who is doing it in their database. 
When you see what I had to do to get Kestrel working with this, you'll place it squarely in advanced.
Yes, that's correct. The library exposes the same "normal" functionality and allows "streaming". It essentially simulates the same workflow as when the user is playing a YouTube video in a browser, but without the actual browser. In the end, it comes down to what the end users decide to do with this library and wether it's malicious or not.
&gt; You have to battle a giant pile of persnickety nested types to change anything. If that’s true, then the codebase is badly designed. If single responsibility and dependency inversion have been properly implemented, then changes should be easy. 
So this is one of the reasons NOT to use full IIS with VS development but rather use IIS Express (IIS is optimised for perf not really for dev). Try deleting the temporary [ASP.NET](https://ASP.NET) Files [https://www.matteopozzani.com/visual-studio-cache-cleanup/](https://www.matteopozzani.com/visual-studio-cache-cleanup/) It's one of the odd abstractions in [ASP.NET](https://ASP.NET)...you're NOT really running the files in your Bin directory but rather a copy which exists in Temporary [ASP.NET](https://ASP.NET) files...
I didn't see you clear your temp files anywhere here. Go to a command prompt and type "set" look for the TEMP and TMP variables, go to their paths and delete everything you can. Some stuff will be in use so ignore those. Kill the w3wp processes first might help too. &amp;#x200B; It's just a first line suggestion. You can also use Process explorer (sysinternals, free from Microsoft) to see where it is trying to load the DLL from. That might give you a bit more information. &amp;#x200B; &amp;#x200B;
This means your source code does not match the version on the server. Since VS tries to not allow you change the source code while you are debugging, this usually means your local build does not match the one on the server. You can force things to line up. Build your project, usually you want a Debug build. Then manually copy the files from your bin\Debug to your server and override the ones there. It's particularly important to include the PDB snice this includes all the debugging information. You'll probably need to stop the Web Site in IIS to replace the files, or momentarily kill the w3wp.exe instance (it will come back with a web request though so don't reload the page until you copy the files over). Once you've gotten that version up there everything should be in sync and remote debugging should work.
SQL as a language is pretty similar across all the *SQL* databases. So you're probably good. I usually just use Entity Framework Core which doesn't require SQL know-how unless you need to start optimizing or otherwise find yourself with a need to go beyond using LINQ for queries.
I haven't seen dependency inversion resolve that, only create more interface wiring busy-work. Some may say, "then you are probably doing it wrong." That could be; I won't rule it out. It was easy to refactor in dynamic languages, but is some kind of 3D chess in type-heavy languages that I haven't cracked yet, and Spock left our company.
But given a good dynamic stack, you don't *need* four people. One is very productive in a well-tuned dynamic stack. It's as if one has to add more checks and balances via strong typing because more people are needed on the team because strong typing made them unproductive: a slippery slope. They make you need more people, and then you need more checks and balances in the stack to handle more people, making you need yet more people. Paul Graham has made a similar suggestion about anti-productivity herding mechanisms somewhere. I'll see if I can find the quote. Maybe it's a matter of personality. I was more productive and happier with dynamic languages and stacks.
&gt; a quarter-million lines of code Much, much sooner if your team isn't very highly disciplined. And yeah, like you said, the more people, the more likely you have someone that isn't.
Non nullable reference types are in C# 8.0. 
This link says: &gt; You could also need to cleanup your user's temp folder[\[1:1\]](https://www.matteopozzani.com/visual-studio-cache-cleanup/#fn1). it is usually located under &gt; &gt;%USERPROFILE%\\AppData\\Local\\Temp &amp;#x200B; By "cleanup" does he mean delete everything in this folder?
Isn't it only free for the first year?
Sorry, but that's silly and suicidal. Silly because large development projects need a lot of people, regardless of the language, and the more people you have the more specific the module definitions need to be. And it's suicidal because your approach makes every person critical, and if one person leaves and takes their knowledge with them the whole project can collapse. 
Gotta be honest, I'm very skeptical of anyone who suggests that four developers on a project is too many. I thought we were past that lone wolf rockstar junk.
[removed]
Thats why it was written in past tense (and thus deserved no downvotes). Part of the discussion is about o why C# and asp.net is not more popular. History of cost of tools and hosting is definitely a part of that
We used to call projects like that throwaway code. Good to demonstrate principles and find design problems, but you know you're going to take the knowledge and not the code when you start for real
JavaScript.
I understand where you’re coming from and I agree: a dynamic language is super-easy to refactor compared to a codebase in a static language that hasn’t been carefully designed for maintainability. It does take a lot of experience and discipline. At one job I had to deal with both a terrible codebase and a nice one, and yes, I’d much rather the terrible one had been written in Python. I do understand (from many experiences) that sometimes you’re just saddled with a bad codebase. Happens to us all. Sorry if I came off as argumentative. 
A coworker sent me these a few months ago as we are transitioning into a TDD workflow. Definitely not a deep dive, but a good primer on the material and I'm sure the author has much more available. [https://www.youtube.com/watch?v=ub3P8c87cwk](https://www.youtube.com/watch?v=ub3P8c87cwk) [https://www.youtube.com/watch?v=DwbYxP-etMY](https://www.youtube.com/watch?v=DwbYxP-etMY)
Too much power can indeed lead to too much chaos. Static frameworks being harder to customize/change means the damage done by riff-raff is limited, but it can also stifle good stack managers. As someone once pointed out, "They don't give nukes to foot soldiers".
Can you post code from your View/ViewModel?
Yes; in general any 'Temp' file is (for a users point of view) idempotent...VS SHOULD recreate temp files on each recompile but some files can be 'stuck' with a lock from another process (IIS OR even your virus scanner can cause issues) so cannot be overwritten. SO they don't match your source code in that case. I think it's improved in 2017 (2019 RC3 has it's own problems).
IMO, refactoring is easier in static languages, because the compiler has your back. And the language service makes automated refactoring a lot easier, so there are usually tools to do a proper rename/move/extract instead of search+replace+hope your test coverage is good enough.
Coming from a few years as functional analyst, I've "just" begun my trainings to become a C# developper. It will be hard, it will be long but in a few years, I know I've taken the right path (that and a few more english courses...). This motivates me ! Let's hope I don't make a wrong career turn :D &amp;#x200B;
I always recommend The Art of Unit Testing by Roy Osherove. It doesn't use xUnit, but all those frameworks are the same.
Had a look that's more machine learning. I'm more thinking about pure stats 
I'm currently using this combination for a project. In my opinion, trying to combine the 2 into the same project is just asking for a world of headaches. When I was starting out I was using the "official" Vue.js/.NET Core template from Microsoft, it was incredibly complicated and even the smallest tweaks or package updates became days of troubleshooting and modifying .csproj and webpack to fix breaking changes. Eventually I got tired of it and decided to split them both into their own separate projects and most of my headaches went away. I am now able to use the [Vue CLI](https://cli.vuejs.org/) to manage my Babel config (in the time it took for me to switch, WebPack was already being replaced by Babel?!) and it leaves my .NET .csproj files much simpler without having to manage the build pipeline for Vue.
What kind of conversation are you looking for?
codingblocks.slack.com
As a current enterprise Java developer, reading this only made me want to break into the .NET world even more. I’m relatively fresh out of college, but spend most of my free time writing projects with C# and the .NET ecosystem, but not because I feel the pressure to “always be building something” that can be pretty rampant in our industry in certain areas. I genuinely love the language and the ecosystem and if I’m being honest, it’s just plain gosh darn good ole fun to build with. It truly is a passion hobby now. I kind of fell into this Java job as my first gig, but I know I’ll always be a C#/.NET dude deep down. I feel like an imposter because a lot of my coworkers love to shit on Microsoft and are set in their 90s JEE/Spring ways and refuse to learn differing paradigms. I’m counting down the days until I can finally get the experience on my resume that’ll get me past the HR filters so I can finally land a .NET job. 
&gt;Build your project, usually you want a Debug build. &gt; &gt;Then manually copy the files from your bin\\Debug to your server and override the ones there. It's particularly important to include the PDB snice this includes all the debugging information. &amp;#x200B; My server is my local development machine. The directory for the application in IIS is pointed at my development code. My dev code and my ISS application code are one and the same. 
Bit of a rant, but I just flicked through and by chance stumbled across a variation of my favourite bad TDD example. If you had this method: public int Multiply(int a, int b) { return a * b; } How would you unit test it? So going around the room you'd get answers like "does it handle int.MaxValue?" and "What happens if you divide by zero?" To which the answer is always. "Why is this even a method?". It's a trick question, but extrapolates to more complex cases. Writing tests is as hard if not harder than writing the code it tests. Don't be disheartened by that, it's an underestimated complexity of our craftsmanship. 
I agree; just create a vanilla .NET Core API project in one folder (`api` for instance) and whatever frontend framework you want in another (i like `web`), or you can even split the code into two separate repos if you want. The only disadvantage is that everything doesn't "just work" when you debug the back end but this tradeoff is 1000x worth avoiding the constant headache that comes with an integrated solution. The same goes for React and Angular also, just keep everything separate unless your needs can't be met by a single SPA and/or you want or need MVC for some reason.
&gt;Writing tests is as hard if not harder than writing the code it tests. Don't be disheartened by that, it's an underestimated complexity of our craftsmanship. That sure is true. I'm still very green with this and I have already started changing my approach to method writing and refactoring in order to be more testable, just because there was no clear way to test it as it was.
&gt; [https://support.solarwinds.com/Success\_Center/Orion\_Platform/Knowledgebase\_Articles/Clear\_Net\_cache\_manually](https://support.solarwinds.com/Success_Center/Orion_Platform/Knowledgebase_Articles/Clear_Net_cache_manually) This link had instructions for deleting Temporary [ASP.Net](https://ASP.Net) files: * C:\\Windows\\Microsoft.NET\\Framework\\v2.0.50727\\Temporary ASP.NET Files\\root. * C:\\Windows\\Microsoft.NET\\Framework\\v4.0.30319\\Temporary ASP.NET Files\\root. * C:\\Windows\\Microsoft.NET\\Framework64\\v4.0.30319\\Temporary ASP.NET Files\\root. * etc. I followed the instructions there, but no success. Still getting hollow breakpoints. &amp;#x200B; &gt; [https://www.matteopozzani.com/visual-studio-cache-cleanup](https://www.matteopozzani.com/visual-studio-cache-cleanup/) This link had instructions for deleting temporary files in the user appdata folder. I completed these instructions as well, but still no luck. Breakpoints are still hollow. &amp;#x200B;
&gt; Go to a command prompt and type "set" look for the TEMP and TMP variables, go to their paths and delete everything you can. Some stuff will be in use so ignore those. Kill the w3wp processes first might help too. &amp;#x200B; This is essentially the same suggestion that was sugggested in u/scottgal's response, via this link: &gt; [https://www.matteopozzani.com/visual-studio-cache-cleanup/](https://www.matteopozzani.com/visual-studio-cache-cleanup/) I tried this, but it didn't solve the issue. :( &amp;#x200B; &amp;#x200B;
Impossible to help accurately with the lack of detail in your post. Posting some code would help. To me it sounds like you'd be able to use a linq query or some derivative of this. YourCollection.Select(i =&gt; i.Column4).ToList();
So annoying question...are you sure you're compiling in Debug mode for everything? Solution -&gt; Properties -&gt; Configuration Properties They all need to be 'Debug' and 'Build' just having 'Debug' in the drop down isn't enough. If you've deleted temp files are you sure everything is being recompiled each time (look at the file dates)? The ';out of sync' means that the *.pdb files don't match up to the symbols in the compiled assembly. Check your PDB and dlls are of the same *date*. Look in your bin directory and see your assemblies and Pdb files have the same timestamp. Also ensure that your references haven't messed up. Aliases should be 'Global' and Copy Local should be true. 
Have a look at SysInternals Process explorer too. It's free from Microsoft. You can apply filters so you're not spammed with a billion events, and it might show you where the file is being looked at. I didn't see that in /u/scottgal's post, so reiterating in case it's missed :) 
I’m going to stick with what others are saying here. It sounds like you have your vs version in “release” mode and your dev environment pointed towards your debut build There’s a drop down at the top of VS with your config in when you’re building, check it’s not set to release or that your iis isn’t pointed towards release and your vs is in debug
aspnetcore.slack.com
Is this something I would need an invite to join?
Helping your check your changes is nice, but that by itself doesn't give you more options for changes. You are still bound to lots of static interfaces/types that are not easy to rework. 
&gt;are you sure you're compiling in Debug mode for everything? Solution -&gt; Properties -&gt; Configuration Properties They all need to be 'Debug' and 'Build' I double-checked the solution configuration properties at your suggestion. All projects are set to 'Debug' configuration, and 'Build' is checked for all projects. I'll begin checking the .dll and .pdb dates and update when that's done.
There's the C# Discord: http://aka.ms/csharp-discord
I will agree that large projects will need a different structure/framework from small and medium ones. One size framework does *not* fit all. Use the right tool for the job. MVC is sometimes the wrong tool for a job.
Did you double check that your build configuration (Build-&gt;Configuration Manager) has the build checkbox checked for all your required projects? Also... maybe try "iisreset" from the command line to start/stop IIS. Just to confirm that it's a file open issue with IIS (I've been using IIS from VS for years and years and haven't had any problems with open files or needing to cleanup temp directories). Also... did you launch VS as "Administrator"? I'm pretty sure the answer must be yes because debugging IIS won't even start without it. Good luck!
Small doesn't mean "useless". Some apps don't need 80 tables to do a needed function of the business 
Thanks. Do I need an invite to join this.
Have you looked at matrix.org?
Haven’t been on it in a bit, but I think codingblocks slack had some rooms of that nature
What's wrong with the documentation? It's fairly well made.
https://aspnetcoreslack.herokuapp.com/
https://aspnetcoreslack.herokuapp.com/
It’s perfectly normal, I personally don’t even notice they are there anymore. We delete them through clean scripts and ignore them in .gitignore. 
If you want to keep your \`src\` tree clean, you can change the location of \`bin\` and \`obj\` to live outside your source. The corefx project, for example, sends generated files to an \`artifacts\` folder at the root of the repo. &amp;#x200B; Take a look at the \`BaseIntermediateOutputPath\` and \`BaseOutputPath\` msbuild properties, which control the locations of \`obj\` and \`bin\`, respectively [https://docs.microsoft.com/en-us/visualstudio/msbuild/common-msbuild-project-properties?view=vs-2017](https://docs.microsoft.com/en-us/visualstudio/msbuild/common-msbuild-project-properties?view=vs-2017)
If you don't mind me asking, why do you think Visual Studio is terrible? What about VS Code? I think Visual Studio is possibly one of the best IDEs I have come across. Plenty of third party extensions and reasonably configurable.
It's not a template as such but I developed a .NET Core Vue.js sample app which you can find here on GitHub: [https://github.com/cofoundry-cms/Cofoundry.Samples.SPASite](https://github.com/cofoundry-cms/Cofoundry.Samples.SPASite) It mostly just relies on the [VueCliMiddleware](https://github.com/EEParker/aspnetcore-vueclimiddleware) and keeps the Vue CLI project in a separate folder. Unfortunately there is [an issue](https://github.com/EEParker/aspnetcore-vueclimiddleware/issues/7) with running debugging with the VueCliMiddleware, it's fixed in the repo but not published to NuGet so I had to include the code for the project in the solution for now.
I would expose a RESTful API on the [ASP.net](https://ASP.net) site that the local service can query to receive its instructions and update its status.
You could use SignalR.
I've had this happen where the debugger attaches to the process but attempts to debug the wrong type of code. When you open the attach to process dialog make sure that the correct code type is selected. If it's set to automatic, try manually setting it to managed v4.0 etc...
&gt;When you open the attach to process dialog make sure that the correct code type is selected. If it's set to automatic, try manually setting it to managed v4.0 etc... I forgot to include this in the list of things I tried. I did indeed attempt this, but doing so removed the w3wp option from the list of processes to attach to, so it seems to be an invalid approach for me.
&gt;Also... maybe try "iisreset" from the command line to start/stop IIS. I was always doing it from the command line. I wasn't even aware that there was a way to do it through VS. &amp;#x200B; &gt; Did you double check that your build configuration (Build-&gt;Configuration Manager) has the build checkbox checked for all your required projects? Yes. &amp;#x200B;
Thats strange... I use exactly the same development approach. Here's what I do: Debug-&gt;Attach to process Select the process (or processes if there are multiple w3wp processes I want to debug) Then, I change the type if necessary. If all else fails, I would try creating a new application pool for the app and see if that helps... Also, make sure that you click show processes from all users and see if there are multiple w3wp processes
NServiceBus
When I attach to w3wp, then reopen the 'Attach to Process' dialog through the Debug menu, I can change the "Attach to" code type selection, but I don't see away to commit this change. The previously selected 'w3wp.exe' process is grayed out and the only way I can figure to commit this is to select a process and click the 'Attach' button.
I use Hangfire to run jobs on other machines. Is this what you need? [https://www.hangfire.io/](https://www.hangfire.io/)
you change it before you attach but after you have selected the process in the list. When you attach to w3wp what type of code is it trying to attach to?
Thanks. Yeah they're in my gitignore and everything, I just find it weird that they sit there amongst my source. Maybe it's because I'm using VSCode, not VS? I have a feeling VS might hide them, which would explain why it doesn't bother other people.
Something that implements the basic pandas stuff would be pretty cool. If you start an OS project please let me know, would be quite handy for a some of the stuff I do. 
try devops. its crazier. i cant take a piss without a recruiter sneaking in the other stall and going "Pssst... i have the job for you..."
No you can run a test site with the *.azure.com for free. The catch is it most likely in a production environment would not work if you exceed the limit. Still works perfect for what it is designed for and that is development or to play with and fuck around. Go over the docs there are step by step and it's totally free. Awesome platform to get stated and learn, when you get a paying customer charge them with a premium on what you pay.
Cool idea. Basically automates a Electron.NET build. 
Yeah sounds like you need HttpClient in the Winforms app to talk to a JSON API running in WebApi (or you can easily get it working using JsonResult in MVC too). You'd use the HttpClient to send a message to the MVC (or WebApi) Action which then causes something to happen.
Ok. I'm following you now. This generated odd results. After selecting the w3wp process, and then selecting 'Managed (v3.5, v3.0, v2.0) code' I was able to attach without losing the breakpoints- they stayed solid rather than becoming hollow. However, when I navigated to the piece of my application that uses the code where the breakpoints are set, nothing happens. The breakpoints don't get hit and I never get a yellow cursor for stepping through the code. Additionally, any new breakpoints that I add while in attached debug mode appear as hollow breakpoints with the message: "The breakpoint will not currently be hit. No symbols have been loaded for this document." So... progress, I think. But still not there.
No, please don't do this... if you want to build desktop app, build it natively.
Try selecting both 'Managed (v4.6, v4.5, v4.0) code' and 'Native code' That's what works for me. I'm by no means an expert in this area but I'm glad you're seeing progress!
or VS Code or Azure Data Studio? Electron isn't inherently bad, but just as any tool, it can be misused. 
Isn’t the slack desktop app built with electron?
I'm really confused as to why Reddit seems to have eaten my reply here. I can see your reply to me in my messages, but it's not visible in the thread.
You're looking for OAuth. Microsoft has a guide on it here: [https://docs.microsoft.com/en-us/aspnet/core/security/authentication/social/?view=aspnetcore-2.2](https://docs.microsoft.com/en-us/aspnet/core/security/authentication/social/?view=aspnetcore-2.2)
It's time to embrace HTML as the cross platform UI for .NET CORE. While this may not be the most resource efficient way to build a desktop app, it's certainly the most time efficient. A few different build switches and boom -- linux or macos support.
but what is the benefit to wrap web app in the exe? it still depends on many resources outside of your process or even computer...
Yep, you gotta pay me a lot more money to learn xamal.
To build electron style apps no?
Use the Process class to execute your command. Create a handler for OutputDataReceived and ErrorDataReceived. Append the text from the DataReceivedEventArgs.Data in your handler to a StringBuilder reference. There is more to setting up the Process class, study the Process class documentation. That is how I did it. It is a great thing to build and have in your source control for future projects too. An alternative is to learn what PowerShell is doing that you want (find the API's) and write the code yourself instead of invoking a PowerShell script. 
If WPF existed for linux/macos it'd hands down be the UI to know. However, it's clear MS's push with .net core is to regain ground lost in the backend. Front end just isn't the focus -- anything to get Azure usage is the focus. 
Lol
Lol you trashed my post on sql interview questions to study a while back.... guess what. I got the job by answering those exact questions.
I think thats OPs problem, that they feel like there is a problem with slack's desktop app
 [https://www.nuget.org/packages/Microsoft.PowerShell.5.ReferenceAssemblies/](https://www.nuget.org/packages/Microsoft.PowerShell.5.ReferenceAssemblies/)
HTML/CSS doesnt has any competition at all. I don't understand why Microsoft isn't pushing XAML to cross platform already, imo it's really long overdue. I wanted it 10 years ago when I first learned WPF and eventually stepped into Windows Phone 7 development. XAML is imo superior compared to the clunky and chaotic HTML/CSS mess. Kinda sad how it's all about HTML now while after 10 years I'm still praying for some sort of reliable cross platform C#/XAML solution. They should at least push XAML to webkit/web or something. The fact that it only runs on Windows is too much of a drawback... can't believe Microsoft isn't attempting to change that.
Thanks, this was my usual approach with .Net 4.7. I wasn't sure if there was anything slick with Core that was worth trying the integration.
Thanks, I'll give it a look. 
That's my usual approach, guess I'll stick with it.
Which is why they are beating everyone in just about all benchmarks. I love the amount of support .net core has received and how far it has come. .Net Core is beating nodesj at json serialization O.O
if its anything like the angular template, stay far away from it. 
I can second the docs. I’m a fresh C# .NET jr. dev, and the docs have been extremely helpful! 
if you're targeting some desktop features, and you lack resources to do it, then ok-ish, but if you're just bringing web into the container PWA is better solution and maybe even less effort to do it.
&gt; We did not want OS specific dependencies in our solution. Yeah but it's a *Windows* service. Of course it's going to be OS specific! I have done a couple of these background services running in ASP.NET Core pools using IHostedService now. It works pretty well, haven't really hit many snags.
VS does hide them in the Solution Explorer. You can do the same in VS Code but I guess it's not the default: http://donovanbrown.com/post/Hide-folders-in-Visual-Studio-Code-Explorer
VS hides it. It’s no different to node_modules folders etc. And deleting them is your fastest way of cleaning a project. I’m pretty sure there is a configuration to change the paths by the way, but I don’t think it’s recommended. 
I changed to using a Textbox which adapts to the row I have selected instead of using a Textbox next to each row. It's way simpler to implement. Thanks for your help tho
I changed my interface to solve the issue (see other comment) thank you tho!
In this case, there are no outside dependencies. The backend is an ASP.NET Core app, and it's included in the exe. It's a converter for a file format used in the German construction industry and written in C#. The desktop version doesn't make any outgoing network calls. I needed a quick way to get a desktop app with the same functionality as the website, and Electron made that really easy. 
cool. I was thinking your sample was oversimplified proof of concept for electron because in my experience clients tends to have more complex requirements. nonetheless, cool :)
Altho I changed my GUId your answer could still be helpful for others so heres the code. #.xaml: &lt;ListView Name="listviewSetting" Selected="listviewSetting_Selected" Grid.Column="0" Grid.Row="0" Width="Auto" Height="Auto"&gt; &lt;ListView.View&gt; &lt;GridView&gt; &lt;GridViewColumn&gt; &lt;GridViewColumn.Header&gt; &lt;GridViewColumnHeader Content="Name" Padding="5,0,0,0" Width="Auto" &gt;&lt;/GridViewColumnHeader&gt; &lt;/GridViewColumn.Header&gt; &lt;GridViewColumn.CellTemplate&gt; &lt;DataTemplate&gt; &lt;TextBlock Text="{Binding Path=Name}"&gt;&lt;/TextBlock&gt; &lt;/DataTemplate&gt; &lt;/GridViewColumn.CellTemplate&gt; &lt;/GridViewColumn&gt; &lt;GridViewColumn&gt; &lt;GridViewColumn.Header&gt; &lt;GridViewColumnHeader Content="Type" Padding="5,0,0,0" Width="Auto" &gt;&lt;/GridViewColumnHeader&gt; &lt;/GridViewColumn.Header&gt; &lt;GridViewColumn.CellTemplate&gt; &lt;DataTemplate&gt; &lt;TextBlock Text="{Binding Path=Type}"&gt;&lt;/TextBlock&gt; &lt;/DataTemplate&gt; &lt;/GridViewColumn.CellTemplate&gt; &lt;/GridViewColumn&gt; &lt;GridViewColumn&gt; &lt;GridViewColumn.Header&gt; &lt;GridViewColumnHeader Content="Default Value" Padding="5,0,0,0" Width="Auto" &gt;&lt;/GridViewColumnHeader&gt; &lt;/GridViewColumn.Header&gt; &lt;GridViewColumn.CellTemplate&gt; &lt;DataTemplate&gt; &lt;TextBlock Text="{Binding Path=DefaultValue}"&gt;&lt;/TextBlock&gt; &lt;/DataTemplate&gt; &lt;/GridViewColumn.CellTemplate&gt; &lt;/GridViewColumn&gt; &lt;GridViewColumn&gt; &lt;GridViewColumn.Header&gt; &lt;GridViewColumnHeader Content="My Value" Padding="5,0,0,0" Width="Auto" &gt;&lt;/GridViewColumnHeader&gt; &lt;/GridViewColumn.Header&gt; &lt;GridViewColumn.CellTemplate&gt; &lt;DataTemplate&gt; &lt;TextBox Width="120"&gt;&lt;/TextBox&gt; &lt;/DataTemplate&gt; &lt;/GridViewColumn.CellTemplate&gt; &lt;/GridViewColumn&gt; &lt;/GridView&gt; &lt;/ListView.View&gt; &lt;/ListView&gt; #.cs listviewSetting.ItemsSource = dirSettingTemplate.Values; #explanation 3 of the 4 columns are being filled with dirSettingTemplateValue Attributes (Name Type DefaultValue), the 4th column consists of Textboxes which have to be filled by the user. Once a button below the Grid is pressed, all values have to be read and connected to the Type Value of the according row. So at the end I have a list of Objects which have Type and Value. Sth like (fantasy code): List&lt;myObject&gt; list = new List&lt;myObject&gt;; foreach(row in listview) { list.Add(new myObject(TypeColumn.Value, MyValueColumn.Value)) }
The customer request was literaly just "can I run your website offline on my desktop without having to send my data over the wire", so it was super simple in this case:) On the desktop version, all I had to do was to replace a call to an external service with an internal implementation, since the web version is actually just an UI for a REST API. And some UI changes, of course.
I've seen that, but their guide shows how to set it with cookie authentication. I don't think it's gonna work if all my clients are native mobile apps or SPAs. Thats exactly my problem, almost every guide/tutorial I found deals with browser type clients and thus they work great with cookies. 
You're welcome
Whoa, that's awesome. Thanks for the idea. At that version it doens't even add any extra difficulty to use the lib. But it's not yet documented tho.
Well in fact I thought about the decision for "Rest"-prefixed methods. These names are a little cluttered yes, but I wanted to make them clearly distinct than their non-rest counterparts (from Httpclient). I'll surely take a look at your lib, thanks!
&gt;.Net Core is beating nodesj at json serialization And it's going to be faster, when System.Text.Json is finally complete, with pure UTF-8, allocation-less\* serialization &amp;#x200B; \*allocation-less: less uneccessery allocations due to usage of pure UTF-8 Bytes and efficient reuse of resources and more magic
Your post has been removed. Self promotion posts are not allowed.
Looks pretty cool. I've not really ever messed much that required something like this, apart from once using stuff from BLAS. Looking at your code however it seems quite a mixed bag (i guess the list of tags on github says it all). What were your own motivations for this? You using this somewhere else?
Congrats on getting it this far. And I love a lot of it. Some of it though I am confused a by. Why would I want to to do `Multiply(7m, 7m)` instead of `7m * 7m` ? As far as I can tell this ends up dynamically compiling an expression in `MultiplyImplementation&lt;T&gt;` It would seem to me that this is not going to perform well for your example of a physics engine. Have you done any performance testing?
It's people like you that give me imposter syndrome about being a software developer. Well done and thanks for contributing it to the open source community :)
The junior position will completely dependent on the company where you want to work. But my advice to you is: 1. Build up awareness of technology in the .net environment. When you have awareness, you will know what to google for. Spend time to become a good "googler", it will become your BBF 2. Understand basic concepts, inheritance, interfaces, client side vs server side, decoupling, design patterns etc. (dont try to memorize it, understand it at least) I seen to many people straight out of university that don't understand basic stuff But do understand - the industry (software) you picked, will always change. Make sure you stay up to date with the community. Do you want to be a full stack, front end, back end etc developer? Set goals and build awareness.
[posted 1 day ago.... Why would I use the Vector and Matrix in your framework over the .NET ones that support SIMD?](https://www.reddit.com/r/csharp/comments/b3calg/towel/eiylgu9/) 
If you only want to support one type with your code, then you don't need to use techniques like I am using. However, what my code let's you do is perform math on generic types. ComputePi, Least CommonMultiple, IsPrime, etc... All those functions only have 1 code, but they work on multiple types. :) And I have done quite a bit of performance testing yes. :) I still need to do more, but so far things are very fast considering the advantages.
I do still need to look into SIMD. :) And I plan too. But that is only one piece of the code. If it turns out that my vecots and matrices suck I would just remove them, but all the other topics are still useful. However, I think there are still gonna be benefits to my code vs SIMD at first glance. But I'll have to find out. Also... I'm kinda new to reddit so I didn't know how to link other posts. Thanks for linking that. :P
If I may, I would like to recommend my own (of course ) solution. Medium: [https://medium.com/@danijelhdev/multi-page-net-core-with-vue-js-typescript-vuex-vue-router-bulma-sass-and-webpack-4-efc7de83fea4](https://medium.com/@danijelhdev/multi-page-net-core-with-vue-js-typescript-vuex-vue-router-bulma-sass-and-webpack-4-efc7de83fea4) GitHub: [https://github.com/danijelh/aspnetcore-vue-typescript-template](https://github.com/danijelh/aspnetcore-vue-typescript-template) 
I'm using the code in a lot of stuff. :) It is a bit of a mixed bag yes, but it is pretty much a compilation of a ton of tricks or code that I could see almost any program using. Every program out there needs data structures, it is rare to see a program without it using dictionary. Well my omnitree (although it probably has room for further optimization) is a fairly fundamental data structure for multidimensional sorting. And nearly every program out there needs to do math. I've seen tons of code where people have to loop through IEnumerables and add all the items up. With my code you can do that with a single extension method and it will work for any numeric type. And most of the other stuff is similar in that I just think it could be useful in a broad sense.
Thanks. :) But I'm sure you are good too.
I did a quick test on floating point and it is pretty quick. 10000000 float \* float took about 18 ms standard and 208 ms with your library. So chances are you aren't going to notice in a lot of applications.
Exactly. That is why I wanted to start sharing the code. ;) I'm sure there is more potential outside of just mathematics.
But keep in mind... The first time you call it it is performing the compilation... So you want to disclude that from your speed tests. Call it once before you start timing it. Cause after the first call is the standard expected speed.
What I found interesting was I tried using a static field for the compiled expression so it doesn't compile every time. But it really didn't help. In fact it was probably slower.
I'd have to see your code... But I assume you are running into the issue where the compiler is compiling the code every time instead of allowing caching. If you share your code I could possibly tell you what is happening.
If you’re fine with going deep in books and formal learning then start by absorbing the latest edition of pro C# by troelsen. It’s amazing and covers pretty much all of C# and .net in a single book, after that you can specialize. It’s more than you need for a junior position by far
I've not done much with OAuth yet, so I'm not sure beyond that was else to do. Sorry!
&gt; I have a set of entities which contain my data and have quite a few links between each other (using virtual keyword for lazy loading). I have AutoMapper setup which maps the data entities towards DTOs This is a great recipe for a performance disaster.
I wasn't really running in to an issue, rather I wasn't sure if Compile() did some internal caching. It would seem it must as when I instead do this internal static class MultiplyImplementation&lt;T&gt; { private static Func&lt;T, T, T&gt; compiled; static MultiplyImplementation() { ParameterExpression A = Expression.Parameter(typeof(T)); ParameterExpression B = Expression.Parameter(typeof(T)); Expression BODY = Expression.Multiply(A, B); compiled = Expression.Lambda&lt;Func&lt;T, T, T&gt;&gt;(BODY, A, B).Compile(); } internal static Func&lt;T, T, T&gt; Function = (T a, T b) =&gt; { return compiled(a, b); }; } It is actually slower. (This is with an initial call before any timers)
Thanks, I'll take a look
&gt; Towel is a C# .Net Standard libary intended to add much needed functionality that is missing in C# as well as redesign some aspects to bring the language up to modern standards. Bold statement. Nice library, though. I may have dinner applications for it right now.
I will look into that once I get the chance. Here is another version I wrote several years ago if you were curious: https://www.codeproject.com/Articles/992340/Generic-Math-in-Csharp-Using-Runtime-Compilation It is still there in my they framework project.
No, no, it's cool man, thank you! 😊
Hopefully I live up to the statement. :D
Alright, and how would one setup this kind of situation? Trying to learn here mainly, as performance is indeed not good. To clarify, my database is mainly built up from entities like Company holding Users holding UserTypes etc.
btw you should do a nuget package, even if it's in preview :-)
I know how to code C#... Buy I actually haven't made a nuget package before. I probably need help to do it right. :D It looks easy on tutorials... But I didn't want to push a nuget and have people think it was release ready. :P
&gt; List.Where(predicate).Include(predicate).Select(new object { only select fields I really need)}; That's fine. I personally never use lazy loading.
As a general rule don't use lazy loading. Explicitly load what you need. Otherwise it's easy to get into an N+1 situation. 
Alright thank you! Just what I thought!
Alright thanks for the feedback!
\&gt; Make sure you stay up to date with the community. What are the best resources to do this? Do people follow specific tech news sites?
The good thing is you can set version suffix and it will be listed as prerelease so then at least it's clear that things could change. You'll probably get people trying it out more if you do have a nuget package. e.g. dotnet pack --version-suffix beta it's so much easier now with dotnet pack and meta data in .net core/standard csproj files than before.
Thanks man! :) I will try to do that sometime here. Putting your work on Reddit is nerve wracking enough. :P Idk why but a nuget is kinda scary too. But I'll grow a pair and push a package soon.
If I understand correctly you want to dynamically add the controls to a page then hook up to their event handlers? You should generally be adding dynamic controls to panels (just to make design easier as otherwise you have to worry more about size and position). This may help: [https://codereview.stackexchange.com/questions/143393/dynamically-adding-controls-to-a-form-in-a-winforms-project](https://codereview.stackexchange.com/questions/143393/dynamically-adding-controls-to-a-form-in-a-winforms-project) before you add it you can then 'hook into' the UserControls events... &amp;#x200B; &amp;#x200B;
I am looking for a similar open source solution where I can pass html string and generate a PDF. I have used ABCPDF before and works well other than licensing cost. Would like to get some suggestions here: &amp;#x200B; Can we pass css files to Puppetteer-Sharp? Any other open source solution people might be using?
Looks pretty cool! You should probably add some performance tests using BenchmarkDotNet to prevent performance regressions in-between releases.
I've actually never done speed testing using a framework. I always do speed testing on my own in a console app. Do you have any links you could share so I can figure out what speed testing frameworks are out there? :) I've just always been afraid to use frameworks cuz I don't want things like reflection over head offsetting the speed testing.
This is insane
Don’t forget to bring a towel!
The library I referenced: [https://github.com/dotnet/BenchmarkDotNet](https://github.com/dotnet/BenchmarkDotNet) It's used for the .net core code base and a lot of other frameworks.
As others have said don't rely on Lazy Loading for loading related entities. Deferring as much execution at the database will help tremendously with performance. While your doing that get your self a profiler so you can start measuring performance. This will help you identify what parts of your application have performance issues and will help you pinpoint where the bottleneck is. In cases where you are still running into performance issues with EF you could also look into Dapper if you are confident in your SQL skills that way you wouldn't lose the automatic mapping of your result sets to your entities that you're currently getting with EF. 
Follow dotnet core. [Microsoft documentation](https://docs.microsoft.com/en-us/) on really anything that interests you here. News channel on the startpage when you open Visual Studio.
Well, I went through it but in this case the OP had already predefined some drop down Control in the Designer file to which he could listen for events and then dynamically add more options. What I'm trying to achieve is to have a Dedicated Class which generates the control without having to define anything in the Designer.cs. Here's a link to the [repo](https://github.com/antoanyanev/ToDoList) if you want to check it out. It's still very messy and nothing is commented so just letting you know - the class that's generating the Controls is Login.cs. 
Great post! What are your thoughts on managed databases? If you were a single person working on an app, would you recommend them over installing your own on a VM?
Did you decide on a hosting company yet? I've mainly been looking into Heroku because I din't really want to manage anything, but DigitalOcean looks to be the best in terms of price and performance. Just need to spend some time on the admin side.
Using the designer can be hard when the number of controls start to grow. It isn't clear why the login page controls need to be separate. You may find it easier to add, position, show and hide controls grammatically in the Form.
That's amazing. It's the App Service hosting you are talking about right? https://azure.microsoft.com/en-us/pricing/details/app-service/windows/ Not the VM?
Yes it will be easier but a lot of things will be going on in the app itself so adding a few thousand lines of code in the main Form file is not an option.
Not yet, I've postponed it since I had some other stuff I wanted to do meanwhile :)
Yeah, it's pretty neat. I'm almost done with the Azure course.
When should lazy loading be used then? It seems like a great idea.
You can add `-anything` to the end of your version string (e.g., `0.1.0-pre1`, `1.0-beta4`, and your package will be considered “prerelease”, and won’t show up unless you check that box in the package manager (or whatever the equivalent is for PowerShell). 
There are a number of ways to do this but start off with the basics. Look into jQuery, Ajax and partial views. Once you have that working you can look at using libraries that specialize in in what you're looking for.
Would you suggest using view components over partial views?
:)
God damn dude that Library looks awesome! Thank you!
In a production level app, honestly, I can't think of a single reason. Its useful for throwaway tools and such though where you just don't care about performance. To be fair though, I live in a world at this point where the cost of the conventions EF uses writing queries makes it a performance concern and even Dapper we have to use the more explicit approaches to avoid the inherent SQL type casts that occur if you don't. Most people silently eat those costs without blinking.
Can you elaborate on the SQL type casts in Dapper? I haven't really used Dapper that much so I'm curious about potential pitfalls
Thanks. I'm pretty proud of it. :) Hopefully people can figure out how to properly use the code until I have time to make tutorials. The main thing to consider is that my "Stepper" is pretty much the same thing as an "IEnumerable". Good luck!
Definitely view component, since you need a db call to fetch the data.
Have you tried deleting everything under the /packages folder?
Thank you!
Can't agree more. I've seen a million euro project fail partially because of lazy loading completely trashing the database. This was in hibernate and Java,but the principles are the same. One innocent line of code can generate million of queries: model1.Collection1.Select(x =&gt; x.Model2.Collection2.Select(y =&gt; y.Model3)) And boom goes the database.
That's one that took me by surprise. Take for instance, a table with a Field of type VARCHAR(5). DECLARE @test NVARCHAR(MAX) = 'Test' SELECT Field FROM Table WHERE Field = @test In several cases, before SQL can actually do the comparison above, it actually has to convert @test to a VARCHAR(4) first before doing the comparison. You can see the difference in the IO counts on the query. Most people don't actually consider this, or even need to really. At large scales though, those conversions can add up. Now the next point is someone that really knows the SQL Engine will come in and say yeah, but if Field is actually an NVARCHAR and not a VARCHAR, you avoid the conversion... until you have to partition tables in storage. Suddenly, not just type, but length of the passed variable matters too for some reason. And its actually fairly significant. But again, not something most need to worry about. Now, when I do an EF query with .Where(x =&gt; x.Field == "Test") guess what EF sends to SQL? NVARCHAR(MAX) by default unless you specify it. Dapper sends NVARCHAR(4000) if I remember right. And how many of you actively attribute your models completely: [Column(TypeName = "VARCHAR")] [StringLength(4)] public string Field { get; set; } The upshots are kind of this: Properly attribute EF models / use the long verbose mappings. In Dapper use the fully defined parameters collection and define the type and length on your query parameters, dont rely on passing a dynamic. You can probably get away with it in most basic things, its just cost of doing business, but there are larger data situations where you actually have to know about the implications of that and account for it.
Include is completely pointless when you are projecting to DTO's. That's for when you are fetching your domain objects directly without mapping them to DTO's. WHen you are projecting to DTO's (and your DTO doesn't contain domain objects), then EF will do the necessary joins itself and no lazy loading will happen.
Yes I absolutely would recommend doing that. I've used Azure's managed SQL databases for a side project in the past and been very happy with them. Having said that, if you're running on a VM and your data access method is suitable (many reads, fewer writes), don't discount SQLite for smaller apps! 
[Make sure you use Microsoft Identity for authentication and account management, since this has built-in support for third party logins.](https://docs.microsoft.com/en-us/aspnet/core/security/authentication/social/?view=aspnetcore-2.2) 
[Use the official documentation.](https://docs.microsoft.com/en-us/aspnet/core/?view=aspnetcore-2.2). It's maintained by the open source community and fairly good. And avoid blogs, asp core is fairly and sill changing, meaning that older articles get outdated vast. 
It's very easy to get by without knowing what a query plan is or how to read query statistics for a long, long time. I'm guilty of it. But it eventually catches up to you if you have to work on something at scale, for sure. That said, if you never work on something at scale, those millions of IO operations you just caused might... work for a while. I feel like thats where most "tutorials" on ORMs leave people though. Here's just enough knowledge to get it to spit out SQL marginally better or worse than what you could write on your own, that is just as bad because you don't understand the underlying storage system or how to make this tool use it correctly.
I got that error message a few times as well. I cleaned the projects, cleaned the solution, saved, and then closed and restarted VS. 
Write a simple ASP.NET Core Web API site to receive your data via HTTP. On the WinForms side, I use RestSharp. It’s a lot easier than HttpClient and will do the JSON serialization for you. 
If you are selecting from a child entity with a navigation property before you resolve and iqueryable you do not need the include. Too many includes can lead to joining repeatedly and giving you multiple records where a lot of data is the same just to get a little bit of unique data. You can explicitly load the child data through the context afterwards and it can be faster than a single query depending on your object complexity. 
Great answer, thanks! IIRC EF Core scaffolding does properly add the length attributes, so seems like they might be covering this base which is good. Good to know for future reference though!
I agree the docs are simple, aren't filled with walls of text, and have lots of code examples. You will just want to pay attention to which version of .NET Core or the host setup they are for as many changes have happened in the last 2 years and many methods were renamed and better patterns introduced. 
Congrats. 
s/disclude/exclude 
:) thanks. Now... Just gotta show people how useful it is :D (easier said than done)
Back in the late 90s I would have said the same thing about "big iron". But instead of listening to other devs at that time who were making money hand over fist doing Y2K conversions on COBOL code, I'm glad I essentially started my career over and got into web dev. Today I would follow a similar path by moving away from server-centric web page delivery such as ASP.Net and focus on some of the more client-centered frameworks that have proliferated over the past decade. Like Angular, Vue, Ember, React, etc. IMO they're way more fun. 
Your job will determine the answer, but I'd say you are fine. Most of my .Net gigs used SqlServer, but I've also used Oracle and my last job had PostGreSQL. I've heard people talk about using MySql but it's far less common in .Net environments. Fortunately, in general, SQL is SQL and you just have to learn the environment. 
Alternatively, load the top 5 for all genres and show/hide based on which radio button is checked. May be a larger data load up front, but it is incredibly simple to code the ui for, which is a nice bonus for a start - you can optimize for performance later if needed. 
Make sure you have the latest version of Visual Studio 2017 v15.9+ installed. That might fix the error.
why don't you add a login dialog form? Visual Studio even has a template for that with the correct spacings and tabs and so on. You can select that when adding a form
starred! great job!
`Include()` is useless when you perform a projection.
Oh interesting, didn’t know that!
Interesting, learning a lot of useful stuff here, thanks!
Keep up the good work mate, really nice to see someone reaching out on Reddit to discuss the stuff they're building and not getting shouted at by the dev community - gives us all hope :) &amp;#x200B; Take a look at [myget.org](https://myget.org) if you want a playground for nuget before you make something public. It'll let you iterate on your idea in a private nuget repo and allow you to push it once you're happy.
I ended up having to go this route since the PowerShell assemblies didn't really give you the output I wanted. 
Ninject is simply more powerful. Unfortunately it's also more complex to wire up with ASP.Net _Core_ - But this process is already automatically taken care of by the code in Startup.cs and the init folder of Magic.
You could create a API endpoint that takes the genre as a parameter and returns the movies in JSON format. Then use Javascript Fetch to call the api and update the ui. 
No wont this break things? Where can I find the /packages folder?
I know I do I recently installed it. Its version 15.9.9 I also used repair on the installer and it didn't fix it. 
I tried repairing whole visual studio from the installer and it didn't fix it Also cleaned, saved and restarted like you said and the same issue
As I understand you're a begginer on web dev. I suggest not doing any complex logic in the view using Razor. Load the movies into website and try using Javascript only for that. No library is necessary for this.
Nope, nuget will restore missing packages. Check %HOME%\.nuget\packages Just make sure you actually delete everything. If some files are locked, just resboot your pc and try again. 
It's a nice idea but I've figured it out. What I did was to create an event handler with a callback. Then you can subscribe the button instance to this event. &amp;#x200B; &amp;#x200B;
Don't wanna be that guy, but is there a specific reason you've selected Windows Forms? The whole experience around WPF is much, much nicer and allows for a far better separation of concerns, is all :)
Well, I have no idea idea why I chose it but one thing's for sure now - I won't be using it again for such apps. I haven't tried WPF but now that you mentioned it, it's going to find a place on my list to checkout next time I want to build a GUI application. I was even looking into frameworks like Electron but I was already way too deep and didn't feel like rewriting most of the code base. Have you used it?
As a dotnet developer with 13 years in the game, I wouldn’t spend that much time with Windows Forms. Really consider getting into asp.net core, unless you really want to say on legacy projects.
Thanks for the level-headed reply dude, I wasn't sure whether or not my comment may have been interpreted as snarky, certainly wasn't the intention :) WinForms is kinda dead in the water, having been superseded by WPF. I don't think it's been formally deprecated due to its prevalence in the industry, but with first class support for WPF in .Net CORE I'd definitely give it a bash! I've used WPF in a couple of gigs for sure, and though i've moved away from .net in recent months due to client preference, it does hold a special place in my heart! One of the lovely things I like about WPF is how rapidly it renders, plus being able to enforce MVVM in a super lightweight manner is really lovely. If what you're after is cross-platform desktop, however; Electron is definitely your guy (and it's super quick to get going with, too!) There are some quite lovely out-of-the-box bindings for VueJS with Electron. It's super delicious.
You should probably focus on .NET Core and learn the basics of web development (HTML/CSS/HTTP) so that you can play with some front-end frameworks such as Angular, React, Vue, etc., as far as which marketable/useful skills to build solutions with, but you don't necessarily have to know all that to fill a junior role. You will need a solid understanding of how to write quality code with C#/.NET though. So the basic concepts of OOP and how to use SOLID priniciples will get you far. Nearly every interviewer will ask those types of questions since they are basic and are the proper foundation for writing well-designed code...for almost every language.
Thank you for your thorough reply. I've never enjoyed using HTML and CSS but I'll get there, I'll focus on C# (.NET Core) and JavaScript now. I suspect once I feel like it, picking up HTML and CSS again should be easy enough. 
WPF allows for winforms-based approach if that is what you're familiar with, but it doesn't trap you into that way of doing things - extending and completely changing UI controls is relatively "easy." There's a learning curve, but the difference is that anyone can make all buttons round, blink and spins with highlights when you mouse over them, and still be able to modify the details like background on per-button basis after the fact. Good luck doing that in winforms.
I don't have extensive knowledge by any means, but I've dabbled in lower level aspects of the framework. There's several aspects of implementing a language, including parsing and tokenizing the raw text input so that you have something structurally that you can begin to understand as code. I'd invite you to spend some time with Roslyn getting familiar with how it approaches the problem, and there might be some extensibility there that you can leverage so you don't have to roll everything yourself. Once you have that you need to turn the structured represenation of the code into MSIL instructions. For this you will need to dig into the System.Reflection.Emit namespace. This is actually a fairly straightforward namespace, but because you're building IL, it's a very different from normal programming. You need understand all of the [OpCodes](https://docs.microsoft.com/en-us/dotnet/api/system.reflection.emit.opcodes?view=netframework-4.7.2) and work with the stack in order to build the program/assembly/class/method/etc. This is hard enough when you're trying to do it directly, but you're going to need to do it based on some sort of dynamic input. The only book I can point you to is [this one](https://www.amazon.com/Expert-NET-Assembler-Serge-Lidin/dp/1484220242/) and there's not too much else published on the subject. Of course Microsoft has published all you need to know in the language specs, but that's not exactly light Sunday reading. I'd start [here](https://visualstudio.microsoft.com/license-terms/ecma-c-common-language-infrastructure-standards/) and [here](http://www.ecma-international.org/publications/standards/Ecma-335.htm). There are also several open source projects that either dynamically generate objects via System.Reflection.Emit, or modify MSIL for some purposes. The main one that comes to mind is[Mono.Cecil](https://github.com/jbevain/cecil), but several DI libraries do this too. I know [LightInject](https://github.com/seesharper/LightInject) does emit IL, but there might be better codebases to look at. If you haven't spent significant time looking at [ildasm](https://docs.microsoft.com/en-us/dotnet/framework/tools/ildasm-exe-il-disassembler), then I recommend you jump into that, as the output of that tool is what you'll need to be building. There's a decent amount of stuff out there for building IL, but it's not super extensive. There's a lot of trial and error, as it takes a good amount of knowledge to be able to stare at opcodes and know what's going on. That being said, it's a cool aspect of the .Net Framework, and you can get some pretty cool error messages when you're testing things.
Lexing/Parsing is already covered. Right now I have an adapter that compiles my experimental language to LLVM and I was interested in writing a CLR one.
If you want to dive deep, the .NET compiler, CLR, and class library are all open source and have documentation. https://github.com/dotnet
If you've already got LLVM byte code, then you might want to look at some other projects that convert to MSIL https://github.com/dotnet/llilc https://dotnetfoundation.org/blog/2015/04/14/announcing-llilc-llvm-for-dotnet https://github.com/soywiz/llvm-to-msil
The only difference between them now (VS 2019 has codelens into community as well) is the testing tools (e.g. Live unit testing, Code-coverage), and other non development related features that Pro and Enterprise has. Otherwise Community is actually the same with the SKUs, the only restriction you have on the Community version is that you're limited to using it if your dev team in the company is 5 or less. Anything higher should use Pro licenses.
CodeLens is coming on VS 2019 to community too though so there's literally no difference aside from the developer # per company (5 or lower if I recall) limit clause that community uses.
Why not use hangfire?
Oh rendering... that's where WinForms suck at the most for sure. It was only when I added a background image when I realized it. An then came transparent labels... It's not getting any better is it? Thank you very much for the suggestions and of course I would take your comment as a piece of suggestion. I'm not that experienced with programming, let alone GUI. I could always use some advice instead of banging my head in the wall needlessly.
I see, WPF seems to be the heir to WinForms and and it's supremacy is now evident to me. Next time I need to build a GUI I'll start off with it. I feel enlightened and a bit stupid because I didn't quite do my research. Thanks for leaving a comment!
Hit me up mate whenever you like, more than happy to either code review or lend a patient ear or chat through whatever you might be struggling with! If you wanna target windows, wpf is ace dude. Opengl rendered too :)
Appreciate it man! I'll keep this in mind.
I'd redommend Scott Hanselman, he is a Microsoft employee but has a private blog an makes a podcast every week. He also appears on shows like channel9 Most other well known programmers (like e.g. john skeet) are active on stack overflow or write books. 
Hi @Shrodes, thanks for letting me know that we do not need to setup RID for a windows service. From what I read and sample I went through at that time my understanding was that we would need one, at least for .NET Core 2.1 . But, I could be wrong. However, I would probably add that I'm personally not a great fan of a windows service. In our case we did not have any windows specific dependency, why then use a "Windows" service? As a matter of fact, just by choosing a web app ([ASP.NET](https://ASP.NET) Core) instead of a Console/ Windows application we got my things out of the box, such as health endpoints. In addition to this, we wrapped RabbitMQ implementation with a popular library [Rebus](https://disq.us/url?url=https%3A%2F%2Fgithub.com%2Frebus-org%2FRebus.RabbitMq%3Ah-Uf5D5fjnZ0E1JzAca2gDNDvok&amp;cuid=5349337). Rebus provides a great abstraction over RabbitMQ and takes away all the complexities. See the sample here: [https://github.com/rebus-org/Rebus.ServiceProvider/tree/master/Sample.WebApp](https://github.com/rebus-org/Rebus.ServiceProvider/tree/master/Sample.WebApp) This effectively means we do not need with implement \`IHostedService\` ourselves. The other advantage of using Rebus for us was that it makes the implementation very generic and in future we can easily migrate our solution to any other service provider when we move to cloud.
You mean someone who follows you on Twitter then unfollows after you follow them back?
Checkout ... &amp;#x200B; [https://github.com/matthewblott/simple\_aspnet\_auth](https://github.com/matthewblott/simple_aspnet_auth)
I got so fed up with the complexity of something that should be quite simple I wrote this ... [https://github.com/matthewblott/simple\_aspnet\_auth](https://github.com/matthewblott/simple_aspnet_auth) Tutorials here ... [https://coderscoffeehouse.com/tech/2018/07/30/simple-aspnet-auth-update.html](https://coderscoffeehouse.com/tech/2018/07/30/simple-aspnet-auth-update.html) [https://coderscoffeehouse.com/tech/2017/09/05/simple-aspnet-auth.html](https://coderscoffeehouse.com/tech/2017/09/05/simple-aspnet-auth.html)
Immo Landwerth on the .net team started a video series on writing a language for the CLR. First part is here: https://youtu.be/wgHIkdUQbp0 Its quite accessible
Check out Immo Landwerth’s .NET Live Coding - Let’s build a compiler videos. Here’s the first episode: https://youtu.be/wgHIkdUQbp0
Good question! We had some discussion around whether or not use Hangfire. For starters, using Hangfire does not solve my problem of hosting. We would still have similar issues while hosting it on IIS (to keep it ALWAYS ON). Second, Hangfire does not have any official support for RabbitMQ. But third and the most important reason for me, personally, I would question why you need Hangfire? What problem does it solve? My use case was very simple, I just needed a message broker to process my messages. We did not really need, \*yet another dashboard\*. I try to keep away from adding variables for no reason. If there was use case, I would but not for what we were building.
Wes Doyle puts out great tutorial videos on YouTube 
https://github.com/dodyg/practical-aspnetcore
Mosh Hamedani
Tim Corey has excellent content on YouTube, and his own personal web page, blog, etc. pumped full of great knowledge 
Seconded 
KudVenkat on YouTube!
I can recommend Tim too. He explains everything he does and teaches you about the tought process of developing something with c#/dotnet 
Rick strolsberg
for C# specifically i can’t recommand the old eric’s lipper blog from when he was ar microsoft, it’s a goldmine : https://blogs.msdn.microsoft.com/ericlippert/ Sadly it stops in 2012 when he left microsoft but it’s a great read with a lot of insight on why C# was designed the way it was and it clears up a lot of myths/misconceptions
... Oddly specific. 
Kudvenkat on youtube.
K Scott Allen / odetocode.com - best . net pkuralsight videos for sure. Great teacher.
Thank you so much! It was very helpful..
this and Anders Hejlsberg
Thanks everyone. &amp;#x200B; Theres some great recommendation.
Mosh Hamedani hands down.
Bummed i had to scroll this far down to see Scott mentioned. He's got a ton of content on his blog and pluralsight
Hello! I've spent some time building some small compilers that emit CIL assemblies. I think the simplest way to learn how it works is using the System.Reflection.Emit API (or its cross-platform counterpart Mono.Cecil), and by compiling small programs in C# or VB and inspecting the resulting assembly with tools like IL Dasm or any other similar CIL disassemblers. About the CLR, you can find the whole ECMA-335 Standard with information of how it works and how it interact with the Type System.
The VM inner workings can be found in the ECMA-335 Standard. Some basic information about the type system I can give you is (everything is on the standard anyways): - The CLR has its own primitives in IL, int32, int64, float32, float64, uint8, etc. that are mapped to the CoreLib types System.Int32, System.Int64, etc. - Types are on paper all equal, but have special traits depending on from which type they derive: For instance, types that derive from System.ValueType are considered Value Types (duh) and are copied everytime they get pass around, they are allocated on the stack and are freed with the stack frame (aka when they leave scope), and have an implicit constructor created by the CLR that initialises every member with its default value. C# structs are compiled down like this Types that derive from System.Enum are, duh, enums, they're value types (again, copied when passed around, allocated on the stack, freed on scope exit), but can only contain literals (constants) of any CLR primitive type, and a special "value__" field. All fields must be of the same type. The rest of the types are reference types, meaning they're not copied when passed, instead you pass the reference (a pointer) to the value on the heap, and speaking of that, they are allocated on the heap and are elegible for Garbage Collection. Arrays are not a type, they're created using an IL instruction and are allocated on the heap. 
Is he doing anything non-TypeScript these days?
Tim Corey and Jeff Fritz are the first people that come to mind to me, because they both put out a ton of great practical content. &amp;#x200B; As for podcasts, there are a lot of great ones: MS Dev Show, .Net Core Podcast, the new .Net Bytes podcast, and of course I gotta throw Coding Blocks in there. ;)
Awesome, thanks!
Thanks!
So many names for me to look up.
Angelsix, he has some of the best in-depth content on YouTube.
[Tutorial Link](https://youtu.be/B3DfVHGuvoY) 
I don't believe he's been involved in .net since 4.5 (async/await). 
Any talk by 'Uncle Bob'
Andrew Lock also has a lot of great content: https://andrewlock.net
Yep. Goldmine is no overstatement. 
But more specifically, odd...
&gt;https://leastprivilege.com/2019/01/14/automatic-oauth-2-0-token-management-in-asp-net-core/ No problem :-)
:)
you just add an openid auth provider and set the authority. look at IdentityServer4 docs
Eric Lippert does still have a very active blog at [https://ericlippert.com/](https://ericlippert.com/). A lot of the stuff he's blogging about these days is interesting, but kind of obscure and/or over my head, though.
Do you mean Rick Strahl? - [https://weblog.west-wind.com/](https://weblog.west-wind.com/) I've learned *so much* from his blog.
Can you please clarify whether those "MVC API" and "MVC WebApp" are .NET Core?
If both of them are core apps then just put all your shared code in a NetStandard project. If one is a Net Framework project then the same applies but you might have to tweak some of the binding redirects in the framework app. 
I haven’t read it recently but when he started his new blog it was hardly ever about C# but always about the new company he was at, nothing wrong with that but didn’t feel relevant in this thread
The identityserver templates are not installed by default. You have to manually install them with dotnet new -i identityserver4.templates.
is this the best use case for identityServer considering it's just one web api 
Uncle Bob gives some great talks. Just wish the videos on his site weren’t so expensive.
When you setup your deployment, you deploy one site instead of two. It also makes authentication easier if it's all handled within one site.
Yep. And as your project grows, you may find a need to separate them (aka: you want to have a stand alone back end service that can fulfill multiple clients, you want to generate consumable API libraries, you want smaller deployments, you want to reduce change risk, you want to enforce stricter code standards, etc.). But if you don't know why separating them will help with your project yet, keep it simple.
Came here to say exactly this. If you core code sits on the same web server and hands up the react static, you are covered with CORS nonsense and deployment/pipeline stuff is way easier. This is how I handle all of my apps in our corporate environment.
What is the downside? If you're not building a service oriented product with multiple clients then you're building a "classic web application". If not React, in it's place there would be jQuery or vanilla js. &amp;#x200B; There's nothing wrong with this other than choosing React over Vue.
the benefit is that it’s one web server to deploy and make sure it up. the con is your “app” is less usable by api alone as the api becomes quickly tightly coupled to the app. i would make the api separate. ui related stuff should be put in the backend for the UI. this is called “backend for frontend”.
&gt; CORS nonsense This is literally as easy as adding `app.UseCors("AllowAll")` to your startup. There is no concern with security unless you're relying on CORS to control access, in which case you've got bigger problems. &gt; deployment/pipeline stuff is way easier Can you describe your pipeline? Are you deploying to IIS?
Keeping them together makes it easier to get started but will cause operational headaches down the road. You'll have to decide whether that's a concern, and if you aren't sure you can always separate them later. JavaScript tooling changes at a pretty rapid pace and the .NET tooling to shoehorn JS into a .NET project will likely break due to this, causing you to either be forced to troubleshoot or accept it and be locked in to deprecated versions of things. If you're doing CI/CD, ease of deployment is a non issue as that will be automated. The additional effort to deploy two artifacts instead of one is at most a dozen lines of yaml on any of the popular CI tools.
Does it really matter that the backend is coupled to the frontend if it’s just a one to one relationship? I only think separating the UI and backend should be used if you have a real and immediate reason for doing so.
keeping them separate is good architecture and cleaner. sure you may not have a need now. but once you do you’re find you’ve dug your own grave and it’s a hell lot of work to clean up. with separate apis/microservices it’s trivial to scale out and reuse them. it’s no different then creating creating separate libraries that are reusable. or using abstractions. or using cross cutting patterns like CQRS. or etc... sure it’s *slightly* more work but it’s way less work than refactoring everything later. that’s the whole point of following a clean modern architecture in the first place.
&gt;There is no concern with security unless you're relying on CORS to control access, in which case you've got bigger problems. Is cors and oauth enough? What kind of things should I worry about? 
I currently actively develop a system with a separated UI and API and I can tell you that it’s more pain than it’s worth. If I’m moving fast and trying to build out functionality, I need to time my UI releases so that they are after the API releases if there is any functionality added. Code reviews are now fragmented as they’re across two repos and harder to review properly. I need to deploy twice as opposed to just once. Testing locally is slightly more difficult. You’re also working from the assumption that you can’t just split out an API from the UI. If you have the proper environment, it’s really not a big deal. I’d rather just develop the whole thing in one project and if we have a *compelling* reason to split them up, then only do it at that point and time.
There's no reason you can't have a back end in .NET and a front end in JS in the same repo and with a unified CI/CD pipeline. It sounds like your gripes have a lot more to do with this than with the segregation of the code.
I put my api and front end in the same git repo for this reason (it's just me, no team of people.)
If you want to be risk averse, implement `UseCors()` with the specific domain from which your UI requests will originate. Outside of that, as long as your controllers/controller methods are authenticated you should be fine from a .NET perspective, assuming you haven't rolled your own authentication or something.
I’ve nothing to offer but empathy; nugget and package management is the most frequent cause of me wanting to drop my laptop from a height! : D I’m saving this post hoping someone else will chime in with recommendations.
I guess I'm just confused by what you meant by having bigger problems with cors controlling your access
I guess specifically that would be a lack of CORS, but someone _could_ rely on a same-origin policy as authentication, basically treating any request from the same domain as authenticated. That would be insecure to do without also using authentication (like OAuth in your original question).
Ok, I thought I missed something with the purpose of cors but it sounds like I'm on the right page
Maybe you could stand to learn more about packages and so on, maybe not... from your description of the problems you have I suspect that your team's use of source is maybe less than optimal. Am I correct in guessing that your team doesn't have any automated build or CI (continuous integration) process set up? Any developer should be able to pull down a project and hit "build" with no issues... CI is the key to making this happen. Here's a hypothetical example of what might be happening. Another dev (we'll call him Tom) goes to update one of the internal libraries that his MVC project uses. He updates the library, then to test it he copies the dll from the library project over to his MVC project. Everything is working fine, so he updates the library version and pushes a new package to the internal nuget, but... he forgets to update the package reference in the MVC project (it works locally for him after all). He checks in all of these changes, and no one thinks about it until you grab his MVC app weeks or months later. Now you get build errors and have to spend time researching until you eventually figure out to update the version of that internal package. The point of automated build is that every check in will trigger a build, and ideally that build starts from a clean folder to catch this type of mistake. TFS can be set up to run builds, or you can look into a dedicated CI product such as TeamCity.
Can’t you already do this with arrays? `var array = new[] {1, 2, 3};` I guess this brings that same feature to objects. 
C# team investment in Roslyn is really paying off.
Since the question is answered, I'd suggest developing on separate projects, so you can use hot reloading, but release a a single build. Best of both worlds
`private readonly static object s_syncObj = new();` I dont see how this makes code clearer. New what? Who not just instantiate objects like this then `private readonly static object s_syncObj();`
Why even bother with new. If it’s inferred all we need is {} it’s pretty clear 
I’m gonna use this compiling technique to create CPU intense things that run on the client via C# code as WASM 
Yes, definitely. Check out this generated ASP.NET Core ".gitignore" file: https://www.gitignore.io/api/aspnetcore Everything in the "Build results" section should look familiar. 
No you don't. But it does depend on the company you eventually work for.
With arrays yes. Now it can be inferred on objects
The tooling (Visual Studio, msbuild, nuget) has obviously changed a lot from 2012 on. Plus the framework versions and the additions of standard and core add to the complexity. I've found it hard to find definitive docs for packaging that will match up with what I'm seeing in the wild. For me what has helped is setting up isolated playgrounds to experiment with creating and using packages across different projects.
I'm waiting for C# 9 and `var myDict = new();`
C# 10 will just read tour mind and write code bug free
You never want to put /bin or /obj into source control, so yes. Put the following in your source control or just add [the whole template](https://github.com/github/gitignore/blob/master/VisualStudio.gitignore): [Bb]in/ [Oo]bj/
It sounds like your team checks in things that don't build then you have to fix it. It can be time consuming when you don't know wtf they did to break it. I'd first suggest pushing very hard for a team wide rule that says if someone checks in, the code/project needs to build. That is incredibly very fundamental. The problems vary greatly and I've never come across a book that covers the breadth that you will run into. With 30 years of programming experience, you know about libraries and dependencies. Learn about the GAC, how libraries can be loaded and the ANY CPU build flavor behavior. I don't like to use nuget and until .NET Core I stayed away from it (besides at my work). The packages are just a zip file so you can rename the package, extract the library and add it as a reference avoiding the nuget experience. 
I like the new() better because it's still very explicit that you are calling for instantiation. Your example looks like an interface method.
Lol! Although I don't understand all the scepticism I do look forward to that version of c# 10 that saves my hands from early wear of the joints and let's me program but free! 😁
That wouldn't be consistent when passed as a parameter (last example in the article), where there is no variable name to append () to. new also makes it clear an heap allocation and constructor will occur, and keeps the declaration = assignment structure intact. &gt;void myFunc(Dictionary&lt;string,string&gt; dict){ &gt; &gt; dict(); // Calling a function or instantiating a new object? &gt; &gt; dict = new(); // Clear &gt; &gt;} &amp;#x200B;
There's a slight difference. The array construction you posted is typed based on the first element's type, not the expected type of the array in context.
I recommend taking some time and learning what those files are. You will come across .dlls and .pdbs very frequently as a .Net dev.
Yeah.. that kind of somewhat unfortunate inconsistency is what happens when a language is extended over the years :/. I am not a fan of this new syntax myself. (That doesn’t mean I’m not a fan of other new syntax.)
very good improvement, I like it, code becomes more clean, readable, without a losing of information
Just wait for .net microcore 10 with C#12 on a windows 2022 domain MyApp =query&amp;solveAllUseCaseAD;
Yay more messy code that makes future maintenance even harder....
Yes. It can be that easy, but what's the value of separation like that? Sure if you are building a shared web api and want to build a front end to consume it, that's great, but that isn't a general use case when building a simple web app. As you mentioned lower, specifying a domain in you CORS setup is the most secure, but again, why go through any of this unless you have a use case? We have multiple environments, but most are either IIS or cloud. It's much easier to have one domain that the client app and web server sit on and then proxy downstream calls through the web server. For shared web apis, again, the CORS setup makes sense, but multiple UIs are consuming it.
C# 11 lets you skip the whole programming thing and just hands you paychecks. &amp;#x200B; In all seriousness, being able to switch VS to a voice command mode would be amazing. 
Yeah, CORS shouldn't be your only means of security, but it is a piece of it. There's a reason you have to specify that CORS is allowed and from what domains.
This exactly. Splitting them out unless you definitely need a shared api, is unnecessary cost and effort. When you have to support many apps, this gets overly complicated.
Voice commands that work, not the way they are today. On another note, c# 12 will be just embedded in your asshole and will produce code based on your shit. So your code will truly be shitty :)
This sounds like the opposite of the var keyword. Now you can leave the type off either side of the equals. (But not both sides)
Yes!
Exactly, so removal of noise when it's visible already what's there. I mean imagine private static ConcurrentDictionary&lt;someClass,someotherClass&gt; myConcurrentDictionary = new ConcurrentDictionary&lt;someClass,someotherClass&gt;() That is simplified to something smaller like ConcurrentDictionary&lt;someClass,someotherClass&gt; myConcurrentDictionary = new()
&gt;So your code will truly be shitty I don't have to wait for C#12 for that!
Yeah, that was the joke, from shitty code to code from shit :)
The benefit is in the decoupling of the layers. This allows you to develop to an API spec which is easier to test and validate, and it allows greater control of options should a layer need to change dramatically. Tooling is separate this way, and its easier for separate teams to maintain each part independently if needed.
Great now we can argue endlessly over which side of the assignment to carry type on instead of whether or not "var" is good or not.
its no good. i even dont use keyword var
Yup. It’s frustrating because the environment I work in is very dogmatic. I’ve suggested we don’t split out small webapp out into 3 microservices *until we need to* and I get lectured about how bad monoliths are.
Most people seem to like var.
To get some peace of mind - upgrade your projects to the latest format and delete packages.config after that. New format avoids this nuget mess altogether and in our project with 160+ nugets it's now under control ( previously I was like you).
I know. I don't even like "auto" in c++ too. Personally I prefer stricter rules
Or just get a build server? ;)
Came here to say this since I recently stumbled on this website when googling best practice for hit ignore files for a .NET core web api I was creating, excellent website!
I don’t see why two repositories/projects can’t be deployed together? I’d argue it’s a clean separation of responsibilities in your CD pipeline if you have builds for backend with dotnet core and front end with yarn/webpack/latest-new-js-thing. Then you combine the artifacts in one deployment. 
it's not you, it's nuget. nuget is not a nice package manager. i also always have issues when retrieving code from tfs especially when it doesn't automatically restore packages 
you're on target. we're not doing automated builds/CI yet. it's coming "in the next few months", but everthing is always delayed by at least a quarter, and I hope that the transition to that actually helps some of the issues that i'm encountering now. When I joined the team, I expected and hoped for automated builds. Yes, lots of this seems to be related to copying and moving around the dll files. you're right, it works fine on my co-worker's computer and he's able to deploy it to production and it works.
How you type your results from LINQ then? There are instances where it's much better practice to use var than specifying the type, *especiually* with LINQ. The only rule I mandate is no var for local variables.
I think having the new would actually make it clearer. It took me a while to realize you had the parens there and I thought you were referring to making fields defined without a pre-set value in C# default to calling a parameterless constructor like in C++. Having the difference be non-obvious between an initialized object or null (or whatever default) would make code harder to read.
not quite. it pretty much always works whenever we check it in. sometimes what i check in works on my computer and i can deploy it and then my coworker's not able to use what i checked in. other times it's the opposite direction, my coworker checks in and i can't run what works on his computer. sometimes it's related to projects that have been inherited from a former team member. it worked for them before they left, and now it doesn't work for me or my coworkers with lots of fiddling. I think you're right that learning more about the GAC would be helpful to me, so I'll investigate that further. It seems that VS/MS do some quirky stuff and try to "best guess" some situations, and it would probably help me to understand the logic used in how it makes those best guesses. I'm beginning to agree with you that I don't like nuget. Unfortunately business rules prohibit me from using CDN and open source unless the package exists in our moderated nuget library. I'm beginning to think that it would be best for me to build from scratch in an effort to avoid these kind of issues, but a big part of me yells against the logic of reinventing the wheel when I know an appropriate package exists for what I need.
Exactly, there's times when it says it can't find the package or doesn't have the reference, when I really think it should. Most of the references aren't my teams or my organizations. A good example tends to be ANTLR. It seems like the package doesn't exist in my org's nuget library, but it automatically gets installed as part of an MVC template when a new MVC project is created. Somehow it gets installed or updated automatically when I install/update another separate package (webgrease? it's been a couple days so forgive me). I've gone so far as wondering if it's something that's overlooked in the management of our internal nuget library. There's also times when removing the nuget package doesn't properly clean up references to it, and I think this failure also impacts updates to other packages that depend on these. That's why i really hope to find some documentation or guidance that breaks it down for me.
We are making an effort to upgrade all of our projects... deleting a packages.config sounds scary, but if it miraculously gets autogenerated correctly somehow, this could be very advantageous. Am I understanding you right, just delete it and it'll get recreated?
I like var when it's obvious. e.g. var x= new smth(). It's obvious that x is of type smth
I should edit my comment as "I don't use var except in linq expressions". I use "let" among them. So you got me. Anyway I thought it could be a design flaw like "exception hell" in java. I'm not talking about this specific feature. As if everyday I hear new c# 8 feature. &amp;#x200B;
What software is this?? This looks fun 🙂
I learned to like `auto` in C++ after I had to type `std::map&lt;std::string,std::vector&lt;int&gt;&gt;::iterator` a bunch of times.
It's perfectly clear what type that variable is.
You typically do not want to include anything that you build yourself in a project. I'd almost say you should never include any DLLs or executables, but I'd make an exception on that for assemblies that are third-party and cannot be rebuilt of your own volition. With that said, I'd personally add the entire bin folder to your .gitignore since you are building it yourself. There's really no reason to be storing that in your repo since it's the output of your project.
You can use the Pwned Password API to check for previously breached passwords. There are some .Net Core password validators that make this easy to implement https://github.com/andrewlock/PwnedPasswords/
That's not how readability works, and is the common, ignorant response to taking a deep look at WHAT it means to have easily readable code... It isn't about "can the reader figure it out", it's about "what do the majority of C# dev's expect to see when they read the code, and how quickly can they (at a glance) make a determination about a piece of code based on the way its written?". Cognitive load is a major factor. `var` is a prime example of where it can (and often is) misused and causes much higher cognitive load in the reader as they can no longer ascertain the jist of a method at a glance, and actually have to figure out types of some ambiguously used fields. It uses intellisense as a crutch to describe the code, and if it's not in an IDE it gets even harder. `new()` has the abusability potential of `var`, in that inexperienced developers will use them as lazy crutches and make code less readable. The language is essentially giving them more rope to hang themselves with. It would be very handy here and there, but because it's `easier` it can also be used across-the-board and hurt code readability.
I'm not saying they can't. My current work project deploys Azure Functions, database, and web, all from one artifact. The question is, is there a business reason to separate the front end and api projects? As others alluded to, if the API only serves for the front end, isn't shared, and you don't forsee sharing it in the near term, I think can keep it within the front end project without any adverse effects. It's a situational question, but I think it's always worth it to take a moment to ask the YAGNI question. OP asked about the benefits of keeping it all in one project. To me, the simplicity can be a benefit.
Visual studio will migrate for you. Update to the latest version, set your preferred restore Style to package reference either globally in Vs config or via msbuild property in directory.build.props and the Right click on your reference nodes in the solution Explorer.
I stand corrected; thanks for actually trying it. Would it be fair to say that `readonly struct` *is supposed* to prevent the copy and this is a performance bug in the compiler or JIT?
new object()
`/bin/*` and `/obj/*` are compilation output and should *always* be ignored. If you are using Visual Studio, it has a tool to generate a default `.gitignore` file that includes everything you should ignore in a typical .net Visual Studio project. From Team Explorer, click *Settings*, then *Repository Settings* and under the *.gitignore* section click *Create*. 
first off if you don't know what those files are then you need to read a little more about programming as those are literally the files that are your program. That said you definitely want to ignore them on git.
`XmlReader.Create(reader, new() { IgnoreWhitespace = true });` I really, really don't like this example. Sure, it has made the code shorter, but I now have no idea at a glance what object type is being instantiated.
I don't see myself using this too often, except in the case of method parameters. XmlReader.Create(reader, new() { IgnoreWhitespace = true }); Thank s is really cool. Helps write concise code for method parameter objects much like in JS.
I just tried Razor pages for the first time and I love it. It is so simple and easy. I could make a web application using Razor pages about 3-4 times faster than with Angular and a Web API. The simplicity is great. Sure, it won't work in all scenarios but for basic applications this just seems so easy. 
I am going through this right now. I have little to no experience in c# and it is created towards beginners. Make sure to check all links that they are referring to, they have wonderful explanation and just enough to understand the whole process. 
Not sure why this had some downvotes, seems like the smart move to me.
Hover over it then? Do you not use var either?
Does anyone else hate giving variables names that start with "my"?
This is Unity3D and it is super fun !
Thank you . I will be find tutorials on how to use it! Keep doing great work!!
Cool I have tutorials on how to use it check out my channel [YouTube](https://www.youtube.com/c/dilmervalecillos) 
If that's your argument, then you are arguing against literally any change. Everything is "how devs are used to it" in it's current state. Every new feature added will be a change from current state.. no shit... You need to be asking is &gt;MyClass x = new MyClass(); As easy to read and as clear as, &gt;MyClass x = new(); I'd argue the second is more concise and just as clear. I think it's easier to read than the other version &gt;var x = new MyClass(); 
I agree in this specific situation it would be a bad use of it. Hopefully they add an easy style warning to flag that.
Subscribed 🙂👍🏾
Could should be readable without the use of an IDE. A good example of this might be from using code review tools such as when reviewing a pull request in Azure DevOps or Github at a glance.
Okay so now I have to keep pressing F12
Var if it's something you're declaring. New if it's someone else's
"public datetime date equals datetime dot now" public DateTime date = DateTime.Now "semicolon" public DateTime date = DateTime.Now semicolon "No no no! Erase that" public DateTime = DateTime.Now semicolon "No! Not date! I said that! Undo undo!" public that semicolon "You know what... forget about it." *formatting C drive* "What are you doing!" 
Your post has been removed. Self promotion posts are not allowed.
I don't know why you wouldn't use the build tools from the command line anyway. That's how i power builds and package restore. 
Why?
Yes they are both .NET Core.
I don’t use var for that reason.
sounds awfully like my experience with dragon
Once I am happy with using one project instead of two and need to expand later by splitting the projects, I assume using a JWT in API calls would be the natural transition for handling authentication. Is that correct? Also, how would I handle XSRF? Usually in MVC you use special form handlers to add a RequestVerificationToken but not sure how that works if using something like React.js and a WebAPI in ASP.Net Core.
It is a bad thing to actually do, but it's alright in examples, like foo bar baz
Thanks for the insightful comments! I'll keep them in the same project for now and only split them if I ever find a reason to.
Implement your domain model as you see fit. You should then map that to your entity framework model(s) as you see fit. Since I don’t know what your domain minders would look like, it’s hard to tell, but assuming that your interface defines a base set of properties and your extended classes add extra properties, you might be able to get away with persistence EF models that have null able properties to support all of the different classes. AutoMapper is your friend for doing these kinds of mappings. It highly extensible and can map pretty much anything. 
In 99% of cases when glancing over the code like this(especially without and IDE, code review I assume?) you're not ever gonna care that the object used there is called XmReaderSomethingConfigurationSomethingSomething, you'll just assume that the property inside is meant for configuration of the reader. Adding more words in a line does not always make the code more readable.
The thing is for API you usually inherit from ControllerBase (which has no View support) and for MVC you inherit from Controller. Instead of creating a base class, why not just create extension methods that you can share between your API and MVC.
But with the var at least the type is immediately in RHS so I just know the type by glancing over
But with the var at least the type is immediately in RHS so I just know the type by glancing over unlike this new feature.
While reading code I need to know the type of the arguments that are passed to the function. With this syntax there is no way of knowing the type until we look at the function definition.
This is exactly how I do it.
I wonder if we can omit the parentheses too like you can normally if you don not have any constructor parameters.
Not always. To make code and intent easier, I create small functions that are named well. `var students = getStudents();` In the above, you don't know what students is. It can be the domain/model class, or it can be a ViewModel class. I hate going for the mouse to hover over that, or pressing F12. `List&lt;StudentViewModel&gt; students = getStudents();` Is just more clear, but that is my own personal opinion.
Prefer composition unless you have a clear case for inheritance. It sounds like staking plan might be a decent case for inheritance. I prefer TPH over TPT/TPC almost inevitably.
Parallel steps can be easily simulated with help of snapshot dependencies in TeamCity. Not to mention that different build systems have concept of parallel tasks. 
Why is it pitfall of TeamCity? Don't you have a choice not to do that?
I would, respectfully disagree, in most cases. If you require a shareable web api layer, then yes, everything you said is important. I think this as TCGPlayer.com. They have a UI but they also have a consume able web api that other people can use to build their own sites and apps. So, in that case, it makes a lot of sense. However, if you are only building a web app with no intention of making a shareable web api, then it's much easier to bundle the two together. Again, I am speaking from a long term support and commitment perspective. A team would be expected to own both the client and web server code and they have no use except to each other. They are tightly coupled by design, because the extra resources to keep them separate provide no value to our use case, it's an over optimization. When you maintain dozens of assets across a number of teams, this is an easier maintenance model. You can then focus on spiking out back end services that require dedicated support and scalability, optimizing there. Again, there are many architecture patterns, not just one. Each pattern has trade offs that need to be considered.
Does this work for ASP.Net MVC packages, which cannot be changed to the new .csproj format (but can be switched from packages.config to &lt;PackageReference&gt;)? Also, you will generally have a number of packages referenced from packages.config that were transient dependencies that will no longer be needed to be referenced directly and should be removed to avoid dependent versioning issues.
&gt; I'm beginning to think that it would be best for me to build from scratch in an effort to avoid these kind of issues No. Like the other poster said, get your projects converted from packages.config to &lt;PackageReference&gt; and that will eliminate 90% of issues. After that, you may just need to manual assembly bindings in your app/web.config, but even then it should mostly just be for projects like ASP.Net MVC v3-5 that cannot be converted to the new csproj format. I run a &gt;100k line of code, 10+ year old project that's been in the process of migrating to targeting .Net core. There's some minor challenges, but nothing that can be sorted with a bit of education, trial and error, and process. Certainly not enough challenge to forgo NuGet and start re-inventing every package in house. That's silly.
OMG, lol, I feel your pain. I just got through a DevDay where my whole focus for the org was how there are multiple service architectures, not just 'microservices'. Each pattern has pros and cons, but each has value and costs associated. We were calling everything new a 'microservice' and making that the only pattern to use...um I'll take a well written SOA over 14000 'microservices' (which are actually just orchestration services and not required to scale) for 1 web app please. Sometimes I think we throw out years of experience just because a new shiny ball showed up.
Check the web.config file, rewrite rules are aved in there. Either comment it out or set the enabled to false
&gt;one of the worst build systems Seriously? Could you elaborate, please?
Nowdays TeamCity allows configuring builds with type-safe Kotlin DSL which can be stored along with your projects in VCS. Of course, it supports Docker builds as well. As for $$$ - there is a really generous free professional version. &amp;#x200B;
Initially I thought inheritance, it just seems to fit to me, but everywhere I read says as you say - prefer composition....I'm too inexperienced to know the way to go...so I figured I'd err on composition... A staking plan will basically always have a bunch of rows that calculate a running profit/loss and the amount to stake on the next row...they will never need to quack or fly or anything like that...at least I dont think so...(altho I must admit I dont fully understand the full implications or advantages of composition yet) I do know that in terms of databases I also prefer TPH tho :) 
Thank you, do you mind me asking what a domain minder is? (I have never heard that term before). I dont currently use automapper, but I have messed around with it before.
I think in that instance, you might consider standing up IdentityServer and look at implementing the OAuth Code flow using PKCE.
I think your opinion would change if you were to try both. These "extra resources" that you feel come with a decoupled approach don't exist, unless I guess if you have a ton of legacy MVC and Razor views, in which case yeah there's not a lot you can do.
That's the weird thing: I did check it but I didn't see anything about rewriting but I'll look again and update soon as I can.
No clue, maybe in 8.1 :)
It makes me crazy that Microsoft bases one of the core technologies around a third party library. 
Isn't it a good thing though? Microsoft recognized the importance of the library, embraced it to the point that they decided to use it inside one of the most important product of their dev tooling. And besides why reinvent the wheel and roll a whole new library when someone has already solved the problem once (and efficiently), right?
&gt;New if it's someone else's Or if it's a field.
For ASP.NET Core 3.0 they're finally writing their own (proper) JSON serializer.
Our software just got flagged with a security concern by a government client for including Newtonsoft.JSON, and we are having to deal with that, so, yes, not a fan right now.
I don't understand why when this works so well? It took them this long to figure out not to write their own browser. Do you have any insight into why this is?
Yeah but then you have two options for resolving version conflicts: Forcing a specific version like in the article here, or going down the npm rabbit hole of each dependency having a complete separate copy of its own dependencies (which then in turn have complete separate copies of their dependencies).
Oh god that’s the stuff of nightmares. Gluing together multiple orchestrators over HTTP because “what else are we gonna do, build a monolith? As if!”
Ha. Sorry. Typo from mobile. Should be domain model!
Yup, totally agree that their should be a better way to handle that.
They're going to write an own one purely for performance gain. Massively reduce allocations (using `Span&lt;T&gt;` and `Memory&lt;T&gt;`) and work with UTF-8 directly instead of passing to .NET `string` first. They don't want to support all features of Newtonsoft.Json and want less backwards compatibility, so these changes can't be added to Newtonsoft.Json. Newtonsoft.Json is also too frequently updated, which causes issue with the ASP.NET Core support cycle. You can read the announcement here: https://github.com/dotnet/announcements/issues/90
&gt; I don't understand why when this works so well? It took them this long to figure out not to write their own browser. Do you have any insight into why this is? https://github.com/dotnet/announcements/issues/90
There's an article somewhere where author of json.net ( who was hired by microsoft a while ago, so I'm not 100% sure if you can call it a third party library now) explains why improving it to use the newer stuff (spans, async reads etc) is hard. Rigid and mature codebase like that makes it much harder to perform optimizations that you want for speed (both de- and serialization) in the modern web landscape. It's a fairly hot topic for ASP.NET since serializers are pretty deep in the layers and even relatively small perf increase or io savings are propagated up the stack; strings don't need to be allocated or transcoded utf8&lt;-&gt;utf16 and GC doesn't need to clean up these strings from the heap, Span&lt;T&gt; propagated through the apis and [more stuff you can read about here](https://github.com/dotnet/corefx/issues/33115) and may be check out the new apis that are planned [in various issues here](https://github.com/dotnet/corefx/issues?q=is%3Aissue+label%3Aarea-System.Text.Json+sort%3Acomments-desc) which as you can see differ quite a bit from json.net. So tldr; for all of better direct performance, less GC load (so more performance) and better async (indirectly affects performance of other stuff while waiting for io)