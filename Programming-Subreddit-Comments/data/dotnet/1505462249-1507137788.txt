Meh. They removed the two main reasons for one to use it - transport degradation and reconnection. 
Is that because they have to trade convenient vs scalability?
I don't know why they did it. Guessing it was harder for them to implement.
It works the same way, except it doesn't. It's not a port but a new implementation from the ground up and the inner working, notably the SQL engine is brand new and was subject to strange behavior in earlier releases. The EF release road map is scheduled on ASP.NET Core, not on it's own advancement so I'm still extra chilly on using it in production. My coworkers are always complaining about it's unpredictable behavior. 
Usage-wise, it's mostly the same though.
Would you just use native websockets then?
Sticky sessions? Wtf. In this day and age they thought this was a good idea when most cloud platforms are trying to get away from the concept? 
I remember a conference where the SignalR guys told that it would still feature transport handshaking, but it starts with Websockets now instead of the other thingy Hmm might have to check this later this day
Great news
Basically. Plan to look at socket.io
The link clearly said the transport degradation is not supported. Also afaic in SignalR2 on full .net it atarted with websocket always
Maybe a good graph database?
Wow, that makes it look like a pit or despair rather than a pit of success.
https://docs.microsoft.com/en-us/aspnet/core/data/ef-mvc/intro
Ridiculous. It's not even in the "known issues" section, it's in the "What's Changed" section. So they decided to go this route.
Oh, that. Yeah, VS is just on Windows. :( I agree with you about IIS. All our .NET Core apps are running in a Docker cloud, even though most of them are developed on Windows machines.
FYI - .NET + Node isn't a stack. ASP.NET and NodeJS are alternatives to each other
How do you see these stacked? Traditionally you would choose ASP.NET or NodeJS, but maybe you have something fancy in mind that I don't know about?
Kind of a cool project, I like the simplicity relative to other logging frameworks. I may mess around and throw and pull request or 2 your way. Dumb question though... I mostly work on the web and not as much with class libraries, especially in Core, but is there a reason to target 1.1 instead of 2.0? I made the change locally and with one or 2 tweaks, seems to be working fine.
Super old comment, but can you point me in the right direction for doing this? I'm trying to introduce clickonce instead of the manual stuff i've been doing, and it's all on the corporate intranet, but i still get the smart screen. The only workaround seems to be turning smart screen off completely.
You can create some really cool UIs in WPF. Heck you can do pretty much anything you want. The only problem is that it's verbose as fuck and if you want to do anything even remotely complex you have to re-template entire controls.
Need to add cert to trusted publishers on each machine. This change can be applied to your entire company etc via group policy. https://msdn.microsoft.com/en-us/library/ms996418.aspx#clickoncetrustpub_topic1 
I'm about to roll out structured messages into the library, just gotta write up the serialization/deserialization to json. I'll also go ahead and upgrade to core 2.0. I thought it was already at 2.0 tbh :) But yeah, I'd love to see what kind of changes you make!
I love how powerful WPF is but I'm writing a business app atm with pretty simple UI requirements and I honestly feel so unproductive with WPF/XAML. Moving from React/HTML/CSS to WPF was a pretty big shock.
Off the top of my head I might make a web example and use it as a Middleware. I may also write the email listener, put some built in throttling... Dunno, but will be fun! 
Sounds good! I honestly hadn't thought of the implementation of the email listener yet. So it'd be great if you wrote that out :P.
Is it an additional library ?
&gt; .NET + Node isn't a stack. Why isn't it? I can have backend services in both Node.js and .NET that communicate with each other.
That's two stacks.
I guess if you want to be pedantic.
Thanks for the reply. I ultimately found that deploying via UNC and FTP was avoiding the smart screen, but if that changes i'll take a look at this. I do have a cert that was issued by our intranet CA utility (idk the proper names, not my department) but it was still hitting smart screen.
Agreed. I suppose that's why Electron is so popular.
Looks like it's Mahapps and some custom controls. For those complaining its tough to make decent looking WPF apps easily they should definitely checkout out Mahapps - it's almost like the twitter bootstrap of WPF. Works well with MaterialDesignInXamlToolkit if you are into the material design stuff
Move to better place))
So honestly, you don't have to have "professional" experience for a specific language. Usually you can simply put the languages you've had experience in (professional or personal), and just list what you've done on your resume. Yes, having .Net professional experience means a lot, but you aren't necessarily going to say "I wrote a banking program in .net", you'll say "I wrote a financial app that allowed users to complete various banking transactions" or something like that. Get some personal experience, try to get into an entry position (which usually needs no professional experience), and learn on the job. I started with little .Net experience myself. I'm 8 years into my career in a .Net market, and I've worked with ASP.NET, .NET framework with Winforms, and Python with Angular. I've sat on both sides of the table and depending upon the position, it doesn't matter. 
Use what you know. Otherwise use something that a lot of people know. I'd probably use EF6 CodeFirst, or EF7 if it supports all the features I need (didn't do DbGeography last I checked). You sound like you're over normalising your database (emails in a separate table just in case they're reused??). Normalisation was popular back in the day because storage was expensive, it's now cheap. Some data replication can speed your app up a lot - you generally want fast reads and don't care if your writes are slower. You state that it shouldn't be size limited (SQL express 10GB) then say its only like 10k entities - that's tiny and won't go near the 10GB mark.
Alrighty. I've got my implementation done. Care to do me a favor and tell me what you think? Most of the important legwork is in https://github.com/Icecream-Burglar/WaterLogged/tree/master/WaterLogged/Templating
I have been working in Microsoft shop for really long time, but want to move to open source world. For your case, I would suggest - get an ASP.NET MVC book and do everything that is mentioned in there. Create sample apps in your local machine itself - shopping cart, etc., Recently MS has released .NET core 2 which would work on any platform. You have to think about if you really wanted to get tied to MS platforms. In my case, I have worked for long in MS and now it has been bit boring for me, as I feel MS is trying to create many approaches to solve same problem. Where I work, over the years, I have seen the opportunities only shrinking. Earlier, when Microsoft releases something new, you study it, and you are settled and updated to latest technology. But now things are so different. There is so much happening outside MS world.
It's very possible to get hired without professional experience in a company's specific tech stack. If you have a github with a project or two that demonstrate you've at least looked at the language and maybe some of the tech they use, that's often good enough. A previous employer of mine was fine with hiring people that fell into this category. Some places don't care that you have absolutely zero experience in their stack. They're interested in how competent you are as a developer, and your potential to learn their tech. My current employer is mostly Java and mysql. I didn't have any of that on my resume when I applied. They didn't care. They even rewrote the on-site programming test in C# because that's what was at the top of my resume.
Can you suggest any? I haven't really worked with any of those.
Thank you for pointing this out. I will take a closer look.
I found [SimplCommerce](https://github.com/simplcommerce/SimplCommerce/blob/master/README.md) today and saw a few things I liked enough to want to make changes to my own stuff. 
It's using Angular 1.6 which is kind if awkward when using Asp.net core 2.0
I use react for work so I just ignored the angular bits. But they seem to have gotten it to work.
Just adding some features so we don't feel left alone.
That's the balance. Use a full ORM like EF for basic CRUD and fine tune performance using Dapper.
Not for .NET Core, though they are close to completion when it comes to porting to .NET Core.
The biggest issue with .NET Core is obsolete answers, often answers from the beta/rc-era or even the preview era (when it was called ASP.NET 5). Many of these answers are no longer applicable. 
T4 can also be used using the Code model of Visual Studio, but it is quite slow and badly documented. It also does not support the newer language features well.
The real problem is speed. Coming from web development to desktop it's painfully slow at displaying complex UIs at times. I heard a developer comment how proud they were to get the initial load time down to 4 seconds. That seemed like an eternity to me.
Perhaps you can answer my question. Some sos debugging extensions used to work from Visual Studio. Is sos still supported from Visual Studio?
You can check out multimodel DB such as * https://www.arangodb.com/ * http://orientdb.com/orientdb/
I agree. If your market is saturated with .NET jobs they are probably *desperate* for good developers of any kind. If you have full stack experience of any kind it's hugely valuable. The front end stuff stays largely the same. We would hire someone like this and give them some time to train up on the job. You may take a pay cut during the ramp up time, but this could super pay off in the end. Negotiate for the best deal you can :)
They got it to work using a newer version of Angular using some Webpack middleware. I'm not sure there is an easy way to jump in with Angular 1.x though.
For the user authentication to your app you could use Forms Auth with social logins. For creating the API tokens you will still need some other form of authentication management like bearer tokens.
Form1 is just another class. You can inject your other class(es) into Form1 via the constructor in your Program.Main() method (which is usually where the main form is instantiated). As usual, there are plenty of different ways to go about injecting dependencies, but that's an easy way to get started before you dive into the world of DI frameworks.
You could pass a form reference to your class. You didn't give more info but can you just use your class and return stuff and you those on your Form??
Your form is just a normal class. What you should do is create an instance of your class inside your form. Then you can access the class functions in your form. The other way is to pass the form to your classes constructor, but this will tightly couple your classes to your form.
I would focus on learning a bit of SQL. Put that on your resume. Most .NET jobs have a SQL Server back end. If you can do basic queries and understand all the different kinds of joins, you'll be valuable fast. I would also send emails out to those companies and ask them what their front end stack looks like. Tell them you are a fresh grad and want to know what to study for new jobs. It couldn't hurt. ASP.NET MVC is the place to start. Now, there is ASP.NET Core, which is imo much better. It merges Web API with MVC. If you are looking for a new position, try a few pluralsight courses and see if you can follow along in code. The main architecture will be done for you at your job so you don't have to be amazing at MVC, just competent enough. 
As an opposing opinion, I would say that no other classes should access your form. Handling the UI is one concern, which the form class handles; generating content to display on the form is the concern of the other classes. Very simple and bad but illustrative pseudo-code: private btnDisplayCustomer_Click() { new var customer = CustomerGetter().GetCustomer(Convert.ToInt32(txtCustomerId.Value)); txtCustomerName.Text = customer.Name; } 
For a basic app, you might want to try the builtin forms/cookie authentication as in Microsoft's [Introduction to Identity on ASP.NET Core](https://docs.microsoft.com/en-us/aspnet/core/security/authentication/identity?tabs=netcore-cli%2Caspnetcore2x) article. I've had a good amount of success starting with that and then moving to OpenID Connect or some other identity provider.
Perhaps an easy way, but I have not understood a word you just said =P This will require a lot of googling. With some luck, it'll help me out.
I don't need Form1 to access stuff in my custom classes. I need my custom classes access stuff in Form1.
I'm not sure I understand what you mean. In my case, I'm writing a class that does some math to update the status of various progress bars in the UI. Setting a progress bar to a value is super simple. But I have to be able to access the progress bar object in order to do it.
I can't return anything to Form1 if the class cannot see Form1. (I don't know what a form reference is. I'm learning C# with Google.)
You need to implement a public property on Form1, then pass the form reference (this) to your class. After that you can use myformreference.property = value. It's a lot cleaner than accesing controls directly.
Instantiate your custom class in Form1 and pass the running instance of Form1 (this) into your class to do your logic. You don't want to do it the other way around, Form1 is your main UI class. If you post your code, we call help you further. 
The class that does the math shouldn't update the progress bar, it should return a value to the caller (or expose a property that can be checked), and the caller should update the progress bar. 
What I'm saying is that's the wrong way to structure it. But if you want to do it that way create your class inside the form and pass this to the constructor.
Alright, I modified my class as described. I'm not entirely sure how to proceed from here. You can look at my class here: https://pastebin.com/XrN0Qhr5 It's supposed to be part of a little game system - designing those is a hobby of mine, which keeps me motivated to learn programming :) This class is a clone of the normal Panel UI element, except that it starts with a series of other UI elements already placed on it. The purpose of this whole exercise is that it represents a "page" in a "spellbook" - a flow layout panel on the main UI, into which these customized panels are inserted. I can already do this at runtime with custom spell names, which I am pretty proud of pulling off with no prior knowledge. This spell panel contains a button that is supposed to be clickable to cast the associated spell. This action should do some math, and update various UI elements on the main UI with the results of said math. This is where I run into the problem of being unable to access Form1 at all. I now have this parentForm field I filled with the reference to Form1, but it doesn't seem to be helping. I specifically made a public method in Form1 for the purpose of testing, but it is not accessible under the parentForm.xyz notation.
I kind of need to do it that way because the class adds additional UI elements, which cannot be part of the main Ui because they are added at runtime into a flow layout panel. And there's a button among those additional elements that must do stuff. (I posted a pastebin link elsewhere in this thread.) Unfortunately, passing the form reference isn't doing what I need it to, as also described in that post.
Hey i have a shitty playlist app with login to a sql database that is angular 1.x on front and .net core in back end. It was fairly easy to connect the two holla if you wanna see it
Be warned that last I checked (was a couple of weeks ago) that IdentityServer4 hadn't been updated to support ASP.NET Core 2.0 yet..
You have passed your form in with the type Form not Form1. Those methods are defined on the Form1 class.
Ah, woops! This is how you can clearly see that I'm only really understanding at most half of what I grab off the internet. It's not exactly always intuitive. Changed the type to Form1, and it works now! Many thanks. :)
Just understand that your "designer" is just a graphical representation of a class that is being auto generated. You do not need to ever use the form designer if you didn't want. That being said, learn what classes are first and foremost. Then it'll all start making sense.
Aha! You're subclassing Panel! For UI classes, when you compile them, they will show up in your toolbox. I notice that your code stores a reference to the parent form, but never uses it. Perhaps what you really want to do is create a user control; then you can drag and drop components onto it, rather than creating them in code. It will show up in the toolbox as well. Either way is fine.
I wouldn't touch anything by service stack. Their licenses are awful. 
I'm using Auth0 and I like it so far. I like that I don't have to write the sub-application that is authorization/authentication and I get offload security to someone who specializes in it. 
IdentityServer is non trivial to setup. If it were me I'd use OAuth2 and integrate with Facebook/Google/etc.
Wow, that came together quickly! Some unit tests showing the way corner cases etc. are handled would be helpful for understanding it quickly. There's a set at https://github.com/messagetemplates/messagetemplates-csharp/blob/master/test/MessageTemplates.Tests/ParserTests.cs that might be useful for inspiration. I think both Serilog and NLog 4.5 conform precisely with these. One thing I wish I'd done early on in the Serilog project is push _very_ hard to get per-event data into `struct`s. The `Hole`, `HoleValue`, and even `StructuredMessage` classes could be converted into structures to save pressure on the .NET GC. If you're keen to push for even more cutting-edge perf, check out the NLog message template parser implementation in particular - it's very nicely optimised to limit allocations: https://github.com/NLog/NLog.StructuredEvents Finally :-) one more thing to consider; a message template can be parsed once, and then cached and used to capture many events. Splitting the parsing out from the capturing in `TemplateProcessor` might be an easy change at this early stage, with potentially substantial wins further down the track. Hope this helps! 
In the event handler in your SpellPanel that does the math, you would use the parentForm variable to access the main form. private void SpellCastButton_Click(object sender, EventArgs e) { int yourValue = YourCalcuations(); parentForm.YourPublicMethod(yourValue); } However, there are better ways to handle this. For example, you could create an event within your class that gets fired off whenever the math finishes, and your form could subscribe to that event and make whatever changes are needed to the form. That way, all the functionality of the form and your SpellPanel class remain separated; they each have their own responsibilities.
So what is inside Docker? IIS or some other web server? Could you kindly point me to some dev ops info, how it is all done in general. Thanks
Thanks for the quick review! Yeah, I'm going to start investing a lot of time into public projects. The goal is to be able to get a job in software development one day, having a minimum of a CompSci AA. Education gets expensive after community-college. So I want to at least have a nicely filled-out github account just in case I won't be able to afford to transfer to a "real" school after I gain my AA. I almost created Hole, HoleValue and StructureMessage as structs in the beginning, but wasn't really sure if they would be more friendly as valuetypes or referencetypes. So I stuck to the "Default" there. :) I'll look into the nlog parser and see what I think of it. And I indeed plan on implementing caching templates at some point. Also, thanks for the link to the unit tests! I'll see what they turn up.
&gt;When I make a new Windows Forms application If you are not using WPF, [you really should.](http://www.wpf-tutorial.com/about-wpf/wpf-vs-winforms/) It’s one thing to maintain an older, legacy application written in WinForms, but anyone starting a greenfield project in WinForms that is actually intended to be a serious product needs to have their programmer’s card revoked. Anyone who is just starting to learn how to program using WinForms is like learning how to drive in modern traffic with a Roman chariot: eminently doable, but quite unwise - your skillset will be obsolete in the wider marketplace long before you master it. To wit: &gt;[“Windows Forms is continuing to be supported, but in maintenance mode. They will fix bugs as they are discovered, but *new functionality is off the table*.”](https://www.infoq.com/news/2014/04/WPF-QA) Conversely: &gt;[“Work on improving WPF has never really stopped”](https://blogs.msdn.microsoft.com/dotnet/2014/11/12/the-roadmap-for-wpf/) Finally, &gt; [“What is the future of Windows Forms? Bitter truth: not good.”](http://www.c-sharpcorner.com/article/what-is-the-future-of-windows-forms/) If you don’t have to support anything older than Windows 10, you can jump straight into UWP (Universal Windows Platform), but if your goal is wide support of all Windows platforms you get the best maintainability and scaleability from WPF combined with a solid MVVM design pattern.
And that "mobile website" is unusable...
VS Code and Visual Studio 2017 IDE both show problems when I try to run these samples. Compiles but shows 100+ errors.....
Oh, I got how I should use parentForm. My problem was that it didn't work because I used the Form type instead of the Form1 type, so nothing from Form1 was actually accessible. Managed to fix that yesterday already after it was pointed out to me. As for using an event? I only just barely learned how events work (largely by copypasting stuff). It didn't even occur to me that they can be used that way. What's a good way to detect that the calculation has finished? I'm not sure what things can be the source of events yet. Can I have a variable inside the button press method, and fire an event when that updates?
&gt; I notice that your code stores a reference to the parent form, but never uses it. That's because trying to use it didn't work (as mentioned in the post). I made a mistake by using the Form type instead of the Form1 type. After I changed that, I was able to get it to work.
Nothing I make at this point is intended to be used by anyone other than myself. And even I use it for only one thing: to teach myself C#. I get that it's old and deprecated, but it's also simpler. I tried making a WPF project before. The result was that even the most simple and fundamental questions I asked about it made people link me to topics like Model–view–viewmodel, which made me question whether or not I was still reading English text, or just stumbled upon an entirely alien form of communication that's indecipherable to the human mind. To this day I'm leaning towards the latter. I don't doubt that for a developer, it's paramount to get into WPF early-on. For a hobbyist like me who throws together a few lines of code once a month out of sheer interest despite lacking zero formal education in the subject and not even being a native English speaker? Yeah, no. I'm going to stay the heck away from it. =P
&gt; transport degradation You have to support IE 8 and earlier? That's the real tragedy here.
It's probably handled transparently in Azure App Service using session affinity cookies.
Participate in .NET Core open source projects
You can style a &lt;select&gt; object to have checkboxes using some CSS and JS, however I found I prefer to use [David Stutz's multiselect](http://davidstutz.github.io/bootstrap-multiselect/) project for this purpose. It works quite well with Razor views using Html.DropDownListFor() right out of the box.
Okay, if your entire usage case is to learn C#, then it’s one that is quite understandable. The platform isn’t what’s important here - the language is. But aside from a few exotic edge-case gotchas (which I could have done without), it took me less than 40 hours to lock down the basics of WPF and build a functional app. And this is without a book to learn from. My question: what is your history with C#? Have you ever used it elsewhere before, such in WebForms or MVC? Or are you jumping into the language itself at this time, with zero prior experience?
Came here to vaguely echo /u/Silound, in that what you are trying to do requires JS and CSS as it is not a standard HTML tool. In HTML you have either a Select (one item selected), a Multiselect (multiple items selected), or you use a rendering loop to paint out checkboxes or radio buttons onto the page. To combine two or more of these is to swim against the current, and that requires JS. And when you do this, remember that you are working with an array, not individual items. Make sure your model makes use of an `IList&lt;ArrayName&gt;` to handle these items.
They call the web host [Kestrel](https://docs.microsoft.com/en-us/aspnet/core/fundamentals/servers/kestrel?tabs=aspnetcore2x). I don't know much about how it works, but that page says it's based on [libuv](https://github.com/libuv/libuv), which also is used by Node.js. Rather than having the app hosted in IIS or IIS Express, it seems like Kestrel is mostly contained inside .NET because we start up the server by calling `dotnet run` on the main executable result of building. We have our own version of the [dotnet Docker image](https://hub.docker.com/r/microsoft/dotnet/) which we use as our base image when building a Docker container, and we use `dotnet run` as the entrypoint. Because it isn't in IIS, there is no web.config and you don't get frustrated with making sure your web.config files don't conflict with nested web.config files. Most of the configuration is done [within the app](https://docs.microsoft.com/en-us/aspnet/core/fundamentals/hosting?tabs=aspnetcore2x). I say most because as part of our deployment process, we also inject environment variables based on which environment we are deploying.
I have jumped into it with "zero" prior experience in the sense that I had never touched C# or Java before. I have in the past (some of it fairly distant past) dealt with C, HTML, TurboPascal, and Python. But out of those, only HTML involved anything remotely related to user interfaces (and then only because a website is a UI in itself). This is also not the first time I try something in C#, because I do this on-off whenever I feel like it. I poked at it earlier this year already, with mixed success.
Unless you need to generate entire types or specific IL, using `Linq.Expressions` for dynamic method generation is often easier. [This should work.](https://repl.it/LNGG/0)
It does. Edit: The hardcoded delegate type is just an easy way to get the `MethodInfo` for the static method to be called, it's irrelevant to the actual event subscription.
This looks quite good. The license seems permissive enough (unless I'm missing something) and it's definitely a good thing having a viable alternative to Razor.
Meh. Doesn't CAKE get promoted here a bit much? It's great it exists as an option, but it's not a great one in my experience. The thread is upvoted, but empty. There's nothing even of note in this release other than it was broken. I question dropping every release in this forum. The GitHub Releases feed would be an appropriate place for that feed.
Async. Use async process both in the front end (JavaScript, etc) to allow the process to run in the background. Use async on the web server to not take up front end threads. A more advanced implemention could use something like SignalR to notify the front end when a long running process is complete. 
Yeah I've yet to really see the point of CAKE. If I want custom builds per OS or something, why not just setup a new build in the CI? Done.
I don't use it, but Cake isn't a replacement for CI, it's an alternative to make.
Well it's rather opposite, many want same build process regardless of OS, environment or runtime, they want same process to be able to run and be debugged across environments (locally, build servers etc.). Some want their process to be versioned with their code. Some do more than just build in their process. 
Generating IL by hand is a pain in the ass, wrought with potential errors, and screwing things up will take down your entire program (in spite all your exception handling). Not only that, it will be some of the most unmaintainable parts of your program. I've done it once, and i would have it be the absolute last resort if I had to do it again. My suggestion is to use something like [Dynamic Proxy](https://github.com/castleproject/Core/blob/master/docs/dynamicproxy.md) which is a library that allows for dynamically generating classes at runtime in a much easier fashion then writing the IL yourself. Several DI and mocking frameworks use it, so its very well tested and should do all you need to.
whats the advantage of using llblgen if youre already using EF and can generate your models from the db or the other way around?
I bet if you look at your server's process monitor the CPU is pegged at 100% during the processing. 
Exactly what I was looking for! Thanks!
I don't really know because I never use LLBLGEn to generate EF code although its designer does support it. I always use LLBLGen native framework which predates EF. It just gets better and faster in each iteration in comparison to EF which gets rewritten instead.
Wait, why? Reads should not lock file access. Multiple reads from multiple requests should be fine. Unless you are really trying to synchronize access for some other reason. You might want to back up and think about some other optimizations. Like are the file contents always changing or can you cache?
You don't have to detect when the calculation is finished - you are in control of the event, so you fire it off when you're done. It looks something like this: In your SpellPanel class: public delegate void SpellCastHandler(int newValue); public event SpellCastHandler SpellCastFinished; And then whenever you have finished a calculation you would notify anything that wants to know by simply calling SpellCastFinished with the new value: int result = DoMyCalculations(); SpellCastFinished(result); Note that this will cause an error if nothing has subscribed to the event, so you'd want to check to see if SpellCastFinished is null before you try to call it. Fortunately, C# makes this really easy; you'd just replace that last line with this: SpellCastFinished?.Invoke(result); The real beauty of events like this is that you can have more than one subscriber, so in the future if you needed to update your form *and* some other object needed to know about it too, you don't need to write any extra code. You subscribe to the event the same way you'd subscribe to any other event like a button click: SpellPanel spellPanel = new SpellPanel(spellName); /* ... Initialize the panel with whatever attributes ... */ spellPanel.SpellCastFinished += SpellPanel_SpellCastFinished; and then add that method to the form class, with the same signature as the SpellCastHandler delegate: public void SpellPanel_SpellCastFinished(int newValue) { this.myProgressBar.Value = newValue; } Unfortunately there's one more caveat. This will compile, but it will crash when you run it, because when your class fires off the event, the event handler responds in a different thread than the one that the UI is running in, [and .NET doesn't want you to alter the UI from anything but its own thread](https://docs.microsoft.com/en-us/dotnet/framework/winforms/controls/how-to-make-thread-safe-calls-to-windows-forms-controls). So you have to do a little extra work to make it thread safe. The InvokeRequired property of your form (or any other Control) will return true if you're *not* in the proper thread, so then you use the Form's Invoke method to call the method again, but from the right context. public void SpellPanel_SpellCastFinished(int newValue) { if (this.InvokeRequired) { this.Invoke(new Action(() =&gt; SpellPanel_SpellCastFinished(newValue))); } else { this.myProgressBar.Value = newValue; } } Now you can use SpellCastFinished() anywhere in your panel class at any time for any reason and the form will respond by updating the progress bar with whatever value you pass it, and your panel doesn't have to know what form it's a part of.
It does sound like the CPU is maxed out or the file is large enough to max out your bandwidth. It could also be a limitation of the number of concurrent requests per user. Try making a page that waits for 10 seconds. Load that and then try another page. This would tell you if it was a concurrent connection problem. https://docs.microsoft.com/en-us/iis/configuration/system.applicationhost/sites/sitedefaults/limits
Not sure if this applies to you but the default ASP.NET session state can block requests. If you are reading and writing to the session state during a request it will block subsequent requests that also read and write to the session state until the first one completed. http://johnculviner.com/asp-net-concurrent-ajax-requests-and-session-state-blocking/ https://stackoverflow.com/questions/3629709/i-just-discovered-why-all-asp-net-websites-are-slow-and-i-am-trying-to-work-out https://msdn.microsoft.com/en-us/library/ms178581.aspx
I'll take two. ;)
thanks a ton! But as a reality check from a buddy developer - why do we use .NET Core? Does word `better` comparing with Python or NodeJS can be applied here? Tbh until recently when I was doing NodeJS apps it was a nightmare, recently it is become much better. I mean why do you personally stick with .NET, is it because they provide a solid dev environment? I mean world is crazy, people are dumb, recently all startups were jumping on Ruby as if it were free money, now Python is a ruler, (and RreactJS that I hate btw). I am just trying to use my brain, but I don't want to be the only guy holding a WinPone in my hand. That's a metaphor, of course, I've got XiaoMi which is awesome 
First of all, IMHO, isn't it better to use one server-side framework (ASP.NET)... I just can't think of anything that I can't do in ASP.NET :) The best way is to learn by DOING. If you wanna join me (I'm on this project currently, just to learn): https://github.com/0xRumple/EFMongoDemo/tree/develop
Wow! Thanks for this reply. I got it working by now (in what I assume is a much more crude fashion), but this looks like a really interesting way of doing things and I'm definitely going to try it out as well :)
Are you trying from the same browser but a different tab? I've seen this happen before where you the browser doesn't let you have multiple requests. Try the two requests on separate PC's or browsers
The EF Core mug will come without handle and cracked by design
oof
The Dapper mug is just a handle. Easy to hold, but it doesn't want to tell you how to drink.
I really like the ASP.NET newsletter: https://www.getrevue.co/profile/aspnetweekly
Jimmy Bogard migrated to his own blog now.
I like http://www.blinkingcaret.com/. Found some really nice posts there.
I still check out [The Morning Brew](http://blog.cwa.me.uk/) for a list of decent articles.
https://dotnetkicks.com/
I already tried async but it does not work because I have to wait for it to complete than I can continue. I need the value from the task. But I think SignalR might work. I will check that out.
Please stop using this sub for build/release notifications.
Show us some code. Async should solve you problem.
Let me add some more detail... First, async with `.Wait()` will not help, and could make things worse - so don't do that. Then you'll want to address the point that causes the app to wait, and that could be several places. I'll use an example app to illustrate some areas that may (or may not) be applicable. Let's say we made an app to make a graph of word frequency per chapter of the book Moby Dick. Great, we write the code to read in the text of Moby Dick from a text file and parse and return the results. This approach will be slow, not due to the actual code, but the design. Each request will try and lock and read the file every time. This will lead to contention. One way to avoid this is to open the file read-only and place fewer locks on the physical file (e.g. `var fs = new FileStream(path, FileMode.Open, FileAccess.Read, FileShare.ReadWrite);`). In this case, the text of Moby Dick is unlikely to change from one user's request to the next, so why are we reading it in on each call? Maybe we can alleviate the disk I/O by reading the text once when the app starts and we store it in an `IMemoryCache` or something. That way we are only reading from fast memory and not slow disk. But we can go further, there's no need to recalculate word frequency each time. Again, let's read and process once and store in some persisted state (maybe memory or a database) and simply run SQL or LINQ from that pre-aggregated data which will take milliseconds. Last, but not least is the front-end. I'm an advocate of fully controlling the user's experience - including errors. One common way to do that is to have the web server return a (nearly) empty page. Then let Javascript (or jQuery, or Angular, etc) make an async call. That way the user will always get a page, and worse case there will be an error message that you can control/explain, not a generic (scary) browser message. Now, this may not apply without knowing your specifics (your data may change in the file frequently, etc).
Some .NET-related sites I like that are still posting content: * Jon Skeet - https://codeblog.jonskeet.uk/ * Scott Hanselman - https://www.hanselman.com/blog/ * K. Scott Allen - http://odetocode.com/ * CodeProject - http://www.codeproject.com And the ASP.NET Weekly newsletter is great as well. 
In that same vein, [Morning Dew](https://www.alvinashcraft.com/), same idea but ran by a different guy.
Is there any loss of functionality by this migration to asp.net core?
Agreed, really hard to make a complex and fluid UI with this tech, WPF layouting is really slow.
[New posts are rare but the author is quite active on twitter](https://elian.plus/2017/08/27/aspnet-mvc2-handbook.html)
This is fantastic thank you
* [ASP.NET Official Blog](https://weblogs.asp.net/) * [Scott Hanselman - Microsoft Lead](http://www.hanselman.com/) * [Jeff Atwood's "Coding Horror" - SO Co-Founder/Discourse Founder](https://blog.codinghorror.com) * [A List Apart](http://alistapart.com/) * [Jon Skeet - Google Engineer](https://codeblog.jonskeet.uk/) * [Visual Studio Magazine](https://visualstudiomagazine.com/Home.aspx) * [David Walsh - Senior Engineer at Mozilla](https://davidwalsh.name/) * [DZone - Clickbait for Developers](https://dzone.com/) * [K Scott Allen's "Ode to Code"](http://odetocode.com/) * [Math Intersect Programming](https://jeremykun.com/) * [Dan Luu - Microsoft/Google Engineer](https://danluu.com/) Some of these aren't so much .NET as much as they are just Software Engineering in general, but they're all really good resources. Lastly: [Hacker News](http://news.ycombinator.com) for general programming news
I don't have a good answer for you. I personally stick with it because I like C#. Other than the Oracle thing, I can't find any rational reason to pick Node.js over .NET Core or .NET Core over Node.js. I've never used Python, so I can't say anything about that one other than I've been too scared to try it. Also, as much as I dislike writing serverside code in JavaScript, it really does look like a bunch of people have been jumping into Node.js the last couple years. Like you said, you wouldn't want to invest heavily into something that will turn out to be just the latest trend that's dropped in a couple months. At our company, we allow people to develop little APIs using either Node or .NET Core. One of our architects suggested we try to move towards .NET Core once the Oracle drives come out, but I don't know why he decided that.
Link to ,net weekly: https://www.dotnetweekly.com
Added the important part of the code. With async I still have to wait for the task to end because I need return the result.
You have won the .NET community, sir.
Added now short description of my code. My data is updated frequently so Memory will not work. But I think SignalR should solve it. Just trying it out, seems promising.
InfoQ covers .NET news and runs interviews with prominent Microsoft and open source project members. https://www.infoq.com/ This is the one that hired me a few months after I discovered Reddit.
The sheer performance of trying to load product combinations drove us to a hosted solution.... How's speed now?
SignalR will let you "signal" the front end to let it know that the response is ready. It won't be quicker, but it may allow you to manage the user's expectations via UI (which is important). If you know the size of the last time that you read the file, can't you just read the new bytes? Like` int n = fsSource.Read(bytes, numBytesRead, numBytesToRead);` and keep the rest in memory? That way you'd only be readind x records instead of the whole file? If two requests occur at the same time, do you really need to re-read the file? Could there a single background process to monitor that file (maybe a `FileSystemWatcher` and update a shared in-memory cache (maybe even sorted) while the web server reads from that cache instead of ever going to the file? (of course, that works better if older data never changes - only new records appended) 
My morning routine right there :) Alvin is the man. Should have been an MVP again
You won't find anything good by now. Try the official documentation, is the best place to learn and honestly, it is pretty good.
It's licensed under AGPL and a commercial license. Those bastards want to get payed for working on servicestack, what an unspeakable crime!
Official documentation is where it's at. https://docs.microsoft.com/en-us/dotnet/core/
Id tokens are to be used by the client only and not sent to the resource server, according to spec (I know some missuse it). What openid flow are you using and did you request the access token?
Anyone who links you to Atwood isn't your friend...
Following this logic, ADO.NET would be just a pile of clay? lol
$1,000 per developer for the floating license. They advertise it as royalty free, but I don't trust them enough not to change it. 
Nothing like that exists yet. The closest you'll get will be some early access stuff like https://www.manning.com/books/asp-dot-net-core-in-action and https://www.manning.com/books/dotnet-core-in-action ...but note the content in there now is largely pre-2.0, so although it will eventually be the place to go, right now, its not really. (especially the asp one, see https://forums.manning.com/posts/list/40980.page : "Yes the book will cover ASP.NET Core 2.0 at the end of publishing. You'll see new chapters in the MEAP to begin to cover 2.0, and earlier chapters that were written before 2.0 was announced will be updated to cover 2.0 at a later point. ")
Checkout [C# Digest](https://csharpdigest.net) – a weekly newsletter with only 5 links in .NET and C# that I hand pick together every week.
I get almost all of my .NET news from twitter. Follow a few big guys, and before you know it you'll be in the depths of things.
I try to keep [DDD Weekly](http://dddweekly.com/) focused on articles about Domain-Driven Design in .NET, but I also share blog posts and videos that aren't specific to .NET.
[https://www.ssw.com.au/ssw/Standards/Default.aspx](https://www.ssw.com.au/ssw/Standards/Default.aspx) Their YouTube channel is pretty active.
this is also my workflow: create DB first, then reverse engineer to EF6 using LLBLGenPro. LLBLGenPro will create 2 projects: Models and Persistence. The models are all the POCOs (entities, typed views, etc.) The persistence project gives you access to the DbContext. I like EF for inserts and updates because the SaveChanges() is transactional. For most reads, I'll use the LLBL-generated POCOs with Dapper. EF's object materializer is a lot slower than Dapper's.
&gt; $1,000 per developer for the floating license. So you have a problem with the price, not the license? By the way, you can just use a named indy license for $299. If your team doesn't have an incredibly high churn, it's way cheaper. I really, really do not get the hate. If you do not think that you get your your money back in terms of increased productivity, just don't buy it. I feel the same way about resharper, but I do not frame that as a principled opposition against the license. 
Why do people want books? As soon as they are published it's usually outdated especially with the speed that .Net Core is moving at.
Is it? I find a lot of the samples are out of date. I suppose the main topics aren't too bad but I've found whenever I've had an edge case the documentation is a bit lacking.
Whenever you find an edge case, file a case https://github.com/dodyg/practical-aspnetcore and I will create a sample for you
And I agree with you about resharper, but if you were ever caught in a license that suddenly changed and put you in a bad position, you would get that what you view as animosity is really fear of getting bitten by a familiar predator.
Have you tried OpenCover? I think Dot Net Core isn't supported but perhaps check this thread: https://github.com/OpenCover/opencover/issues/601
[removed]
*sigh* What you misinterpret as a predatory move was a necessary step to ensure the survival of the project. Servicestack until v.4 was open source under a permissive license, but it was run as a hobby project by some guy who worked full time for Stack Exchange, Inc. This kind of arrangement, where the project depends on people basically doing two full time jobs **never** works in the long run, and everybody who uses such a project for something serious is either very inexperienced or likes insane risks. By the way, v.3 is still there, it still works, and it's still under BSD. But nobody bothered to fork it, because most people who use servicestack do not give a fuck about a few hundred bucks if this ensures the long term viability of a critical component. 
Looks like they support dotnet core but the profiling API that it relies on hasn't been ported properly yet - so it's not supported on linux/mac... looks like I'm gonna have to install parallel
Why did this need to be a YouTube video? 
Is this a joke?
Alternatively use this https://github.com/dodyg/practical-aspnetcore/blob/master/projects/aspnet-core-2/features-session-redis-2/src/Program.cs 
I installed VS 2015 and I installed SSDT and I can't get CodeLens, any ideas?
Did you add roles to the database? What's the value of userModel.AspNetUserRole? I'm guessing the value is null, or it's non-null and you don't have a Role that corresponds to that value. 
I was not aware of data breakpoints. I can think of numerous times those would have been useful.
Nope, the value is "Admin" which exists in DB. EDIT: as you can see it says NULL is not allowed in AspNetUserRoleId column, not the AspNetUserRoleName column.
Right, but that overload will lookup the Role Id based on the name provided as a argument. 
[removed]
Just re-checked the thing. userModel.AspNetUserRole = "Admin" Checking the DB: AspNetRoles.Id=jibberishId AspNetRoles.Name = Admin 
Sorry I'm stumped, it all looks like it should be working...
I know! I don't know what the hell I'm doing wrong here.
Can u post ur code where you seeded the role "Admin"
You mean this: --AspNetRoles INSERT INTO AspNetRoles(Id,Name) VALUES ('3C3BB7B6-6E1D-4FA6-982A-35E7BA9D6401','Admin')
Are you using .net core? Problem may be this: the AddToRoleAsync should take in the entire user and not just the id. You need to first get the user Var addedUser = await UserManager.FindByEmailAsync(user.Email) Then AddtoRoleAsync(addedUser,UserModel.AspNetUserRole) Even if u are using a diff version framework, i can guarantee that the value of user.Id is null. Even though properties are passed by reference, you need to get the Id that was just generated from the db by making a call the the db in some way.
I have run into a vaguely similar issue, in which (like you) I needed a second dimension of authorization. My one option was just making a second set of “rights”, in parallel to the normal rights, that would allow access to the different sections, but this would mix site-access rights with feature-access rights, which would make administration a bit of a headache. As in, everything would still be entirely within Identity, but without any easy way to automatically distinguish between the two major sets. My other option (which I will most likely take) is to duplicate the functionality of Identity (but call it something else) to provide that second dimension of authorization all by itself. That way I have Identity and that second system running side-by-side and each doing complimentary but very different content-access tasks.
No, doesn't work. user.Id is not null, it's the correct userId. However, I tried your suggestion: Argument 1: cannot convert from Project.Models.ApplicationUser to 'string'
What framework are you using?
This should be text, not a video. Downvoted. 
Thanks for the reply. I'll probably be really starting this project back up next week. I'm leaning heavily towards just manually handling it in some way or another rather than fighting with integrating it into Identity functionality. I think it's probably a bit beyond my understanding at this point to tackle in any sort of timely manner.
I like Stephen Cleary's [async tutorials](https://blog.stephencleary.com/).
5
Did you try AddToRoleAsync(addedUser.Id,UserModel.AspNetUserRole)
Thanks, that's really helpful :-)
I am recently working on a SSO project, [this](http://docs.identityserver.io/en/release/quickstarts/1_client_credentials.html) might help you (before the "Further experiments" section). The best thing you can do is check the id_token with jwt.io and verify if everything is in order.
I've just done this at work we are using a mix of roles and claims but have also added a permission system for fine grained control of buttons within views etc.
Don't waste your time with responding in long format. Simply reply with that following: "My rate is $100/hr. Let's set up some time to talk if this fit within the salary requirements. Thanks." If the role pays $100/hr, then it's worth checking out. If it doesn't, it's a waste of time. Only about a third respond.
Alright, tried it. But it is exactly the same exception as the original one. addedUser.Id is also the same as user.Id. I don't know why you believe that to be null. because it isn't. It really is not! :)
We combined a User-Role-Permission system with Claims Identity and custom stores in order to granularize our application. Permissions are a static database table of actionable items (for normalization &amp; reporting). The application uses a T4 template to create an Enum of the Permission table rows (no magic numbers in code). Roles are fluid (admins can add, edit, delete) and mapped to [0:n] Permissions. Users are assigned to [0:n] Roles. When a user logs in, the Identity is created (a cookie is also created to remember the user). A custom AuthorizeAttribute on each controler or action checks the Identity User Id and the required Permission against the database to determine if the user has that permission. No permission? They are simply redirected to the last page they were on, or by default the dashboard page. It's not highly scalable for millions of users, but the scope we were working with is under 1,000 users (no more than 500 concurrent), and we tested it successfully to work with 1000 concurrent users and there was no problem with the authentication/authorization systems. We did run into problems with the SSRS instance not liking that many users pounding it, but SSRS scaling is really it's own set of issues.
If you have a standard one-to-many relationship between the users and the sites, you can just have a foreign key entry for each user defining what they have access to. If it is a many-to-many relationship (any one user can have access to one or more sites), the. You need a translation table in the middle (essentially what Identity uses with Roles) and it might be more effective to have a full second dimension of Identity duplicated for this functionality.
Show parameters in the call stack FTW!
Ok the only other thing i can think of is ur way of seeding the user role manually and not with the rolemanager. I would delete the user roles from ur database and code it in ur project using the rolemanager i put a sample on pastebin https://pastebin.com/vkjwBmCH
It's a big project that I dove in to, I'm not too sure I can screw around with the database. It already has a lot of users, I think I need to sit down with the original developer when he gets back from his trip.
Aha. Good luck buddy! Who added the user role "Admin" to begin with?
UWP is absolute horeshit. Stay away from it.
Will it not use a lot of memory if the file might have more than 500.000 Lines? And I just tested SignalR. But I do not know how to call a function from the Page class.
I've thought about using this, but every time I go to use it a little voice inside of me says "this is a bit hacky".
I know exactly what you mean. In fact, I think that thought was in the back of my mind when I decided to write the post. The conclusion I've settled on is that a) a bit of "white-box" testing can be pragmatic and b) InternalsVisibleTo is the least hacky way to achieve it.
Do you have an example of this on GitHub or similar? I would be really curious to see your implementation.
I don't have a complete sanitized version handy, sorry. Below is a brief overview, but it doesn't have much more than the Microsoft documentation on the topic. Speaking of, [this Microsoft article](https://docs.microsoft.com/en-us/aspnet/identity/overview/extensibility/overview-of-custom-storage-providers-for-aspnet-identity) covers everything you need to do custom providers for ASP.NET Identity. Literally everything. Custom implementations of Identity are sickeningly powerful and simple under the hood, yet the whole system seems to go totally underappreciated. I should also note here that I do not use an ORM, my work is done strictly in ADO.NET so all of my implementations accept ISomeRepository objects via DI. I implement IUserStore, IRoleStore, IUserRoleStore as a layer for the MVC app. The class constructors accept the repository of the corresponding type from the DAL via DI, so my custom stores are really just accessing the normal data layer. public class CustomUserStore : IUserStore&lt;MyUserClass, int&gt; { private IMyUserRepository _userRepo; public CustomUserStore(IMyUserRepository userRepo) { ... } // IUserStore contracts // IDisposable contracts } public class CustomRoleStore : IRoleStore&lt;MyRoleClass, int&gt; { private IMyRoleRepository _roleRepo; public CustomRoleStore(IMyRoleRepository roleRepo) { ... } // IRoleStore contracts // IDisposable contracts } public class CustomUserRoleStore : IUserRoleStore&lt;MyUserClass, int&gt; { private IMyRoleRepository _roleRepo; private IMyUserRepository _userRepo; private IMyUserRoleRepository _userRoleRepo; public CustomUserRoleStore(IMyUserRepository userRepo, IMyRoleRepository roleRepo, IMyUserRoleRepository userRoleRepo) { ... } // IUserRoleStore contracts // IDisposable contracts } I also implement a custom class called ApplicationUser that inherits from ClaimsPrincipal, which just keeps things neat and tidy in my base controller so I can do things like CurrentUser.HasPermission(Enum perm) and return true if that user is assigned to a role which has that permission. public class ApplicationUser : ClaimsPrincipal { public ApplicationUser(IPrincipal principal) : base(principal) { } // Some useful properties to make it easier to look at principal items public string UserName =&gt; FindFirst(ClaimTypes.Name).Value; public int ID =&gt; int.Parse(Identity.GetUserId()); ... ... public bool HasPermission(PermissionEnum permissionValue) { // Either DB check here or call this.HasClaim(...) if you're storing permissions in claims } } PermissionEnum is the resulting enum from the T4 template, but has things like CanViewSomeData, CanAddSomeData, CanEditSomeData, CanRunBusinessProcessOnSomeData, etc etc. The Name/ID fields from the database are the enum name/int value respectively. Finally, the standard MVC template gives you details how to implement your own ApplicationUserManager, ApplicationSignInManager, and ApplicationRoleManager. Mine happens to authenticate against an Active Directory instance.
Is 4.00 still going to be targeting net461 on release or that just still being worked out and changed to netcoreapp/netstandard by the time it's done?
I'm running VS2017 community edition. When I try to add a view this error pops up now. Searching around I found places that said to delete the bin/obj folders - didn't work. I saw a recommendation to delete EFs onmodelbuilding class - that didn't work either. I've restarted VS and my computer to no effect and I don't know where to go from here. Anyone else run into this? Man i'm tired of working through these seemingly random errors. 
Use chartjs, it is a frontend framework.. You could use razor pages to print the javascript data to generate the charts 
So I would use pages within regular views in order to inject the charts JavaScript? I’m still having a tough time figuring out why to use Razor Pages.
I had a good look myself recently and couldn't find anything :-(
.net ecosystem is really lacking :/
It is. I'm hoping it will change now x-platform has official MS support but .NET is still some way behind when compared to the Java ecosystem.
Razor literally just generates html and javascript. Razor pages is for getting the data from your backend and dealing with requests. You can just write the javascript in your view.
With any Javascript library you don't need any backend page generation like razor but you do need a service that returns the data for the chart. Depends on your architecture. 
It should be the default
Yup, I've got a lot of: [assembly: InternalsVisibleTo("LINQPadQuery")] Littered around my Assemblies!
thanks for this, you obviously put in a lot of work on this. i guess my use case would be .net core stack using sql server/dapper/web api angular 4.
This is a good start (made by a contributor), using EF In Memory DB (https://github.com/dodyg/practical-aspnetcore/tree/master/projects/aspnet-core-2/razor-pages-mvc) I have not added it to the readme yet.
add System.ComponentModel nuget package?
He has System.ComponentModel installed. I know this because the exception is in the ComponentModel namespace.
Lively podcasts: https://www.dotnetrocks.com/
Try clearing your visual studio component model cache. It is in your appdata c:\Users\\AppData\Local\Microsoft\VisualStudio\&lt;version&gt;\ComponentModelCache Close your visual studio and delete the contents of the folder
No such luck, I tried this a few times but keep getting the same error. Thanks for the info though.
Have you tried StackOverflow? They are the best resource for this.
I was getting a similar error in VS2017 Enterprise within the past 3 months or so? When I attempted to create a view with a model, it would fail. If I created a view saying Empty(Without Model) it would work fine. At some point, this stopped being an issue for me - so with that said, are you sure your VS is up to date (Tools -&gt; Extensions and Updates)? I keep my pretty updated and I think the current version is 15.3.5 (Help -&gt; About Visual Studio). My scenario could also be completely unrelated but it never hurts to check for updates :)
Use .net core, it is significantly faster for this simple scenario
Sadly not an option the dev supervisors want to pursue, thanks for the suggestion. 
But your other requests should be able to be processed 
It even does not have WCF support.
I’m thinking partial views with a list of my model as the view model will be best. What do you think?
It depends on the charting package. If you go with a pure js solution all you need is an index.html page and web api/service stack/controllers that return the appropriate json. It really depends. You can also serialize your view model to json on the page as another option that is pretty easy to do.
https://github.com/BillChirico/Tipage - This is my repository. I was thinking on using chart.js as it seems to be the most popular. What’re your thoughts on this route? I might redesign my architecture when I migrate to core v2 so I’m open to opinions.
I have never needed to but I believe you can contort EF to front any back-end data model design you want, it can just be painful like WCF is painful. Personally I would develop a facade interface that can make both applications happy and write to that. In the old app the implementation will be a bit of a mess but that does not matter if you actually plan to toss the old system (you ARE really going to, right?). This simple [ef example](https://stackoverflow.com/questions/14390237/using-sql-to-pull-data-from-multiple-tables-and-display-it-in-one-view) is what you can expand upon for you facade implementation. Note that if you have a lot of records and/or you force LINQ to do lots of expensive Joins then this can be a performance hit on the older code-base. Re-sharper can be a lifesaver here as it will tell you if a LINQ expression or use of a generic collection will trigger n+1 or more iterations. 
What is their reasoning?
Why do you need wcf server in 2017? There is wcf client in core
that's because dev supervisors don't have to pay for servers. if you use more efficient frameworks, you can get away with less hardware for longer, which will pay for new dev supervisors.
You are going to declare an action method (standard asp.net stuff) and make it async so that control flow can return to handle other stuff while waiting on the db server. Make sure you set up output caching by parameter with an appropriate expiry time. This is not a hard thing to implement -- don't overthink it. The method signature will look something like [OutputCache(VaryByParam="myParam") [HttpGet] public async Task&lt;ActionResult&gt; MyMethod(string myParam) 
Convert it to json and process it. /s
Why would you need WCF when web API supports xml and Json serializers both? 
What's your architecture? Cloud? Load balancing? What hardware? What volume?
As other have said, the facade or adaptor patterns would work well here.
If they'll let you, create views at the database level.
Write data adapter interfaces that can be adapted to each schema. Just write the concrete methods to conform to the requirements of either schema. Meaning write your interfaces to conform to schema B as necessary and the in the concrete classes consume schema A converting them to schema B. 
You'd be surprised what kind of crap you can hide with new projections, unions, and possibly some select distinct and case statements. Upshot here is that generally you can still take advantage of database indexes to make it somewhat reasonable for performance as well.
Sounds like a case of EF being the wrong tool for the job. Any time your abstraction layer complicates things you should consider another solution.
What are the drawbacks and limitations of .net core in terms of developing a given system, support for deployment in various platforms, IDE, maturity of community. Where do you see .net core in the future, will it sustain the race?
Not the OP but every upgrade has been a major pain in the ass, to the point that for every version I just start a new template and add my logic back in. Obviously this is for personal projects. That would never fly for a Enterprise app
This question is very vague...what performance perspectives are you speaking of? Size of the payload over the wire? Amount of time it takes to serialize/deserialize? Amount of time it takes to parse the XML to do something with it in the webmethod? Also, is this raw XML, or is it an object that will be deserialized? What is happening to the XML after it is processed (is it dumped into a DB? Passed to another processing layer?) Performance is such a broad topic, you’ll get better answers if you are more specific in your end to end description of the operations you are doing.
ASP.NET Core 2.0 has more robust architecture than ASP.NET 4.6 and can run cross platform (currently working on a project on Windows with a Mac collaborator and hosting on Ubuntu). Leverage entity framework to connect to your database. The Microsoft documentation is fantastic. The community is just forming -- here we are. IDE support is there on Mac and PC. .NET Core is everything you don't hate about Microsoft. It's got open source integrations out the wazoo and it's fast and effective to develop with.
Check out Automapper and its Queryable extensions. https://github.com/AutoMapper/AutoMapper/wiki/Queryable-Extensions
Leverage EF? it's hardly a 1.0 release with all the missing features.
Don't think so I've be using SQLite recently, which IS supported by EF. 
There are many cheap options to buy shared windows hosting. Can they run a dotnet core web application? Can you give a couple of examples of cheap options to host a dotnet core application?
I made a system where I make appdomains with a set of permissions (e.g read file permission to C:\test). Since .net core doesn't support appdomains anymore, what can I do to port this system to .net core? I've read about AssemblyLoadContext but (as far as I know) they don't support permissionset. I have read about using the Operating System features for code isolation but I can't find something that fits my needs (specific permissions for code isolation). I'm talking about a sandbox.
You can't. It's not supported in .NET Core.
Did you update to 15.3.4? I had the same problem too but it went away after.
Web API is type-less text based REST crap, not strongly-typed web services framework that supports basic features like WSDL or WS-* standards. We and not PHP so strongly-typed interface contracts please only.
I disagree with the EF bit. Is there any reason to struggle with EF Core, if you need support for stuff like cross-database joins and comparison on nvarchar columns with collation? Sure, it supports basic syntax out of the box, but in an enterprise app, i think you are better off using a micro orm like Dapper.
I've been waiting a while to see something like this crop up. At this point I don't know if I'd rather see something WPF-like, or something built more like Git Electron but with .NET replacing NodeJS/Javascript.
Yes, the UI module of .NET Core is sorely missing! I understand the look &amp; feel won't feel exactly "native", but bundling a web browser with your app and using Electron via .NET bindings is IMHO even less optimal. I think the best would be if [Eto](https://github.com/picoe/Eto) supported .NET Core since it's sort of a .NET world version of Qt that builds the UI with the respective platform's native controls, but it [can't do that easily](https://github.com/picoe/Eto/issues/457). I'm unsure if .NET Core 2.0 helps though. So I guess that's why Avalonia probably has a better future for now _if you have to work with .NET Core_. However, I think I prefer the concept of Eto better, especially now that Microsoft owns Xamarin and GTK# is free and all.
Glad to see some "official" posts about this. I see FAR too many "How do I make a cross platform GUI?" in here and /r/csharp when a 10 second google would have shown them.
I haven't checked in on ETO or Avalonia in awhile so I'll have to give them another shot based on this article. One other one worth mentioning is [Invention.](https://gitlab.com/hodgskin-callan/Invention) It's only Windows/Android/iOS, but really does have 100% code sharing without any tricks. I also like the way that that it treats device resolution, and allows you to quickly and easily emulate different devices and resolutions on the desktop. I'm always open for more options though. Thanks for sharing the link.
Is it still useful if the file is updated very frequently? Then the File Watcher would constantly be called.
Wow! So readonly fields are fields that can only be read from. Fascinating.
Part of the beauty of dotnet core is that it *doesn't* need to be hosted on Windows. Certainly there's no shortage of cheap (and even free) Linux boxes out there.
Yeay, a new WPF! There are too few "WPF-like" versions that does not work like any other WPF.
Microsofts answer seems to be: Use Electron. VS Code and the new VS Installer are both Electron apps.
Was this written by a non-technical PR person?
&gt;training on Do you do actual development or do you just provide training?
To be fair, WPF itself didn't really feel native either. (Which was ok at the time because everyone was getting sick of looking at the classic Win32 controls.)
Hmm, I'm working on a WPF app right now for testing databases. Maybe I should rewrite it to use this before it gets too large.
&gt; while(true) { Thread.Sleep(10000); } and I start my app, and then the NTP daemon on the system changes the clock 500 milliseconds forward, will the thread loop 9500 milliseconds from now instead of the original 10000? Or would it wait 10000 milliseconds even though the OS time has changed? This is calling operating system methods, so it's unrelated to .NET. Besides, you're not saying "wait until that time", you're saying "wait for 10000ms" - that does not change when you change the time. When you change the current system time you just say "now it is xyz", but it does not "roll the time" forward very fast. &gt; Similarly, if I was doing some type of DateTime.Now comparison, would DateTime.Now adjust once the OS adjusts its clock, or will it hold the original timing at application launch steady and just increment that time as the application continues to run? It's not caching the value. It will use Win32 API (or other system APIs for Linux) to retrieve the current time. There's no magic or surprises. Everything happens as one would expect.
This might end up being the most efficient answer, tbh. A lot of the other patterns suggested here are quite similar to what I've already implemented, though without showing off all the code (which I can't do), I of course can't be sure it's not able to be improved. Buuuut it's a small enough program that I may just stick with what I have rather than bother the guy who manages the old db. It won't be too much to rewrite for the next version, and I may end up waiting a while to get him to set up the views properly.
Just make sure you are using mvvm and appropriately separating your UI from the rest of your code. The truth is, cross platform UI is a dream that's gone unrealized for a *very* very long time. Don't plan on a solution until it actually falls into your lap.
Yes and no. First, FileWatcher may not make sense in your specific case. The thing here is to minimize work (specifically I/O here). You could set up a job to read the text file every 15s - but what if it doesn't change? You could be doing a lot of extra work. What if it only changes during business hours? The FileWatcher introduces the possibility to only read when the file changes. But if the file changes every millisecond all the time, that may not make sense. The same is true with an IMemoryCache. Yes, it will have a memory hit, but that's not the point. The idea is to have a single, shared, and quick (RAM vs I/O) way of getting the data. If each web request loads the file into memory as it converts to JSON and returns, each request has a sperate copy in memory - and that will have a bigger hit in memory. In both cases, since I don't know the details, may not apply, but both are examples of trying to do the least amount of work possible (only read data once, shared memory cache, etc). If you're interested, I could put together a proof of concept to illustrate the differences in response time and resource consumption.
I feel like Windows 10 UWP would be a logical next step for a System.Drawing library in .NET Core (I don't know enough about System.Drawing or UWP to know if this makes sense). But it would be great if MS were to unify those two and have a true cross-platform framework that can make some pretty nice UI.
I'm not sure where they are with it, but this was posted a few months ago by an Avalonia contributor https://www.reddit.com/r/csharp/comments/6bp5s9/avalonia_ui_05_released_now_with_net_core_support/dhoi2zi/ If they follow through, you could design an app using Avalonia &amp; C#/Core, compile it to WASM and run it in a browser. 
Is you database completely managed using an ORM like Entity Framework Core? If so you might be able to switch to something like SQLite, which is basically just a file. That being said, most recommend that docker containers do one thing, so it might make more sense to spin up a separate SqlExpress container and hook them up, perhaps using something like docker compose.
Yes, using EF Core, and I am coming to terms with the one role mentality. Since this is just a test app for focusing on other things I really wanted my "one thing" to be a self contained application... I've got it to work by rebuilding the whole app as a /windowsservercore image and copying the aspnetcore Dockerfile. Definatly not the best practice design. I'll look into a Docker compose next
Oh, I don't disagree. I do the same thing with my companies app for when I design our "demo-in-a-box". This used to be a virtualbox VM that took up about 40-60gb, now i can use a significantly smaller windowservercore based docker container to host IIS and SQLExpress.
Microsoft's official answer is use Xamarin.Forms, as discussed at .NET Conf 2017 https://channel9.msdn.com/Events/dotnetConf/2017/K111 
The official suggested one is Xamarin.Forms, as discussed during .NET Conf 2017 keynote. https://channel9.msdn.com/Events/dotnetConf/2017/K111
System.Drawing is being ported to a compatibility library for UWP, starting with Windows 10 Fall Creators Update. https://github.com/dotnet/corefx/issues/20325
System.Drawing is actually not going to support UWP. It would require a full rewrite because GDI+ is not available there. (I'm the dev working on System.Drawing at the moment).
The choice of the framework itself will need to answer a lot of questions about what you're trying to achieve, scale of the application, etc etc. But if you're just looking to start with frontend, I'd recommend angular because it will be a lot easier for you to learn as a .net developer. There's nothing that react can do that angular can't and vice-versa, all mainstream modern day frameworks are equally capable of achieving the same thing, it's just how they do it is different, X framework may do it a bit better than Y. If you have some background in JavaScript, then check out VueJS as well. 
I thought he was shown the door for not working nicely with the people with the "UI vision" that gave us Win 8.
Thanks so much for the feedback. Do you have any recommended resources for learning angular? I was thinking of taking this course. https://www.udemy.com/the-complete-guide-to-angular-2/ Would it be easy to pick up React/Vue after getting Angular under my belt?
You say /s, but I largely agree - if, of course, you can get JSON in the first place using `accept/json` or something.
Why don't they use it then?
No they will not be processed because the main thread is waiting for the other task to complete. So it can not do anything.
Just FYI I found that course helpful when learning angular 2 so I would recommend it. 
So why it is part of the recently announced "Windows Compatibility Pack for .NET Core" to be released as part of the Windows 10 FCU? Containing: * Microsoft.Win32.Registry * System.CodeDom * System.Configuration.ConfigurationManager * System.Drawing * System.Runtime.Caching
Most likely because support for GNU/Linux, WPF and UWP is still work in progress, to be finalized by the upcoming major release.
If you use a sync that's not how the default kestral server middle ware works. There's not a single thread for all the requests. That's how node works, not .Net. 
can't speak as to much with my experience with react but you'll feel right at home with angular coming from .net developer background. there also seems to be a developer issue with facebook/react licensing issues too. 
I recently had to work with an api that was xml only and it sucked. Looking at Tempo for Jira. It was horrible!
Yes.
Por que no los dos? juejuejue
No.
There are lots of O/RM options.
In general it looks like you followed the examples. On first look, you may consider using scoped lifetimes for items that you want per request as you typically don't need to keep creating them (transient). Also, if you are going to use AJAX to build the charts you'll want to add some ApiControllers. We standardized on Service Stack so I prefer a slightly different architecture but I think you're on the right track. For the front end you might consider something like vuejs or angular (vuejs is much easier to learn). 
Docker serves this purpose for .NET Core. https://www.docker.com/
All you need is a device (any device) and a public static IP address for the device (port forwarding, dns records). Any cheap linux VM in any cloud can do it.
Development is proceeding rapidly, don't throw out the baby for the bathwater.
For reference: The [first "worth 1000 words" image](https://cmatskas.com/content/images/2017/09/ef-core-compiled-queries-1.png) showed a 53% time reduction. And then the [follow up image with multiple runs](https://cmatskas.com/content/images/2017/09/ef-core-compiled-queries-2.png) showed anywhere from -28% to +42%, for an average reduction of ~6%. So YMMV.
What would you suggest doing after the course to continue learning? Just build side projects?
We are still finalizing the compatibility pack, but ultimately some of these components will not support UWP. For example, the registry cannot be used from UWP -- it is fundamentally inaccessible. It will primarily be a compat pack for .NET Core, but from what I understand some components will be targeting .NET Standard instead (and so will be usable in UWP). System.Drawing is going to support .NET Core on Windows and Unix, but not UWP.
Yeah definitely. The course will take you through the main features of the framework, which is all you need to get started. You’ve just gotta start putting stuff together after that. 
I believe a lot of the wait x amount of time probably uses the environment tick count most likely is not affected by changing time and is instead more related to system uptime Edit: carefully when using the 32bit tick count as the documentation says once int32.max is reached it uses min next which is negative. They have a method for getting the 64bit into count instead https://msdn.microsoft.com/en-us/library/system.environment.tickcount(v=vs.110).aspx 
I started to read it and I am liking it so far. I am even sharing my progress on a github repo. I would really love to see an F# version too.
I hate how Entity Framework is practically inseparable from Identity. We have a proprietary, carefully crafted and more easily maintained data access layer that is not a candidate for replacement. Also, this article is nice, but the explanation for .NET Core's existence is singular: it's better than a pure javascript backend. I guess I'm just not the target audience since I'm a .NET dev and I've never worked in a full javascript stack.
It's really hard to get away from Entity Framework, though, with all the Identity classes touching EF namespaces. It's a chore to avoid using, as it has been since MVC. I never bought into EF or Code-First/Migrations; we've got our data in just the shape we like it already, and we have a data access API for it. I shouldn't feel like a rebel because of that.
EF has it's quirks but it is solid code.
I read that facebook has literally never exercised their patent clause. It's a non-issue.
It's easy to learn and fun to code with but our software quilt is database-driven. I don't want the EF-generated tables (aspnetuser, etc), I want to be able to add columns and tables without having to rebuild everything and perform a coordinated rollout. I don't want to be forced into role-based authorization. Have you done any custom auth stuff outside of EF? I'd be interested in some of that wisdom.
Angular uses Typescript whereas React uses JSX and Vue uses ES6 (with support for Typescript and JSX) If you want to futureproof yourself in the world of JavaScript, I'd say you study JS itself, once you master JS to some degree (not necessarily super deep) you'll be able to switch frameworks with ease.
Then I feel mislead by the information transmited at the .NET Conf keynote, which lead me to mislead others as well.
I don't know a lot about auth, sorry.
I hated front end. Ive worked with AngularJs, KnockoutJs and a few others and disliked them all. I tried angular with typescript and I have to admit I was impressed. Coming from a .net background I felt right at home. I've got a popular open source project that is using angular 4 with typescript if you are interested in some sort of side project.
Yup +1 here it just feels natural for a more backend developer 
I'd go the opposite way. React is much easier to understand and to work with (also from .net POV). I'd suggest a good training course and you are good to go (learned from Pluralsight-it goes from setting up the environment to coding and unit testing). 
One API I worked with (Feefo, for the record), returned horrid JSON... not sure if they've upped their game yet - but rather than serialize to JSON, they converted the XML to JSON and the result was not pretty. Glad we dumped their shit.
I honestly tried to do that first for my project just to make it easier to deal with but it ended up just being more of a hassle. There are xml serializer I just didn't want to have to deal with them. I complained to Tempo and their answer was, we are working on a new api and we won't provide any eta's of course. Their current API has no get record by id (laughable) you have to query records by DATE and then parse it out of the xml. Fun right.
Just read the intro page and scanned the first few after that. This looks brilliant. ASP.NET Core is the only reason I'm on this sub. I come from a Rails and Node world, and the idea of using this on Linux sounded great. I set up my Arch dev machine for it without too much trouble, but I had to learn through blog posts and Microsoft's unfinished docs. It was very hard to find the Linux specific stuff. But this book looks so polished and explains the basics well. It would have saved me so much time and effort. I'm definitely going to use this as I continue.
Nonsense, look at what it turned into W10 is awesome. 
As the author has kind of alluded to - these results are likely a little bit misleading. The performance increase is from saving building the expression tree - and then using that to lookup the generated sql (or something like that) and having an immutable query at that point. We used these quite a bit with ef 6 and found to be effective - we had to preexecute the query with default params to not pay the “hit” at runtime - which would cause the query plan to be cached. These were supidly large queries - and the bulk of the time was plan compilation vs expression tree translation. Admittedly- I haven’t looked at the test code - but without creating a new db between test runs or using either the in memory or potentially the sqlite provider it’s not eliminating the the first run “hit” - although the numbers look suspiciously like our findings with ef 6. Nice to see this feature - but it’s not the panacea that it’s made out to be.
&gt; I had to learn through blog posts and Microsoft's unfinished docs Which docs were unfinished? Are they still unfinished?
I've been a developer for a little over 5 years, and I'm honestly embarrassed to say that I only understand *maybe* two of the articles from the front page based on their titles. So many concepts that I had no idea even exist. How do you guys keep your skills up to date, especially if you work in a dev shop that doesn't use the latest and greatest?
Go for React. Much better maintained, thoroughly updated and regularly used by some of the best companies in the world.
PM'd
Don't be embarrassed. I usually only read the articles that are related to my work and only read the others if I am feeling adventurous. The low-level parts of the CLR may be interesting, but I don't understand any of it and it doesn't really apply to me. 
Neither. I'd rather roll my own all day everyday. Angular is a rockstar at making the DOM impossible to read. React Is better and easier to read in my opinion, but still you have Markup in the JS and CSS in the JS. Plus its tied to Facebook...
You might consider vue as well. It is a really nice framework with a smaller learning curve. 
Unfinished might be a harsh word to use. What I mean is multiple comments are at the bottom of the tutorials posted that mention problems people had. And the tutorials were scattered around. It was hard to find a complete set of tutorials one could use for Core on Linux. Some things I only found VS on Windows tutorials for. And I had to search and use blog posts to fill in those gaps.
I'm surprised nobody told you that they are actually apple and orange. Choosing between Angular (2+, not AngularJs) and React is like choosing between ASP.NET MVC and Razor. Angular is a full framework that includes everything, and they are designed to be fitting each other. While if you go with React, the only thing you have is View Components. You will need to choose other components to make a complete SPA (things such as routing, state management, etc.). This gives you more flexibility, but things could be a bit overwhelming at the start, especially for new-starters like us .NET devs.
This feels like a problem solved by selecting the "windows integrated security" button. If you want mixed AD/ASP.NET auth then you need to build something (or search for where people like me have done it....)
I've used both professionally, and here's my quick take on it: If you're working professionally, you'll probably end up using angular. There's a few reasons for this, but basically it boils down to: Telerik doesn't have a good react library ([yet](http://www.telerik.com/blogs/kendo-ui-for-react-in-2017)), and there's pretty strong tie-in to angular from .net (project scaffolds, etc). Some companies are also concerned about reacts licensing issues, although [it's questionable](https://blog.fossa.io/dont-over-react-to-the-facebook-patents-license-629f708f2221) that's really a significant issue. ...but, if you're just hacking away on side project, I cannot strongly enough encourage you to pick react to play with. There are three reasons: 1) Angular sucks ass at making libraries, and the 3rd party react ecosystem is far better. I'm not going to go into it, but modules are a pain in the ass to write and maintain and test, and as a result the 3rd party ecosystem of angular components isn't very good. https://material.angular.io/components, or pay $1000 for the telerik components. That's really your choices. For react, you just have to search. You want a tree? https://react.rocks/tag/TreeView &lt;-- take your pick. You want a dynamic lazy loading auto complete? `npm install react-select --save`. Take [your pick](https://github.com/brillout/awesome-react-components) from 100s of prepare stand alone isolated components that you can just drop in. 2) *sigh~* angular2 vs angular is still an issue. Basically, any time you find any tutorial or help you *still* have to check if they're talking about angular or angularX. It can be pretty frustrating, especially on stack overflow. 3) React-native I know native script exists, and a quick google will explain all the 'nativescript vs react native' issues to you; but my $0.02 is: react native is god damn amazing, heavily used in production and lets you leverage exactly the same tools to build desktop, mobile and web apps. Nativescript well. It's certainly a thing. I'm not going to judge, since I haven't used it heavily, but try these two google search results "nativescript 2017", "'react native' 2017" and have a look at the results; you may see a trend. Basically; after using both, my take is: - composing angular applications out of small reusable building block is harder than using react. - using little 3rd party pieces with angular is *much* harder than with react. - the native story with react is much better. - the community working with react is much larger - the 3rd party ecosystem with react is much bigger - ...but react sucks hard if you want to use typescript. If that's a deal breaker for you, pick angular. (but ES6+ isn't that bad, really, if you already use js heavily; and if you don't want to use typescript, stay the heck away from angular). ...but, ultimately, I recommend you try building a little 'todo app' front end in both and see how you like each. You should try vue too (I haven't used it much, so I can't comment, but it looks very good too). 
So I should be using transient services for the services? Also, you think angular would be a better front end framework then using the razor views?
I was saying you should consider using scoped or per request. You might read up on the difference between per request and transient. Angular v. Razor. That depends on your front end. If it is pretty simple it might be overkill. My preference is vue but that's just a preference.
Been trying to get this working all day. If i want to call one controller constructor from another controller what value do I pass as the IOptions param?
Thanks so much for the thoughtful and thorough reply, it's really appreciated. In your opinion how difficult is it to pick up React/Angular after getting the hang of one of them? At the end of the day I'd like to learn both.
What pluralsight course do you recommend, I've been a subscriber for a bit?
No problem at all. The initial scaffolding is a bit of a pain, but if you use [angular cli](https://cli.angular.io/) or [react starter](https://github.com/kriasoft/react-starter-kit/blob/master/docs/getting-started.md) you'll be up and running in no time. The syntax is a bit different with angulars decorators and reacts jsx, but ultimately what you're learning is about how to create applications using component composition instead of MVVM, and that's the same in both. There's a bunch of blog posts out there about this, but this one in particular I thought really hit the nail on the head of 'getting it' about using component frameworks: https://medium.com/@dan_abramov/smart-and-dumb-components-7ca2f9a7c7d0 
After reading up on the different life times, I should set my shift service to Singleton correct? This way each request is using the same one and it doesn’t have to spin up a new connection each time. The other two services are there by default and I should probably just remove them as I am not going to use them.
Have you tried Vue?
I really liked the simplicity of compiling a program with ConfuserEX but after I started using signed clickonce with some of my apps I gave it up as it complicated things a lot. Dotfuscator looked pretty powerful but way more cumbersome and complicated than ConfuserEX
The documentation around .net core in general is super confusing right now. It's hard to tell if you have found something from pre 1.0, 1.0, or 2.0. All most of pre 2.0 does not work.
If you want to implement authentication / authorization, you can see [this](https://github.com/tugberkugurlu/AspNetCore.Identity.MongoDB) MongoDb implementation, and just swap with your favourite orm for data access. I alao used IdentityServer to configre a SSO (single sign-on), and in that case it was just a matter of registering the correct interfaces with their corresponding implementation (IProfileService, IUserManager etc). I am not sure, but i think that the same pattern can be applied in your example.
This is great. The sections on testing, azure, and docker were great. Too many tutorials and quickstart guides miss those bits.
This is great! I literally just setup a VM environment to learn web development with asp.net core 2. (I've been developing desktop for last decade or-so.) So thanks!
Read the docs. There's a whole section on security and auth. Oauth likely isn't the way to go here, that's mostly useful for creating trust between two 3rd parties, you just want cookie based authentication
Learn MVC because it enables you to build scaleable enterprise web applications. Model-View-Controller architecture represents a systematic way of expressing the methods for handling URL endpoint HTTP events. As enterprise applications grow, the natural tendancy is for technical debt to cause a logrithmic velocity growth. With SOLID MVC architecture you can maintain linear velocity with scaling growth. This means you stop getting in the way of yourself. See also: Model-View-ViewModel. Frameworks like Angular.js and WPF (Windows Presentation Foundation) act as clients for MVC backends with a REST (representational state transfer) interface in many of today's popular enterprise architectures.
I've seen and played around with it but not used it properly
can you link to the sources of your open source project please? I'd like to see what the code of such a project looks like. 
The shady licencing makes me very wary about react. 
https://github.com/tidusjar/Ombi Still a work in progress.
I could try both ways and test which one is better. But my current problem is that I cannot get the current page within the Hub Class. The lineEnd variable that I use cannot be accessed.
Very well done. I have one remark, though. For deploying the .NET Core apps with the Docker, you should use "dotnet xxx.dll" command and dotnet runtime image instead of full SDK For example https://github.com/noordwind/Collectively.Api/blob/master/src/Collectively.Api/Dockerfile And before you can build a Docker image, you need to publish the application using dotnet publish, for example like this: dotnet publish --no-restore ./src/Collectively.Api -c Release -o ./bin/Docker
I think you won't regret it :)
You don't. This is why the core stack uses dependency injection for most of the stuff. If you need to access a different controller because of a feature, then you need to extract that feature to a service/helper class *Opinion built up from many many different AspNet Core posts/blogs/projects.
You probably want scoped for most things especially dB related activities. Singleton is fine in cases where the same instance can work for the entire app (not dB). 
MVC represents convention over configuration, wherein all the models, views, and so on are to be found in a default, logical place. It makes it very easy to someone else to understand where to find things in the application. It also represents opinions on where code should "live". For instance, heavy models, lightweight controllers, and so on.
Thanks! Don't worry I didn't expect it to be fully finished. Open Source Software is always a work in progress IMO. ;)
I'm a seasoned .NET dev and find the docs confusing, I left a comment saying this will leave newcomers bewildered.
Even worse, some of the samples are outdated.
It never ends!
Ok....?
Indeed! But your project is already really advanced, congratz! 
&gt; better than a pure javascript backend. As someone who has been working in C# since 1.0, that seems like a very low bar :P
There might be a way, we have EF code-first data contexts that we share using nuget packages. Any chance you can switch to code first? There is a wizard to generate the code first from an existing database.
Glad to hear someone's doing it, at least. Unfortunately I can't switch for now--dealing with lots of legacy stuff and management isn't comfortable with code first. It's my goal for new projects though.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/csharp] [\[xpost from \/r\/dotnet\] Nuget pack'ing an EF context along with class library](https://np.reddit.com/r/csharp/comments/71r9wv/xpost_from_rdotnet_nuget_packing_an_ef_context/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
All I can say is good luck. I looked into the code briefly and man is it convoluted.
What do I get if I call within the next 30 minutes?
WebForms and MVC were built with different visions A lot of people had a bad time with WebForms. Even when it was their fault for doing things wrong, they would blame WebForms for the problems. I felt that the first couple versions of MVC were way over-hyped but the people who hated WebForms loved it. Aside from the times when people did foolish things, I had a good experience with WebForms, part of which was knowing when to just use an httpHandler instead of and aspx page. I've said in other threads that being WebForms is not sufficient reason to rewrite a project, but I don't think new projects should be started with WebForms. One thing to keep in mind while making the transition is that both WebForms and MVC run on asp.net, so lots of low level stuff is the same. 
If you use the wizard and generate an empty migration, you will have essentially the same thing but without the nasty edmx files. &gt;management isn't comfortable with code first Its more a technical issue than a management issue; what sort of reservations do they have? ...I just re-read your post, you are packaging the edmx files? That seems odd, shouldn't you be packaging the dll from the project that contains the edmx? 
nuget pack puts the DLL into /lib/$targetframework and puts the *.tt files into /db/ (edit: this is where they live normally in the project). I was not packing the edmx originally (and I tried it for the heck of it with no difference in outcome). I was wondering if the generated class files from the context are getting merged into the resulting DLL and VS just doesn't know how to find/reference them.
Bingo? . &gt;upgrade Its a downgrade of a lot of things in return for being cross platform. An acceptable trade-off if that's what you need. 
&lt;comment obligatory="obligatory"&gt;relevant username&lt;/comment&gt;
here's a tree of the resulting nuget package: Package │ MyLibrary.nuspec │ [Content_Types].xml │ ├───content │ └───DB │ MyData.Context.tt │ MyData.tt │ MyData.edmx.sql │ ├───lib │ └───net461 │ MyLibrary.dll
Do you work as a developer? IF so, how old are you? If you are young, learn MVC. The .Net world is moving that way, learn is just to stay current and revelant professionally. If you are middle-aged: If you want to keep developing new stuff, learn MVC since that is where most environments are going. If you want to maintain stuff, don't learn MVC. There will be a shortage of people who understand WebForms and can maintain them. If you want neither, then manage the young MVC coders, and bring your wisdom with you. If you are elderly: OMG, retire!
This isn't 100% accurate. React has a companion router framework and if you decide you need state management, most people use Redux. That integration is extremely well documented and tested. I'm currently reading [this article ](https://css-tricks.com/react-router-4/) about the latest version of React Router since I'll be using it soon.
VBA shares some things with VisualBasic.net Moreover, the logical thinking of excel and access will transfer. There's still a lot of learning and work to do, but I'd say go for it! Find a user group near you though, it's tough alone
I love the content... But please go to YouTube. Their player is more than meh. https://youtu.be/yecu4g5JYB8
A is true in the sense that if you know one programming language, you can probably learn another.
In .Net, Application_Error was so simple to use.
So kind of odd question because I have been out of the whats new in .Net loop for a few years. I have a standalone application (not web based) that I have to maintain for Mac and Windows and my boss now wants to add linux support. I was going to look down the Xamarin route with .NET Standard to try and unify code bases. A friend is telling me that i may want to entertain the idea of a .NET Core app with a GUI front end that is all run locally on the users machine. The GUI itself isn't very unique so i don't think I have any real limitations by using javascript and HTML as my front end. What are your thoughts on this? Seems really odd to run an entire server locally for the user to use my app, but a 98% unified code base sounds really nice. Edit: Missed a word
Xamarin is a UI framework for Android, iOS, Windows Phone, TV, UWP, and Silverlight (and Mac + Linux, I stand corrected). Go with .Net Core for platform-agnostic program execution on Mac+Linux+Windows. https://forums.xamarin.com/discussion/67734/whats-the-relationship-between-the-xamarin-and-net-core
It's faster, too.
Cool so you don't see any problem with bundling the whole web package in a standalone non web app? This would make my life a lot simpler. My main concern is with app start time. (Waiting seconds for a server to spin up would be a downgrade for my users) GUI responsiveness is my other concern but being run on localhost might fix that. Thanks for your answers (Also Xamarin has macOS support as well as Linux on the horizon according to the .net conf keynote)
[Getting Started](https://docs.microsoft.com/en-us/dotnet/csharp/getting-started/) [Technical Schools](https://www.ntc.edu/programs-courses/all/technical-diplomas/IT-microsoft-NET-programmer) [Textbooks](https://www.google.com/search?tbm=shop&amp;q=o%27reilly+c%23&amp;spell=1&amp;sa=X&amp;ved=0ahUKEwjpqe3ZsLnWAhVj0oMKHSjdDIgQBQiMAygA&amp;biw=1050&amp;bih=1550)
A locally hosted webview is a great way of making sure your UI is responsive and usable cross-platform -- i.e. Steam. That's the .NET Core way of doing things. Mono is another approach you should check out. http://www.mono-project.com/
You can implement your own stores and avoid using entity framework. I'm currently using a set of store implementations that use dapper. 
Thank You very much for these resources. Exactly what I was looking for. 
Neat, thanks for the info. I'm going to give the .NET Core another look, seems i may have been to quick to judge it as being useful for web apps only.
"Every app is a web app!"
I want a Channel 9 app for Apple TV already! I was fortunate to watch most of the three day conference live and loved it. So much great information. It's so nice to get all the little why's and gotcha's that aren't always included in the documentation out there. 
[Building Secure Web Services](https://msdn.microsoft.com/en-us/library/ff648643.aspx)
The C# source code should be portable enough. You might have to write some adapter/facade types. Use SQL Server if you can afford it, otherwise MySQL is a perfectly good option. Migration projects like this go through a few phases: 1. Environment Setup 1. Data Migration 2. Client Migration 3. Quality Assurance First, set up the new environment. Get your server up and running, set up your database, set up your web deploy. Now is when you validate that your O/RM doesn't have weird bugs, etc. Second, reverse engineer the database schema of the Access application. Re-create the schema in SQL Server or MySQL. Export CSV files for each table in the Access DB. Import them into SQL Server or MySQL. Migrate other database objects as needed. Third, re-write your client using ASP.NET and JavaScript using your new database server as a data source. Fourth, continuously validate quality. Bugs are always out there and it will take some time to stomp 'em. * https://docs.microsoft.com/en-us/ef/core/ * https://en.wikipedia.org/wiki/Software_testing
I had a similar plan in my mind. I guess I'm still wondering about how to write an authentication component based off the existing database. Do you have any suggestions?
[Introduction to Identity on ASP.NET Core](https://docs.microsoft.com/en-us/aspnet/core/security/authentication/identity?tabs=visual-studio%2Caspnetcore2x)
Hey I'm coming across your post from the point of view of a Django developer moving to dotnet. I've been using Django for 8 years and am about two weeks into dotnet. I'm astounded by how low-level things are over here. There's an ORM in dotnet, sure, but it is lacking in joy. It feels like a clunky mashing together of existing low-level primitives that mostly resemble what an ORM is for. But reading it, would I be excited to use it? No. None of the developers here are, and I'm not surprised. My first task was to make edits for a simple edit form. Opposed to defining a neat little forms.Form class, I'm writing things like this: EmailTemplateTypes = Enum.GetValues(typeof(EmailTemplateViewEnum)) .Cast&lt;EmailTemplateViewEnum&gt;() .Select(x =&gt; (x.ToString(), x.ToPrettyName())); Wow. I would expect to write something like this _once_. Bury it deep in a base class and let every view extend from it. In fact somebody else should have already written this. But here, it's considered standard. When I bring up a better way I get arguments like "we don't do this too much so it's not worth the effort" This ecosystem feels bogged down by its past. It spends time explaining to developers how this is different any maybe better than Web Forms, an abomination spawned by desktop developers who tried to apply their existing stateful model to the stateless web. Not to shit too much on dotnet; I am very excited to see how performant a compiled solution can be. I'm rather excited to be working in a strongly typed environment. I'm sure there a lot of great stuff I haven't seen yet. But as for Django, well it has the benefit of starting from scratch. It wasn't trying to port over an existing legacy framework, it worked with the current state of things. Whereas Microsoft came up with SOAP ("simple" is the last thing that should be used to describe it) and XML, Django used what came out of web developers on the ground: REST and JSON. The Django ORM, form classes, so elegant. Pared down to the absolute minimum and a joy to work with. Overall, you shouldn't be surprised at how much better an environment Django is. And to be fair, Django is starting to show its age so we'll be saying the same thing about the next framework in 5 years. For instance its whole template system is fairly obsolete, these days the modern approach is to use DRF to return JSON to an Angular front-end. Django provides poor support for front-end setup: collecting static assets, compressing and minifying are gunky. Not nearly as nice as what's coming out of the Node community. 
https://github.com/giorgos07/Daarto
You can write your own identity provider, however bolting it directly on top of your existing tables could be tough.
I put together a quick sample (not knowing what your app looks like - this is VS 2017, .NET Core 2) of an app that reads an 800k row file at startup into memory and then the API methods return *paginated* chunks of that file. It seems to go quickly enough that SignalR or any other tech isn't necessary. If it's not paginated and you return 800k records to the front end, it takes a while.... because of 800k records. https://pixeldra.in/u/B0mZqk
I probably should have uploaded that to GitHub or the like for ease, sorry about that.
Same issue here, haven't seen a solution yet. Will post it on the Jetbrains support site.
The short answer is that you really don't need to. Learn how to pass your server model off to the front end, route, and stop there. MVC stops being helpful around the time you need to do more than show a static page and need it to be maintainable. For everything else there's WebApi
Update. Net standard 2.0 is automatically being run with netcore2.0 clr which was not supported by dotCover back then. It is now.
Depends what your goals are. If you never plan on using your web api with a mobile/desktop app, then do cookie auth. If you do plan on mobile/etc, then use jwt token auth. Jwt will take a bit more effort than cookie auth, but it's probably worth it, tbh.
If you didn't find this yet, you can use something like private void UserControl_LostFocus(object sender, RoutedEventArgs e) { if ((Keyboard.FocusedElement as Control).Parent == ParentPanel) e.Handled = true; } where ParentPanel is the grid or whatever you use to hold the content in the usercontrol. If the various controls in your usercontrol isn't at the same depth you'll need to add some more comparisons. Edit: That's assuming it's your own usercontrol. If it's a closed usercontrol (which is probably more likely now that I actually think about it) you'll need something like private void UserControl1_LostFocus(object sender, RoutedEventArgs e) { if ((e.OriginalSource as Control).Parent == (Keyboard.FocusedElement as Control).Parent) e.Handled = true; } again requiring the controls to be at the same depth and in the same container, otherwise you'll need to do a little more work.
I'm new to the .NET world, coming from open source. Web Forms was the wrong approach from the get go, built to satisfy platform developers used to stateful applications. The foundation of the web is that web applications are stateless. The server doesn't need to know about the state of the front-end. If a user has checked this box or that one, the server doesn't care; not until they click submit and you wrap it up in a form body. This idea of your app sending constant AJAX requests to the backend to alert it to insignificant user decisions makes my skin crawl. HTTP requests are (relatively) expensive, you don't want to make them until necessary. Learn MVC because it's designed around the architecture of the web. MVC more relates to code organization than what I'm talking about, but the two go hand in hand. Learn it because all modern development is centered on it. It will prepare you for single page app development with Angular.Js, React, Vue.Js, etc. 
Isn't webAPI gone in .NET Core? I was under the impression they just rolled it into MVC... and also isn't webAPI essentially just using the "C" of MVC anyway? When I make a webAPI project in visual studio it always dumps in model and view folders that I just erase anyway
Most of the project I develop for is essentially a single page that has dozens of elements that need to be updating constantly... either by user interaction or by signalR events telling them to update. Would MVC simplify this or does it not tackle the problem of my million AJAX partial-postbacks? It seems trivial right now with webforms when I can just wrap a handful of controls in updatepanels and not have to think about writing a bunch of javascript
I find myself asking this question now mostly because I see .NET Core releasing and becoming more popular, and ASP.NET WebForms aren't getting any more development. A lot of things I use like SignalR, hangfire, etc. are transitioning towards .NET Core so my familiar stomping grounds are shrinking whether I want them to or not
It's gonna be a lot of work to migrate. You'll end up writing front-end code that gets the data from those dozens of elements and POSTs them to the backend. How that is triggered could be the user clicking 'Save', an automated save on element change, periodically saving every 5 seconds, etc. &gt; It seems trivial right now with webforms I mean, of course it does because that's what you're used to. I assume the scale of this app is not very large, such that these millions of AJAX requests aren't bringing your server down? Then what's the point of migrating? That would be probably the least fun way of trying to learn MVC. If I were you I'd learn with a hobby project. 
Its worth noting specifically it was relicensed today to fix that.
I like it.
I'm not necessarily looking to migrate now, just getting an idea of what I will most likely be heading into in the future. I like to rewrite code, I get a buzz from making something more efficient than it was, and if mvc will give me any of that I'd try it out. My website isn't "large" at the moment but there's a big chance its going to grow rapidly in the near future and clunky stuff is going to give me growing pains I'm sure.
Always ready to welcome a VBA user into the modern world. With that said: the market for C# programmers is much, much larger than that of VB.NET programmers. If you intend to make a career out of it, move to C# If you really want to make a leap to something that is *becoming* big, you might want to peek into F# before making your decision. While it is a functional language, and therefore *much different* than an object-oriented language, it is growing like crazy. However it can be mind-bending at first, as it is also a very concise language, and the learning curve for you would be much steeper than even for C#.
Ah, ok. I was imagining a work project that would be a chore to migrate. Still, I think it would be better to start from scratch. Learn the patterns, write them a few times, you know. Then figure out how to wrangle your current code in that direction. I am a big fan of Django, and it's got great tutorials. Here's a step by step to creating your first app: https://docs.djangoproject.com/en/1.11/intro/
Thanks will try it out. It actually is my own usecontrol And this solution looks so much better than the last one I tried :)
Thank you this is helpful. I'm planning on having a front facing web app that uses the web api. And then the same web api will be used by mobile apps. But I need to secure the front facing site needs secured as well.
I’d go with jwt token auth then. You could also use both cookie (store your jwt in a cookie) and token auth. However, I think it makes more sense to just use regular jwt auth with refresh tokens, especially if you decide expand your react app into a standalone spa.
Asp.net doesn't have to render the front end. I'm using web api with a react/typescript front end. Personally I think a .Net backend plus SPA front end is a fantastic stack.
Don't. Just use identity and then write a migration routine to recreate the users, from a CSV dump, with their permissions. Someone else here linked the documentation, so I recommend you go read up 🙂
Java and .NET aren't going anywhere for the foreseeable future. Regardless of what node.js hipsters advertise, a quick visit to [Tech Empower](https://www.techempower.com/benchmarks/) shows who rules in performance. Modern ASP.NET is done together with Angular and React, with direct support on Visual Studio. Typescript is mostly designed by Microsoft. All our native UIs on Windows are based on WPF, with some experiments in UWP gaining steam. All relevant Java web frameworks are built on top of servlets, even if there is no need to use the API directly. Also Android isn't going anywhere for the time being.
Why first remove and then add a password? Just overwrite it? Second, you do not send in any string as password to be envrypted and saved. It seem to be a generated password? If it is so, youll have a hard time logging in if it is encrypted. 
I'm not strictly answering any of the questions you've asked with these, but there are a few things to keep in mind. * Node.js is a single-threaded application server that uses Google's V8 JS engine... which has a hard 1.5GB RAM limit. (Source: Heroku's documentation) * Node's package manager lets anyone submit anything, so its packaging system inherently has a lower signal to noise ratio than curated systems like NuGet (.NET, curated by Microsoft) or Maven Central (Java, curated by the Apache Foundation). * Java Servlets and JSP are antiquated technologies; they came out around the same time **classic** ASP did. * Most Java devs use either Spring Web (MVC) or JavaEE (usually Java Server Faces) for server-side applications. * React and Angular are generally referred to as SPA (Single Page Application) systems for a reason. * Microsoft is still updating ASP.NET MVC. RazorPages are a new technology that use it. * Although RazorPages seem to promote mixing code and templates in the same file, a practice that has been frowned upon for the last decade or so. It's one of the reasons PHP gets as much flak as it does. * WebAPI exists if you only need to serve REST services. However, you need to create a project with MVC if you want to set up identity services as you need the login/logout pages from it. * Likewise, Xamarin requires you to have access to a Java and XCode compiler to compile for their respective phone OSes for a reason. * Although Xamarin Forms does have support for desktop OSes as well (Windows 10, OSX, and soon Linux). 
this is how an example was on the web. What do you mean sending a string as password? newPassword is the string with the new password in it.. I have tried other examples too but I can't get anything to work. It is a generated password, which will later be e-mailed to the user, but for now I'm just debugging and stepping through the code.
First off, there is ChangePasswordAsync. No idea why you’d ever remove and then add again... Second off, I think whatever guide you’re following is bad. Here is an official MS one: https://docs.microsoft.com/en-us/aspnet/identity/overview/features-api/account-confirmation-and-password-recovery-with-aspnet-identity
I have tried ChangePasswordASync. Had trouble generating a token. I will try it again!
The token is not supposed to be generated in the same method, it’s supposed to be the one you email to them to reset their password. If you’re generating the token just to immediately pass into the ChangePassword method you’ve done it very wrong. 
why? In what other way can I generate a new password and mail the new password to the user?
NuGet isn't curated. Anyone can build a package and push it to NuGet.org. 
Confusing is what it is: dot.net core, dot.net standard, mono.. ASP.NET MVC, ASP.NET __Core__ MVC... dammit what the hell is going on? Then there is the Xamarin stack which builds on Mono on OSX, but another version is cross platform... Frankly, I'm lost. What is open source, what is closed, what is from Microsoft, what is from the community which is both... man. 1) Node: old time developers hate that shit. Some still believe javascript is not a real programming language. 2) JS is core to most modern web developpement. It is more important than C# in a sense, as you will use it all the time in all projects. C# is unique to .net. I suppose back end work does not need JavaScript at all. 3) For most corporation, web is the way to go as it lower the cost of deployment and maintenance. 4) never used xamarin 5) Yes. You can make an app with asp.net mvc and use all those front end libraries. I use VueJS. 6) C# is amazing. I fucking love that language. It does what I need, how I need it, it supports cool modern stuff like lambda, tuples, dynamic typing, anonymous objects, reflection, etc. Everything you need to shoot yourself in the foot :) I had to work on some java projects. And man. Fuck that shit. I felt like I traveled back in time 1993 office space. Slow IDEs, terrible compilation times, horrible deployment, awful configuration. Searching for help on the web is akin to archaeology. I got gray hairs from those times. What I like about Asp.net MVC, is that it gives me a solid project structure and a no bullshit back end to build any type of front end. I realize by typing all this that most of the praise I give this stuff is based on experience and habituation. I guess someone else could tell you the exact same thing about any other stack.
Quick aside - Not sure what you mean by "the open source stack". .NET Core, ASP.NET Core, EF Core, the Kestrel web server etc, are all open source.
Isn't this a deprecated use case anyway? Generated passwords create friction and additional work on the developer &amp; user. Why not follow the more widely adopted use case of providing a self-service password reset interface? (email encrypted password reset URL that takes user to a one time use reset form)
3) The rise of electron suggests web developers still want to create desktop applications.
I am working on a dotnet core backend with am angular 4 front end. It is my new favorite way to work! Also I use typescript for Angular which is such a pleasure over jabascripr.
&gt; 3) Do you guys see desktop development as a dying field (winform, wpf etc) and everything going in web dev or database or mobile apps ? The fact that Microsoft released a new version of WPF yesterday suggests that they think people are still using it. 
1) As others have said, you seem to be confusing "Javascript" with "open source". Microsoft made .NET and it's related technologies open source a while ago. 2) I'm relatively competent with JS and can build decent single page apps with Angular and/or jQuery. I'm sure somebody who does UI/UX only is better than I am with it. 3) Yes, absolutely. I see the future state of "desktop" apps as hybrid web/desktop apps that can be run locally or have what is essentially the same app accessed remotely via a browser, built with something like [Electron](https://electron.atom.io). Only the most demanding productivity apps would still be true desktop applications. 4) Not an expert, but I have limited experience. Xamarin fans would probably disagree with this, but in my view the apps are a little heavier than native ones, but at least they generally have full native API access unlike JS derived apps. That said, have a look at [progressive web apps](https://developers.google.com/web/progressive-web-apps/). The API isn't quite as complete as native, but it's still pretty vast, and they're still going to be relatively light weight since they're leveraging the browser as a shell. Personally, if I wanted to do a single code base mobile app, I'd probably start looking at PWA for my use case and upgrade to Xamarin if my app is more demanding than a PWA would support. 5) Yes. Using ASP.NET doesn't stop you from using the other technologies you've mentioned. You are probably interested in building a "single page app", but you can integrate JS libraries with MVC based apps as well. 6) My completely biased opinion as that of a .NET developer is that .NET is the dominant platform at this point. Java is still very much alive and well (though this somewhat depends on geographic region), but I see .NET as being the biggest, best supported, and most progressive platform out there. To me it's the default choice for any larger line of business apps. I see NodeJS and other JS backends being mostly good for smaller, simpler applications*. *yes, I know somebody will be quick with some anecdote about the big sophisticated Node app that they work on. I'm not saying you can't build it in Node, I'm just saying your life would have been easier if you had built it with .NET.
 I started in C# and .NET and at some point in my career had to switch over to Java. It was exactly as you say. To me it was like going down the river in a motor boat (C#) vs going down the river in a rickety old boat while whittling oars blindfolded (java). I never felt like I couldn't achieve the same things in Java, but everything was just so much more effort. 
&gt; Regardless of what node.js hipsters advertise, a quick visit to Tech Empower shows who rules in performance. Does it? That chart was a bit incoherent for me. I went there expecting to see .NET core dominate it, but I'm failing to see any sort of clear pattern emerge that points to it.
Don't mail any passwords. You should be mailing a one-time password reset link to the user. 
Don't feel bad for being confused, it's a long and twisted story. To try to clear things up for you, in chronological order of inception over the last 15 or so years: 1) Old/original/full/standard .NET framework is where .NET started. Microsoft would do well to issue an official and formalized rebranding of it to avoid confusion. Since this hasn't happened, people often refer to this as "full .NET", "standard .NET", or "desktop .NET". 2) ASP.NET is the web app framework built on .NET (i.e. it's a subset of full .NET). MVC is just a more modern and specific technology for doing the server side rendering of HTML pages (compared to the old web forms). 3) Mono was a 3rd party cross platform reimplementation of the .NET specifications for language, API, and runtime. Since it's a reimplementation of the original .NET API, it's generally code and even binary compatible with standard .NET. 5) Xamarin is for mobile devices. It's essentially native API interfaces built with Mono in the case of Android and a cross compiler into native apps for IOS. 6) .NET core is Microsofts own reimagining of the original .NET framework. This is their attempt at a true cross platform implementation of .NET (as opposed to Mono, which was originally 3rd party). It was built with the intention of making it leaner, truly cross platform, and more suitable for cloud based deployments. The organization of the API and the way apps are composed/built/deployed differs from the original .NET. Unlike Mono, even though .NET Core is conceptually the same as .NET standard and you're still writing C#, your code isn't necessarily compatible with full .NET. 7) .NET Standard - which is a **TERRIBLE** name, since people like to refer to the original .NET as "standard .NET" - isn't a technology or platform. It's just a specification to allow code bases to target both .NET Core and full .NET, and essentially represents the portions of the original .NET API that have been reimplemented in .NET Core. By targeting .NET Standard, you're building libraries that can be mapped to either the .NET Core or standard .NET APIs. It's Microsofts way of mitigating the fragmentation of technology that came about when they introduced .NET Core. I hope this helps.
Like /u/HerpDerpImARedditor said, you shouldn't email passwords. If for some reason you _did_ email them a password you'd want to force them to change it as soon as they logged in again, which puts you back in the position of having a value that is only usable once... so a one time use token. Look at the MS guide. That is the recommended approach and is guaranteed to work.
Have a look at [ASP.NET Identity](https://www.asp.net/identity). You've got plenty of other (and potentially simpler) options, but this is Microsofts official answer to supporting modern authentication and authorization. I prefer this because you can [pawn the burden of authentication off on Facebook/Google/etc](https://docs.microsoft.com/en-us/aspnet/mvc/overview/security/create-an-aspnet-mvc-5-app-with-facebook-and-google-oauth2-and-openid-sign-on). As others have said, if you want something really simplistic, you can go with good old cookie auth.
"Decoupling of code" is the short answer. With MVC you're making a full separation of the UI code from the application code that feeds data and settings into the UI. 
It's not conceptually gone. You've always been able to do much the same things with MVC controllers that you could with web API controllers, it was just a matter of conventions being applied in an attempt to simplify things. Yes, the API itself looks like it's been unified at this point, but I wouldn't be surprised to see "web API" make a comeback in ASP.NET core in the future. Even if it doesn't, you can still build "API only" backends with ASP.NET Core.
If you know VBA you should be able to understand code in a VB.NET app, and pretty much any programming language will have a lot of the same fundamentals. I think the similarities end once past the fundamentals though. Microsoft provides tons of "getting stsrted" documentation, Google is your friend here.
What do you mean by $600 cheaper per server instance? 
You'll get heavily biased opinions on this anywhere you go. My suggestion is to go with Angular. JavaScript nerds seem to be drawn to React. I can tell you that the learning curve is much steeper with React compared to Angular, and personally I don't think there is much practical advantage. Hav a look at both and see which is easier to comprehend.
Nested Virtualization, because i've always wanted a VM inside my VM. So I can VM while I VM.
I do all my dev within a VM so this feature was huge for me
His point was that traditional Webservices still run on Java c++ etc. Not on node etc. Part of why c# isn't there yet is because fully featured .net stuff just released thus no widely spread usage. I expect this to increase during the second half of 2018 when the first big server backends have their first few experiences with net core on their belt.
Anything you use is going to be a JavaScript framework and not specific to ASP.NET. [D3 JS](https://d3js.org) is a popular and powerful option.
We're the same setup using dotnet core. The tooling is getting much more mature and becoming awesome to use. Overall it's a great stack. 
I'll be really curious to see how well this works with non-primatives.
Build some top-to-bottom apps (for pay, or not) in your spare time to build your competency. Look for jobs that don't demand "senior" level .NET devs. I think most shops in that category would be willing to accept somebody with a different background who can demonstrate competency during an interview.
1) What is the state of .net compared the open source stack today? *.NET has better development tooling and more [SOLID](https://en.wikipedia.org/wiki/SOLID_\(object-oriented_design\)) architecture.* How well C# and Asp.net compare to the Javascript ecosystem out there like Node, ang, react etc is .Net still doing good or node is starting to invade slowly the backend ? is java still used a lot or ? *ASP.NET is very mature. Node is a tool window in Visual Studio in VS2017. Java is not part of .NET, it's a different language.* 2) How good you guys are in JS compared a frontend guy who do just that all day? *Rather than mucking about with [duck typing](https://en.wikipedia.org/wiki/Duck_typing), we rely on [Rosyln](https://en.wikipedia.org/wiki/Roslyn) to help us with types. Use TypeScript for big JS projects.* 3) Do you guys see desktop development as a dying field (winform, wpf etc) and everything going in web dev or database or mobile apps? *Cross-platform development is increasingly popular. Web is the universally supported UI framework. Almost all applications use a web service or two these days.* **Webdev is databases and cross platform mobile apps that primarily run on desktop**. 4) Any experts in xamarin who can talk about how well apps run compared native one or the one made with JS framework like phonegapp etc *Xamarin is faster to execute but takes eons to compile. Webview UI code is interpreted, not compiled, so it makes for a faster development cycle. A good JS engine like V8 can execute JS at rates approaching native speed, nothing to be afraid of.* 5) Is it possible today to make a webiste "as good" or "as modern" in the latest asp.net today compared to React or Angular, Ember etc *Yes. VS2017 integrates the best open source tools out there. Things like node, gulp, grunt, bower, etc. You can install Angular, React, etc. easily from NuGet* 6) What is the state of C# and how popular is it today ? For java Ive been told by some java programmers that java servlets are dying and not used much anymore and that Java is mostly for backend old legacy banks programs etc I'd like your advices on that compared to C# ecosystem or if its better to do everything in JS theses days *C# is in Version 7.0, mature, stable, well-adopted, and increasingly common globally. C# and JS interop is easy so don't be scared.*
**SOLID (object-oriented design)** In computer programming, the term SOLID is a mnemonic acronym for five design principles intended to make software designs more understandable, flexible and maintainable. The principles are a subset of many principles promoted by Robert C. Martin, . Though they apply to any object-oriented design, the SOLID principles can also form a core philosophy for methodologies such as agile development or Adaptive Software Development. The SOLID acronym was introduced by Michael Feathers. *** **Duck typing** In computer programming, duck typing is an application of the duck test in type safety. It requires that type checking be deferred to runtime, and is implemented by means of dynamic typing or reflection. Duck typing is concerned with establishing the suitability of an object for some purpose, using the principle, "If it walks like a duck and it quacks like a duck, then it must be a duck." With normal typing, suitability is assumed to be determined by an object's type only. In duck typing, an object's suitability is determined by the presence of certain methods and properties (with appropriate meaning), rather than the actual type of the object. *** **Roslyn** Roslyn may refer to: *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/dotnet/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.27
[Windows Server 2016 Licensing](https://www.trustedtechteam.com/products/windows-server-2016-standard-oei-dvd-16-core-instant-license?dfw_tracker=22777-&amp;gclid=CjwKCAjwjJjOBRBVEiwAfvnvBL_5ct5BQpXbuAf8ztQp7NNbcIEtuWfA51Cl71lhzYf7grrqX45i1BoCe20QAvD_BwE)
I'm working on two .NET / Angular apps at work right now. I'm still pretty jr, but it seems like a pretty good tech stack to me!
If MS wants to stay current with modern web practices then most definitely they will still support RESTful API services. https://docs.microsoft.com/en-us/aspnet/core/tutorials/first-web-api This covers how to create one with core 2.0. 
I meant to address your followup about a webapi's purpose as well. Sorry. So the C in MVC is control. Generally I tend to think of this in terms of flow control. I make a call out to my workflow's controller and it tells the view what "step" or view should come next. You should not be using it simply for data management, that's a lot of overhead to save a value and reload a page instead of dynamically updating your view through js. Generally speaking I use MVC controllers to serve my view along with a model of information the client should not be able to alter and I want to generate server side. Then I'll make a series of calls to my api to hydrate that view. If actions are taken on the view that wouldn't send you anywhere but have a data change (i.e. single page apps.) The benefit of this divide is clear: separation of concerns by both responsibility and domain. 
Testability is another one of the huge benefits of using MVC over webforms. You are writing unit tests for all of your controllers, right? Testing webforms is much more difficult since the UI and what would be “controller” logic is so tightly coupled together. Also, the postback model of webforms is fundamentally flawed as it attempts to make the HTTP stack behave in ways it was never intended to. MVC aligns almost perfectly with the HTTP stack, thus making it behave like it should. One could argue though, that MVC within .Net itself is too tightly coupled to the UI, and I firmly believe that some sort of service backend (WebAPI, or some other RESTful architecture) should be completely decoupled from whatever frontend UI framework you want to use. MVC controllers are not reusable across disparate frameworks, WebAPI controllers are.
Id rather email the user a link with a hash code for authentication. To let the user set their own password. Mailing passwords is not a good approach. Ok looked like a password generator, thought you wanted to type in the password yourself. Do you encrypt the password in the db? Id look for other sources of saving passwords. That snippet looks old. 
Load up a new mvc ptoject with identity template. Should be built in in visual studio. Working out of the box. Check how they do change password there. Cant remember if they mail out a link to users for password reset. 
[removed]
I've been interested in this as well. Unfortunately, it appears there aren't really any tools for non-Windows platforms right now. Looks like there's an "opportunity" there to develop one.
Would you recommend creating a table to link the user id from the old system to the id in the identity table? I thought I would put a table like that in the application if I used asp.net identity.
If you think you need that data then it's your call. You can also extend the User class which Identity provides, so you could just add a LegacyId field to that. Personally I vote for simplicity, if you can get away with grandfathering a system and starting from scratch, do that. If you need any legacy info in the new system then do whatever seems sensible for the long run.
:P
Thanks a bunch! That's actually a way better idea than I had. Unfortunately, I the legacy data needs to stay.
Thanks for the response - unforunately that did not work (I restarted the site &amp; app pool to test)
The react license was changed to MIT btw
I hope this doesn't come across the wrong way, but I'll address some of your points. &gt; Code First is where you define the DB in code, and then push that definition to the DB server, where the DB itself will be created by the code, from your definition. What you are describing is EF Migrations with Code First/Fluent API. I'll touch on this later, but don't really want to get into a debate. Having used both approaches extensively, I find defining the schema in SQL to be much more productive and successful than Code First/Fluent API. &gt; These are mutually exclusive, and your method is something i have never seen before. When you say they are mutually exclusive, it sounds like you are stating as a fact that it is impossible to automatically generate a Code First/FluentAPI model from an existing database. To prove your statement is false, we simply need to demonstrate how to generate a Code First model from an existing database. I am already aware of using MS Scaffolding and LLBLGen (and the question is if there are other tools that can accomplish this). Just one approach is enough proof. **The approach I outlined steps for has been used on multiple very successful commercial projects I've worked with, some with very complex DB models.** You can't convince me it can't be done, because I've done it. Microsoft provides scaffolding that can generate a EF Code First/Fluent mapping from an existing database. So that alone proves they are not mutually exclusive. LLBLGen can generate a code first model from a database. It's a first class feature and from participating in their community I guarantee other people are doing this: https://www.llblgen.com/pages/EntityFramework.aspx Even Microsoft staff has admitted that "Code First" is a poor name. I can't find the article at the moment, but since scaffolding allows you to generate a "Code First" model from a DB, then it is really a misleading name. &gt; To create the DB first is called DB First. You build the DB in SQL Management Studio, then get Visual Studio to reverse-engineer the DB to the models it needs to do CrUD operations. Either you are referring to generating an EDMX mapping or you are referring to using Scaffolding. I'm not sure which without specific terminology, but as mentioned, I am looking for an alternative to these. So I'll touch on why each of these approaches is not as efficient as using an SQL schema first design. But I didn't really want to get into a debate simply since my experience with all of these approaches is fairly extensive. I used EDMX up until Code First was released and saw alot of the problems with EDMX eliminated, and then about 4 years ago I was fortunate enough to join a team and be introduced to LLBLGen. EDMX doesn't allow changes to mapping conventions without manually editing the XML, but as soon as you generate the mapping to included additional tables or updates, your manual XML edits are blown away. This is one of the reasons they've moved away from EDMX. It's not officially deprecated, but Microsoft has made it clear that it doesn't have a future, and with good reason. Creating a UML model and a Code First model is three times the work. The third part is you have to manually reverse engineer Fluent API from your DB design for any compelx relationships. I've yet to meet anyone who uses Code First/Fluent API that can create a Shared Primary Key relationship without multiple attempts at trying to get the Fluent API right. For complex relationships, it becomes a combination of guessing/googling, testing the SQL generation, and repeat until the resulting SQL schema is desired. It's completely backwards. If all else fails, I'd rather drop $400 on LLBLGen that will automate this process accurately than go back to fighting with Fluent. However, if I'm going to publish an open source project, I don't want to require other developers to have such an expensive tool.
If I recall correctly, you need that if you want to run a Windows Phone 10 simulator inside the VM that you keep Visual Studio.
If you want the cheap route, forget about Azure. The free tier is meant for simple test-apps or for development. It's not meant to host an actual website on it. It also has limitations, if there's too much load on your website it simply shuts down - you don't want that, right? I'd suggest you to self-host a small virtual private server (VPS). Set up your website there. Then you can also use the VPS for whatever other purpose you want - not only your single website. Even 10 websites if you want. Personally I use Linode and I'm happy with them. They start at 5 $ per month. I'm sure there are also cheaper options out there.
Our current process at work is to use DB Projects to maintain the database schema and then generate / regenerate our code context and classes using a built-in tool (add -&gt; new item -&gt; data subgroup -&gt; ADO.NET Entity Data Model -&gt; (add) -&gt; Code First from Database) Overall it works well. Code doesn't affect the DB schema, avoiding the potential migration headache. The code matches a particular "snapshot" of the DB at any given point in time. When changes need to be made to the DB schema the developers change the DBProject, sync the changes to their local or dev environment, regenerate the EF classes, and check in all the relevant changes as close together as possible. Our DBAs then do a sanity check and we're done.
slap a free cloudflare in front of it.
You need to include a sample program demonstrating the problem before anyone can help you.
https://github.com/ErikEJ/SqlCeToolbox/wiki/EntityFramework-Reverse-POCO-Code-First-Generator
There is a better example of this in Microsoft's dotnet-architecture github. The sample project [eShopOnWeb has a generic EF Core repository implementation](https://github.com/dotnet-architecture/eShopOnWeb/blob/master/src/Infrastructure/Data/EfRepository.cs). Notable differences are that they don't expose IQueryable, they expose a List as the result of specification queries. This makes it possible mock your tests against a fake repository targeting a List, and to test your queries directly against a List. When I used this myself, I also added the UnitOfWork pattern with Commit / Rollback and an IsolationLevel. Without that its really hard to do any actual database work.
~~What is the scope of your user control? Is it a single control inside a window? How are you loading the control? Depending on the scenario, you could try the unloaded event.~~ Edit: After rereading your question, the event you want is keyboardlostfocus.
Thank you!
This seems to work better than the older scaffolding. Thanks :)
This is what I’ve done multiple times in the past. You still have actual Azure resource issues to consider (the lowest Shared level will take care of those), but if the domain and SSL are the only impediments its a no brainer. Edit: I meant Shared, not Basic, I got my plans confused. 
He’s using Azure and mentions SQL, so I’m assuming .Net... Unless he’s using Core, Linode will not be an option as they don’t provide Windows hosts. Even if he is using Core the SQL issue is going to be a problem. I’d advise going up to a Shared instance and using Cloudflare to handle the SSL and domain. Edit: I meant Shared, not Basic. Got my plans confused. 
He can keep the SQL server on Azure and host the website on a VPS. Or host the SQL Server on the VPS server too. SQL Server runs on Linux (tho only as a preview).
He *could* keep the Azure SQL, yes. I would not advise it by any means...
As an architect, please don't do this. First, don't make generic repositories (I have yet to find a good reason for it), second, don't make a repository over a repository (EF is a repository). Generic repositories, and repositories for that matter, can get really hard to maintain, especially in complex domains. Developers either implement it correctly and the repository gets massive, or they get lazy, and start reusing implementations, causing a large amount of needless coupling or performance problems. Either way, it's bad. I have yet to find an implemention of repository that didn't fall into either of those two traps (not counting small projects). Also remember that this is a repository pattern over an implementation of repository and unit of work patterns... Abstractions over multiple abstractions is often bad. If you worry about unit testing EF just use Effort (or with core use Sqlite in memory mode). It's closer to a real database then just mocking in memory lists. My solution is to use a light variant of CQRS, which handles my issues with repository pattern, and other developers issues with exposing EF directly.
Why not? 
Usually SQL traffic is unencrypted, mostly. Latency also becomes a much more significant issue when you’re talking round trips to a database. For a normal website it’s probably not a big deal, but you don’t know what he may be doing. Though I suppose with 50ms latency on every query you’ll quickly realize which queries you’re doing wrong, so there’s that. 
As the saying goes, you get what you pay for. They are other options, sure but anything drastically cheaper you will be making some sacrifices for ease of use. You aren't paying as much for simple hosting, anything can do that, but a friendly power platform with a lot of features. To throw it out there, I have the B1 as well, and used to to host one site. Then 3. Now 5. All small, simple apps that me or my friends use. So if it helps, that 55 has become something like 11 bucks a site, all with access to Azure features. I haven't bucked up against an resource limits yet either, not even close. Hope this helps.
OP said they're using core, and it's hopefully likely they're using an agnostic ORM like EF which means their backing database can be anything that supports SQL, not just mssql. A Linux VPS and a free SSL cert from [Let's Encrypt](https://letsencrypt.org/) will likely work just fine for OP.
You’re right, I missed the one instance of “Core”. So a VM could be possible, but obviously more difficult. I still stand by my workaround that keeps him running on Azure as-is. 
This is really just a proof concept, as stated in the post, that's why it exposes IQueryable. Ideally, your web layer would not be aware of database layer, nor would you inject IRepository inside of your controllers. And you could expose IQueryable to your service layer or something like that, to get paging or/and sorting working. It is just a basic generic repository that covers basic CRUD operations. And in no way is that massive. I have seen needs for generic repository quite a few times. You can use generic repository by just passing a type to it and you can then perform CRUD for any of your entities. Of course, everything can be done via dozens of various ways. This is just an example how to do things via generic repository pattern. If your application is more suitable for CQRS or something else, go for it. As with everything, what you will need and use depends on your project and it's influenced by various factors. 
I'd be interested in seeing an example of your solution with CQRS. I mirror your sentiment about abstractions over abstractions, but EF just comes with too much baggage justify releasing unrestrained IQueryables all over your application in all but the most basic CRUD applications. Yes, you "keep it simple" by not destroying EF's unit of work, but you also eliminate any boundary between data access and application. I've reached a point where I just give up with EF. Not to sound like the many fanboys out there that gawk over Dapper, but at least with Dapper, I've been able to implement separate repositories that are all wrapped into a single unit of work pattern, allowing me a separation of concerns and transaction support. I'm just not sure this is possible with EF anymore. I also just haven't ever seen the benefits outweigh the work required to implement CQRS except in large applications that follow DDD. I think it's a great pattern, but not every application warrants that kind of architecture. Even DDD-based applications have areas of basic CRUD; so, how does CQRS fit in there? 
Your first three paragraphs are falsehoods 
&gt; All connections to Azure SQL Database require encryption (SSL/TLS) at all times while data is "in transit" to and from the database. https://docs.microsoft.com/en-us/azure/sql-database/sql-database-security-overview Looks like it's required. But I would agree a Linode to Azure SQL might be slow. Internally though - I would expect the latency in the same datacenter to be lower than 50ms. I might have build a quick app to test it :)
Good to know, I didn’t realize that (only ever used Azure SQL from an EF app in Azure). I expect the latency within the DC to be less than 50ms too (I’d be supremely pissed if it weren’t). I was talking about between Linode and Azure SQL. 
Been googling this option and it seems kind of hacky, but at this point I have no other option so close to launch day. (Tomorrow) Worst case, I’ll bite the $55 per/mo bullet and hope somewhere down the line I’ll be able to take advantage of the multiple instances the plan provides much like [u/fastbreak99](https://www.reddit.com/user/fastbreak99) describes. 
Queries against a List? Can you clarify that? IQueryable is something you use to build up queries, and after you are done filtering you then turn that to list.
I've been leaking toward CQRS in my designs as well. How are your implementations "light"?
I completely disagree. I work at a software consultancy and I engineer very agile platforms. We use Generic Repositories and Generic API controllers, which I've designed. They come in entirely useful... A client started with Azure DocumentDB, and much later decided they didn't like the pricing model, so we changed our registered repo in our app container to a MongoDB repo and changed the entire app to use Mongo with a one line code change and the addition of a mongo settings file. The repo pattern does more than just abstract DAL away, it also abstracts the MEANS of the DAL. Switching or going hybrid with different DB/DALs/ORMS becomes trivial. It makes your projects more sustainable and more agile, when you need to leverage it. It also creates a very dependable design pattern that, when it gets reused across many projects, makes the projects easier to work with despite different DB/ORM stacks. We also use our repos on Mobile Apps, from prototype to production. It's common to start a prototype using an in-memory or on-disk repository, something that uses an Embedded documentDb or something, so we can go to prototype without a backend. When we work on a production release, we finish the generic web api and then swap out our embedded documentDB repo for a Generic HTTP Client Repo that automatically knows how to call our new WebApi, generically. No code changes, just swap types. All of our generics/repos/apicontrollers are available in nuget packages, which makes setting up our data structures in new projects a cinch. When we start a new web api project for instance, we only need to define our models. After that, we just register our generic api controller, and tell it what generic repo to use (EF, MongoDB, DocDb, SQLite, etc) and give it the type of the model, in just a few lines of code. You say "please don't do this" but I argue you've never actually witnessed the benefits of doing it, or did it wrong. 
One of the signatures looks like this: public IEnumerable&lt;T&gt; List(ISpecification&lt;T&gt; spec) Its a heavier implementation in that flesh out a strongly typed class for each fetch plan. The advantages are that you can test each fetch plan separately against a normal list separately from everything else, and you can easily find a list of all of your queries for review or refactoring. The implementation I linked is heavily focused on test-ability and might be a waste of time if you aren't planning to unit test each of your queries. I see the value in it because many plans as a team to unit test usually fall apart when they can't figure out how to properly unit test things that interact with data without running through an in-memory or local database.
An EF data context isn't a repository on its own. It's a shitty simulation of one that requires a lot of boilerplate code to actually use. https://www.infoq.com/articles/repository-implementation-strategies And then there are the interesting things you can bake into a repository. https://www.infoq.com/articles/repository-advanced
I hate public functions that expose `IEnumerable&lt;T&gt;`. It gives you no indication as to whether or not the returned object is fully materialized or still tied to a data context. It's worse in their example because the method is named `List` but it isn't a list at all.
That's a lot of words, but not one of them address the problems he actually raised on the topic. In fact, your defense only changed the topic. 
I think this is a great article for someone first looking to get their start with the Repo pattern. Having experience maintaining my own generic repos (EF core included), I would also suggest defining a TEntity&lt;TKey&gt; type which has a `public TKey Id {get; set;}` , this allows you to define the type of key for your models, too. In EF, it often makes sense to use int or long, but in MongoDB for instance, the default is a UUID. Having a generic key gives you some more flexibility (though I've managed to use long id's with MongoDB too). I also wonder why the Author chose to make this signature for this method: Task Update(int id, TEntity entity); Personally, I found it enough in my repo pattern to just have: Task UpdateAsync(TEntity entity); And I can just infer the ID (TKey) from my Entity, since most of my TEntities inherit from my IRepoEntity&lt;TKey&gt;. The TKey (Id) doesn't leak into my interface this way. 
I agree the implementation in this blog post is terrible, but anti-corruption layers are a thing. I don't want EF (or other) exposed as a (direct) dependency in my domain, let alone in something like my web controllers because the rate and risk of change is out of my (the team's) control. A basic wrapper gets put over the parts that expose the more generic things like `IQueryable` but that's it.
Do you really need to care? All you're going to do with it is enumerate, anyway. Though I agree if it's called `List` it should return a `List`.
Yes indeed, I haven't done it before, mostly used exclusively int or few times Guid, but that definitely makes sense. Thanks for the suggestion.
I thought I had addressed my opinion of his concerns in my comment, but I'll try to be more direct this time. I don't think the repos he saw were doing it right. &gt; Generic repositories, and repositories for that matter, can get really hard to maintain, especially in complex domains. Developers either implement it correctly and the repository gets massive, or they get lazy, and start reusing implementations, causing a large amount of needless coupling or performance problems. Either way, it's bad. I have yet to find an implemention of repository that didn't fall into either of those two traps (not counting small projects). &gt;"Developers either implement it correctly..." ^^ IMO, it sounds like he never actually saw developers implement it correctly. - Maintainability: They shouldn't be hard to maintain at all. The repos should only know about how to do simple CRUD using the given model type and the underlying DB stack. Nothing more. When you start writing business logic, which has the tendancy to change, it doesn't belong in that repo. It belongs in a further business abstraction, which uses the generic repo. This means that your business logic, no matter how complex, still uses the simple IRepository pattern and can switch underlying DB stacks willy-nilly with out surrounding code change. Sounds to me like if his teams were creating overly complex repos that were hard to maintain, they failed to follow the crucial Single Responsibility rule and leaked their business logic into their Repos, which explains the trouble he had. - Performance problems: If the repos are designed to work with IQueryables, and the underlying DAL supports IQueryables, and the dev knows how to work with IQueryables to optimize all of his queries, then there should not be any performance problems. If there are, you did something wrong, and you fix it. Having performance problems because you used the Repo pattern isn't the Repo pattern's fault, it's bad programming. - "devs get lazy, and start reusing implementations, causing large amounts of coupling": To me, it sounds like the devs in question violated many of the SOLID principles, creating leaky abstractions, and cross-dependencies. Again, this isn't a problem with the IRepository pattern, it's a problem with the Devs. 
Happy to help! We learn as we go. I made a similar mistake in my v1 of my repo pattern. My delete looked like this: ``` Task DeleteAsync(TEntity etnity); ``` D'oh! I just needed the Id in this case, not the whole entity. This made our generic api controllers clunky because they'd have to do a read from the repo (GetById) before it could delete. Version 2, I fixed it to use ``` Task DeleteAsync(TKey id) ``` Which made more sense. Sidenote: I also didn't use a TEntity&lt;TKey&gt; at first with my repo pattern either! I made my TEntities have a `public long Id {get; set;}`, which made sense when I was working with SQL... but when I first made my MongoDB repos, and realized longs didn't really work so great when MongoDB uses UUID by default, I refactored to a generic TKey in Version 2. 
My variant of CQRS uses Jimmy Bogard's MediatR library to facilitate the separation of model usage between different commands and queries (he has a nice article about using CQRS with MediatR somewhere). This is a really simplified variant of what most people think of with CQRS. In essence, it's just model segregation between different actions with some extra structure to facilitate binding between modules. Only commands/queries can access EF (IQueryables) or reference EF's models. Each action against the database is encapsulated into distinct units, with well defined coupling and dependencies. This makes unit testing dead simple, refactoring less risky, while keeping all the benefits of EF. A simple example could look like this, I've removed the interfaces (damn code is hard to write without intellisense): public static class GetUserById { public class Query { public string Id { get; set; } } public class Result { public string Name { get; set; } public string Gender { get; set; } } public class Handler { private readonly EfContext _context; public Handler(EfContext context) { _context = context; } public async Task&lt;Result&gt; Handle(Query query) { var resultQuery = from user in _context.Users where user.Id == query.Id select new Result { Name = user.Name, Gender = user.Gender }; var result = await resultQuery.SingleOrDefaultAsync(); return result; } } } So on a different layer, maybe the API layer, calling would look like this: var result = await _mediatr.Handle(new GetUserById.Query {Id = "GUID"}); There's little development overhead with this implementation - you just need a good dependency injection library and some R# snippets. I've even started to use it on my smaller projects because it allows me to conceptualize the system better. I've seen 10,000 lined repositories that make me very sad that no one wanted to touch (they were using Dapper). I really don't think the problem is with EF vs Dapper, rather something else that I can't point to right now.
People don't think that hosting on Linux servers actually takes any time or configuration, and it just works for free out of the box.
Yeah, that is kind of odd. Internally they are calling .ToListAsync() so I'm not sure why they are returning IEnumerable&lt;T&gt;. Probably just as a way to give a slight nudge to people who like to mock IEnumerable instead. Faking tests with an actual List feels really easy to me. I think when I took some of this code for a smaller project I renamed the method to Query. I was more posting to just show that there is an easy way to separate out a query specification, and that anyone reading might want to consider how to do transactions.
You don't know that. Or rather you do because that's literally the only thing I can safely do with it. I've lost track of how many times I've had to write this stupid function: IList&lt;T&gt; AsList&lt;T&gt; (IEnumerable&lt;T&gt; source) { if (source is IList&lt;T&gt;) return (IList&lt;T&gt;)source; return source.ToList(); } 
&gt; Yeah, that is kind of odd. Internally they are calling .ToListAsync() so I'm not sure why they are returning IEnumerable&lt;T&gt;. For some people it's a case of magical thinking. They assume that if they expose a `List` as an `IEnumerable`, it magically makes the list read-only. Of course as soon as any code that uses reflection hits it (e.g. data binding libraries) that disguise disappears. What really confuses me is why they don't at least expose `IReadOnlyList`. 
letsencrypt.com
Welp, reinstalled EF a fifth time seems to have fixed it... Leaving this here if someone else gets the problem...
I was about to suggest using the "Rebuild solution" option in VS, that usually helps with these things, but I don't know if it would have made any difference in this case...
code first ... not even once!
Sorry I badly phrased it, it was actually meant to be a question - what else would you want to do with the IEnumerable (in the context of it being returned by something else as an interface)? Though fwiw I agree with you, return types should (in most cases) be a specific implementation type rather than a super high level interface.
Ah, the no true Scotsman defense! Maybe show us an example of a generic repo done right?
OP's example is pretty close. If my company made our Repos open source, I'd link ours. The problems that were mentioned only happen when you leak business logic into a repo, and violate the single responsibility rule. **If someone wants to post an example of this problem, I'll show how to fix it by following single responsibility.** In op's example, I'd change the Update method signature, and I'd also define a TEntity&lt;TKey&gt; type which defines the Id of the entity generically. Op's EF example would be one concretion, I'd make other concretions as needed (Mongo, Docdb), and they'd only be aware of CRUD logic. Then, when I need to work on the business logic, I'd create another class which uses the generic repo and implements the business details. All of the concerns the other guy mentions aren't present, if done correctly. If I took OP's example and followed my suggestions above, I could start a project using SQL w/ EF and easily migrate to something else like MongoDB without making surrounding code changes in my business logic. Seperation-of-concerns/SR is all that is needed. 
I have VPS servers with a different provider and all SQL with Azure. Its fine and latency is about 15ms.
&gt; If the repos are designed to work with IQueryables, and the underlying DAL supports IQueryables, and the dev knows how to work with IQueryables to optimize all of his queries, then there should not be any performance problems. Nevermind that your entire data access scheme has leaked into your application layer (and quite possibly presentation layer since nothing stops it at that point). &gt; "devs get lazy, and start reusing implementations, causing large amounts of coupling": To me, it sounds like the devs in question violated many of the SOLID principles, creating leaky abstractions, and cross-dependencies. Again, this isn't a problem with the IRepository pattern, it's a problem with the Devs. There are performance problems around EF lying in wait inside the IQueryable abstraction, but dismissing them offhand doesn't just eliminate them. You're giving developers access to data when the links between entities may be much more complex than EF lets on. This is *not* a matter of "If you know how to use IQueryable, there are no performance problems." You eliminate performance problems when interacting with the data store by defining strict guidelines by which that data store is given queries or commands. That's where EF goes horribly wrong, and adding *another* abstraction that destroys EF's transaction support in place of your own is quite literally putting lipstick on a pig. You're ignoring problems by holding your IRepository up on a pedestal when it really doesn't do anything for you. Your argument here went from "I can swap to whatever database tech I want," to "it's the dev's fault if it doesn't help" without ever providing a single *benefit* over ADO.NET or direct access to EF. Both of those are set up to abstract differences in DB technologies. Both of those provide transaction support. But if your solution doesn't solve the problems that EF creates, I'm not sure how you call it a great solution. No architecture is perfect, and we all choose certain factors over others in different situations, but I think you're clearly ignoring severe architectural/performance deficiencies in the name of having *one* interface. TL;DR: I'm definitely not arguing with you that exposing EF throughout an application is a bad idea and breaks SOLID principles. I'm saying you didn't solve that problem with IRepository&lt;T&gt;.
Hah! You apparently weren't listening to anything I said. My data access scheme doesn't leak into my application layer or presentation layer. That's what business logic layers are for. I didn't write off problems of EF. If you have performance problems, like I said, you did something wrong, go back and fix it. You ran into problems because you misunderstood something, not because of the IRepo pattern. You said I didn't list any benefits... again you didn't listen. It makes your code more agile, it defines a dependable, consistent design pattern that you use with any DB stack, making the reusability more flexible across projects and more understandable. It hides away the specifics of your db stack so you can just focus on your model definitions and business logic. &gt;TL;DR: I'm definitely not arguing with you that exposing EF throughout an application is a bad idea and breaks SOLID principles. I'm saying you didn't solve that problem with IRepository&lt;T&gt;. Again, you're not listening. I never said I solved the problem of leaky abstractions with IRepo. I said I solved them with Solid Principles and good programming. IRepo made my projects more flexible, more maintainable, and significantly increased my productivity, especially when handing multiple projects at once. Any argument against IRepo I've been able to not just argue, but refute with examples of why those arguments are invalid, when proper technique are used. 
Not really hacky, its akin to putting an SSL device on your network in front of your web infrastrcutre. This is done on larger networks that serve out SSL a lot. It's kind of how SNI works. 
If you saw repositories with anything approaching 10,000 lines, devs were doing it wrong. I don't think that invalidates the IRepo pattern. I think it just means that those repos were doing *too much*. [Here's a solution of repos that I manage.](https://imgur.com/a/YhRRC) Each repo project is a nuget package. The average # of lines of each of these repos is ~200 lines, and that's with full StyleCop Documentations, so less if you exclude that. The EF repo is 170 lines, DocumentDB is 230. We don't put business logic and things in our repos... only things specifics to our underlying db stack to achieve basic CRUD. The idea is to simply abstract out the means of data access, so that all of our projects can uniformly use one design pattern for data access. We pull down the nuget packages, and wrap them in logic and/or service layers, which following IoC, only depend on the IRepo pattern for CRUD. The IoC also lets our service/logic layers become agile with our underlying data structures. Whatever filled up most of those 10,000 lines, it probably shouldn't have been there. That logic should have been extracted into other layers, don't you think? I can understand why you'd harbor a distaste for Repos after that, but I wouldn't write them off without considering that maybe the repos you saw were simply an abuse of the pattern. 
^(Hi, I'm a bot for linking direct images of albums with only 1 image) **https://i.imgur.com/bgZYgvK.png** ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme) ^^| ^^[deletthis](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=delet%20this&amp;message=delet%20this%20dngip5f) 
Happened to me once but I believe restarting VS fixed it for me. Also, make sure in the console the correct project is chosen
Having done exactly this (except in C++) one thing you have to be careful of is that the "stdio bridge" treats newlines as log entry boundaries. Therefore (using this method) you cannot have multiline log entries. If that isn't a requirement, then by all means this is a quick way to get up and running. If it is, then you'll need to look into interfacing with [sd-journal](https://www.freedesktop.org/software/systemd/man/sd-journal.html). The `sd_journal_send` function is great for sending structured log messages. 
The thing is, I've never seen a repo that doesn't have issues. That repo was primary composed of data access logic. How do you handle different projections? I've either seen this: GetUserById GetUserAndPermissionsById GetUserEmailById GetUserPasswordHashByEmail Or this: GetUser Both of which are painfully bad. This is even worse: Get&lt;T&gt;
I think most of those examples you gave fall outside of the responsibility of Repositories. Those aren't CRUD calls, those are service implementations. You want a service to simplify your work, rightfully so, so you should write those methods in a service layer instead. &gt;This is even worse: Get&lt;T&gt; I'd actually say this is best: `GetById&lt;T&gt;(TKey Id)` and also `Get&lt;IQueryable&lt;T&gt;&gt;(Func&lt;T, boolean&gt; predicate)` The Repo would only implement these for the get methods. The other method examples you provided also wouldn't typically apply to my projects because the user repo would never be responsible for Permissions(auth), Email (identity) or Password Hash(identity), we manage those things with Identity Server and our Auth layers. Let's say they do though, taking your examples, I would write a service layer (say, web api), and I would write logic for your other methods there. If I had some domain specific things, I'd wrap the repo around a service layer, too. So I could put my domain specific things there (data hiding... projection, etc) So in these examples, my UserService uses my UserRepo. The UserRepo just does CRUD.: [Route("api/user")] [HTTPGet] public HttpResponseMessage GetUserById(HttpRequestMessage request, long id) =&gt; _userService.GetById(id); Typically, I wouldn't just access the user repo directly, it would be used through another class, a user service instead, which would maybe do some data hiding or projection or logic. I tend to leverage the IAdapter pattern for data hiding, instead of Automappers. As for `GetUserAndPermissionsById`, that's not something our web api's would expose. Instead, we use IdentityServer, and the user's permissions are passed along with it's Id token, as json claims. This token and these claims are passed along with every request, and we decorate our api controllers with attributes that handle claims auth. You wouldn't need a method like "GetUserAndPermissionsById" because that isn't really the job of the User repo/service, it's the job of the Auth/Id services, and the permissions are present in your claims. In fact, our User repos are typically reserved for admin areas, only. Same with `GetUserEmailById`, our web api controllers wouldn't need to expose that. Email is a part of the User Identity, and would be present in the Id token. However, if I was going to write it, it would look like: [Route("api/user/email")] [HTTPGet] [AuthorizeClaims("role, "admin")] // only admins can call this web method public HttpResponseMessage GetUserEmailById(HttpRequestMessage request, long id) { return request.CreateResponse(HttpStatusCode.Ok, _userService.GetById(id).Email); } Now, I'll provide an example: say you want to save an image with a new user, for their profile pic. I'd do the following: [Route("api/user")] [HTTPPost] [AuthorizeClaims(Claims.Self)] // this tells our auth layer to only allow the user ID of the user being posted to use this web method public Task&lt;HttpResponseMessage&gt;GetPostUserWithImage(HttpRequestMessage request, [FromBody] UserAndImageBase64 user) { await _userService.InsertOrUpdate(user); // user service uses repo to update model, and updates IdSrv identity for user, too // do saving of assets. typically this will write to the file system, which then serves the images to the web. Also generates a record in a DB and assigns a guid to the file name, other domainy things. try { await _userProfileService.CreateOrUpdateProfileImage(user.ImageBase64, user.Id); } catch (Exception ex) { // exception handling request.CreateErrorResponse(HttpStatusCodes.InternalServerError); } request.CreateResponse(HttpStatusCodes.Ok); } **You'll notice that all of my domain-specific details above talk nothing about repos.** That's because those kind of things don't belong in repos, my repos are only simple CRUD machines and require little maintenance, and all of my domain details are extracted into single responsibility containers (services). This is how repos should be used. 
No, ashamedly I've never actually written a unit test, they've always confused me a bit. I assume I'll need to figure that out more when I start scaling up and performance becomes a bottleneck
Maybe I want the count. Maybe I want to enumerate it backwards. Or enumerate it using Parallel LINQ. Maybe I want to assign it directly to a List&lt;T&gt; property. And who knows what a data binding library is going to do with it. Honestly, I often have no idea what the most efficient use is going to be from the client code's perspective. So it's better to offer everything that I can without making my code more expensive.
Also, enumerating an IEnumerable&lt;T&gt; is much slower than enumerating a List&lt;T&gt;. Usually that doesn't matter, but if you are dealing with performance sensitive code its an important thing to know.
&gt; Although RazorPages seem to promote mixing code and templates in the same file, a practice that has been frowned upon for the last decade or so. It's one of the reasons PHP gets as much flak as it does. I cannot find the article for the life of me, but the explanation I recall was that [based on the MVC Pipeline (warning, PDF)](https://docs.microsoft.com/en-us/aspnet/mvc/overview/getting-started/lifecycle-of-an-aspnet-mvc-5-application/_static/lifecycle-of-an-aspnet-mvc-5-application1.pdf), View engine Code is a separate step from the controller code, and there could be some concerns about threads and resource allocation towards said threads. If I had to guess, they changed how some of this model code is processed to get around whatever concerns were there in that regard. From an overall design perspective I think it's not great. The *intent* appears to be having fancier things going on in the Model code, and the way the model should work that's fine I guess. You could really do some interesting RAD and even DDD stuff with it, actually. You'd be really walking on/over the line on certain design principles but I can see where it might make sense. My *worry* is people will instead turn it into the PHP-like Ghetto you describe.
&gt; If you worry about unit testing EF just use Effort (or with core use Sqlite in memory mode). It's closer to a real database then just mocking in memory lists. I usually advise against unit testing EF queries. Using a different LINQ provider or database engine for your tests than you will be using in production is just asking for false negatives to ruin your day. 
Did you try just restoring packages before reinstalling?
You left off the rest of it: if you don't understand what you're doing.
YES thanks you! Abstraction of abstraction of abstraction is often done by astronaut architect and I hate it. My approach is to encapsulate all EntityFramework dependency into a Repository class. This repository class is not abstract though. (except if I have good reason to do it later) I use real Sqlite for testing. I am still not sure if I should get rid of the Repository for the querying part to be honest. I understand why people get rid of it though. An UX who has querying capabilities get needlessly constrained by an intermediate repository layer.
you call it a mediator, as far as I am concerned, it is clearly a repository. Only difference is that you break it into several classes instead of one class.
Make sure you have entity framework CLI tools installed.
Damn, that's some elegant C#. 
&gt; I've yet to meet anyone who uses Code First/Fluent API that can create a Shared Primary Key relationship without multiple attempts at trying to get the Fluent API right. If this is a standard one-to-zero-or-one relationship where the secondary table makes use of the primary key of the first table as its own primary key, yup. Been there, done that, EF code first, nailed it on the first try. Rather large private-signup site, too (10,000+ registered users). Had to do it at least twice in the system for two major classes of user because I didn’t want to engage in DB partitioning -- the Identity 2.0 User table was getting bloated enough as it was, so I wanted to offload a lot of user-related content to a secondary table without having to roll a separate primary key (it made sense to re-use the user’s primary key, since it was going to be unique in the system anyhow, and the secondary table would only ever have at most one entry for every user).
Install the .design package as well.
In your profile image example it isn't clear what happens in the _userService.InsertOrUpdate-method? From context I would guess it's an update, but what updates? If it's "user has profile picture" what happens when the save file method fails? 
This is really frustrating but gladly I did not get this yet in .NET core 2.0. Sometimes it is loading your other project in solution even you pick your server project. In my case, WPF and ASP, it will always trying to run update-database on WPF even I unloaded the WPF and selected the ASP in Nuget command Window. Otherwise, spam restart, reinstall EF, restart whole pc, re-download source only from your git and let it restore packages, cold boot, reinstall visual studio, etc it will eventually work.
Just posting here again for anybody stumbling upon this (it's been about 5 months). I went back to Azure and managed to get that working. I hated it previously because it wouldn't work for me properly. But it was because I made some errors when trying to deploy to Azure. Got them worked out and now things are fine. I still don't know any good free alternatives that are easy to use, although I didn't really look too much into using Docker but I think that might be something. Good luck and don't give up!
Yes I thought that was one of last week's good news! 
Yes, good news indeed! 
My approach for this was using the EF CLI to generate the model classes. I found this and it saved me as I was trying to find a way to get it done as well. https://docs.microsoft.com/en-us/ef/core/get-started/aspnetcore/existing-db The thing that really sucks with this approach is even the smallest change in the models makes you have to delete the files and re-scaffold the entire thing from the command line.
Or if ASP.NET Identity is being used, you can just use the built in methods to do this for you.
It's pseudo-code, just to show how I'd split up responsibilities into different services to keep my repos only aware of CRUD. `InsertOrUpdate` is a [common Repo method](http://rycole.com/2014/01/25/entity-framework-repository-pattern.html). It is used to either insert a record (if new) or update a record, usually based on the Id (if Id is default, it's new). As for the image profile service, which "creates or updates user profile image", the job of that service is to deserialize the base64, write the image to file, and then update the IdSrv profile with the image's URL. If the `InsertOrUpdate` fails, WebApi will automatically return a failure response and the I/O will not execute. &gt; what happens when the save file method fails? That's what the try/catch is for, and the little comment "// exception handling". If `CreateOrUpdateProfileImage` method fails, you'd typically write further logic in the try/catch, where I put a comment for "// exception handling". Typically, you'd see something like rolling back the previous transaction there, and then the return of the error response. In the real world, I'd probably rearrange the order of operations, and I would attempt the I/O first, and if that was successful, then do `InsertOrUpdate` on the user entity. 
.Core vs .Net is, unfortunately, another topic
[Aww shucks](https://media.giphy.com/media/3otPoO4cfZXsVGkIwM/giphy.gif)
https://docs.microsoft.com/en-us/azure/cosmos-db/table-storage-how-to-use-dotnet
Actually I have read and done this tutorial but it concerns Table Storage. Im using something diferent, EasyTables from Azure mobile services. Is it the same thing? Can I use this tutorial and adapt it to my needs? As I said, all of ths is a bit confusing to me.
I like Get&lt;T&gt;. I use an ORM that uses reflection with runtime table analysis to generate the right SQL.
How do you feel about netcore and MVVM pages?
You have to give permission to the user your application pool in IIS is running as or use impersonation on that step 
And how can I do it? I only know the username and the password of the directory and I can't grant permissions to other people. My windows account can browse the folder because I used the account, but with the IIS account is a different story.
Do you have an example of a chunk of code that didn't work for you so others might be able to pick at it?
It’s somewhat possible to reuse the users table but you will have to pverride chunks of ASP.NET Identity. If your passwords aren’t encrypted or you don’t mind asking ALL users to set their passwords again, I’d recommend sticking to the default table and extending it instead before migrating data over. If passwords are hashed but you have access to the algorithm (and it doesn’t depend on the machine key, which I suspect it is) I’d also port that and still migrate across.
Out of curiosity, what’s still missing? I remember working woth EF core 1 and helluva lot of the queries were being processed in memory, but I can’t remember off the top of my head what queries were that.
IIS runs one or more websites from something called an application pool. Just open up IIS manager and click application pools find the one for your site and you can change the user the pool is running as 
Would you like us to write your application for you too? Snark aside, research the components individually. They aren't exclusive or dependent on one another, so any examples for one that you find should still be applicable with another. 
Without an example or context: Task.Run is your friend. Pass one stream to one, and another to the other. Bam. Parallelism. 
Yeah, I played with that one for a bit. I believe they now support 64-bit apps too. Never tried with core though
This is the approach that makes the most sense to me. Parallel.ForEach() is designed to help you process the same type of work on a collection in parallel, not handle two different separate streams of work asynchronously.
You are not operating on a set. Parallel.ForEach is meant for set based operations. Do not use it for input loops or you're gonna have a bad time. You just need a read function wrapped in a task
ublock origin is blocking an ad script that makes the searches fail. Just posting in case that trips anyone up. Once I loaded in a private browser session without the ad blocking, everything works and the information looks good.
There are templates available check google for SPATemplates 
I think the idea its to treat them as separate applications. The Angular 2 application should self host in its own docker container and then the Asp.net core MVC application that implements the REST API is hosted in a separate docker container. The two docker containers can (and should) then be scaled separately. You can merge the http traffic under one domain with a third container using Nginx/Haproxy or leave separate with cross domain policy. Container focussed hosts like Open Shift handle this scenario perfectly. There's probably a way to setup the debug in visual studio or vscode to start the node server and launch it's page for you but I haven't researched that yet. Edit: fix autocorrect on phone
That doesn't work for me either - all requests to search/autocomplete are coming back 500. Must be overloaded.
Fine downvoters, here I did it for you: https://docs.microsoft.com/en-us/aspnet/core/tutorials/first-web-api https://medium.com/@levifuller/building-an-angular-application-with-asp-net-core-in-visual-studio-2017-visualized-f4b163830eaa
Thanks for the heads up. Taking a looksie.
I found while searching for PetaPoco it's says .net core ready -- but it's not. It might be assuming that PetaPoco.Core is somehow meaning .net core support. None of the petapoco forks are mentioned as alternatives. This is definitely a helpful service though! Thanks man! 
&gt; PetaPoco Not able to recreate that - PetaPoco is coming back all red for me! It uses the NuGet API to check so the spelling of the package name shoudn't affect it. You sure on this one buddy? And I hadn't thought about forks. Maybe a Travis CLI lookup might be a worthy addition. 
I'm a total idiot -- Petapoco was the first one I checked for, and I assumed the "X" in the column meant it did support..... derp derp.... Long day, ignore me. 
Start a project with it and without it.. you will see the difference is a few lines in startup 
Thanks for that :-) I'll try it out
Hmm. Try this link. https://blog.xamarin.com/getting-started-azure-mobile-apps-easy-tables/
Think you were right about the rate limiting. Have added some response cacheing in the mean time.
This is not true. The names are confusing, but 'code first' does not mean the code existed before the database, it simply means the mappings are POCOs and not edmx models. [MSDN](https://goo.gl/5pDCyX) ...Google url shortener because Microsoft has () in their url.
Well that was a slow way to do it, had to move across every file and folder related to Identity. 
FB announced a shift to an MIT license for React the day after your comment 🙂. https://code.facebook.com/posts/300798627056246/relicensing-react-jest-flow-and-immutable-js
Would you mind writing about what you found? It would save the rest of us the trouble
I was hoping that there was a way just to run the install package again which would install the relevant folders and files. Unfortunately, unless i am totally wrong, I had to create a new project, copy and paste across all the new files, and manually change the files with mixed content. Once moved over I went through the 60 odd errors and intellisence fixed the namespace issues and used the one from the copied files. Then when the program ran I renamed the namespaces to all be the same as the original. It does seem to have worked. I havn't yet run the login itself, but the program is now running without errors. But 1/2 way through I strongly wished I had saved a backup of the program, or at least had it under source control :-) 
None of that should have been needed the auth is a nuget package ... 
It works now, thanks!
For future reference I would love to know a simpler way. 
I actually noticed that the "dotnet new" command for ASP.NET Core had a template for making an app with Angular. It was neat, it was all integrated into the build and everything.
All sites published to IIS for asp.net and core use a web config .. in the project itself .net core mvc projects use app settings and before core the web config was the same for IIS and your project in net core it is just redirecting basically 
.net core has its own webserver, this webserver reads from appsettings.Json and does t support reading web.config entries (to my knowledge -legacy format that is hard to support) If you deploy .net core to an iis server it deploys a web.config that tells iis to forward traffic like a proxy to the .net core server. I would have assumed for iis express it did the same thing, but maybe they have a different hack for local 
Yeah, I suspect there's some undocumented hack for local IIS Express that doesn't require a web.config, because my application seems to run without any issues and I don't have a web.config anywhere in my solution.
Have you checked the bin directory?
Also IIS managed settings are generally stored there. Things like authentication that it knows how to read/write to the config for you. 
You are correct that that is the way it *should* be done, but the .Net community as a whole seems hell-bent on making the .Net project the "master" for some reason, even though it makes no fucking sense anymore when you are talking about two separate applications.
I think the term you may be looking for, is 'compatibility level'. See: [this page](https://docs.microsoft.com/en-us/sql/t-sql/statements/alter-database-transact-sql-compatibility-level). Create a database in your SQL 2016 server, but in the options, set its level to 110 (SQL Server 2012). You can also change it on an already existing database with the ALTER DATABASE command. Also, not 100% sure here, you may also need to specify in the connection string the 'Type System Version' (see: [this page](https://msdn.microsoft.com/en-us/library/system.data.sqlclient.sqlconnection.connectionstring\(v=vs.110\).aspx)). I have never used this though, not sure if this is even available in .NET Core.
I was expecting realtime programming (like RTX by IntervalZero) although I guess that's not really posaible with just a library :) The definition of realtime on this site is quite broad and covers many technologies. A better title might be messaging protocols in .NET
Here's a nice overview: https://docs.microsoft.com/en-us/aspnet/core/fundamentals/servers/?tabs=aspnetcore2x So Kestrel really is the "web server" as far as your MVC Code is concerned. And so it gets its configuration settings from appSettings.json (and code and/or [attributes]). This doesn't mean that the "real" web server couldn't also have its own particular configuration mechanism (eg. web.config for IIS, who knows what for ngnix et al). Though... just to confuse things.... on Windows you can run an MVC Core app using HTTP.sys instead of Kestrel. HTTP.sys is the "front end" to IIS (i.e. deals with the muckiness of listening to the network). Looks pretty complicated to use: https://docs.microsoft.com/en-us/aspnet/core/fundamentals/servers/httpsys
Would it be possible to put share links as is a common question in my company so http://www.dotnetcoreready.com/?packagename or something? 
Check the .vs folder in your solution. Somewhere in there there's an applicationHost.config file which sets up everything for iOS express, and includes the particulars for proxying to kestrel
How would private protected be declared in C++/CLI?
Thank you very much. 
* Non-trailing named arguments Yes please. I use those all the time in VB for readability purposes. * private protected Currently I simulate that using `internal`, so I'll probably use it. * Readonly references This is an important performance tool... for people other than me.
"protected internal" should have meant what will soon be represented by "private protected".
Yeah, it's not in there.
It may not be a Runtime feature, just a C# syntax feature (i.e. the compiler does something to only allow the correct calls through, but the output IL is standard).
So I found this: https://msdn.microsoft.com/en-us/library/ms178685.aspx I'm guessing what's happening is there's a web.config higher up the hierarchy that is handling this for me on my local machine. Presumably, Visual Studio creates a web.config for your application when you publish it because it's more common to want to override certain IIS configuration for each application once it lives in a deployed environment.
* Compile time enforcement of safety for ref-like types This mostly means "no `Span&lt;T&gt;` values in closures or fields" (it is a little more complex than that, but you probably don't really need to worry about it). `Span&lt;T&gt;` is a type that represents a slice of a specific array (among other things). It has no allocations of its own but instead points to the memory of the underlying array. So the following is valid right now: public class MyThing { Span&lt;int&gt; _elements; public MyThing(int[] array) =&gt; _elements = new Span(array); public Bar Foo() { /* uses _elements */ } } But that is REALLY bad because the span contains a pointer to array which is not necessarily fixed in memory (the CLR can move managed types around and will not correct random `IntPtr`s that happen to resolve to them) so `Foo` can reference memory that it should not be able to. It turns out there are a number of edge cases where you must not allow this type in order to prevent it from getting in the heap. Some examples: * cannot be in a parameter to a method that does a `yield return` * cannot be used on both sides of an `await` expression * cannot be lifted into a lambda or local function * cannot be used in a `Tuple` or almost any existing collection type * cannot be boxed And others... On the other hand it would be really nice to be able to compose types that contain Spans as fields (and other "ref-like" types). The solution is to let the concept of "ref-like" to be infectious similar to the way `async`/`await` is: To create a value type that contains a ref-like type, the value type must itself be ref-like. To facilitate this, new syntax will be added: ref struct MyThing { Span&lt;int&gt; _elements; public MyThing(int[] array) =&gt; _elements = new Span(array); public Bar Foo() { /* uses _elements */ } } And now `Foo()` is safe again from dereferencing bad pointers. full draft proposal here: https://github.com/dotnet/csharplang/blob/master/proposals/csharp-7.2/span-safety.md 
I've added the ability to autofill the package id, so for example: http://www.dotnetcoreready.com/?id=Newtonsoft.Json Will load the page for that specific package id. Is that what you were after? I'm also in the process of adding the ability to get an email alert when a non-compatible library becomes compatible with .NET Core. Will leave a comment here when that is done.
The 'raw' github feature descriptions: https://github.com/dotnet/csharplang/tree/master/proposals/csharp-7.2
Yup that's perfect. Guess I meant also adding readonly box with that link in with a copy and pasting ability be good or just populating the url on submit would work. Just for quick sharing saying 'hey person check out this package it's dot net core ready' know we discuss packages quiet alot when trying to migrate to core but always some stickers. Like the email feature that be cool. 
Exactly that. `protected private` or `private protected` (the laxer modifier applies to access from within the assembly; the stricter one applies to access from outside).
I agree. It would just make more sense to have "protected internal" mean that a variable can only be used in subclasses of the same assembly. Private protected sounds like something impossible
This looks similar to the approach D has taken for ref returns.
That is built into VS, its called the object browser. I think higher copies of VS have better tools too. There are also some 3rd party ones that could let you build these out. If you want to know the built in objects MDSN docs do this in some cases but not nearly to the detail you would like. I don't think I have ever seen anyone make a UML-like design diagram for the in-built components. 
The restrictions are basically the same as you already have for `ref` parameters and variables (in regards to where they are used). I'd say the whole thing is basically extend the existing rules to a class of potentially user defined objects. It does make me wonder if there are other interesting types to be created with `IntPtr` fields backing them.
You can publish the website to the server by right clicking the web project and picking publish. There are a few ways to publish, I've mapped a network drive to mine and use publish to directory to copy it into the website folder on the server. You could also use this to publish to a folder, zip it up and copy it to the server manually. You can also install Web Deploy from the Web Platform Installer, once it is set up and IIS configured to use it you can publish using that as well. Hope that gives you somewhere to start.
make me
haha wish i had the wisdom to see what framework is viable by 2020 :)
No 100% portable binaries yet. Just compatible byte-code for different platform specific runtimes. You can package the CLI for your chosen target platform with your code. 
Web.config is only used to configure HttpPlatformManager (Asp.net core module) into the IIS request pipeline which forwards straight http traffic to Kestrel but is not used at all by .net core.
&gt;It may not be a Runtime feature, just a C# syntax feature (i.e. the compiler does something to only allow the correct calls through, but the output IL is standard). According to the [proposal](https://github.com/dotnet/csharplang/blob/master/proposals/csharp-7.2/private-protected.md), the runtime already has this. The proposal is just to give C# a way to specify it. 
Depends you can create a self contained application that will run a specific platform without any dependencies. This will not be one binary though and the output only works for one platform. You could create multiple output to work on every platform without changing code but you would have to distribute different exes for each. You can also create a normal dot net core console app that will run on any platform as long as dot net core is on that platform. This option will be a single binary as long as you don't have any dependencies. Again though the platform/environment must have dot net installed on it to work. This is similar to how Java does it. There is one more option that use CoreRT that works much the same as the first option I mentioned but bundles all the dependencies into one file that is native C++. [https://github.com/dotnet/corert/blob/master/Documentation/intro-to-corert.md](https://github.com/dotnet/corert/blob/master/Documentation/intro-to-corert.md) Its very new and doesn't work all the time and is not easy to setup/use but its an option.
How can I do this?
is there a tutorial for this, btw the link is broken
use the runtime flag when building. eg "dotnet build -r linux.x64"
I'm a bit late to the party, but do you have a code snippet that shows how you set this up? This is what I ended up with trying to figure it out, but it's not quite right. public class TEntity&lt;TKey&gt; { public TKey Id {get; set;} } public interface IRepository&lt;TEntity, TKey&gt; { TEntity Get(TKey key); } public class GenericSqlRepo&lt;T&gt; : IRepository&lt;T, int&gt; where T : TEntity&lt;int&gt; { private ApplicationDbContext _context; public GenericSqlRepo(ApplicationDbContext context) { _context = context; } public T Get(int key) { return _context.Set&lt;T&gt;().FirstOrDefault(x =&gt; x.Id == key); } } public class GenericMongoRepo&lt;T&gt; : IRepository&lt;T, string&gt; where T : TEntity&lt;string&gt; { public GenericMongoRepo() { } public T Get(string key) { return null; // TODO } } public interface IMyPerson { string FirstName { get; set; } string LastName { get; set; } } public class MyPersonSql : TEntity&lt;int&gt;, IMyPerson { public string FirstName { get; set; } public string LastName { get; set; } } public class MyPersonMongo : TEntity&lt;string&gt;, IMyPerson { public string FirstName { get; set; } public string LastName { get; set; } } class Program { static void Main(string[] args) { ApplicationDbContext context = null; // TODO IRepository&lt;IMyPerson, int&gt; a = new GenericSqlRepo&lt;MyPersonSql&gt;(context); // Error: cannot convert type IRepository&lt;IMyPerson, string&gt; b = new GenericMongoRepo&lt;MyPersonMongo&gt;(); // Error: cannot convert type } }
Fixed the link. Self contained applications or SCD are described [here](https://docs.microsoft.com/en-us/dotnet/core/deploying/deploy-with-cli). For CoreRT its much more complex but the general guide is [here](https://github.com/dotnet/corert/blob/master/Documentation/how-to-build-and-run-ilcompiler-in-console-shell-prompt.md)
Check out https://github.com/datalust/piggy for a fully-fledged example with (AppVeyor) build scripts, Linux and macOS gzipping, and Windows MSIs.
signalR is the best "signalR" for .NET. There is a new signalR rewritten from scratch for .NET Core that should be in alpha2 very soon, people seem pretty happy with it.
Only a downgrade till it matures a little more.
Could be a few things .. I'm not sure about your skill level and we don't have an idea of what troubleshooting if any was done .. so start with the easy ones 1) you need to include the namespace that the context is in ... using mynamespace; 2) there is invalid code in the context open it up by expanding context in the solution explorer and going into the .cs to start .. might have been generated using a bad tool version so namespaces need fixed 
So ... &gt; are you missing a using directive or an assembly reference? If they **are** there, have you checked that the assemblies are all actually where the project thinks they are? &gt; I reloaded all of the files into a new project in order to build a clean slate. Sometimes when you clone a project from source control or move and open projects packages and their assemblies may not get copied or installed where the project specifies. Use Nuget to make sure all th epackages are installed correctly.
This post is 5 month old and doesn't even cover .net core 2.0 ...
The fundamental message that the runtime and SDK are different is still relevant. It's a pretty common misconception.
Not sure if this month we're streaming but we usually try at the DotNet Meetup group and thats the subject this month: https://www.meetup.com/Leeds-Sharp/events/241812863/ And ofc welcome to come along if you happen to be in Leeds UK 
mkdir to create folders?
Except the developer is well known for producing extremely efficient [Serializers](https://github.com/neuecc/ZeroFormatter).
i can confirm on Vue, i came from angular background and Vue seems like a fusion between react and angular and it fun too.
Alright: Lets assume my skill level is low. 1) I have included the namespace everywhere I think it should be post copy, but it is still erroring I am assuming that I am missing a context somewhere that may not be obvious. If my ApplicationDBContext is missing links to all of my models (which seems to be the case) where would the most likely place to be for my fuckup.
Ho does one check on where the project thinks the assemblies are? Nuget has them all installed appropriately. That was the first issue I had, and I believe I resolved that.
In VS Solution Explorer, expand the References section (of each project.) The properties of each reference includes the path to where VS expects to find the assembly. 
Why so much snark? It's a good question, considering that the original ASP.NET Core MVC Angular 1.x templates put the angular spa resources under the MVC wwwroot folder. There is a nuanced culture shift towards properly separating layers.
Sorry, I just feel like you keep missing the mark... What does this have to do with Angular at all? This is no different than a normal install of Entity Framework. On top of that... you're saying dotnet new angular, that's Angular4, not Angular2. You posted this same article like 6 times, you're just doing it for ad-revenue.
I feel like everything you post is pretty close to something I'm looking at or implementing... Are you sure you're not me? Or is it just a regional thing?
&gt;Those things are done on the back-end; the component only keeps a reference to which page it’s on, and asks for the next page when the end is reached. Does it keep the things like sorts and filters in some sort of session state on the server?
Use identity manager by microsoft? 
I read the issue for Newtonsoft. Is pulling down 1.3 dependencies it a common problem or something specific to Newtonsoft? Is there a away to limit the results to show only ones that target Standard 2.0 and/or won't add pre-2.0 stuff to my projects?
Sure but this is a hell of a lot simpler to set up.
Google says there’s a SOAP api for it. Might be worth checking out. 
The results are showing 1.3 because that is the highest .NET Standard level currently targeted by Newtonsoft.Json, but you should still be able to use this in a .NETStandard 2.0 application due to backward compatibility. Currently there is no way to filter to libraries above or below a certain .NET Standard limit, but I can add it in as the next feature. Would that help you?
It's a view model instance; it lives on the server, created on a component's connect call, and is kept alive until explicitly disposed by the component on dismount, or by some other events. Management of these instances is independent of ASP.NET. 
Yes there is. I've been through this problem. 1. Stop building to a common bin folder. Each project should build to its own output dir. 2. Go back to using NuGet and check every single packages.config file for each project and work out what your dependencies are. 3. Go through each project, bottom up, and work out where along the chain the DLL versions are wrong. You'll probably have different projects referencing different versions of the same assembly. (Eg Newtonsoft.Json). Standardise on the same version. 4. Setup your own nuget repo and make everyone uses that repo and only that repo. Only add the versions of packages that you want everyone to use. Hopefully that helps!
Everyone is moving towards git, and VSTS online defaults to it. That said the integrated Git support in Visual Studio sucks and you'll end up using either command line or a 3rd party tool to actually manage your commits/pulls (I use SourceTree). https://www.sourcetreeapp.com These links may help in deciding: https://docs.microsoft.com/en-us/vsts/tfvc/comparison-git-tfvc https://stackoverflow.com/questions/4415127/git-vs-team-foundation-server
In addition, look into assembly binding redirects for things like JSON.NET that have pretty similar APIs if one project is just very far behind.
Sure, that can work too. My approach is just avoid the complication and make everyone use the same version, it vastly simplifies things. But that's not always practical. 
If you want to convert your database to sql 2012, you can install sql express 2012 on your local machine. You could also transfer the database to an existing server by using the generate scripts option in SQL management studio. In the advanced options, you can choose to export DATA and Schema and select which version of sql server to target. https://docs.microsoft.com/en-us/sql/relational-databases/scripting/generate-scripts-sql-server-management-studio
No, I absolutely agree your approach is correct and the best option. It's just not always possible to upgrade package x because of some reason, and redirects can help there. I've been through too many "it's not on the schedule" conversations to be a total optimist.
The system is able to find all of the References. What it cannot find is my Models.
you can simplify steps 2+3, if you have a SLN which includes all the projects. if you don't, you can make a temporary sln just for this purpose. with that sln in vs, you can do "manage nugets" at the solution level (right click on the root node, not on a project). then there's an extra tab to reconcile nuget package versions. i think the tab is called "consolidate". really helpful when you've got nugets all over the place. it shows which projects have different versions.
Nice find. Thank you.
Where are the models defined? Are they in the same solution? The same project? Or different solution/project? 
 using System; using System.Globalization; using System.Linq; using System.Security.Claims; using System.Threading.Tasks; using System.Web; using System.Web.Mvc; using Microsoft.AspNet.Identity; using Microsoft.AspNet.Identity.Owin; using Microsoft.Owin.Security; using CPVCWebApp.Models; namespace CPVCWebApp.Controllers { [Authorize] public class AccountController : Controller { private ApplicationSignInManager _signInManager; private ApplicationUserManager _userManager; public AccountController() { } public AccountController(ApplicationUserManager userManager, ApplicationSignInManager signInManager ) { UserManager = userManager; SignInManager = signInManager; } public ApplicationSignInManager SignInManager { get { return _signInManager ?? HttpContext.GetOwinContext().Get&lt;ApplicationSignInManager&gt;(); } private set { _signInManager = value; } } public ApplicationUserManager UserManager { get { return _userManager ?? HttpContext.GetOwinContext().GetUserManager&lt;ApplicationUserManager&gt;(); } private set { _userManager = value; } } // // GET: /Account/Login [AllowAnonymous] public ActionResult Login(string returnUrl) { ViewBag.ReturnUrl = returnUrl; return View(); } // // POST: /Account/Login [HttpPost] [AllowAnonymous] [ValidateAntiForgeryToken] public async Task&lt;ActionResult&gt; Login(LoginViewModel model, string returnUrl) { if (!ModelState.IsValid) { return View(model); } // This doesn't count login failures towards account lockout // To enable password failures to trigger account lockout, change to shouldLockout: true var result = await SignInManager.PasswordSignInAsync(model.Email, model.Password, model.RememberMe, shouldLockout: false); switch (result) { case SignInStatus.Success: return RedirectToLocal(returnUrl); case SignInStatus.LockedOut: return View("Lockout"); case SignInStatus.RequiresVerification: return RedirectToAction("SendCode", new { ReturnUrl = returnUrl, RememberMe = model.RememberMe }); case SignInStatus.Failure: default: ModelState.AddModelError("", "Invalid login attempt."); return View(model); } } // // GET: /Account/VerifyCode [AllowAnonymous] public async Task&lt;ActionResult&gt; VerifyCode(string provider, string returnUrl, bool rememberMe) { // Require that the user has already logged in via username/password or external login if (!await SignInManager.HasBeenVerifiedAsync()) { return View("Error"); } return View(new VerifyCodeViewModel { Provider = provider, ReturnUrl = returnUrl, RememberMe = rememberMe }); } // // POST: /Account/VerifyCode [HttpPost] [AllowAnonymous] [ValidateAntiForgeryToken] public async Task&lt;ActionResult&gt; VerifyCode(VerifyCodeViewModel model) { if (!ModelState.IsValid) { return View(model); } // The following code protects for brute force attacks against the two factor codes. // If a user enters incorrect codes for a specified amount of time then the user account // will be locked out for a specified amount of time. // You can configure the account lockout settings in IdentityConfig var result = await SignInManager.TwoFactorSignInAsync(model.Provider, model.Code, isPersistent: model.RememberMe, rememberBrowser: model.RememberBrowser); switch (result) { case SignInStatus.Success: return RedirectToLocal(model.ReturnUrl); case SignInStatus.LockedOut: return View("Lockout"); case SignInStatus.Failure: default: ModelState.AddModelError("", "Invalid code."); return View(model); } } // // GET: /Account/Register [AllowAnonymous] public ActionResult Register() { return View(); } // // POST: /Account/Register [HttpPost] [AllowAnonymous] [ValidateAntiForgeryToken] public async Task&lt;ActionResult&gt; Register(RegisterViewModel model) { if (ModelState.IsValid) { var user = new ApplicationUser { UserName = model.Email, Email = model.Email }; var result = await UserManager.CreateAsync(user, model.Password); if (result.Succeeded) { await SignInManager.SignInAsync(user, isPersistent:false, rememberBrowser:false); // For more information on how to enable account confirmation and password reset please visit http://go.microsoft.com/fwlink/?LinkID=320771 // Send an email with this link // string code = await UserManager.GenerateEmailConfirmationTokenAsync(user.Id); // var callbackUrl = Url.Action("ConfirmEmail", "Account", new { userId = user.Id, code = code }, protocol: Request.Url.Scheme); // await UserManager.SendEmailAsync(user.Id, "Confirm your account", "Please confirm your account by clicking &lt;a href=\"" + callbackUrl + "\"&gt;here&lt;/a&gt;"); return RedirectToAction("Index", "Home"); } AddErrors(result); } // If we got this far, something failed, redisplay form return View(model); } // // GET: /Account/ConfirmEmail [AllowAnonymous] public async Task&lt;ActionResult&gt; ConfirmEmail(string userId, string code) { if (userId == null || code == null) { return View("Error"); } var result = await UserManager.ConfirmEmailAsync(userId, code); return View(result.Succeeded ? "ConfirmEmail" : "Error"); } // // GET: /Account/ForgotPassword [AllowAnonymous] public ActionResult ForgotPassword() { return View(); } // // POST: /Account/ForgotPassword [HttpPost] [AllowAnonymous] [ValidateAntiForgeryToken] public async Task&lt;ActionResult&gt; ForgotPassword(ForgotPasswordViewModel model) { if (ModelState.IsValid) { var user = await UserManager.FindByNameAsync(model.Email); if (user == null || !(await UserManager.IsEmailConfirmedAsync(user.Id))) { // Don't reveal that the user does not exist or is not confirmed return View("ForgotPasswordConfirmation"); } // For more information on how to enable account confirmation and password reset please visit http://go.microsoft.com/fwlink/?LinkID=320771 // Send an email with this link // string code = await UserManager.GeneratePasswordResetTokenAsync(user.Id); // var callbackUrl = Url.Action("ResetPassword", "Account", new { userId = user.Id, code = code }, protocol: Request.Url.Scheme); // await UserManager.SendEmailAsync(user.Id, "Reset Password", "Please reset your password by clicking &lt;a href=\"" + callbackUrl + "\"&gt;here&lt;/a&gt;"); // return RedirectToAction("ForgotPasswordConfirmation", "Account"); } // If we got this far, something failed, redisplay form return View(model); } // // GET: /Account/ForgotPasswordConfirmation [AllowAnonymous] public ActionResult ForgotPasswordConfirmation() { return View(); } // // GET: /Account/ResetPassword [AllowAnonymous] public ActionResult ResetPassword(string code) { return code == null ? View("Error") : View(); } // // POST: /Account/ResetPassword [HttpPost] [AllowAnonymous] [ValidateAntiForgeryToken] public async Task&lt;ActionResult&gt; ResetPassword(ResetPasswordViewModel model) { if (!ModelState.IsValid) { return View(model); } var user = await UserManager.FindByNameAsync(model.Email); if (user == null) { // Don't reveal that the user does not exist return RedirectToAction("ResetPasswordConfirmation", "Account"); } var result = await UserManager.ResetPasswordAsync(user.Id, model.Code, model.Password); if (result.Succeeded) { return RedirectToAction("ResetPasswordConfirmation", "Account"); } AddErrors(result); return View(); } 
 // // GET: /Account/ResetPasswordConfirmation [AllowAnonymous] public ActionResult ResetPasswordConfirmation() { return View(); } // // POST: /Account/ExternalLogin [HttpPost] [AllowAnonymous] [ValidateAntiForgeryToken] public ActionResult ExternalLogin(string provider, string returnUrl) { // Request a redirect to the external login provider return new ChallengeResult(provider, Url.Action("ExternalLoginCallback", "Account", new { ReturnUrl = returnUrl })); } // // GET: /Account/SendCode [AllowAnonymous] public async Task&lt;ActionResult&gt; SendCode(string returnUrl, bool rememberMe) { var userId = await SignInManager.GetVerifiedUserIdAsync(); if (userId == null) { return View("Error"); } var userFactors = await UserManager.GetValidTwoFactorProvidersAsync(userId); var factorOptions = userFactors.Select(purpose =&gt; new SelectListItem { Text = purpose, Value = purpose }).ToList(); return View(new SendCodeViewModel { Providers = factorOptions, ReturnUrl = returnUrl, RememberMe = rememberMe }); } // // POST: /Account/SendCode [HttpPost] [AllowAnonymous] [ValidateAntiForgeryToken] public async Task&lt;ActionResult&gt; SendCode(SendCodeViewModel model) { if (!ModelState.IsValid) { return View(); } // Generate the token and send it if (!await SignInManager.SendTwoFactorCodeAsync(model.SelectedProvider)) { return View("Error"); } return RedirectToAction("VerifyCode", new { Provider = model.SelectedProvider, ReturnUrl = model.ReturnUrl, RememberMe = model.RememberMe }); } // // GET: /Account/ExternalLoginCallback [AllowAnonymous] public async Task&lt;ActionResult&gt; ExternalLoginCallback(string returnUrl) { var loginInfo = await AuthenticationManager.GetExternalLoginInfoAsync(); if (loginInfo == null) { return RedirectToAction("Login"); } // Sign in the user with this external login provider if the user already has a login var result = await SignInManager.ExternalSignInAsync(loginInfo, isPersistent: false); switch (result) { case SignInStatus.Success: return RedirectToLocal(returnUrl); case SignInStatus.LockedOut: return View("Lockout"); case SignInStatus.RequiresVerification: return RedirectToAction("SendCode", new { ReturnUrl = returnUrl, RememberMe = false }); case SignInStatus.Failure: default: // If the user does not have an account, then prompt the user to create an account ViewBag.ReturnUrl = returnUrl; ViewBag.LoginProvider = loginInfo.Login.LoginProvider; return View("ExternalLoginConfirmation", new ExternalLoginConfirmationViewModel { Email = loginInfo.Email }); } } // // POST: /Account/ExternalLoginConfirmation [HttpPost] [AllowAnonymous] [ValidateAntiForgeryToken] public async Task&lt;ActionResult&gt; ExternalLoginConfirmation(ExternalLoginConfirmationViewModel model, string returnUrl) { if (User.Identity.IsAuthenticated) { return RedirectToAction("Index", "Manage"); } if (ModelState.IsValid) { // Get the information about the user from the external login provider var info = await AuthenticationManager.GetExternalLoginInfoAsync(); if (info == null) { return View("ExternalLoginFailure"); } var user = new ApplicationUser { UserName = model.Email, Email = model.Email }; var result = await UserManager.CreateAsync(user); if (result.Succeeded) { result = await UserManager.AddLoginAsync(user.Id, info.Login); if (result.Succeeded) { await SignInManager.SignInAsync(user, isPersistent: false, rememberBrowser: false); return RedirectToLocal(returnUrl); } } AddErrors(result); } ViewBag.ReturnUrl = returnUrl; return View(model); } // // POST: /Account/LogOff [HttpPost] [ValidateAntiForgeryToken] public ActionResult LogOff() { AuthenticationManager.SignOut(DefaultAuthenticationTypes.ApplicationCookie); return RedirectToAction("Index", "Home"); } // // GET: /Account/ExternalLoginFailure [AllowAnonymous] public ActionResult ExternalLoginFailure() { return View(); } protected override void Dispose(bool disposing) { if (disposing) { if (_userManager != null) { _userManager.Dispose(); _userManager = null; } if (_signInManager != null) { _signInManager.Dispose(); _signInManager = null; } } base.Dispose(disposing); } #region Helpers // Used for XSRF protection when adding external logins private const string XsrfKey = "XsrfId"; private IAuthenticationManager AuthenticationManager { get { return HttpContext.GetOwinContext().Authentication; } } private void AddErrors(IdentityResult result) { foreach (var error in result.Errors) { ModelState.AddModelError("", error); } } private ActionResult RedirectToLocal(string returnUrl) { if (Url.IsLocalUrl(returnUrl)) { return Redirect(returnUrl); } return RedirectToAction("Index", "Home"); } internal class ChallengeResult : HttpUnauthorizedResult { public ChallengeResult(string provider, string redirectUri) : this(provider, redirectUri, null) { } public ChallengeResult(string provider, string redirectUri, string userId) { LoginProvider = provider; RedirectUri = redirectUri; UserId = userId; } public string LoginProvider { get; set; } public string RedirectUri { get; set; } public string UserId { get; set; } public override void ExecuteResult(ControllerContext context) { var properties = new AuthenticationProperties { RedirectUri = RedirectUri }; if (UserId != null) { properties.Dictionary[XsrfKey] = UserId; } context.HttpContext.GetOwinContext().Authentication.Challenge(properties, LoginProvider); } } #endregion } }
Severity Code Source Description Project File Line Suppression State Error CS0260 IntelliSense Missing partial modifier on declaration of type 'Startup'; another partial declaration of this type exists MyProgramWebApp C:\Users\Me\documents\visual studio 2015\Projects\MyProgramWebApp\MyProgramWebApp\App_Start\Startup.Auth.cs 14 Active Error CS0246 IntelliSense The type or namespace name 'ApplicationSignInManager' could not be found (are you missing a using directive or an assembly reference?) MyProgramWebApp C:\Users\Me\documents\visual studio 2015\Projects\MyProgramWebApp\MyProgramWebApp\Controllers\AccountController.cs 18 Active Error CS0246 IntelliSense The type or namespace name 'ApplicationUserManager' could not be found (are you missing a using directive or an assembly reference?) MyProgramWebApp C:\Users\Me\documents\visual studio 2015\Projects\MyProgramWebApp\MyProgramWebApp\Controllers\AccountController.cs 19 Active Error CS0246 IntelliSense The type or namespace name 'ApplicationUserManager' could not be found (are you missing a using directive or an assembly reference?) MyProgramWebApp C:\Users\Me\documents\visual studio 2015\Projects\MyProgramWebApp\MyProgramWebApp\Controllers\AccountController.cs 25 Active Error CS0246 IntelliSense The type or namespace name 'ApplicationSignInManager' could not be found (are you missing a using directive or an assembly reference?) MyProgramWebApp C:\Users\Me\documents\visual studio 2015\Projects\MyProgramWebApp\MyProgramWebApp\Controllers\AccountController.cs 25 Active Error CS0246 IntelliSense The type or namespace name 'ApplicationSignInManager' could not be found (are you missing a using directive or an assembly reference?) MyProgramWebApp C:\Users\Me\documents\visual studio 2015\Projects\MyProgramWebApp\MyProgramWebApp\Controllers\AccountController.cs 31 Active Error CS0246 IntelliSense The type or namespace name 'ApplicationUserManager' could not be found (are you missing a using directive or an assembly reference?) MyProgramWebApp C:\Users\Me\documents\visual studio 2015\Projects\MyProgramWebApp\MyProgramWebApp\Controllers\AccountController.cs 43 Active Error CS0246 IntelliSense The type or namespace name 'ApplicationSignInManager' could not be found (are you missing a using directive or an assembly reference?) MyProgramWebApp C:\Users\Me\documents\visual studio 2015\Projects\MyProgramWebApp\MyProgramWebApp\Controllers\ManageController.cs 16 Active Error CS0246 IntelliSense The type or namespace name 'ApplicationUserManager' could not be found (are you missing a using directive or an assembly reference?) MyProgramWebApp C:\Users\Me\documents\visual studio 2015\Projects\MyProgramWebApp\MyProgramWebApp\Controllers\ManageController.cs 17 Active Error CS0246 IntelliSense The type or namespace name 'ApplicationUserManager' could not be found (are you missing a using directive or an assembly reference?) MyProgramWebApp C:\Users\Me\documents\visual studio 2015\Projects\MyProgramWebApp\MyProgramWebApp\Controllers\ManageController.cs 23 Active Error CS0246 IntelliSense The type or namespace name 'ApplicationSignInManager' could not be found (are you missing a using directive or an assembly reference?) MyProgramWebApp C:\Users\Me\documents\visual studio 2015\Projects\MyProgramWebApp\MyProgramWebApp\Controllers\ManageController.cs 23 Active Error CS0246 IntelliSense The type or namespace name 'ApplicationSignInManager' could not be found (are you missing a using directive or an assembly reference?) MyProgramWebApp C:\Users\Me\documents\visual studio 2015\Projects\MyProgramWebApp\MyProgramWebApp\Controllers\ManageController.cs 29 Active Error CS0246 IntelliSense The type or namespace name 'ApplicationUserManager' could not be found (are you missing a using directive or an assembly reference?) MyProgramWebApp C:\Users\Me\documents\visual studio 2015\Projects\MyProgramWebApp\MyProgramWebApp\Controllers\ManageController.cs 41 Active Error CS0246 IntelliSense The type or namespace name 'ApplicationUserManager' could not be found (are you missing a using directive or an assembly reference?) MyProgramWebApp C:\Users\Me\documents\visual studio 2015\Projects\MyProgramWebApp\MyProgramWebApp\App_Start\Startup.Auth.cs 21 Active Error CS0103 IntelliSense The name 'ApplicationUserManager' does not exist in the current context MyProgramWebApp C:\Users\Me\documents\visual studio 2015\Projects\MyProgramWebApp\MyProgramWebApp\App_Start\Startup.Auth.cs 21 Active Error CS0246 IntelliSense The type or namespace name 'ApplicationSignInManager' could not be found (are you missing a using directive or an assembly reference?) MyProgramWebApp C:\Users\Me\documents\visual studio 2015\Projects\MyProgramWebApp\MyProgramWebApp\App_Start\Startup.Auth.cs 22 Active Error CS0103 IntelliSense The name 'ApplicationSignInManager' does not exist in the current context MyProgramWebApp C:\Users\Me\documents\visual studio 2015\Projects\MyProgramWebApp\MyProgramWebApp\App_Start\Startup.Auth.cs 22 Active Error CS0246 IntelliSense The type or namespace name 'ApplicationUserManager' could not be found (are you missing a using directive or an assembly reference?) MyProgramWebApp C:\Users\Me\documents\visual studio 2015\Projects\MyProgramWebApp\MyProgramWebApp\App_Start\Startup.Auth.cs 35 Active Error CS0246 IntelliSense The type or namespace name 'ApplicationSignInManager' could not be found (are you missing a using directive or an assembly reference?) MyProgramWebApp C:\Users\Me\documents\visual studio 2015\Projects\MyProgramWebApp\MyProgramWebApp\Controllers\AccountController.cs 35 Active Error CS0246 IntelliSense The type or namespace name 'ApplicationUserManager' could not be found (are you missing a using directive or an assembly reference?) MyProgramWebApp C:\Users\Me\documents\visual studio 2015\Projects\MyProgramWebApp\MyProgramWebApp\Controllers\AccountController.cs 47 Active Error CS1061 IntelliSense 'ApplicationDbContext' does not contain a definition for 'healthypics' and no extension method 'healthypics' accepting a first argument of type 'ApplicationDbContext' could be found (are you missing a using directive or an assembly reference?) MyProgramWebApp C:\Users\Me\documents\visual studio 2015\Projects\MyProgramWebApp\MyProgramWebApp\Controllers\healthypicController.cs 19 Active Error CS0246 IntelliSense The type or namespace name 'ApplicationSignInManager' could not be found (are you missing a using directive or an assembly reference?) MyProgramWebApp C:\Users\Me\documents\visual studio 2015\Projects\MyProgramWebApp\MyProgramWebApp\Controllers\ManageController.cs 33 Active Error CS0246 IntelliSense The type or namespace name 'ApplicationUserManager' could not be found (are you missing a using directive or an assembly reference?) MyProgramWebApp C:\Users\Me\documents\visual studio 2015\Projects\MyProgramWebApp\MyProgramWebApp\Controllers\ManageController.cs 45 Active Error CS0019 IntelliSense Operator '&gt;' cannot be applied to operands of type 'method group' and 'int' MyProgramWebApp C:\Users\Me\documents\visual studio 2015\Projects\MyProgramWebApp\MyProgramWebApp\Controllers\ManageController.cs 294 Active Error CS1061 IntelliSense 'planthost' does not contain a definition for 'healthypics' and no extension method 'healthypics' accepting a first argument of type 'planthost' could be found (are you missing a using directive or an assembly reference?) MyProgramWebApp C:\Users\Me\documents\visual studio 2015\Projects\MyProgramWebApp\MyProgramWebApp\Controllers\planthostsController.cs 35 Active Error CS1061 IntelliSense 'ApplicationDbContext' does not contain a definition for 'healthypics' and no extension method 'healthypics' accepting a first argument of type 'ApplicationDbContext' could be found (are you missing a using directive or an assembly reference?) MyProgramWebApp C:\Users\Me\documents\visual studio 2015\Projects\MyProgramWebApp\MyProgramWebApp\Controllers\planthostsController.cs 148 Active Error CS1061 IntelliSense 'rejuvination' does not contain a definition for 'sample' and no extension method 'sample' accepting a first argument of type 'rejuvination' could be found (are you missing a using directive or an assembly reference?) MyProgramWebApp C:\Users\Me\documents\visual studio 2015\Projects\MyProgramWebApp\MyProgramWebApp\Controllers\rejuvinationsController.cs 80 Active Error CS1061 IntelliSense 'rejuvination' does not contain a definition for 'isolateID' and no extension method 'isolateID' accepting a first argument of type 'rejuvination' could be found (are you missing a using directive or an assembly reference?) MyProgramWebApp C:\Users\Me\documents\visual studio 2015\Projects\MyProgramWebApp\MyProgramWebApp\Controllers\rejuvinationsController.cs 103 Active Error CS1061 IntelliSense 'sample' does not contain a definition for 'sampleLocations' and no extension method 'sampleLocations' accepting a first argument of type 'sample' could be found (are you missing a using directive or an assembly reference?) MyProgramWebApp C:\Users\Me\documents\visual studio 2015\Projects\MyProgramWebApp\MyProgramWebApp\Controllers\samplesController.cs 26 Active Error CS0103 IntelliSense The name 'FilterConfig' does not exist in the current context MyProgramWebApp C:\Users\Me\documents\visual studio 2015\Projects\MyProgramWebApp\MyProgramWebApp\Global.asax.cs 16 Active Error CS0103 IntelliSense The name 'RouteConfig' does not exist in the current context MyProgramWebApp C:\Users\Me\documents\visual studio 2015\Projects\MyProgramWebApp\MyProgramWebApp\Global.asax.cs 17 Active Error CS0103 IntelliSense The name 'BundleConfig' does not exist in the current context MyProgramWebApp C:\Users\Me\documents\visual studio 2015\Projects\MyProgramWebApp\MyProgramWebApp\Global.asax.cs 18 Active 
This was an intentional change from the behavior of the .NET Framework. Because there may be major breaking behavior changes between versions of .NET Core, applications are not guaranteed to function the same when run on both versions. In many cases (almost all), they actually WILL work just fine, but that's an explicit decision that the application author needs to make -- and hopefully test and verify. Note that this policy has been made a little bit more lenient after .NET Core 1.0. While the CoreCLR loader will still prefer an "exact version match", it will now allow newer versions if they are available. I can expand on that if it doesn't make sense. (On the .NET Core team)
Cheap flexible branching - branches live in same folder, you can switch branch extremely quickly. This allows great workflows where you do feature branches without pain (merging is generally easy). Pull requests allow for code reviews before merging back into main branch. Local commits without pushing let's you checking throughout the day and rollback without effecting other developers. Single build definition can build any of the branches (not sure this was possible with tfvc). Easily move features between branches. Can push/pull to other remotes other than the TFS server (keep extra copy of source on githib). Distributed so if a dev does screw things up you still have a local copy on your machine with full history. Can push full history to another remote eg makes migrating easier. Can rewrite history with filters to remove things you shouldn't have checked in. The list goes on. Git is far superior 
All this, plus no more "File checked out by XXXX user" error message. But to add on the moving stuff between branches, that is a one time merge back to the source branch with tfsvc. If you try to do a merge to catch up your feature branch, it assumes every single file was changed. Arrrggggg....
Git support is fine in VS for the whole team minus the one or two that manage all the PR and merges and while it is possible it can sometimes be best to go to command line for a more complex operation (normally I only see this when somebody has been working in a silo too long and has drifted too far which is an indication you need to bring them back into the team). Git provides more and has a bigger community easier to find quick answers like stackoverflow etc I honestly can't remember enough about the actual differences except the whole team seemed to make the switch fairly seemlessly and more automated build and release tools has extensions for Git 
Had totally forgotten about server workspaces, client workspaces were a major improvement that some companies never got. 
The basically do the same thing, but what matters are the way they do it and the third party support. 1. Hassle-free branching allow for a more AGILE inspired workflow. 2. Git have all the toys and is the de-facto standard. 3. Going forward, Microsoft is promoting Git as the go-to Version Control System. If you do the switch, I recommend updating to VS2017, as the VS2015 git internal tooling isn't adequate. VS2017 use the standard git executable instead of a c library mimicking it.
Getting people used to Git is going to be a major learning curve. We finally switched several of our major teams over to Git, but there is still issues when two people are trying to merge conflicting changes. Three way merges blow people's minds, and often not in a good way. That said there's a ton of stuff that is just so much easier in git, or just can't be done in TFS without manual hacks. Natively Cross platform is also a plus - I do git pulls/pushes from our Linux boxes all the time. 
You're never alone. We always watch.
Also, TFVC, like anything that tries to be a black box that does everything, has some really bizarre quirks, and seems to just not fucking work waaaay too often (like showing files as checked in that aren't really checked in, or just failing to download certain files WITHOUT SHOWING ANY ERRORS). Additionally, the fact that they make it all but impossible to manage it from outside of a 13 GB IDE is a major problem in of itself (want to set up a CI build server that isn't on your TFS box? Fuck you, you need to install 13 GBs of shit that is completely irrelevant to that environment, rather than a 4 MB executable).
I don't have a real need at the moment. I read the issues that is linked which makes it seem like trying to use it from 2.0 brings in a lot of unwanted things and wondered if that is a general problem with anything targeting pre-2.0 &gt;There is no way to pull down Newtonsoft.Json without getting .NET Standard 1.3-dependencies. Thus effectively rendering the application unusable. https://github.com/JamesNK/Newtonsoft.Json/issues/1423
So ... yes?
I am actually setting up 2 new projects that are "the same , the second one doesn't have the issue.
Yes, it can store state on the server.
I believe you might need to pass a lambda to LessThanOrEqualTo so that it recalculates DateTime.Now every validation: LessThanOrEqualTo(c =&gt; DateTime.Now); 
You're the man (or woman), thanks!
...but nothing .NET...
Wouldn't load for me so thanks for the heads up :)
SOAP webservices are usually handled by WCF. If you have a project opened in Visual Studio right-click on the 'References' in your solution explorer and select 'Add Service Reference'. There you can put in the WSDL address and the client proxy will the generated. http://wcftutorial.net - Is good starting point
Here’s a decent example using the HttpClient. I’ve done similar myself. The trick is to set it up in a fashion whereby you automatically serialise your source object to XML, usually with the aid of declaration attributes. https://long2know.com/2016/07/consuming-a-soap-service-using-httpclient/ I tend to write an http handler factory that produces an object based on the transmission protocol SOAP / REST. Then simply serialise the object posted differently (XMK/JSON) depending on the protocol type instantiated from the factory. Any questions just reply here and I’ll try and explain. 
SOAP services typical have an exposed wsdl address. I think it's the root SOAP service address with ?wsdl on the end. Open a new VS project and add a service reference to the wsdl Url. VS will generate all the communication code for you then you can call this code from your main application code. It may take a couple times of generating the service reference to get the names spaces the way you like them. If you don't have the wsdl address to auto generate a reference then you'll have to use the XmlSerializer to deserialize the response from the server. 
Somehow their WSDL didn't generate much of anything, I had better luck using WSDL's from other services but not this one. Its as if they didn't "finish" writing it or something. I was trying to avoid manually creating and send raw XML but I don't think it can be avoided.
I don't really have access to WSDL from them, I've used WSDLs from others without issue but not this endpoint. I am more having trouble creating the request than processing the response. They want it in a SOAP envelope with headers, a body, payloads, and a bunch of other specific fields. Is there a library or anything to generate the SOAP envelope and everything automatically without me having to just manipulate a giant string of XML? I tried to use XSD from command line to create a schema from a similar file and got a hundred errors, so I'm hoping I can generate classes or something based on an example XML file they provided me instead...
The alternative is the pain of being stuck with old design decisions for the sake of perpetual backwards compatibility. There are pros and cons to both approaches.
As someone who knows nothing about react, knockout, or node, which version of dotNetify do you recommend trying out? Also, as someone who already has websites that take advantage of signalR hubs for other uses, would I still be able to manipulate signalR users and groups or would dotNetify inhibit my normal signalR use?
If you have only worked with pure html/js in the past, knockout would be easier to pick up; but there are so much good things in react - not to mention currently the most popular framework in the planet, which means a lot more available resources to tap into - that I would recommend it instead. So for client-side, dotnetify-react. If you don't want to use node/webpack yet, you can start with script tags (see the website's installation page). Server-side, it works with both .NET Core and .NET Fx. Existing SignalR hubs shouldn't be a problem. DotNetify is just another hub at the end of signalR pipeline, and I believe groups are per hub.
same solution and project
Thanks, I've been reading a lot of good things about react so I was leaning towards that anyway. Something I have to do pretty regularly with my existing signalR hub is try to keep track of active users/connections (in a DB) so I can see usage and stats about my users... does dotNetify offer any new/different way of tracking or would I just continue using the methods I've already made in onconnected/ondisconnected?
Run Fiddler to trace an actual transaction to the service. Make a class that looks just like the XML request object. Instantiate, serialize and submit it to the webservice. Do this while running Fiddler to ensure there are no differences.
I'll look when I get to work in the morning and see what I can figure out. Maybe you can see if they will email you the wsdl file info. Otherwise you are reverse engineering a soap service and that takes time. 
I've had to in the past do a simple webrequest and just send raw XML. It doesn't make you feel good, but when you're given shit, sometimes that's what you have to do. I've also done it where I've created wrappers around them and just formed my own API from that and used it that way.
There's the capability to write middlewares on dotNetify hub pipeline. It will give you access to signalR hub context for this purpose. Take a look at DeveloperLoggingMiddleware.cs in the github and Middleware documentation on the website.
WCF is the way to go if you are deeply concerned about security. WCF has implemented a great deal more of the security protocols. 
Too bad most of this stuff is ancient.
The cleanest solution to this problem is in my experience to never mix output files from different builds. Put all projects that are part of the same logical distribution unit (for example, one setup) in the same solution and only ever build it by building the entire solution. By keeping it all in one solution, it's easy to upgrade NuGet packages for all projects in one go so that all projects in that particular solution always use the same version, and as long as all projects use the same version of all dependencies, there should be no problems combining the outputs of all those projects. I've never used the GAC for anything but the .NET Framework itself, so not sure if or how it deals with it if you load multiple assemblies that use different versions of the same dependencies in the same process, if it even handles it at all.
So, to make that clear all 40 projects are part of the same solution and are built together. We manually go through references of each project, often reading the csproj file, and have checked thar no project reference old versions of assemblies, but many times the version of the assembly to use is unspecified. I can find no reference to Newtonsoft 6.0.0.0 for instance, but this version appears in the bin folder on the build machine but not on my development machine. What I meant by the GAC is that msbuild might be resorting to looking in the GAC to find Newtonsoft.dll if it cannot find it elsewhere (but we have the correct version 8 in.. /.. /assemblies/newtonsoft.dll which all project references should point to) . We never want msbuild to resort to the GAC because the solution should be self-contained and we have no control over what is on the GAC on different machines. I was beginning to wonder if perhaps some of the third party libs we use themselves reference Newtonsoft, if this is possible it may not even be visible on our csproj files? Some Google g I dictates that Azure dolls reference newtonsoft? The reason we disabled nugget was that it was pulling new versions of assemblies that had retaking changes, we for instance need sqlite 1.0.093,while 1.0.098 and newer breaks our build.
&gt;I was beginning to wonder if perhaps some of the third party libs we use themselves reference Newtonsoft That's quite likely. It's the defacto standard JSON library in .NET and even Microsoft use it in some of their libraries. Like I said, I don't know how the GAC handles this, but when using NuGet, the solution is usually as simple as just installing the latest Newtonsoft.Json and having a binding redirect in the app.config that tells it to use the latest version for everything at runtime. NuGet usually adds the binding redirect automatically. &gt; The reason we disabled nugget was that it was pulling new versions of assemblies that had retaking changes, we for instance need sqlite 1.0.093,while 1.0.098 and newer breaks our build. That should not be the case. NuGet's packages.config stores the exact version of all installed packages in a project, and when restoring, it should always restore the same version. Upgrades with NuGet are a manual operation.
You need to install some sort of Asp.net core module for IIS. Then you just set your app pool to "No Managed Code" https://docs.microsoft.com/en-us/aspnet/core/publishing/iis?tabs=aspnetcore2x
What he said - One additional note is that too redeploy you need to stop the website because the exe will be in use. Second note you may need to create logs directory and check wire permissions on it.
I've only consumed a couple SOAP services that were not implemented using WCF. The one thing I remember about them was that they had incomplete or unusable WSDL files.
[Developing Custom ASP.NET Server Controls](https://msdn.microsoft.com/en-us/library/zt27tfhy.aspx) [ASP.NET Page Life Cycle Overview](https://msdn.microsoft.com/en-us/library/ms178472.aspx)
2008
Open their WSDL file in a web browser and save a copy of it locally. There are a million ways to break an XML document, and any two implementations may disagree on whether or not a document is well-formed. The WSDL may be correct by their system's definition, but not by yours. See if you can mess with local copy to make it work for your system. By referencing the local copy you lose the ability to automatically update from the remote end, but that tends to break other parts of your programs anyhow.
This. Knowing page life cycle is key. I would also add [ASP.NET View State](https://msdn.microsoft.com/en-us/library/bb386448.aspx) for knowing how to persist between postbacks.
I'm so sorry for your current situation. Thoughts and prayers.
Holy shit I just realized that was almost 10 years ago...feels like yesterday.
tl;irisydht: He doesn't like Moq's names for things. He also doesn't compare functionality between the frameworks.
It really depends on what you are trying to do. Ive used webforms for 10+ years and have recently moved over to MVC. The learning curve was immense, but not to the point where it will break your soul like java. 
 I was able to figure it out as documented [here](https://stackoverflow.com/questions/46273067/asp-net-core-2-0-resource-access-token). In particular, [this project](https://github.com/juunas11/aspnetcore2aadauth) got me on the right track.
Can't upvote this one enough. Learning the Page Life Cycle will save you hours on hours of debugging and troubleshooting. 
find a new job man holy shit
Welcome to the real world. My advice to you is not to fully learn WebForms, just understand the concept and focus on understanding the style of the developer who created that application. Note that most of the time things might seem complex and complicated but what you need to understand is that MVC is more advanced. If you know how to do that WebForms would easy. From experience, WebForms with Java and JSON would behave in a similar manner to MVC but without a router or controllers. For that a trick which I would use is to render static data in the page and then use Javascript to get, html, Data or JSON object from another. Also IIS web.config would contain some settings to assist the application, URL rewrites. As for resources I wasn't that lucky with books. I would recommend that you download the software somewhere and start tinkering with it. 
TFSVC has code reviews now. They are listed in the "My work" tab. You could use this for a pull request like feature.
Hell.
offtopic. This vid explains on versions to choose https://channel9.msdn.com/Shows/On-NET/NET-Standard-Deep-Dive?term=standard#time=28m11s
Agreed, tremendously helpful when working in that environment. 
Thoughts and prayers
When I used to interview new programmers for web forms positions the two things i always asked were the page life cycle and the difference between response.redirect and server.transfer
Press F to pay your respects. 
In ASP.NET webforms a man has a name, and that name is freakyxz.
I find pull requests much better still
Non-sarcastic response: subscribe to Lynda.com or Pluralsight.com. Watch all. Or, do what I did and buy WebForms books and read them. Apress has some good stuff.
Thoughts and prayers 
The down-low on WebForms is this: place [web controls](https://msdn.microsoft.com/en-us/library/system.web.ui.webcontrols.webcontrol\(v=vs.110\).aspx#Inheritance%20Hierarchy) on a page (a file with an .aspx extension) using markup (or the graphical designer), write/read [properties](https://msdn.microsoft.com/en-us/library/system.web.ui.webcontrols.webcontrol\(v=vs.110\).aspx#Properties) of the elements (e.g. `myLabel.Text = "Hello, world"`), bind their [events](https://msdn.microsoft.com/en-us/library/system.web.ui.webcontrols.webcontrol\(v=vs.110\).aspx#Events) to handlers (e.g. `myButton.Click += myButton_Click`), and [write methods to handle the events](https://msdn.microsoft.com/en-us/library/system.web.ui.webcontrols.button\(v=vs.110\).aspx#Examples) (e.g. assuming C#, `void myButton_Click(object sender, EventArgs e) { myLabel.Text = "HELLO WORLD!"; }`). All pages and controls follow a life-cycle that is generally in the order: [Init, Load, PreRender, Unload](https://msdn.microsoft.com/en-us/library/ms178472\(v=vs.110\).aspx). Each stage triggers -- starting from the parent and iterating through the child controls, in turn -- an event to which you bind a handler. For example, consider a page with two controls on it. The page goes through its Init stage, and each control goes through their respective Init stage in turn; then, the page goes through the Load stage, and each control goes through the Load stage; the page goes through the PreRender stage, and each control goes through the PreRender stage; and, so on. There are some subtleties in the order in which parent and child controls trigger events, but those can be found in the documentation. Hope this helps. Edit: When did we start considering server-side web technologies as back-end? In my days, the browser code (HTML and JavaScript) was the client-side; the web application was the front-end (ASP.NET WebForms, ASP.NET MVC, Struts, JSF, etc.); the service and database layers, the back-end. Nowadays, the front-end seems to have been rediscovered as "server-side rendering" */rant*
If you do not want to set up your own NuGet repository, the following should get you there. Tools, scripts, and third-party assemblies go in separate folders in the solution root folder. Each project references the required third-party assemblies by relative path and builds to their own \bin folder. NuGet should be favoured for any assembly that is packaged.
By far the most popular way to connect to a SQL Server db is to use Entity Framework. No sense in reinventing the wheel. It does take a bit of learning to grasp the way data flows into and out of the application via entity framework but imho it is the best way. If you wanted to write your own sql queries id suggest you code the backend in php instead. No point in using the .Net Framework if your not going to use the .Net Framework lol.
You're going to want to use an ORM of some sort to avoid a bunch of tedious boilerplate code. I'm not 100% sure what you mean by control "over the flow and structure of data", but EF certainly isn't your only option. Also interesting that you lump in ADO.NET, since that's about as low level as you're going to get in the .NET world. All that said, if you want a leaner ORM, I suggest having a look at something like NPoco or Dapper, and from the sounds of it you'd probably like to pair those up with stored procs instead of direct table access.
By definition, major version increments generally mean breaking changes. Microsoft kind of spoiled (and confused?) us by maintaining an extremely high level of compatibility through pretty much all the versions of the "full" .NET framework, but at the end of the day we shouldn't be shocked that .NET Core 1 and 2 aren't 100% compatible.
What do you guys see as being gained with this pattern? I get that the general notion of circuit breakers is "stop calling broken services to avoid errors", but I'm not understanding the advantage here VS "fire and forget" async calls. At the end of the day, either you're reliant on these other services, or you're not.
Server.Transfer :S It seemed like a good idea, but not so good in practice. The risk of re-posting was worse than redirecting. I actually demoed this on stage at DevDays 99. A person in the audience came after the demo and asked what would happen if I did F5, so I did and it broke the demo app :P 
On one of my first projects I created a SQL connection into my db instance and pulled data into the application only to load into a model through iterating over a linq query called on a datatable. I forgot what the reasoning was behind doing it that way...I think it was suggested to keep the logic on the server in a sproc or something. I wouldn't suggest doing it this way. Just use EF.
Its very subjective. Based on the examples you've shown I would choose Moq.
I would recommend looking into Dapper. It's a micro ORM so it doesn't have all the bells and whistles of EF but it is simpler to use.
There are a ton of really good reasons not to want to use Entitity Framework, or an ORM at all. The biggest one being speed. Claiming that there is no reason to use .NET just because one does not use a very spesific subset of it's host of features is ignorant at best. Seriously... equating the two doesn't even make sense...
I thought Webforms is dead, however there is an ancient saying: what is dead may never die.
Isolation frameworks? Huh. That's a new one, I've never heard of them called that before actually. But yeah, I get why you might call them that. I still prefer the word mocking though. Edit: Read the article, well written. I totally agree. I find Moq overly-obstuse meanwhile NSubsitute has a much easier to read and write API. Surprised to see the relatively negative response in here, but overall does not surprise me. /u/Xellarix I would personally recommend cross posting this to /r/csharp as they are usually more open to new ideas.
Unless you have a compelling reason to do otherwise, stick with EF. It’s well documented with tons of code examples. Often a minor advantage of another method results in more extra work than it’s worth. I only fall back to data access via ADO.NET if I have a specific need - maybe the app only has one or two queries it needs to execute, or occasionally for unusual performance reasons like bulk loading millions of rows which EF isn’t optimized for.
Thinks and pray
What would be a more performant solution than Entity Framework if you are building a .NET application? 
Did you try to set the memoryStream.Position = 0 before parsing it?
❤ Yeah that was it, thanks so much
Literally dozens of other more lightweight ORMs, or ADO.NET. Raw ADO.NET is of course unbeatable, but there are some micro-ORMs that get pretty close to it in performance, leaving EF in the dust. Sure, EFs performance improved in many ways with Core -- and I wont bother with anything but EF when developing Core apps --, but OP explisitly states that he is using 4.5. https://www.exceptionnotfound.net/dapper-vs-entity-framework-vs-ado-net-performance-benchmarking/ http://ppanyukov.github.io/2015/05/20/entity-framework-7-performance.html etc. etc. It's easy to find performance comparisons if you do a few quick searches. I currently use Dapper for most projects, but fall back to EF if I need something hacked together quickly without having to worry about performance. Dapper is just a personal preference amongst the performant ORMs, tho. Looks like other posters in this thread agrees with me.
There's extensions that help you out in many of the normal use cases as well. 
I feel like EF would be the easiest to pick up and start with and once you're familiar with it you learn the pitfalls and can decide if you need more performance. I also haven't used Dapper so I could be totally off. I started my career before ORMs when we wrote stored procs for everything, don't put yourself through that.
I didn't invent that name, it comes from Roy Osherove's book, https://www.manning.com/books/the-art-of-unit-testing-second-edition, he doesn't like the Moq's API either, he suggests using NSubsitute.
I feel this is solving an astronaut architect problem...
Writing your own SQL queries (especially if you're good with SQL) is more performant. EF can generate bloated queries, I like to have full control over my database.
EF or Dapper. What normally settles it for me is how the DB schema is to be updated. If i have control then i use EF Codefirst along with migrations, if I don't then it's often easier to use Dapper as EF in opinionated on what things should be named that can lead to more work if you can't align the DB to match conventions. Don't use an EDMX.
I started reading a similar comment from above and I was about to write "yes!" when I see the poster recommend PHP instead if they aren't going to use EF. I'd like to echo your sentiments - EF is well documented and easy to use for most out of the box functions. You'll learn it's limitations pretty quickly. When i can't get what I need through EF, I use my dbcontext and connect to a stored procedure. I recently bought on a senior developer (I'm don't consider myself senior) and spent two weeks trying to "convince" him EF was a good choice when he 1) said he had EF experience 2) knew the project was existing and utilized EF and 3) he ended up having no EF or code first experience. I had to let him go after two weeks of no results. His parting shot "well, I'm senior and you just don't know yet. EF is NOT an efficient or fast framework. Fact!". This guy is 20 years older than me, and seriously a crazy genius, so I respect him, but I lost it. I pulled one line of his code and told him to go fuck himself. It was something like var result = db.People.ToList().Where(......) I asked him to send me a message once he figured out why EF was not fast, still haven't heard back. Moral of the story, you sort of get what you ask for with EF! Second point; there's an excellent nuget package for bulk inserts. I use it frequently for anything over 1000 records. 
Use EF for sinple CRUD operations. Lambda expressions for more complex queries. For complex operations write your own stored proc. For bulk updates stored procs all the way. Watch your indexes, data types and foreign keys. Don't bother writing your own ORM. 
What's wrong with an EDMX? Never caused me any problems. 
Same here. Wrote a massive app with stored procs for everything. Ended up with about 800 procs... when EF came out it was a massive cause of celebration for our team!!
Wow. That dude did a table scan.
It is refreshing to see that not everyone is in love with EF as job postings make it appear.
Merge conflict issues were my main issue. But used to find all sorts of things would break in them. 
Also not sure I could work without auto migrations and the wonders they do for branches
Use the lazy version; job done!
At job yes, but not at coding interview ;)
What? Why? Seriously if you consider using `Lazy&lt;T&gt;` for the task it was designed for bad, then I wouldn't want to work with you anyway.
You are aware that by putting .ToList() before the Where clause reads the entire table back into memory before filtering right? 
Having used Moq for a few years and NSubstitute for only a few months, I still prefer NSubstitute. I think it is mostly because it feels less verbose. In the end, the difference in experience is so small it doesn't even really matter to me though.
Yuck.
I don't know much about Lazy but I read something about threading issues once. Could that be related to the criticism?
`Lazy&lt;T&gt;` is OK as a solution for *me*, but that was a coding interview. If I used lazy then I would be asked "Can you implement it without using lazy?" anyway. What I am not happy about is that solution that contained a bug (missing volatile keyword) was accepted as something working, and that is why I quickly wrote this blog post. Asking people about singletons at job interviews encourages people to A. use handcrafted code instead of a better alternative (DI for me, say Lazy for you) at work B. spreads code that works in most cases (say 99%) but may fail sometime (my solution - was also the solution that the interviewer wanted) C. there are people that just because of boredom will go for the handcrafted code In short without Lazy singletons are hard to do right at job interview. 
Lazy *is* the solution to the threading problem of "which thread is going to initialize this thing first". Jon Skeet has an article on it. TLDR: Use Lazy. http://csharpindepth.com/Articles/General/Singleton.aspx
This comes up a lot and it always makes my eye twitch... Perhaps my coding experience has been an outlier, but only once have I seen a case where just making your class static isn't all that is needed over making a singleton class. And the other time where singleton was appropriate was due to some inherited bad architecture. Sure you can't use interfaces, and all of the child props and functions have to be static, but it operates predictably, efficiently, and easier to maintain. If you actually need to pass a singleton as a parameter to a function, I would argue that 9 out of 10 times you are probably not using it right and making things needlessly complicated. Perhaps I am being old a curmudgeon-y about this, but I am always fascinated how much this comes up over something that seems like the choices are between readable and maintainable VS fringe case of needs.
Thank you. Only once in my 13 year programming career I've had a production bug related to singletons and it wasn't because I'd implemented it wrong, but because I used it for the wrong case. 
Mocking children is rude
Yea the “solutions” he presents are pretty poor. I would not hire this person. 
A lazy programmer wouldn't worry about concurrency and use a lock. Honestly, I think that's the one thing java got right. Instead of using the lock mechanism it uses synchronize to handle concurrency. Maybe we can get this in C# 8? 
Think you might have misunderstood my post. I was talking about the `Lazy&lt;T&gt;` option: http://csharpindepth.com/Articles/General/Singleton.aspx#lazy
nah, i got it. I just wanted to talk about another way to do it. 
Seems simple enough. I typically create a folder in my user directory called 'bin' and add it to my path - all batch and powershell scripts in there will be accessible anywhere on the command line.
Yup UWP has replaced WPF. It's supposed to be able to be used on PC, Xbox, and Windows phone. They even had a tool that is supposed to convert WPF apps over. 
Synchronized in Java is basically the same as wrapping everything in `lock (this)` which is considered bad form on account of: * a) being way too broad and giving programmers a false sense of security (it's too easy to slap 'snychronized' on everything and call it a day) * b) locking on a public object (e.g. `this`) In actuality C# *does* already support this with [MethodImpl's Synchronized option](https://msdn.microsoft.com/en-us/library/system.runtime.compilerservices.methodimploptions.aspx) but you'll almost never see it referenced anywhere because it's (rightly) been superceded with more modern concurrency approaches.
It really depends upon what your desktop app needs to do. UWP apps can replace desktop apps in certain situations, but not in all of them. In our case we need full ownership of the file system, to be able to use COM components from third party vendors, and interact with dozens of different bits of hardware from various manufacturers. We found that we didn't have the required amount of control of the machine that we needed with UWP, and are quite happy with WPF.
If you're dead set on using a singleton, that's how to do it safely. Don't use singletons. Just say no.
Btw to follow up this the video is available here https://www.pscp.tv/w/bJ9EgDFEWUVYeGJsTnZFZ0x8MWxQS3F3QnJuT1pKYv2M0AtniPHoAtSDd4WZgAEYc2W_dDohpQLp5dBD8wFg
&gt; How is the library compatibility? UWP in Windows 10 Fall Creators Update will be .NET Standard 2.0 compatible, which will increase overall compatibility with older libraries.
Nah, you can pack your WPF app into APPX package, but it's not converting your app into "true" UWP app.
UWP is like a copy of WPF where they forgot to bring everything across. Unless you want to deliver to the Windows Store, I personally would recommend WPF over UWP. Also, if your target users are not all on the latest version of Windows 10, WPF is a better option.
If you need to do any of: 1. Deep system integration (admin access, complicated filesystem access, process management, any not so standard WinAPI calls, etc..) 2. Run app on a non-Windows 10 machine Then you need WPF Otherwise if it's more or less just a CRUD GUI for a webservice - UWP is a good choice Library compatibility - basically almost every .net library is compatible. 
WPF, if you want to have Windows 7 users on your app. 
Good call, https://docs.microsoft.com/en-us/windows/uwp/porting/desktop-to-uwp-root
I'm waiting for the next, next XAML based UI toolkit. I've heard of a couple ones bumping around that may actually be cross-platform.
Do you enjoy it? I have never used it.
I may be a broken record for when these things come up, but Auth0 is pretty much everything I ever wanted. Quality of life has gone way up since we outsourced user management.
WPF. Contrary to it's namesake, UWP is still very lacking in the 'universal' compatibility department. We just got done with a large UWP app and are having huge issues with deployment, even on Windows 10 devices. The guys at Microsoft are making strides but IMO it's not there yet.
I use it
What would be the point of an automated unit test? To check each controller exists and each action exists? If so, then if you removed one action accidentally the automation would simply correct the tests to appear that this was the new correct state? How would it know otherwise? Also, most web apis use facades etc for interacting with other systems or repositories for data access. You’d also need automation to mock these out and then how would it determine both the good and bad cases for each test? Not trying to be confrontational or anything, just genuinely trying to have you question the legitimacy of automated unit tests. I can see why having integrated your swagger docs you are keen to automate more via reflection etc however I don’t think this is a good practice when it comes to guaranteeing your expected state of your api. 
I've been doing the same for many years now, the built-in Identity always felt like a bit too much for me.
Nope, I use okta as a drop in replacement. 
Identity is a claims-based system You could have just used Membership, which is the NET roles-based membership system, and it would be almost guaranteed to be more secure and reliable than anything you have written yourself and solve almost all of those problems. Security is one of those "NEVER roll your own" things.
Yes. It's fine and well-tested and supported and scaleable, even at enterprise level. You can also plug in external OWIN providers etc and give yourself social logins like Facebook and twitter that still tie-in to your internal logic through OAUTH2 or whatever. It's quite a big subject though, so best to do some reading on the basics.
It's just... too much magic, and I feel like I don't have a handle on the flow and end up spending a lot of time on something that should be so very very trivial. So I end up rolling my own which probably is worse in about a hundred ways, but at least I know what's going on.
Don't apologize. You are the broken record everyone needs to hear.
You wouldn't unit test the web and point. Unit test the business layer inside
Yes, and I would still recommend the standard “out of the box” solution to begin. On the negative side, it’s got too many layers of abstraction. This is one place where they had (have?) historically fragmented the interface SO much, it’s painful. For us, we started with ASP.NET identity but have customized it heavily as we’ve progressed (multi-factor authentication, multi-stage login, SSO from other partners, custom token formats etc). We’re at the point where we’ve got more of our code than MSFT in identity ...
I only heard about that in relation to encryption.
Reading this, I'm confused. Are you saying you can't send people emails and SMS messages, or create custom roles when using Identity? Setup is also very simple. It's all done for you when you create a project, and Microsoft has written it to be secure. This is a big selling point. That coupled with how easy it is, I'm not sure why you wouldn't use it. 
I just googled this, but I don't see why it's necessary. Can you tell me what advantages they provide over the Identity Framework?
Honestly, not a chance. I just tell everyone to use auth0. Then anyone st any point can change their authentication / authorization services. At the price point its at, its always been worth it
I use it for user registration, but I roll my own custom jwt token auth using identity claims though.
It's not really a matter of capabilities, just time savings and efficiency. User management is a project until itself if done right and full featured. With legal concerns and the increased focus on personal information leaks, outsourcing that to a company who makes sure things are safe and secure, social logins keep up with changes the providers may make, and making the API adaptable to multiple apps. We did the math and we probably spent 5 or 6 times more money/time on building and maintaining user management pieces to our apps than we did to just pay auth0 (and stormpath before then) to do it for us, and way better than we did. For our smaller apps, the cost was less than one lunch per month. 
Identity w/ azure ad I see no point it using Auth0 just to reconnect back through to azure ad. Unless you're company is tiny and you're not using azure ad anyway. 
I agree that security is very important. I also agree that outsourcing it is a good strategy. With Identity Framework, you are outsourcing it to Microsoft, which I think is a very good strategy. What I don't see is why you need to take a step further and have someone else host it for you. User management is a project of its own, but Identity Framework is feature complete and provided out of the box for free. There's no reason why you can't use it to authenticate users on any platform of your choosing, to impement social logins, or to keep data secure. Identity Framework is no hassle to use. There'd be more steps, and more latency, to use someone else's solution.
IdentityServer and MS Identity. The only thing that frustrates me is MS pluralizes AspNetUsers, AspNetRoles and and AspNetUserRoles by default.. (edit, tables). 
I keep looking at Auth0 for an upcoming project. However, it's for a non-profit who doesn't seem to like paying even $13/month, but requires the use of user roles for granular permissions. I am leaning towards IdentityServer myself, but toying with Auth0 and footing the bill myself..
Yes, and it's absolutely everything I could ask for in the .NET world. You will see people claim that "it's inflexible" or "it isn't granular enough" or "it doesn't work with my database/code/design/entities/whatever out of the box" or "it's not plug and go easy" or "you have to write your own &lt;whatever&gt; to make it work". I believe those people either completely miss the point or have never actually drilled down into the inner workings of Identity 2.0 and have never attempted to do anything more than use the basic example provided by the default VS project. It's a *framework* for a claims based identity, not a one-size-fits-all NuGet package you add to a project for instant gratification. The whole idea is that you extend and implement your own custom code to provide robust, full features that your project needs without the extra overhead or security flaws that exist from implementing your own system and without being forced to implement aspects of the system you don't need. 
I wouldn't consider identity framework outsourcing at all, you are just using someone else's framework that is given out. To just get something up and running, sure identify framework may be close to the same LOE if you are doing something scaled down, but once it's live it is something else. For instance password recovery is something that can be a pain in the ass to write. Auth0 would take care of it all. The constant requests that would come up around security audits are also gone. And my developers have not had to scream at anyone about fixing their own goddamn login page in years. The bottom line is we took what was taking up an inordinate amount of time and moved it to something much more reliable than what we could build on our own, even with the help of a solid framework. It's what they do as a business instead of what we would do as a side item for our real app. Edit: And people sometimes ask, I am not affiliated with Auth0 in any way at all, really. Just a very happy customer.
No, it's not. Aside from the encryption (which, you should not write), auth code is more akin to a CRUD app with some middleware for the rest of your code to utilize.
Yikes, if 13 bucks a month is scaring them off, I would hate to think what they are (or aren't) paying you. If you need some fodder for a sales pitch, I always stress it around piece of mind, security of customer data, and free yourself to work on things that are core to THEIR business instead of trying to replicate someone else's as a side project. User management is easy to do, but expensive to do correctly and to maintain.
I do work for the school pro-bono in my free time since it’s a cause I believe in. It’s a 100% free/reduced school so money is a huge issue for them. 
I believe it went to a free licence. Haven't used it for a while myself, but it was quite useful for learning and testing ideas on it. 
Heck yeah the pro version is worth it. At work I use it for a c# scratch pad, little utilities, and for doing quick cross platform data analysis.
I'm looking at moving to it, not sure yet. It looks like it'll handle our use-cases better, but our current authentication is a bit of a mess and it's something I've been tasked with fixing for future apps.
I use it frequently, but never anything to do with LINQ. Just to write up some simple test code, like what happens if I try these different format strings on this output or try weird casting situations.
I use the pro version everyday. I use it for testing out code, and also like to see the SQL that gets generated as well. The seeing of the generated SQL works because we generate our code first code from MSSQL but have a SQLite DB that the client uses, this let’s me see in the SQL query is compatible with SQLite. I also use it to change one off production data, using the grid view. 
There really is no hard-fast rule of "never" doing anything. However, it should be looked at very closely and the options should be weighed heavily before deciding which route to go. It's usually less of a "you're not capable" and more of a "it's too expensive to do right." The issues come into play when people are incapable of deciding between those two correctly. The cheapest option is always to use something already made and well tested. How expensive it is to "roll your own" depends how deep down that rabbit hole you go. If you're wanting a proprietary encryption algorithm to be used under all of this, great that's technically not wrong. However, you better be willing to pay for a Bernstein type (who I doubt would be willing to do such a thing anyways) to handle it for ya.
Wow, no way we’d ever outsource identity! Identity/customer data is core to the business so it’s the last piece we would/could outsource. We would license tech, but that data, it’s canonical version will live squarely in our SQL databases with us having full control over it. Azure AD and Auth0 would be permitted for just some toy projects.
Probably different industries then, most people aren't in the business of their customer's data as much as using it to facilitate their business, but I can see if that was your core you wouldn't want it offsite. Nonetheless, curious as to how Auth0 with Azure AD would be more suitable than using Auth0's storage?
No, we don’t literally sell or manage identities for the business but I meant that any business is around people (or companies which have people). Identity is the foundation of the business in that sense. We ultimately get paid by person ABC (or their Dept) for providing capability X where X is segment related. All other systems, CRM, support, marketing, sales etc have been easier to integrate because of our total control on the identity layer. Hope that clarifies what I meant being at the core of the business! We’re cloud native (for the most part), but outsourcing core identity makes my hair stand up. But yeah, it’s about preference and trade offs.
[removed]
Again I must disagree. I don't think password reset is particularly difficult at all, and Microsoft provides methods to hash passwords and generate password reset tokens. All you have to do is use them, and plug in your preferred email technology to send emails to your users, and a database to keep track of things. I'm not sure why this would take up an "inordinate" amount of time, as you put it. If your team of developers can't handle it, I'd question their capabilities. There are much more difficult problems to solve than password reset, which in the grand scheme of things is fairly basic for a web developer. Please understand that I'm not trying to insult you or your team, but if you class this as a very difficult task, I find that very strange. 
For sure, I would be interested to hear what you have tried and haven't that makes outsourced ident management not appeal. Has there been problems in the past or just general uneasiness at trying it?
No insult taken, and I hope I am not insulting you either, but perhaps you haven't had to manage these large user apps before? Very big user systems have very big problems that can happen very fast. It's the nature of those systems. We are good at it, but we are not as good as a company that does nothing BUT that, and we are saving money for it. Creating the stores and processes, getting them passed, and then moving on is relatively easy. The thing is, maintaining them can be a bitch. If login, password recovery, or order systems can't get to data, it's all hands on deck to recover it and I don't care how good a dev team is, given a long enough timeline, even if it's 3 lines of code, it will eventually fail and have to be maintained. Different strokes different folks perhaps, but it definitely works for us.
Ah, well my first decision to do it on personal projects was me thinking it would save me maybe 10 hours to do on my own, and 2 hours per month of maintenance on average. It became a function of my time's worth vs the dollars I was spending. Based on that, I think the 13 is worth it.
I did the same
I've never connected LINQPad to SQL and would still highly recommended it. I've used it to test out code quickly, work with SharePoint on-prem, test out larger LINQ queries and written small scripts to process text files and other such things. It's been a figurative life-safer on several occations. If I didn't get it from work I'd buy it myself.
The Pro version also gives you NuGet, which is what I use the most: scripts small enough not to justify a full VS project, but with external dependencies.
I've avoided pre-canned auth in ASP.NET like the plague for years, but I finally gave in and tried it out. I'm using Identity on ASP.NET Core for a recent project and I find it to be simple and straightforward. I'm not using most of what's available, but I still saved a considerable amount of time not having to roll my own code.
The upgraded license adds autocomplete, debugging, and support for referencing NuGet packages. It's worth the upgrade to me, but otherwise the free version is fully featured.
I've written multiple huge apps using just ADO.NET and I've never tried EF or any other ORM... My tables are vast, complex, change frequently, and I've never felt the need to map it all out into classes or objects. That said, I don't really know much about ORMs because I've never actually tried any. Is it hard to move from plain ADO.NET over? Should I switch up what I'm doing?
I have the full version of LINQpad and recommend it wholeheartedly. The main thing I use it for is being able to test snippets of code, so if I want to know exactly how something behaves I can just do that. I'm also excited to be able to start automating things in C# without having to create an entire VS project for each thing. 
I encourage you to use the open source alternative, RoslyPad https://github.com/aelij/RoslynPad. It's not as mature; but it's still pretty great. Disclaimer: I'm not affiliated with the development/developer of the project.
Second. I have a license for LINQPad 4, but have really used it mostly as a C# scratchpad for general code, rarely for actual LINQ. I found the upgrade price to 5 rather steep for my usage and discovered RoslynPad not a long time ago. If you just need a scratchpad with FREE autocompletion (this is the main reason I bought the previous version of LINQPad) give RoslynPad a try.
i've personally bought the pro version for my home pc. And my company just bought a company wide license for it. 
You can start from here: https://www.asp.net/learn asp.net = works only on windows and is mature. asp.net core = works on windows/linux/mac, 1.1 is stable, 2.0 is the bleeding edge those both work on .net (core) which is the foundation. Latest .net is 4.7 .net core = 2.0 Almost all .net libraries will work with 4.7 so you can rely on that. Nuget.org is the repository of libraries same as npm. 
&gt;For instance password recovery is something that can be a pain in the ass to write Really? Maybe I've been doing it wrong because IMHO it’s pretty darn easy. User wants to reset a password. They trigger a request that sends an eMail to that user’s stored address with a link that has a key, key gets stored with on-the-fly encryption in DB (thanks MSSQL 2016) with a timestamp. If key gets used more than a certain amount of time after timestamp it is invalidated. Old entries get purged every 24hrs to ensure time limit. Only the correct key that matches up to both time limit and user’s eMail will provide access to password reset page, and that is *before* 2FA and challenge/response kicks in. And the key I use? A fully randomized GUID. Bloody simple, all things considered. The dev I replaced just eMailed the original passwords back to the users in plaintext; don’t tell me that this is what you are talking about. Now, if you are using a multi-platform system or use multiple different ways of logging in, I can see things getting pretty complicated pretty quickly, but if you are limited to only one platform (MVC, for example) and restrict login methods to one or two ways, I am just not seeing what the problem is.
No, I haven't done anything with a large amount of users, but I don't see how what would increase the complexity of user management. You say that maintaining these user management systems is the difficult part, and that there could be problems if they can't reach the data. I agree, but the SLA of your external provider will at best be the SLA of your own solution. Furthermore, I don't see how using an external provider will cut down on maintenance. Whether you use the Identity Framework or an external provider, you are still using somebody else's API. If I create a Login method for my website, then I have to pass that data to the Identity Framework, or to an external provider. The surrounding code should probably be the same. The code within the user management system will be maintained by some other company, and the surrounding code must be maintained yourself regardless.
Use it pretty much every day and absolutely love it! Fantastic for testing small snippets of code too. Guy I work with lets me use his license. Think it can be active on 3 devices. When I move jobs I'll definitely be buying it myself.
I put [this](https://github.com/matthewblott/simple_aspnet_auth) simple boilerplate together as I wasn't satisfied with user management in ASP.NET Core (way too complicated for simple stuff, especially newcomers) and wrote a blog post on it [here](http://www.coderscoffeehouse.com/tech/2017/09/05/simple-aspnet-auth.html).
What do you mean by utilities and cross platform data analysis? I can understand how it's a nice C# scratch pad, but how does it help you do data analysis?
I sometimes use a console project in another instance of Visual Studio to do those things. Is the experience significantly better in LINQPad versus trying out those same things in a console app?
Do you know SQL well? How is the experience different between trying out a SQL query in SQL Server Management Studio and trying out something in LINQPad in C# that will generate the SQL for you? Does having foreign key constraints on all your foreign keys make using LINQPad significantly better than writing raw SQL yourself? The database I'm currently working with doesn't have foreign key constraints on all its foreign keys, so I'm afraid trying out queries in LINQPad wouldn't be as smooth of an experience as it could be, since I'd need to join on all the foreign key IDs myself.
Start with ASP.NET MVC. If you are not on windows, start with .NET Core. That's the most modern.
I can do both fairly easy, but my preference is Linqpad. Using linqpad with foreign keys is really nice as you can just click through to get to the foreign keyed table. Since you would have to write TSQL joins in management studio, you could just write the joins in linqpad just as easy. There are some on my team that only use management studio, but they also have the red gate tools that give them intelligence. My preferred ide for database queries is still linqpad. But anything other than queries, I use management studio. 
Same! It also displays WPF controls now.
Is WinDbg actually available as a stand-alone app again? I stopped using it back when you had to install a suite of tools to get it.
I've have been using LinqPad for about nine years and it is one of my favourite programs and for me it is definitely worth it. What do I use it for. Linq2Sql Queries, Data analysis, one-off reports, prototyping reports, One off Import and export routines. I even have a few 'proper' programs that have a reference to linqpad.exe just to be able to use LinqPad's Dump routines. I have one (thankfully only one) database which does not have foreign key constraints and I would still use LinqPad if I need to execute a query on it. If you are using Linq you need to type in the join commands so it isn't much different from writing TSQL queries.
Why not avoid fakes and moqs all together... they're just snake oil.
Yes, it definitely is! It also has cheap licensing for companies, with a shared license.
It lets you run Linq queried against a data source. That’s really it’s intended purpose. What I did is I downloaded the free version and use it to see if it was worth it to me. After three days I pulled my wallet out and bought the highest level it had convinced me that it was so valuable. Within 4 months of using it the company I work for bought enterprise it had been so useful. Now my entire team uses it. 
I've been using LINQPad near daily, since discovering it during college in 2007. LINQPad is an invaluable tool, which keeps getting better. Between interfacing seamlessly with SQL server, providing first class debugging support and dozens of useful extensions like .Dump(), it is _the best way_ to test code spikes and build simple scripts in C#.
I use it all the time. Even though we use Entity Framework in our app, I often times write reports with linq2sql. Or I link it up to Entity Framework DLL from our app and can run code that way as well. And it's a great app for prototyping out little ideas or getting stuff done
Thanks! :)
That’s pretty much the same experience for most of what I do. It’s just nice convenience. The one benefit is that it will output objects in a nice visual format if you use the expression or statement type. See here https://www.linqpad.net/CodeSnippetIDE.aspx 
One example of a utility would be a clipboard data manipulators such as converting a CRLF-delimited list to a comma-separated one. On Friday I made a config file transformer. I used "data analysis" fairly broadly. An example for me is mashing up data between two unrelated data stores; log data from one area combined with business data from another to help troubleshoot some situation.
~~[PdfSharp](https://www.nuget.org/packages/PdfSharp) should get you there.~~ edit: The project I worked on that we did this I misremembered. We used [Ghostscript.NET](https://ghostscriptnet.codeplex.com/) to open and rasterize the pdf. 
From working in a corporate environment, Auth0/Identity Server makes a lot of sense. To touch on a few points. Password resets are tough, and you have to implement them, maintain them, and prevent oracle timing/padding/brute force attacks to guess a key(Auth0 does this out of the box) and keep track of IPs you should block. Along with edge cases of a user's email was never valid, or changed. In most organizations that is a change control process to get it modified in the DB or Active Directory. That is only for email, you still have to deal with closed social media accounts and modifying how they log in if that account terminates or they shut off their facebook for a week. SLA for login providers only matters when a user logs in, then they can stay logged in for a period of time. SLA for login providers is a different calculation than for a DB server or web server. SSO is something not talked about beyond the scope of social media providers. Third party systems want a SAML provider, which you can surely grab from nuget, try to configure locally with your NAT'd dev workstation and get a SSL certificate. Or you can just configure Auth0 or Identity Server to do it for you. In larger environments you want everything driven off of their Active Directory account, so you can disable that and access to 14 other systems is disabled too. Once you move to more than one system, Auth0/Identity server makes a lot more sense. Lastly, managing servers is hard. I have seen hosted SSO/SAML third party identity providers fail from misconfiguration and lack of training which could add up to $100,000 in support hours of just troubleshooting the issue.
LINQPad allows you to run raw SQL as a type of query. F#, C#, SQL as far as I can remember.
Why use FormattableString and FromSql if you can just use LINQ queries which will do everything for you, and possibly optimize your query?
Usually i resort to stand alone console applications only for very long running tasks (matters of hours of execution), or if i want/need to play with configuration files (maybe im testing a new component). Otherwise linqpad all the way. 
I'll throw another log on the fire as a happy user. I have the pro license and it's easily paid for itself. One thing I do a lot with it is import entity and business logic dlls to do one off things that we don't have any UI for. This way I can make sure all my complicated business rules get applied to whatever it is I'm doing. Some of this stuff will do things like fire off api calls to external systems to keep those in sync with our system. It would be practically impossible to do this kind of thing by manipulating the data directly in the database.
Thank you! I'll check it out!
Its available in the Win10 store as a standalone app &gt; **Installation** - You can install the WinDbg Preview from the store if you have Windows 10 Anniversary Update or newer at https://www.microsoft.com/en-us/store/p/windbg/9pgjgd53tn86 - WinDbg Preview uses some features from the Windows 10 Anniversary Update, so that’s required for now. 
Maybe we just have a difference then. I don't have issues with password reset. It's really just a case of generating a token, which Microsoft provides a function for; storing it in the DB, and emailing the user. I don't think blocking IPs is really the job of a user management system, but it's an interesting thing. There's always someone trying to brute force a database if it's connectable over all IPs. Every waking second there's some Chinese botnet trying to brute force my development database; don't know why. They have no idea that the password is ridiculously strong, and there's nothing in it anyway. I don't have this problem with my production database because it's only connectable over one IP. However, I did write a little console application that blocks their IPs anyway. To check the validity of a user's email, I agree that's the job of a user management system, but again it's rather simple. Microsoft even boiler-plates you a method for this (and for password reset, I believe). If a user wants to change their email, they'd have to contact me, and I would have to change that for them. Managing servers could get a bit error prone if you have many of them. In terms of user management, that would be the database server, or servers.. but you're going to have the same number of servers regardless of whether you outsource this, right?
Nice!
Is your relationship with auth0 purely as a customer?
I don't believe PdfSharp does any rendering. It would allow you to add an image to an existing PDF but I'm pretty sure it doesn't do any sort of rendering. I've used PDFium to display pdfs in an app before, and a quick search showed that someone has done a fork to produce jpg images. I don't have any experience with that part though.
in an app? web app? or a desktop app? It would be best if PDF could be rendered directly on the page without converting them to an image or whatever. So if PDFium can do that it's awesome!
You know. You are right. I had it confused in my head, I pulled up an old project to refresh my memory, will update my comment.
Thanks, that’s some good news
Yup, I get asked this a lot when I rave about them. Mostly as a manager of a tech team who had a lot of resources freed up when we moved to them, but every once in a while as a dev.
/r/nocontext
First of all, the dev you replaced has a special layer of hell reserved for him and people who talk in the theater. In your use case for password recovery, yes relatively simple architecturally. But now there are new tables and relationships to maintain, an SMTP server that has to be outside of our marketing server for spam reasons (and separation of concerns), and fielding support requests if emails don't reach someone or whitelisting becomes a problem. Fringe cases, but cases. Then if we have something even MORE complex like the register with one click on FB, close their FB account and now want to login, what handles that? The case where they want to login with both? Do we ENFORCE making a password and having a new step with registration outside of one click? All of this is edge case stuff, but enough where there would be meetings with the UX team, and we would implement them for a few rounds, and then maybe switch to something else, etc. It just frees up time and brain power to focus on our core services and products.
&gt;Then if we have something even MORE complex like the register with one click on FB, close their FB account and now want to login, what handles that? That makes sense. Most of my work is enterprise-level stuff, either integrated into AD or with a single type of login (invariably eMail/password, with 2FA and challenge/response for added security). Having various types of logins just doesn’t make much sense for the majority of projects I work on. &gt;the dev you replaced has a special layer of hell reserved for him A nice enough guy, but totally stuck in the past. Web forms (as late as 2015), nchar fields that needed trimming every time they were used, and *plaintext passwords in the DB*. Thankfully I have already rewritten the majority of his projects in MVC with full and proper modern techniques, but still… it’s like as soon as he learned just enough to do his job, all learning came to a screeching halt.
Is there any other way to record a trace on another machine or do you have to install windbg there, since this is probably a no-go for most production machines?
Loved the TimeoutAfter extension method. Brilliant!
This is a template meant to help people grasp the authors implementation of a good backend setup / structure. 
I have not personally purchased a piece of programming software in the past 15 years, that I can recall, but I bought LinqPad and a subsequent upgrade out of my own pocket. 100% yes. 
I think it's because your experiences with Identity are atypical. I don't know what you consider to be a lot of users, maybe I just haven't reached the pain point yet, but I built the online store for the department of fish and game in a state famous for its fishing and hunting. We have what I would consider to be a lot of users, 6 figures worth of them. We use Identity and have had no problems at all. I certainly can't imagine a side project outgrowing Identity. To me, auth0 is a solution looking for a problem. 🤷‍♂️
Here's an advantage to Auth0 that I've found, I think. Working with other people's systems is often the bane of my life. I've just implemented Google login for an upcoming web service. Using Google login with an MVC site is fine. Now I want to use Google login from WPF and Xamarin.Android applications. This is where the complexity hits. It seems like Auth0 has a one-liner for this in terms of code.
I have to be honest. I totally thought mongodb was a dead technology already. Are people still choosing this as a technology, and if so, what for?
I still see lots and lots of node/meteor/python apps using Mongo still. I barely see anyone in the .net world use it though.
I freaking love it! I can prototype everything on there. I even did a pdf ocr app completely on linqpad
Yeah that's a good call. I've seen it on the NodeJS side for sure. Thanks for the reminder ;)
Desktop app. I wrote a PDF manipulation program. At first I was checking after each run, then tried web browser, then pdfium. Pdfium was pretty fast and easy to use. 
I do the same :) So Iko goes there as well. I've aliased it to `i` so if I want to open a project with VS15, then I open run and do `i iko` and it'll open it for me. 
Xamarin Forms has been such a traumatic experience for me that I would not try it myself the new version. But still interested by feedback. Also they should work on making the feedback loop for UI development shorter. React Native is popular only because of that, and the frustration of Xamarin Forms largely comes from that.
Yes. Name recognition alone is going to keep it going for quite awhile longer even though it's the worst in class for pretty much all use cases.
I use it every day, it is a quick and lightweight way to explore a snippet of C# or F#, with built in visualisation and drill down into object hierarchies that make it a superb way of exploring APIs, endpoints and datasets. I also use it as a flexible front end for visual studio team services allowing me to slice and dice tickets and changesets as my work requires. Highly recommended.
I think Azure Cosmos DB is more of a replacement for MongoDB, i've not used either though, but I get that feeling
We use https://www.nuget.org/packages/PropertyChanged.Fody/
Looks more mature. Thanks for the link.
It's only code generation for the boring notify property change pattern. ObservableProperty embed it so you won't care about it at all anymore.
Fair points, it's a pity you've been downvoted (though somewhat predictable).
Cosmos DB has a Mongo API. There are a bunch of Mongo tools out there that for it.
Here it's being used for analytical things. So lots of data that can be used for reports. And with lots of data I mean lots. Thousands of user actions each second.
I couldn't agree more. 
https://github.com/wasabii/OLinq
It's proprietary software and you can't even self host (unless I'm missing something) so it's not a very good replacement.
Ghostscript is licensed under AGPL (restricts network deployment), and if you need to use lib based on ghostscript you need to purchase (expensive) [commercial license ](https://www.ghostscript.com/Licensing.html) as well. I can recommend to use alternative solution based on [poppler tools](https://poppler.freedesktop.org/). You can deploy it with your asp.net app and run it directly with System.Diagnostics.Process, or use existing poppler .net wrappers that will do that for you. 
as a n00b in the dotnet world, color me confused.
well, I'm author of poppler .net wrapper (you can google for it) but this is commercial component - not sure that I can advertise it here.
Wow, this article and the others in your series about this topic were super helpful to me. Thank you for sharing!
What year was that? I has made significant progress in the last 12 months with Microsoft's cooperation. What is the recompile to screen time for React Native? Much less than you saw with Xamarin Forms?
Startups.
Xamarin Forms is using net core or mono?
Is this a web project or winforms? If it's webbased, read on; Google Docs offers a PDF render engine here. Replace the pdf995.com url with the URL to your PDF - https://docs.google.com/viewer?url=http://www.pdf995.com/samples/pdf.pdf If your app can serve up the PDF dynamically i.e. www.myapp.com/pdf?docId=100 then all you'd need to do in your HTML is render https://docs.google.com/viewer?url=http://www.myapp.com/pdf?docId=100 in an iframe and you'd be all set - nothing needs to be installed clientside. 
&gt; Unless you're company is tiny and you're not using azure ad anyway. You're missing the obvious one: your users don't work for the company.
"no need to name the property with its literal" This isn't an issue anymore either with the use of nameof(property)
I personally don't like the nature of Fody. It weaves changes into your code at compile time... it works a little too much like magic. I've also had a hell of a time in the past solving bugs caused by devs using Fody without understanding what Fody does, causing weird OnPropertyChanged bugs in the code Fody generated and weaved in. Also, Fody doesn't allow you to bind many properties to the same OnPropertyChanged call. For instance, I might have a "Total" field, which should be updated anytime my variables "X", "Y", or "Z" change. With Fody, I can't tell it that "X", "Y", and "Z" should all call "OnPropertyChanged("Total")". Instead, I'd much rather manage all of my OnPropertyChanged code myself, and I can save time by using code generation. Resharper can detect usages of INotifyPropertyChanged, and automatically implement the boiler plate for you. I feel this is much more manageable than Fody's magic behavior. Plus, it's a little unsettling that you don't know how your code will *actually* look when you compile. You have to decompile DLL's to see what Fody did under-the-hood, or I think there is an interceptor you can use too. I'd much rather know that my code will compile unchanged, and just deal with a little more boiler plate. Plus the Fody Dev team aren't the most helpful on their github. 
I love `nameof`
Sorry to hear that! I'm not an advocate or shill for Fody, just giving an alternate/mature offering. It works well for us... 
Glad it does, and I hope it continues to work well for you! I just wanted to offer my opinion on Fody for any other devs who may be considering it. To each their own! 
Literal or nomeof(), you still have to test the property name before doing the job.
Two applications, or two web projects in the same solution at any rate. One is the cms (n2, umbraco, whatever) and one is your homebrew. Third project is a class library for shared code (really you're going to want multiple projects in your homebrew anyway). Consider splitting to two solutions for ease of source control management if you plan to hand off development or maintenance on the cms to another group later. You can use private nuget packages to share code between them if need be, but if you try to force a homebrew application into a cms, it will be painful later. I have done it, and it was not pretty.
Azure has that solved with B2B. Now, I totally see it if you're not using Azure or AD at all. 
Not sure if you know about sharepoint but it is OK for intranet use and supports adding pages with your own code etc 
&gt; bugs caused by devs using Fody without understanding what Fody does, causing weird OnPropertyChanged bugs in the code Fody generated and weaved If you don't really understand what it does you can't really blame the library, that's just bad form.
Normally I'd agree, but the nature of fody makes it all too easy to make those mistakes. It's unsettling when anything changes your code at compile time...
I highly recommend contentful cms as a service, that static pages no problem, the dynamic pages pull the data from contentful via your controllers and cache that data. I'm pretty sure theres a .net sdk for it, if not I built a simple one awhile back and put it on github. 
Not saying you should leave but your career is taking a step back instead of moving forward. I cut loose from a web forms chop shop few years ago because they just didn't want to invest in migrating to newer technologies and worried about my career skills going stale. 
I kinda like Fody, but only the plugins that require you to explicitly enable them. Like this one, you need to use the interface for the code to be added. When you use e.g. [Caseless](https://github.com/Fody/Caseless), then it's an absolute nightmare.
Yes, my personal experience with Forms it was before partnership with MS. Like 3 years ago. I have not used react native myself, but from what I heard of one of our developer who used xamarin.iOS and react native, he said it does not even compare. Adding a button on the iOS designer on visual studio is buggy as hell, and checking if the result was as expect took like 30s to 1min of compiling/deploying. With react native it is just save and see immediately. He did not used forms though, but I would expect it to be even worse as it is one more layer where things can go wrong.
It won't make any difference. In .NET, [connections to the database server are pooled](https://docs.microsoft.com/en-us/dotnet/framework/data/adonet/sql-server-connection-pooling). I'd suggest using the `using` statement around SQL connections and let ADO.NET take care of the pooling for you, rather than trying to implement it yourself.
Ado.net objects might fail. If you use same instances repeatedly, you will see unexpected errors. You must create, open, close and dispose on your function context, dont recycle.
If you're writing to multiple tables then you should use a sql transaction which typically means you need to use the same connection 
Mono.
Wouldn't a singleton be suited for situations like these, when dealing with unmanaged resources? 
Yeah man, this has got to be one the best and easiest error logging services ice ever used in .NET
When using unmanaged resources you should implement the IDisposable interface and free the unmanaged resources there. Then either use using (preferred) or call Dispose directly. Singleton is not needed and could cause issues with connections being closed
How does Contentful differentiate itself from SharePoint with Office 360?
Any reason you can't use an ORM like EF and let it handle the minutiae for you?
It just a really simple SqlCommand. So haven't think about EF but yeah maybe I should reconsider this.
Great info. Thanks a lot.
You may want to check out ReliableSqlConnection: https://msdn.microsoft.com/en-us/library/microsoft.practices.enterpriselibrary.windowsazure.transientfaulthandling.sqlazure.reliablesqlconnection(v=pandp.50).aspx
I wouldn't, you don't need one to run a single command. They have overhead that you don't need.
Also, check out Paket. It provides solution level package management on top of NuGet, along with tools to manage it all. 
Whats with the downvote? Dependency injection is so mainstream nowadays. 
Dapper keeps your SQL commands super simple. It doesn't involve near the configuration that EF does. It's really just a set of extensions to the IDbConnection interface that return .NET objects from SQL Commands, and is about as minimalist as you can get. I prefer rolling my own SQL, and fell in love with Dapper. I have nothing to do with the project, I just really like Dapper. :) EDIT: Revised C# to .NET. It probably works great in F#, too, I just haven't tried it.
Since you have worked with node.js, .NET Core is very similar to Express. I highly recommend you to start on ASP.NET Core 2.0. The asp.net core documentation page is good. Also check out my ASP.NET Core samples https://github.com/dodyg/practical-aspnetcore/.
using
This video does a good job explaining it. Basically looks like you're defining JSON structures and allowing a content manager to create and edit instances of them. Then you call into contentful's api to insert the content into web pages. https://www.youtube.com/watch?v=hK4mfxbcbpw&amp;feature=youtu.be
It's actually a lot easier and cleaner to use `using` blocks around all of your DB resources. ADO.NET will handle the tricky work of pooling you connections and your code will be easier to read/change. 
Thanks, will check it out :-)
I think it’s important to add: Connections that are not explicitly closed might not be added or returned to the pool. It is recommended to always close the connection when you are finished using it so the connection will be returned to the pool. 
When a connection is returned to the pool a sp_resetconnection is executed, releasing any locks.
Not a down voter but, you don't want a singleton in the case on a SqlConnection. If you use the connection object properly and let the framework handle the pooling you will have many open connections to the database. Disposing the connection will not actually close the underlying connection, it will simply be returned to the pool of connections and reused. A singleton would create one connection to the database and could potentially cause a bottleneck. 
Doesn't have to be EF. That was just an example. It can be Dapper like /u/NecroBob recommended. Which still adds some overhead, but I personally believe the benefits outweigh the overhead.
You don't have to recompile your code at all on react native. If you have hot reloading enabled it updates instantly. If not, you save the file then refresh your emulator view and you can see your changes. I'm working on a xamarin project for work, and also some react native stuff at home for personal stuff. React native is so far ahead of xamarin it's not even funny.
Dapper's pretty good, but you still have to manage connection objects. Here's my alternative. https://github.com/docevaad/Chain/wiki/A-Chain-comparison-to-Dapper