Yea that's me. I can promise you that my automapper configuration is complex
wow this is pretty interesting stuff. 
I've always loved this post: https://meta.stackexchange.com/questions/10372/is-stackoverflow-com-written-in-ruby-on-rails
Looks like you can inject with https://stackoverflow.com/a/42493106/516419 Or query the user property with https://stackoverflow.com/a/43475929/516419
You can inject IHttpContextAccessor into your services. services.AddSingleton&lt;IHttpContextAccessor, HttpContextAccessor&gt;();
I think it stands for Big Ball of Mud (aka no real architecture)... https://en.wikipedia.org/wiki/Big_ball_of_mud
It gets even more fun when we talk a out .Net Framework or .Net Core. Hell it's even changed from 2.0 to 2.1. But don't worry, this time they finally figured it out /s
So technically, any calls to `.ToList()`, `.First()`, `Single()` or anything that implies you returning an actual element or a list of elements would materialize the query. What is going wrong here is that `.Where(...)` returns a query object and `db.Posts` is not really all the posts from the database. It's the beginning of your query and the `Where` should have been built within the query sent to the server when it materializes after. Why it's not? That might be just another epic investigation from Nick. :D
Cool. On parallel, they have this minimal style and make the visual studio run like they're native mac application. What I don't feel right is that it's actually running on Windows 10. There would be great to have a solution to tune down the cpu &amp; ram usage of windows os.
VMWare Fusion has this too- “Unity”. I don’t really use it though. I just swipe to the windows os full screen when I write code and swipe back to macOS for other things. Bonus is that you can test web apps in either environment quickly.
That's why I converted to Dapper for most reads - I control the SQL statement executed by the server. After this SO outage, I have even less confidence in the SQL generated by EF.
Looks like the EF Core team are digging into it now: https://github.com/aspnet/EntityFrameworkCore/issues/13524 Weird thing is we use this kind of predicate in EF6 fairly frequently and it is translated correctly into SQL so it would seem like this is just a missing feature in EF Core
I use parallels here. It’s awesome. I dev front end web in viscose on Mac side tho
What kind of bizarre code do you write for that to happen? It’s not *that* hard to work with EF.
Polluting your business classes with ASP.NET Core specific types is best practice?
Excellent point about being able to run cake locally, I forgot to mention that. Means you can debug your build scripts!
Exactly the same. Works really well.
I usually create a CurrentUserService, which proxies the user from IHttpContextAccessor. You can provide additional logic for the user there (like roles, claims), and it's clean, because the abstraction (interface) can be shared among projects without introducing ASP.NET Core as an implicit dependency. 
For any VM related stuff, I think 16 gigs is a minimum. 8 will work but it will put strain on your ram and swap. And since you are also short on that it'll become troublesome with just a few tabs open in chrome.
30 tabs, phpstorm + visual studio + navicat + dev service to be exact. Handling that amount of application is acceptable for 8gb on Mac. Getting more is better but doesn’t mean 8gb can’t handle that.
By the way EF Core now allows to run hand-written queries. Dapper still has the upper hand in materialization performance.
Parallels for me too. I boot OSX on my SSD and Windows on my HDD, then you can just switch between the two with gestures. 16gb ram helps when you can give 8 to each.
It's absolutely not clear why this could not be translated... So weird. I'm very curious about the explanation.
Inject UserManager into the class: Declaration: using Microsoft.AspNetCore.Identity; ... public class SomeClass { ... private UserManager&lt;ApplicationUser&gt; _userManager; Then: public SomeClass(ApplicationDbContext context, UserManager&lt;ApplicationUser&gt; userManager, IConfiguration configuration) {... &amp;#x200B;
Hm, that is pretty slim. I usually give my VM 4 gb of ram, and that works fine. But chrome in your Mac will eat the remaining 4 pretty quickly. Also for the disk, if you have to go external, I think you’ll need it to be thunderbolt and SSD or the IO will slow you down too much. I don’t have any numbers for you on battery, but a VM will definitely shorten the life of a charge. A shot in the dark, but maybe half? I’ve never timed it and compared. Note regarding Visio- have you checked out Lucidchart? It’s cheaper and web-based. For most things I like it a lot more.
dotnet new webapi is all you need. You don't need MVC 
I think you shouldn't be too concerned about your stack matching exactly the future company you apply for. In my opinion having decoupled front and backend frameworks mean you are more versatile in the market. The fundamentals such as Web API theory, front end auth flow, state management etc. are more important. .NET Core implemented for backend only is quite common at least in markets I am in. Do learn EF Core though as it is commonly required.
I hire developers and I don't care which backend languages you know. I care about how good you are at coding in your preferred language. Learning a different one is very easy. Just pick something yoi enjoy.
`dotnet new react` https://docs.microsoft.com/en-us/aspnet/core/client-side/spa/react?view=aspnetcore-2.1&amp;tabs=visual-studio `dotnet new angular` https://docs.microsoft.com/en-us/aspnet/core/client-side/spa/angular?view=aspnetcore-2.1&amp;tabs=visual-studio
I’m currently using vue with aspnetcore. We use both APIs and razor views/Mvc for different things. On pages that are critically seo we do all server side rendering for content. With everything else it’s all Ajax/vue rendering. While it may have been the most popular choice to use angular with it previously, it was never the only choice.
This. My go-to is mini-spas as I usually build large apps with a variety of use cases that are too connected to make as separate apps, but have distinct enough parts that benefit from a mix of client side flow and server side rendering.
I personally found React waaaaaay better to learn and work with as a .Net dev.
Is that true? I've been with .net since the beginning and I have a hard time with Angular. I always thought Angular was used simply because it's popular and because it adopted TypeScript and was a good showcase for that.
As far as the ASP.NET ecosystem is concerned, ever since MVC5 there is no difference between Web API and Web MVC. 
Our organization uses servicestack id you want an alternative. Although I think service stack is a huge piece of shit, and isn't intuitive at all. It's an alternative. 
I dunno, I actually haven't used Angular (2+), I just see people say that a lot. It makes sense to me that it'd feel more familiar since it uses TypeScript, concepts like DI, and seems to use more typical OOP design patterns.
Yeah fair enough. There's still a distinction in the CLI though so hopefully I steered OP in the right direction.
No you absolutely don't need to subject yourself to MVC development. You'll probably enjoy making a SPA with a REST API. I also use Vue for this. MVC is certainly ~infamous~ "popular" but not as maintainable or enjoyable to use, but it has a lot of job share historically. Perhaps make a few small apps with MVC in order to compare and contrast (more like be incredulous) with how developing a SPA works.
Exactly this. And Razor Pages. Do check out Razor Pages.
I don’t know about lucidchart but I’m willing to get a tool that help me analyze project easily. The book I read was heavily use and mentioning Visio. 
Is there an example of this pattern anywhere? I feel like it would add a lot of overhead 
I have to admit. I've been doing this job for a while and its pretty interesting to watch our ecosystem naming conversions. Everyone these days seems like it has to be named something like _minimal lightweight simple {toolname}_
Are they that popular?
Not sure if I'm missing something but from a super quick glance of your implementation it seems to depend on static dictionaries which aren't thread safe. [https://docs.microsoft.com/en-us/dotnet/api/system.collections.generic.dictionary-2?redirectedfrom=MSDN&amp;view=netframework-4.7.2#thread-safety](https://docs.microsoft.com/en-us/dotnet/api/system.collections.generic.dictionary-2?redirectedfrom=MSDN&amp;view=netframework-4.7.2#thread-safety)
What exactly is required to maintain a redis or memcached database? I don't think it's as much as finding and fixing bugs in your own repo.
I also wanted a solution that a) i am familiar with to a T and b) that could be changed up in an instant to fix anything, I just thought someone else may find useful
It's easy to pick up the fundamentals but actually learning a language is going to take a lot more effort.
My mind went to "so my web app is hitting this". Consider that scenario, multiple threads hitting your database simultaneously and in the docs, as I've linked they usually mention thread safety for the classes you'll be using. In this case the first step would probably be moving from a Dictionary&lt;K,V&gt; to [ConcurrentDictionary](https://docs.microsoft.com/en-us/dotnet/api/system.collections.concurrent.concurrentdictionary-2?view=netframework-4.7.2). In *any* case. You saw a need, you made something to fill it, put it out there for all. Good for you so keep it up. You might want to check out Redis for a mature key-value DB if you want an example of something similar.
I do enjoy coding, so it was fun setting it up as much as productive
Some feedback: 1. You shouldn't need to have separate projects (and duplicate code) for different targets. Full .Net projects can consume core and standard projects out of the box. 2. Rolling your own encryption based on 3DES might not be too secure. Particularly since the encryption key will need to be hardcoded. System.Security.Cryptography.ProtectedData might be slightly more secure. 3. The foreach loops with File.WriteAllText seems suspect as I think you would only end up with one variable in the file at the end of the loop. 4. For Fields/Properties you are better off capitalizing them to differentiate from local variables. I would look for a coding standard you like, read through it and follow it as it can help develop as a programmer. 5. All the variables are static. Current initializing two different instances of `DataController`'s with different `nameInput` would result in every instance using the same file and collection because of those static variables.
Thanks, much appreciated
Why did .net have any bearing on how easy you found react? Also could you elaborate on why you felt it was easier?
I respectfully doubt that
This was unusual cause it went mostly without hiccup so it was fun
I think it's just a different way of thinking. MCV is *easy* to me and I don't get the hate? 
Strange, I’m a .net dev and had used React in the previous job and just started angular at my new place and really enjoy it. Using services, models and views seems very familiar to MVC! I never felt that way about React.
*shrug*, I absolutely believe you. I'm not sure why one feels better than the other to me. 
I agree that is why mastering one language is much more important than learning them all without any deep knowledge. It doesnt matter if it's the one you will use at your next job. You just have to show you can master one and you will get plenty of opportunities.
A solution should not be harder than the problem it is trying to solve.
You would typically build a restful API for your browser code to call, so it shouldn't matter what framework or patterns you use on the API side or what its internals look like. Java, Python, Ruby, whatever. Your Web API REST controllers should present the same contracts your browser code expects. You should write tests against them to avoid regression. You should also build a service/data layer inside your browser app so you can test your browser code without the API actually being present. I.e. in your Angular 2 view models you want to inject service providers so you can mock them and test any business logic you may have there. .Net Core Web API is probably the path to go for C#/.Net API development, or at least a very solid option. You'll use the "Microsoft.AspNetCore.Mvc.Controller" class. Try not to get too hung up on the namespace. What you do inside may be complete custom with business/data services injected and such. You should be more concerned with the REST surface of your API, the simple models and verbs that represent your "API contract." 
Right, OP may be getting too hung up on the namespace where the Controller base comes from. It's not important.
Well part of this may be due to Typescript...
It didn't really, I just found it amusing that Angular would be considered more "comfortable" to a .Net developer, especially since I personally didn't feel that way. I like the way React is structured and found the various guides and documentation to be very easy to follow to figure out what I needed to do. Like I'd go through some stuff on Angular but not really feel I remembered much, but with React I felt like I was decently productive after only a few hours.
I was just making the comment to clarify to OP that there is no difference. It's important because it can be confusing to someone new. 
How do Razor Pages fit into this?
True. But all the webapi template is is an mvc project with the 'v' being removed (no razor included by default, and controller inheriting from ControllerBase).
Nope! :) I personally enjoy Web API more. It helps separate presentation from API so well, and in extent makes the web service more maintainable. I think. :)
I have a 2012 iMac with a Fusion drive and maxed out RAM. I use VMware Fusion with the VMs on an external USB 3 SSD. It works great for me. 
I do this even with my angular front end, mostly because the data is for an HR application and very useful for multiple projects.
I actually bury the accessor behind my own ICurrentUser interface and then inject that. I just wire up different implementations to it in DI as they change things. I do that with all my aspnet dependencies. I didn't mention that to keep the answer simple. Yugatube's answer is more comprehensive.
Good, that's how it should be done.
This highlights the importance of enabling tracing to see the SQL being generated by EF - at least for new queries. Once you're satisfied, you can turn tracing off. https://stackoverflow.com/a/20751723/291719
Yes, there are differences.
It's easy to make a mess sure
And they've designed it so that if you need more functionality than Razor Pages offers, you can mix and match with MVC-style controllers and the like.
There are a lot of great comments here. I'll just plug service stack as they have some great integrations for spas. For instance it can out of the box generate a typescript client to call your Apis. You don't need any mvc components with it. Downside is you have to pay for a license at least in a commercial environment. 
I just click Publish in Visual Studio and publish directly to one of my AWS servers via IIS Web Deploy or FTP. Is there something wrong with that? Is another tool going to somehow make me more politically correct?
Blazor sure looks a lot like a C# version Vue and that's a good thing.
But I thought that Razor is just a view engine, how a view engine alone can do the job?
People underestimate bootcamp. I have been using bootcamp Win 10 and running VS 2017. It’s running nicer and quicker on 8GB ram MacBook than 32GB PC. Parallels is nice, but your MacBook resource would be split between macOS and parallels .. With bootcamp you are using the full power of your MBP just to run the windows. You just can’t go wrong with it. 
I think https://www.asp.net/learn is a great resource. Lots of tutorials for both classic .NET and .NET Core. 
If you want to promote a library or something, explain what it is for fuck sake.
Pluralsight &amp;#x200B;
It's the how Razor integrates into the API so sweetly that makes it somewhat attractive. You get to piss out server-side-rendered front-end code that has access to the all of the niceties of living on the server (easy access to DB, quicker processing, cache, etc) while writing your front-end code in tandem. The nicest part is that you can easily define what percentage of your page is pre-rendered, or is gotten in an async manner. Maybe you want your landing page to be an extremely simple RazorPage (FAST loading times) and populate the rest of your website with mini-SPAs. 
It's...interesting. Going from a language that's statically typed to one that's dynamically typed takes some getting used to. In some ways it can be nice, in others it's kind of annoying. Also kinda feels like stepping back into VB.NET in a way because you don't use brackets for blocks, you use words like def/do to start something, and end to, well, end them. Rails is also kinda weird. It's pretty powerful, but loads of "rubyists" like to go on about how you can just run a generator and it builds a lot of shit for you, and the framework is basically just magic, but I'm not really a huge fan of that, at least not yet. It's funny because when I started messing with Rails about 4 years ago it sort of "unlocked" the MVC design pattern for me and made picking up ASP.NET MVC and then Web API pretty quick, but I find myself liking the .Net implementations more. That said, I'm still very green to working with RoR professionally, so my opinions of it could change at any point. However, I do know of a few other devs in the company who come from .Net backgrounds who have been there longer than me and also still feel the same way. If anything RoR is just the tool and framework being used to get the job done, and my employer is paying me *very* well to work with it, especially for not doing any portion of their interview in the language. But who knows? They also work with React Native and JS is a bit more familiar to me, so maybe I'll transfer to a team that works on all that at some point.
Agreed. Blazors server side rendering model was officially announced as the next Razor, called Razor Components, and will ship in 3.0
Pluralsight is really the best. From beginner to advanced topics. I hate if if you go on Youtube and search for something advanced they act like you have never touched a computer before.
I have a 2015 Air with 8gb ram. I run VMware fusion and my vms are on an exteranal 512GB Lacie solid state drive with a thunderbolt connector. Honestly I think it's a fantastic combination . The only annoying thing is it takes forever for the external drive to eject from the Mac. Not sure why. I can run multiple instances of visual studio without issue plus all of the normal developer software. 
Another upvote for Pluralsight. The best option I've found so far.
What benefit does Dapper have over EF for reads?
In his case more doable solution is to use something like LiteDb of even SQLite with blobs and serializations.
Interesting idea, but that C# project is atrocious and makes it look like this post doesn’t belong in a .NET specific subreddit. Should probably go in a general web dev subreddit. 
The concurrent collections are terrible performance wise. You would not want to use them in a cache server. Concurrent collections proc the GC like mad.
Haven't heard of this one, thanks.
Also gonna have to vote for pluralsite, had me coding along with my team from 0 xp in 3 months. 
Yep about three quarters down the page. Not once did OP explain that in the submission title, submission text, or in a comment. Neither did he explain in the introductory part of the article. So your point is moot.
Exactly. Youtube, Google and other peoples open source projects. Too much there and all these people want 'compiled' resources.. ffs. And they want to be good programmers.. noobs. Now just downvote me too.
.NET is over represented in enterprise. Angular is over represented in enterprise. This is why you may see a correlation between .NET and Angular. Aside from that, there is nothing tying the two together. Angular, React and Vue works just as well with .NET, NodeJS, Java or Ruby on the backend. At my job we use React on the frontend and .NET/NodeJS on the backend.
Actually you can do [VB.NET](https://VB.NET) on macOS with Mono (I have). I even got VB.NET WebForms running on macOS and then deployed to Linux successfully. That said, if it's a big project with multiple users you'll probably need Windows: in the past I used Parallels and I'd say it's easily the smoothest of the options. You can even run it in 'Coherence' mode which runs the Windows programs in the macOS environment.
Yeah, Marten is great.
Pretty good but I recently switched to Linode who have similar prices but they also have phone support.
Go through these examples https://github.com/dodyg/practical-aspnetcore (they are very small) and read the ASP.NET Core guide at the same time. You'll go far.
Thanks!
&gt; In another post, a highly up-voted comment said that the only thing you need is new Web Apps. There seems to be many, many, many approaches to ASP dot NET - is that the consensus on the best approach? My intention is to build SQL databases for Azure and build applications based on those databases. ​For a beginner yes. You can migrate to Azure later. &gt; Am I wasting my time by trying to learn ASP.NET Core 2.1 and C# at the same time? Should I just go ahead and try making stuff in ASP.NET to figure it out? Or should I focus only on C# for awhile? dotnet core is a framework, C# is a language. Stick to the MSDN docs and you should be fine. ​ &gt; Although I have been reading and watching many videos, I am not so sure that I "get it." I think I understand the following, please correct any misunderstandings: &gt; - The view can be built in HTML or javascript via other systems. &gt; - The controller does calculations and routes data through the Model and calls views. It's like a middleman between the model and the view &gt; - The Model holds all the data and/or the data logic. - You don't build views in Javascript, you build views that _might_ leverage it. - Yes - Yes &gt; Does anyone have any recommendations for approach to learning or resources? I have been going through many different Youtube videos. I bought a book, ASP.NET Core MVC 2.0. They have helped. I've also been going through Learn C# for Beginners with Mosh. [This](https://www.microsoft.com/net/learn/dotnet/hello-world-tutorial) and [this](https://docs.microsoft.com/en-us/dotnet/core/).
It’s really annoying how slow it’s to eject and mount the external drive. I gotta say mount and eject on windows is a much smoother experience. Anyway, what visual studio were you running?
It’s nothing big. It’s just a win form project for cashier at the check in and check out gate. My coworker can only work with c# Winform so I need a visual studio to run it also.
It's a google product. It **definitely** doesn't belong in dotnet
JSON files seem pretty lightweight
ASP.NET core is tough. Everyone says they want someone with experience, but no one is using it. 
I am still unfamiliar with JSON, I needed something i knew
You are mixing a few things up. 1. C# is used in ASP.NET and .Net Core. C# is the programming language you will use in both frameworks. 2. There is not much difference in syntax and functionality when it comes to .Net Core (ASP.NET Core) and classic .Net (ASP.NET). The main difference is that classic .Net is only for Windows while .Net Core is cross platform. Personally, I would learn ASP.NET Core MVC and WebAPI with a nice Frontend like React. If you want to do databases, you'll have many options. You can go with a ORM (Object relational mapping) framework like Entity Framework Core which takes a lot of raw SQL writing from your shoulders. In the end, just try a little bit of everything, pick something you particularly like and go with that.
.Net is moving towards the end of it's life-cycle. .NET Core is Microsoft's go-forward platform, and I'd put all of my efforts towards it. .Net will be around for a long time, but I expect all of the interesting new things from Microsoft to come out of .Net Core i'd also avoid ASP.Net for just about everything except for some of the security-related features and very basic MVC stuff. The front-end is ruled by the javascript frameworks, so pick from Angular, VUE, or REACT... or something else, just not WebForms or ASP.Net rendering.
Or you know.just go use the standard template libraries
One comment I want to make here. Dont simply just design your data around a view of what's being displayed on the page, if that's what you're saying. If there's something like a service/provider layer maybe that makes sense. 
That's all JSON is, actually. 100% key value
I shall pursue this further 
&gt; The view can be built in HTML or javascript via other systems. Yes. HTML is by itself pretty unchangeable. You need something with HTML to change it - Razor, Javascript (or one of libraries/frameworks like VueJS or ReactJS). &gt; The controller does calculations and routes data through the Model and calls views. It's like a middleman between the model and the view Yes, although I wouldn't say "Routes Data through the model". The controllers do the bulk of the work. They take a request from a browser, analyze it, and then makes a query to the DB if needed, modifies the data if needed, and structures it according to models. &gt; The Model holds all the data and/or the data logic. The models are pretty much just that - models. They are blueprints that describe how objects should be built. Take for example your car. It's an object, an actual thing. Somewhere in an office at Honda is a blueprint that describes how to build this car - that's a model. A model for an Employee object would describe things like "Employee objects have an attribute called FirstName which is a string no bigger than 50 characters. It CANNOT be null. Employee objects have a attribute called Age, which is calculated by taking DateOfBirth and subtracting that from Now, which is also a DateTime field. " 
Good advice had already been given, but I just want to mention one thing. Depending on the companies and industry you want to work in, you might not need any of the front-end frameworks (Angular, React, Vue). I've been a full-stack developer for several years in both large enterprise and a couple smaller start-ups, and I still haven't had to use them. At work, anyway. Knowing them will certainly expand your options. I just wanted to point out that they aren't 100% necessary to be a full-stack .NET developer. Also, I'm not saying you can skip JavaScript and CSS. Even if you're not using a front-end framework, you still need a solid understanding of them. I'm a fan of TypeScript. Whether Razor is good for creating views is subjective. I personally like it. I'm also looking forward to Blazor (https://blazor.net) and hope it gets big. Whatever you choose to learn will be in a constant state of change. So the biggest thing is willingness to learn and keep learning. Forever. You can never stop. :)
On the syntax, I'd beg to differ. What language version is he on with C#? ASP.NET core is going to have a bunch of smaller syntactic changes. I ran into this recently wiring up authentication for an MVC app. Specifically it seems AddIdentity() is used over adding SigninManager()s and UserManager()s. Dependency injection and all that.
Again... It's also literally the third sentence.
I read the whole article also and still wondered what exactly Bazel was and why I would want it vs what I already know.
Isn't that more about the framework being used rather than language syntax though? If I'm thinking correctly (the WebAPI middleware pattern), both are just extension methods on some startup interface.
&gt;Also, I'm not saying you can skip JavaScript and CSS. Even if you're not using a front-end framework, you still need a solid understanding of them. I'm a fan of TypeScript. TypeScript + ReactJS is an amazing platform for doing front end stuff (once you get the basics of React and JSX), and is what I'm now doing as standard. Admittedly, it can be a pain in the arse to set up the first couple of times (getting your tsconfig &amp; webpack config right is the PITA bit, though create-react-app removes a lot of the initial set up).
I get you know- agreed. All the newer examples do use the latest syntactic sugar, but unless I'm mistaken, there's nothing in C#7 that's in .NET Core and not in .NET Framework?
That's also a good point, core being a slimmer subset of the Framework.
The confusing bit for newbies, I imagine, is when learning [ASP.NET](https://ASP.NET) Core for example, and following examples for Entity Framework - there are differences in EFCore and classic EF and you gotta make sure you're reading the right tutorial.
I ran interested the EF vs EF Core thing at one point also, now that you mention it. "Oh, this is the wrong EF..."
I am pretty sure MVC is getting less popular time to time. You do not have to learn it but since it is very easy to use, you might wanna learn a bit of it. You do not need to get some 'hand-on' experience. Just get familiar with it at high level. 
Syntax is a feature of the language, not the framework. C# is C# whether you are using .NET Core or .NET Framework.
I thought they were using Dapper?
This is awesome for my mixed vue.js asp.net frontend. HMR will finally work! 
To avoid confusion you should call them .net core and .net framework. That's what in all the documentation. There's also .net standard, which you'll want to target with any libraries and they can be used for both core and framework. 
Do you mean avoiding [ASP.NET](https://ASP.NET) all together([ASP.NET](https://ASP.NET) \+ [ASP.NET](https://ASP.NET) Core) or just [ASP.NET](https://ASP.NET)? Sorry for the stupid question, I just got confused.
Yeah, Pluralsight is pretty cool, I'm learning C# from it and it's doing great job, however I have to say that C# Essentials with Visual Studio 2015 from PluralSight would be really hard for anyone who hasn't experienced programming before because at first(currently) he just like ignored basic stuff like if conditions and foreach loop and other little stuff' syntaxes/advanced work and he didn't really focus on them as he just briefly mentioned them and explained them so I really feel like this will be hard for any new programmer(he even says that his tutorials need some kind of previous programming experience at first) so I suggest choosing another tutorial and then coming back to it after getting the basics, I don't know really, it might be easy for some new programmers, it's just what I felt while watching it.
You could use Dictionary&lt;string, string&gt; to store values and some function to parse the input from a console. If you need keep a value's type, you could store Tuple(type, object) as value and cast object to stored type. Although it's not quite fast due to boxing/unboxing.
No. You'll need to pull in dependencies for this. Something like a headless browser may be a decent place to start, unless you can figure out where that information came from (if you're lucky, it's an API you can ask directly)
Dapper requires you to write the SQL yourself and doesn't perform a lot of the same functions as EF so it runs much faster.
Never heard of such a thing in 40 years of MS/SQL coding. Not wasting time on reading. 
I wish I hadn't. 
Sorry for your loss.
My view on it: Your server-side rendering (i.e. Razor pages, ASPX, whatever) should be the minimum necessary to get your content working with JS disabled. The fancy presentation of said content should be done using JS+CSS.
Use a stored procedure. Job done.
This is just what I need for work where we’re not allowed to use .NET Core. The one drawback I see is the same corporate policy that stops us from using .NET Core also prevents us from using unapproved NuGet packages. FML...
Why in the world would you do this in lieu of a stored procedure...?
Please no to classic asp.net since there's already classic asp
What's the context? Typically it's whatever is *hosting* the app... container or server.
Opinions differ. Sounds like you prefer anemic domain models, while others prefer robust ones. If all your logic is in controllers, that has effects: hard to unit test, nothing to share to a non asp.net project. If more logic is in the models, you can unit test it, and use the models equally well in some console app scheduled task
MVC is it's own set of stuff to learn. Asp.net (whatever flavor) is it's own set of stuff to learn. Personally I'd recommend getting your c# chops up first sticking to console apps at the beginning, then making libraries and using those in your apps, adding unit testing. THEN come back to the web side. That way it's not an entire universe to learn at once. I knew c# when I learned MVC, and that was challenging enough for me. 
Whole internet? https://en.m.wikipedia.org/wiki/Host_(network)
Non-Mobile link: https://en.wikipedia.org/wiki/Host_(network) *** ^HelperBot ^v1.1 ^/r/HelperBot_ ^I ^am ^a ^bot. ^Please ^message ^/u/swim1929 ^with ^any ^feedback ^and/or ^hate. ^Counter: ^218014
Fear of stored procedures is quite common. Far too many developers don't understand how to do basic things like put them into source control.
Why use sp for something this simple?
There are some examples of a REST API. This is my GitHub. https://github.com/codenesium/samples A lot of people reference this project as something to go off of. https://github.com/EduardoPires/EquinoxProject This is Microsoft's demo project https://github.com/dotnet-architecture/eShopOnWeb There aren't a lot of simple examples out there but these all have things in common. SOLID principles. Separation of concern etc. 
In "asp.net" the "host" (if you're talking about things like a host transfer) is the web server that is hosting it, including server side actions.
VS 2015 pro runs great. I can run 5 instances. 2017 not so much. It's kind of a hog. 
[removed]
[removed]
[removed]
\+1 for that. It ran VS 2013 great so I install VS 2017 community and then all hell break lose. I think I will try VS 2015 since you said that it run great.
I'm pretty sure it refers to an OWIN Host. &gt; Host — The process an application and server execute inside of, primarily responsible for application startup. Some Servers are also Hosts. http://owin.org/html/spec/owin-1.0.html#2-definitions
I can confirm. It was very easy for me to pick up Angular and be productive in a really short time.
https://github.com/JasonGT/NorthwindTraders This one is really good and comes with a video explanation and an angular front end
Nice one, but I generally create some integration tests in order to insure that all dependencies all declared. Having to resolve all controllers that way will hurt app startup performance. 
Sure, that is a proper way to do it. And in our case in local development it doesn't affect performance. It is also emphasized that this should only be in development mode. Integration test can be run always.
It's a build tool, akin to [cake.build](https://cakebuild.net) or [psake](https://github.com/psake/psake) . In most cases \`dotnet build\` or \`msbuild\` is enough. But sometimes you want to complicate things - add standardized versioning, build nuget packages and push them to different development and production repos, or package a published [asp.net](https://asp.net) core site for use with octopus, etc. That's where these build tools come into play.
I will, thanks!
No one? Really? But its moving forward and having support, right?
when you put it like that... :D
titles annotated for future references, thank you!
Heres the catch with your question. Architecture scales, the bigger the project generally the more layers you start to need. Also depending on the requirements the end design could end up looking quite different, e.g. a simple rest crud v an app with heavy and complex business processes but a streamlined UI. There is no, one size fits all. So when looking at any example given, you need to keep this in the back of your mind.
You can intercept the token in the `JwtBearerOptions.Events.OnMessageReceived` and set the `Token` member in that context. .AddJwtBearer(options =&gt; { options.Events.OnMessageReceived = context =&gt; { var unencryptedToken = context.Token; var encryptedToken = Decrypt(unencryptedToken); context.Token = encryptedToken; }; }) Then normal principle hydrating will occur as usual as if the token was a plain ol simple JWT.
Thank you! This is exactly what I needed :) Much appreciated!
If the payload in the JWT is the only thing that is encrypted, would this be a problem? \`context.Token\` is the full token as a string but only the payload inside the token is encrypted. Also, little off topic but I need to use AES encryption. Is there any good library or technique i can use to simplify this? Most code examples for AES seem giant.
It is a thread responsible for managing the startup and lifetime of some arbitrary process. https://docs.microsoft.com/en-us/aspnet/core/fundamentals/host/?view=aspnetcore-2.1
You've broken down your problem into [an easy part and an impossible part, and now you're asking for help with the impossible part](https://blogs.msdn.microsoft.com/oldnewthing/20130501-00/?p=4493). JavaScript only runs when your browser is open. There's no point in trying to pull from it in a C# console app because there's not going to be anything to pull from! You're going to have to analyze the JavaScript to see where IT pulls the data from. Then you can have your C# console app do the same thing with HttpClient or whatever. As long as the website permits use of their data and server by other applications.
Mostly just do things the same way until you can't (e.g. changes in the project files or config). Stuff like Span is special purpose and most of us will never touch it 
Why don't you use a JWE instead? Then you just add the decryption key to the options and it'll handle it for you. (Sorry, I'm on my phone or I'd give you a more concrete example)
The short answer is it’s a giant company and I’m paid very well to not ask questions like that. The long answer is it’s a giant company with many IT departments; some using Java, some using Clojure, etc. Thus, automated approval and audit processes exist for Maven and npm. Since .Net is only used by a handful of departments, the NuGet package approval process is manual and I have no way to even submit a request without the approval of management and a tech strategy committee.
Yeah I ended up doing that. I found out that the standard JwtSecurityToken constructor does not support the encrypting credentials parameter but after doing some digging I found that the JwtSecurityTokenHandler's CreateJwtSecurityToken method supports it which seems strange to me. Then I used the Decryption key options parameter on the WebAPI side 
It's not exactly a recent choice. They were running LINQ2SQL wirh Dapper before. What's new is that they replaced L2S with EF Core. I would stick to one technology unless you measure that you have an actual performance problem. Otherwise it's premature optimization.
I neglected to mention L2S, because I didn't think it was relevant. Them mixing two different techs isn't new. But them mixing Dapper with EF Core, *is* recent. Even if it doesn't apply to my situation, I'm still curious whether or not tests have been done. For SO, I imagine they'd want to use their own stuff as much as possible. But I think it would be interesting to see if there are any noticeable differences between the two.
Entity Framework will never perform as well as something like Dapper because it is an apples and oranges comparison. EF has model state, so before a query is even fired it has to set up a whole bunch of cruft in memory, after the query returns the result is mapped into that model, and the model's constraints are verified. Dapper on the other hand sets up nothing beyond the database connection before query, and maps the result to an object when it returns. Dapper is like using a raw ADO.Net connection with a mapper on the result. Entity Framework is a full ORM with all of the benefits and costs that are typically associated with that. 
Dapper doesn't do the object to insert/update statement creation that EF Core does. It's focused on reading that writing. You can do writes, by executing hand rolled SQL (or a stored proc) but that's the exact complexity they avoid with EF Core. 
I'm aware. I mentioned that SO is using Dapper for reads and EF Core for writes. I'm curious on the performance between the two on the reads.
[removed]
This might be of interest to you. Benchmark comparison of multiple ORMs https://github.com/FransBouma/RawDataAccessBencher
That's great. I also managed to find one on the Dapper Github page: https://github.com/StackExchange/Dapper. But a third party review is even better. Thanks!
IdentityServer is not trivial to setup and get running (but not impossible either). If you're doing a oneman project, I will pretty much guarantee that you will feel lost for time implementing your own ID-server, if you're also responsible for the API and the frontend as well. But basically, you need a service (like ID4) that can spit out access tokens (typically via Implicit Grant) for use in your SPA. ID4 also needs to be there to check the tokens you've issued so far. If you wanna save a ~~bit of time~~ a shit ton of time, you can go for a solution like Auth0, or other auth-as-a-service providers. I think Azure and AWS offers these as well.
A huge part of the problem is they way EF is typically used with DI. Instead of creating an EF DBContext when needed and disposing it when done, they like keeping the connection open for the entire duration of the web request. This means while one web request is busy serializing JSON, another request has to sit and wait for a DB connection.
Their choice makes sense. Using each tool where they are stronger: Dapper for executing fast, hand-written SQL for what I imagine are presentation DTOs. And EF for more complicated aggregate changes and leverage its awesome change tracking.
That's a whole lot of words for a post with so little substance. This is the only actual technical complaint you raised: &gt; Only today I was dealing with an EF webapp that was keeping 2k suspended or sleeping spids open and causing the EF framework to fail to connect as it had used up its internal number of connections. EF doesn't manage the connection pooling/lifecycle (hint: ADO.NET does that, so Dapper would have the same issues given the same configuration). 
I wouldn't say so! I am using it very extensively in our internal framework that I am trying to upgrade. It, along with Memory, ArrayPool, Unsafe and other .Net Core classes are used extensively, as they can help with performance a great deal.
Well I did say "most". Someone has to use this stuff to build the low level libraries the rest of us use.
Thanks for the detailed reply. A good bit of what you say confirms my impressions based on my reading lately. I haven't heard of some of the things you mention, like Postman, but will look into them. 
EF Core is actually doing quite OK!
&gt; I don't need to go into the technical detail of why its terrible Of course. But why should anyone else be convinced by your argument then? If you only posted here to convince yourself then it was a wasted effort. I'm happy to have a technical discussion on EF's benefits and limitations, but neither your first post nor this follow-up contain anything resembling a technical critique. 
&gt; Instead of creating an EF DBContext when needed and disposing it when done, they like keeping the connection open for the entire duration of the web request. That's a valid complaint. Unfortunately if you go look at EF tutorials (including on MSDN) a single universal context was a popular recommendation for a long time. It is only semi-recently that Microsoft's documentation moved on to EF contexts housed within using(){} blocks (to reduce the lifespan yet further from a normal method scope collapse/automatic object Dispose()). Unfortunately once bad habits get ingrained, it is twice as hard to undo the damage. 
&gt; It is only semi-recently that Microsoft's documentation moved on to EF contexts housed within using(){} blocks (to reduce the lifespan yet further from a normal method scope collapse/automatic object Dispose()). Reference please. I would love to have something I could point people to that was published by Microsoft.
Ah yes, the old "I never make mistakes" defense for a bad API design.
Too bad it still can't do basic things like call a stored procedure or table-valued function. (Yes, I know about `FromSQL` and `QuerySet`. That doesn't impress me.)
It doesn't take advanced skills to get it right. Which doesn't mean there aren't bad developers who don't take the time to learn it properly. But that's the fault of the developer. &gt; .ToList().Where(x= This is a prime example of a developer not knowing how the tech works, though. It's not the norm. If the dev doesn't know that ToList() returns data, that's on them.
It depends... If EF overhead is your bottleneck then for sure go with Dapper. From another point of view Dapper will not help you with complex queries, and EF also. For solving complex query problems probably you will need to use proper indexes or denormalization, or preprocessing, so it's not about framework you'll choose.
&gt; For solving complex query problems probably you will need to use proper indexes or denormalization, or preprocessing Sure, I just mean all things being equal here. I'll probably end up sticking with EF Core unless it is the cause of slow downs.
I can’t remember as yet. I do it a lot I’m normal entity. I’m pretty sure I’ve written something recently where I needed to make the call in core and I think it’s just been updated in 2.1 to make it easier Although my post states about using core for stored procs, it applies to anything I do in .net to be honest as SQL can optimise a stored procedure more than a query passed through. I know SQL does optimise queries which are called often but stored procedures are precompiled and the query plan is known up front so as long as statistics are up to date and indexes are good then it’s as fast as you’re going to get it and I like that aspect of it. Some people call me old skool for going down this route but I generally think that some developers ignore the power of SQL for doing the job it is meant to do 
To call a stored proc in EF Core 2.1 you have to... * Create a model for the results (ok) * Register the model as a `QuerySet&lt;T&gt;` on the DBContext (huh?) * Make an inline SQL call that uses string interpolation to pass in parameters (WTF?) 
I'd suggest giving linq to db a try its the best of both, it doesn't do change tracking but you can you can write updates fluently so it's all good.
I remember thinking that registering the model felt weird. I see the dbset as a table but then you’re passing it as a model It does ring a bell on passing the params and I think it’ll be something they’ll work on I think we’ve been spoilt with how entity worked as entity used to be a similar pain when calling stored procedures (either entity or linq2sql, can’t remember which)
I see experienced contractors who generally I consider solid dotnet developers fall over on EF more often than anything else. These guys are often on the equivalent of $1000/day which is a hella lot in my city and not by any means amateurs considering the non EF stuff they have produced. Maybe I just by luck seem to interact with a lot of very good developers at c# who are just really bad at entity framework but it sure seems like EF is the the common factor. 
Everyone makes mistakes, its just some technologies are easier to make them in. 
Whilst I agree with many of your points about EF (and a reason I don't use it), I don't think there's anything inherently bad with a code-first approach if you know what you're doing.
&gt; Instead of creating an EF DBContext when needed and disposing it when done just inject a DbContextFactory then haha
[removed]
&gt; if you know what you're doing I agree so long this part is true. Yet to see it happen though. 
Some of my solutions contain multiple back and front end projects, so using Webstorm to open the front end project separate is useful in that the scope for searches, autocomplete, etc within WS is just the single project. For solutions with just a single back end and front end then Rider is indeed great for handling everything.
If you're using EF Core, you can also setup your context to use no tracking by default and opt in to tracking with .AsTracking() 
&gt; When working with Web applications, use a context instance per request. Don't do this. Your going to paint yourself into a corner in a hurry. EF DbContext's are one of those things that you need both the convenience of an ambient, default instance as well as the ability to opt out of that instance and explicitly create your own. There's a great article detailing the issues and some potential solutions: https://mehdi.me/ambient-dbcontext-in-ef6/
Look into Azure Active Directory Business to Business and Business to Consumer. It should be able to do that you're trying to achieve. 
Really? Do you have an example how to set that up? 
Absolutely. If you do one per web request, that caps you at the connection pool's max (multiplied by instances). If you keep them active only as long as needed, your concurrent cap is significantly higher. It is a dangerous anti-pattern, but unfortunately a very popular one. 
But I don't need to specify that NoTracking is default?
Sorry, I misread his post. Ignore me.
I have my developers follow a simple rule. If you're not absolutely sure what SQL EF will generate when you write a LINQ query, then you need to run it and verify. Yes it's a hassle and yes it slows down development, but it's a real issue and there's a price to pay. EF offers advantages and we have to decide what the right balance is. The benefit of forcing yourself to check is that you learn quickly what SQL EF is going to produce, and it pushes you towards isolating your queries and making them testable. We like EF for managing relationships and change sets - it's used primarily in our domain services. We pretty much never use join, but use a lot of .Includes. Filters are simple, and there's essentially an aggregate root or list of them we are selecting. EF seems to shine here. We also make it easy and safe to drop into SQL with EF, which works quite well - we can set up a more complex query on a root entity and still use Include, for example. And then of course we also have a micro ORM.
&gt; That shit does not happen when I old school roll my own .Net SQLConnection. It sure can... The only thing you've done is show that you don't know how to write EF code correctly.
Are you updating these entities or are they read-only?
Read-only. You need a DBSet to do updates directly against the entity. Very few ORMs allow you to take the results of a SP, change some values, and save them to a table. Mine does (Tortuga Chain), but I'm very opinionated as to what an ORM should be able to do. 
 services.AddAuthentication().AddJwtBearer(cfg =&gt; { cfg.RequireHttpsMetadata = false; cfg.SaveToken = true; &amp;#x200B; cfg.TokenValidationParameters = new TokenValidationParameters() { IssuerSigningKey = TokenAuthOption.Key, ValidAudience = TokenAuthOption.Audience, ValidIssuer = TokenAuthOption.Issuer, // When receiving a token, check that we've signed it. ValidateIssuerSigningKey = true, // When receiving a token, check that it is still valid. ValidateLifetime = true, // This defines the maximum allowable clock skew - i.e. provides a tolerance on the token expiry time // when validating the lifetime. As we're creating the tokens locally and validating them on the same // machines which should have synchronised time, this can be set to zero. and default value will be 5minutes ClockSkew = TimeSpan.FromMinutes(0) }; &amp;#x200B; &amp;#x200B; From: [https://github.com/Longfld/ASPNETcoreAngularJWT](https://github.com/Longfld/ASPNETcoreAngularJWT)
You can use a git or SVN client.
Yep. In your DBContext class: protected override void OnConfiguring(DbContextOptionsBuilder optionsBuilder) { optionsBuilder.UseQueryTrackingBehavior(QueryTrackingBehavior.NoTracking); }
Forget all the noise, I'm with you. A tool is only useful if you know how it won't work as well. Too many people just take ablog post or some tutorial and run with it without understanding how it might be used incorrectly. That's I don't do my own electrical. I know how it works but don't fully understand the consequences some times, so I punt to an electrician.
I'm not very comfortable with stored procedures in general. I don't like the idea of moving some of my business logic into the database. I'd rather depend on EF Core (with any provider I end up loading into it later on) than depend on specific relational database tech. Plus then I'd have to worry about making sure the stored procedure is present on any database I deploy. I'd rather be able to run "docker-compose up" etc and be done with it, having my database good to go.
You forgot to mention what UI framework you are using.
General advice on the topic. https://www.infoq.com/articles/CSharp-Models
Edited. Sorry &amp; Thanks.
Not my thing, but have you already read this article? https://docs.microsoft.com/en-us/aspnet/core/mvc/models/validation?view=aspnetcore-2.1
Yeah that's a great article and I learned a lot from it. But I still wrestle with the concept that the whole validation stems from attributes like \[Required\] being set, which I personally interpret as the code saying "when you save a new entity of type this model, make sure this value is there, else throw error." And that isn't my scenario - I just want to reference that model and say make sure this input is in the list of entities and if not, throw error.
How often do you change dB tech. That is a massively expensive undertaking and you are definitely sacrificing performance for some perceived ease of migrating? You get what you pay for.
[removed]
[removed]
[removed]
[removed]
Please use AddIdentity&lt;IdentityUser,IdentityRole&gt; instead of AddDefaultIdentity&lt;IdentityUser&gt; since it does not enable roles. If you check UserManager properties, it says roles not available (I'll confirm the exact property name when I'm in office) but that's it
Thank you so much, that was it! Your response is very much appreciated. I also had to move my ensure create to the top of the DbInitialize file, which I think I had just moved down when I was trying anything I could out.
Regarding your first paragraph: Sounds like a nice company where having your own opinion is really approved. /s I agree that approval is necessary for adding dependencies as any dependency involves a learning curve and is potential a liability, but the approval process must be accessible and rational.
There’s always migration scripts An example recently was a query which combined historical and current data into one chart. I started off writing a small class that queried out the data I needed and returned it over the API; this took around 400ms. I then rewrote the DB call to use a stored proc but feed the data into the same class, it now currently takes 80ms I’m confident now that scaling that API call will be far less expensive than before. I cache all my calls like that anyway into Redis but the initial data collection is far less expensive now
You can use a SVN client to access Git repositories on GitHub?
You can do a sparse checkout: https://stackoverflow.com/a/13738951
I guess I overreacted. But for me it is hard to imagine how most devs would be lucky (or maybe unlucky - depends on how you look at it) enough to "never touch" stuff like Span, as I find it highly useful :)
There are benchmarks on the Dapper page. There are some other ORM's with benchmarks too which compare themselves against Dapper and EF Core.
Thanks for that, I'll give it a try. 
That's just common sense. Use the tool until you hit an use case where you have to optimize. Even when you need a hand-written query EF may be enough since it supports that as well. If it's still too slow, than introduce Dapper or something similar as needed.
A less elegant way but might be quicker : https://github.com/download-directory/download-directory.github.io 
So you're looking for model validation on the front end when the user is typing values in?
Question to those that have tried out ML.NET: How easy is it for someone with no machine learning experience to get into it? I've been wanting to get into machine learning for a while, and now c# has a native library for it I feel like I should finally get off my butt and start learning. :)
Extremely quick and easy to get something up and running; their documentation has a number of concrete examples that you can use as a base to start training with your own data.
You are welcome.
Accord.Net is a machine learning library that is written in C#, has been in development for years, supports most major machine learning algorithms and has [numerous examples](http://accord-framework.net/samples.html) that you can learn from. 
No worries if you don't have time to address this, but switching to AddIdentity from AddDefaultIdentity is preventing the "Register" and "Login" links in _LoginPartial.html from working. Does AddIdentity require a different path than AddIdentityDefault? Thank you again.
&gt;Login AddIdentity does not add default login and register pages so you'll have to manually add those. Or better you can call AddDefaultUI like this services.AddIdentity&lt;ApplicationUser, IdentityRole&gt;() .AddEntityFrameworkStores&lt;ApplicationDbContext&gt;().AddDefaultUI().AddDefaultTokenProviders(); 
Nice, didn't know. There seems to be an option to selectively re-enable tracking too https://docs.microsoft.com/en-us/dotnet/api/microsoft.entityframeworkcore.entityframeworkqueryableextensions.astracking?view=efcore-2.1 
I don’t think making it so generic as IRow but the idea is the same as I was thinking. Come up with a more descriptive name to describe their commonalities.
Would you just take the loss and do pattern matching over the rest of the app to see which type each row is?
One idea is you could define the row class with a RowType enum and string Value property. Then all the rows could be the same type, and the enum will tell you how to process the data in the Value property. 
You could just use the linq method OfType to return only items of a certain type from a collection. Then you could use object IRow or whatever for your type.
What does option based mean? You could just save "numerical" and "text" as a string to use the same field. Although, that may introduce some boxing/unboxing down the line..
Sadly no, it's one of the thing I would like to do, but I think for that we need to start by creating a nugget(s) package(s), but right now you can go to the main SFML site an get the csfml binaries (at least for Windows) and build them for the other platforms
I came across this problem in a few different projects in the past. The quick and dirty solution is to send a $type property for each new object to (de)serialize. It's ugly, as the JSON from the client has to know the fully qualified name of the types on the server... yuck. The bigger problem always was that not using inheritance would've been the better solution, each and every time. Composition over inheritance FTW. Let me elaborate. The tougher solution is you make your Row object which holds the common data (like a base class), and that "has" many nullable properties for each subclass (Number, Text etc.). It doesn't seem OO, but it is. It is unconventional, but that is the model you try to make sense of. This is the same as TPT (table per type) mapping in relational databases (as opposed to TPH and TPC, which are table per hierarchy and table per concrete type, respectively). Let me know if this helps, also whichever route you chose to solve the problem. 
It would seem your form would benefit from using drop down list bound to your model rather than text inputs that need to be validated after the fact.
It would seem your form would benefit from using drop down list bound to your model rather than text inputs that need to be validated after the fact.
It would seem your form would benefit from using drop down list bound to your model rather than text inputs that need to be validated after the fact.
Doesn't matter if they're encrypted or not,. What does matter is if they're signed with the digital key and haven't been tampered with.
Just FYI ASP.NET is not ASP. ASP uses VBScript and has .asp file extensions. ASP.NET (web forms) usually uses VB.NET or C# and has .aspx file extensions. ASP.NET binaries are typically DLLs.
A nice overview of various considerations!
Very cool! I didn't know about that function!
It sounds like you are looking at the bin folder in a web application which contains compiled DLL files. If so then the best way to modify their behavior is to work from the existing source, then edit and compile your own. IF you don't have access to the source then you can use something like .net reflector to reverse engineer the dlls you have into human readable source codE. https://stackoverflow.com/questions/4608587/decompile-precompiled-source-code-asp-net
So Enums can be represented as numbers, so that works. Perhaps, you might need to enforce number usage where they need to be used as numbers? In the UI or database? Inbetween they can be strings.
What realistic scenarios can happen if someone get s an account ID? If you're worried about that, create a secondary ID and use that instead.
Thank you for sharing. I think the route we are going to go for now is to have one collection of Rows on the Form, with each concrete row inheriting from a base row class. Then, we will rely on type matching in code to determine the row type. From there, we will use DTO's that break up the Rows collection into multiple collections that separate rows by type. Could you please elaborate on your middle paragraph, using composition? How would that solution look? Or did you already describe it in your last paragraph?
Yes, the last paragraph described that solution. Using inheritance won't work well with type matching, because the JSON serializer won't know the target type to match. Easiest way to test this is just have an action parameter of IEnumerable&lt;Base&gt;, where Base is abstract. No way to know what type to instantiate there, unless the client provides the concrete type in the payload. I'm gonna show a simple example which uses composition and no inheritance (on mobile, so I'll omit visibility modifiers and property getter-setters) : ``` class Row { int Id; Text Text; Number Number; } class Text { string Content; } class Number { int Value; } ActionResult Post(IEnumerable&lt;Row&gt; rows) {...} // This will work out of the box ``` As opposed to the hierarchy like the following, which won't work unless the client sends a $type property with each element: ``` abstract class Row { int Id; } class Text : Row { string Content; } class Number : Row { int Value; } ActionResult Post(IEnumerable&lt;Row&gt; rows) {...} ``` The latter will throw an exception, because there is no way to know what to serialize from a JSON like this: ``` [ { "id" : 1, "content" : "", "value":1 } ] ``` It only works if you provide the $type: ``` [ { "id" : 1, "content" : "", "value" : 1, "$type" : "MyProject.Number" } ] ```
Check this out: [Model Diagram](http://www.nomnoml.com.s3-website-eu-west-1.amazonaws.com/#view/%5B%3Cframe%3EModel%20%7C%0A%0A%5BForm%20%7C%0A%20%20%20%20DateTimeOffset%20Time%0A%20%20%20%20String%20FolderId%0A%20%20%20%20Row%5C%5B%5C%5D%20Rows%0A%5D%20%2B-%3E%20%5BRow%5D%0A%5BForm%5D%20-%3A%3E%20%5BBaseEntity%5D%0A%0A%5BRow%20%7C%0A%20%20%20%20Int%20OrderIndex%0A%5D%20-%3A%3E%20%5BBaseEntity%5D%0A%0A%5BNumberRow%20%7C%0A%20%20%20%20String%20UnitOfMeasure%0A%20%20%20%20Double%20Value%0A%20%20%20%20Double%20UpperWarning%0A%20%20%20%20Double%20LowerWarning%0A%5D%20-%3A%3E%20%5BRow%5D%0A%0A%5BTextRow%20%7C%0A%20%20%20%20String%20Value%0A%5D%20-%3A%3E%20%5BRow%5D%0A%5BOptionRow%20%7C%0A%20%20%20%20Int%20ValueIndex%0A%20%20%20%20T%20Options%0A%5D%20-%3A%3E%20%5BRow%5D%0A%0A%5BNumberOptionRow%20%7C%0A%20%20%20%20T%20of%20Double%0A%5D%20-%3A%3E%20%5BOptionRow%5D%0A%0A%5BTextOptionRow%20%7C%0A%20%20%20%20T%20of%20String%0A%5D%20-%3A%3E%20%5BOptionRow%5D%0A%0A%5BFolder%20%7C%0A%20%20%20%20String%20ParentFolderId%0A%5D%0A%5BFolder%5D%20%2B-%3E%20%5BForm%5D%0A%5BFolder%5D%20%2B-%3E%20%5BFolder%5D%0A%5BFolder%5D%20-%3A%3E%20%5BBaseEntity%5D%0A%0A%5B%3Cabstract%3EBaseEntity%20%7C%0A%20%20%20%20String%20Name%0A%20%20%20%20String%20Id%0A%20%20%20%20String%20Description%0A%5D%0A%5D)
My main issue, is I want to have a concise model, while still making the code easy and intuitive for new programmers. For example, it's not exactly intuitive that I have to pattern match on each \`Row\` in \`Form.Rows\` to interact with its specific properties.
This looks like a great solution for JSON deserialization. Just as a reference, here is my [domain model](http://www.nomnoml.com.s3-website-eu-west-1.amazonaws.com/#view/%5B%3Cframe%3EModel%20%7C%0A%0A%5BForm%20%7C%0A%20%20%20%20DateTimeOffset%20Time%0A%20%20%20%20String%20FolderId%0A%20%20%20%20Row%5C%5B%5C%5D%20Rows%0A%5D%20%2B-%3E%20%5BRow%5D%0A%5BForm%5D%20-%3A%3E%20%5BBaseEntity%5D%0A%0A%5BRow%20%7C%0A%20%20%20%20Int%20OrderIndex%0A%5D%20-%3A%3E%20%5BBaseEntity%5D%0A%0A%5BNumberRow%20%7C%0A%20%20%20%20String%20UnitOfMeasure%0A%20%20%20%20Double%20Value%0A%20%20%20%20Double%20UpperWarning%0A%20%20%20%20Double%20LowerWarning%0A%5D%20-%3A%3E%20%5BRow%5D%0A%0A%5BTextRow%20%7C%0A%20%20%20%20String%20Value%0A%5D%20-%3A%3E%20%5BRow%5D%0A%5BOptionRow%20%7C%0A%20%20%20%20Int%20ValueIndex%0A%20%20%20%20T%20Options%0A%5D%20-%3A%3E%20%5BRow%5D%0A%0A%5BNumberOptionRow%20%7C%0A%20%20%20%20T%20of%20Double%0A%5D%20-%3A%3E%20%5BOptionRow%5D%0A%0A%5BTextOptionRow%20%7C%0A%20%20%20%20T%20of%20String%0A%5D%20-%3A%3E%20%5BOptionRow%5D%0A%0A%5BFolder%20%7C%0A%20%20%20%20String%20ParentFolderId%0A%5D%0A%5BFolder%5D%20%2B-%3E%20%5BForm%5D%0A%5BFolder%5D%20%2B-%3E%20%5BFolder%5D%0A%5BFolder%5D%20-%3A%3E%20%5BBaseEntity%5D%0A%0A%5B%3Cabstract%3EBaseEntity%20%7C%0A%20%20%20%20String%20Name%0A%20%20%20%20String%20Id%0A%20%20%20%20String%20Description%0A%5D%0A%5D). I wouldn't want to pollute my core model with the above solution because it appears to violate SRP, but this looks like a good solution for DTOs on the web api side. I can just use a mapper to get from the DTO to the core form entity. Thanks for your help!
.NET core is not only faster in a lot of ways compared to the older framework its going to receive newer features/updates way more often than the older framework. MS now recommends .NET core for new development where possible.
I usually use the "pattern" attribute on input elements. It uses regex to validate the input and lets the user know if the input is invalid as they type. https://www.w3schools.com/tags/att_input_pattern.asp
If you're targeting standard, then you can run on either core or framework. &amp;#x200B; Usually libraries are in standard, and apps are either in core or framework.
I'm actually really surprised at how succinct this is. I thought it'd just be an ad for Telerik wares, but it turned out to be a great article! 
In ASP.Net 2.1 there is a new extension method, `services.AddHttpContextAccessor()` which basically does the same thing, but is directly supported by the framework.
Core
Hell yeah i will, anything that spares me from the hell that is JavaScript is more than welcome.
The server-side version of blazor is going to be in .net core 3.0 and it will be called razor components. I plan on using it. Then when webassembly improves I'm guessing it will be trivial to enable it to run in the browser.
If I were to create an Angular app with dotnet, I would create a the template - https://docs.microsoft.com/en-us/aspnet/core/client-side/spa/angular - look at the source code, understand it and then create a new project and try to add what I need from the template. I did that with a react application, and I understood what it did, which helped me a lot, plus I could organize my project the way I wanted. 
If I understand correctly it sends interactions to the server through SignalR, and then it gets back diffed DOM updates. There shouldn't be any postbacks, and the viewstate equivalent should be much lighter.
When .NET Core 3.0 comes out we will use the server side version for internal web applications and tools and we might consider using client side Blazor after it is released if the performance is palatable.
Core
If any viewstate it could be implemented in sessionStorage, but it seems really complex and kind of confusing if it is JavaScript, server side (get with no refresh) or server side (post which would allow refresh). But they will are likely to make a decision which will make sense. As it is for now, I have been out of the .net game for a while, and now Razor pages is kind of back, where when I left it was the one which people would avoid since it was kind of like classic asp. I might have to look more at Blazor, but I am still feeling it is a far stretch and will be hard for many developer to grasp. 
I'm trying to port something right now. All the ASP.NET stuff comes with Bootstrap, but I figured out the tab panes don't work because Blazor intercepts anchor links. But someone has written [BlazorStrap](https://github.com/chanan/BlazorStrap) which looks like exactly what I was trying to come up with as a replacement.
Thanks for the link to BlazorStrap, just skimmed the source code, but my first impression is - wow, that is complex.. 😏 How is your current experience with porting your something? And why did you not choose something like React, Vue, or..... ? 🙂
Yeah. I've played around with it a little and done all the usual todo and weather apps that are popular for starting out with a framework. I've also started converting one of my projects to it to get a feel for how it works and I have to say I'm really looking forward to the possibility of it becoming production ready
I have some logic that needs to be reimplemented on both the backend and frontend, which is really annoying to implement in JS (the backend is already ASP.NET Core), and also just annoying having to update two implementations every time something changes. The implementation of BlazorStrap isn't the simplest, but using it is easy enough: https://chanan.github.io/BlazorStrap/tabs.html
Like @wllmsaccnt said, it's probably a good idea to wait until .NET Core 3 comes out to start using it as Microsoft already announced they're shipping it as part of .NET Core 3.
I think blazor + electron makes a good cross platform UI framework. You can make pretty UIs quicky since you can hijack all the web frameworks.
This isn't an official solution, but it might be useful. I'm the author of warp, a tool that allows you create self-contained single binary applications, supports .NET Core on Linux, Windows and macOS: https://github.com/dgiagio/warp
SaaS-based?
Like others have said, Core is the future and it's stable. There's not many reasons to build on older tech at this point.
I use the cli exclusively for my Angular app and use .Net Core api exclusively for the api. They really don't even need to be in the same solution, but it's easier.
*This is going to be broken up in to micro services for some of the heavier parts* Core for sure. I just wrote a...micro-ish.. service using Core for the first time, and the only big differences I had to read up on were using the built-in dependency injection, and the appsettings.json files that replace web.confg. The DI is awesome and easy to use, and when you combine it with appsettings.json you can [inject custom configuration objects](https://andrewlock.net/how-to-use-the-ioptions-pattern-for-configuration-in-asp-net-core-rc2/) which saved me so much time.
I inherited an application that did this. public class FormValue{ public string TextValue; public int? IntValue; public decimal? DecimalValue; public bool? BoolValue; } The database table had a constraint so only one of the four values could not be null. It worked.
I doubt you'll be able to do this without some serious hacking. I believe the options variable there has a thing called JwtBearerEvents (you may need to assign it a "new JwtBearerEvents() { /\* your stuff \*/ }), and on there you'll see various stages in the pipeline for the token. OnMessageRecieved gives you a chance to mess with the token before the framework does anything. You can attempt to decrypt, and on failure, reject it there. However i'd strongly recommend \*not\* doing that, and just making sure that the stuff in your jwt isn't particularly sensitive. If a user has authenticated, they own their jwt. If you inspect jwts from other websites, you'll see claims about your email, or userid, or whatever.
Isn't compiling to a single file coming out in .net core soon? I thought I saw something about it recently. 
i'm not sure if this exists in ef, but in ef core you can have dbcontext pooling. there's some limitations around this that i can't quite recall, but if you aren't doing anything too off the beaten path, it should "just work" (tm), and you basically get the dbcontextfactory for free.
this is where abstraction is nonsense, in my opinion. it's like abstracting over aws and azure. migrating between dbs or cloud providers is going to be a huge pain in the ass no matter what. so just pick one and use it.
Mother of god, that font. It's like comic sans meets r/fellowkids
No, I'm not interested in it. I'm already familiar with using TypeScript for front end right now and haven't felt a need for something different.
Mother of god, that font. It's like comic sans meets r/fellowkids
These answers here are all sort of right and sort of wrong. It is easiest to explain by example. Let's say I have written an [asp.net](https://asp.net) core app. Some routes, some logic, etc. This code needs to run by a webserver somehow. So I need: \- An [i](https://asp.net)mplementation of the [IServer](https://docs.microsoft.com/en-us/dotnet/api/microsoft.aspnetcore.hosting.server.iserver?view=aspnetcore-2.1) interface. This is what kestrel is. This is the thing that knows how to read from and write to web requests (broadly speaking). But this is just an interface capable of doing webserver stuff, but something has to run it. So I need: \- An implementation of the [IWebHost](https://docs.microsoft.com/en-us/dotnet/api/microsoft.aspnetcore.hosting.iwebhost?view=aspnetcore-2.1) interface. This is the part that actually wires up DI and has the Run() or RunAsync() methods. This is basically becomes the entrypoint for your program. This is what i would call the "[asp.net](https://asp.net) core host". It is the thing that bootstraps the webserver. So now you have a process capable of serving web requests, but you need to run this process somewhere. So I need: \- A place to run the process. This may be a container (a la docker), or a vm, or maybe even aws lambda behind api gateway (they implement the same interfaces). This part could also be considered a host, but it would not be an [asp.net](https://asp.net) core host, it would just be a host for a process. You can host any process in this fashion. &amp;#x200B; As an aside, in 2.1 they introduced the concept of the "generic host", which is a \*different\* interface, [IHost](https://docs.microsoft.com/en-us/dotnet/api/microsoft.extensions.hosting.ihost?view=aspnetcore-2.1), which, in their infinite wisdom, is not a supertype of IWebHost. However the concept is the same, the generic host is the thing that bootstraps your program and effectively becomes "main".
I dont think you need to worry about viewstate. As far as your blazor app is concerned it would be running as if it was running in the browser. Think of it like rdp, the browser is sending mouse movements, keys and the server sends back the pieces of ui to update. I use a framework called wisej that uses a similar model but is more like winforms.
I am implementing it now on a very small internal web app. I was fairly proficient in AngularJS, then started down the path of Angular 2+, got annoyed, and am pretty excited about Blazor. Zen washes over me every time I can reference the domain objects from the client side. So far the biggest challenge has been that the way things are implemented changes very fast and the documentation isn’t completely up to date always. It’s hard to google examples because posts that are even a month old are out of date. Still worth it. I haven’t tackled razor components yet because the methodology seems pretty contrary to the Web. It doesn’t sit right to have the server handling UI interactions/updates instead of the browser. That doesn’t seem scalable to me, but that is just speculation. 
Is there a written recap by now? In the past they did that. I really can't stand watching a 67 minute video for 5 minutes content.
I look forward to the day when I don't have to write a single line of javascript ever again.
Yep that's essentially what I ended up doing. Just made a model to reflect the request being submitted and added remote validations on the fields in question. Works fine - maybe not the best way (I should get more creative with how I capture the input, but that's a phase 2 issue). Thanks!
Managed to do it by studying the JwtJBearerHandler code and adding this: options.Events = new JwtBearerEvents { OnTokenValidated = context =&gt; { var jwtToken = context.SecurityToken as JwtSecurityToken; if (jwtToken?.RawPayload != null) context.Fail("Token not encrypted"); else context.Success(); return Task.CompletedTask; } };
Wow, most commenters here don't know what .NET Standard is. If you plan or might plan to share code between different projects (Core, Framework, WPF, Blazor, Mono, Xamarin), the shared code (models, service interfaces, common helpers and extensions) should be in .NET Standard projects. That is only for *code portability*. You still need a runtime, and you should go with .NET Core, but some enterprises still depend on legacy Framework assemblies. If you have no alternatives, use the old framework, but you'd be better off trying to avoid those dependencies (or if they're in-house, move them to .NET Standard). 
WPF?
How does it work? I had a quick glance at the code on mobile and saw tar and gzip mentioned — does it extract all the files to a temporary directory and execute from there? Or something else?
So.. ILMerge for Core?
Oracle has recently taken their [Oracle.ManagedDataAccess.Core](https://www.nuget.org/packages/Oracle.ManagedDataAccess.Core) package out of Beta, [here's a usage example from Stackoverflow](https://stackoverflow.com/questions/41459631/how-to-connect-to-an-oracle-database-connection-from-net-core). 
You need to download the Oracle Data Provider from nuget. Its an ADO.NET driver for Oracle databases in .NET Core. You should be able to execute queries just like you do in normal ADO.NET except you use an OracleConnection, OracleCommand and OracleDataReader object string conString = "Pooling=false;User Id=Maher;Password=oracle;Data Source=localhost:1521/mydatabase;"; using (OracleConnection con = new OracleConnection(conString)) { using (OracleCommand cmd = con.CreateCommand()) { try { con.Open(); cmd.CommandText = "SELECT COL1, COL2 FROM TABLE"; OracleDataReader reader = cmd.ExecuteReader(); while (reader.Read()) { i++; await context.Response.WriteAsync($"#{i}: " + reader.GetInt32(1) + "\t" + reader.GetString(0) + "\n"); } reader.Dispose(); } catch (Exception ex) { await context.Response.WriteAsync(ex.Message); } } }
I'm waiting for it to get to 1.0 before diving in due to so much change. That being said, I'm excited for doing things this way. We can finally write business rules once and use them both places. Also, all sorts of cool controls can come out of this that you can just get a package for and have full intellisense. This might kill all the JS frameworks too, so no more trying to stay ahead in that mess.
[removed]
Thanks for your reply. I'll check that
I'll keep my eye on it and do some small projects based off templates. I won't do anything professionally with it for several years most likely (barring something that overwhelmingly convinces me that it's stable/mature enough). 
Javascript hasn't been hell for a long time. The Javascript \*ecosystem\*, on the other hand...
Probably not. A lot of the work recently in the web development community has been on prioritizing client bundle sizes (JS in this case). We're talking major production applications in under 15kb or so. The reason for this is to support a large amount of users around the world who are on mobile devices with very slow internet connections (3G speeds max). Companies want to open their products to these markets and prioritizing initial load times on front-end web apps is key for this. Blazor requires downloading a large (in relative terms) run-time before anything on the page can be rendered. I think the idea is great but until the bundle size becomes on par with the modern JS frameworks we have now, I will probably pass. (Server side blazor is also unfeasible in these cases because maintaining a websocket connection on a slow 2G/3G device is also unrealistic). This is my current outlook on the situation anyway and obviously is subject to change once we see a more production ready version of blazor.
&gt;~~Cross-Origin Request Sharing~~ is a mechanism to bypass [Cross-Origin Resource Sharing](https://en.wikipedia.org/wiki/Cross-origin_resource_sharing) FTFY
**Cross-origin resource sharing** Cross-origin resource sharing (CORS) is a mechanism that allows restricted resources on a web page to be requested from another domain outside the domain from which the first resource was served. A web page may freely embed cross-origin images, stylesheets, scripts, iframes, and videos. Certain "cross-domain" requests, notably Ajax requests, are forbidden by default by the same-origin security policy. CORS defines a way in which a browser and server can interact to determine whether or not it is safe to allow the cross-origin request. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/dotnet/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
Consider cross-posting this to /r/rust! Glad to see more tooling in Rust supporting other languages.
You are basically right. I just added a "How it works" section to the README if you are interested - https://github.com/dgiagio/warp/blob/master/README.md#how-it-works
I'm looking forward to that. But I'm not sure when it's arriving and whether it would support all features of .NET Core (such as full reflection). In the meantime, Warp might be helpful.
It doesn't work at the IL level, it's more a generic tool that works with any kind of application that has an executable and dependencies, not just .NET Core.
Sounds like a good idea, just did. Thanks for the suggestion.
No, I am quite happy with C# on the backend and a front-end Javascript SPA. I know a lot of people aren't willing to learn Javascript because its cool to hate though.
ValueInjecter
Automappee
Use Xamarin
Shameless self promotion here :D I made a lib that uses zero configuration, but enables runtime mapping extension. Feel free to take a look (also available on NuGet): [QueryMutator](https://github.com/yugabe/QueryMutator). We've used it in production in 3 different project up till know, a few minor issues are known, but most cases are successfully mapping. It also supports mapping enumerables/collections of different types to each other, including nested types. The next version will integrate with dependency injection, and will be part of a larger framework. It's currently in experimental beta at [MutatorFX](https://github.com/yugabe/MutatorFX).
This is actually a valid concern. Would love to hear some opinions on how this might be addressed. 
I do it by hand. I've found that libraries which claim to do it for you are brittle and I would rather see a compiler error than a runtime exception.
You're welcome! obligatory: [Duty Calls](https://xkcd.com/386/)
Xamarin Forms makes it pretty easy to make cross platform iOS / Android / Windows Store apps
What about writing a T4 template that uses reflection to generate these mappings? Or, after some googling, something like https://github.com/cezarypiatek/MappingGenerator ?
Yes, matching the same regular expression against the same string will always return the same result. The "deterministic", as used by the article references individual subexpressions: &gt; Nonbacktracking subexpressions ... If you do not use this construct, backtracking searches from the larger expression can change the behavior of a subexpression. That means, you only need to know the input to a `(?&gt; exp )` subexpression to determine its output. It is "deterministic", a.k.a, it is a mathematical function mapping a string to a match. A `( exp )` subexpression, however, requires knowledge of the whole regular expression to determine its output. It is context sensitive and therefor not a mathematical function, aka not "deterministic".
I recommend Xamarin Native over Xamarin Forms. Forms sounds nice and if you are strictly making "forms" then it might be a good choice but, but if you want to deal with native functionality I found it rather buggy and frustrating. Also it's been 2 years since I've used Forms. 
I am making an app where you put in your YouTube subscriptions and then it presents a feed of new videos which you can download as MP3, so I can listen to them on my commute. To be honest I think it may be against Google's terms of service, so it may not ever be put on the app store, but I would like to use it. It is very simple, I already made a WPF app that downloads the MP3 using YouTubeExplode nuget package. YouTube's API can be used to get the video links for any given channel. It is just a case of making a simple UI for it and sticking it on my phone.
You could just click the download button under the YouTube video in the YouTube app...
Searching SQL strings with Regex to find Uniqueidentifiers. That sounds like some serious WTF... Good luck with that project.
Just cast the source object to dynamic then use reflection to loop through the target object's properties and reference accordingly using try/catch to eat any missing member errors.
Yeah. Is this a one-time information-gathering expedition where the output will be verified by a human? No biggie. It could be workable. Is this supposed to be a permanent part of the system that is used in production? Oh, fuck no. Tony the Pony He Comes, and all that.
Well yeah, but why would a bunch of UniqueIdentifiers need to be parsed out of strings with RegEx? If you have a string field in a database it should at least be JSON or XML so it can be parsed. Regex is not something you usually use in SQL Queries...
How does Blazor scale and handle many users?
Doesn't the YouTube app stop you from listening with your phone locked? I think you have to pay to unlock that. Also I don't want to download the video, just the audio.
Not sure. I just pay for it anyway, don't know what features it gives me. 
That’s a lie. YouTube Red came out barely 3 years ago. Doubt you just discovered the app
You're right, it gives me ad free YouTube. That's what I pay for it. Not sure what else is included. 
I'm surprised by the amount of positive comments. Last time I tried to develop an app using Xamarin, visual studio crashed quite a lot. I ended up just working in android studio with Java with great success. From what I read most recommended native development. &amp;#x200B; Maybe I should give it another shot.
It depends on what it's doing. Some Blazor apps can be 100% client-side and hosted on CDNs at any scale you want. Others are going to be making lots of API calls to backend services talking to databases, in which case they'll be limited to how well those services can scale. And some apps will be running server-side Blazor, which I would be skeptical of scaling beyond a large office environment.
Actually it's only one line of code if the target is already initialized. `foreach(var prop in typeof(Class2).GetProperties()) {typeof(Class2).GetProperty(prop.Name)?.SetValue(class2, typeof(Class1).GetProperty(prop.Name)?.GetValue(class1)); }`
I'd reject this as a single line in a code review. 
Maybe, my point though is you're using a library for something it isn't designed for which would be a much more egregious error during a code review. You aren't gaining computational efficiency vs using a mapping library since text parsing is incredibly computationally intensive, and serialization libraries are large. I ran your code vs mine through the debugger on a pair of three property classes with two matching properties, reflection took 1ms, serialization/deserialization took 215ms. If you're going to import a library, use the right one.
There is no way it took 215 ms to deserialize + serialize anything. Regardless, its a matter of simplicity. Which tool to use depends on what the use case is. I merely offered a suggestion of a simple way to go from one object to another with very little hassle. If he needs to optimize it, then he can go with your way.
I'm really looking forward to 0.7, now. I finally found the time to start really messing with Blazor and I'm loving components.
I think it's because I assumed current Blazor was more or less only server-side, which is why I raised the question about scability. I don't know much about Blazor yet, but perhaps I should try it out soon.
I put your code, my code, and automapper in a new console program and stepped through it with the debugger. That's the timing I got from the diagnostic tools in visual studio to run that line. It seems there's some overhead to the first call, so I "primed" each call then ran each one 10000 times. Reflection took 1ms, JSON took 83ms, and automapper took 32ms. So yes, not as drastic, but the difference is still there. In a high volume system little inefficiencies can add up. It's better to not promote bad practises, a lot of code I've had to go back and optimise was written with the mindset of "this is how I always do this" neglecting the fact that it's now in a huge loop.
You're doing it the hard way. This is all you need: &lt;&lt;(.*?)&gt;&gt; And use the first group to grab each identifier. Use this site to test: https://regex101.com/
Could you elaborate a bit on this? Sounds like a good approach but I'm just confused on how you would set it all up. Do you mean something like running Razor Components on a local web server and then the UI would just be razor pages with some bootstrap thrown in?
It started out as just a way to run C# in the browser on a Mono runtime ported to wasm.
Wait, so the member signatures are the same just different classes? Assuming I can't touch the classes themselves I'd probably just use reflection to iterate through everything and copy the values over.
I said this is a reply to a comment, but it unless you have hundreds of properties just manually code it. It makes for less bugs, easier debugging and easier refactoring.
In Visual Studio it displays the number of references to a property. When you add a property, look at the references of other properties. When I want to find out where a property is being used and it has zero references because it’s all done via AutoMapper I find that even more challenging.
Yes, they do. But downloading the content from YouTube is against their TOS and will get your app removed from all app stores. Musi is a popular app that plays the audio while the app is in the background, but it specifically does not allow downloading.
Even better use named capture
I actually didn't know you could do that. Good to know. Should make complicated regexs a lot easier.
I use Xamarin Native on a couple projects, only very minor issues.
You should, it works very well now. I prefer it to using Android Studio which I have way more issues with than Xamarin. (I use Android studio in my day job, Xamarin for some freelance work)
Just use a non-greedy repetition, I.e. `*?`.
serverside blazor addresses this. but that is becoming razor components anyway, so not really the wasm blazor i think we're really talking about here. if the net core runtime could be loaded static from a cdn, you'd get caching at least, maybe even across sites. and if they figure out the il linker situation (or corert ever ships) the entire program will be much smaller. i think it can be done, but it's a ways off imo. 
no, it would be v8 running the net core runtime via wasm which in turn is running blazor. blazor does not require a server except for the initial static asset downloads, which in an electron app are bundled inside the app. it's an interesting idea but is getting rather meta... at least two layers of vms. but as with all electron apps you'd get xplat for free. 
aws has cognito which works with the openid middleware with a little massaging. but honestly, after using it, i wouldnt recommend it. it's a massive pain in the ass. it feels very enterprisey and doesn't behave how you'd expect. 
i watched a demo of using "razor components", and they just flipped a couple switches and it turned into blazor in wasm. seriously the ability to choose between server side and client side like that would be a massive win, imo. 
Oh so with V8 then you are referring to the client side version of blazor right? Is there a feasible cross platform desktop strategy using razor components and electron?
setting that up is non-trivial for beginners. getting the paths right, spa fallback routes, setting up hmr, etc. i agree this is the best way but learning from the templates can help to figure out what you're supposed to be doing. 
Actually, the site I linked has a quick reference in the lower right corner. Figured it out from there. ;)
Years ago I was forced to learn all native when cross platform wasn't big, meaning Android with Java and iOS with Swift. I still exclusively use native. Sure it takes alot longer but nothing beats developing apps with the technology that it's intended. The biased dev in me recommends taking some time to learn both Java and Swift.
Might be later available in the language itself if the following proposals are implemented: [https://github.com/dotnet/csharplang/issues/164](https://github.com/dotnet/csharplang/issues/164)
This T4 idea would solve that as well.
EF is a good example. You can't return EF entities over a REST call because it will often include stuff that you don't intend to return. DBContext cache pollution is the primary cause of this. But you could also simply be checking a property on an included child object that you don't want to return.
I recommend use Forms and Native - forms for all basics , and Native for platform specified things.
Seconded. Xamarin, Flutter, React Native, they are all good choices. The best choice is the one where you can ship your app the fastest; and if you’re already a .NET dev, that’s almost certainly Xamarin.
In that case I use Attributes to tag elements of the class I don't want to serialized to be ignored for serialization.
Last I checked, we don't have a .NET Core database driver for Oracle.
Check this out: https://www.nuget.org/packages/Dapper.Oracle/
Thanks for your reply. So is it ok to use Dapper?
Dapper or EF, you won't get far without a database driver. Oracle said they're working on releasing something soon(ish).
Devexpress XtraReports. 
What's the performance on the EF Core FromSql call to create your own raw SQL query?
[DocRaptor](https://docraptor.com). Behind the scenes it uses [PrinceXML](https://www.princexml.com/) which is the most impressive HTML to PDF converter I've seen. So instead of learning a new tool, I do my reports in HTML/CSS from [ASP.NET](https://ASP.NET) and simply convert it to PDF. PrinceXML supports every CSS feature imaginable. Footers, headers, paging, page numbers, index tables. All are done with CSS! And that means you are free to also add images or even use your favorite charting application on top of it. Do note that PrinceXML's JS engine is weak so I had to run another JS engine before sending the result to Prince but DocRaport seems to have a better JS engine that runs before your document HTML is sent to render in PDF. I've used PrinceXML directly and among other things I've made one massive financial report that has indexes, footers, headers, paging, page numbering, maps, charts, crapload of tables, text using CSS columns. Almost 40 pages long, looks great (it's intended for big clients). &amp;#x200B;
Does it work in Azure? I understood it needs to use pinvoke to call the wkhtlmtopdf dlls 
It's a bit low-tech, but the print features in Bootstrap are pretty good for simple page breaks, footers and showing &amp; hiding elements while printing. &amp;#x200B; &amp;#x200B;
How is the interop with existing .NET libraries?
PrinceXML has a .NET library available but it's just a wrapper around a command-line tool. It's enough since you are mostly telling it "take this as input and output the result in a stream/file" and some very basic configuration. That's the thing, you do all the work in getting the HTML/CSS output that you want and then you tell it to convert to PDF so there's not that much to configure beyond that. Anything particular (header/footer...) is all CSS-based which they have documentation on.
I write PostScript code in my app and then use the GhostScript command line utility to generate a PDF. You do have to install GhostScript on the server though...
Also Mac apps
PrinceXML is great, an alternative that also supports the CSS Paged Media Module is PDFreactor. Those are pretty much the only HTML to PDF options worth a damn (other than the likes of DocRaptor that use one of these behind the scenes)
Ditto... Super old version of webkit that doesn't properly support flexbox. If you can find any alternative, do so. 
no I was born this way :)
That's true, I missed the part about it needing to be in Azure. My apologies.
Xamarin is great. It's sometimes pain to work with, but it is definitely better than alternatives.
1) Why aren't you logging API calls server-side? Of course, do this asynchronously. 2) Store client-side errors in a queue and have some retry-logic? 3) Do use a logging framework. Even the client-side stuff should hit an endpoint that simply call the logging framework. That way you have flexibility to change configuration of how to log stuff in a single place.
1) if this is a concern, put your logging calls to your logging api in a background thread so they can execute and complete outside the thread of the request. no change in response time to the caller. 2) if the call to your logging api failed you can check `response.IsSuccessCode`. If false (basically not a 20x code) then you now something is wrong. Either way, you should have redundant logging. May I suggest NLog? Internally, we love using NLog with a Slack target so we can get instant notification of issues in a private slack channel. 3) Since you are relying on a secondary API for a critical function, that is a dependency so you should be checking that it is available when you make calls to it (again, `response.IsSuccessCode`). If not, then you should be using a secondary logging mechanism to notify your team (like that nlog slack target I mentioned) Centralized logging is a great thing for many people, as centralized logs can be more easily accessed, it just shouldn't be the *only* means of logging. Redundancy in logging is a good idea. Note: You can create custom NLog targets, so if you are thinking of implementing NLog, I would refactor your calls to your logging API to be a Slack Target for consistency. 
Sounds like you might have re-invented the wheel. Have a look at Seq for server-side logging. Serilog will batch up calls to it asynchronously. You'll probably also want to write file logs in case your logs server goes down. If you do use Seq, check out structured logging. You'll be able to search for elements within your log entries without hardcore string parsing. 
Before I code any design / code any logging, I ask the questions. Who will read these logs? What will they be trying to find in the logs? How far back do we want to keep the logs? Do we even need to log anything other than Exceptions? If an exception occurs are the right people notified and is the stack trace readily available? Good luck.
As you already have quite a few good responses on the design of it, I wanted to ask if Application Insights as a central store is a possibility. It is extremely easy to instrument into an application, and handles a lot of batch logging itself.
Alternatively Devart has an custom Oracle connector that's .NET Core compatible: [https://www.devart.com/dotconnect/oracle/editions.html](https://www.devart.com/dotconnect/oracle/editions.html). It doesn't mentions Dapper so not sure that'll work. I used their library to use EF 3 with Oracle back in the day (bad memories) and the library worked quite well, good support too.
Or elasticsearch/kibana if you don’t want to be tied to windows. Even runs in docker. 
We are planning on moving to Azure and that has actually been one of my recommendations. It does seem very nice. 
Dapper works with any ADO.NET (i.e. System.Data) compatible library. 
 When I use Swashbuckle to generate my ASP.NET swagger files, it automatically creates a UI for it as well.
https://github.com/swagger-api/swagger-codegen
LOL. That would be a great tool, but sadly the mantra for web developers seems to be "eh, it kinda works so we're gonna call it done".
Seq runs in docker now too. And it pisses all over Kibana in terms of usability
It doesn't really have a good way of separating applications and environments, though?
Yep, second this. AutoRest is used internally by Microsoft to generate some Azure libraries iirc.
Those buttons have no view state. For dynamic buttons to work in asp.net webforms, you will need to recreate those buttons and events in page_init
There's already an example. Strictly experimental but here you go &amp;#x200B; [https://github.com/SteveSandersonMS/BlazorElectronExperiment.Sample](https://github.com/SteveSandersonMS/BlazorElectronExperiment.Sample)
[https://github.com/SteveSandersonMS/BlazorElectronExperiment.Sample](https://github.com/SteveSandersonMS/BlazorElectronExperiment.Sample)
Thanks! Would I move most of the code that creates the button (and ties it to the event) to Page\_Init, and just do the `c.Controls.Add(btn)` line in `DayRender`?
Oh, nice they've finally made docker support! Yes I'd also take seq over kibana any day, but at the time (last year) I had to use it I didn't have windows as an option.
Well it's still pre-release technically, but I'm already using it in production. Good luck 
Well originally I wanted to migrate to aspnet identity b/c that would give me the option to further implement oauth at some point if I want, which I just don't see a need for within the next 5 years. I've just been having the fits trying to get the damn thing set up in my web api .net core app. My plan was to just run the sql to generate the schema it needs, then do a manual thing to get the accounts created, then make the switch. The big hang up was sql memebership has a table aspnet_users and the identity has the same table without the _ and the s, but the entity frame work scaffolding had a problem b/c it thought they were the same. Honestly, I'm open to move to anything that has been around for a while and it somewhat standardized, this is just seemed to be way more complicated than I would have expected, hence the part of building my own damn one. Honestly, looking back I could have had it done from scratch by now, given the amount of time I've spent trying to get it to work
Security is always harder to get right than it appears, in this case its best to try and stick with tried solutions, the extra steps and details can be a pain but trust me, its better but a huge CYA when something goes wrong and you are being audited (YMMV I am not sure how critical this app is to your LOB). If you are willing to dump the architecture entirely I would just migrate to something I like, write some scripts to port the user principal data over and force all users to create new passwords under the new auth system. You would likely end up having everyone need to reset credentials no matter how you cut it really. 
I couldn't figure out a way. I'm setting a cloudrolename for each service/environment and sending it along with the request. You can filter it in app insights then
I'm fine with going with something brand new, it's just I can't really even find something where I can just run scripts to create the schema, and then work off of it. I already had plans to migrate users. This type of software is something where anyone using it uses it almost daily, unless they're not at work, so my plan was to get the schema created, then have a custom function on login that will create or update their account with their un and password every time they login the old way. I'd have months of this, so the risk of me missing a user is almost 0, and I could always have a script for that too, to double check. 
You don't really migrate security data into data structures directly anymore. Most secure systems require the use of the API in order to do any operations. There is little to no monkeying around the back-end in most modern setups. If you want more control it is expected that you run an LDAP or AD system and then integrate with that.
We have 1 appinsight per application/environnements and at deploy time octopus automagically change the config to point to the right environnement.
I think there may have been some confusion. I was on my lunch break when I posted this so I may have not been clear. In our WebAPIs we are using a separate WebAPI just for logging in a centralized location. So yes the APIs are doing the logging server side just over HTTPS. However, for logging to be centralized we are also using this same Logging WebAPI to log performance and error logs to from clients like our ASP.NET MVC WebApps.
I run [api2pdf](https://www.github.com/api2pdf/api2pdf.dotnet). Our client library works in .net core and you can use the Headless Chrome endpoint. Most of our customers only spend $2 / month so you won't find anything cheaper than that. Let me know if you have any questions, I would be happy to help.
Stop trolling.
Sorry if your new here and/or don't know what your asking. The c# vs javascript question is more often than not purely asked to build up a circlejerk about how shitty javascript is and there's some of us that would prefer to not have that pointless discussion again. for the other questions. No... React and angular aren't competing with .Net (Blazor is a long way off) and i would argue neither is Node, Just like ASP.Net Node is a tool that's good at some tasks but not others. ASP.Net core is an excellent choice for businesses and enterprise solutions, Nodejs/Express is great for small IO heavy microservices(IMO). It's also important to note .Net core IS open source, Microsoft have given up on their closed source server solution both because it makes their product less desirable and the real money is selling Azure. That's their new model, Entice people in to a free open source dotnet core and dangle Azure goodies in front of developers, you can use ASP.Net core without Azure just fine but if you've even dabbled in ASP.Net core you can see they've gone out of their way to make Azure easy to integrate. I'm personally interested to see if .Net core gets attracts a lot of Java houses that don't like what Oracle has been doing lately (i would call Spring a competitor to ASP.Net as they target the same end users), there's an opportunity for the community to really expand. I'm also hoping for some great Qt bindings for .Net core (or some other cross platform application toolkit), .Net core 3.0 will support desktop applications but only on windows. Cross platform native apps built on .Net core would be awesome.
That doesn't sounds bad. Hopefully you make the log API call asynchronously.
I just don't understand from where "[ASP.NET](https://ASP.NET) for enterprise solutions" come from. I mean it's like there is no any difference whatsover, you can still use [ASP.NET](https://ASP.NET) for home/small solutions and it would be as fine, just because Visual Studio is heavy and [ASP.NET](https://ASP.NET) has more built-in stuff than Node.js doesn't make it officially "The solution for enterprise only"
With the SUM and COUNT functions. 
Historically because of database and server costs in the Microsoft ecosystem. To get a Windows server comparable to a Linux VPS was relatively expensive for a small project. A few years ago, I looked into porting my old PHP site to ASP.NET MVC 5. Using my own domain name and having an SSL certificate would have required a bump up from the cheaper basic tier and cost about $75 / month. The alternative would have been to use a shitty Windows shared hosting account. Now with ASP.NET Core, all that has changed. I can get a decent VPS through Digital Ocean or Linode for $5-10 / month.
No, I haven't found a way to get an aggregated request through multiple services yet, it's a pain. I was actually thinking of doing something along the lines of your correlation ID idea too, bad practice be damned if it works
I don't prefer C# over JavaScript. I use both. I write C# for the back end and write TypeScript and compile it down to JavaScript for the front end. They're both open source, so they get my respect that way, and I've gotten comfortable enough with both that I don't find either of them difficult to work with.
Fair enough, I didn't dig too deeply.
Don't write business logic in the controller. This goes elsewhere. Instead, add like a service layer (or business layer, you can name it whatever) which reads the data from the DB and the performs calculations.
So what your saying is i can stick my business logic in the controller, the service layer and the database! /s
What does the HandleUnauthorizedRequest in the AuthorizeAttribute look like? Is it stock or bespoke? 
great article!
Are you behind a load balancer that is terminating ssl?
Thanks for the info. Sorry I'm not sure on this one, definitely seems like unusual behavior, and I'm not sure what could be causing it. 
What kind of problems were you having?
I would sprinkle a little client side as well
\&gt;However I love working in C#. If I moved to flutter it would be a whole new load of learning before I could get my prototype up and running. &amp;#x200B; You're gonna encounter a learning curve either way. Dart is very similar to C# and you'll pick it up easy within a day. The challenge with any mobile solution is never the language but its learning your way around an all new UI framework. That's where the challenge lies. &amp;#x200B; \&gt;the whole opening curly brace on the same line thing gives me hives. Maybe I could get used to it though. You will get used to it. I was the same way when I first started using Swift, I would still use the brace-on-new-line style and after a while I thought to try it on the same line and now I actually prefer that style. When I'm in C# I convert back to new line style since all my co-workers use that style but for personal stuff I use same line. &amp;#x200B; I know you feel comfortable with C# but thats actually why you should try Flutter. You learn so much when you push yourself out of your comfort zone. I would also recommend playing around with Kotlin and Swift if you ever get a chance.
Outperforming the unsafe stackalloc code is impressive.
&gt;razor components are server side, so you'd wind up needing a server. True but I'm wondering if it's possible to run a **local** [Asp.Net](https://Asp.Net) Core web server on the clients desktop that uses Razor Components. The Electron app would just make all of its calls to the local web server. Do you think that's feasible?
Thanks for the info. My org has always used Swashbuckle, and I'm looking to Swaggerize a service soon. I'll try both!
This submission has been randomly featured in /r/serendipity, a bot-driven subreddit discovery engine. More here: /r/Serendipity/comments/9nljjw/interested_in_knowing_how_net_applications_are/
[removed]
Learn SQL, you can do pretty much everything with it. Microsoft's flavor of SQL is T-SQL (my personal favorite) Even the basics (grouping, joining, subselects) should give you all the tools you need 
You should be able to enforce https with kestrel, which is what I would recommend if you are doing anything more than serving static assets. [Take a look at this piece of documentation](https://docs.microsoft.com/en-us/aspnet/core/security/enforcing-ssl?view=aspnetcore-2.1&amp;tabs=visual-studio).
I'm doing this class right now and it's pretty solid. [https://www.udemy.com/build-an-app-with-aspnet-core-and-angular-from-scratch/](https://www.udemy.com/build-an-app-with-aspnet-core-and-angular-from-scratch/)
Ive heard of this amazing architectual pattern called microservices where you can stick your business logic everywhere, all over the clouds.
What kind of math?
The server level is one place you can do it, but you can do it closer to the code as well. I can get it to redirect, but the problem is that it then gets into an infinite loop of redirects: load page, see it's not https, redirect to https login, except the framework drops the https. So now it's not https, so direct, etc etc etc. So I need to solve whatever's causing that first.
That looks interesting. What would be a typical use case for it?
Does it go into detail on the ASP.Net side of things? 
What kind of detail are you looking for? It walks you through writing .net core web api. Authorizations, controllers, models, migrations, JWT, plus more that I haven't got to yet.
Show me a non-trivial React/Angular/Vue app that is "under 15kb or so"?
That might be good enough. I guess I was hoping for something that explained the middleware, models, and controllers in more detail. I like to supplement books with a video course to help drill everything in. I'm currently working through Pro ASP.NET Core by Adam Freeman. I wish he had a video course too ha. 
I was looking at that. I may try that one after I finish the Building Your First Api. This one seems to be better at explaining things than the other one I went through. Thanks
just simple math e.g. the way I did it is `public decimal Total {get {return Quantity * Price}; }`
This explains those items but not in great detail.
+1 Did all the big ones and this is my favorite.
Hi, fellow junior dev here. I dont have an account on stack overflow and will try to answer shortly here. If you find that answer helpful i can add a more detailled one on stack overflow. Your original Code from Stack Overflow: //Models public class TransactionModel { public int ID { get; set; } public int Name{ get; set; } public DateTime Date { get; set; } public string Address { get; set;} public string City { get; set; } public CountryList CountryList { get; set; } } public class ApplicationDbContext : DbContext { public DbSet&lt;RecieptModel&gt; Reciepts { get; set;} public DbSet&lt;CountryList&gt; coutryList { get; set; } } public class CountryList { public byte Id { get; set; } public enum Country { Germany, US, UK } } &gt;//Controller &gt; &gt;\[HttpPost\] &gt; &gt;\[ValidateAntiForgeryToken\] &gt; &gt;public ActionResult Create(\[Bind(Include = "ID,Name,Date,City,CountryList")\] Reciepts reciepts) &gt; &gt;{ &gt; &gt;if (ModelState.IsValid) &gt; &gt;{ &gt; &gt;db.Reciepts.Add(reciepts); &gt; &gt;db.SaveChanges(); &gt; &gt;return RedirectToAction("Index"); &gt; &gt;} &gt; &gt; &gt; &gt;return View(reciepts); &gt; &gt;} &amp;#x200B; //View &lt;div class="form-group"&gt; @Html.LabelFor(model =&gt; model.CountryList, new { @class = "control-label col-md-2" }) &lt;div class="col-md-10"&gt; @Html.EnumDropDownListFor(model =&gt; model.CountryList) @Html.ValidationMessageFor(model =&gt; model.CountryList) &lt;/div&gt; &lt;/div&gt; Original Requirement taken from Stackoverflow: &gt;**Objective** Create a Reciept with date,reference... &amp; country. Country is Required and should be a dropdownlist. I did not try your code because i dont have visual studio available right now but here are my two (maybe more) cents. I will add my suggested (not tested) implementation and comment on the changes. Please feel free to comment or correct me as i am also learning :-) &amp;#x200B; [http://www.entityframeworktutorial.net/code-first/configure-one-to-many-relationship-in-code-first.aspx](http://www.entityframeworktutorial.net/code-first/configure-one-to-many-relationship-in-code-first.aspx) look at the Convention 4 # (EF) Model Classes: //EF Model Classes public class Recipe { public int Id { get; set; } public string Name { get; set; } public DateTime Date { get; set; } public string Address { get; set;} public string City { get; set; } public int CountryId public Country Country { get; set; } } public class Country { public int Id { get; set; } public string Name { get; set; } public List&lt;Recipe&gt; Recipes{ get; set; } } //DB Context Class public class ApplicationDbContext : DbContext { public DbSet&lt;Recipe&gt; Recipes { get; set;} public DbSet&lt;Country&gt; Countries{ get; set; } } 1. Your Entity Framework Model Classes should be named in a way that will tell you what the class tries to represent. It will be a "transactionmodel" anyway when you add it as a property of DbSet&lt;Recipe&gt; Recipes in your DBContext Class. 2. The Name property should be a string 3. What you probably want to achieve is a 1 to Many relationship between Recipe and Country. One country can be referenced by many Recipes but each recipe has one country. 4. Renamed CountryList Class to Country with Id and Name property. 5. Added Navigation property to List of Recipes (to get all recipes for a specific country lets say with id 5 you can query your dbcontext like this: List&lt;Recipe&gt; recipesForCertainCountry = db.Countries.FirstOrDefault(c =&gt; [c.Id](https://c.Id) == 5).Recipes; ) 6. Renamed properties in your DbContext Class to match the changes 7. What you will get now is a Recipe Table with Foreign Key CountryId which points to the Primary Key Column Id of Table Country. &amp;#x200B; # Controller //Controller [HttpPost] [ValidateAntiForgeryToken] public ActionResult Create([Bind(Include = "Id,Name,Date,City,CountryId")] Recipe recipe) { if (ModelState.IsValid) { db.Recipes.Add(recipe); db.SaveChanges(); return RedirectToAction("Index"); } //Add your IEnumerable or List of Countries to ViewBag. ViewBag.Countries = db.Countries.ToList(); return View(reciepts); } 1. Renamed parameters to match changes 2. You only need to send back the CountryId which is the foreign key to the Country Table. EntityFramework will take care of the relationship when you add the Recipe Object to the Context and Save the changes. 3. The Dropdownlistfor helper that you want to use works this way: it wants a selectlist which is a list of selectlist items. in your case your select list items are your countries. What you want to achieve is that the user clicks on a country from the list (e.g. Id=5, Name=Germany) and your View populates the ViewModel's CountryId property with a "5". # View @model [YourNamespaceToEfModels].Recipe &lt;div class="form-group"&gt; @Html.LabelFor(m =&gt; m.Country, new { @class = "control-label col-md-2" }) &lt;div class="col-md-10"&gt; @Html.DropDownListFor(m =&gt; m.CountryId, new SelectList(ViewBag.Countries, "Id", "Name")) @Html.ValidationMessageFor(m =&gt; m.CountryId) &lt;/div&gt; &lt;/div&gt; 1. Changed Model declaration naming to match previous changes 2. Label For should be for Country property which should display "Country" 3. changed enumdropdown helper to dropdownlistfor because we want to "use a selectlist to set the CountryId property of our model" 4. Validation Message should be for CountryId and should give you a validation error for null values because CountryId is a non nullable int in your Recipe Class. That should fullfill the "country is required" from your requirement. Please try to implement the changes and comment if that was helpful and if it works :-) &amp;#x200B; kind regards from germany :-)
Oh my god, don’t bind your shit, use a viewmodel to hold it! Seriously, binding stuff will only lead to headaches down the road. Extract your data from the DB, dump it into a viewmodel, and use that viewmodel to populate any form for editing. You can even have both methods and views doing double-duty for both adds and edits by having the primary key in the viewmodel default to a null value. That way, in the method that catches the form submission you can make that check and fork the code: do an add if the key is null (leaving out the key when you move the data from returned viewmodel to data model), and do an update if the key is populated with a logical value. You kick this off in the method that calls the form in the first place by making the variable it looks for nullable. If it doesn’t exist, you just call the viewmodel (an add) and give the user an empty form. If there is a value it becomes an edit and you stuff the viewmodel with data from the DB so the form is pre-populated. You can even extend this to auto-populate drop down menus from the viewmodel itself. Yes, even if they are data-driven.
Yeah that is easy to do in SQL. I wasn't sure if it was partial differential equations or something really advanced that is hard to do in SQL :)
&gt;I'm still on VS2008 Oof. Start there.
I keep meaning to put this on my TODO list of side projects to do. I wrote a code generator years ago that generated comprehensive classes for copying values between models, or for serialisation. It was so great to have code generated so you can keep reading/writing old versions of models, and to also have the compiler find errors for you. If there was an option for AutoMapper so it would output the resulting logic to actual code - that would be pretty useful.
Fellow. NET Rocks listener here. It's a great place to start getting a high level overview of WTF is going on in the. NET space. 
Linq join is inner join. var innerJoin = from matcher in Matches join matchee in Matches on matcher.MatchedWith equals matchee.Matcher where matcher.Liked is 1 || matcher.Liked is 2 &amp;&amp; matchee.Liked is 1 || matchee.Liked is 2 select new { matcher.MatchedWith, matcher.Liked }; &amp;#x200B;
linq version: var results = from matcher in Matches join matchee in Matches on matcher.MatchedWith equals matchee.Matcher where matcher.Liked == 1 || matcher.Liked == 2 where matchee.Liked == 1 || matchee.Liked == 2 where matcher.Matcher == 1 where matchee.MatchedWith == 1 Method chain version (I've deliberately extracted the `matchee` and `matchers` variables for extra clarity) var matchees = Matches .Where(x =&gt; x.Liked == 1 || x.Liked == 2) .Where(x =&gt; x.MatchedWith == 1); var matchers = Matches .Where(x =&gt; x.Liked == 1 || x.Liked == 2) .Where(x =&gt; x.Matcher == 1); var results = matchers.Join(matchees, a =&gt; a.MatchedWith, b =&gt; b.Matcher, (a,b) =&gt; new { a.MatchedWith, a.Liked }) 
PREPARE for your interview. Ask what they expect you to know and spend some time studying! I forget all that stuff too, that’s why I spend a 5-10 hours preparing before and interview. Also, Pluralsight.com
But what is the underlying technology used to do the actual state transitions? There must be some sort of timing or queuing mechanism and a backing store for what tasks are pending, etc. 
&gt;Lol I'm still on VS2008 You can't keep up with the times, *if you're not keeping up with the times.* You can read as many books you want about programming methodologies, but if you're not building modern apps, then you're not keeping up with the times. ASP.NET Core is the future. Start with that.
Second this. Most interviewers, especially at smaller companies, are terrible at interviewing..they google "interview questions for X developer" and slightly alter the questions and ask those. No reason a person, as the one being interviewed, can't do the same.
Use a nice database design with relationships with EF core code first and you’ll never use a join again in your life. 
I still have issues using ViewModel method too. "System.NullReferenceException: 'Object reference not set to an instance of an object.'" &amp;#x200B;
Legacy codebase maintenance, not fun but someone has to do it.
Cross platform XAML will most likely never exist. WPF is very platform specific. Microsoft has no plans to make it cross platform.
Cross platform XAML will most likely never exist. WPF is very platform specific. Microsoft has no plans to make it cross platform.
Your best options would be Xamarin or Uno. Even the new VS installer is Electron based, the JS crowd has taken over DevTools it seems.
Avalonia is probably best option here, but still early. [Avalonia](https://github.com/AvaloniaUI/Avalonia)
Requiring to install huge frakework like Mono to run a single app on Linux or Mac is overkill anyway.
Unfortunately that is a very generic error message that can crop up in many different places, but essentially it is saying that you are trying to refer to an object that doesn’t exist, because you never created it in the first place. It’s like trying to fill a cup with water from the tap without ever grabbing the cup in the first place. *Of course* you are going to run into errors. But the problems you get with binding are much, much worse, and far more restrictive in terms of what you can do. For example, let’s say you have a list of products, and you want to display the entire list. These products have an ID and a name, along with a boolean that can indicate if it is actively being displayed or not. There is more in that Products data model, but this is the minimum we would ever want to display. To show that page which has the list of products, you would call it like this: public async Task&lt;ActionResult&gt;Products() =&gt; View("Products", new ProductsViewModel(await _unitOfWork.ProductsRepository.GetAllAsync())); When you show a list of products, this would be the *primary* viewmodel: public class ProductsViewModel { public List&lt;ProductsListModel&gt; Products { get; set; } = new List&lt;ProductsListModel&gt;(); public ProductsViewModel() { } public ProductsViewModel(List&lt;Products&gt; data) { foreach(var item in data) Products.Add(new ProductsListModel(item)); } } This would be the *secondary*, list viewmodel for the list of products themselves: public class ProductsListModel { public Guid ProductId { get; set; } public string Name { get; set; } public HtmlString Active { get; set; } public ProductsListModel() { } public ProductsListModel(Product data) { ProductId = data.ProductId; Name = data.Name; Active = Extensions().ActiveIcon(data.Active); } } That way, when you build your page, you can do this: @model Project.Models.Products.ProductsViewModel &lt;h2&gt;The products&lt;/h2&gt; @if(Model.Products.Any()){ &lt;table&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;Name&lt;/th&gt; &lt;th&gt;Active&lt;/th&gt; &lt;th&gt;@Html.ActiveLink(" ", "Product", "Products", new { }, new { @class = "fa fa-plus btn btn-default btn-primary", title = "Add a new Product", rel = "tooltip" })&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; @foreach(var item in Model.Products){ &lt;tr&gt; &lt;td&gt;@item.Name&lt;/td&gt; &lt;td&gt;@Html.Raw(item.Active)&lt;/td&gt; &lt;td&gt;@Html.ActiveLink(" ", "Product", "Products", new { id = item.ProductId }, new { @class = "fa fa-pencil-alt btn btn-default btn-primary", title = "Edit this Product", rel = "tooltip" })&lt;/td&gt; &lt;/tr&gt; } &lt;/tbody&gt; &lt;/table&gt; } else { &lt;p&gt;There are no products to display.&lt;/p&gt; } One aside: notice that `Active` boolean and how I handled it? I don’t want to drive an actual boolean to the view and handle it there each and every time. No, I want to follow DRY, which means that if I want to show a user-friendly icon to show a True or False, I build that shit *elsewhere*, so I can re-use it over and over again without having to repeat myself: public static class HtmlExtensions { public static HtmlString StatusMark(bool item) =&gt; new HtmlString(item ? "&lt;span class=\"fa fa-lg fa-check-circle text-success\"&gt; &lt;/span&gt;" : "&lt;span class=\"fa fa-lg fa-times-circle text-danger\"&gt; &lt;/span&gt;"); } Now when you Add or Edit an individual product (regardless of either), *that* ViewModel would be like this: public class ProductViewModel { public Guid ProductId { get; set; } = Guid.Empty; public string Name { get; set; } public bool Active { get; set; } public ProductViewModel() { } public ProductViewModel(Product data) { ProductId = data.ProductId; Name = data.Name; Active = data.Active; } } Notice the one major difference between the ProductsViewModel and this ProductViewModel? Yes -- the primary key. If one isn’t given, it defaults to an empty Guid. This is very, very important later on. Not going to show the whole damn form, I think that one is pretty self-explanatory. Just make sure you have a hidden field for the `ProductId`, because you will be wanting to bring this one through regardless of an edit or an add. You will see why in a moment. In calling the page with the form, we can call it the same way whether we are talking about an edit or an add: public async Task&lt;ActionResult&gt; Product(Guid? id) =&gt; View("Product", id is null ? new ProductViewmodel() : new ProductViewModel(await _unitOfWork.ProductRepository.FindByIdAsync(id))); You catch that? If we use the link in the table header (the Add link), we don’t pass on an ID, the ViewModel gets called raw, and an empty Guid gets added to the ID. That is critically important for processing. But if we click on any Edit link in the body of the table, the ViewModel gets populated with data from the DB, giving the primary key a real non-empty Guid. That way, when I call that display page using this ViewModel, all I have to do is this: [HttpPost] [ValidateAntiForgeryToken] public async Task&lt;ActionResult&gt;Product(ProductViewModel model) { if(!ModelState.IsValid()) return View("Product", model); try{ if(model.ProductId is null){ // Add product var p = new Product(); new ProductMap(p, model); // My custom hand-rolled mapping tool, use whatever you need here to stuff product with model contents. This is a static class under its own folder. _unitOfWork.ProductRepository.Add(p); } else { // Edit product var p = await _unitOfWork.ProductRepository.FindByIdAsync(model.ProductId); if(p is null) throw new Exception("The product could not be found for updating. Please contact the developers with all the data you tried to enter for assistance.") new ProductMap(p, model) // We can use it here again, because internally it doesn’t match up the primary key; with an Add the DB creates one, with an Edit one already exists in the data model _unitOfWork.ProductRepository.Update(p); } if(await _unitOfWork.SaveChangesAsync() &lt; 1) throw new Exception("The data could not be saved. Please contact the developers with all the data you tried to enter for assistance."); } catch(Exception e) { ModelState.AddModelError("", e.Message); return View("Product", model); } } As long as all three fields exist within the form you are using to update products with, you should not experience any errors in using viewmodels everywhere.
Cross platform XAML: [Xamarin.Forms](https://github.com/xamarin/Xamarin.Forms), [Avalonia](https://github.com/AvaloniaUI/Avalonia) and [Uno](https://github.com/nventive/Uno) . C# on WebAssembly on PWA/Electron: [Ooui on Electron](https://github.com/praeclarum/Ooui), [Uno on Electron](https://github.com/nventive/Uno) and [Blazor on Electron](https://github.com/SteveSandersonMS/BlazorElectronExperiment.Sample) Other libraries/tools/frameworks: * [Electron.NET](https://github.com/ElectronNET/Electron.NET) * [Eto.Forms](https://github.com/picoe/Eto) * [Qml.Net](https://github.com/pauldotknopf/Qml.Net) 
Google: "Basic C# interview questions" If you have 10 years of experience, you should be able to answer most of those. Review occasionally.
Linux filesystems are usually case-sensitive, and I notice that you are using `Sansa.Web` instead of `SanSa.Web` in your second copy. Could that be it?
The more I hear about C# 8, the more I realize I need it more urgently I need than water! Haha
VS2008 was pretty good but nothing beats VS2017.
It's great to hear and encouraging but maybe describe how you made that jump back. It may be more helpful for the OP.
Have you been reading books? Blogs/articles? I you want to get back to the basics perhaps hitting one of the Microsoft certification books will help you. For the rest I combine keeping an eye on some blogs, checking stuff up on Youtube and reading books on subjects like DDD, EF Core and such. Yes it takes time on top of work but trust me, the edge I get from expanding my knowledge beyond what I'm currently working on pays off. Be curious, explore, try something new just to see how it works. You've got keyworks from those interviews, TCP/IP, SOLID, Tasks, Threads, OOP. Start at Wikipedia and dig further as needed. There are many articles on "what's new in C# X.X". Catching up from 2008 is a daunting task but in an idea world you wouldn't have to catch up from so far since you've kept up to date. But you have to start someday. Start now and keep the momentum. &amp;#x200B;
Create a html select input most of times is beautifully handle by drop-down list extension from asp.net MVC. Although there some cases witch we all struggle a bit, like dealing with enums or N-to-N relationship entities. Don't panic, there always a way. Passing the list of options to the view through ViewModel or Viewbag is an option, although it make your controller a bit coupled to your view logic. Conceptually, IMHO, would be best to use ViewModel between them 2. Other good option that I strongly suggest is use html extension methods, take a look at this link: https://stackoverflow.com/a/694361 
Despite the AutoMapper and FluentMapper packages, I would suggest you to override the implicit/explicit cast operators, take a look here: https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/statements-expressions-operators/using-conversion-operators
Any topics you learnt in particular that helped when you returned to programming?
Yup also love Dot Net Rocks. Books are good for a deep dive. You can normally preview a chapter or two on Amazon (not iOS), which combined with the reviews is a good way to find the right book for you. 
I would not recomnend parroting common interview questions. But using such a list as a jumping off point and guide him towards fixing his blind spots might be a good idea. 
I used to love PluralSight, but they just can't keep up with the ever changing world of dev technology. I wish they'd move away from 8 hour courses into more honed 20 minute focused courses that they can re record when a new update comes out that invalidates the previous one.
Thank you! You have nice collection of it... I haven't gone through all but Uno seems for me most interesting (because UWP development enthousiast).
I use podcast / meetups as the best way to keep up with what's going on in the industry. Occasionally I follow a Hello World type app of whatever the tech is so I see a bit hot it works, etc. and if I'm really interested in it then proceed to read more / do my own small projects. This makes interviewing a lot easier as well because you're probably at least familiar with it and saying something (but being honest) is a lot better than saying never heard of it because x job never used it. &amp;#x200B; For interviewing though I just review some basics and google top questions for x language to get prepared and put together talking points for my experiences. &amp;#x200B; &amp;#x200B;
They op can't answer what solid is. Suggesting Google it is totally a solid suggestion.
Well while doing IT I learned a lot about networking and I did a lot of dabbling in development in my free time. But it really helps to see the big picture. Security, active directory, etc...I just have a much bigger understanding of the entire industry. And I've worked with so much software that I know what makes software bad, and can avoid making the same mistakes in my own software. I'm also MCSE/MCITP in 2000, 2003, and 2008, plus an MCDBA. So I know SQL server pretty well and it really helps when designing databases for your software. Of course, a lot of it depends on are you writing enterprise applications, or writing mobile games.
Just get IntelliJ and google and you’ll be good. One difference that may not be obvious, .NET can do unsigned bite arrays whereas Java (at least Java 8) cannot.
Huh, I never thought about it like that. Shorter videos would be good. Also, I have 20 years professional experience as a developer and the pace of change is increasing, no doubt.
Syntactically they're pretty darn close. But like you mentioned, the eco system around it is very different. I found it pretty frustrating to grasp in college (after being a seasoned .NET guy for so many years). Things just work with .NET and Visual Studio. Java and Eclipse on the other hand seemed so archaic comparatively speaking and seemed to take so much effort just to get the environment working 
[.NET Core 3 will support WinForms and WPF](https://blogs.msdn.microsoft.com/dotnet/2018/10/04/update-on-net-core-3-0-and-net-framework-4-8/). [It'll be released in Q1 2019](https://github.com/dotnet/core/blob/master/roadmap.md#upcoming-ship-dates).
But it will still only support windows for WPF
What would break if you're usiing 2017 vs 2008? Arent they all backwards compatable? 
I've been fortunate enough not to run into those questions in interviews about historical things. But for me i use ankiweb for everything i learn, I have thousands of cards and i habitually go through 10-20 every morning and it works wonders for my memory and learning :) Heads up Anki can be hard to get a handle on at the start but it's worth the investment 
I gave up on Eclipse. I have no idea how Eclipse is popular, as a piece of software it barely works. IntelliJ is infinitely better, but still infinitely worse than Visual Studio. Honestly, at this point other than for legacy reasons I don't know why people would still want to use Java.
[merge conflict](https://www.mergeconflict.fm) is my favorite dev podcast. It’s focused on mobile development with Xamarin and really fun to listen to. After that it’s a mix of - Channel 9 - Hanselminutes - Brent Ozar’s SQL server office hours - Under the Radar - Weekly Dev Tips - RunAs Radio
Thank you, this is really helpful!
True, but instead of just learning the SOLID mnemonic it would be best if he read an article or two on what it's about. 
Generally, yeah. However, before 2012/2013, you'd have to upgrade your projects/solutions every time you moved to a new VS. The upgrade didn't change the code - just the project files themselves - but made them unopenable in the old version. Upgrading from 2008 to 2017, OP will have to deal with this too. Certain projects aren't supported anymore (such as Silverlight), or will be upgraded to use new versions (such as Office projects), but beyond that, as long as you still have all the stuff installed you need, Visual Studio will still play nice.
Get a good understanding of the SOLID principles, and learn to build a proper architecture. Knowing about unit testing and integration testing is also a big plus.
Perhaps focus on how an application is best put together in a clean, maintainable, flexible way. Read about design patterns, and as /u/fartinator mentioned, SOLID principles.
Many companies don't need reporting solutions or cloud technology, single devs don't want to spend hundreds of dollars for just testing the real implementation (eg paid SDK etc.) 
Everything in C# is easy except async await. Nail this aspect of the language. 
Accept that your programming can be bad without tests and mentor others.
Java has a lot of corporate support. While Google doesn't support it as heavily as they used to, they still do support it. IBM has heavily supported Java for longer than C# has existed. And, as you've mentioned, Apache heavily supports Java despite not being a corporation.
People have already discussed IDEs, but you're going to want some experience with either Maven or Gradle as they are the most popular build systems/project systems in the Java ecosystem. Both support Maven Central, which is the Java equivalent of NuGet. For reference, Maven and Maven Central are two different things.
Async/Await is easy to use, but there are a lot of subtle nuances that can cause your code to be buggy. Check out this video about how the compiler handles Async/Await code: aka.ms/AsyncAwaitBestPracticesVideo
You mean a `IEnumerable&lt;T&gt;.OfType&lt;T&gt;()` implementation for ICollection?
Dependency injection (.net core has it built in, but with framework checkout Ninject or whatever the other ones are). Figure out when you need to use something in the Singleton/Transient scope.
We use Splunk. Serilog has a sink built in. You can have your application do rolling file logging locally on the server and then a Splunk agent application runs in the background picks up those logs and sends them to the Splunk server. So you will have local logs if Splunk goes down and then you aren't making extra http calls from your application when logging. 
Jenkins to build from GitHub, then Octopus to do the actual deploy. 
Nice, yeah that seems to be the best approach from a performance standpoint. I really want to avoid doing logging over HTTPS. During code reviews I noticed a lot of developers have been putting the http logging calls in ActionFilters where they cannot be performed asynchronously which is definitely an issue. Using the approach you mentioned could still be done there and would be much better from a performance standpoint. 
Hmm, logging in action filters might make swapping things out to a different solution harder. Maybe log via middleware? 
Why did they choose to log using actionfilters and not directly in the controller?
I think they had cross cutting concerns in mind. Was easier to write the logging code in one location instead of duplicating it in the controllers since they could utilize the OnActionExecuting and OnActionExecuted methods. 
If you really want to be full stack, you probably need to learn a javascript framework like vue/react/angular, at least that is what I see in most postings. I use c# .net core / vue and it's a great combination.
I would suggest looking at multithreading in C# as a whole instead of just looking specifically at async/await. Knowing how to make a class thread safe is important as well as what other facilities the .NET framework allows for multithreading (such as the Task Parallel Library). I have seen first hand what happens when somebody tries to write multithreaded code but doesn't really understand all that goes into it. I caught a few deadlocks in code review (without even having to run the code) because the person writing the code had very little understanding of how to write safe multithreaded code.
Yeah having to manually add each service implementation by hand is going to get old real fast. Most 3rd party DI libraries allow adding implementations from an assembly by name and other ways which is a must have in larger projects.
You should look into MEF....
Try more on architecture side and also opps, web api, rest api. That will help you more to stand ut with better skills.
I generated an Angular/.NetCore application with the dotnet CLI template, but since the template has Angular 4, I deleted the ClientApp folder contents and created an Angular 6 project instead, with the ng new command. It works perfectly and I can start both projects with 1 button click.
I'd recommend Autofac or SimpleInjector. LightInject is being adopted by Umbraco, so that'd be useful in the future. 
I always wonder what "full stack" actually means these days in progressive shops with strong developers. As someone who has been a full stack developer since the beginning (15-16 years), I feel that I'm lacking severely in every aspect of the stack. It seems to me, unless your job is your life, these days it's simply impossible to be really good at all parts of the stack at once. The change of pace is basically unmanageable.
TDD is a major part of SOLUD not just a “big plus” 
Scrutor
Also understanding the difference between multithreading and async/await.
How is TDD in any way a part of SOLID? SOLID is a set of design principles, whilst TDD is a form of development approach.
TDD has no relation to SOLID.
What features in particular?
Nooo. Inversion of Control has nothing to do with it 
I don't know if you're trolling or if you really don't know what you're talking about?
do you think Test driven development is inversion of control? 
Thanks 🙏 
I don't look for full stack resources that have a firm grasp on every nuance. I look for critical thinkers who can solve a problem, know how to test their code as they go ... and have a cursory knowledge of the stack I'm using. These days if you don't know something you can Google it, I'm more interested in someone who is good at finding answers over someone who happens to know the answers to the questions I happened to ask at the time. 
I wrote Java for 3 years at a big Four after working with C# for over 10 years before that. I hated Java, it was basically an exchange of big wads of cash for a lobotomy. I felt like a refugee. Happily back in the .NET world now, and even got my brain back ... If you want to be a happy Java dev, either never touch C# or just accept that Java sucks.
I wrote java for a few years before making the switch to dot net. It was fine, the biggest problem that I had was the awful documentation and the excessive reliance on XML and attributes. I'm sure it's much better now. But honestly, the language that you're coding in won't make any difference in how good a job is. What makes a good job is good people. If they are passionate, smart, helpful, nice and know how to have fun then everything else is secondary. Who cares about the syntax for declaring an inline array when you can play table tennis at lunchtime!
I do. I'm here because I used .NET Core a few times for smaller personal projects so I started following this sub. I'm not currently using it but I still like to keep up with the news and discussions.
It has two meanings. Some people think it means a lot of in depth knowledge of the everything. A lot of seniority, many years experience. Depth as well as breadth. Some people mean it as just someone who works on, well, the full stack. So you could start your first junior Dev job and fix a query, add a feature to the API then sort out an issue with the front-end.
[Qml.Net](https://Qml.Net) is by far the best I have use for cross-platform desktop. Being QML, it is write-once-run-everywhere, like Electron, but much better performance. Compared to Xamarin.Forms, again here, you have only one project, not one-per-platform and none of the worrying about differences between platforms that you would have with Xamarin (and Forms' Mac and Linux support is still very early stage, beta quality, and incomplete). Compared to Avalonia, you get all of QML, which has been commercially used and developed for many years now, and is far more mature because of that.
I write Java full time at my new job after writing mostly C# for the last 5 years. I think Java is still behind C# but Java 8 brought most of the features I missed from C#. I like to keep up with C# because it is useful to me to see how other languages solve problems. 
I used to write Java for my day job. I used C# on the side for some game development (MonoGame / Unity). Now I write C# for my day job and my hobbies. The main thing that I miss is the Java ecosystem. Things like caches, collections, and multithreading primitives were top-notch in Java, either in the standard library or in popular third party libraries. In C#, I've found that these don't exist, and if I really want them, I have to roll them myself, which sucks.
I gave up on Java about 5 years ago, so I cannot say much. Everything to get it running just took too much time and felt primitive. Plus everyone are hyped about open source and how Java is original which leaves shortage of C# developer, hence I can ask for more salary.
I can't remember off the top of my head but I believe it is the fact that in StructureMap you can add generics over their enclosing type and ASP.NET DI doesn't allow that. I was able to get around it by registering a Func that took an enum and then would return the correct implementation but StructureMap was much more elegant in achieving the same functionality. I'll look at the code at work tomorrow and I can let you know for sure what the major feature was.
Run an analysis tool on some of your code (or somebody else's code) and try to understand the different defects and issues that the tool will return. Then research the subject around those same defects. The good thing with that approach us that it will be tailored to your particular situation. Even after 10 years working almost exclusively with C# and .Net I still discover new way to improve my skills that way. And those analysis tools are getting better every day. Then on top of that I think that there are a few books that are mandatory reading such as "C# in depth" and "CLR via C#".
Once you go C#, you never go back to Java.
Right now, developing an MVC 5 (no luck getting the green light on .NET Core) app in front of Spring Boot APIs. I work in both codebases.
Mostly I agree, the only thing stopping me being 100% C# is I use linux, and it requires mono to fully function and it takes a big hit with mono :(
I went from C# to Java professionally. I still like C# a lot more but most of my complaints are regarding trivial things, like oh it’s annoying that I can’t use *var*, or this would be easier in LINQ, or how the fuck do I instantiate a List with default values already? But for the most part, the language doesn’t matter very much to me.
I've been happy writing C# on .NET Core. I go Mono for F# though, so hopefully both languages will be fully functional soonish.
They have nothing to do with each other.
Hie about https://www.hanselman.com/blog/HowDoYouUseSystemDrawingInNETCore.aspx? Have you tried it?
Nope, still doesn't work on my machine: [https://imgur.com/2AvouHx](https://imgur.com/2AvouHx) &amp;#x200B; Maybe it's a OS specific thing.
And for caching you have [MemoryCache](https://docs.microsoft.com/en-us/dotnet/api/system.runtime.caching.memorycache?view=netframework-4.7.2) and an overview of caching in the framework [here](https://docs.microsoft.com/en-us/dotnet/framework/performance/caching-in-net-framework-applications).
I will try it on Mac later tonight and report back. 
That's actually a funny quote from one of the people on the PowerShell team regarding security: &gt;I can't even keep up with this, and I wrote half of it.
Haha. So it’s working now for you?
Ok great to hear. Thanks. 
Here's a run down of my complaints since you seem to be curious :) Caches ---- C#: * [MemoryCache](https://docs.microsoft.com/en-us/dotnet/api/microsoft.extensions.caching.memory.memorycache?view=aspnetcore-2.1) and that's pretty much it. This is just a very heavy, string -&gt; object cache. No type safety, very limited configurability. Java: * [Guava Caches](https://github.com/google/guava/wiki/CachesExplained). Extremely configurable, type safe, with removal listeners. * [Caffeine](https://github.com/ben-manes/caffeine). Even more better than Guava's, with facades and various backends, as well as some novel [LRU algorithms](https://github.com/ben-manes/caffeine/wiki/Efficiency). Collections --- C#: Notably missing here is a PriorityQueue. I'm also ignoring the untyped collections, pre-generics. * [List&lt;T&gt;](https://docs.microsoft.com/en-us/dotnet/api/system.collections.generic.list-1?view=netframework-4.7.2) * [LinkedList&lt;T&gt;](https://docs.microsoft.com/en-us/dotnet/api/system.collections.generic.linkedlist-1?view=netframework-4.7.2) * [Queue&lt;T&gt;](https://docs.microsoft.com/en-us/dotnet/api/system.collections.generic.queue-1?view=netframework-4.7.2) * [SortedList&lt;TKey, TValue&gt;](https://docs.microsoft.com/en-us/dotnet/api/system.collections.generic.sortedlist-2?view=netframework-4.7.2) * [Dictionary&lt;TKey, TValue&gt;](https://docs.microsoft.com/en-us/dotnet/api/system.collections.generic.dictionary-2?view=netframework-4.7.2) * [SortedDictionary&lt;TKey, TValue&gt;](https://docs.microsoft.com/en-us/dotnet/api/system.collections.generic.sorteddictionary-2?view=netframework-4.7.2) * [SortedSet&lt;T&gt;](https://docs.microsoft.com/en-us/dotnet/api/system.collections.generic.sortedset-1?view=netframework-4.7.2) * [Stack&lt;T&gt;](https://docs.microsoft.com/en-us/dotnet/api/system.collections.generic.stack-1?view=netframework-4.7.2) Java: There's... there's a lot. Lists * [ArrayList&lt;T&gt;](https://docs.oracle.com/javase/8/docs/api/java/util/ArrayList.html) * [CopyOnWriteArrayList&lt;T&gt;](https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CopyOnWriteArrayList.html) * [LinkedList&lt;T&gt;](https://docs.oracle.com/javase/8/docs/api/java/util/LinkedList.html) Sets * [ConcurrentSkipListSet&lt;T&gt;](https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ConcurrentSkipListSet.html) * [CopyOnWriteArraySet&lt;T&gt;](https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CopyOnWriteArraySet.html) * [EnumSet&lt;T&gt;](https://docs.oracle.com/javase/8/docs/api/java/util/EnumSet.html) Specialized impl for enums * [HashSet&lt;T&gt;](https://docs.oracle.com/javase/8/docs/api/java/util/HashSet.html) * [LinkedHashSet&lt;T&gt;](https://docs.oracle.com/javase/8/docs/api/java/util/LinkedHashSet.html) * [TreeSet&lt;T&gt;](https://docs.oracle.com/javase/8/docs/api/java/util/TreeSet.html) Maps * [ConcurrentHashMap&lt;TKey, TValue&gt;](https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ConcurrentHashMap.html) * [ConcurrentSkipListMap&lt;TKey, TValue&gt;](https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ConcurrentSkipListMap.html) * [TreeMap&lt;TKey, TValue&gt;](https://docs.oracle.com/javase/8/docs/api/java/util/TreeMap.html) * [EnumMap&lt;TKey, TValue&gt;](https://docs.oracle.com/javase/8/docs/api/java/util/EnumMap.html) Specialized impl for enums * [HashMap&lt;TKey, TValue&gt;](https://docs.oracle.com/javase/8/docs/api/java/util/HashMap.html) * [LinkedHashMap&lt;TKey, TValue&gt;](https://docs.oracle.com/javase/8/docs/api/java/util/LinkedHashMap.html) * [IdentityHashMap&lt;TKey, TValue&gt;](https://docs.oracle.com/javase/8/docs/api/java/util/IdentityHashMap.html) * [WeakHashMap&lt;TKey, TValue&gt;](https://docs.oracle.com/javase/8/docs/api/java/util/WeakHashMap.html) Queues * [ArrayBlockingQueue&lt;T&gt;](https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ArrayBlockingQueue.html) * [ArrayDeque&lt;T&gt;](https://docs.oracle.com/javase/8/docs/api/java/util/ArrayDeque.html) * [ConcurrentLinkedDeque&lt;T&gt;](https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ConcurrentLinkedDeque.html) * [ConcurrentLinkedQueue&lt;T&gt;](https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ConcurrentLinkedQueue.html) * [DelayQueue&lt;T&gt;](https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/DelayQueue.html) * [LinkedBlockingDeque&lt;T&gt;](https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/LinkedBlockingDeque.html) * [LinkedBlockingQueue&lt;T&gt;](https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/LinkedBlockingQueue.html) * [LinkedTransferQueue&lt;T&gt;](https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/LinkedTransferQueue.html) * [PriorityBlockingQueue&lt;T&gt;](https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/PriorityBlockingQueue.html) * [PriorityQueue&lt;T&gt;](https://docs.oracle.com/javase/8/docs/api/java/util/PriorityQueue.html) * [SynchronousQueue&lt;T&gt;](https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/SynchronousQueue.html) And this isn't even covering the collections offered by the likes of [Guava](https://github.com/google/guava/wiki/CollectionUtilitiesExplained), [Koloboke](https://github.com/leventov/Koloboke), or [FastUtil](http://fastutil.di.unimi.it/) Multithreaded ---- **Task Scheduling** C# : [TaskFactory](https://docs.microsoft.com/en-us/dotnet/api/system.threading.tasks.taskfactory?view=netframework-4.7.2) and [Task.Run](https://docs.microsoft.com/en-us/dotnet/api/system.threading.tasks.task.run?view=netframework-4.7.2) are super limiting. Java : All kinds of [ThreadPools](https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/Executors.html), giving you super fine grained control on how your actions are executed. **Atomics** C#: [Interlocked.&lt;stuff&gt;](https://docs.microsoft.com/en-us/dotnet/api/system.threading.interlocked.increment?view=netframework-4.7.2). Generally cool, but you can only Interlocked.Read a ref long, and there's no support for booleans, leading to "weird" patterns like [this](https://stackoverflow.com/a/24893231/1917135) Java: Atomic&lt;EveryPrimitiveType&gt; gives you exactly what you want. **Scheduling** C#: [Timers](https://docs.microsoft.com/en-us/dotnet/api/system.threading.timer?view=netframework-4.7.2) Java: [ScheduledExecutor](https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ScheduledThreadPoolExecutor.html) usability is hard to beat. **Misc** C#: [WaitHandle](https://docs.microsoft.com/en-us/dotnet/api/system.threading.autoresetevent?view=netframework-4.7.2)s are pretty nice. Java: Third party [Apache](https://commons.apache.org/proper/commons-lang/apidocs/org/apache/commons/lang3/concurrent/package-summary.html) and [Guava](https://google.github.io/guava/releases/18.0/api/docs/com/google/common/util/concurrent/package-summary.html) have you covered for pretty much everything else. 
Thanks! I've replied to this [below](https://old.reddit.com/r/dotnet/comments/9o6032/does_anyone_here_write_java_for_their_day_job/e7s14xw/?context=2). I've used MemoryCache but have been very disappointed with it. I've spent a lot of time looking for something that can compare feature wise to Guava Caches or Caffeine, but haven't been able to find anything. I ended up writing [my own cache](https://github.com/wallstop/WallNetCore/tree/master/WallNetCore/Cache/Advanced) to suit my needs, but even that is missing some very important perf features (concurrency is implemented as whole-object-lock instead of per-bucket).
Would be very interested if you had knowledge to share on this! I've spent a lot of time looking into solutions for the mentioned chunks above for both Java and C#, and am still lacking replacements in my C# toolkit.
I have 12+ years of C# experience. I also have significant experience in Python and C++. When I interviewed for my current job, it was a C# position. When I joined, it was a Java and Kafka position, due to the Kafka Streams libraries being much more mature in Java than .NET. Now I'm a Java dev for at least the next few months.
You didn't mention anything from \`System.Collections.Concurrent\`, yet you included their Java counterparts
This. I've come to value my problem solving / critical thinking skills much more than development skills.
What's not working for F# on .Net Core?
I just remembered one critical thing that might throw you off: In Java, all non-static methods are virtual.
My question is: why do you need so many different collections? Just having more types is not always better. (I do agree PriorityQueue is missing.)
I've found various uses for roughly each of the above doing performance-intensive java code. For example, we were able to get some much-needed iteration perf by simply swapping out the Map implementation from HashMap to LinkedHashMap. Deque allows for removal from both head and tail, and the specific implementation (Array v LinkedList) has performance tradeoffs. With C#, there's really only what's in the standard library and nothing else. With Java, there's the vibrant standard lib, *and* a plethora of third party libs for even more use cases. If you're aware of a robust third party collections package for C#, please let me know! Apologies for generic complaints! The above is really just a showcase of my opinions, not an attempt to persuade anyone to agree with me. It's a collection of the "man I wish I had ___" that I run into for my day to day use cases.
Fair, will update my post! I also didn't include any of the collections from Guava, Koloboke, or FastUtil due to a lack of any third party C# collections libraries.
I've used all those different collections (in java) except for maybe five or six of the queues.
I think you left off a lot of C# list. There are ArrayLists, Linked lists, ConcurrentDictionaries, queues and stacks.. Am I missing something?
I didn't include the untyped, pre-generic data structures for both Java and C# for a more fair comparison :) Java also has things like Vector to C#'s ArrayList. All the other one's mentioned are linked above.
I have been interested in Kotlim for a while now. Could you please point me to a helpful resource for C# developer? Thanks.
Very minor correction. You forgot to specify that it compiles to JVM **bytecode**. 
last time I checked: type providers. fsharpi is pretty useful too.
Will do. I do plan on exploring Kotlin. It sounds interesting.
[removed]
Kotlin is pretty darn fantastic. I've been doing mostly C#, but we picked Kotlin for the backend for a new project. We picked spring, as we have a few devs who are experienced with that. Been tinkering a bit with the Kotlin 1.3 RCs and Ktor alpha though, and I'm really excited for that. 
Xamarin Forms has wpf support. 
I'm not an experienced Java programmer, [this article about ASP.NET] (http://cephas.net/blog/2003/08/08/httphandlers-httpmodules-servlets-filters/) says: * IIS &lt; --&gt; Apache Tomcat * HttpHandler &lt;--&gt; HttpServlet * HttpModule &lt;--&gt; HttpFilter [This](https://docs.microsoft.com/en-us/aspnet/core/migration/http-modules?view=aspnetcore-2.1 ) ASP.NET Core doc contains information on mapping between ASP.NET HttpHandlers/HttpModules and ASP.NET Core middleware. 
https://www.degruyter.com/downloadpdf/j/acss.2018.23.issue-1/acss-2018-0005/acss-2018-0005.pdf 
If you're learning Spring Web MVC, then you generally don't have to worry about servlets directly; you configure your web application to forward everything to Spring's DispatcherServlet, which in turn dispatches it to the appropriate controller. ASP.NET MVC handles this for you already.
Would you mind pointing me to the appropriate sorted collection? The only appropriate one that I can see is SortedList. The other collections require unique keys, which is not a constraint that a PriorityQueue has. Additionally, SortedList is typed by &lt;TKey, TValue&gt;, so you'd end up with some fairly confusing type signatures and usage patterns. It also doesn't support any typical Queue methods, so you'd have to roll your own via extensions, which feeds back into my original: &gt; and if I really want them, I have to roll them myself, which sucks.
I implemented it with a SortedList with a custom comparer, which has the priority as a property of the model objects. 
Using `Insert` method should be really CPU cache friendly because `List&lt;T&gt;` uses array internally and it doesn't do any unnecessary allocations so it's GC friendly as well. If you have **huge** priority queue then maybe some other implementation might be faster. It's true that you have to roll your own, but from my experience you rarely need priority queue. If your projects needs it often then writing extension methods for `List&lt;T&gt;` is trivial. One collection that is missing and I've need it in the past many times is generic `OrderedDictionary` and it's not so easily emulated with other collections. But it's finally going to be added https://github.com/dotnet/corefxlab/issues/2456
Insert should be cache friendly, but heaps are generally implemented as an array under the hood too, but with different indexing schemes, which should generally be pretty cache friendly as well. Don't get me wrong, I love C#. I just wish it had more robust collections, or third party libraries that had them (and the multithreading facilities mentioned above), and that Java (standard library OR third party library) has C# solely beat in these areas. That's all I'm trying to say here. I tend to need PriorityQueue, you tend to need OrderedDictionary, and they don't exist, and that's a bummer. Granted, it doesn't look like Java has a Map with the properties of an OrderedDictionary that you're interested in either :) 
Noone uses Eclipse anymore, it's not 2000. IntelliJ is in many ways more customizable and subjectively(from someone who worked on both VS2017 and IntelliJ/AndroidStudio/Rider) better than most other IDEs.
It's quite technology agnostic and not directly about any of your listed problems but I'd start with Clean Architecture by Martin, even if you're not gonna implement all that stuff on day to day basis, it's important to understand boundries between layers of your software and something a lot of people do not understand. It will be easier to understand why certain architectures were created and what problems they're trying to solve.
Only time you return a page with model is OnGet(). In order to update the text on the page you have to return something to it. You can "submit" value via POST and then return a page with updated model, or you can make a POST which will return only data (not entire page) and then call it from js on the page and update the textbox accordingly.
Yes. I work on a european telekom company, in the past year my team had the luxury of rewriting most of our codebase from spring + tomcat server setup to a spring cloud based. With the netflix things like zuul, eureka and feign we have a large flexibility in deployments and making a new microservice and integrating it into a stack involves very little configuration and can be done in about an hour. I'm still looking for .net alternatives, I know steeltoe.io exists, but it seems silly to mix java and .net.
Since i need this particular POST to be done when a device (scanner) sends a signal (OnBarcodeEvent) and the device manufacturer only provides support for c++/c#, is there any way to call c#-code from js on the page? 
I can't really picture the situations you've come across, I'm fairly new to programming and have barely touched asynchronous programming and threading, I just reacted to the blanked statement using keywords I was sure I had seen in .NET Many of the items on your list is just left me wondering "in which case would I want to use this?" By the sound of it, PriorityQueue just seems to be a SortedSet with a specific name. &gt;An unbounded priority [queue](https://docs.oracle.com/javase/7/docs/api/java/util/Queue.html) based on a priority heap. The elements of the priority queue are ordered according to their [natural ordering](https://docs.oracle.com/javase/7/docs/api/java/lang/Comparable.html), or by a [Comparator](https://docs.oracle.com/javase/7/docs/api/java/util/Comparator.html) To me it seems a bit counter-intuitive in the sense that its name implies it's FIFO, yet its contents are reordered. Then it's actually just a set of items, from which you expect to be able to get the "first" item based on its comparable value.
&gt; I’d say it is even better than C# :) I’m biased, but I know it first hand, I was ReSharper project lead for many years, and now working on Kotlin language. Could you list some of the things that makes you like it better than C#? Does Kotlin have something similar do LiNQ? How suitable is it for functional programming?
I'd suggest starting with Koans: [https://play.kotlinlang.org/koans/overview](https://play.kotlinlang.org/koans/overview) We still need to write a proper guide for C# developers, but there are some blogs &amp; materials out there. Like there is a JVM survival guide by Hadi Hariri ([https://hadihariri.com/2013/12/29/jvm-minimal-survival-guide-for-the-dotnet-developer/](https://hadihariri.com/2013/12/29/jvm-minimal-survival-guide-for-the-dotnet-developer/)) which is not fresh, but still mostly correct. 
&gt; If you're aware of a robust third party collections package for C#, please let me know! There's [C5](https://github.com/sestoft/C5/), though I have never used it.
All the issues I could find about this ([2406](https://github.com/Microsoft/visualfsharp/issues/2406), [3303](https://github.com/Microsoft/visualfsharp/issues/3303), [3736](https://github.com/Microsoft/visualfsharp/issues/3736)) are closed, so I think it should be working now.
Doesnt microsoft provide an official one?
Yes Microsoft does, I am using that one to shorten the code needed to create the token. It's using the same AddJwtBearer method under the hood. 
Neat package. On expiry defaulting to 2 days, definitely need to not hard code that. Could be made configurable in Token settings. That's just a little NuGet hygeine.
Thank you very much for your feedback. I shall fix it in future versions. Much appreciated.
No problemo.
[removed]
cool! Honestly, I haven't written F# in a while. Maybe F# on .NET Core is good to go.
If you are writing spring you might not enjoy the language, but libraries will make up for it imo. Ejbs - I rather go to dentist
Thank you for the suggestions! I'm currently working my way through *Clean Code*, and it has been great, so I'll definitely check out *Clean Architecture*.
Can you use Kotlin with JavaFX?
This is a cool project, thanks for sharing. Please note that these *box drawing* characters are not part of the original ASCII specification. They we're later added as an extended ASCII set. More info on the history and availability of these characters can be found here: [https://en.wikipedia.org/wiki/Box-drawing\_character](https://en.wikipedia.org/wiki/Box-drawing_character) &amp;#x200B;
Never tried kotlin. Sorry..
As soon as you say Micro-service you have to use .NET Core. Why? .Net Framework isn't design to work as small isolated services (i.e. you need a full Windows install with the full .NET Framework installed on all your instances). &amp;#x200B; .NET Core is designed to be "containerized" so you can easily build small .NET core "apps" (a service) that run on a very small platform / OS. Doing microservices with .NET Framework - which is *possible* \- would be a nightmare. It would be **super** expensive and slow as you would need to deploy a full **licensed** Windows OS for each service. With .NET Core you can just deploy a self-contained app (i.e. runtime is included as part of your executable) so you don't even have to worry about **whether the OS on the container has the correct .NET Core runtime!** That's huge. And if you deploy to a linux container then all your OS's are cheap (free). &amp;#x200B; .Net Core just happens to be incomparably more performant- as a side-effect of being open-source and designed to run in smaller environments. .Net Core 100%.
It's quite cool how javafx changed the old swing controls. Idk but is Kotlin worth it? I mean the scope.. Heard that SpaceX was using it.. I wonder why not pick pure C for speed/precision..
Absolutely! People even made their own Kotlin adapters to make it easier: https://tornadofx.io/
It was Android. ... Fuck Android.
Ok mock-up, but completely useless for programming. If my UI designer gave me this, I’d practically have to redo most from scratch for it to be usable. Nothing uses binding or data templates. This is effectively using Blend the same as a illustrator / vector software. - The grid, why not use a uniform grid with binding? - Schedule details should be a list view with data templates. - The color overlays of periods should be done with data triggers in the cell of the Uniform Grid 
Oh, that's just the overview page. Click on `Get Started` or check the menu on the left for more specific items.
Does [this section](https://docs.microsoft.com/dotnet/standard/library-guidance/versioning?WT.mc_id=social-reddit-marouill) on versioning still doesn't make sense? NuGet has a version that is irrelevant of the packaged assemblies while the assemblies themselves have their own version number irrelevant of whether they are being packaged in a NuGet or not. I know it's not as helpful but it's the state of things at the moment. Now, I'm not saying that they shouldn't be the same (they totally should!). But here's what you would need to do. First, define a `Version` in your `&lt;PropertyGroup&gt;` then use it `$(Version)` in all other version properties. That serves 2 purposes. First, `nuget pack` and `dotnet pack` will use that `Version` to qualify their package version. Second, that number is going to be reused everywhere. Note: All binding redirect issues only really apply to .NET Framework applications and shouldn't apply to .NET Core apps. If they do, DM me and we can debug what is going wrong. Makes sense?
As someone who have just recently started to learn WPF, is there any benefit to using Blend over just coding in Visual Studio outside of rapid prototyping?
You can right click any control in Blend and edit every template it uses. If you choose edit a copy you get the whole default template and can inspect and edit it to your liking.
SourceLink missing implementation for on-prem TFS. "Nice" first-party support here...
Yes, when you out really dig into blend, you can be extremely productive when supported by a team that understands Design time binding, providers, templates and so on. At the same time, if you are just doing ‘the same’ as in VS, there’s no need to use blend. 
Does it? There's documentation right there: https://github.com/dotnet/sourcelink/blob/master/README.md#team-foundation-server Let me know if it doesn't work. I know who to reach.
Git only, TFVC in issues marked as 1.0.0 milestone
Alright, I'll investigate this. I'm feeling like if at the very least we can't support url, we should at least support symbols for this.
An Nlog _reader_? Nlog supports _writing_ to various output formats based on a logging configuration that is usually set through a config file. Reading the data you've written back would depend heavily on what you've written, and I don't think there's any external libraries for reading/writing the log configuration files. It might help if you clarify what exactly you're looking for, because what I'm reading doesn't make sense to me. If you're looking for a .NET Core library to log data (i.e. _write_) llike how NLog does it, the latest version of Nlog (4.5.10) on [Nuget](https://www.nuget.org/packages/NLog) supports .NET Standard 1.3+ &amp; 2.0+, so any .NET Core runtime that implements those could use the standard library. Serilog is also popular and supports .NET Standard 1.0+ or 1.3+. If you're wanting to read logs, I'd suggest finding a structured format that one of the libraries supports and changing your output to suit that. You could even log to a logging service and use fancy log viewing tools/services.
You're a week late :) https://blogs.msdn.microsoft.com/dotnet/2018/10/09/net-core-october-2018-update-net-core-1-0-and-1-1/?WT.mc_id=none-reddit-bramin
You're a week late w/ the repost :) https://www.reddit.com/r/dotnet/comments/9mun3g/net_core_october_2018_update_net_core_10_and_11/
&gt; What would break if you're usiing 2017 vs 2008? Arent they all backwards compatable? Windows Mobile stuff
Re: Queue v SortedSet. The key difference here is that SortedSet will produce a collection with unique elements, while a PriorityQueue allows duplicates (a SortedList, if you will). Recently at work, I needed something to help with scheduling arbitrary jobs at arbitrary times. The only thing of interest here is the next time they should be ran. With a SortedSet, if two different jobs just happened to run at the same instant, I would end up losing one of them (there are ways to get around this in this specific scenario, but I hope this helps) For the Java use case, we had extremely tight memory and runtime constraints. We did a ton of crazy stuff, like compress floats to bytes, intern DateTimes, analyze perf + memory consumption of all of the above Collection implementations to name a few. One of our (many) hot spots was computing the hash codes of strings (which is why a string-type-only keyed cache leaves a bad taste in my mouth). These use cases aren't extremely common, but when you find yourself in one of them, I'd much rather be able to reach for an off the shelf solution than roll my own. If the above project were written in C# instead of Java, we would have launched months late due to the amount of things we would have had to hand-roll.
Thanks! I had discarded this due to not being maintained (last time I checked, the latest update was in 2011), but it looks like they're trying to start maintaining it again.
Really? What is the name of said package?
Interesting. The title is right hah
That nobody knows? Serilog is pretty well known.
The last Serilog version had over 1 million downloads... It's really well known!
Perhaps you can link a resource explaining how this is done?
NgineFx it's a rest api framework for geeks. 
Thanks for explaining, I had to google what MediatR helps with because I didn't fully understand its use.
While not documented, this is actually pretty default behaviour for properties in C# due to how they work. Properties are actually just fancy syntax sugar for declaring a field, getter method and setter method all in one step (and transparently accessing it). This can be easily observed when trying to name a method that way: public string FirstName { get; set; } public string get_FirstName() { return string.Empty; } You'll get an error that says "Member with the same signature is already declared." because it conflicts with the internally created getter method for the property. If you want to use C# properties from another language (like VB.NET) you also call them in that way.
https://docs.microsoft.com/en-us/aspnet/core/tutorials/web-api-help-pages-using-swagger?view=aspnetcore-2.1 
1 month old framework with no documentation and a sketchy website. Way to go..
It's a four years old framework actually, I have developed more that 4 applications with it! 10x more productive than servicestack. 
God damn it Reddit! I searched for the url it didn't show! 😬😬😬
I always enjoy finding new libs like this. Can you briefly explain how it is better than service stack? 
SqlKata, just found out about it. Pretty awesome library together with dapper.
I think msft employees post them to reddit after they're published. They always show up the same day or next morning.
Main advantage is convention over anything! For example Representing objects like Models, Commands or Queries as REST API, Instead of explicitly writing controllers or Services. The main idea is a chain (pipeline) of small reusable behaviors for every API. These chains can be created explicitly or conventionally. A typical chain for invoking a command is: \[Authenticate\] &gt; \[desterilize (bind) the input to the model\] &gt; \[invoke the validator for input\] &gt; \[invoke the command for input\] &gt; \[return success message\] So Ngine scan all commands and create a chain with this template and assign a route
Some do. Most is community however. Personally, I just like to push them to the community and see how it fares in the upvotes/downvotes. I really try not to repost within a short timeframe. Look spammy or automated which I don't do. PS: I'm a msft employee.
You could grab a Pluralsight + Code School subscription: https://www.pluralsight.com/codeschool Student Discounts: https://help.pluralsight.com/help/do-you-offer-student-discounts It will give you a route to follow and give you a sense of if you even *like* web-development. .Net/C# will come up further down the line if HTML/CSS/JS doesn't scare you off. 
Microsoft's docs.microsoft.com is pretty good. I'd recommend "Get started" for .NET Core from this page: https://docs.microsoft.com/en-us/dotnet/#pivot=docs&amp;panel=getstarted
Microsoft have many courses for free online: A beginner one is here https://mva.microsoft.com/en-US/training-courses/16169 You can even start programming in c# / .net online without installing anything by using https://dotnetfiddle.net to run your first programs. Pluralsight is a subscription based website with many training courses, with tons for beginners. Not .net based, but there is a beginning programming on the Khan Academy website. It doesn’t really matter that match which language you start with, they all (* not all *) have a bunch of the same concepts. *I put the not all so that my fellow developers don’t murder me and talk about Haskell, lisp, Forth, and so on. 
https://docs.microsoft.com/en-us/dotnet/csharp/ 
I'm sure if you google / youtube programming fundamentals you'll find plenty resources... if you're keen to learn dotnet - download visual studio - create a "hello world" console app, then try read two integers and add them, then print the result. Have fun! 
`System.IO.Abstractions.TestingHelpers`. It has around 400k downloads, which is about half as much as `System.IO.Abstractions`. It's really nice to be able to unit test heavily file IO bound systems without actually needing to use your file system. It's even better when you don't have to implement the mocks yourself :D
Reddit search engine sucks multiple forms of ass :(
Other people: links and technical stuff Me: YouTube. Just start slow and learn gradually by YouTube videos. If you get into it and enjoy it, then you can look into more technical resources. It's quite vast, so learn the basics and then focus your goal down to the specific subjects you're interested in.
I'd also highly recommend CrashCourse computer science on YouTube for the basic understanding if you don't already know it https://youtu.be/O5nskjZ_GoI
Microsofts 'getting started' docs are plenty good IMO. [https://www.microsoft.com/net/learn/dotnet/hello-world-tutorial](https://www.microsoft.com/net/learn/dotnet/hello-world-tutorial)
Azure is pretty competitive when it come to Linux boxes. You can also use the azure PaaS for hosting asp net core apps. I forgot what it's called
For the love of god just use nameof on your options classes so you don‘t have to hard code strings...
Not the author but will share with Steve. 😬
Thanks for the tip - handy to know. I'll get this updated
I really like azure
I have a micro EC2 on AWS running some of my older .Net Standard stuff. Pricing isn't too bad. If you're doing dotnet core digital ocean is always a nice option. 
Been using Azure since about a year after it came out. For simple stuff that is not used or even development its not bad at all. If you have MSDN you get free credits that handle most of your dev. You can ramp to larger stuff as you need, the costs scale pretty well. They can be a bit more expensive than a traditional host but I have never had a traditional host come close to what I can do with Azure short of the old days when I was given a root shell on my instance or having an expensive VM.
Jasmine is amazing! 
Updated! &amp;#x200B;
They already provided useful links and technical advice but Always remember, the first step is the hardest part, after that, it will be all nearly a cake walk. 
Azure is cheap for me. $5/month for Azure SQL + free Web Apps. But I'm doing toy projects where I don't need performance or custom domains.
Vultr and Linode work for us with dot net core. We could probably be served better with Azure or AWS cloud services but we are not in a rush to fix things that are not broken.
for unit testing I really like NSubstitute. It works with .net core as well. For model state validation (and client side validation), Foolproof validation is really good, but sadly only for .NET Framework &amp;#x200B;
If you're on .NET core - Heroku supports docker (documentation @ [https://devcenter.heroku.com/articles/container-registry-and-runtime](https://devcenter.heroku.com/articles/container-registry-and-runtime) ). Good enough for quick prototyping.
smarterasp.net for MVC 5 app, but now doing app on core, so will try linode as well.
I just learned almost everything about VB.NET by watching YouTube video's. 
I feel it is wrong to use the archaic mess that is the current web development stack as an introductory coding platform. I would probably start with pure C# console apps and get a good foundation for the basic building blocks and operators.
Awesome thanks!
Cloud South https://www.cloudsouth.com/dedicated-servers/ Some stuff on AWS and Azure.
MySql db. Dot net core with MySql db == the beauty of C# with the added bonus of being able to host on cheap Linux servers. Win win. 
Can you elaborate with a snippet of code please?
Can you target .Net Standard instead? That would allow you to run your library against both .Net Framework and .Net Core
 What I was doing previously was just copy pasting the code of each class and just modifying that one line. That is most certainly wrong but maybe this is too. Do you have any suggestion on how to do it correctly?
DigitalOcean
Works well for aspnetcore too. There's a 3rd party build pack for it. You can't run EF Core migrations the same way you can with Rails migrations, but you can add some code in your Program.cs file to run any pending migrations as it starts up.
This reminds me of the abstract repository pattern. Sounds great until you need custom functionality, then it all falls apart.
Which asp framework are you using? WebAPI 1 doesn't support inheritance for routes, FYI. WebAPI 2 supports it, with some extra work, and the newer aspnetcore stuff works without anything special needed.
Did not know about this. Very useful, thanks for sharing :)
My questions are * How many repositories are there? * Whats the likelihood of any of these repositories will require any special handling? To keep with this idea though, perhaps keep your Repository creation in a DI container and do the following: [Route("api/v1/[controller]")] public abstract class ABMApiController&lt;T&gt; : Controller where T : class { private readonly IRepository&lt;T&gt; _repository; public ABMApiController(IRepository&lt;T&gt; repository) { _repository = repository; } [HttpGet("{id}")] public IActionResult Get (int id) { return Json(_repository.Get(id)); } } then public class CustomerController : ABMApiController&lt;Customer&gt; { public ABMApiController(IRepository&lt;Customer&gt; repository): base(repository) { } }
I do too, I just find it's pricing model confusing, and expensive once you start throwing sql databases and storage into the mix
This would work if there is enough test coverage. Using code contracts and embedding verification could speedup this progress. There are great tools out there which could complement this nuget automatic updates. [http://www.postsharp.net/blog/2017/01/default](http://www.postsharp.net/blog/2017/01/default)
I don t think in a dotnet core Project u can target dotnet standard librarie.
Yeah, thought so. Exactly what I'm planing to do for my ongoing project, so I don't have to host on win servers.
So. Much. This. Yes, you should have an abstract controller class (DRY), but also override and extend methods where appropriate.
I use Azure only.
There's syncfusion with a Community license. They have PDF, XLS, and DOC generation. Very easy to use.
For HTML to PDF, PrinceXML is one of the best I've seen. I've heard good things about PDFReactor but that requires it's own web server.
Might want to add that neither of those are cheap solutions. 
Good point. They are top of the line in quality and features but also in price. But crappy HTML to PDF converters are a dime a dozen. I've tried many and most of them have the same sub-par engine.
Ahhh, yeah they can.
This is what I use and it has been working well: https://github.com/ststeiger/PdfSharpCore
Why dont you look at porting you .net project into core? It might be easier than you would think. Im halfway through doing this now by breaking out all the external dependencies into .net standard libs so when the time comes we can switch accross the last project to core with most of the hard work already done.
For the last years iv'e stayed up to date with blogs/articles from .net blog aggregates like The Morning Brew ([http://blog.cwa.me.uk/](http://blog.cwa.me.uk/)).
&gt;syncfusion Is there a problem with SyncFusion being dependant on GDI+ [https://www.reddit.com/r/dotnet/comments/7myyrb/pdf\_library\_for\_aspnet\_core\_20\_on\_the\_full\_net/drygyud](https://www.reddit.com/r/dotnet/comments/7myyrb/pdf_library_for_aspnet_core_20_on_the_full_net/drygyud) &amp;#x200B; I'm trying to find one that someone is actually using that is purely managed .NET Core - i.e. no dependencies on OS. Thanks.
I think aspose has some .net core libs for this but they are not cheap. 
I'm not going to port the pre-existing project, but I would like to use the same identity database with a new project thus be able to build the new project in core
Moving from EF6 to EFCore isn't really an upgrade, its a migration.
I’m new to dot net but I’ve generated thousands of PDFs from HTML using a cli tool - wkhtml2pdf Also, checkout pandoc.
I have many dotnet based website customers and I choose Azure and AWS where I need to handle all support activities. As cost effective, latest .net core &amp; MVC, and customer support, I have used Accuwebhosting's windows hosting. A2hosting is also a good option.
[removed]
In Framework you can too. “Standard” just indicates what API version is supported so it can determine what is the minimum level of runtime to support it. A library that’s .NET Standard 2.0, can be produced by or run on .NET Framework 4.6.1, 4.6.2, 4.7, etc or .NET Core 2.0, but won’t be able to be produced by or run on 4.5.1 or .NET Core 1.0. https://docs.microsoft.com/en-us/dotnet/standard/net-standard
Ah okey i get the Point now.
Plus one for Aspose. It works really good, and has good documentation. However you are right, it is speedy!
I work for an insurance company that creates many financial exhibits in Excel, and Word. We use Aspose. It has a great API that supports every single function Microsoft apps do. Also supports nearly flawless PDF conversion.
For Excel automation that evaluates formulas we use spreadsheet gear. Also awesome.
I would be very careful with using anything that depends on wkhtml2pdf. I'm currently looking to get away from it. It is pretty buggy. For instance, if there is an broken inline image link on a page, it will crap out and not generate the pdf. 
Any COM component requires [registration](https://stackoverflow.com/q/5665772/55209) with admin rights.
Have you thought of maybe using something like [Blazor](https://blazor.net/index.html)? No idea if it's going to work but it looks like add-ins for OneNote are in JavaScript due to Browser/Apps mode that requires it to run everywhere. No direct knowledge, just my impression.
Seconded. What are you moving to?
Jsreport. 
I already use NLog for logging and it works flawlessly and writing logs isn't my problem. NLog supports multiple targets and we can install packages to support further targets. I figured that the same thing existed for reading files generated by NLog. Like NLog.Xml.Reader or something. Anyway, I wrote my own log reader. The only downside is, when I adjust the layout in my NLog.config file, I will need to make adjustments, which sucks. But I guess there's no going around it.
Thanks, much appreciated. :)
you idiot? or blind? NO JAVASCRIPT
giving shitty answer instead of what you've asked for and ignoring what's written in the question -- this isn't help
He said blazor? That is c#? 
He suggested blazor, and then gave you a reason why you HAVE to use javascript. Blazor would be the only possible alternative. You should probably actually think before posting, and being toxic to someone attempting to help you.
&gt; shitty answer What about their answer is shitty?
Chrome has a headless mode that produces pdf output from html. It's your best bet if you want an up to date browser engine.
Recent versions of SQL Server have in-memory tables. That's another option for you to look into. https://docs.microsoft.com/en-us/sql/relational-databases/in-memory-oltp/in-memory-oltp-in-memory-optimization?view=sql-server-2017
Ok thanks 
You could try Puppeteer Sharp: https://github.com/kblok/puppeteer-sharp It's a .NET wrapper for headless Chrome. There's an example of PDF generation on the project's GitHub readme page. 
For HTML to PDF, you might want to try Puppeteer Sharp. It's a .NET wrapper around headless Chrome: https://github.com/kblok/puppeteer-sharp
Blazor is .NET that can be compiled to JavaScript allowing you to write in your native language and "compile" to the web. 😀
For the interested: Summary of changes in 2.2 vs 2.1: **Routing:** We’ve introduced the concept of Parameter Transformers to routing in ASP.NET Core 2.2. **Link Generation:** Added a new service called LinkGenerator, it is a singleton service that supports generating paths and absolute URIs both with and without an HttpContext **Health Checks:** This check will make sure that the application can communicate with the database you configured for MyContext **Validation Performance Improvements:** In 2.2.0-preview3, we’re adding a feature that allows MVC to short-circuit validation if it can determine that a given model graph would not require any validation. This results in significant improvements when validating models that cannot or do not have any associated validators. **HTTP Client Performance Improvements:** For applications making many outgoing HTTP requests, such as some Microservices architectures, throughput should be significantly improved. **ASP.NET Core Module:** We added support for the ability to detect client disconnects when you’re using the new IIS in-process hosting model. The HttpContext.RequestAborted cancellation token now gets tripped when your client disconnnects. **ASP.NET Core Module diagnostics:** The ASP.NET Core Module also features enhanced diagnostics logs that configurable via the new handler settings or environment variables that expose a higher fidelity of diagnostic information. **SignalR Java Client**: Preview 3 includes a few notable changes to the SignalR Java Client as we progress towards a 1.0 release: &amp;#x200B;
He said blazor? That is c#? 
ClosedXML library is what you want for the Excel automation.
Out of process 64-bit debugger seems like it could be a big win. And it seems like it's coming to 2017 by the end of the year too judging by the roadmap.
Ha. I've spent quite some time trying to solve this one. 1. [**wkhtmltopdf**](https://wkhtmltopdf.org/)**:** decent converter, but is lacking some css support. Operated from the command line. Works on both windows and linux. Spent days trying to fix shitty css problems that somehow only exist in wkhtmltopdf. Expect it to work well with html/css that is specifically designed for wkhtmltopdf. 2. **headless chrome/chromium** with great success on both platforms. By far the best support. Also very easy to develop and debug, because the result will be the same as the print preview in Chrome. Called with: `chrome --headless --print-to-pdf=github.pdf https://github.com/` This method lacks more fine grained control for printing, but works very easily on both platforms. (Out of the box) 3. For easier control of the print settings, I would recommend [**Puppeteer**](https://github.com/GoogleChrome/puppeteer)**.** It uses nodejs, but makes it very easy to tame the chromium print settings. 4. For windows, I've also used **CefSharp (Chrome Embedded Framework)** with great succes. Works very similar as puppeteer, except you won't need to install. 5. For linux, I've tried **CEFGlue (Mono bindings)**, and succeeded, but it's installation was a lot more effort than I would have wished, and if possible I would stick to Puppeteer. 6. For MS Word and Excel, I would highly recommend looking into **libreoffice**. Their PDF game is pretty strong. It will allow you to convert from and to a lot of different formats. `/usr/lib/libreoffice/program/soffice.bin --headless --convert-to pdf --outdir /test/path /test/path/test.doc` &amp;#x200B;
Just don't pay them anything. We call them SuckFusion where I work. They will bait and switch you. On the phone their engineers will tell you you only need licenses for developers working with their components. Later, their lawyers will do everything they can to extract license payments for everyone that has access to your code repository, including SQA, managers, etc. Fuck them.
No C# 8.0 yet?
We use jQuery Datatables and Datatables editor. It's really easy to use and supports many features such as sorting, pagination, search, reordering, and editing. Like others have said most reliable solutions cost money but in my opinion it is well worth it. https://www.datatables.net/
That headshot kills me every time
Probably unrelated to the VS update band. Also probably going to be a big one with default interfaces and the null changes. 
No it isn't. Blazor doesn't compile to javascript, it compiles to Web assembly. 
Which part? Blazor is. Net which compiles to Web assembly. Neither of those things is javascript. 
Blazor compiles to WASM, not JS
Please buy Sonarqube already
It's been a long time, but I think sqlite has an in-memory database you might be able to leverage.
First preview version is likely to come out at the next build conference.
An "easier" http request API... with throwing out a lot of good practices. - Do not use a static `HttpClient`. I thought that news reached everyone by now. Don't do it. - Why are the parameters mutable? Are you modifying the passed query parameters or custom headers? Why can't I pass an immutable data structure? - Turning verification of SSL off should be an absolute exception case, not a regular parameter on the method (and every method again). - Why would I have to make `T` in `PutJson` a class? Structs should work too. - Why do you always carry over the synchronization context? Not once you use `ConfigureAwait(false)`. - Why do you assume that the presence of the `DataContractAttribute` menas the data contract serialzer should be used? Newtonsoft.Json uses those attributes too! - Why does your `SendFile` method contain **EBAY** specific code? - Use `using` instead of manually disposing. - Your comments do not align with the code (e.g. "write to console" when there is no console involved). - The LoggingHandler should not use `Console`, but instead an `ILogger`. - There is absolute no documentation in your library. - Everything in your library is public, including an **extension method for string**. Keep your internals internal, don't pollute the public namespace. 
Cool, thanks. 
Adding further blog topics from the same series: https://asp.net-hacker.rocks/2018/09/24/customizing-aspnetcore-02-configuration.html https://asp.net-hacker.rocks/2018/09/27/customizing-aspnetcore-03-dependency-injection.html https://asp.net-hacker.rocks/2018/10/01/customizing-aspnetcore-04-https.html https://asp.net-hacker.rocks/2018/10/04/customizing-aspnetcore-05-hostedservices.html https://asp.net-hacker.rocks/2018/10/08/customizing-aspnetcore-06-middlewares.html https://asp.net-hacker.rocks/2018/10/11/customizing-aspnetcore-07-outputformatter.html https://asp.net-hacker.rocks/2018/10/17/customizing-aspnetcore-08-modelbinders.html 
Doesn’t MySQL have performance issues due to the indexing? That’s what shifted me to Postgres at least.
I've used [this](https://www.browserless.io/) to wrap Chrome to generate PDFs. If you're hosting it yourself, there are some settings on the Docker instance to get throughput too.
 Is the new csproj format only for Core projects? I'll have a look at migrating to Paket.
Yep, thanks guys - Aspose are definitely on my short list. Do you know if they have dependencies on OS features? Can i run it in Azure as a Function or API App Service?
Thanks for this really useful list - I would never have thought of using headless Chrome! &amp;#x200B;
Clif notes: in .net core there is an memory provider, it doesnt support transactions and sql commands (and referential integrity? wasnt covered). SQLite does support sql commands... Done. Not enough to justify an url imho.
Hell yeah. 
No, SDK-style projects can be used for 'old' .NET Framework projects too. Better yet, for libraries you can multi-target very easily with it.
Using a static/singleton HttpClient is fine unless you are dealing with DNS changes. HttpClient is designed to be re-used across requests. Can you point to any documentation that states is should be disposed/re-created for each request?
I tried using the in-memory db for testing and it wasn't fruitful. 
* Coding blocks * Complete developer * Developer on fire * Developing up
Try the app SoloLearn and choose C#. It's free and goes through the absolute basics. Most of it you can fly through but theres some bits in there that have 1 line descriptions that help a lot. I did this before an interview a few years ago and there was a few bits I could explain but never knew the exact meaning/names of what they were. this app helped. Also this playlist on design patterns is awesome: [https://www.youtube.com/playlist?list=PLrhzvIcii6GNjpARdnO4ueTUAVR9eMBpc](https://www.youtube.com/playlist?list=PLrhzvIcii6GNjpARdnO4ueTUAVR9eMBpc)
Would advise against this and use SQLite
The limits exist so an unprivileged processes can't hog up your whole system by opening tons of files. For dotnet is apparently common to need a bit more than the system defaults. Open file descriptors use memory. The most important thing is that there's a limit so your app can't accidentally (or deliberately) crash your system. (Similar to eating all your ram) For modern systems its probably not a big problem of you open eg 400k files, but having a ulimit still makes sure this is a deliberate decision.
Would you pick him up if he was hitchhiking? 
I used it on my last project and it was pretty good. It ment i didnt have to interface out all of my data layer, bonus. n.b. dont test crud, test your business logic.
In the SharePoint world we have [this guy](https://twitter.com/jeffteper).
oooh a reviewbrah reference in the wild.
I prefer Brent Ozar laughing at my query plan https://pbs.twimg.com/profile_images/419822942642384897/bm1afnid_400x400.png
Pluralsight is the best resource for a variety of topics. There’s a lot of courses around architecture types there. Usually the course creates some sort of app that puts the topics into practice. 
A lot times when I begin a project I don't know how to accomplish every little detail. &amp;#x200B; If you want to recreate something like twitch search how to handle videos, streaming and so on. Every time you get stuck search and just keep at it. Eventually, you will learn everything you have to know and next project will be easier. This is probably a good approach for someone who has some experience. &amp;#x200B; If that does not work for you pick up a C# first, then .Net or try a service like plurarsight. Then, try to make something like twitch.
Yeah but keep in mind his app will have to read in a 1 billion record database from disk every time it starts up to populate his database, since SQLite is in-process. SQL Server might be a better choice in this case.
It is only thread safe if you use it to make calls, not if you need to change the settings. The problem is that you probably need more then one if your using different urls, with different settings. One way to work around this issue by making a http factory, and caching the httpclients based on the url Ex: https://github.com/tmenier/Flurl/blob/dev/src/Flurl.Http/Configuration/FlurlClientFactoryBase.cs
What did you have problems with? We have a whole suite using it and haven't ran into to many problems.
 Microsoft.EntityFrameworkCore.InMemory =&gt; UseInMemoryDatabase? I was using it for tests and had problems that didn't exist with the real db. Next time I need to do something similar, I will try the SQLite in memory for a more realistic provider. 
By using migration scripts and not automatic migration. 
By using migration scripts and not automatic migration. 
Yeah, for multiple base URLs I usually use a HttpClient dictionary with the URL as the key to reuse it for each API. 
Your post has been removed. Self promotion posts are not allowed.
Sounds like I can expect a PR soon?
With docker compose? Do you work with volumes? Can you explain a bit more?
Her are a view points. Let the SQL Server do some work (Stored Procedures, Temp Tables, Views). Overthink your DB structur if you have such big Tables. But a Load Balancer (Redis or something) between user and service.
Since i don't know what infrastructure* you'll rely on I'll just throw some pointers off the top of my head that may help in your search for a solution: * Can you run these calculations in an asynchronous way? if so, try to use a messaging system (ex: Azure Service Bus) for calculation requests that will distribute the load through worker jobs (ex: Service Fabric Services). * Does the data needs to be all loaded beforehand? can't a divide and conquer approach be used instead? (basically solving multiple subsets of the problem to solve the problem as a whole). * If the two previous point stand, can a batch processing approach (ex: Hadoop) fit with your requirements? * Can the calculations be done beforehand? if so, try to create materialized views of the results. * Can multiple requests from a user have the same result based on some pattern? if so, try to use a cache to retrieve requests that match previous patterns (ex: Redis) ^\* ^- ^What ^technologies ^are ^available ^to ^you, ^the ^expected ^costs ^of ^running ^the ^application, ^etc. It's hard to go into detail without knowing the whole spectrum of the problem, I hope these points are of use to you, the basic idea though is cache what you can and try to scale horizontally instead of vertically when managing big datasets. 
Are these calculations being done on the entire dataset at once (millions of rows) or just a subset of them (a few thousand rows)? In either case, but especially if you are working with millions of rows at once, you should do the calculating on the SQL server via stored procedures, views, etc. This will be significantly faster than doing the calculations on the web server, but can still be very slow. The extreme ideal would probably be a data warehouse with fact and dimension tables\* where the SQL server calculates everything, stores the results, and the web server merely grabs the stored results. This allows you to have complex data crunching that could take hours, but the web server is just grabbing flat data and would be extremely fast. It sounds like you are expecting some sort of user input that could impact that calculations though, so this may not work. \*caveat: I haven't worked in that realm in a few years, I have no idea what the current norms are for that type of thing.
Pretty much what was said - execute the operations asynchronously and store the results somewhere (a table....in a redis cache...etc.) Then from a UI perspective you can tell the user when the operation is done (using SignalR or someone messaging bus) and allow them to view the results using paging - which would necessary if trying to view millions of records. Even if you compress data coming back from SQL server (which is a network concern) they'll still be represented in memory by whatever CLR objects you choose to use. Load balancing will help scale the app to multiple users, but for doing the actual calculations in the background you may need to bring up workers dynamically as needed (some sort of CPU specialized cloud instances). These should be separate instances that the web app itself that are focused only on doing the heavy background work. &amp;#x200B;
Start with the official .net docs. They have lots of great tutorials. https://www.asp.net/get-started 
Independent of docker. Easiest/most reliable would be to keep your DB schema in source control, that way master always has the scripts to make a dev DB look just like production. As part of your CD pipeline you create a temp db with that schema, call it source. Create a temp DB from the EF schema, call it dest. Use a schema compare tool like redgate to generate the script that makes prod schema changes. Then run that against prod. One client of mine required developers to maintain their own schema change scripts, which sucked. EF classic had the ability to generate scripts built in, but I think that was ditched with Core. 
Thanks for this.
Are you guys ever going to integrate the Alive realtime development pluggin tech you purchased years ago?
Have you tried googling?
Udemy has some great classes.
My company actually does this except the data is stored and read from the CSV files uploaded by the users. We went with disturbed services (C# windows services) that handled the work from a queue. Just recently, we moved them all to Docker so that each job could spin up a new container to perform the needed operations. I could get into a little more overall architecture if you are interested. 
I don't know of any guides but it's not difficult to accomplish this. If you're using shared schema where all tenants are in the same DB you create an abstract class that all of your entities inherit from. This entity has a tenantId property. Add a tenantId property to every table in your database. Add a global query filter for every table. This will filter all of your requests. Then you need some way of getting tenantId into your context. I just make a property on the context and set it in my IOC container when the request cones in. The tenantId is in a claim that is in the bearer token from the client. If you're using separate databases you take the claim for tenant from the request and map it to a connection string that's used in your context. You don't need any of the stuff from shared schema that I described above. https://docs.microsoft.com/en-us/ef/core/querying/filters has a lot of what you need.
I don't see how you can have confidence in your tests when foreign keys don't work. I can let transactions slide if your transaction management is tested separately. I also went with sqlite in memory and am very happy with it so far. 
I'd like to hear why you went with docker container instead of running jobs in services.
Regardless if there is user specific input or not, long running processes would likely be better off handled via a queue/bus setup? Input is sent to management service which validates command/query and dispatches the message to the queue (or checks for existing cached/calculated result matching request parameters). When passing a message to the queue manager could also attach an ID to the message and return that to the client. Work processes, whether they run as windows services in the background or whereever, read messages from the queue and process them. Once task is finished, a notification message would be sent to the queue by worker indicating that a task with the specific ID has been finished, and results stored somewhere using the ID to identify the result set. Manager or another process would pick up the notification and use the ID to query result set / notify the client of results / send an email / cache result etc. If you recognise it's not feasible to run calculations in real time you have to precalculate them (if possible) or accept that it's not a real time task and use messaging and notifications.
I would definitely use asp.net core as it's lightweight and portable, and I think as a framework it's far clearer what it's doing. You could use the empty template and replace the Hello World response with the work you need to do on the xml. Alternatively, if it's easier due to mvc experience and guidance on the web, you could use the Web API template and have a single controller action as the entry point to your work. I'd definitely say a full on mvc or spa template in either asp.net 4.5+ or core would be overkill, since you don't need views or much routing. I personally wouldn't use web forms today, but if you're most comfortable doing that, then go ahead.
Thanks! To add a little context, this will be running on-prem on IIS 8, so I don't need portability, and resources aren't a concern (not only will it be on an overpowered server, we're looking at maybe 10 posts a day from the vendor). Given these facts, would there be any benefit at all in investing my time in going the Web API route over the empty template approach? 
What sort of processing are you doing on the XML? It might be worth just storing it when it is posted to you, then processing it asynchronously so that your web request isn't hanging on.
A .NET Core WebAPI template is pretty empty anyway. Has enough for doing some routing and handling (de)serialisation but otherwise not a lot else there. I'd suggest just using one of those templates, changing the routing to suit your needs and your away. It'll be incredibly easy. Shame it has to be on Prem though, this sounds like a near perfect use case for Serverless like Azure Functions.
Thanks - I'll go with the Core WebAPI, might as well learn something new even it's on something as trivial as what I'm doing. I suspect one day we may go Azure, but likely not in the near term.
You could use Azure Functions too with webhook. Then just use c# on your visual studio and then just deployed to Azure. It is very cheap to run and no maintenance.
Thank you very much! didn t know about pluralsight.
Thank you for the advice!
Web API - add a controller and set up your route and you're done. That seems like the easy part - how is your vendor going to be authorized to call your api? Will need to have some kind of key/secret exchange to secure it.
&gt;EF classic had the ability to generate scripts built in, but I think that was ditched with Core. At least in the current version it is possible to generate migration scripts with EF Core: [https://docs.microsoft.com/en-us/ef/core/managing-schemas/migrations/#generate-sql-scripts](https://docs.microsoft.com/en-us/ef/core/managing-schemas/migrations/#generate-sql-scripts)
&gt; EF classic had the ability to generate scripts built in, but I think that was ditched with Core. Is it what you're looking for? `dotnet ef migrations script --idempotent --output "$(build.artifactstagingdirectory)\EFMigration.sql"`
I plan on switching over to CORE in the 3.0 release. I guess I'll see if there is an issue then. 
There’s so much more info required here to give an accurate answer but I’ll take a shit anyway. It sounds like you’re doing an ETL operation and the complexity of the insert isn’t obvious no the table structure it’s being inserted into or how it’s setup index wise. My company does lots of ETLs and for our workload we tend to do the following. 1) prepare all data for insert, 2) batch upload to DB in a temp table, 3) perform matching (typically hash) 4) bulk insert or update rows as required as a single transction
Depending on what the use is for your *Get*, a [Predicate](https://docs.microsoft.com/en-us/dotnet/api/system.predicate-1?view=netframework-4.7.2) might work. interface IRepo&lt;T&gt; { T Get(Predicate&lt;T&gt; predicate); } With usage... class Thing { public string KeyA { get; } public string KeyB { get; } } void Method(IRepo&lt;Thing&gt; thingRepo) { var getResults = thingRepo.Get(thingObj =&gt; thingObj.KeyA == "AValue" || thingObj.KeyB == "AnotherValue') }
Out of curiosity, what do you mean by a complete change? Like you guys are totally rebuilding your front end from scratch, or are you just updating the layout? Are you staying in web forms or moving to MVC?
Right. Questions about the effort of each check operation, the other loads on the server, other jobs that might be locking tables needed, possibly even network traffic depending on the topology of machines used for this. Loading it all into SQL Server and then doing the processing allows most of that thread balancing work to be done by the server. 
Off the top of my head: There's nothing to say that your Tid generic type can only be a single value, you might have a struct containing a composite of your two key fields, and it would be up to your concrete implementation to use those multiple parts in the query. An alternative, and one that might work better with your 'no key' tables, is to break the interface down, and only implement Get&lt;Tid&gt;() on those repositories that can be distinguished by an ID. &amp;#x200B;
I think what you're looking for is the `params` keyword. I would setup your interface like this: public interface IRepository&lt;T&gt; where T : class { IEnumerable&lt;T&gt; GetXNumberOfRecords(int recordsToGet=0); IEnumerable&lt;T&gt; GetAll(); T Get(params object\[\] id); bool Add(T entity); bool Delete(params object\[\] id); bool Update(T entity); } The `params` keyword will allow you to pass in zero, one, or more objects as a key. Used like so: var item1 = noKeyRepository.Get(); var item2 = oneKeyRepository.Get(intId); var item3 = threeKeyRepository.Get(intId, stringId, stringId); The method gets an array of objects as ids that your method will parse to determine how to call your ORM. Some ORMs even take an `object` as an id for their own `Get`/`Delete` methods.
Just rebuilding frontend from scratch, staying in Web forms. 
We started with running jobs inside the services, but we changed to Docker instances for a couple of reasons. The first and biggest was cost cutting. We moved the services to .Net Core and are now running them on Linux Docker instances. With the size of Windows machines we were using to handle the large (4+Gb) files, this decreased our cost a couple of thousand dollars a year. The Docker instances also scale better and easier to accommodate more parallel jobs. The second reason was it simplified our deployment of those services. Instead of needing an install on the machines, the CI/CD pipeline just updates the Docker image and AWS knows to use the latest. In the case of a roll-back, we just point AWS to the previous image. It has cut our deployment time down to a quarter of what it used to be.
this is very interesting. so with params being an array of objects, it'll work with multiple data types? I'm hoping...
Interesting. Can you elaborate on how you go from sending a command to start a task with some parameters, to spinning up a docker image to process that request? What orchestrates it all?
If you're passing the predicate straight to a DB or, then you'll want to wrap it in an Expression&lt;&gt;
I like having interfaces for various reasons, but specifically this one, it seemed like a pretty common approach I saw people doing for repository pattern/classes so I started with it, but it doesn't cover the more complicated real world scenarios like no primary key, 1 primary key, or multiple primary keys.
Both read lines and database operations are IO Bound therefore use async programming
We implement messaging using AWS SQS. Our front-end web application will queue a message. We have some long-lived containers that are available 24/7 to handle messages. The service will listen for a message in the SQS and pull it to start the process. If the long-lived services are busy and the SQS queue gets over a certain number of messages waiting, AWS will spin up some short-lived containers to process some messages. These take about a minute to spin up which is why they are only spun up after a certain number of messages are waiting in the queue. The SQS messages have the minimum required information, and the services have access to our Redis/DynamoDB and S3 buckets to get all the information they need. 
Pretty cool :) 
Entity Framework seems to use `params object[]` for their repository interface. If you want to be as generic as them with your repository pattern or will be using EF underneath your repository, then I'd argue that you should use `object[]` to define your primary keys to expose similar behavior. Can you guarantee that all composite keys will be made up from int data types? Your repositories could all inherit from a base class that provides overloads for each method taking in an int and converting it to the data type: `public T Get&lt;T&gt;(int id) =&gt; Get&lt;T&gt;(new object[] { id });`
Surely the answer to this is the same as any interface, a simple decoupling of the data layer from the business layer, so that there isn't a dependency on a concrete class in the business layer?
It's just Core. Not CORE. 
What stops me from calling the following? var item3 = threeKeyRepository.Get(intId); I believe the keys should be type safe as well.
Using something because you've seen it done before is called cargo-cult programming. You should always have a specific, well-understood purpose for any abstraction you add. YAGNI. [https://en.wikipedia.org/wiki/Cargo\_cult\_programming](https://en.wikipedia.org/wiki/Cargo_cult_programming)
We use build tasks to assign the various assembly info, which includes the numbers, at build time. There are various frameworks to support this, depending on which tool chain you are employing. [WriteCodeFragmentTask](https://docs.microsoft.com/en-us/visualstudio/msbuild/writecodefragment-task?view=vs-2017) is useful if you are exclusively MSBuild. Cake/Fake/Rake/*ake libraries all have counterparts. Just search for "assemblyinfo &lt;name of your chosen build tool here&gt;"
This particular interface is not useful, because there is very rarely code that needs to consume "some repository that can get a thing by id(s), save a thing, update a thing, etc but I don't know what thing it is." Specific repository interfaces for different collections DO make sense. \`IWidgetRepository\` can have \`Get(int id)\`, \`IFooBarRepository\` can have \`Get(int id1, int id2)\`. In general, don't add an abstraction until you have a need for it.
Or better yet, replace `ValueTuple&lt;int, int&gt;` with a struct called `TeamSeasonKey` with the appropriate properties.
if your app isn’t that big you might consider having the business depend on the ORM (EF). It is a pragmatic approach and allows you to get a lot done quickly. Keep it simple!
NO to using `object`! Why would you want to lose strong-typing? I don't understand this fascination with creating generic abstractions for things that don't need to be abstracted. Can you show an example of a situation where `IRepository` is necessary?
If you absolutely must have a generic repository interface, this is the way to do it. But what advantage does this provide over just using the DbContext itself with FirstOrDefault(predicate)? Unit tests can use DbContext too, just use the in-memory provider.
All I have to say is that WebForms is always going to be the bottleneck, unless you migrate to MVC or something else.
Ok. Then make a class that encapsulates your Id’s and pass that in. You not locked to int’s only. Then in the implementation you decide what to use. 
Are you using EF? If so bear in mind that EF already implements repository and unit of work patterns. The main (only?) argument for abstracting on top of EF is to make it easier to switch ORMs, but IME that's not something that most projects are realistically going to do without major rewriting anyway.
Why I still recommend repositories with ORMs: https://www.infoq.com/articles/repository-advanced
EF needs a repository wrapper in my opinion. It leaks far too many implementation details to the caller. 
Nothing in that article recommends a base/generic `IRepository` that abstracts CRUD of an arbitrary collection. The term `IRepository` is not even mentioned in the article.
That tool can accept the collection of objects. It shouldn't depend on a repo or perform any querying of its own.
For example?
Determinism isn’t something just Microsoft is pushing, the entire software industry is doing it. Having fully deterministic builds provides a number of advantages for development including discovering if your build setup has errors (build twice, get different output, then u probably have a bug in the build) Here is the best resource I’m aware of that tracks deterministic builds at the industry level https://reproducible-builds.org/
OK.. but you're already using EF in your codebase. And then you add a repository wrapper around it. Now your devs have to know and use EF's API #and# implement your custom repo API? What's the benefit of wrapping it?
I don't think you are in a "best approach" situation if you are re-doing an old web forms again in web forms! So you were sent static files that represent a new design and need to built it out in web forms? Have you built web forms sites before? My first step would be to identify the biggest hurdles and try to figure out as much about them first rather than diving right in. For example, one of the issues that stands out right away to me is that your web forms controls might not output markup like you'll find in the static assets provided to you. 
I think that's what we're going to try doing actually. Simple and should cover our scenarios.
The reason you are running into the problems you describe is because this interface serves no useful purpose and does not describe the methods necessary for all your repos. May I suggest: public interface ICustomerRepository { Customer GetCustomerByID(int id); } public interface IOrderRepository { Order GetOrderByID(int id); } // etc...
I dont expect anyone to rely on anything. I just think that when asking for these kinde of things you should show that you tried something.
Thanks, a good read. If I understand this correctly, deterministic builds are geared more towards the security needs of between independent developers. Since we're both the producer and consumer of our components this is doesn't seem to be as much of a concern for us.
&gt; So some people just aren't allowed to write the EF code itself? To be fair, I don't trust myself to always get it right either. Especially for the basic CRUD operations where the mind wanders. But I do envy you. I'm in big-E enterprise development now so I have to use a lot of barely literate code monkeys. &gt; I don't see you recommending that... Agreed.
Agreed. Web API is the way to go in this situation.
Nothing. That's the power (and sometimes weakness) of `params`. Presumably, the `Get` implementation would throw an error when not given enough keys or keys of the correct type. OP presented a generic repository so I tried to give them a generic solution to the question they asked. I agree with a couple other users here that this approach is not as practical as it seems and getting a little more specific with the interfaces is probably a better approach.
There are more benefits than security. Deterministic builds are a big help in debugging. I should have the same binary output for a given code input - then my symbols will match, which means my source can be easily found during debugging, and then all my break points which I have saved for that version will be hit... etc. Getting the same binary output for a given source input is a big help in removing a lot of noise when improving the maintainability of your software.
So you ask others to trust your wrappers and home-rolled ORMs? You must be very sure of what you're doing. I would be very worried if anyone spoke like this in my work environment, whether it was my lead or my coworker.
IIRC Direct Show is deprecated so the answer would be no. Wikipedia says it is being replaced by Media Foundation. I don't work with video input myself so I don't have any library suggestions, sorry. 
ORMs already implement the repository pattern for you. There’s no need to wrap a repository in another repository...the only situation I could think of where it would maybe have some benefit is if your ORM doesn’t support another database that you 100% know you will transition to in the near future. And even then you’re not really saving *that* much time.
It's not like I'm preventing anyone from seeing/editing the wrappers. Rather, it demonstrates the patterns I want the junior devs to emulate. As for my own ORM, I primarily use it when I'm working solo on the backend and don't have the time to deal with EF's boilerplate. It has far better performance than EF and requires less LOC than EF or Dapper. But I will use EF if the client insists and is willing to pay for the extra dev cycles.
I'm investigating a similar situation for a client. I'm finishing up some work I performed for them, adding a new process to their internal portal that they've built over the years in Web Forms targeting ASP.NET 4. For my client, my chief suggestions are to try to start targeting .NET 4.7.2, or to at least start moving in that direction. With .NET 4.5 general model-binding and the **SelectMethod** and related attributes were added to various controls that will allow all of the CRUD logic to be moved out of the view and back into the code-behind. From there they can start looking for common logic and start pushing these pieces into their own layer (currently everything is one big project), starting the process of decoupling frontend and backend. In .NET 4.6 model-binding was upgraded to support async. I don't know that my client's app generates enough traffic to merit the work, but the option is there. Finally .NET 4.7.2 added support for Dependency Injection in Web Forms. This would synergize well with moving CRUD and business processes to their own layer, further decoupling backend and frontend. These are broad strokes, but hopefully provides enough to my client in a position that they can continue using Web Forms with a cleaner, more structured solution, or that it opens the door to start migrating the project to a newer stack.
&gt; NO to using object! That's what EF does. So what is it? No to objects, or no to wrapping DbSet&lt;T&gt; and/or DbContext? You can't have both. You're all over this thread arguing your point(s) but you're not even logically consistent. Sounds like you've also never had any scenarios where it's useful to intercept the IQueryable before materialization, or implement any other kind of cross-cutting logic on your entities beyond the couple of simple features EF provides, like soft delete. Screaming "NO IREPOSITORY EVER" all over is just as much cargo-cult programming as always implementing an IRepository&lt;T&gt; just because you've seen it a lot.
Use google big data instance processing. 
Did you actually read the articles? I ask because to make that argument you have to claim either * it's ok to allow those implementation details to leak into higher levels of the code * those features mentioned are not necessary
&gt; They said that was IPv6 format but I am wondering if it is just giving that because I am debugging Yes, or more correctly it is giving you that because the IP address you are connecting to the web app from is your localhost address, which in IPv6 is "::1". &gt; is there something else I can try? Yeah, hit your website from a different IP address, e.g. from a different machine on your network.
i think we’ve passed the *ake era :)
Thx a loz, at least that's an answer. The good people at stackoverflow just downvote the question, although I really can't tell why it shouldn't be a legitimate one. 
I'm used to the ease of debugging with Visual Studio on windows. Debugging a site running locally in docker toolbox felt like going back decades, lots of things to fiddle with and the only thing I was able to get working was debugging with VSCode following this example: https://github.com/Dispersia/Dotnet-Watch-Docker-Example Everything I had tried before finding that led me nowhere :S
Try looking at the machine.config, as the web.config gets layered on top of it. Does the _layout have the page validation turned off, it should look like `&lt;%@ Page ValidateRequest=”false” %&gt;` Also check to see if the current request context has the validation disabled explicitly
I read both articles. First off, they aren’t talking about abstract repositories, they’re talking about just the act of hiding an ORM behind a repository. I have hidden ORMs behind repositories before in previous projects, and I am pretty strongly against it now for most cases. Bulletpoint one is something I agree with. It’s ok to leak implementation details to something you think will most likely never change, if the cost of abstracting over it is high. And with repositories, it *is* high. That’s why you see a lot of people start by just wrapping with a normal repository, then by the 15th *GetItemByDateRangeAndSomeOtherField(...)* and then they go hey, why don’t I just use an abstract repository and use expressions for stuff like that? So then they do, and then they’ve basically just done their own weak reimplementation of that ORM. And what’s the benefit? How often do you plan on changing your ORM? If you don’t have it already planned, it’s a pre-optimization, plain and simple. Bulletpoint two I don’t really understand. Do you mean it’s not necessary to create helper functions for the ORM? Like for UPSERTs?
You can also download a cosmoDB emulator to run locally. However, I’m not sure if it’s possible to containerize that.
That won't work with IIS Express. I don't know about .net core's equivalent. 
As quentech said it's because you're localhost. Since you're debugging you're likely locked into localhost. If you publish the app and/or allow connections from other sources, it will give normal style IP addresses instead of that ::1
You'll probably have to look at the X-Forwarded-For header in the long-term and fall back to RemoteIpAddress when you'll run this behind a load balancer. If you're not running behind a managed load balancer in the cloud, you probably should be as managed load balancers such as ELB's provided by AWS provide extra protection along with WAF / Shield rather than exposing your application port 80/443 directly to the world.
Ive had this problem many times. I just change each entity so it has a single primary key... It might fail 2nf but it simplifies everything. Dump the interface, implement an abstract repository. Avoid a generic repository. Sorted.
The ForwardedHeaders middleware will take care of all of that. Op can continue using the same convention to get the remote ip address. 
The point of having a repository / service layer is to consolidate and encapsulate your business logic and protect your database from being the dumping ground of anyone who wants to toss their garbage in there. Used inside the service layer with an ORM like EF this pattern is completely unnecessary. Outside the service layer this pattern is best way possible to repeat your business logic everywhere in your presentation layer and leave your database exposed to all kinds of abuse. 
Invert control over the key selection to the caller. Provide a default key selector in a derived interface. 
The properties of the RemoteIpAddress will confirm it is IPv6
It isn't lying. Your browser is asking the OS to connect to your machine from your machine. The OS uses the fastest route from you to you which is the loopback adapter, and that is the IP Address of the loop back adapter.
It is normal to have it the way it is. The default template is leaving it up to you to decide how to take it from here. You can think of the controllers as part of the UI layer in a typical 3-tier architecture (UI, Domain, Data). Start simple and expand from in complexity as your requirements grow. Here are some additional thoughts you might consider: https://purple.pizza/how-to-organize-your-projects/ My usual starting point is to create a project for the data layer and another for the business logic. Doesn't really need to go much further than that until you start adding more complexity.
&gt; Can you show an example of a situation where IRepository is necessary? * data doesn't all come from a single source * some entities don't come from the database at all * caching Not needed but nice is attaching common queries via extension methods. It also allows tighter test doubles by restricting the surface area of what outside services can call. Now, if you want to argue that a CRUD interface is the wrong one, sure I can absolutely get behind that because not every entity can be deleted or updated or created. 
I completely agree that putting a specific entity collection behind a repository interface can be useful for all of your reasons above. I'm specifically arguing against the existence of a generic IRepository that all of your different repository classes would implement.
Can you point to which of my comments are inconsistent? My solitary point in this entire thread has been that a generic IRepository implemented across disparate entity collections is useless. My comment here about using `object` follows from the overall point. Forcing in an overly generic abstraction leads to bad design like losing the strong typing of keys/query parameters.
OP, this is the answer.
K Scott Allen has a recent series about structuring a repository on odetocode.com. He's generally brilliant.
Separate projects should only be created at deployment boundaries. Is there ever a scenario where your data layer gets deployed with a different assembly instead of the business layer? No? Then keep them in the same assembly. The biggest contributor to slow build times and solution load times is number of projects. Namespaces are sufficient for organization and layering.
EF uses object[] in it's API for multi-column PK's. You simultaneously say, don't use objects and don't lose type safety, but that's your starting point with EF. You say don't wrap EF with a generic repository, but that's exactly how you can add type safety and hide the non-type safe EF api's. You don't need an entity-specific repository interface or implementation for that, either, and if you're not already using entity-specific repository interfaces - perhaps you use commands and queries instead - you'd likely prefer a generic version.
He didn't ask how to have fast solution load times. He literally just created a brand new project from scratch. 
And you suggested adding two projects right off the bat, which is bad advice.
There's no need to use the object[] API, it's bad. Use strong typed where expressions. No need to hide them, just don't use them. What kind of client code needs to get IRepository&lt;Car&gt; instead of ICarRepository? I can't imagine such a situation. 
You strategically didn't paste the part where I said what I LIKE to do. Not what he MUST do. You've got your opinions, nothing wrong with that. There are tradeoffs. I'm offering a handful of ways to think about it. I don't think slow build times are at the top of the OPs list of concerns. To say that creating a second project is had advice is a bit much. 
It's not good advice. No need to seed new people with bad habits.
No, the existing CosmosDB emulator is Windows-only, and the Windows container they ship for it is monstrous. It's really not suitable for local development. As much as I may dislike using MongoDB locally (mismatching production), it's worked really well for me on a project I started last month.
Ok man, Scott Allen is gonna be so proud of you for defending his ideas.
I'd love to hear the consensus on this. The system we're developing has a ton of projects. The main reason is because the old application was absolutely monolithic but needed to be super customizable per customer leaving us with a whole mess of slightly different solutions. In the new system we're developing we have a ton of projects which allows us to make nuget packages for everything including our core libraries and only bring in the assemblies that we need for that client. Having the different projects should make managing dependency versions much simpler. We're also using ServiceFabric so each service is its own project.
There are native gdi plus implementations that you can ship to Linux/Mac.
I spent the last five months trying to convince them that source control is not optional and I will not deploy stored procedures they email me. Or attach to tickets. Or happen to be in the dev database. And no, I won't accept a "production ready" stored proc that reverences Customer_Test_TCK instead of Customer. My company has some truly talented people... working on other projects.
yes
Official from who? Is there a directory structure certifying authority? &gt; My controllers directory sits at the same level as bin and obj... is that normal? Shouldn't code be inside src or lib? Doing things a certain way simply because other people do them that way without regard for your particular situation is a recipe for cargo cult development. If you don't want your controllers directory at the same level as bin and obj then don't put them there. I don't think a controllers directory is necessary at all and simply create a folder per feature, all inside a src directory that sits at the project root. That reduces the number of places I need to look when I'm working on something. I rarely work on something that affects more than one feature. I frequently work on something that affects models, views, and a controller all related to the same feature. See the way that works? I identified a problem I had and found a solution. I didn't do what other people do just because they do it. That's silly.
Yes under the principal of security bin depth. 
It's not an account based system. It's specific credentials used for other services. I *have* to decrypt them.
I don't think you understand what I'm doing and I don't know why you're being a jerk about this. The username and password are being used for third party services that I have no control over. You pass a user name and password to the API. I can't pass an encrypted password.
Gotcha. BCrypt threw me off. That is a 1 way hash and sounds irrelevant now. It sounded like you were storing user credentials. This sounds just as bad. What kind of services are you talking to and why aren't they doing this in a secure way, like OAuth2 instead of having you send passwords?
If you are using Azure, you're looking for KeyVault.
Wow sorry they are on your case. You're right and this commenter does not understand your case.
There is really no way to keep this kind of credential secret from a determined user. You can use layers of obfuscation and indirection, but in the end, the plain text key can be retrieved. If you absolutely must keep the third-party credentials secret, you can build your own proxy service. Your app or user authenticates with your service and you forward their requests to the third party. This lets you reduce the surface area to only allowed actions as well as apply additional validation and throttling.
Yeah, OP had already solved their problem.
bin and obj are temporary folders that you probably just want to hide and forget about, if your IDE/editor doesn't hide them already. It's not ideal, but it's the way it is and most .NET developers just get used to ignoring them. They should never be checked in to source control. With that out of the way, you can organize things however you like. There is no official way. It's quite common to use a root src folder that contains all project in the solution. See for example the source repo for ASP.NET Core MVC itself: https://github.com/aspnet/Mvc If you're new to .NET you may also read up a bit on the concepts of `solutions` (`*.sln`) and `projects` (`*.csproj`) in the .NET world.
Absolutely none of that is true. Projects are built in parallel and unchanged projects aren't built at all, in a lot of circumstances, multiple projects will build **faster** than one monolith. Even with load time, visual studio does load on demand now so projects are faster there too. Beyond that, the reason you separate the data layer and the business layer is not organisation it's because there is or at least should be a layer between your data and your business and your presentation layers because they are not the same thing. If you need to scale out, these components will probably scale out at different rates, and if you need to change one of them, you need to be able to change it in isolation. That's what layered architecture is about, separate layers you can change independently. That's not to say you should create a project per file or anything, but keeping everything in one project because you think it'll make builds slow is just stupid. 
You can use the DPAPI to encrypt the strings without having to deal with encrypting the encryption keys themselves. It has limitations, but at least you wouldn't be storing anything in plain text.
Check out ORMLite as well, and do not ignore EF. It got a lot faster lately.
As far as I know, you can't scope things in namespaces the way you would do it in Java packages. For example, you implementing a class which should only be visible in the namespace, which is not possible and you would have to create a different assembly for it ("internal"). 
Best bet with stack overflow to avoid the flyby downvoters is to avoid subjective sounding questions eg “what is the best” with concrete ones “what is the most up to date Microsoft library for...”. Also add a paragraph break or two and use dry language. Tbh though, lately I feel like skipping SO altogether and asking questions here. 
David Fowler has a [gist with a recommended layout](https://gist.github.com/davidfowl/ed7564297c61fe9ab814#file-dotnetlayout-md).
Can you expand on why multiple projects contribute to slow build times? With a single project if you make any change you have to rebuild everything. With multiple projects only the projects effected get built, which speeds up build times. If you are doing a 'build all' then projects can be built in parallel, which speeds up build times. We use multiple projects to separate domains - spaghetti code soon becomes clear when the project references become a mess.
Here is a link to a question I wrote ages ago, might help getting started on what the code looks like in .net https://codereview.stackexchange.com/questions/136144/h-264-image-encoding-using-media-foundation-net At the time media foundation was the way to go but didn’t have apis in .net so I had to use media foundation.net library. With UWP maybe there is something new. I never advanced the code in my SO question because we switched back to using opencv to encode. 
You're right, it is little more than raw SQL, but it IS type-safe, that's the thing it provides, it's basically a very thin layer on top of ADO.NET public class Dog { public int? Age { get; set; } public Guid Id { get; set; } public string Name { get; set; } public float? Weight { get; set; } public int IgnoredProperty { get { return 1; } } } var guid = Guid.NewGuid(); var dog = connection.Query&lt;Dog&gt;("select Age = @Age, Id = @Id", new { Age = (int?)null, Id = guid }); Assert.Equal(1,dog.Count()); Assert.Null(dog.First().Age); Assert.Equal(guid, dog.First().Id); [https://github.com/StackExchange/Dapper](https://github.com/StackExchange/Dapper) People often cite the performance as the main aspect, over Entity Framework, which is true, but on the other hand people call EF oh-so slow, which is often false - from what I can tell it's that people write absolutely horrendous Entity Framework queries, forget to turn features on or off depending on the query, or their graph itself is so tightly coupled that almost the entire database is being scanned for very simple operations, graphing that Dapper isn't able to do, so of course it won't take it long a time to not do something.
I suspect it is popular because it if free and simple to use. LLBLGen is my favourite. It isn't free but is very powerful. It has a great designer, lots of chide generation features, good technical support. 
Recently had to replace EF Core for Dapper because of speed. It really hasn't.
&gt; people write absolutely horrendous Entity Framework queries, forget to turn features on or off depending on the query, or their graph itself is so tightly coupled that almost the entire database is being scanned for very simple operations Anything you'd recommend to read to get to know those 'features' and possible reasons for slow queries(besides bad DB structure ofc.)?
The queries aren't type safe just the mapping
Hmm. Can't really without making it a commercial. Read on at your own discretion: &gt;!Julie Lerman has some really good Entity Framework courses on Pluralsight.com where she really does highlight pitfalls.!&lt;
Alright, I think we're thinking the same thing. The `IRepository&lt;T&gt;` interface itself is too generic and ergo a pretty poor abstraction. But at the same time, I can see the advantage to having a consistent way of interacting with entity storage. Breaking the interface across its different actions might help it (eg retrieval, deletion, etc) but I'm not sure about that. 
I will describe my own reasons on why why I chose Dapper over EF (in a financial application): 1. I don't need db-agnostic ORM (if DB changes you still have to test everything related) 2. It is explicit, I know the exact SQL that is going to be executed 3. I don't need EF's concepts of repositories, unit of work, etc 4. DbContext is not thread-safe and it is easy to make a mess if you don't keep it in mind 5. Overall EF has too many blips and blops I don't need but you have to know them, because they can cause "wtf'-moments when you don't expect 6. I like to keep it simple and create complexity only when it is required (which is not so often)
.NET core uses appsettings.json instead of app.config. [https://blog.bitscry.com/2017/05/30/appsettings-json-in-net-core-console-app/](https://blog.bitscry.com/2017/05/30/appsettings-json-in-net-core-console-app/)
Big fan of ormlite. They have some wonderful tools that made it trivial to build kendo Grid backend support (filtering paging etc). The other orm OP might checkout is npoco. 
Having small projects should actually speed up build time. One they can be built in parallel and two you only have to rebuild projects you've changed. I get the feeling you haven't worked on many large projects.
Can you explain #3? Why don’t you need these standard design patterns?
Yeah, but why pay for SQL Server and use none of its features? User defined functions, stored procedures, common table expressions etc... are really useful. 
The documentation.
Putting queries in stored procedures and calling them with Dapper is my preferred method of using it. It's actually a lot easier than [ADO.NET](https://ADO.NET) when used that way and because it doesn't have the overhead of EF it's faster. EF provides a lot of additional benefits though. It's just a matter of knowing your tools and what they're good at. I have many old applications that I have to update for our newer systems. Almost all of them use [ADO.NET](https://ADO.NET), datatables, etc. and as I get the chance I move them over to dapper. Since most of what I'm doing is calling stored procs I don't need to pull in the EF beast and it's almost a no brainer to convert the [ADO.NET](https://ADO.NET) code that exists now to use POCOs generated via Dapper. In larger, newer apps I tend to use EF. EF tends to offer a lot more flexibility. 
When compared side-by-side with EF, Dapper tends to be faster. EF has a lot of overhead with having to track entities though. Dapper is a little harder to use in complex project though. There is a trade off and knowing which option suits the situation best is what's important. 
I prefer Dapper for simplicity. I know what's going on, and I don't get a lot of features I didn't know I was getting.
But ::1 _is_ a normal-style IP address...
&gt; EF has a lot of overhead with having to track entities This is exactly one of the features you should know about and know when to turn off with AsNoTracking() when you're only doing reads. &amp;#x200B;
You rarely _need_ a design pattern, they just come in handy a lot. Being a financial application, I'm guessing OP's application is mostly reads.
Yes, but here you get it in a simple one-liner mapping with a type objects returned, parameterized queries in ADO.NET are fine but tedious. I think even the dapper way is tedious as you have to specify it - whereas EF automatically figures out if your LINQ argument contains a captured variable and parameterizes it.
Yeah, but I usually want it to track entities if I'm using it. 
I think part of the issue is that because EF is so good at abstracting the data access layer, people that use it tend to not think about what it's really doing under the hood. It's easy to use EF poorly, and once you've painted yourself into a corner it's easier to rip it out and replace it with something that gives you full visibility than to learn the ins and outs of performance tuning for EF.
Official documentation: https://docs.microsoft.com/en-us/aspnet/core/fundamentals/configuration/?view=aspnetcore-2.1 It says ASP.Net Core, but it’s not specific (for the most part, it’s doing everything in a console app anyway), and has some great info about other providers you can use for your config. 
Yes, it can be easy to make a mistake here as the query parameters are not typed. Typically you'll put Dapper queries into a Repository class so your risk is constrained to only one place.
Because repository pattern is used to abstract away the usage of such libraries in order to not get dependant on 3rd party libraries and to be able to quickly switch implementations underneath. By using Entity's DbSet as repository, you make yourself dependant on certain framework. You suddenly put 3rd party ORM library into your business logic. Entity's repository pattern is created to make entity independant of DB used, but by using DbSets directly, you make yourself dependant on Entity Framework itself. It's kinda pointless then.
I use it because it's quick, easy to use since I'm proficient with SQL, and is simple from the start. EF always felt like I had to jump through extra hoops to do anything complex. The .Net world is full of frameworks and tools that are really complicated ways to make a job easy. Dapper (and other micro ORMs) are one of the few things that are just easy to use from the start.
If you follow command/query, then you can just turn off tracking for all queries! Makes reads faster and makes damn sure your queries don't modify anything, double whammy
Please don't ever spread business logic between code and the database. Especially triggers. Hot damn are they a pain. If you don't understand why people say not to do this; the main reason is because it makes a program/system a lot more difficult to understand, debug and test. 
Triggers suck. I understand not using any features but why pay for sql server? Use something cheaper.
Dapper is not ORM. 
It's a lot more dramatic a difference than that, or was when we first started using it. For us, any time EF needed to join about half a dozen tables, especially on an update, its performance got bad enough that queries could sometimes spike to ~2 minutes whereas the dapper version was just a couple seconds. And I absolutely will concede that in many cases that dev team did some stupid things with their usage of EF due to not really understanding it, and that a team where *all* the developers really understood SQL and EF well would probably not have seen that kind of performance gain, but... I don't think I've ever worked on such a team. Sometimes simpler is better just because your people are also simple.
How many events are you talking about? You may be overly complicating the situation for possible future growth. One option is to start simple, one database and shared tables to start, and migrate to multi DB in the future when performance becomes a problem. If that’s not an option, you’ll either need a copy of your entity classes per tenant if you use multiple tables or for multiple database you’ll need a factory that creates a dbcontext per request for the correct tenant.
For experienced SQL users EF means a lot of mental overhead for more complex queries. If I want to do queries that have a lot of HAVING conditions or stuff like NOT IN (subquery) you're basically hacking the LINQ syntax until it generates sane SQL statements. It's a leaky abstraction layer. Like your C code of an algorithm looks like an efficient solution but you need to completely rewrite it because the compiler turns the assembler output into a mess.
&gt; If you follow command/query What do you mean? 
Because they bring me more complexity over efficiency. This is purely subjective and depends on the situation. Sometimes these patters are very practical, for example when you have many changes in single database transaction, but don't want to expose transactions explicitly outside persistence layer. In case of repository pattern it's just my experience - it works only for simple schemas. Once the schema and queries become a little more complicated than simple CRUD, repositories become tightly coupled with each other and loose the point of separation. Just an observation of what was usually happening in my projects. 
This comment is worth gold. 
CQRS, where your read requests/queries are handles completely separately from any commands.
Correct answer here. Just wanted to add: What in specific is your problem? 
A very simple example, instead of writing this, returning the entire record only to use one value: `string name = context.Customers.FirstOrDefault(c =&gt;` `c.Id` `== id).Name;` Just select the name: `string name = context.Customers.Where(c =&gt;` `c.Id` `== id).Select(c =&gt; c.Name).FirstOrDefault();`
Thanks for the input. It turned out to be a facepalm moment... seems that MVC does *not* perform XSS validation when the body type is json... only on form data. Can't believe I've never run into that before.
We write a lot of raw SQL in EF because the LINQ interface isnt one to one with SQL. It also generates horrendous queries in some cases and outer joins in LINQ are a complete mess. 90% of our queries are LINQ, but in many cases we've had to fall back to SQL and it's not a code smell, it's a necessity. 
Give me a random team of six developers, and probably five will get anything that gives you the correct behavior, albiet with bad performance under volume, wrong. That's not ideal, but it is what it is. If I get a developer who understands that unnecessary full table scans is a bad thing they're easily in the top quarter of devs in terms of coding for SQL performance. And no, that isn't a high bar to clear. At some point it's less frustrating to provide a simpler tool instead of spending all day every day cleaning up other people's shit. 
Yeah sorry should have said CQRS. It's a design pattern where you seperate things which change a system (commands) from things which read the state of the system (queries). 
Because you have to pay for a database if you want to use one? I pay for Spotify but don't use auto-suggested playlists, am I doing it wrong? No, I'm using it the way I want to. Just because SQL server has a bunch of features doesn't mean you need to use them. Same with any price of technology...
That being said, System.Config is in Core now and you can use an app.config if you really want. But I'd stick to the JSON config.
I switched to postgres. Free, and way better performance in my case (I have a LOT of writes to my tables, and concurrent read/write is quite a lot faster in postgre). Yeah, it requires some getting used to, but in my case it was well worth it
Here's my main problem with EF (or at least EF Core): the first query a server makes, the models take awhile to instantiate and this makes the first query for every model slow, but the subsequent ones are much faster. This isn't usually a problem. When you are using a serverless architecture though, every query is the first query so this makes EF extremely expensive to cold start. AsNoTracking() has no effect and this makes EF essentially useless in a serverless architecture 
And that's where I think EF *is* a simple tool, and it's harder to maintain complicated queries as strings, that EF would otherwise generate for you. Just because it allows stupidity and tries its best doesn't meant you'll end up in a better situation by allowing handwritten SQL.
Triggers suck when they are causing data side effects, but are incredibly useful for other things, like bridging data changes to event storage / history, etc.
I simply find it frustrating that in code we tend to translate/transform over, and over and over and back again. So much wasted coding and CPU to 'transform' data into a format that 'works with your code'. The MVMMMVMVMMVM pattern. :( Instead of sharing the actual model/type. I feel like TypeScript saves us a bit of headache here.
It's not a matter of EF not being a CAPABLE ORM, clearly it is. But it is all those bells and whistles that causes performance issues, lazy loading issues, graph traversal issues, entity tracking issues, etc... its just a lot of things to always have to think about and get right. Doable, sure, but I guess I just hit a point where I wanted it all out of my way and went back to SQL and Dapper. I think part of it is "how much magic am I comfortable with". Yes you can learn what its doing and use it properly and blah, blah, blah, but I can do a lot MORE with SQL (CTEs, table functions and all kinds of other things, etc.), and sometimes I HAVE to because I'm working with an established DB, etc. But I know exactly what I'm getting with Dapper (plus noticeably better performance at scale and decent sized graphs). Those other features that seemed like nice things at first just ended up getting in my way over time. I also find that people who are SQL first and really know the languages tend to prefer something that lets them use those skills to their fullest, which EF won't, and Dapper by its nature will. Sometimes for good or ill.
Yea sorry something like that. That ugly crap 💩 we used to do in WebForms in 2001. 
Haha, man you're at it for way longer than I am! No idea what you used back then. Still, IDataReader is ugly... but fast.
I can write straight ADO.NET out of my head if I need something quick or not terribly involved. Entity Framework is my tool for anything more complicated. Would you recommend Dapper over ADO.NET?
If you truly don't mind mapping all your objects, I wouldn't
She is! She and Scott Hanselman explain things in a way that I get.