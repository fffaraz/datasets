Gotcha - thank you. I'll end up using PKCE flow. My question was still about if I am using .net core to host my angular app, if I can still run background processes via hangfire. I.e. this is not anything that runs in the angular app - these are C# services in the .net core app. Per the documentation, when you create an angular project template, the angular app is all the UI concerns while the .net core app is used for data access (optionally). Can I just offload my background process tasks into the .net core app that hosts the angular app? The docs state the following: The project template creates an ASP.NET Core app and an Angular app. The ASP.NET Core app is intended to be used for data access, authorization, and other server-side concerns. The Angular app, residing in the ClientApp subdirectory, is intended to be used for all UI concerns.
WebSocket compression for SignalR. Most web browser WebSocket implementations support compression, but SignalR does not. You can transform an uncompressed stream in to a compressed one.
I‚Äòm looking for help as well. Maybe you are interested in Docker: https://github.com/HofmeisterAn/dotnet-testcontainers.
If you are doing some mapping stuff, take a look at https://github.com/vivainio/FastExpressionKit for some hints/ideas
Oh that's actually a really good idea. Everything makes sense now
It sounds like you could use the .net core app hosting your angular app to take care of these hangfire tasks, but it may not be the optimal approach. You don't need a dotnet core app to host your angular application. There will be a way you can host the static files in Azure and get all the benefits of a cdn. High availability, edge caching etc. I'm more of an aws dev at the moment and the aws equivalent would be your angular app hosted in an s3 bucket with cloundfront acting as your edge server. The background tasks sound like a good fit for Azure functions. Simple serverless tasks that can be kicked off on a schedule or from events within azure and can be written in dotnet as well. This is probably more complicated but should be cheaper when compared to hosting a dotnet app.
IText7 has some licensing related issues if you want to use your software commercially.
That sounds like a good idea. Might be easier to boot to create a serverless function to do some background processing tasks. I'll most likely end up going down this approach.
&gt;And it should be something for which there is a clear need/gap Disagree strongly. Some of the most useful (not to mention fun!) projects I've done were things that either had no real world application or that already had several existing solutions.
OP clearly expressed an interest in contributing to the community/NuGet. A project with no real world application may be fun, but it doesn't help the community. And a project that already has several existing solutions and isn't very clearly an improvement on them (thereby filling a gap) is just extra noise for people searching NuGet to sift through. I stand by my statement.
I thought the point was learning. That looks like a misunderstanding on my part.
why don't you save the image on a server and save the path in the database rather than saving the image itself in the db
That's the original direction I was going but want to find the best way to allow the app to use Azure Storage when in Azure and the path on the server when not in Azure.
If you want to contribute to existing projects, you can [find C# libraries projects with +5 help-wanted issues here](https://github.com/search?l=C%23&amp;q=help-wanted-issues%3A%3E5+library&amp;type=Repositories)
You can learn and develop at the same time. I'm using " you" loosely here, since _you_ apparently cannot.
why, are you going to be saving in different locations or what? I'm not getting you, maybe because i don't know how azure storage works. can't you serve your files from azure storage even when not in azure?
Yes, different locations. Usually when people are invested in Azure, they want to make use of all the Azure services. When not in Azure, there needs to be a location storage option, especially if the app doesn't have access to outside services. You can link to Azure storage from a local app, but you may as well use all Azure services. Also for web apps, you don't usually run them in virtual machines but instead a web app service. Much cheaper that way. Then you also use Azure storage because you don't want to store files locally in Azure.
I'm attempting to port PdfClown to .NET Standard.
I‚Äôm doing this with one of my projects. You‚Äôve got the right idea. I have a single interface and depending on the hosting I am either using the Azure Blob Storage implementation on Startup or just the local file storage implementation. It just needs to return a Stream, the consuming service doesn‚Äôt care where it comes from.
Thank you. I figured that would be the best route. Thanks for confirming that I'm not alone on my thought.
my libs that somehow related to 'object mapping' and 'transformation': * https://github.com/nreco/data * https://github.com/nreco/lambdaparser
Qr code reader
Yikes. I think I've only ever written cancellation into an async task once in my life and even I know that it should be done via cancellation token.
Did you get anywhere with this? I've been trying to find a usable way to setup React with .NET Core for about a week now but everything I have read through seems quite outdated.
&gt;just use the full flexbox which supports things like sizing items to their natural size which Bootstrap did not seem to support I believe this is supported in bootstrap. "col-auto" will size the column to the width of its content where "col" will fill all remaining space. You can stack many of these on the same row as well. Bootstrap does also offer basic flexbox functionality such as "d-flex," "flex-column," "flex-grow-1," etc. The last classes there really don't save you any more effort than inline styling though.
It doenst really work with Blazor components and it never did. It doesnt suggest methods that can be used and are there. When you open the same project in VS without Resharper everything is working alright and all methods show up in code completion suggestions. Also it suggest that you have errors in code all time but when you switch to VS they are gone and everything is alright. And in other occasions the formating just remove your code sometimes when you press space or enter when using Razor pages. I tried to use it on Mac but I was really turned down by all this and on top of that debugging performance is just so bad compared to VS on Windows. Btw I have used Rider on Windows and Mac and debugging performance is just bad compared to VS.
I have used IronPdf once, for printing HTML To Pdf on the backend side. I was underwhelmed: broken layout, some css not handled properly. I ended using Puppeteer sharp in order to do print html to pdf (puppeteer is a headless chrome automation tool) Works really good.
You created an account just to post links to your twitter that clicks through to your website that links through to the humble partners to generate revenue for your partner account...
Link without having to follow a nest of links and no partner link at the end. https://www.humblebundle.com/books/microsoft-and-dot-net-books
I've also posed the question to StackOverflow as well: https://stackoverflow.com/questions/55678984/dllimport-native-dependency-from-nuget-package-not-working-on-net472-but-works
Last night I putzed around with Reflection to see what sort of information I could get on assemblies and their types. I know stuff like DotPeek already expose a lot of that information, but the meta-data loving nerd in me is always interested. I wound up extracting out a small library of common utilities. I think I'm going to go back over an AI Roguelike server project from last year and see what other helpers I can extract and just try to build a library that makes my own code much simpler via extension methods, etc. &amp;#x200B; Stuff that generally interests me - teaching / tutoring / mentoring, AI, gamedev, and project management (though I'm under a non-compete on project management work for awhile from coming off of 9 years in the industry).
I'm currently looking for the same for postgres. Have you taken a look at SchemaSpy. It's LGPL, which is more permissive than GPL to my knowledge.
Yeah I saw SchemaSpy. Unfortunately, my employer prohibits the use of GPL and its derivatives. SchemaCrawler is under LGPL too.
If you use a model/class for your query parameters (using the [FromQuery] attribute) you could then inherit from some base pagination class.
I'm going to give you the fish, but learning how to catch it. Use failed request tracing to resolve these kinds of issues.
It's really hard to help you without an exception message or something similar :D
https://www.hanselman.com/blog/HowToSetUpASPNETCore22HealthChecksWithBeatPulsesAspNetCoreDiagnosticsHealthChecks.aspx
The .NET Framework assembly binder doesn‚Äôt understand the ‚Äúruntimes/RID/native‚Äù nuget package setup. You need to have extra targets to copy over the native libraries when targeting framework.
That's an outdated library at this point. There's the more modern AppMetrics: [https://github.com/AppMetrics/AppMetrics](https://github.com/AppMetrics/AppMetrics) And there is the industry-wide language agnostic system OpenCensus: [https://opencensus.io/](https://opencensus.io/)
Very helpful, thank you
no appDomain and synchronization context either in .net core
For what's it worth dotnet core already has a template for angular with some minimal samples (counter &amp; fetching data) that you can get in console with `dotnet new angular` (or by clicking through menus in VS / Rider).
If you're familiar with Angular, the .net core template is a good start. I haven't used it to start a new project recently, but the only prior complaints were that it was outdated on the Angular side. That's super easy to fix, and then you're up to date. If you're not familiar with Angular, you might try just using the Angular CLI to do local development first. It's good to learn idiomatic Angular before you try to fit it into another ecosystem.
I've done 3 projects with dotnet api and angular front end. We didn't use any template for angular besides ng new. Angular code is a totally different project we edit in vs code. Are you all in on building a SPA?
This. Apart from fundamentals books, I find that most things don't even work by the time I pick them up because so much has changed. I find it easier to just frankenstein something together from the latest VS templates, documentation, StackOverflow, etc. Much quicker too without having to read pages and pages of bloat. It's amazing how many books are targeted at "intermediate" or "expert" level but still go into extreme detail on the most basic concepts as if we've never touched a keyboard before.
Your post has been removed. Self promotion posts are not allowed.
My guess as to why the Office API isn't lumped in with the rest of the .NET documentation is that it's an extension to the .NET framework dealing with one of Microsoft's other products, i.e. not a part of the "core" of the .NET framework. I'm just guessing on that one, I've never worked with the Office API itself and I'll admit when I first read "Visual Studio Tools for Office API" it sounded like something Visual Studio specific (which it very well could be, I honestly don't know as I've never worked with the Office API). Your best bet is probably to just Google how to do things with Office in .NET and find relevant Stack Overflow posts to point you in the right direction.
We use GemBox components at work, so naturally [GemBox.Pdf](https://www.gemboxsoftware.com/pdf).
Check out [RealWorld](https://github.com/gothinkster/realworld) example app on github, its asp.net backed paired with most popular frontend frameworks.
Whilst I found Azure B2C pretty easy and cheap in some scenarios, I was really surprised at just how restrictive it was. Customising the login screen was incredibly painful for example.
I love this. Re-usable UI in [asp.net](https://asp.net) is a bit of a holy grail for me. Shows how time flies though - seems like only a few weeks ago he was presenting the asp.net core 2.0 version at Build 2018. Razor components and Blazor would realy be a great modern web dev paradigm.
Razor Components are basically what Blazor is currently, right?
You can try Syncfusion [.NET Core PDF library](https://www.syncfusion.com/pdf-framework/net-core/pdf-library).
Checkout Syncfusion [HTML to PDF in C#](https://www.syncfusion.com/pdf-framework/net/html-to-pdf), it uses popular rendering engines such as Internet Explorer (IE), WebKit, and Blink (Google Chrome) and it is reliable, accurate, and high-performance .NET library. [C# HTML to PDF example](https://www.syncfusion.com/kb/9143/how-to-convert-html-to-pdf-in-c-and-vb-net)
Razor components is blazor running on the server
Syncfusion HTML to PDF converter is a [.NET Core library](https://www.syncfusion.com/pdf-framework/net/html-to-pdf) for converting web pages, SVG, MHTML, ASPX, partial web page and [HTML to PDF using C#](https://www.syncfusion.com/pdf-framework/net/html-to-pdf) with just 5 lines of code. [Convert HTML to PDF in Azure using .NET Core](https://www.syncfusion.com/kb/9779/how-to-convert-html-to-pdf-in-azure-using-net-core) [Convert HTML to PDF using ASP.NET Linux](https://www.syncfusion.com/kb/8481/how-to-convert-html-to-pdf-in-asp-net-core-linux)
Syncfusion [.NET PDF library](https://www.syncfusion.com/pdf-framework/net) supports converting PDF to image. Refer following KB for converting PDF to image. [Convert PDF to image](https://www.syncfusion.com/kb/9112/how-to-convert-pdf-to-png)
They even renamed it back to server side Blazor a few days ago https://github.com/aspnet/AspNetCore/issues/8931
I loved Resharper first, but i kicked it. Waiting 20+ seconds per project is really not worth it. &amp;#x200B; I try it regularly with every major update of VS, but so far, the performance is even going down. &amp;#x200B; Given that those performance issues persist for years now, it seems the JetBrains team does not care either.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/latexandloaf] [Introducing Razor Components in ASP.NET Core 3.0 - Daniel Roth](https://www.reddit.com/r/LatexAndLoaf/comments/bddtw8/introducing_razor_components_in_aspnet_core_30/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
I'm kind of glad they did this before it shipped, it was a little confusing to the uninitiated. It reminds me of [linus' recent rant](https://www.youtube.com/watch?v=gShRBsahzXg) on USB naming conventions but not quite as bad :P
So, I'm trying to publish files to a folder. I changed ASPNETCORE\_ENVIRONMENT in launchSettings.json. I also verified the change in the solution properties that the variable is set to 'Production', but I'm still getting this error message. Please help. Thanks
Is this on-prem? If so, I'd check the events to see what the actual error is.
That's the standard Error.cshtml page. What it's saying is that you are NOT in Development mode, and that if you were in Development mode, you would get a more detailed message.
You are getting that page **because** you have it set to Production. Did you even read the message? You have an internal error in your application, but the error details are hidden because you're in the production environment. A production environment should not share details about internal errors. You can get the details by switching to development mode, but that should not be set in production environments.
I use [my own](https://github.com/JaimeStill/PatternsAndPractices) modified template based on `dotnet new angular`. It uses Angular Material rather than Bootstrap and has a lot of additions for the environment I work in, but this shows that you can build your own `dotnet new` templates.
Good coverage of the topic, I'm glad that they put event handlers near the top because I find those to be the most insidious. I see it a lot in WPF/MVVM systems and naive implementations of Domain Event patterns. All the various reference issues involved with closures ("anonymous methods" in the article, though not all anonymous methods are problematic closures) are also a huge problem, one that the JS people have been fighting with for years. Other areas of concern might be the Singleton pattern, various configurations of registrations in DI containers, faulty error-handling that causes cleanup routines to be skipped, etc.
&gt; Many share the opinion that managed memory leaks are not memory leaks at all since they are still referenced and theoretically can be de-allocated. It‚Äôs a matter of definition and my point of view is that they are indeed memory leaks. They hold memory that can‚Äôt be allocated for another instance and will eventually cause an out-of-memory exception. For this article, I will address both managed memory leaks and unmanaged memory leaks as, well, memory leaks. He should not have needed to say that, but I'm glad he did. Thinking that there is only one kind of memory leak is just a step away from not being able to understand why your program is getting OOM exceptions.
there is a /div in excess...and if removing it does not solve the problem try adding this after the form &lt;div asp-validation-summary="ModelOnly" class="text-danger"&gt;&lt;/div&gt;
Swap to dev environment, then deploy the app and your message will be more detailed.
I feel like that a recipe for issues. Sometimes it is important to learn some of the concepts of the framework from a book.
It certainly isn't without its drawbacks as you say, I can happily admit that. The issue is finding a book on the current major version of the Framework in question. Personally I find it very difficult to find anything up-to-date when trying to learn new tech.
I think it might be clearer to say that Blazor is Razor Components running in the browser :)
or, more simply \`Marshal.AllocHGlobal\`
I thought this was a great read.
If you really think about it, by the definition that "reference == no leak", native memory leaks aren't actually leaks either since you can make a pointer that references them whenever you want. You might have to scan the entirety of the memory space to find the thing you're looking for, but you can do it if you want to.
My only problem is that he then goes on to list a few of his items which are clearly patterns which just happen to use a lot of memory. Not memory leaks. I think I would define a memory leak as a developer attempting to free an object but failing to do so, regardless of the reason. So if an event subscription keeps an object around after everything else doesn't, probably a memory leak. Forget to Dispose an object there are no references to, memory leak (though TECHNICALLY not since GC cleans it up eventually). Forget to free unmanaged memory, memory leak for real. Create a cache or master list of objects that you never free, probably not a memory leak, usually that is done on purpose. That said, a developer will usually be looking for any way to bring down memory usage, not just leaks, so the full list is still useful for that for sure.
Yeah back when all we had was unmanaged, a leak was just that, memory you didn't know you still owned and had no way of referencing. But in .NET you're very rarely going to be working with unmanaged memory now. So I think it is fine to relax the definition to memory you don't know you still owned, even if you have a reference to it. An easy example is when internal classes you didn't write have references (that you forgot they make or you didn't know about in the first place) to your objects you purged from the classes you did write. Event subscriptions are a good example.
launchSettings.json only applies to testing from VS and won't apply to publishes. There are a few different ways, this post has a few: [https://stackoverflow.com/questions/41546943/how-to-set-aspnetcore-environment-to-be-considered-for-publishing-an-asp-net-cor](https://stackoverflow.com/questions/41546943/how-to-set-aspnetcore-environment-to-be-considered-for-publishing-an-asp-net-cor) You can also modify web.config as yet another method to set an environment (those methods in there may result in a modified web.config, I'm not sure).
B(rowser)L(??)(R)azor!
I really doubt there are any bindings. You'd have to roll your own with p/invoke.
Well, WHERE statement does not order any field, it's like SQL-WHERE. Linq-EF queries are tricky, i suggest you try Sql Server Profiler to check compilation query result. B linq query si redundant.
&gt;Linq-EF queries are tricky, i suggest you try Sql Server Profiler to check compilation query result. Yes, that's what I was thinking about, maybe EF does some kind of magic under the hood that enhance this query performance.
What is the idea behind ordering by your filters first? A) and B) are going to create dataset in completely different order. You should use orderby only for sorting data in desired order.
Trying to keep things clear for future readers, i will copy/paste/tweak a post of mine from a while ago... (Yes, i realize this is 12h old...) https://github.com/aspnet/AspNetCore/issues/8931#issuecomment-478151056 &gt; **We will still refer to the *component model* as Razor components** (i.e. a .razor file will still be a Razor component), but when talking about the application model we are finding it very cumbersome to have different names - Daniel Roth From Dan's OP in that thread: &gt; To address this confusion we are going to switch back to referring to the ***application model*** as **Blazor** with different **hosting models.** --- Blazor renders Razor Components, be it client- or server-side. Razor Components will not be unique to the Blazor projects, they will be usable in Razor Pages and MVC as well. (This came out of Dan Roth's mouth as well, i can find a link if need be...)
see https://www.reddit.com/r/dotnet/comments/bdbu2u/introducing_razor_components_in_aspnet_core_30/ekyxkuq/
For DBAs EF is sql hardcoded. EF compile your dotnet expression into sql. There is no guarantee your EF Query is optimized, in complex escenarios you should check EF queries. Multiple join queries should be put on stored procedures. EF is great but is not perfect.
The first thing I was asked to do at my first job was figure out why X program was leaking memory. It caused a lot of arguing in the office when I reported back that we were simply caching objects to the wrong collection because of a copy/paste bug. Half the office thought it was a memory leak, the other half insisted it wasn't but didn't have a good name for it.
&gt; "Uh so first we have to define our use of 'immutable' here". I think what would be necessary here is an antonym to side effects But "immutable" IS the opposite of "side effects". In this and many other languages, when you talk about immutable classes or immutable lists, the expectation is that a reference to it will have its data frozen, and adding an item or changing a value returns a new instance with the changes.
I recently used the Angular template. The only downside to it is that the Angular app is outdated, but you can simply delete that app and create a new app with the ng CLI. I did it this way because I would prefer to have the .NET code and the NG app integrated in the same repository, but the NG application can stand alone as well. I don't see myself moving away from .NET, so I even send a config JSON object from .NET to the NG side.
&gt;hidden i m looking for reference application SPA with NOSQL or SQL DB
It's not free but I've used it with good results in the past: \[LogicNP CryptoLicensing For .Net\]( [http://www.ssware.com/cryptolicensing/downloadnet.htm](http://www.ssware.com/cryptolicensing/downloadnet.htm) )
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/latexandloaf] [8 Ways You can Cause Memory Leaks in .NET](https://www.reddit.com/r/LatexAndLoaf/comments/bdnljy/8_ways_you_can_cause_memory_leaks_in_net/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
Your Angular app can live without ever knowing about your background Hangfire tasks. Any API keys used for background tasks should not be exposed to the Angular app unless you're exposing then somehow. If this is a .net core app, you can add in Key Vault to your builder, and any API keys stored in Key Vault will be available via your IConfiguration object. The built in DI can pass the key vault info directly into whatever you need it to, and Angular is none the wiser.
ez-ee-kay.
Actually it won't create different order. Since only entitites with Name = "foo" is included in the result set the OrderBy(x =&gt; [x.Name](https://x.Name)) will do nothing.
7 is incorrect. The dispose pattern is incorrect and does not guard against cases where Dispose is not called. It should have a ~Finalizer/Dispose/Dispose(bool disposing) pattern. You call Dispose(bool disposing) from the finalizer and Dispose method. Then you release the memory in Dispose. If somehow Dispose was not called, eventually the finalizer will do it.
Thought this was the case. Thanks!
 [https://exceptionnotfound.net/entity-framework-and-wcf-mapping-entities-to-dtos-with-automapper/](https://exceptionnotfound.net/entity-framework-and-wcf-mapping-entities-to-dtos-with-automapper/) ? See this
Good luck. I'm dealing with a similar issue, but we're taking a different route by breaking our background processing tasks into timed Azure Functions/Queue messages.
I've used both log4net and Serilog for years. This post is a summary of my experiences with both. Let me know what you think.
Read a bit further. Item 8 is about the dispose pattern
If you want to sort the result using a single column , then A is sufficient. If you want to sort using multiple columns, then you use B. In example B, the result will be first be sorted by the Name. Then sort the result by the Date (only those with the same Name) B actually translates to this query SELECT * FROM People where Name = 'Foo' ORDER BY Name, Date
Serilog.
Since you did not include your automapper config where you setup the mapping rules, here's my assumptions: &amp;#x200B; You have a mapping rule for OrderResource and Order You have a mapping rule for OrderItemResource and OrderItem &amp;#x200B; Solution (possible): You need to explicitly add in the mapping rule for OrderResource and Order that you want to map OrderItemResource to OrderItem &amp;#x200B; Something like this: CreateMap&lt;OrderResource , Order &gt;() .ForMember(dest =&gt; dest.OrderItem , opt =&gt; opt.MapFrom(src =&gt; src.OrderItemResource ))
They shouldn't create different datasets. He's filtering for name already, so every row has the same name. The sorting algorithms should be stable, so the order of rows is not changed.
?
The winner of the two.
Whenever I encounter that kind of issue, I always check first if I am actually hitting the correct method in my controller. Next is I inspect my ModelState if the error is actually there. Just like in the screenshot below. &amp;#x200B; If the error actually exist and is not showing up in my view, I then I inspect element the browser to see if the span element have the error. &amp;#x200B; If at this point I still don't see it, I go to stackoverflow for possible reason and solution.
Amazing about time!
In my company we use xml based configuration to enable deployment-specific logging configurations. Works without issues. We also moved from log4net to serilog because of structured logging. If you habe the infrastructure this is killing the discussion. I‚Äòd propose however to always restrict yourself to the microsoft.logging.abstractions ILogger&lt;TContext&gt; interface via DI. Because then you can easily replace one logger by another.
Ah ok :) Agree (and the conclusion of the post too)
They could just make all the components dependencies so you only import the parts that relevant to your project
I usually use a mix of C#-based config and then some deployment specific variables in the config. Using ILogger is a good idea and something I have been advocating for in the past (just with CommonLogging since Microsoft.Extensions.Logging didn't exist back then). In real life, I haven't replaced the logging framework more than one or two times. I believe that switching often involves so many changes (like going from text-based logging to structured), that you would want to rewrite large parts of the logging code anyway. But totally see your point and agree.
how about nlog vs serilog?
That is definitely a harder choice. Here you go, mate: [https://blog.elmah.io/serilog-vs-nlog/](https://blog.elmah.io/serilog-vs-nlog/)
Ah yes this the correct namespace. I was guessing while commuting to work üòÖ Yes you are right. Exchanging logging infrastructure is something that ideally isn‚Äòt done at all. Still I don‚Äòt like to see 3rd party implementations in my code if I have the choice to use abstractions.
I wish [elmah.io](https://elmah.io) had a free tier for open source, pet projects that developers do at home ...etc. I don't want to be paying $17 a month for a pet project. If they had that, and developers got a lot of value from it on their pet projects, then it is an easy sell to the businesses they work for.
There is definitely an option for that. Check out [https://elmah.io/sponsorship/opensource/](https://elmah.io/sponsorship/opensource/).
Ok, I think I'm going to be falling in love. Will report back if I manage to get this.
You might consider decoupling handlers from the service that know how to handle car types. These handlers would reside in the business layer, not the domain and would be able to trigger domain logic. A common library to do such decoupling is MediatR (https://github.com/jbogard/MediatR). The service code in that case would publish a command on the mediator, e.g. mediator.Publish(ICaraMaintenanceCommand). Handlers may indicate, whether they are responsible for this command (e.g. by inspecting the car type) or not. If no handler is responsible, you would throw an error, because you cannot handle this car type. This pattern plays pretty well with most Dependency Injections containers. If you use it, your service will be just a facade and you got rid of all the switch statements. Handling will be encapsulated per car type in a dedicated class that has access to infrastructure and domain.
I‚Äôm currently in the process of replacing a custom logging library by Serilog because of the structured logging. What I want in the end is to log things to Elasticsearch to being able to analyze later with Kibana. I thought on using two sinks: 1) File, logging as text (default formatter), so that in last case someone can easily read the logs directly in the server. 2) Elasticsearch, logging as JSON, for later analysis with Kibana. Does that sound as a good approach? Would anyone have other suggestions/recommendations? Thanks
That sounds like a great approach and what I'm using on [elmah.io](https://elmah.io) too. Logging to files for having something to look through quickly when on a server (could live without this really) and then logging everything to Elasticsearch using [Serilog.Sinks.ElasticSearch](https://www.nuget.org/packages/Serilog.Sinks.Elasticsearch/). In my case, I log all warnings, errors, and fatals to [elmah.io](https://elmah.io) as well, but that part depends on being a customer of that service of course.
We used to log4net, but switched to serilog, because we need structed logging for export logs into elastic. Also interesting feature of serilog is enrichers and log context properties. We using log properties for save and print trace id of request during processing that request(http, queues) and it very helpful.
Good article that will surely help a lot of people
\+1. I've not used MediatR, but I recommend decoupling through events/in process pubsub\\mediator pattern. It also helps with testing if you use a test framework. Because you can observe the events raised from the SUT you don't need to mess about with white box testing or mocking dependencies. &amp;#x200B; A nice example of that is the email service dependency problem. Your class (SUT, Subject Under Tets) is supposed to send an email on a certain condition. Traditionally, as the email service would have been injected into the SUT, you'd have to mock the email service and test the mock had its SendEmail method called. Nasty. &amp;#x200B; Now you create your SUT and test it raises the "SendEmail" event\\message. No mocking required, no checking internal state.
Good to hear that I'm not the only one digging Serilog :) We are using enrichers and context properties heavily too. Request info is a good example. We are also enriching this kind of messages with timing info, which allows for performance graphs in Kibana.
Yes, the result is the same in both cases. u/z0mbienjo the idea of B is helping the query to get the results faster, since order is applyed before the selection, with this we'll have a smaller dataset to apply the order with ThenBy with "Data" column.
Yes, thats the point that I'm trying to understand, the query that you posted above, shouldn't be more performatic, since the db apply order first, and them select? Or, will it depends on how my data is distributed?
Is log4net even worth serious consideration today? It doesn't support .Net Core (the last time I checked), and it's had no new feature development since 2012. Its feature set is totally outdated compared to a modern framework like NLog or SeriLog. I'm not saying you *can't* start a new project using it in 2019, but doing so is almost certainly a mistake IMO.
I would never consider log4net for a new project. I'm not saying that it's a bad framework and it has served me well for a decade. But as you mention, both NLog and Serilog are way better alternatives. Unfortunately, there are a lot of devs out there, that doesn't really catch up on new frameworks and just use what they have always used. &amp;#x200B; Just as info, log4net does support .NET Core.
Right now we using only File sync for logging and filebeat for sending data to elastic from log files. We refused from elastic sync near 2 years ago, because we had some suspicions about perfomance of this sync. But i didn't remember details =( Probably it s not actual today . As a variant, you also can use scheme with File sync + filebeat. imho it makes log configuration more simple and flexible. But you should understand, that logs inside log files will be in json format(it is not very comfortable for manual reading).
We also measure request timings, but do it using wrappers on input points. After each request we write 1 detailed message about request, that contains fields like event name, execution time, trace id, processing status and others. After we using this messages for monitoring rps, average exectuion time, erros count. And we can see all logs for each message using trace id, if it need for problem analysis. And remark: trace id is constant for all request processing througth several microservices. So using trace id we can see kibana all logs in all microservices about this event. Sorry for my bad English. I understand, that is really hard to read my messages.
Log4net is still a very robust mature and stable logging framework. If the choice is log4net or roll your own log4net wins every time. However with that said, in actual usage through out your code, the differences are extremely minimal. Both have log.level methods and can be injected via ioc. Log4net can sort of do structured logging by outputting valid json as the log message through formatting but it's a slight pain and a bit of a hack. Overall if I see a project (even a new one) choose log4net I'm not going to say they made the wrong choice. It's a lot like Ali v Fraiser both good and the top of the pile but one is better in given situations
If I understand correctly everything worked until you added 'Project' to 'OrderItem'? It worked when you had 'Project' in 'UserProjectSettings' but not in 'OrderItem'? If so, are you referencing the same 'Project'-entity? Did a using statement mess things up?
I think not. They are on the same namespace so 'using' will not be used in this case.
The error message describes this issue pretty well. I'm not pro at db providers, but i'm unaware of the type "Project". What db provider are you using, and if they do not support that type, i'm not sure this will work, unless you place the \[Not Mapped \] attribute above the property in which you will not receive any data for it,
The error message does not. 'Project' is a known entity and even has its own DbSet on the DbContext object. Strangely enough, I have another entity called 'User' and that works in 3 different entities.
&gt; If the choice is log4net or roll your own, log4net wins every time. Sure, but you *aren't* stuck with that choice. There are multiple mature alternatives available.
OrderBy should be last in general. I am not sure if it matters in EF, depends on what SQL it generates. But in general you would want to put OrderBy (and ThenBy) last, since, outside of an SQL context, it has to run a sort function on the entire enumeration. If you use .Where calls first to cut down the enumeration size, it should sort the results faster.
Then merge those points or use a different example.
The OrderBy in B will do nothing since there is only one Name. Thus order will remain unchanged. These will have the same results, but B will waste a little bit of time doing nothing. I recommend going with A. However if you are trying to do things programmatically, and as a result occasionally you do a useless sort like in B, there's no harm done, unless you are working with huge data sets. If you are seeing performance issues you might want to come back and try optimizing things.
People who are saying they wouldn't choose log4 net for new projects, can you elaborate why? We're starting a new project, and another team creates a boilerplate project for us - which includes log4net. I don't have strong arguments for serilog, so I left it at that, but if serilog is definitely a way to go we can discuss it - I just need to have good arguments. I get the structured logging, which can be hacked by JSONning the arguments (a bit hacky, yes, but not that hard). Is there anything else?
Does anyone use Trace/TraceSource? What do you think about them? Is it worth it to setup a more complex logging framework for small projects?
&gt;The property 'OrderItem.OrderProject' is of type 'Project' which is not supported by current database provide I think your FK cannot be of type project. I'm pretty sure a key can only contain primitive types.
EF should be able to create an int FK called ProjectId so that is not the concern. My other entities works as expected excepts this one. My only problem is that the migration tool does not like my mapping so it returns an error when using the 'add-migration' command.
 [https://github.com/aspnet/EntityFrameworkCore/issues/9817](https://github.com/aspnet/EntityFrameworkCore/issues/9817) the last three comments, should point you in the right direction.
just found this gem on github. easy to use and elegantly done library for using JWT for authentication in aspnetcore apps.
instead of (Project) Project \[FK (ProjectId)\] try (int) Project \[FK (ProjectId)\] &amp;#x200B; Do you need the enitre project entity in the OrderItem entity? If you have your FK set up, that should be enough to index off of something.
That's throwing complexity into the product.
What's up with the sound effects
is the site down for anyone else?
https://github.com/serilog/serilog-settings-configuration
The website's margins are super large which is screwing with the code formatting.
&gt; Now let's see the results: &gt; [Image points to HTTP 403 Forbidden] Not exactly an impressive benchmark. :P
Today I learned that Elmah is still going! We switched to Serilog from log4net. It‚Äôs so much easier to work with and I really wish many big frameworks weren‚Äôt still reliant on log4net. I wouldn‚Äôt consider log4net on a project now.
That sounds like a great approach and what I'm using on [elmah.io](https://elmah.io/) too. Logging to files for having something to look through quickly when on a server (could live without this really) and then logging everything to Elasticsearch using [Serilog.Sinks.ElasticSearch](https://www.nuget.org/packages/Serilog.Sinks.Elasticsearch/). In my case, I log all warnings, errors, and fatals to [elmah.io](https://elmah.io/) as well, but that part depends on being a customer of that service of course.
I have been using the Elasticsearch sink for at least 3-4 years and it is running smoothly.
I think that the post actually outlines some of the many benefits of Serilog. It probably also depends on a lot of other factors as well. If someone within is creating a boilerplate for you where log4net is included, it could be an issue of wanting to use the same logging framework on all projects in the organization. &amp;#x200B; As mentioned in the post, I wouldn't start a new project on anything else than Serilog, Microsoft.Extensions.Logging or NLog. But that's just my personal choice.
Trace is fine for simple things. But you don't have all of the benefits from traditional logging frameworks like different log levels (well you have info and error if I remember correctly), structured logging, target destinations and much more.
ELMAH is very much alive. Please notice that while we share name, [elmah.io](https://elmah.io) and ELMAH are two different options. More info here: [https://docs.elmah.io/elmah-and-elmah-io-differences/](https://docs.elmah.io/elmah-and-elmah-io-differences/)
I dont know about structured logging but TraceSource has 5 different levels and target destinations. I have used log4j which I think is kind of the same as log4net but I dont miss much in TraceSource from this experience
Log4net is used in new projects in 2019 because it works as intended and is extremely reliable, works in .net core, and is perfect for business/enterprise environments because of that. Why add features just for the hell of it? We don't always need a trendy new framework.
Sorry for the slow reply. I decided to keep it simple and just use the create-react-app and then add the build inside the client app location in ASP.Net Core rather than using the provided middleware because people have mentioned that create-react-app is going to be maintained in the future whereas microsoft said that once a template is created for react they tend to no longer support it. I think this is a more future proof method.
&gt; The only way to resolve the warning is by downgrading from 12.0.1 to 11.0.2. Um, have you not heard of assembly binding redirects? If this really was the only option then all non trivial applications would be impossible to deal with.
For #1, it's only going to jit what you actually call.
#3 is the most laughable. If it only does one thing, then why can't you write a test to verify that it does that one thing? And if you have the test, then you will catch any regressions.
I'm sorry, but these are completely unconvincing. I agree that taking unnecesary dependencies is a bad idea, but no one is adding dependencies for fun - they're all being used somewhere. If anything, rolling your own half assed implementation is likely to accumulate much more technical debt than a a well maintained third party solution. And the examples mentioned (JSON.net and EF) are absolutely classic examples of solved problems that mature libraries are an excellent fit for. There's no need to be messing with ADO when there are a whole bunch of mature ORMs and micro-ORMs for whatever your use case might be. And then there's the _extremely_ tenuous link to serverless applications. I can see the argument that these should do a single thing, but that doesn't mean this single thing isn't complicated or that you need to throw together your own JSON serialiser.
It‚Äôs just for entertainment üôÇ
do you even EFCORE bro?
Some guys just aren‚Äôt core, you know üòÇ
I does make the video more fun. I like it.
Not sure if you want to trust a security implementation of someone who stores their nuget API key in a public GitHub repo.
I think you‚Äôre going to have a hell of a time trying to map external users to AD roles. If the goal is to only manage users &amp; groups for the applications in one place while allowing external users access, than I would suggest not using AD accounts. Otherwise I would just use AD accounts for employees and use something else for external users. There is a clear separation between employees and external users so managing them separately really shouldn‚Äôt be an issue.
That's not actually the API key itself - [it has been encrypted first, so that it can only be read by the AppVeyor CI build](https://www.appveyor.com/docs/build-configuration/#secure-variables).
Oof
Why the blank class? Code Complete teaches us never to create empty classes. https://github.com/Xabaril/JWTSimpleServer/blob/master/src/JWTSimpleServer/GrantTypes/InvalidGrantType.cs I am also not sure what a "jwt server" is? Why not use a real OAuth2/OIDC server like [IdentityServer](https://github.com/IdentityServer/IdentityServer4) which is a battle tested server that can issue identity, access and refresh tokens and validate them.
Consider converting CarMaintenanceService into a base class for everything they hold in common, and then child CarFordMaintenanceService, CarToyotaMaintenanceService, etc. for everything specific.
Using IdentityServer at work right now. While it works, it is like a fucking black box. Documentation is terrible. But you are right, it is battle tested and does the job
Nice username
elmah.io is just a paid service for saving logs from elmah. The official elmah page is here: https://elmah.github.io/
Documentation isn't bad and the code is actually super easy to read and follow. I'm a contributor to the project and I also use it at work. The problem is that it requires a thorough understanding of the OAuth 2 and OIDC spec which is where the massive learning curve comes in. If you don't have that foundational knowledge IS4 doesn't make any sense.
We would be using asp identity for external accounts (maybe identityserver4 or similar), it's mostly the role management that they're not fond of. They want to keep roles in ad but don't understand that external accounts are not in ad.... I meant to specify that external accounts would be our customers that would be able to log in and see their portfolio info, documents, etc. If there were clear role separation between internal and external accounts it wouldn't be such a hard sell but they want to group certain roles in such a way that both an external user and an employee might be in the same role. I know I can set up roles that mirror AD roles in sql but the problem is managing the users in those roles. Maybe I just put my foot down and tell them it's not possible and if it's a company email address, they know to use AD and if it's not, they know to use whatever control panel we end up making for role management for external accounts.
You can set up multiple authentication methods for the app, and then use claims to map external memberships. I'd recommend using OAuth or OIDC for them all. Alternatively, you can use a federated identity provider, like Azure B2C or Auth0.
Yea I don‚Äôt see how you could manage AD roles for both internal &amp; external users without creating a custom interface to manage those AD roles where they can see both types of users at once. That sounds like a lot of work when you could just split the management. Maybe do something like this: Create Identity roles and provide functionality where a Identity role can be mapped to an AD security group. Then your application can just use the Identity roles for both types of users. This way internal users could be managed in AD and external users in your application while using the same roles between the two.
The flows are a pain in the ass
I don't think you want to have to go down the route of syncing AD groups via stored proc. It's more overhead to keep things in sync. &amp;#x200B; There is a github project by Mohammad Younes, [MixedAuth](https://github.com/MohammadYounes/OWIN-MixedAuth), that combines Windows and Forms authentication. This might be a good starting point for what you're trying to accomplish. &amp;#x200B; If you enable Windows Authentication at the IIS level, any domain connected machine should authenticate with no issue. If they are connecting from a non-domain machine (example: home machine that is using VPN to connect to the office), the NTLM authentication should fail, and they should see a prompt. Once they enter their domain credentials, they should be able to see the site.
first 35 minutes are general asp.net "community update" type material, ~25min - starts Blazor "community" material. some may have noticed my mild obsession with getting the blazor vs razor components terminology right... this post by Dan spells it out pretty well: https://github.com/aspnet/AspNetCore/issues/8931#issuecomment-478151056 hell, even the title of that issue can be confusing to newcomers, given his followup. anyhoo, Dan demos what i'm on about in my mini-rants here: https://www.youtube.com/watch?v=ap60h3eQE5Y&amp;t=57m44s So, Razor Components won't be limited to Blazor apps. (And then Jon goes on to use the term "blazor component"... smh... üôÑ) He also shows including Components in Razor Class Libraries to share between the other project types.
Client Credentials is pretty simple. You can honestly generate your own JWTs and validate them without any need for a server if you want to get that basic. The main reason for an identityserver4 is because you literally have an identity you care about.
Is this a shitty question? Why is it getting downvoted? Is this sub only for news or something? I can delete it I guess.
I really want to try out blazor at work. But getting some push back from management to wait until its a "proven" stack. I'm getting tired off angularJS at this point and would love to get back into solid C# for both client and server side code.
Great link, thanks. I'll definitely be reading through this. Yes we currently do use windows auth on a couple of external webs now, which works well and does prompt as you mention, I'm mostly just trying to figure out how to satisfy my superiors and their craze for wanting one point of config for roles/claims..... I'm going to try to explain that it isn't really feasible.
im sooo excited !!! its like im waiting for the next release of gta or something
AngularJS might be proven, but it has significant flaws and shortcomings compared to Angular / React / Vue which are all production ready. I think your decision makers just don't feel like supporting heterogeneous application setups or they dread considering alternatives or re-platforming...and they are hiding it behind risk aversion.
&gt;If you don't have that foundational knowledge IS4 doesn't make any sense. Any resources on getting that knowledge that you'd recommend in particular?
I think a more valuable comparison would be Dapper Vs SqlKata
What about optimizing sql queries? Will this generate the same ugly sql as EF?
No here you write the query by yourself
To be fair, Blazor is an experiment at this point. Razor Components (server-side Blazor) are in the [ASP.NET](https://ASP.NET) Core 3.0 preview, so that's for sure coming out. It might seem unfair, but the cost of maintaining something is often more than building it.
Lots of stuff going on here so the first thing you need to do is break down the problem into smaller pieces. &amp;#x200B; First problem is how to access the information in the database. Given the situation you have a described I would go with the [Database First approach as described in this article](https://www.tutorialspoint.com/entity_framework/entity_database_first_approach.htm). This will set up the connection between your application code and your data utilizing Entity Framework. You will effectively get a single Class per table in your database each with properties that line up with the fields in those tables. &amp;#x200B; Second problem is allowing users to interact with the information. Pick one of the tables and then create a view for it in the Razor page syntax which is mostly HTML controls. Put in an input textbox and add a button to insert. The [Getting Started with ASP.NET Razor pages and EF Core article](https://docs.microsoft.com/en-us/ef/core/get-started/aspnetcore/existing-db?toc=/aspnet/core/toc.json&amp;bc=/aspnet/core/breadcrumb/toc.json&amp;view=aspnetcore-2.2) does a pretty good job of explaining how to do that. &amp;#x200B; from here it is simply a matter of grinding it out across all the tables and figuring out how to craft each interaction with the user. That can take you some time to sort out and there is a lot involved that a tutorial can't teach you since it will be specific to your particular company. The thing you need to do is learn how to look at what the company is trying to accomplish and break it down into smaller bits that you can then work on to achieve the overall goal. A lot of the stuff out there covers very specific cases and not all of them are going to be applicable to what you are doing at the moment. &amp;#x200B; Final note, if you are super short on time, it may be worth looking into [PowerApps](https://powerapps.microsoft.com/en-us/). The tool allows you to pretty quickly create a Line of Business app where a user is simply viewing and interacting with data. Full disclosure, I've never used it so it may turn out to be more trouble than its worth. YMMV.
I'll try and find some blogs when I get to work but I learned the hard way by googling OIDC and OAuth 2 grant types and flows, I read a few blogs that seemed easy to understand, I also have pluralsight but I didn't use it so you may want to check there. Then there's the OIDC spec which seems huge but it's actually super readable. It basically details the order of the requests and responses to get tokens. Make sure you understand what a JWT is first. Also the difference between OAuth and OIDC can be confusing so just keep in mind OIDC is all about this concept of "identity".
scaffolding creates all razor pages necessary to access all tables. Last time I tried, user experience was very slow. I converted part of my website to ajax.
I saw EF, I was checking out this tutorial on creating the form with ADO.NET, how would the two differ? https://docs.microsoft.com/en-us/visualstudio/data-tools/create-a-simple-data-application-by-using-adonet?view=vs-2019
To be fair, assembly redirects in Azure functions are painful. Not so much of an issue if you're on V2 though.
See the ASP.NET Core tutorial on Microsoft Virtual Academy for a quick start.
As soon as something mentions Unity I completely disregard it.... &amp;#x200B; Why am I like this?
It is rather competitor to PostSharp, and since everything is done in compile time so no runtime footprint
Microsoft has implemented a new healthchecks library recently. You might look into that? [https://docs.microsoft.com/en-us/aspnet/core/host-and-deploy/health-checks?view=aspnetcore-2.2](https://docs.microsoft.com/en-us/aspnet/core/host-and-deploy/health-checks?view=aspnetcore-2.2) &amp;#x200B; They have readiness checks and health checks. Maybe you could roll your own custom checking logic as well?
Oh yeah, I think it AspectInjector seems pretty neat. But I just hate on Unity a ton because (in my opinion) it's an anti-pattern. I also know a lot of people that choose to use Unity and I wouldn't exactly call their code maintainable. &amp;#x200B; .Net Core ships with good-enough DI built in and would have suited most needs.
Completely agree :)
That would have been good to put in the article.
Nice comparison between EF and SqlKata, but the wrap-up was terrible (‚Äùwhich one would you choose, I would use SqlKata‚Äù) :-) The answer, according to everything else you wrote, should have been: ‚Äùthat depends on the use case‚Äù.
Agreed. I also agree that the rest are, for me, not great advice or not relevant specifically for Serverless.
Agreed. I also agree that the rest are, for me, not great advice or not relevant specifically for Serverless.
I would say there's a LOT of documentation, and it isn't all BAD really, but OAuth in general is a complicated subject manner and it does little to simplify the setup for people who aren't intimately familiar with it. Knowing most of that I could stumble through it (eventually) because I understood the underlying concepts, but for someone who doesn't, I understand the complaint. It IS the best option though, and is extremely well thought out. Its just a painful and complicated topic.
&gt; teaches us never Best practices are guidelines, not rules. All of them. It's easy to fall into that trap. They are tools to help guide you in making architectural decisions, but are NOT religious doctrine. In this case, I think his usage is perfectly acceptable, and is a simple solution to a polymorphic issue.
Thanks for the detailed writeup. Currently we're on AngularJS 1.7. I've been warning management that this is a bad idea and we should at least considering moving to Angular. But they believe the changes between AngularJS and Angular are too significant to make our small team learn and retool at the moment. I personally like the changes they made in Angular. Especially the component stuff. Management is way too risk averse around here to try something new. So hoping Blazor gets to a point where its not experimental and becomes an integral part of the .net ecosystem.
I decided to chime in to see if I can be of help as well. Firstly, I apologize if I sound like talking out of my ass and don't know anything, but from what I've seen, both Entity Framework and [ADO.NET](https://ADO.NET) accomplish same thing and are same performance-wise. However, EF helps you to reduce development time over [ADO.NET](https://ADO.NET) by it automatically auto-generates Model, DAL, and mapping code for you. I am not sure if this was the answer you were looking for and again apologize if it isn't.
Only works on .NET Core :(
Well, sort of. It works fine with net461 and even UWP, however yes it requires dotnet core to be installed on to your machine.
So far I have the health checks configured in the app. It's just not so transparent how long Kubernetes should wait to start doing health checks and how often to keep checking the health.
Ahh I see. I guess I'm not 100% qualified to answer that with kubernetes, but we use the health check libraries and our load balancer queries the endpoint to determine if an app server is working or not. It queries really quickly (multiple times per second maybe?) and i haven't noticed any real performance impact. &amp;#x200B; Sorry if that doesn't help you at all!
Echoing what labrz is saying, the primary difference is the amount of work needed to accomplish your end goal. Entity Framework is what is known as an Object Relational Mapper (aka an ORM). It allows you to interact with your database utilizing objects rather than direct SQL. So using the example article you listed, in order to insert into the Customer table you use the following code. private void btnCreateAccount_Click(object sender, EventArgs e) { if (IsCustomerNameValid()) { // Create the connection. using (SqlConnection connection = new SqlConnection(Properties.Settings.Default.connString)) { // Create a SqlCommand, and identify it as a stored procedure. using (SqlCommand sqlCommand = new SqlCommand("Sales.uspNewCustomer", connection)) { sqlCommand.CommandType = CommandType.StoredProcedure; // Add input parameter for the stored procedure and specify what to use as its value. sqlCommand.Parameters.Add(new SqlParameter("@CustomerName", SqlDbType.NVarChar, 40)); sqlCommand.Parameters["@CustomerName"].Value = txtCustomerName.Text; // Add the output parameter. sqlCommand.Parameters.Add(new SqlParameter("@CustomerID", SqlDbType.Int)); sqlCommand.Parameters["@CustomerID"].Direction = ParameterDirection.Output; try { connection.Open(); // Run the stored procedure. sqlCommand.ExecuteNonQuery(); // Customer ID is an IDENTITY value from the database. this.parsedCustomerID = (int)sqlCommand.Parameters["@CustomerID"].Value; // Put the Customer ID value into the read-only text box. this.txtCustomerID.Text = Convert.ToString(parsedCustomerID); } catch { MessageBox.Show("Customer ID was not returned. Account could not be created."); } finally { connection.Close(); } } } } } Notice how a SQL command object is being created and you are supplying all sorts of information to it? You'll be responsible for figuring that all out for every bit of data you want to Create, Retrieve, Update, or Delete in your applciation. &amp;#x200B; In contrast, Entity Framework allows for an abstraction layer on this so that all you need to do is fill in the Data Object (aka entity) and then call a method on it to perform the action. EF takes care of the SQL from there. So clipping from [Saving data in a connected scenario](https://www.entityframeworktutorial.net/crud-operation-in-connected-scenario-entity-framework.aspx) we see the following example for creating a new record in a "Student" table. &amp;#x200B; using (var context = new SchoolDBEntities()) { var std = new Student() { FirstName = "Bill", LastName = "Gates" }; context.Students.Add(std); context.SaveChanges(); } A lot less code involved here. All you did was set the property values and then call the Add() and SaveChanges() methods. EF took care of all the rest for you. This is what makes EF great for general purpose input/output data interactions. The flip side of this of course is that there are certain scenarios where EF can make your life completely miserable and it is up to you to realize when the tool isn't working for a specific scenario. For example, complicated Joins across tables where you need to supply the join criteria don't typically work well. In that case, there is nothing wrong with implementing that particular scenario via something like a Stored Procedure where you pass in the parameters so you have finer control over what is happening. Again, the important thing is to remember that while the tool will cover you for 90% of what you need to do, there is going to be that 10% where it just doesn't work well and you need to use a different tool. &amp;#x200B; Another way to think of it is the example of digging up a hole in your back yard. You could use a shovel to dig up everything ([ADO.Net](https://ADO.Net)) or you could use a [Backhoe](https://en.wikipedia.org/wiki/Backhoe) (EF). The Backhoe can get a lot of work done really fast, but you really don't want to use it too close to the foundation or any pipes since it could really do some damage if you're not extra careful/skilled. Those are cases where using a shovel is the more appropriate tool to get the job done. As I said before, a big part of your job is being able to recognize which tool is the most appropriate for what you are trying to accomplish at the given time.
**Backhoe** A backhoe ‚Äî also called rear actor or back actor ‚Äî is a type of excavating equipment, or digger, consisting of a digging bucket on the end of a two-part articulated arm. It is typically mounted on the back of a tractor or front loader, the latter forming a 'backhoe loader' (colloquially known as a "JCB" in Ireland and the UK). The section of the arm closest to the vehicle is known as the boom, while the section which carries the bucket is known as the dipper (or dipper-stick), both terms derived from steam shovels. The boom is generally attached to the vehicle through a pivot known as the king-post, which allows the arm to pivot left and right, usually through a total of 180 to 200 degrees. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/dotnet/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
I aggree with all this.
Do you intend to use mvc or a front end framework?
check out channel 9
I was thinking of mainly using a front end framework, potentially Bootstrap.
 [https://www.udemy.com/the-complete-aspnet-mvc-5-course/](https://www.udemy.com/the-complete-aspnet-mvc-5-course/)
I'm not a .NET person, but how would you write code that say, calls out to the database or network or other IO source without worrying that you'll block all underlying threads in your threadpool? The only other option I'm aware of is that you have to use an event driven library, with supporting drivers for your connection source, and have those wrapped around in a `Task`. What fibers give you is that you do not have to worry about your DB or other source providing async drivers to begin with. The runtime will take care of multiplexing requests for you.
He didnt mean a front-end framework like that. He meant Angular/vue/react.
Don't waste your time with MVC 5. Find tutorials using .NET Core 2.2
if you're looking for a complete well structured tutorial you're going to have to pay for it on sites like udemy or pluralsight. but if you're looking for free tutorials on youtube. you are going to have to specifically know the tech you're looking for and search for it, there are alot of good scattered tutorials on youtube just search for what you want. eg asp mvc tutorial, .net core and angular, bootstrap etc
middleware in node and c# work similarly but you wouldn't need to implement the middleware for checking jwt because it has already been implemented for you. you just need to add It in your startup.cs plus c# also has filters which works like middleware but in a different way
Doesn't the startup middlewares run on every route tho? I use some for just specific ones, thats why i call them from static methods in the routes itself when an user enters them
Ah, good question. Tasks do exactly what you describe for fibers. Again, I'm not a java person, so we'll probably have to meet in the middle, or a pub :) &amp;#x200B; There are two parts here. The first is Tasks and async-await. Tasks came first, they were the 4th or 5th iteration of how .NET did async stuff. Although it's worth remembering that Tasks are not necessarily asynchronous, You can do Task.FromResult(10) which just returns a complete task with the result "10" in it. Tasks were quite explicit to use. You had TaskFactory, or [Task.Run](https://Task.Run) or Task.Wait or Task.Result or ... it was still quite involved to make it work. &amp;#x200B; async await takes that code and removes a lot of the boilerplate. an async method doesn't ever need to use a thread. It can run entirely synchronously. I don't mind writing a blog about this as I was discussing it with a colleague at work today, but there are probably enough already :) The important take away is that a Task is not a thread, it's an object in its own right that may or may not do something asynchronously, with threads or without. &amp;#x200B; Think of a lambda expression. If I have let x = ()=&gt;Console.Writeline("Am I running?") (psuedocode), x is now a variable that you could execute x(). But it's not running. It's waiting for something to run it. &amp;#x200B; The interesting part is: "Which doesn't it exhaust the thread pool?". This is an excellent question. The answer is *deep breath* : &amp;#x200B; .NET/CLR sits on the OS and the OS sits on the hardware. The OS and the hardware have a bunch of mechanisms for alerting .NET (I'm using .NET and CLR and runtime interchangeably from here on in) that something outside of the process has done something. Remember we said the Task is just an object. It doesn't need to be doing anything. So the OS can notify the runtime that a network connection request has arrived. You don't need a thread waiting for that connection request, you can have a Task, which is not running, not consuming a thread be notified by the OS that something has happened. The framework code that handles a network connection uses the OS (Win32 on Windows) libraries to register interest in certain interrupts. &amp;#x200B; So now imagine we have a Task. The Task has said "Listen to the network and do x when a connection arrives. The Task is executed as 1) Ask the framework to notify it when a connection arrives. 2) Provide a continuation for framework to execute when it arrives. The framework will receive the interrupt, the interrupt will be enqueued and processed. So our Task doesn't have to be waiting on a thread. &amp;#x200B; Threads are a bit weird anyway. The ThreadPool can grow if there are a butt load of requests that it just can't handle, but generally the trick is not to put anything on a ThreadPool thread that will actually block that thread. In this way the Threadpool can queue requests for a thread and they should be handled quickly. &amp;#x200B; We can easily start threads outside of the threadpool if we have long running tasks. Timers provide a solution to scheduling code. Even Windows UIs use an event loop where a queue of inputs are processed one by one (bit like Node I guess) &amp;#x200B; I've written quite a bit, so I'll stop now, but I guess the **TL;DR** is: Tasks don't represent executing code, or threads. They represent a potential. The framework, OS and hardware provide mechanisms to notify the process that something has happened at which point a closure in the Task's state machine (generated by async-await) will be called by the runtime. So no thread is used until that point :) &amp;#x200B; I hope that helps. It gets complicated fast, and I only have a hazy grasp on some of the hardware level/OS level stuff.
You can get a 3 month pluralsight trial through Visual Studio Dev Essentials, they have an [ASP.NET Core learning path](https://www.pluralsight.com/paths/aspnet-core).
Like this? https://www.pluralsight.com/courses/aspnetcore-mvc-efcore-bootstrap-angular-web ASP.NET Core
yes it does. but the authentication middleware in startup will only apply to routes with [Authorize] filter. so for every route that you don't want to authenticate you should remove the authorize attribute filter.
Highly recommend Scott Allen‚Äôs courses on Pluralsight for this. They have a ten day free trial: [https://learn.pluralsight.com/programs/pluralsight-learn](https://learn.pluralsight.com/programs/pluralsight-learn) They also offer paths which contain several courses of varying difficulty, learning checks and skill IQ tests. In the beginning I thought it was expensive, then got into it and learned heaps. Currently my employer pays for the subscription but I would buy one myself anytime if they decided to stop paying it. Especially for .NET this is a great resource.
Would you mind elaborating on why someone shouldn't waste their time with MVC 5? Just telling someone to do or not do something without a good or valid reason is pointless. FYI, not trying to antagonize you, but instead I truly want to know your reasons.
The microsoft virtual academy has some nice (free) videos, althought I don't know how updated they are now.
Because it is a pretty massive overhaul of the framework. Why spend time working on learning parts of a framework that no longer exist. Especially if you dont need to maintain an existing code base. That said, if you don‚Äôt know anything about MVC, the principals of the pattern remain the same.
If it‚Äôs to get started and there is a great course on MVC 5 or even 4, I would definitely go for it. The basics are more or less the same: Controllers, models, views, razor, front end technologies, ... You can focus later on the differences between versions (like middle ware and build in dependency injection). Besides, there are companies that entirely use Microsoft systems and the .NET framework where I think it‚Äôs perfectly reasonable to use ASP.NET MVC instead of .NET Core. This makes things like working with the file system or authentication probably less complicated because there is no or at least less abstraction needed. Both have their advantages, e.g. MVC 4 is pretty mature and Core has for example it‚Äôs cross platform advantage. There is a lot more to say about it of course and all very interesting but as I said, if it‚Äôs for learning I wouldn‚Äôt get lost in these things immediately. It doesn‚Äôt matter when you are getting started if you ask me.
See how much more helpful a valid answer is explaining why is here? Especially if the OP is new to development in general.
&gt; to use to interact with a database. Full desktop unless you are going to put a web service between them.
Any particular reason? I'm genuinely curious about the why in this case.
You can apply middleware to particular routes using UseWhen() on the app builder. This will give you a predicate (to select by route fragment or whatever you want) and another app builder, which you can then add the middleware on. The request context will pass onto the next middleware in the pipeline, which might be MVC routing (for instance) if you‚Äôre using that.
UWP was designed for sandboxed apps, mostly stuff like phone games. Database access was an afterthought and not well supported. They just assumed that everything will be handled by a separate server. Also, until recently it didn't even have a data grid, which is a must have for most business apps.
Gotch, that makes sense. Thanks for the explanation.
I guess my next question would then be, do you have any recommendations of youtube videos I could watch to see some examples of how a full desktop app would be designed?
Thank you for the reply. I get the gist of what you're saying. I believe Java's [CompletableFuture](https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html) is similar to what you're describing if I'm not mistaken. &gt; The framework code that handles a network connection uses the OS (Win32 on Windows) libraries to register interest in certain interrupts and then do something when such an interrupt is received. I believe this is what I was referring to earlier. You're describing an event driven library with an event loop underneath. Would I be able to use plain ol' blocking API calls to a database for instance, wrap those calls in a Task, and have everything work out? Does .NET automatically know how to preempt, schedule, and notify any arbitrary Task that makes any arbitrary blocking call such that other waiting Tasks make progress? If so, then it's basically the same as fibers.
Definitely recommend Tim Corey: https://www.youtube.com/playlist?list=PLLWMQd6PeGY3t63w-8MMIjIyYS7MsFcCi He is primarily dedicated to .net and is very thorough!
Unity is just not very good as a DI container. I regret introducing it at my previous role.
100% agree. In my personal opinion there is no reason to implement unity anymore as there are better options (Microsoft DI or Autofac)
Not off hand, I learned from books.
Sign up for \[Visual Studio Dev Essentials\]([https://visualstudio.microsoft.com/dev-essentials/](https://visualstudio.microsoft.com/dev-essentials/)). It's free and comes with 3 free months of Pluralsight. You'll find plenty of good videos on there if that's how you prefer to learn
You're welcome. Don't use me as a source of truth, but I'm happy to give it a shot :) You're right really, but Windows (I believe Linux is the same, but I'm not confident enough to assert that) is fundamentally event driven. It's all queues of pending events. The ThreadPool is pretty good at scheduling. Task adds onto that with more. So, from my previous reply, Task.FromResult(10) returns a completed Task and that doesn't trigger any context switch. We have a port of Netty call DotNetty. I'm slightly envious of some of the Open Source stuff in the Java ecosystem, especially as I've written at least 2 socket servers :/ Can you drop me a link to anything about fibers with JDBC? It's a nightmare googling stuff from a tech you're not familiar with :/ It would be nice to see if the JVM expanding to include common use cases like JDBC for optimisation purposes. That's kind of cool. Honestly I know how CLR works, but I'm going to have to read things to make a proper comparison. Actually, drop me a few links, I've got time in the office tomorrow, I'm happy to dig in :)
Ditto. I found out about him a couple of weeks ago and provided the most clear explanation and examples on some hard concepts for me. Looking through his page he has lots of videos. Good free option.
They are retiring MVA courses at the end of this month, and will retire the entire site later this year. They redirect you to here now: [https://docs.microsoft.com/en-us/learn/](https://docs.microsoft.com/en-us/learn/) I have been following a learning path on [academy.microsoft.com](https://academy.microsoft.com) which links to required courses on [edx.org](https://edx.org) to complete the learning path and earn a certification. I think pluralsight will have better options specifically to .net courses than [edx.org](https://edx.org) based on what I saw from searching for courses a few months ago.
As someone who's done Ruby, PHP, .NET (ASP classic and .NET and .NET Core) -- I know *very little* about front-end frameworks and why someone would choose one of them over, say, a simple ASP.NET CORE MVC/Razor Pages. Might you recommend a book that could give a solid overview of why? Last book I bought talked about Knockout but, right now, I can't find *any* advantage of using, say, Vue instead of a simple MVC.
I like the underscore for private and protected fields. lower case vars are for locals. Upper case Stuff is properties.
This is why I‚Äôm used to. My recent showdown with stylecop made me rethink my whole life. Do you use stylecop?
can you elaborate? we use unity at work and im curious whats wrong with it
My experience is that it makes it a LOT harder to find dependencies if you're not diligent about where you declare them. &amp;#x200B; Junior devs have a tendency to just grab objects in the middle of giant classes and it becomes a pain to maintain that stuff. &amp;#x200B; Also by using Unity you are opting into using Unity and it's not easy to switch out DI Containers &amp;#x200B; &amp;#x200B; This guy explains it better than I can: [https://www.c-sharpcorner.com/article/why-service-locator-is-an-anti-pattern-for-dependency-injection/](https://www.c-sharpcorner.com/article/why-service-locator-is-an-anti-pattern-for-dependency-injection/) &amp;#x200B; Or this answer is good too: [https://stackoverflow.com/a/38202169/10581964](https://stackoverflow.com/a/38202169/10581964)
Oh I didn't know that, I learned a lot thanks to them, then pluralsight will the go to. Also I just remember, OP [u/GoldenSpiral20](https://www.reddit.com/user/GoldenSpiral20) Microsoft gives you 1 month trial on pluralsight when you create a Dev Essentials account. Take a look at that.
Google has one, I only heard about it today, so I can ask for the details tomorrow it you don't get an answer.
I use this.camelCase. I believe this is ms coding standard. Although their own code doesn't adhere to it all the time.
I prefer the underscore because it avoids the `this.privateField` nonsense in the constructor. Although if your ctor arguments are named ever so slightly differently from the private variable name, you wouldn't need `this.` in front. Which, I guess, is the real point of putting the underscore on the front. So you have sane constructor parameter names and identical (except for the underscore) private field names.
For a mock up I‚Äôd just use a static list. That will live as long as your application is running.
Modularity, nicer HTML - JS integration, minimization, can reuse API‚Äôs that exist for say an android app, better SEO, SPAs are much more responsive and not at risk if internet is spotty, etc. Angular, React, and Vue also all have features that you just can‚Äôt get anywhere else. Vue‚Äôs templating is fucking great, React‚Äôs virtual DOM, and angular coming as basically an entire server for the front end right out of the box.
This is old, bad advice. UWP runs on dotnet core and can use all of the dotnet core database tools. Additionally, the DataGrid is infinitely customizable (as is the one in WPF). If you intend to learn/use XAML then learning the UWP infrastructure will be a longer term skill set.
&gt; UWP runs on dotnet core Do you have any proof of that? I know UWP participates in the .NET Standard scheme, but that's not the same thing.
As of now a lot of 'solo fullstack' people practice a lot the combo Laravel + Vue.js. The reason is they are complementary, good, and you can enter production the fastest. (Especially if you know php, since Laravel is a framework of it). Vue.js requires some learning in html css javascript obviously. But is great. Long story short, Laravel makes the MC of MVC and vue is View. I think that for both, you'd be better off with online tutorials/videos.
I don't use 'this.' its not necessary and adds cruft. Apart from that it's 'how Resharper says'. Honestly \*it doesn't matter\* as long as everyone working on the source does it consistently got wild!
Well it all depends. Someone once explained it like this. If you want to make software that is kind like a web site like reddit, you don‚Äôt need a framework. But if you were trying to make software that mimics shrink wrapped software that you would install back in the day, a front end framework would help. Personally, I find it pretty damn challenging to implement Angular or View in a application being done by a one person or a small team. But if you work on a larger team and can have some people focus on the front end and others do the backend, it makes a lot more sense. Modern browsers refresh the entire screen so quickly, SPA frameworks don‚Äôt seem all that necessary anymore.
The API looks great. I'll try this over eastern to replace some ugly MediatR pipelining. Btw some of the docs links are a `404` in the repo.
Good night! didn't need to hear much more than the 40:50 mark - they are just about ready to remove the experimental label. Goodbye always having to write JS.
I fully recommend a book, "Pro [ASP.NET](https://ASP.NET) Core MVC 2" writting by Adam Freeman, it start from nothing to deep of framework Cheers!
Yes I'm already using a list..but I want to put seed data in it once, and have it stay in there throughout and that's not what it is happening.
I don't check this account often, so apologies for the late response. Thank you, it helps a lot!
I have to argue against "nicer html", since there are very very awful ways of doing html in front end frameworks as well. No framework can "make" you html nice. You need to know how html works, and if you know how to use the tool correctly, you can make clean html from any tool. Except PHP. PHP is just awful.
I've never heard of laravel, and after a quick google I found out why: it's PHP "for artisans". I've never heard of a single artisanal PHP coder, they've always moved off to other more structured frameworks, or develop add-ons for WordPress or some other older but insanely popular PHP site.
I have to disagree with your point that most solo full stack people use a PHP variant and a client-side framework.
Perhaps that's why I found such difficulty finding tools outside of Datatables.net to do active things. I'll need to research what these frameworks offer that I might be interested in. So far you've explained it the best.
You should be able to seed it fine in your Startup. Make sure you‚Äôre not new‚Äôing up your list multiple times. If you‚Äôre using DI, check the lifetime of the object you‚Äôre putting in.
https://msdn.microsoft.com/en-us/magazine/mt590967.aspx
That is way out of date and very misleading. For example, what they were calling .NET Core PCL never actually existed, but we did get .net Standard instead. I understand why it lead you to think that UWP is related to Core, but currently they are still completely different platforms.
Note that unlike UWP/XAML UI, WPF will be offered on .NET Core. Does this mean WPF will win over UWP? No, not necessarily. But it is still in the fight.
Right now I am newing multiple times that is the problem. In startup.cs? Make another method or something? Where would I create the list? If by DI you mean dependency injection, I'm not using it yet in this, and I'm not sure how to do that. Very new to core.
Coming from Python, the underscore is just second nature at this point.
&gt; You're right really, but Windows (I believe Linux is the same, but I'm not confident enough to assert that) is fundamentally event driven. True, from my understanding all these event driven libraries (Netty, Vertx, even nodejs) use the OS capabilities (poll/epoll/etc.) to work. The thing these libraries do all this work manually under the hood, and any library that wants to provide an async driver needs to make use of the aforementioned to provide async APIs. &gt; We have a port of Netty call DotNetty Interesting. I don't know how widely used it is, but does it fill some gap that Task doesn't provide? &gt; Can you drop me a link to anything about fibers with JDBC? Part of what I know is from reading comments by /u/pron98 on here, he leads project Loom, or by watching Java One talks (e.g. https://youtu.be/RFF2SfPMfpk?t=4593). &gt; It would be nice to see if the JVM expanding to include common use cases like JDBC for optimisation purposes. JDBC is just an example. As you see from the youtube link (where the demo is using an existing web framework), it doesn't matter what you're writing, the JVM will take care of multiplexing IO calls behind the scenes for you, JDBC or otherwise. Basically similar to what the golang runtime does. They do not need to write any specific DB or HTTP server code to be async, the runtime takes care of all that.
this is a few years out dated. its mvc5. I got hired as a company as a java dev and then I had to do .net projects. I followed this guide to get the basics. helped a lot. https://docs.microsoft.com/en-us/aspnet/mvc/overview/getting-started/getting-started-with-ef-using-mvc/creating-an-entity-framework-data-model-for-an-asp-net-mvc-application
The simplest way (and this isn‚Äôt a good implementation) is make a static class named something like InterviewDB with a static list inside. On the getter, instantiate the list with the seed data if it‚Äôs null. Because this is for an interview, it might be better to look into DI and injecting in your data to the controllers.
Came here to say this
I dislike the underscore for private fields. In practice if I don't know which variables are local or not my class is too big and I try to split it up.
Unfortunately, the trial has been reduced to 1 month now.
From: https://msdn.microsoft.com/en-us/magazine/mt590967.aspx As a .NET developer, you‚Äôll appreciate all that the UWP has to offer. UWP apps will run in ‚ÄúWindowed‚Äù mode on the huge number of desktops that have been, and will continue to be, upgraded to Windows 10. UWP apps will be able to reach all Windows 10 devices with one application package and one code base. In addition, UWP apps take advantage of the new Microsoft .NET Core Framework (explained in detail later in this article). Your .NET business logic can run on other platforms that support .NET Core, such as ASP.NET 5. __UWP apps deploy a small copy of the .NET Core with the app, so the app will always run against the .NET version you tested it against.__ All .NET UWP apps take full advantage of .NET Native, which generates highly optimized native machine code, resulting in performance gains (also explained in this article). More: https://devblogs.microsoft.com/dotnet/net-core-3-and-support-for-windows-desktop-applications/ The highlight of .NET Core 3 is support for Windows desktop applications, specifically Windows Forms, Windows Presentation Framework (WPF), and __UWP XAML__. You will be able to run new and existing Windows desktop applications on .NET Core and enjoy all the benefits that .NET Core has to offer.
Again, you can't trust magazine articles from half a decade ago that still refer to "ASP. NET 5". And Core 3 doesn't actually exist yet. In the future you may be able to use XAML on Core, if they don't change course once again. But today UWP is its own platform.
This is the first time I hear about service locator, how is it related to Unity? I'm legitimately curious but it looks like if you dont use Resolve then you're good?
What details are you sitting on that debunks Microsoft's documentation? Now, UWP is indeed it's own platform frome the perspective that it uses WinRT for it's runtime environment, not Win32, but I fail to see what bearing that has on whether or not UWP is built on dotnet core.
Shawn Wildermuth has a good course on pluralsight: https://www.pluralsight.com/courses/aspnetcore-mvc-efcore-bootstrap-angular-web And if you want something free, then checkout Time Corey on YouTube, he has an amazing series, actually all of his videos are great.
I second this. Tim Corey is amazing.
1 is a field, 2 is a property. 2 has a hidden field that it creates for you in the background. Normally, a field will be private, and only accessible within the class, as properties are normally public accessible outside the class.
Check out the real documentation. https://docs.microsoft.com/en-us/dotnet/standard/net-standard Notice how it lists Core and UWP as separate runtimes? That's not a typo.
The first one is a public Field, and the second is a public Property. Fields should almost never be public. The second one, is a field that automatically sets up a Field for the value. So: public string MyString { get; set; } Is basically shorthand for: private string myString; public string MyString { get { return myString; } set { myString = value; } } I can‚Äôt tell you exactly *why* you aren‚Äôt supposed to make public fields, but it has something to do with errors and security I think. It‚Äôs something I‚Äôve never really understood or bothered to look into. If you‚Äôre making a private variable, use just a regular field. private string myPrivateString; If you want it public, either create a property referencing and setting that field, or replace it with the ‚Äòshorthand‚Äô thing shown above.
In my company, we've recently started using the .editorconfig that the Roslyn compiler team uses. Works well for us. See https://www.hanselman.com/blog/EditorConfigCodeFormattingFromTheCommandLineWithNETCoresDotnetFormatGlobalTool.aspx
&gt; I can‚Äôt tell you exactly why you aren‚Äôt supposed to make public fields The main reason is that switching from a field to a property would be a breaking change. In your example, if you decided one day that you didn't want to allow `MyString` to be null and it's already a property, all you have to do is make the setter explicit and add the null check. If it's a field, you can't restrict the value, and you can't switch it to a property without breaking existing clients.
StyleCop is a **very** opinionated tool. Don't blindly accept and follow it. It's tool: adjust it to your needs.
As a property, the wrapper encapsulates the field and effectively hides its implementation. The caller doesn't know whether it's an auto-property or if it includes more complexities such as updating other fields, calling a database, or firing events. Also it frees the implementer to change from an auto-property to a complex implementation later without affecting the API surface. Note that switching from a field to a property of the same name is a breaking change if the caller does not get recompiled.
 There're already answers here: [https://stackoverflow.com/questions/5203338/property-with-and-without-get-set](https://stackoverflow.com/questions/5203338/property-with-and-without-get-set)
There is no MS coding style. When it comes to fields different teams use whatever style they prefer.
DotNetty is just another socket library, so you can use tasks and async await with it. It's really the difference between language feature and library in the same way as a JDBC provider is. &amp;#x200B; I will have a look at the youtube vid. It does sound like the Java side is doing the same thing as the CLR with regards to how it handles multiplexed IO. The async await stuff sits on top of this as a language feature. I will dig deeper and see if I can figure out what, if anything the differences are :) &amp;#x200B; Oh, I did find this: [article about how async await doesn't block threads.](http://blog.stephencleary.com/2013/11/there-is-no-thread.html) He does a much better job at describing it than I did :)
This is what I'm looking at currently - aiming to make the API as lightweight as possible; these will only be used for DTOs. What I ideally would like to do is remove the setter altogether except when constructing (at the edge) to make it a more functional design and sort of enforce immutability
This is possible, you can either make the setter private, use a backing field which is readonly, or use property initializers.
I recently implemented a custom error handling middleware to realise it already existed with better error handlingüòÆ
is there a way to change visual studio to use underscore for creating and initializing fields when you add arguments to the constructor? i think it currently gives it the same name and uses "this". resharper uses underscore
That‚Äôs why I never said ‚Äúnicer HTML‚Äù. It‚Äôs ‚Äúnicer HTML - JS integration‚Äù, such as in Vue files.
They were never necessary, but they can do so many things that you just can‚Äôt get anywhere else.
Yeah, docs is the thing you usually spend least amount of time for ;)
https://docs.microsoft.com/en-us/dotnet/standard/design-guidelines/names-of-type-members
I've already pointed out the runtimes are different. That doesn't change the fact that the SDK shipping in UWP apps since 10.0.16299 are based on Dotnet core specifically compiled for WinRT. If you search for _are UWP apps compiled with Roslyn_ on DuckDuckGo you will find [(UWP) .NET Native Compiler crashes or mrt100_app.dll Runtime crashes with NETCore 5.3.3 #20773](https://github.com/dotnet/roslyn/issues/20773) which is talking about a bug compiling UWP applications with Roslyn. Roslyn is then used to create Dotnet Native code for UWP applications, which is the Ahead of Time compiler for UWP C# apps. There are some use cases where WinRT doesn't support some Dotnet Core libraries, such as the C# Scripting library, but that's because of platform differences between WinRT and platforms that do support C# Scripting. I think you are getting mixed up in this conversation by trying to equate WinRT to Win32. They are simply different targets for Roslyn. All of the XAML features are shared between UWP and WPF. It will be interesting to see if the controls from the UWP Community make it to WPF. The biggest difference right now is the x:Bind system which is part of UWP but not WPF. x:Bind provides for AoT XAML binding which is much faster than Reflection XAML binding, which is what WPF uses. If you are doing a database application then that alone tilts the scales to UWP.
guidelines
I said a lot, not most. I was kinda pointing towards the solution I think is best for OP.
Some examples of what it can do on the readme.md would be nice! I took a look in the Demo API though
AvaloniaUI borrows a lot of ideas and concepts from css but it's not a 1:1 transform. If you are pretty good with web frontend stuff you could write your frontend with html, css and js and use something like electron to wrap it up and make a desktop application. You should look up the pros and cons.
I know about Electron the problem is its an insane resource hog from what i heard i personally use VSCode which is an Electron app and find it great so don't know how true that is. Also can i code my app in any language in Electron?
How long does it take your app to fire up and respond to the load balancer‚Äôs health checks?
Electron is just the web wrapped (simply put). There‚Äôs some complexity to it. Some still don‚Äôt think it‚Äôs a native feel. With memory, you always have to watch what you‚Äôre doing, just more so in this instance I think. More here: https://electronjs.org
How long does it take your app to fire up and respond to the load balancer‚Äôs health checks?
Would love to hear your input. I still haven‚Äôt managed to find anything anywhere.
You COULD load your HTML/CSS into a web browser control, I don‚Äôt know if that‚Äôs be the best solution. Look into AvaloniaUI and Electron! Read up on calling C# code from JavaScript.
ASP.NET Core in Action is a phenomenal book if you know a little C# already. Also, CBT Nuggets will start rolling out their AZ-203 content in the next few weeks
So how does editor config fit in with StyleCop and FxCop. I like that the later gives you compiler warnings, but I like how the former can also auto format.
Universal Windows Platform (UWP) supports HTML, CSS, and JS. [https://docs.microsoft.com/en-us/windows/uwp/get-started/create-a-hello-world-app-js-uwp](https://docs.microsoft.com/en-us/windows/uwp/get-started/create-a-hello-world-app-js-uwp)
Electron is your best bet for being able to leverage web technologies like CSS, but then you have to have HTML and JS as well. Electron.NET is a promising little project which uses ASP.NET Core to bridge an Electron backend with your HTML/CSS/JS frontend. So this allows you to write your app backend in .NET instead of node.js. Furthermore with .NET Core 3 you should be able to replace the browser JS with .NET code as well to some degree (Blazor). But I'm not sure what the Electron.NET project's plans are for that
I can't give you an exact figure as it's different for every service we host. &amp;#x200B; However, you would look into implementing readiness checks. &amp;#x200B; A health check is to see if the service is responding to inputs, a readiness check is to check whether the service is ready to respond to requests and is warmed up. &amp;#x200B; I think that healthcheck library has those built in.
I'd prefer constructor injection 99% of the time. &amp;#x200B; Unity is a service locator, so that's why I'm not fond of it.
Can you ask? I'd be interested to see it.
Glad it helped. Will say I basically rinsed and repeated this for the 40-486, and 70-487 to achieve my MCSD and MCSA, finished off the 70-487 last Tuesday. I stand by MeasureUp for actually learning the content of the exam, it is quick and easy, their explanations are good. I did everything I said above and got over 80% on each exam. However, 70-487 was hard, I am not familiar with WCF services and their configuration, MeasureUp still prepared me well. I did revisit dumps from Prepway for the last two exams and found them more helpful this time around. Careful with their answers, I have found a few that are wrong. They are actual exam questions and you will see them on the exam. Instead of memorizing them and their potentially wrong answers, research each one you get wrong or maybe questions if it is right. This helped me on 70-487.
This sounds more of a DB design question than a dotnet one.
Reading the docs at [https://docs.microsoft.com/en-us/dotnet/api/system.security.permissions.fileiopermissionaccess?view=netframework-4.7.2](https://docs.microsoft.com/en-us/dotnet/api/system.security.permissions.fileiopermissionaccess?view=netframework-4.7.2) it sounds like this permission allows anyone with the handle to retrieve the full file path the handle represents. It's unlikely to be the cause of your error I think. Typically Access Denied when loading a file means your the user account running the app does not have access to that file. If you are running the app under your user account this is unusual. However if you are running under IIS this is a common problem as it just means you forgot to give the Application Pool account that is actually running the app access to the file (or more likely your application's folder). What is the exact exception and stack track LoadFile is throwing? Be sure to check for inner exceptions as well.
I will on Tuesday, we're in full on Easter mode now until then :)
`A generic data access layer for ASPNetCore` Either a poor description or somehow weirdly coupled to ASP.NET Core. I'm guessing the first one.
You cannot define with absolute certainty the eternal future. All you can truly guarantee are your needs for the present.
!remindme 6 days
I will be messaging you on [**2019-04-24 16:02:58 UTC**](http://www.wolframalpha.com/input/?i=2019-04-24 16:02:58 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/dotnet/comments/be60pq/configuring_health_checks_net_core_kubernetes/el70v5y/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/dotnet/comments/be60pq/configuring_health_checks_net_core_kubernetes/el70v5y/]%0A%0ARemindMe! 6 days) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! ____id____) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
Why would you be using two tables for this record? If the account ties to the transaction and the transaction to the account put it all in the same record. The biggest question is why the heck an account can only be used for one transaction?
I am using Datagrip, or, better to say, datagrip integrated in Jetbrains Rider.
I'm using SSMS for MSSQL Server and I was using pgAdmin for Postgres until few weeks ago when Azure Data Studio team released beta version of Postgres extension for Azure Data Studio. There are still some bugs but the experience is so much better then pgAdmin. I was using DataGrip but I hate their shortcuts and naming conventions so much that I preferred pgAdmin. I was curious about TeamSQL but if I remember correctly they require your email and to install Java so I resigned.
does any one know any other complete free identity server tutorials?
WPF or WinForms doesn't support that feature. On the Java side, JavaFX supports CSS and FXML as a means to build user interfaces.
Standard tools for their respective databases.
Linqpad for viewing data, mssql server HeidiSql for editing data, at current job we use azure, so Azure Storage Explorer
For majority of my projects, I use Roslyn analyzers with .editorconfig for some other style. (EditorConfig)[https://docs.microsoft.com/en-us/visualstudio/ide/create-portable-custom-editor-options?view=vs-2017] and (FAQ)[https://docs.microsoft.com/en-us/visualstudio/code-quality/analyzers-faq?view=vs-2017]
Well, when you work on a distributed environment you must think on database read/write points. A lot of processes or threads will kill database. You need to reduce database connections to minimum. Personally i like to put this points on MSMQ queues, a single process send data related to an isolated thread/process using msmq, i can scalate it if i need to. I do the same for threads. The question is: what will you do with your program output?. Split a giant table to a multiple processes is not hard if you don't need transactions or real time results.
You can try Lynda, if you have access from your library for free.
Hey, I‚Äôm a dev w/ a company that works with several applications that hit solidly sized databases (million+ rows, 150+ tables) What are you trying to accomplish in the end? Not seeing the value in spawning off full console apps. So you want to just read lots of data then display it?
No , there would be a few columns in the data rows , like for example a start datetime and end date time , if the start and end is within a specified range , we call a API and then we update the record
Compare each one to the previous?
A dictionary with previously processed cases will be your better option. We are talking about a finite universe, only 0000 to 9999 combinations are allowed. You don't need a complex algorithm because your cases aren't dynamic.
After doing a little searching I found this recent article. Seems like maybe the impression is that Razor is being pushed as a replacement for MVC for web development? https://www.telerik.com/blogs/razor-pages-the-natural-successor-to-web-forms
1. Split input into digits 2. Initialize test digit with first pin digit 3. Iterate over all digits 4. Increment test digit every time and check against current pin digit.
Pages are the new default, yes. Aspnet core mvc is unlikely to vanish as its also the api framework. But it's UI side is slowly being phased out.
I switched to dbeaver from pgadmin for postgres. The UI feels a little outdated, but I found my workflow to be much faster once I figured out all the keyboard shortcuts.
any ideas for a better description? :-)
wanted to keep readme as concise as possible. so added links at the bottom for examples. thanks!
The task you described does not really require any .NET code. Things like this are usually done in a stored procedure inside the database. Is it MS SQL server or another database?
True, but not very elegant IMHO. Even without the 4 digit limit there are only 28 cases.
So long as you aren‚Äôt making something huge, you shouldn‚Äôt notice too many performance issues with Electron. The issue is when big services (like discord or slack) do it wrong.
Aren't there only 7 cases to check for? * 0123 * 1234 * 2345 * 3456 * 4567 * 5678 * 6789
Yeap, but requirement is 4 number values. It's not necessary a generic algorithm.It's preferable an ugly hardcoded dictionary than an over complex algorithm
Wait when did they start using JS as their language for building Microsoft apps
I use DBeaver for all my databases. The improvements have been amazing over the past few years.
Probably but the tooling is far from ready and there is still years of work to do for it to be mainstream.
What type of rules?
Honestly I‚Äôm trying to understand what the real issue is here. I use entity framework core, and the databases I have to pull data from has a bunch of data I don‚Äôt need. I just ignore it. The database design was put in place long before I arrived so unless you want to rearchitect the tables then just move on with life, ignore the data you don‚Äôt need.
Problem it that this ugly hardcoded stuff quickly becomes a habit. I've seen people hardcoding a bunch of numbers to check if some input is even. Everything in software is "finite" because you datatypes and memory are finite. Where do you draw the line for it to be ok? 7 cases? 20 cases? 100 cases. It often depends on what you are doing. In general you shouldn't hardcode that kind of stuff. If you are writing the firmware of a calculator and need to hardcode a quarter sine wave that's a completely different story but in general you shouldn't do that.
I'd second this. Every course I've done of his is well explained and well thought out.
That's a great thing to do. Have a read about CQRS.
The problem is not a ugly business rule in your code, real problem is how you put on the code base. A good architecture allow the development team to replace a ugly piece of code for a better one. I only have a single business rule, i am not sure how to be placed in base code. The point of doing a good thing and the right thing depends of software requeriments.
This is the right answer
It is, but my issue but issue with it is two-fold. 1. I've heard that trying to do AJAX with Razor Pages is a bit convoluted. 2. It seems the future is SPA and in those cases, the MVC model suits it much better. However, the cool part is that you can mix MVC and Razor Pages into the same app. So you could do both. Also, just remember, there is a difference between Razor Pages and razor syntax.
MVC isn't going anywhere, Razor Pages is a replacement for WebForms, not MVC. WebForms is a very outdated technology that isn't worth using anymore unless you need to give support to an old project. Both Razor Pages and MVC have their advantages and disadvantages but since you can mix them in the same project they are not mutually exclusive. It is up to you to decide which one suits your needs better.
I'm using Squirrel, but I guess it only supports JDBC connections, so need a compliant driver for each type of database.
I forgot to mention that since most UI's nowadays use some kind of client side framework (Angular, React, Vue, etc.), MVC will remain to be the most used since it's what API's are made with.
Assuming `pin` is a string: bool isFourConsecutive = pin[1] == pin[0] + 1 &amp;&amp; pin[2] == pin[1] + 1 &amp;&amp; pin[3] == pin[2] + 1;
psql for PostgreSql. I wish SQL Server had a utility as good.
A bit of an old video, isn't it?
Reading thru the comments gave me some ideas, particularly that there are actually only 7 cases to test. Did something like this: Dim NEWPIN As String = txt1.Text Dim sequences = New String() {"0123", "1234", "2345", "3456", "4567", "5678", "6789", "7890", "0987", "9876", "8765", "7654", "6543", "5432", "4321", "3210"} Dim count = sequences.Length Dim index As Integer = 0 Do If sequences(index) = NEWPIN Then txt2.Text = "Match" Exit Do End If index += 1 txt2.Text = "No match" Loop Until index = count Thanks.
Note to self. Check back here if anyone replies
how do i get it for free on Lynda
YMMV, check with your local library or check your local library website, see if they provide lynda access.
SQLdeveloper or sqltools for oracle, sqlyog community for mysql
[Release Notes](https://github.com/Microsoft/dotnet-framework-early-access/blob/master/release-notes/NET48/dotnet-48-changes.md) Looks like mostly WinForms and WPF fixes among other various fixes.
there's nothing like that around here. this is one of the stuff that there isn't alot of tutorial on. i wonder why?
Regular expressions make determining things like this pretty easy. This tool is my favorite for developing regular expressions: [regex101](https://regex101.com/) So something like \`\^{0-9}\[4\]$\` will strictly check for four digits. You can also make it more flexible to allow whitespace, separator characters between digits, or search for PINs surrounded by unrelated text pretty easily.
Hmmm... your 2 issues seem to be the same issue, and they seem to be based on hearsay. There's absolutely nothing convoluted about AJAX with Razor Pages because, as you pointed out, they can live in the same app with MVC and Web API. If it helps, you can think of Razor Pages as being MVC without a route or a controller. Or rather, a route that is defined as the path to the view and a controller that consists only of `return View()`. In a SPA, that's all the controller you need for the UI. Then you have a Web API controller for the API portion. If, for specific parts of your app, you need advanced routing or controllers, you can still use them. You simply have the option of omitting them when they are redundant.
To be fair, they have pretty good tutorials which you can read and then get the complete repo on GitHub. So, I'd focus more on looking at their documentation for tutorials then relying on videos that get outdated pretty quickly.
If they keep it up they will make a name for themselves in no time.
AnkhSVN, that takes me back! The biggest benefit of Git (IMO) is that branching is extremely easy. It may have changed in the last 10 years or so but whenever my old team used to use SVN they would regularly get to a point where I had to come over, delete a merge/branch SVN hadn't quite managed and then they could try again. With Git that (almost) never seems to happen, it's extremely good at branching and merging changes. I tend to prefer the [GitFlow](https://nvie.com/posts/a-successful-git-branching-model/) workflow as it makes it easier to keep track of live code, upcoming releases, and any hotfixes that you (or your clients) need to come in before those releases. Plus with Git being a distributed system you get a kind of pseudo backup where your codebase exists on all the machines that have pulled it. The biggest downside I'd say Git has over SVN is that a lot of devs (at least when we started using Git) struggled with the difference between committing their changes and pushing them to the remote. There was some disconnect still in their minds where they didn't quite get that their changes weren't available to everyone until they've pushed which could lead to a few more merge conflicts than were strictly necessary early on. As you get familiar with Git I think that tends to go away thought. Overall I'd definitely recommend it, I wouldn't go back now and I don't regret ever having moved on from SVN. &amp;#x200B; ^(Disclaimer: it's been nearly 10 years since I last used SVN, some of my memories of it may be hazy!)
So just off the cuff, you should convert a small one, then look at the changes to see if it's even something you could script in the first place.
Git can be used (more or less) like SVN, but has a bunch of other features. GitHub has features on top of that (such as pull requests). There really isn't a lot of downside, except that you will lose file history unless you find a way to convert it and the cognitive load of learning which features are necessary or useful might make the change annoying in the short term.
The article title clearly states "razor pages the natural successor to web forms". Web forms is not MVC.
Could just use Linq ``` var pin = "4444"; var result = pin.Distinct().Count(); Console.WriteLine(result); // 1 ```
I'm pretty sure they've made a name for themselves a long time ago
Right. I've done that. Part I am not sure about is how to generate the designer files for each of the pages.
I used Subversion for about 10 years and I never got why Git people were so zealous about Git. I've been using Git for about a year now and I totally get why Git people are so zealous about Git. With Subversion, the mere mention of the word "branch" made me scared. I never used them. With Git, the idea of working without a branch is unthinkable. Branches in Git are so easy and useful. It's a completely different way of working. I only use a few of the features of Git. I'm by no means an expert. But I wouldn't go back to Subversion for anything.
Not sure about that. Web sites don't need designer files, web applications do. But that comes with a myriad of pros and cons as well.
Git really is a game changer compared to SVN. There's a reason it's taken over everything, and that's because it's really good. We use Azure DevOps at work, and I use it for myself at home on my side projects. It's free for up to 5 users (just like GitHub ever since MS bought it).
thatsthejoke.jpg
You definitely want to get the rows in chunks and process them before moving on to the next chunk of data. You probably want something lightweight to get the data into C# objects, and Dapper is good at this. Most important would be making sure you table has the appropriate indexes on it so that the data access is as quick as possible. If you‚Äôre going across multiple tables consider a view.
My general advice is to always separate your data models in 3 different layers - data access models (SQL, NoSQL basically storage models) - business logic models (I prefer the usage of POCO's here, just plain objects no logic whatsoever) - presentation/view,transport etc models (Things like the JSON represenation of the model) To give a little more prespective on the why, let's first look at an hypothetical representation of a `Document`. __Example__ 1. The data access model example for a document ```csharp // A document representation on a sample SQL Database [Table("Documents")] public class DocumentEntity { [PrimaryKey] [Column("Id")] public int Id { get; set; } [Column("Uuid")] public Guid Uuid { get; set; } [Column("Content")] public string Content { get; set; } } ``` 2. The business logic models ```csharp // The document model representation used to make business logic decision // REMARK: see that the PrimaryKey was dropped in this example public class Document { public Guid Uuid { get; set; } public string Content { get; set; } } ``` 3. The business logic models ```csharp // A document representation on a sample SQL Database [JsonObject("Document")] public class DocumentJson { [JsonProperty("id")] public Guid Uuid { get; set; } [JsonProperty("content")] public string Content { get; set; } [JsonProperty("links")] public IEnumerable&lt;Links&gt; Links { get; set; } } ``` So now on the why I personally prefer this approach. - There is no leakage of data storage concerns to the application layer and above, I can replace my datastorage from a SQL database to a NoSQL database without theoretically creating friction on the rest of the application code. - I can create a different projection for my Document model without again impacting the different parts of the application, let's say I wanted to represent my Document as a XML instead for example. - Resuming, this approach makes the future changes and introduction of new requirements easier to manage when done properly, because your changes have known boundaries where you'll be working with. All of this goes hand in hand with concepts as [Clean Architecture](http://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html), [CQRS](https://martinfowler.com/bliki/CQRS.html) and others that will make your application to be more robust and easier to maintain. **Last WARNING'ISH...** Remember that these approaches are not dogmas, and they do have some caveats. One easy issue to see is the need to maintain lots and lots of models, mappers, etc. (even though I 100% believe that the benefits make up for the added overhead). Another common issue is that this is easier said than done, and sometimes abstracting the storage is no easy thing to do.
Also says: &gt; Razor Pages is the natural successor to Web Forms. It continues a long line of page-centric web development frameworks. In fact, with the introduction of Razor Pages, MVC is no longer ‚Äúking.‚Äù The default web application project in Visual Studio is Razor Pages, and the Razor Pages framework is Microsoft‚Äôs recommended approach to server-side HTML generation. As this high-level orientation is intended to demonstrate, moving from Web Forms to Razor Pages should not be a daunting experience.
Guidelines for coding style published by Microsoft... sounds a lot like &gt; MS coding style
Perhaps "for .NET Core" or even "for .NET Standard" (if it is enough) instead, since most probably doesn't rely on aspnet, or does it?
You can't insert a Category\_ID without it first being in the \[Post\_Info\] table.
*invest now!*
whooosh
Despite the hate they get, largely bled over from the consumer space, Microsoft has been killing it from the perspective of a developer for like 30 years. They've always had top tier tools. Not perfect, of course, but compared to the rest of the space they've always stood out from the pack. I have to be nostalgic to come up with platforms that competed overall (DAE Borland Turbo Pascal). Exposing the Windows and various MS applications and technologies through developer api's is a herculean task. Running projects like VS, Windows, Office.. imo MS is friggin impressive.
Thanks. That last article seems interesting. I'll try to run some tests myself and check out their behavior.
But I already had the Category_ID in the Post_info table
DataGrip. SQL Server, PostgreSQL, H2, and DB2.
The Id likely has a bad foreign key value, doublecheck that it isn‚Äôt 0.
I love this
Add a breakpoint on `SaveChangesAsync`, but don't execute it. Run execution up to that point and go look at the entity being created and see what's coming up on the `Category` property. You're likely running into an issue with it not finding the foreign entity based on the given key.
&gt;I can replace my datastorage from a SQL database to a NoSQL database without theoretically creating friction on the rest of the application code. In practice such a change may not be frequent enough to warrant the extra layer. And when one does change, usually many other things are changing anyhow such that there are major rewrites that make such a layer moot. (Your shop may vary, but most shops don't switch DB's for existing apps very often.) It's kind of like pricing insurance: don't buy insurance against rare events unless such events would totally wipe you or your biz out, and don't buy insurance against events that not that costly when they do occur. Having too many layers can cost you in too much busy work wiring schemas to similar mirror schemas all day.
https://media1.tenor.com/images/7d09ee53295059ff425a7f05b9fa0af7/tenor.gif
oof
Yeah, i got a 0 for the category_id, but still don't know why though
Depending on your mappings and whatnot, you probably need to supply the foreign key for the linked entity. Take a look at your code and see if there's a logical way for EF to know which foreign category you're looking for.
Looked like there were some performance improvements for Skylake and later processors. Also: *.NET now integrates with antimalware providers to scan assemblies loaded from byte arrays.*
Well, I agree with you and I also disagree with you :) Joking aside, what I mean by this is that it will really depend a whole lot on the context and it shouldn't ever be a binary decision, like "*always do this*" or "*don't ever do this".* But on this I assume we share the same opinion. &amp;#x200B; The SQL change to NoSQL might have been a poorly chosen example, but the idea that I wanted to pass was the seperation of the boundaries and scoped introduction of changes. As I pointed on the warning section, and you also referenced on your comment, this in reality is always a way more complicated task and indeed many other things end up changing, there is no way to deny that. &amp;#x200B; On a personal level I still advice people to first consider this approach, not because it's the *better or right way*, but from past experiences what I saw is applications becoming a tangled mess over time, because the lax of boundary constraints opens up paths to create pieces of code that blur the boundaries and there is no perception on when some concern begins and the other starts since they end up intertwined, this happens a lot with less experienced developers without proper supervision when working in a collaborative environment. &amp;#x200B; But then again, all these choices always depend on the context.
oh, is their documentation that good? some of these docs are quite bad. I'll check it out.
Microsoft is cool, but not nearly as popular as javascript and python
That's a point I always bring up when people say Macs are better because they "just work". They're not entirely wrong, but Apple also only has to support a very narrow range of hardware, which they also happen to make. The fact that Windows runs pretty damn well on a vast range of hardware configurations is damn impressive. I work in a Rails shop at the moment and my co-workers looked at me like I had two heads when I said my next personal laptop will very likely not be a Mac. One of them even asked, "Well what about Brew?" What about it? It's just a package manager, and while yes it's very capable, it doesn't do anything you couldn't do yourself.
they've made a bad one and they on the right way to fix it, that's why you see people using nodejs in servers
Man, my fukin' scrolling finger needs a rest after that page.
Amazing work!
There is at least one false statement in this post. I read the developer survey results when they were released and I remember .NET Core being the most loves technology in a subset called "other tools" etc. You might want to review the results.
However you aren't comparing apples with apples. Infact none of this survey is. JS is really popular because its the defacto front end language you need for web design. There isn't much competition out there for it. You really can't compare it to C# that doesn't do any front end apart from razor or the one starting with B.
In some way these surveys are totally bogus and lead to false conclusions about programming languages. We are not comparing the same things. its like saying penguins are more popular than lions. Both live in completely different environments and do different things.
I went down the IdentityServer path about 2 years ago, only to stop 1-2 weeks in after I realized that if you're not building a multi-tenant enterprise solution that uses a single login for all of the apps (tenants), it's a waste of time and effort. Rolling my own JWT service on top of EF Identity was one of the best decisions I made after those 2 weeks of IdentityServer hell.
Boundaries are often vague or unpredictable in real life, and domains. I couldn't really comment on your issue without seeing the specific scenario. And no, the column-set idea is not about a new or different query language. I'll try to illustrate the concept. Let's say we store column info in a database similar to the following: Column FldSet ------ --- EmplID A LastName A,B FirstName B,C,D MidName C Salary A,D SuprvsrID B SuprvsrName C,E Then one could issue a query similar to: SELECT * FROM dataDict WHERE entity="Employees" AND FldSet IN ('C','D','F') There may be another table involved, but this is rough pseudocode. And sets would have better names rather than letters. There would be other attributes such as title, max length, required-ness, data-type, etc. such that we wouldn't have to re-specify such info to use it. However, we *could* re-specify (override) if and when needed for particular spots or views. Thus, we can automatically use the defaults but are not forced to use the defaults. This gives it more flexibility than what typical data-dictionary-based RAD IDE's typically provide. Note that some columns may be "dummy" columns in that they are not actually in the database. (Another flag column may indicate whether it's a dummy.) Such are useful for custom adjustments or intermediate computations. And there might be overlaps/duplicates that are treated differently under different views or situations. For example, you may have one definition (row) for "LastName" for a data entry screen and different "LastName" row for the listing screen. The framework could detect such overlaps if they do matter, such as 2 columns of a result set overlapping, per database column name. It would reduce a lot of grunt-work of column-oriented programming so that one could focus on domain logic.
!!!! Thats it for us. We already had a number of projects for which the existing the whole front end JS framework workflow was overkill. We are officially on the blazor train with two project for production being switched over (more complex projects still on react). Hopefully in less than ten years from now I will tell my son how we used to always do apps and he will give me the same look like when I told him there used to be some things called video tapes.
If anyone was previously wary of investing time into learning Blazor because it was experimental and Microsoft could pull the plug, this should allay those concerns: &gt;Blazor is no longer experimental and we are committing to ship it as a supported web UI framework including support for running client-side in the browser on WebAssembly.
It's not good for a huge authentication server either. Once you understand the protocols you're doing, IdentityServer gets in the way. What it's really for is spinning up an OAuth-compliant server and user account store fast by copy and paste without understanding most of it. It's a normal use-case to abandon it when the going gets rough.
&gt; Internal and private fields are not covered by guidelines
I keep seeing posts about this can someone tell me the diff between using this vs Razor pages ?
Wow, bit late to the party
Its more like a SPA framework (like Angular or Vue) that happens to use Razor as the syntax for component templates. There are tradeoffs to using the client or server model though: * Client - Relies on compiling to a Mono based WASM runtime, which is slower, bleeding edge, and has a larger download size * Server - Requires keeping a websocket open to clients to render over (and the incidental latency), but otherwise gives about the same experience as making an Angular app with C# on both sides, better server side performance, and almost no client side dependencies (a single js file). If you've used other modern component based JS SPA frameworks, then Blazor seems very familiar.
‚ÄúWTH is up with the hate on C#?‚Äù by The Sharp Ninja https://link.medium.com/jUU01A07ZV
Quick note that Typescript is developped by Microsoft and very valuable to the JS ecosystem.
Chocolatey probably isn‚Äôt quite as rich as brew but it is definitely a nice choice on Windows.
Yeah, didn't think about it at the time the conversation happened, but it's a decent alternative.
I'm using Mercurial. While I haven't worked with Git a lot Mercurial seems to have a slightly better design for me. But Git is pretty much the defacto standard at this point, so I guess everything else is already at a disadvantage solely due to popularity/support at this time when deciding on a new source control system. That said, I'm perfectly happy with Mercurial besides it being a lot less used/known than Git.
Use bitbucket, it‚Äôs still Git, but you have unlimited private repositories for free (up to 5 developers)
Razor will be the default until Blazor is out of preview.
I've poked around for progress on the mono.wasm front, as to me an optimized runtime is really the thing that will prevent adoption. anyone have any info on what's changed recently?
I think they introduced it with WinRT in 2012. You could build Windows 8 apps in it: [https://blogs.msdn.microsoft.com/mvpawardprogram/2012/09/11/building-a-windows-8-touch-application-with-winrt-javascript-and-html5/](https://blogs.msdn.microsoft.com/mvpawardprogram/2012/09/11/building-a-windows-8-touch-application-with-winrt-javascript-and-html5/)
Microsoft is not as popular as JS? How can you compare a company vs a language?
It‚Äôs also free now on github
actually it does. atm the database connection is configured and initialized from the Starup.cs of aspnetcore apps. I will look into making it compatible with other project types. possibly making it a netstandard class library.
Yeah, definitely. It's going to be very much a part of [Blazor](https://dotnet.microsoft.com/apps/aspnet/web-apps/client) as well, so they may be priming the pump for that, as well.
Fastest for me in the past has been deploying from Visual Studio to Azure. Usually only takes a few clicks.
Sorry, but no. Too many dependencies, close to 0 value
Cool now its time for 3 months of incessant "What's new in .NET 4.8" posts
Not much. This is one of the least interesting .Net Framework releases I can recall. Which is fine, but it's pretty much all just relatively minor bug fixes.
Yes its MS SQL , but the operation is we need to call REST API from the data base on a business rule
MS is becoming great again. I love .Net Core and Visual Studio (code) very much
Forget about multiple console apps. You can split your workload into batches (200-500 records perhaps) and do concurrent batch processing in the same process using Parallel.For or Parallel.ForEach To write less code you can use Dapper and Dapper Contrib (just make sure your table has identity PK for the latter).
BTW, for batching you can use Batch extension from here [https://github.com/morelinq/MoreLINQ](https://github.com/morelinq/MoreLINQ)
I wouldn't go with Blazor for the reason that it's going to undergo a lot of change, but hey, someone has to do it!
https://github.com/warappa/XamlCSS
Check XamlCss in github
This looks promising. Can't wait for async/await, any (vague) ETA yet?
TFSVC on premise... Because my bosses decided it, they find it was better than cvs... &lt;rant&gt; I hate the branch system. Who thought it would be a great idea to copy all the content of the project in each branch (having 10 branch to date in my project), making dev wanting to avoid branching at all cost, because config doesnt stay? Some says to not branch, instead make label. And i woukd kill to commit/branching in local, you know, like actual development! &lt;/rant&gt;
Thanks for clearing that up. I haven't tried Razor Pages yet, but just read things like, https://www.mikesdotnetting.com/article/325/partials-and-ajax-in-razor-pages I'll give it a try when I have time.
&gt; *.NET now integrates with antimalware providers to scan assemblies loaded from byte arrays.* There goes those performance improvements. /s
Hahahaha. ah, thanks. I needed that.
That statement isn't false; please check out yourself. [This list](https://insights.stackoverflow.com/survey/2019/#technology-_-most-loved-dreaded-and-wanted-other-frameworks-libraries-and-tools) has *most options* where .NET, Node.js, PyTorch, Apache Spark, etc. almost all important and popular technologies reside. Even, to avoid confusion, in my post, I mentioned .NET Core as a ***technology****;* not ***framework***. [The other list](https://insights.stackoverflow.com/survey/2019/#technology-_-most-loved-dreaded-and-wanted-web-frameworks) *only* includes **Web Frameworks**. So I guess it won't be wrong to call this list (with less variety) a *subset* because it's based on just web frameworks, where all other frameworks aren't counted. So, in my opinion, this one is the subset, not the list consisting .NET Core.
Microsoft has several examples and tutorials on their dot-net sites. I cannot vouch for the quality, though.
&gt; offer higher salaries than Java globally! Oracle screwed Java over with their lawsuits and intellectual property threats. Short-term greed in action.
[removed]
It really depends on the app I think. I'd usually do a translation between business / domain model and api model / view model, because the external facing models almost always are close, but have specific differences to, the domain model. In the long run it makes sense to separate those. For domain vs db model I could go either way. If I had a reason to make data models that match 100% to my DB (i.e., you're using EF with code first, or something like that) then if I had control of that model, my data model would probably be close to my domain model anyway and I'd use that directly. If I wasn't in control of that DB schema (DBAs control, or its a legacy app that I need to integrate with) I MIGHT make models like that if I found I had to do a lot of transformation to it. If I was using Dapper / SQL queries I write directly, I think anymore I'm more prone to just write the query to the business model though, or write specific data layer models only for the ones that I need to pull multiple things and assemble in a wrapping service class, etc.
TVs/Azure Devops
Just search on github or any other code repository.
[Here it is.](https://stackoverflow.com/a/52603580/397807)
This also works well with Intellisense. Just hit underscore and all private fields will be there.
You can have Azure signed in to your github, bitbucket etc. and once new changes are committed Azure will make sure to pull the newest, build it and deploy it
AOT is in the works, apparently within a few months.
I need to display the Project Name.
Well it supports async methods. I mean it correctly executes code after async method. And give you opportunity execute code instead/around async method. If could elaborate more on your scenario?
you should know I'm comparing c# vs javascript
yes i write angular so I use typescript, it feels like c# . i give microsoft that one
I think "Most Loved, Dreaded, and Wanted Other Frameworks, Libraries, and Tools" is a second category. Notice how it starts with "other".
We use Git for source control. Azure DevOps for hosting because of two things: * pipelines / yaml builds are excellent. All the build hosts have the latest .NET toolchain and jobs can run on Linux, macOS,or Windows. * private NuGet feeds for internal packages.
My favourite bug fix: Fixed the issue that SqlDataReader.ReadAsync() runs synchronously. Now the method runs asynchronously as expected
the .NET Framework is in maintenance mode. So there won‚Äòt be new exciting features. The innovation happens in .Net Core.
Are performance improvements not interesting? So that's why they've done it so rare... :'(
Thanks :-)
Thanks Will check both
 Thanks Will check both
Since I'm not rich enough for Azure I just `dotnet publish` locally and then transfer the files through SFTP to my DigitalOcean VM.
&gt;psql for PostgreSql What do you mean by that? Also, SQL Server Management Studio is one of the better GUIs for databases out there. There's nothing as snappy out there for PostgreSQL at the moment.
What's bad about the Identity Server docs? They're one of the most comprehensive OAuth/OpenIDConnect framework docs out there.
My bad then, as I said I'm not familiar with that topic, but from my understanding this is something that only exists in conceptual stages, right? If so, I believe that is of little pratical help to the issue exposed by OP at the moment, BUT it still seems an approach really worth looking into so, do you have any sources that I can follow upon in order to learn more about the subject, or some key words I might put together in order to find useful content on google?
I'm using the free tier of Azure DevOps to build and deploy my stuff. Reproducible builds FTW. Automated deployments FTW.
yes, if you're not having multiple applications connecting through one login, there's no need to use identityServer. that's why we have jwt
I think where I'm getting to is that fibers are like a game loop with built in parallelisation, but as it's cooperative scheduling you could have a fiber be less cooperative and bugger everything up. I'm still working on whether that's the case or not. It's always difficult to find an analogy that fits properly of course.
If we're following correct terminology then you're talking about WebAPI, not MVC as MVC includes the Views (Razor).
I'm going to have to disagree here. Nowhere have Microsoft implied that MVC is being slowly phased out. I find its approach of decoupling business logic from views a lot better for large scale projects than Razor Pages (which is basically the new WebForms).
I am really excited about this. I've been using Blazor client side since early days, just for fun, on small projects. I'm glad to see that it is going forward. My experience using it has been good. It feels nice to be able to do almost everything in C#. If/When WASM Blazor makes it to production I will definitely use it for something.
I wouldn't say RazorPages is a replacement for WebForms because it works really different from WebForms. RazorPages and WebAPI are actually part of MVC. To me RazorPages are more like a flattened and simplified MVC.
&gt;Microsoft Azure is the **second most popular** cloud service used by professionals In today's world (Azure vs. Amazon) that second place is kinda like losing.
Note that GitHub allows up to 3 collaborators instead of 5 for private repositories.
I prefer an underscore prefix - I find it easier to differentiate between properties and backing fields and less likely to make a typo/wrong intellisense suggestion from `_a` than `this.a` to the property `this.A`. If your private field is purely being used for some kind of relevant data storage with no associated logic then there's no gain in having a private property (and potentially a small cost as the private property still has a backing field). If you need to perform validation, or lazy loading or some other task then a private property (and appropriate field) can be the way to go.
I prefer `this`. It's clear; it's consistent between fields, properties, and methods; it's built in to the language. There's not really much reason to use private fields any more now that we have automatic properties. The only situation I'd use them now is where I want to do something that a property doesn't support, like passing the field as an `out` parameter (into something like `int.TryParse`), that's vanishingly rare though.
I've definitely encountered it more than once myself. Linq is awesome when it's structured and concise, but can be pure hell when people (or generators) write unreadable and unmaintainable queries.
i think JWTSimpleServer belongs here: https://github.com/Xabaril/JWTSimpleServer
I had a situation like this yesterday. One of my junior devs was putting an export together where they got records from the dB for say 8-10 objects separately (no EF) and then looped through the records putting it all together in iteration using firstOrDefault() etc. On 25000 records this took ~6 mins. I refactored it to be a link query with joins then outputting the composite object in a single call and it took the time down to ~40 seconds.
Isn't "rolling your own" when it comes to Identity/security/tokens considered incredibly bad practice?
Yes this youtube channel steals MS vids..from youtube.. and reuploads them on their channel in youtube, I guess they've moved into promoting that material this subreddit.
Yeah, it just takes 7 years to reach parity with .NET Framework. Then the real innovation can begin......
I use Hungarian notation in combination with camel case notation. Prefix "a" for argument, "l" for local variable, "m" for private field and "i" in iteration variable. Properties and class are just camel case.
I think there are two issues with linq I have come across: 1) ‚ÄùToo much LINQ‚Äù: Sometimes people get too much into LINQ and become blind to all other solutions. Foreach-loop? Nope, you always have to use .ForEach() with 50 line lambdas. Sometimes it‚Äôs good to remember that there are other ways to solve things. 2) ‚ÄùLINQ can solve anything‚Äù: I‚Äôll admit that in basic collection operations you rarely beat LINQ by whipping up your own methods. At least not by a significant margin. But with LINQ to SQL you have to know it‚Äôs limits. Just a few weeks ago we ran into a query that selected half a table to memory and performed rest of filtering there. Very efficient. Overall I think that LINQ is one of the most important things that you have to know as .NET dev
Used SVN for about 10 years, much like you. But we were a three developer shop, had a lot of binary assets, and generally never worked on the same folder as someone else. The regular company users also used it to version control and share office (i.e. binary) documents. Sparse checkout was also a very useful feature (especially for large repos approaching 100GB). For pure source code work (e.g. text files), Git/Mercurial scale better and work better with managing branches / merges / tags. Both are distributed version control systems (DVCS), so you can create branches / commits (similar to SVN's 'ci' command) while offline. The downside is you have to pull down the entire repo locally (clone a copy of the repo) and you shouldn't put large binaries (over 1-5 MB or so) into a git repo. And you'll want to use something like git-lfs (or even just SVN!) to manage those large binaries. - https://www.atlassian.com/git/tutorials/comparing-workflows - https://trunkbaseddevelopment.com/ - https://nvie.com/posts/a-successful-git-branching-model/ Our team uses the "forking" workflow where each deliverable has its own git repo on Github under an organizational owner. Developers then "fork" (GitHub's concept) the repo to their personal account. You clone down your personal fork to a local repo, create a feature branch locally, work on it, then push that feature branch up to the personal fork. Github then prompts you to create a pull request (PR) over to the organization's copy of the repo. This gives other team members the ability to review the PR before it gets merged into the organization's copy of the code. GitFlow and trunk-based development both work well with the "forking" workflow. Gitflow is overkill for simple websites where you are not support multiple releases in the wild at the same time. We find trunk-based to be better for web apps / APIs where we are the only company hosting the app/API. Github / Gitlab are both hosted solutions that tie well into CI/CD as a service (AppVeyor, for one).
Always used pgAdmin III for postgres (it's been a few years). Best feature was that it would always show you the SQL commands for doing this or that (like how to reconstruct the index). Made it very discoverable if you needed an example of syntax. We're moving over to Azure Data Studio for Microsoft SQL Server. It's similar to VSCode in that it's cross-platform and supports extensions. There may even be plugins for SQLite, postgres, etc.
For #1 .ForEach isn‚Äôt LINQ so it‚Äôs not fair to blame LINQ‚Äôs use there
Good point. The same intent to always rely on fluent syntax is still there, however. And quite often that also comes prepended with a .ToList
it really depends on your use case. but for me it replaced full framework a long time ago. but i‚Äòm also in the camp who uses only web technologies for frontends anyway. i‚Äòm not interested in WPF, Winforms, ... for backend services it‚Äòs IMHO way better than the full framework.
Private fields are an common use case when you use Dependency Injection.
Ah, this guy codes. I take this to a whole new level. I prefix the variable with it's type so that I don't have to rely on IDE or compiler telling me which type it is. Like `void Something(String aStringName, int aIntAge)`. Yes it might look weird in this example but when you don't have the type right next to the variable, this is very.
In practice, our database models (which map 1:1 to underlying tables or views) work fine as the business objects. Especially when we're using an ORM like EntityFramework. For an MVC web application, there's a view-model class that is used by the view(s). The translation between the data model and the view model happens in the controller logic. Validation happens on the view model, not the data model. Something similar for web API scenarios, except that there's a request model and a response model. But we still translate between the request -&gt; data or data -&gt; response in the controller logic flow. Validation happens on the request model, not the data model. Even with NPoco, we're still creating the data models to represent the database tables / views, but we'll also construct some response/view model classes that just get populated by a SQL call (or stored procedure). Useful for those big list views where constructing data objects, mapping to view objects, putting into a list for a UI that only displays some of the properties -- is a waste of bandwidth and RAM.
They really are! They have very nice tutorials for real world use cases like. Js client talking to API for instance.
1) I have to follow team rules. 2) Adding type is nonsense. It is about scope of variable.
This might be something you're looking for: [https://github.com/dotnet-architecture/eShopOnWeb](https://github.com/dotnet-architecture/eShopOnWeb)
But the intent do is quite different as LINQ is all about generating / shaping data, not making use of it. Fluent syntax and lambdas can be used for many things outside of LINQ, so much now that they‚Äôre really not specific to it. I get your point but even with this addition i don‚Äôt feel LINQ fits anywhere in the picture about fluent/lambda/List methods or replacing foreach to make use of data
It is as nonsensical as adding "a" for arguments. If your functions are becoming so long that you need to cope in ridiculous ways, perhaps it's time to split the function into manageable parts.
Yup you totally can do that, I tend to prefer assigning them to properties, that way if you need to modify their accessibility (e.g. Make them protected so derived classes can access them) you can do that with minimal changes and without exposing a field.
It does t really matter as long as the entire development team is consistent. We chose a convention, set it up in StyleCop and enforced it on checkin. Nothing worse than 25 different developers writing code with completely different styles.
A few more if you count the likes of 8901 and 9012 but yeah, why overcomplicate things?
And I totally agree. However it is very handy whenever I get close to 200 lines long method one of my colleagues. I am kind of curious what do you think of rest if it.
As LINQ very much operates with fluent query expressions, lambdas and collections - at least that is the interface used when writing code - I feel that fluent/lambda/List is a collection of concepts very close to LINQ. And I think you make a good point about what LINQ is about: Point 3 in my list would probably be doing very complicated operations in .Select instead of using it to actually select.
I personally don't think so. AWS started its journey in **2006**, Google Cloud in **2008**, and Azure in **2010**. So, Azure is the youngest among them. You have to pay a price if you're late. Google Cloud is older than Azure and still trying to catch it. Azure is doing good, maybe not fantastic, but good. It obviously isn't *losing*; it's *getting tractions,* slowly and gradually...
I use underscores for dependency injected private members and I use whatever the hell I feel like for everything else. I never use "this".
If you dont have medium membership, please use the following link: https://itnext.io/refactoring-the-simple-blazor-mvvm-client-adventures-in-dependency-injection-e9866d194ee9?source=friends_link&amp;sk=10521bc5f6071202f24ae27675483132
Why do you say it doesn't matter? Why is it important to be consistent? I don't find it that difficult to figure out what someone intended even if they use a different style than me. If they started all their private members with the letter G or something, I'd say that matters.
I think 200 lines is way too long
sorry but what does a property have to do with their accessibility?
I mean rest of prefixes. Does make any sense to you use for example "l" and "m" one?
wtf
We did the same but using VS2019 and a [shared .editorconfig](https://docs.microsoft.com/en-us/visualstudio/ide/create-portable-custom-editor-options?view=vs-2019) file.
Have you used it? Works well?
It doesn't la. My comment was sarcastic lmao
nice
Because over a long period of various changes you end up with code inside classes that have different styles and it‚Äôs horrendous to read. The point is that you shouldn‚Äôt have to figure it out. It should just be obvious without having to put an extra thought into it.
I use underscores for private fields. &amp;#x200B; The only reason that I can find now why to use private properties over private fields is executing some logic on reads and writes. If you use them only for pure 'private get' and 'private set' the only thing you gets from it is some overhead
I used to be a big fan of the "this." prefix. However, the underscore prefix is VASTLY more popular, so I switched to that for the sake being consistent with the largest amount of other C# developers. Plus, "this." looks out of place in the default VS color scheme these days, so I'd recommend using the underscore prefix just for that!
It‚Äôs not an ‚Äúacceptable‚Äù practice to use public fields - you‚Äôd always use public properties. So making even private fields properties means that an accessibility change is as simple as changing ‚Äúprivate‚Äù to ‚Äúpublic‚Äù on the property declaration.
Just imagine working with the solution containing 160 projects produced by 15 developers (each of them uses different convention) and time that you spend just trying to figure out what the other developer intended while you debugging
It is interesting, but I am used to seeing more syntax sugar in updates
I've had performance issues related to LINQ. It was used in a critical hot path and created way too much garbage.
Please, oh please tell me this is /s even if you have to lie to me üò±!
For the sake of the entire dev community, can we please not debate this yet again? If there were ever a civil war between factions, this here is the match that started it. Right up there with tabs vs spaces. üòì
I see, I missed the Github issue. The solution there is perfectly ok.
Why our* Blazor Grid Templates Will Make You Question Everything - Telerik‚Ñ¢
What's the new in Update?
Second this. Too many dependencies and I would never want to couple my applications UI up.
For auto generated code, using "this" makes sense in the same way using fully qualified type names makes sense. &amp;#x200B; I'm assuming they didn't qualify their preference with an explanation.
This. FWIW you can download my example here ... [https://github.com/matthewblott/simple\_aspnet\_auth](https://github.com/matthewblott/simple_aspnet_auth)
The answer is in your question. It's easy enough to figure out that DeveloperA prefers ALL CAPS FOR ALL THE THINGS, it's even easier to skip that step if everyone is consistent. Don't add unnecessary cognitive load.
This was my thought when oracle was doing a lot of suing. They were shooting themselves in the foot.
Oh come on. How can we code until we have answers to the big questions? * this. vs \_ * Tabs vs spaces * Opening { on the same line or its own line * Always use {} or skip them on single line statements * Light or Dark theme * Using statements inside or outside the namespace declaration
As a community, we need to get together and assist whichever Open Source project(s) have the best chances of competing with this kind of paid-for option. What are the best Open Source Blazor UI frameworks right now? For example, if I wanted to implement a flexible tree view, what should I use?
I think I'm gonna throw up
I like to use an underscore prefix, despite all the code quality tools saying to remove it.
This is already under way https://github.com/AdrienTorris/awesome-blazor/blob/master/README.md#libraries
mixed mode (AOT and normal MSIL running at the same app) as well was already almost done as said by Dan on the recent ASPNET Community standup.
One advantage so far on my tests projects with Server side is that it's very slick on mobile (as well as being good on battery life) due to not having alot of JS dependencies eating up client resources. One of the good things I'ved discovered so far is that in the future you could in theory easy switch to server side rendering if it detect's somehow you're running on very low end mobile hardware (just swap the script tag to `blazor.server.js` from `blazor.webassembly.js` on first load, provided the app is properly made to support both). So far it's been a blast though, never have I had such ease dev of startup after my years on JS frameworks full stack. On blazor you only download a minimal set of nuget packages as oppossed to MBs of node_modules and use the templates and you're good to go. One thing that really hurts right now is the lack of free 3rd party components like Angular Material (had to go back to manual CSS for now) that I missed on developing using Angular. Though that's hopefully a temporary thing until it gains more developers.
For me it‚Äôs simple: every `private` and `protected` field goes camelCase, and every method (properties included) and `internal` and `public` field goes PascalCase. That means I‚Äôm going to disagree with Unity in its convention (but agree with the rest of the .NET developers anyway).
I'm a sucker for these "awesome-{whatever}" GitHub readmes. Thanks for sharing!
This fills me with Joy, now I'll try to pitch to management on rewriting an internal webapp of ours using Blazor server-side instead of Angular as it's still on the planning phase. The server is just on the next floor so scalability and latency isn't a concern. So far on my side projects it's been a good experience, you can share validations and types finally full stack without a translation layer (like C# to TS build step) which makes it very easy to develop features without having to duplicate alot. There's still the pain point of missing 3rd party components like Angular material, but hopefully it'll be a temporary thing once this takes off and the community matures.
You're joking, but this shit reminds me of JNI: `JNIEXPORT void JNICALL Java_org_example_package_ClassName_MethodName(JNIEnv *env, jobject this, ...);`
I've worked on functions that were 2000 lines long. 200 is too long. 2000 is just a sin.
Eventually you come to a point in your career where you work on a codebase contributed to by many developers. If each used their own personal style the cognitive load required just to understand a single method goes way up. Pull requests get harder to read because every developer reactors each piece of code they touch to match their preferences. That itself opens on more regression opportunities Things that aren't obviously problems to a solo developer become big problems in a team environment.
I have used WSL very successfully with Ruby where dependencies are not natively supported. Best of both worlds.
This is an ad... Does this sub not have any rules?
Thanks for the feedback guys. I used to always use private properties but switched to the underscore convention to follow the approach my team takes. However, began to wonder if the community was moving towards ‚Äúthis‚Äù after watching that channel 9 video I mentioned and reading some Microsoft internal coding guidelines, but those were from 2005 so not truth worthy. I figured maybe ‚Äúthis‚Äù was now the preferred method given TypeScripts popularity. I‚Äôll probably stick to the underscore convention my team and so many members of the community and projects use.
No prob - it's on blazor's official site (blazor.net) at the bottom of the page, either Scott Hanselman or Dan Roth mentioned it in a recent video I was watching a few days ago
* _ * Tabs * Allman-style braces ( { on new line} * Skip for Single-line statements, keep single-line statements brief (Including use of expression bodies) * Dark * Outside of namespace There, that was easy. Anyone who disagrees with the above is _factually wrong_, not a real developer, probably some kind of sexual deviant and almost certainly a communist.
So I've not seen someone say this here, but for me I differentiate private fields and `private readonly` fields. Private fields are `camelCase` and `private readonly` fields are `_camelCase` - this way I can tell from my private fields and my injected services really easily just from the naming (Information that's not visible to the IDE). I don't like using `this.` everywhere, especially as it goes against more recent C#'s focus on brevity and removing boilerplate code. It has its uses and occasionally you'll need to explicitly use this., but those cases are few and far between with the above naming.
Definitely _. It is just shorter. It is not an argument for a small project, but it is a mindset that I'm developing: achieve more with less but keep it understandable.
Yeah seriously. An ad for a terrible company to boot
Jetbrains has a feature request for this for their Rider IDE. This touches on an open source project that may do what I am looking for. However, as others stated on that thread, it's not perfect. &amp;#x200B; [https://youtrack.jetbrains.com/issue/RIDER-4827](https://youtrack.jetbrains.com/issue/RIDER-4827)
Sometimes ReSharper wants me to do something in Lima, but I prefer the readability of a foreach loop, for example.
My team uses the underscore, so that's what I use. Another team used the letter m... so mPrivateMember which I actually liked better for stylistic reasons. In the last 10 years I've seen the use of this go away... maybe because it's more code for no reason? I think the main thing is to use a convention that let's you distinguish between local variables and class variables. Good post!
‚ÄúRolling your own‚Äù would be recreating EF Identity, not a creating jwt token service.
I second that. I've been using the Infragistics suite of components back in the early days of .net Framework 1.1 Ever since I try to avoid these monsters like the devil will avoid holy water.
How is the performance? Has it gotten any better? The last time I looked at blazor performance was pretty bad.
What is wrong with Kendo? It works fine as long as you don't use those messy MVC wrappers and call it directly.
We call it NoKenDo UI
sounds like you're getting closer. how many sites are we talking about?
Kendo is like a bootleg jQuery UI and it's stuck in the same century. Many of its components easily break at the slightest design change and are very difficult to use in any kind of non-trivial layout. Similarly to jQuery UI, its a library that seems like it was built once and then never again updated/maintained. We worked on a large project that relied on it and it was basically impossible to replace KendoUI with anything else because it was so tightly ingrained in the application's design. Redesigning the Kendo components was just asking for trouble.
put a space after line and close out your parenthesis, you monster.
Telerik is awful.
OP is a telerik shill. Look at the post history. This is an ad and mods should delete.
I'm sure all of the delegate calls it uses weren't helping things either. Every time you see a `=&gt;` it means another function that can't be inlined.
Those would be in Visual Studio updates, not the .NET Framework.
Maybe that is the issue, you built the entire application on Kendo. We only use it to enhance it: a grid there, a multi-select dropdown there. But never the entire application, not the data binding system.
&gt; For example, if I wanted to implement a flexible tree view, what should I use? You should create your own component and reuse that over and over again.
So far I think, without MS our IT world would not come to this stage. They make the world very easy to use a computer for newbies. Though it's about five years I am not using MS product except Photoshop and VSC.
NEVER! ALL PARENTHESIS SHALL FOREVER BE OPEN!
I really appreciate your wonderful comment, cheers mate!
TFS 2018 On Prem (Azure DevOps is the fancy new name for it) using Git repos
I know the Angular style guide says opening bracket on the same line, and the Resharper styling for C# says opening bracket on the next line.
There is a *ton* of fixes. Looks like MS have put a lot of work into this.
Is Rails on Windows still handicapped? I recall there were issues with it in the past.
Long $MS
Not entirely sure as I haven't tried Rails on Windows in some time as well, but with WSL it could be pretty mitigated at this point. Also haven't had much time to investigate that.
I prefer fully qualified var names: pvt_ro_str_myString JK, I'm not Satan I do prefer this. though. The _ just looks goofy to me though. I will conform to whatever standard the team has been using, however.
&gt; but as it's cooperative scheduling you could have a fiber be less cooperative and bugger everything up. I'm still working on whether that's the case or not. It depends on the underlying implementation, and where it preempts fibers. If you check what golang does with its "goroutines", they are preempted at defined places, such as IO calls, or even local function calls. See here for more details: https://github.com/golang/go/issues/24543
i think for me the issue that comes up sometimes is specific linq queries work and are efficient but have shit for readability. Sometimes when working on code that is maintained by a large group of devs if the comments take more lines than the linq query to make it understandable it might be worth converting it to something easier to parse
Well the entire application was forms. It was an insurance claims web app where 90% of the views were forms with complex questions and inputs.
Yeah now that I look at it it's kind of obvious. Mods are napping smh.
I will peruse this evening :) Thank you again :)
 private string _myName; private readonly string _yourName = "Larry"; protected int LocationId { get; private set; } public Guid PublicId { get; set; } The best reasoning I've heard is to prefer properties over fields because they're easier to refactor (add logic) and most serializers ignore fields by default.
Also using DBeaver, really happy with it for Postgresql. However, the Azure Data Studio w. Postgresql extension sounds like it's worth looking into.
Yes, just like me. When I'm creating, for example a dictionary I type Dictionary&lt;string, Person&gt; f_System_Collections_Generic_Dictionary_of_System_String__Person_personsMap = new Dictionary&lt;string, Person&gt;() I like qualified names so I know the correct implementation I'm using
Yeah, I've made monsters. Not fun to maintain later. Now I follow KISS, "Keep it simple stupid" ie short and sweet.
I like Roslyn conventions: _ (m_ for Visual Basic) for private fields, protected fields are almost always a no-no, use properties instead s_ for private static fields camel Case for locals (variables and functions) Everything else goes PascalCase For 'this' I have a rule: Only use 'this' if you're on a partial class and the member you're referencing is on another file
With a good CSS framework, its mostly just the lack of animations that really hurts.
The closest thing to "too much linq" I've ever written was for a train repair invoice auditing module we were writing. It would search through repair records looking for valid wheel set repairs ie an axle, two bearings compatible with that axle, and two wheels compatible with those bearings. It was honestly pretty wild to do in linq but this was shortly after I fell in love with linq and was doing everything thing in it.
Private fields I always start with an _lowercase, methods _capital, and readonly/const _ALLCAPS.
And here I am using `this._` like some kind of heathen.
Instead of using .config directly, pass connection string as argument.
Backup before you install! I ran the installer and it started flashing the silly "Hi" screen over and over after it rebooted. I eventually had to power off my machine and reboot several times. It appears to have installed (Visual Studio sees it) but the installer is buggy.
You know, I could buy into this. Functionally, though, it'd have minimal impact, for me. I can't remember the last time I used a private field that didn't fit into one of two categories: 1. Injected dependencies via constructor. These are almost universally private readonly. 2. Backing fields for properties. Generally, these show up in DTOs or "anemic" domain models (which I don't consider an anti-pattern, but that's worth its own thread) and most often auto-properties. Even so, it's not like the underscore is a big deal. &amp;#x200B; Really, though, I consider "this" to be noise. To me, the option isn't "this.myVar" or "\_myVar". It's between "\_myVar" and "myVar". Given those options, it's not really a choice because I want to avoid collision between parameters, local variables, and private fields.
I agree, I often find that private fields on their own have little use these days. As you say they're useful as backing fields for properties and that's about it (aside from injected dependencies).
Heathen's can be both sexually deviant and developers who make bad lifestyle choices, so ... &amp;#x200B; ;p &amp;#x200B; I might be thinking of Heathers which is something totally unrelated, although Winona Ryder does knit and that's basically programming.
And while I'm in the emotional place, "my . disregarded" suggests we need to get you into a programme for unloved variables. Places are tight, so be as variable as necessary to secure a place :)
I mean rewriting an entire ecosystem that's been around for over a decade, from the ground up, to work on platforms it was never intended _and_ to throw in performance benefits _is_ going to take time. However _plenty_ of people are using .net core and have been using it for a while now, with little issue. core has surpassed the full framework in many ways now, with just a few edge-cases around that make it still worth using. However, keep this in mind - .net core is not tied to your system in any way like the framework is. That means it can innovate and evolve with every update, unlike the framework which _must_ adhere to strict backwards compatibility.
The... Then stop using medium?
.Where() is useful with collections.
I do publish in Visual Studio and choose the Web Deploy Option that uses FTP.
If you use query syntax, any LINQ is too much LINQ. Otherwise, ish. If I see a LINQ chain more than, say, 5 functions long, I start thinking whether it would be clearer to use a foreach or a helper function for some parts of it. That being said, I never use LINQ to SQL as it is way too easy to shoot yourself in the foot and load the whole table into memory.
LINQ is definitely not high performance. It's perfectly fine for the vast majority of things, but when you need to minimize run time you probably want to be `for` looping over an array - looping over an array by index in a way that the compiler doesn't need to perform a range check is the fastest way to iterate items (presuming you don't need to allocate an array that you wouldn't otherwise have to).
&gt; it is way too easy to shoot yourself in the foot and load the whole table into memory Or just disable in memory evaluation so you get an exception if you accidentally do that. EF is also pretty dang good at translating LINQ to SQL, considering. EF Core is even better at splitting apart bit that can and cannot be performed in the DB. Also OP seems to be speaking about LINQ generally, not specifically about LINQ to SQL translations.
You can publish net core with either self contained framework, or framework dependent. Self contained includes the framework with the publish output so you can run it on any machine, regardless of net core is installed. Framework dependent doesn‚Äôt include the framework, and requires the framework be installed on the target machine. Self contained would be larger. Maybe it‚Äôs publishing both types?
When does that happen? I've been programming for a very, very long time and I've worked with 5-15 people on a codebase for ten years. How many is a lot of people? I find people using bad design far more problematic than a simple naming problem which can be easily figured out. In general, having conventions is nice except I'd say most of the time the entire team doesn't really agree on them so it's easier for some people and harder for others.
I agree that reducing cognitive load is good. The casing of a variable is not really cognitive load though. If that's a major hurdle for you, that sort of indicates you've worked on either some very simple applications or some overly complicated ones which could benefit from design constraints instead of naming constraints.
I don't really have to imagine. I've worked on solutions with a lot of projects. You know what? The solution didn't NEED all those projects. It was a poor design. The project should not have had 160 projects because that would be a very poor design decision IMO. Better to focus on fixing the design rather than variable names.
Wait wait wait.... he was talking about dependency injection which should pretty much always be private fields if you're doing it properly... this is why I'm confused by what you said.
I'm not signed into Medium and I could read the whole article (which is great btw), am I missing something?
A lot of code is horrendous to read even without following conventions. I guess my point is that the variable name case has very little to do with horrendous code.
I don't use underscores *or* this. Should I change?
I think you‚Äôre confused... dependency injection says nothing about how you actually store dependencies that get injected. Also, I‚Äôm not sure why you‚Äôre specifically hung up on the difference between private fields and properties...an auto getter only private property is virtually syntax sugar for a private readonly field. There is no practical difference between the two at all.
Constructor injection is the "acceptable" way of doing DI. That pretty much means you'll be using a private member whether its a field or property. Your initial comment made it sound like you'd use a property instead of a field to solve some accessibility issue which I (still) don't understand what issue that would solve. Maybe I read your comment wrong?
A linq statement should be more readable. Especially if you do it the point free way where you replace the lambda call with a descriptive function name. Ex. var discountedProducts = products.Where(ProductHasDiscount) Instead of var discountedProducts = products.Where(product =&gt; product.IsDiscounted) That's a trivial example but when it comes to larger linq statements it's very helpful. Anything can happen in a for loop. This way it's very declarative and you dont have to trace through what's going on. You could also reuse functions and compose them. It adds another layer of domain documentation and you dont have to go around changing a bunch of logic if the implementation changes. You just have to go change that one function.
How are people‚Äôs experience with Microsoft Learn? Any good?
It's actually pretty good. I've used it for some azure services and I find it useful
I think visual studio has something almost as good built in
I'm aware of the filter in the solution explorer but it's quite a bit more clunky and more steps compared to with Resharper where I just hit ctrl+t and can open up a file in a second.
ctrl+t works just fine in vs 2019 (and i am pretty sure it was in 2017), without resharper
Hmm, wonder if my keybindings are messed up since I previously had resharper enabled. I need to download 2019 and try it out.
I believe EF Core 3 is addressing this.
In VS 2017 and 2019 I use a "Go To All" feature that I think works similarly (I've not used ReSharper personally but I believe it's the same idea). I have this mapped to ctrl+t but can't remember if I had to set that shortcut up myself or not. Hope this helps?
Ctrl + , That's a comma there fyi, is the default key mapping for the build Vs Go To all. It's pretty good I think essentially the same as the R# feature
Without consistecy you lose intuitivity, this is one of the reason why PHP was (is) hated. I do agree with you that there are bigger issues, but failing to realize any importance in being consistent is an issue as well. I would hate to work on such a code base, it's a clear smell and I wouldn't expect anything better from the reset of the code. Yes here we are talking about fields, but if there is no consistecy with them, then there is probably no consistecy with public members / API and that is truly a nightmare to work with... I'm honestly not sure why you're debating over this... it is generally known that naming conventions are important, you can find books that cover this topic.
Yeah this is what I was thinking of, but I forget the name of it or the default key binding.
Nothing faster than deploying to azure from visual studio. I wouldn't recommend it long term but it takes 5 minutes.
Git using both BitBucket (on prem projects) and Azure DevOps (cloud obviously)
I've read those books. I'm not against this but it's at the bottom of a very long list of things that matter to me I guess. It just feels like one of those situations where it's such a simple thing to fix it's not really worth even talking about. Just rename the dang thing with ctrl+r+r and be done with it if it's at all confusing. It would be nice if our industry could settle on a convention rather than leaving it up to each individual project/team. It's more difficult to switch between projects and remember conventions than just following a general convention I guess.
Not find text from index, at least not yet. I find my self using that feature at lot.
Makes me wonder what the convention is for the minor versioning. 4.5, 4.6, and 4.7 were HUGE and 4.8 is like "meh some performance and bug fixes".
There is "resharper" key bindings set in Visual Studio.
Lowercase.
I agree with most of the comments here. Branching in git is such a bliss compared to SVN. One feature that git has that is almost impossible to do with SVN is reviewing the history and comparing two arbitrary commits/branches. With SVN you need to gather that information from the server and worst, if the two revisions you want to compare are far apart, SVN needs to gather all delta in between and reconstruct the history of changes. In git, it doesn't matter: comparing two r√©visions just need the content of both, regardless of what happened in between (or how far they are from each other). When doing history digging (code archaeology) to figure out when a breaking change happened, the ability to quickly compare any revisions is extremely helpful. I am currently working with a 14-year old code base with, as you can imagine, a lot of legacy and debatable choices that were made.ocer the year. There are in total more than 200 000 commits. Even so, "blaming" a file and looking at the history takes only a few seconds. Last year we moved from SVN to git. Before that, blaming a file are comparing versions was impossible: the SVN server would either take minutes to compute the history or just time out.
About two dozen, so nothing crazy. At this point, I'm just going to continue doing it manually.
40 seconds to do an export of 25k records? If query is already fast and joins perform well. there is no n+1 problem and materialization of SQL result is fast, what would help is to identify lookups and build maps/lookup dictionarties first and then iterate over objects while finding relevant dependent entities using only these lookups.
&gt; s_ for private static fields I don't feel that's a distinction worth making and you're falling back into the problems that Hungarian Notation brought us.
&gt; I disabled resharper yesterday because it was really bogging down my VS That's why I've moved over to JetBrains Rider :)
&gt; If that's a major hurdle for you, that sort of indicates you've worked on either some very simple applications or some overly complicated ones which could benefit from design constraints instead of naming constraints. &amp;#x200B; Where did you pull that crap from?
Im disturbed by the casing of class members in those samples....
Search for gotoall in the keybind configuration menu. Other commenters are right. It entirely depends on your keybind preset. The vs default for is Ctrl + ,
I am not aware that resharper has any kind of boxing analyzers and I doubt that there is one.
I loved EF for a long time. So easy, so good at translating my meaning from C# into the database language, except when it didn't, but I found workarounds... until I couldn't. Eventually I hit a wall. I have a huge database and more and more, I need almost every query to do what I want in ways that I can control in the database's language but can't express in EF. It's become the rule rather than the exception when the tables or indexes involve more than a few million records. Now all of what we wrote in EF has become a burden. Maybe it was the right thing to do because we grew functionality faster, but now that it is expected to scale, not so much. I still love the idea, but it doesn't perform when pushed harder. Just a warning. If an EF query against a large data set seems work well, be wary about extrapolating that interpretation any further than you have actually tested/proven.
Nice tutorial. I didn't know you can set the state of the entity object after using AsNoTracking().
Your examples are fine, but I don't think you have yet run into what OP is talking about. Resharper will will sometimes want you to optimize into seemingly gibberish. I can't think of any examples right now, but If you do that shit during a code review, I'll tell you to expand that shit back out. &gt; Anything can happen in a for loop. This way it's very declarative and you dont have to trace through what's going on. Now we hate for loops? Maybe sometimes I want to debug/step through the iterations?
Yeah, we should refer to this problem-area as "collection extensions" or something.
I host a personal bot on GCE always free tier. I checkout the git repo and just run [this](https://gist.github.com/pauldotknopf/fe56037a96879652d9f2cee829a518a8) script. To deploy changes, I log into machine, update git repo, and restart docker container.
&gt; until I couldn't What have you run into that `FromSql` couldn't get you through?
I highly recommend to read about DDD because it so true to OOP.
https://www.gameprogrammingpatterns.com
So you want to learn OOP with an emphasis on .NET in particular. There‚Äôs a few good courses around particularly on Pluralsight (I‚Äôve never used them personally because I learnt OOP as part of my Uni course). My advice would be this - and please, don‚Äôt freak out - forget the concepts of functional programming and C when learning OOP. That doesn‚Äôt mean forget everything you know about programming in general the core concepts remain the same, it‚Äôs just a big paradigm shift.
If you think .NET object names are long, you will weep when you look at Java. Here‚Äôs an article describing the 4 concepts of OOP (abstraction, inheritance, polymorphism, and encapsulation): https://www.c-sharpcorner.com/UploadFile/mkagrahari/introduction-to-object-oriented-programming-concepts-in-C-Sharp/ If you‚Äôre looking for a good book on C#, Jon Skeet‚Äôs latest edition (4th ed) of C# In Depth just came out and I think it‚Äôs a great book. It might be a little heavy for what you‚Äôre asking for, If you‚Äôre more comfortable with functional programming, you could try out F#. It tries to enforce that paradigm and does a decent job within the framework. I don‚Äôt think choosing C# or F# matters. It‚Äôs all preference. Here‚Äôs the starter article for F#: https://docs.microsoft.com/en-us/dotnet/fsharp/get-started/ You mentioned you are familiar with procedural code. OOP is procedural on steroids. Your routines and subroutines are encapsulated in classes. You can still follow the method of breaking down a problem into steps, there‚Äôs just more of an ability for encapsulation. Here‚Äôs one last article to help explain the difference: http://www.ctp.bilkent.edu.tr/~russell/java/LectureNotes/1_OOConcepts.htm And here‚Äôs an implementation of least squares in C++ and C# of you want to check it out: http://www.alglib.net/interpolation/leastsquares.php
I completely understand what you're saying. I took FORTRAN and Pascal in university and had the same difficulty wrapping my head around object-oriented programming, but now it seems a natural way of thinking to me (I've been doing C# for years). Maybe start with the Wikipedia article about OOP to understand the paradigm: [https://en.wikipedia.org/wiki/Object-oriented\_programming](https://en.wikipedia.org/wiki/Object-oriented_programming) I haven't started with F#, but I expect that will be a similar struggle to going from procedural to object-oriented. F# is a **functional** programming language, and I tend to believe that it has more support in academia than anywhere else. So maybe F# will be more appealing to you than C# for that reason. See [https://en.wikipedia.org/wiki/Functional\_programming](https://en.wikipedia.org/wiki/Functional_programming)
For your purposes you can pretty much ignore the OO for now. I know you want to learn, but you might find it easier to get some code running, develop some familiarity with the tools and then incrementally figure out the OO stuff. Right now you can just bung everything into one class and add methods to do what you want. If you start VS and pick "console application" you basically get what you want here. &amp;#x200B; If VS is a bit heavy for you, give VS Code a shot. It's light and fast. Like everything it has a learning curve, but it sounds like you've figured out how learning works :) &amp;#x200B; Learning resources: Microsoft have something called [Dev essentials](https://visualstudio.microsoft.com/dev-essentials/) This will give you access to all the tools you need, and it will usually give you between one and six months of PluralSight for free. PluralSight provide online training courses for pretty much everything. There will be something in there for you. &amp;#x200B; F# is a functional language, it's worth looking into, it is popular in finance and academia. All the .NET languages compile to the same underlying and compatible framework, so you can write something in F# and use it in a C# project. &amp;#x200B; Procedures still exist, but they exist in little communities called classes. You sort of allude to one good example in your text. Tiny teaser: A class is a definition, an object is an instance of that definition. More fun, the definition can include static members so you don't need to create an instance. Ignore most of that :) When you do Console.Writeline("...") you're just calling a method. This can be translated as calling a procedure that lives in the hamlet of "Console". &amp;#x200B; C# is technically an OO language but over the last decade or so it has absorbed features from all paradigms. Further, good practice in other paradigms has been adopted as a convention for good code in C#. This makes it quite an exciting language to be working in but also quite daunting to new comers. &amp;#x200B; So circling round. Just try and hack out some code without worrying about whether it is well structured and have a poke at dev essentials for free training. &amp;#x200B; Good luck.
As far as OOP is concerned, the main goal is to remember that an "object" is only useful if it can be reused, so people try to design them in a logically reusable way. I think it would be useful for you to look at some code and ask why it was set up that way. Interacting with another person who knows what they're doing would probably be more beneficial than trying to find the exact perfect thing to read.
&gt; For your purposes you can pretty much ignore the OO for now. This.
My co-author and I actually debated whether or not to include that part. Glad you found it useful!
I haven't run into it recently because I split each transformation up. There's lots of linq and morelinq functions that people dont use and try to just jam it into one select statement. If you split up the linq statements then it becomes easier to debug as well. Theres extension methods you can create to debug the output easily. For loops are bad. The only reason to use them would be in high performance scenarios. If you're just doing a crud app like most of us are, then linq should be used in most cases.
Dear, OP. 1. You can find procedures in some OOP languages but often they are actually METHODS of some implicit module-level (hidden) class 2. So, class is a bunch of relations (relations) of some semantical term/entity (class itself) with another ones. Sometimes in can have a state. Sometimes it's only a state (data only). But it's always a term/entity. For example, the term a "matrix" is an algebraic structure (set of objects, with some properties and operations), so it makes sense to make matrix as.. a class. Alternative is a module: for example Ada supports classes as modules, SML uses modules for this, but... Ocaml allows you to have modules and classes. Classes are smaller "module", a term/concept/notion/idea. Better to have classes and to pack them in modules - it's more practical approach. 3. You can try also VB# - it's OOP, but his syntax may be more close to your background. 4. IMHO you have some psychological unwillingness to accept the "new world", and you need to find good sides/features, attractive sides of DOTNET technologies, of the new Microsoft vision. It was the same as for me. I can give you some ideas. If you are old-school guy then you should have good experience with Unix shells. Do you remember all those tricks with processing of data in text representation? For example, when you need to select one column, but columns can have spaces :) Try PowerShell. It's super sexy and very attractive. And it's based on .NET (today NET Core) and it's ideas: you always see its classes and properties, all is object, all has type, all is structured, all can be identified, but you don't lose flexibility of usual shells. It's rightly done Unix shell. And yes, it works on Linux, Mac, etc. Try to find something which is close to your ideas about rightly done things. 5. I knew several old-school programmers (2 women, 2 men) with age about 60+, they all were switched to C# and .NET, they bough several books, with CD-ROMS (it was about 10 years ago), they learned it and as I understand they like it. I think modern Microsoft technologies looks very rightly done: you have very useful things and instruments. But I am agree with you: .NET has some lack of libraries, for example, JVM has more libraries, it's true.
Long names are good for maintenance, especially in business oriented software. Sure am alternating least squares algorithm will never (?) change... but that's more the exception than the rule in business software. Bugs and enhancements are the rule and any particular bit of code will get maintained 20 or 30 times (or much much more) over the years. Having good quality names and comments makes these future efforts much easier and faster. And fast can be important. If you get a support call at 3:00am because the overnight processing is crashing you really really want simple to understand code (especially if the overnight window is closing fast... keeping users locked out in the morning is bad, sometimes very bad). This sort of "simple to understand code" goal is one reason Google invented the language GO. Not the whole reason... just one of the primary ones. So no generics, no operator overloading, etc etc, because when these sorts of language features are heavily used it becomes very hard to quickly figure out what is going wrong with code you've never seen before. And procedural code... well... it can be a godsend in a way. Nice simple straight-forward, and doesn't require an extra large black coffee to understand. Trying to figure out "where the heck does such-and-such come from and why is it null" at 3:00am really really sucks. So... that's one set of reasons why non-academic code is so different. /ps Visual Studio can be intimidating at first glance. But spend some time with it and you may learn to love it... especially the debugger.
I'm not looking to analyze boxing just define rules around methods that use it. So, maybe define a rule to say that, for example, if there is a non string inside string.format(), .ToString() must be used.
I think most teams will gain by following the advice presented in the article, but I have to ask to what degree are you convinced of the personality traits table from point 9?
I just want to say I admire the fact you gave arguments for an initially down-voted opinion.
What's wrong?
Why do you start with the example that makes me want to take you to the coffee station for a private word? &amp;#x200B; It's pretty cool. I often come across little things I should have known but didn't when I read these :)
Public member fullAccess instead of FullAccess
Oh, I missed that one :) When writing for my blog I don't really have resharper or stylecop to fix what I miss :)
Every personality test is always going to represent a narrow view of reality. But every person is always going to prefer a certain personality trait. If you can figure that out, you have an opportunity to change your communication to that trait. Eg. for me, I have to explain all information, for an observer, to appreciate my advice, where an inspirer, only need the ‚Äúidea‚Äù. Both personalities are valid both expose different traits.
I wish but we rely quite heavily on TFS. I didn't think Rider had as food of TFS integration as far as code reviews and the like.
Well tbh, most of programming today seems to be some sort of cult, cargo or otherwise.
Hey, dont sweat it, just kidding. &amp;#x200B; &amp;#x200B; Or am I...?
Relevant: http://programming-motherfucker.com/
Yes. But that's what the client was told they needed to test.
First, that doesn't really count because you _are_ executing raw SQL, which was kindof my point. I could go into other hitches and solutions but meh.... I still like EF, I just use it with a little more skepticism where there might be performance concerns.
I don't know about DI because DI's use cases seem to be comparably easy to understand. At least from my experience working with people. I can see it happening with other patterns though.
DI certainly isn't the answer to every situation. But as I make that statement I think about how Inheritance is similar. Certainly many of us have used it when we shouldn't. Recognizing the patterns in problems and recognizing the patterns with which to build your solution is a core skill that can save you countless hours of work. Many developers miss the second part of it and cargo cults are born. I'd actually say that's the norm. That said, DI is Jesus, get out.
I see it being added to projects where it doesnt belong. Second only to microservices for being a solution to problems we dont yet have
&gt; gives you a kind of design/compile time validation of dynamic SQL that you otherwise wouldn't get until runtime There's other ways to achieve that as well. I generate SQL builder helpers with a template off of my DB and use those in code to create raw SQL for micro-ORM usage. If we neglect to update a SQL after making a schema change, the compiler errors in many cases. &gt; That's what made it so attractive Personally, I think EF's strong point is managing object hierarchies. Micro-orm multi-mappings still aren't as nice as selecting related objects and collections with EF, and of course EF is quite helpful with change management. We also have a rule in our shop that devs must verify generated SQL for all new EF queries and include it in pull requests, unless it's an obviously simple selection/projection, or you can point to a sufficiently similar query that's already been vetted. Even though EF is miles ahead of any other LINQ to SQL translation, it's still too much of an unpredictable black box not to.
Seq?
I have managed to get the scenario that you described above working using the default [ASP.NET](https://ASP.NET) Core Web Application Template [as described in the official docs](https://docs.microsoft.com/en-us/aspnet/core/tutorials/razor-pages/razor-pages-start?view=aspnetcore-2.2&amp;tabs=visual-studio#create-a-razor-pages-web-app). &amp;#x200B; Once the project had been created using the template the only modification that was required was to add `"{slug?}"` on the same line as the `@page` directive inside the `.cshtml` file so that it looked like `@page "{text?}"`. This means that the page takes and optional parameter with the name of "slug" and is described in [the routing docs for Razor Pages](https://docs.microsoft.com/en-us/aspnet/core/razor-pages/razor-pages-conventions?view=aspnetcore-2.2#configure-a-page-route) \- this parameter name should match up with what you have called your parameter in your `OnGetAsync` method, not further modifications should be required in your case as strings are nullable by default. &amp;#x200B; I hope this helps and in the future I would suggest posting questions about implementation specifics on [StackOverflow](https://stackoverflow.com/) as you're much more likely to get a timely response as well as wider audience.
Its the same madness I saw when mock objects were first introduced. I was painfully part of a 32 man-month project where is was deemed *every* class in the entire project should also have a mock object to "make testing easier". There was more code written to manage the mocks + interaction + configuration than there was code implementing customer requirements. God help the people who had to maintain it later on.
&gt; SQL builder helpers with a template off of my DB... create code... compiler errors in many cases.... Do you have a link or something where I can read more about this approach or see examples?
&gt; I am inclined to think a chunk of fellow devs out there implement Dependency Injection in a Cargo Cult fashion. Ok, so what applications do you see it used where it serves no purpose, and seems to be there just because it's common? It seems like it would be a very simple application to not derive some tangible benefit from DI. I think the bar where you hit "this is useful now" is so low with DI that it's not cargo cult to see it used widely.
Look into Azure Application Insights
Nope. I think it is very useful most of the time. Both for tests as well as helping to build a good seperation of concerns. It is not required all time, nor is it well implemented most of the time. I agree that with IOC containers people can be cult like but 99% of the time only the basic features of a container are used. All containers support that use case (I would hope anyways)
Sometimes, yes. Sometimes, no. Use it where you have a problem that it solves. Otherwise, don't. We all have enough real problems to solve, so we should focus on solving those ones instead of problems that we don't have. Not saying that all uses of DI are superfluous. Quite the opposite -- in places where I applied DI to actual problems, I was pleased with the outcome. Especially, might I add, after changing it from poor-man's DI to using Ninject. But I have also used it to solve problems that we didn't have. The resulting application is, in my opinion, worse off as a result.
Hmmm... With git, I still rely on GitKraken (an external git GUI tool) when using Rider. Rarely, I'll switch branches within Rider/VS instead of using the CLI (git bash) or GitKraken. But I don't know if there's a good external program for TFS that is not Visual Studio. (Or maybe VSCode plus a plugin.) And if there's no web UI for TFS code reviews, that's another difficulty (we're a Github shop).
As someone who's been doing this for 20 years, I think a majority of programming work is a complete waste of time.
Yeah, App Insights and a custom event is a great way to track this. You can send kvp properties for each event too, and these events are queryable. https://docs.microsoft.com/en-us/azure/azure-monitor/app/api-custom-events-metrics
I‚Äôd probably go with a dead simple log table if you‚Äôre already using a database
&gt; Anyone else feels DI becomes a cargo cult sometimes? No. It's a really useful design pattern for statically (and even dynamically) typed languages. Do you need to use a DI framework every time? No, but they're helpful.
I did believe that for a long time and I avoided it like the plague. It was only until a colleague showed me how it actually simplified my code so much that I finally switched. I love it now! Not a cult :)
It's all home grown, and I haven't seen much that I can recall over the years for like blog posts on the idea. I've been using T4 templates for a long time. Prior to that it was some template generator tool like MyGenerate or something.. it's been over a decade. T4 editing experience sucks hard, but this started from the Subsonic templates. It's an old ORM from the pre-EF, Linq2Sql days that had a brief flash of popularity (and thanks to a previous dev thinking it was cool, we're still saddled with it a dozen years later). Anyway.. they've undergone an awful lot of changes, but in there you can get a good starting point - including inspecting the project to grab a DB connection string, which is a bit tricky to figure out. Here's an example sql builder helper generated from a template that reads the DB: public partial class Address : SqlTable&lt;Address&gt; { public Address() : this(null) { } public Address(string qualifier) : this("Address", qualifier) { } public Address(string tableName, string qualifier) : base(tableName, qualifier) { AddressId = new SqlColumn("AddressId", Qualifier); StreetAddress = new SqlColumn("StreetAddress", Qualifier); Locality = new SqlColumn("Locality", Qualifier); Region = new SqlColumn("Region", Qualifier); Postcode = new SqlColumn("Postcode", Qualifier); Country = new SqlColumn("Country", Qualifier); } public override Address Alias(string qualifier) =&gt; new Address(qualifier); public override Address AltTable(string tableName, string qualifier = null) =&gt; new Address(tableName, qualifier); public SqlColumn AddressId { get; } public SqlColumn StreetAddress { get; } public SqlColumn Locality { get; } public SqlColumn Region { get; } public SqlColumn Postcode { get; } public SqlColumn Country { get; } } And that might be used like this.. `Sql` there is the builder from PetaPoco/AsyncPoco, though this particular query is actually used with EF and `.Include` to retrieve a list of full object hierarchies: static public Sql AccountsById(IEnumerable&lt;int&gt; accountIds) { var a = Db.Main.Schema.Account.Alias("a"); var ids = new IdListTable("@0", "ids"); var sql = new Sql() .Select(a._Star) .From(a) .InnerJoin(ids, accountIds.ToTableValuedParameter()) .On($"{ids.Id}={a.AccountId}"); return sql; } Here's another usage example: static private Sql LocationsPerFeedHistory(DateTime? start, DateTime? end) { var t = Db.Logs.Schema.Feed.Alias("t"); var lc = Db.Logs.Schema.LocationCode.Alias("lc"); // truncates a number of milliseconds to the day - 00:00:00 var dailyId = new SqlExpression($"((({t.Id}/4194304)/86400000)*86400000)*4194304", "Id"); var sql = new Sql() .Select(t.ResourceId, lc.Code.As("LocationCode"), t.IpAddress, dailyId, $"SUM({t.Hits}) AS {t.Hits.ColumnName}") .From(t) .InnerJoin(lc).On($"{lc.Id}={t.LocationCodeId}") .Where($"{t.LocationCodeId} IS NOT NULL") .Between(t, start, end) .GroupBy(t.FeedId, lc.Code, t.IpAddress, dailyId.Expression); return sql; } And here's base classes: public interface ISqlTable { string TableName { get; } string Qualifier { get; } } public abstract class SqlTable&lt;TSqlTable&gt; : SqlTable where TSqlTable : SqlTable&lt;TSqlTable&gt; { protected SqlTable(string tableName) : base(tableName) { } protected SqlTable(string tableName, string qualifier) : base(tableName, qualifier) { } public abstract TSqlTable Alias(string qualifier); public TSqlTable UnAlias() =&gt; Alias(null); public abstract TSqlTable AltTable(string tableName, string qualifier = null); } public class SqlTable : IEquatable&lt;ISqlTable&gt;, ISqlTable { protected SqlTable(string tableName) : this(tableName, null) { } protected SqlTable(string tableName, string qualifier) { TableName = tableName; Qualifier = qualifier; } public string TableName { get; protected set; } public string Qualifier { get; protected set; } public string _Star =&gt; string.IsNullOrEmpty(Qualifier) ? "*" : $"{SqlReservedWords.Quote(Qualifier)}.*"; public string NoLock(params string[] otherHints) =&gt; ToString() + " WITH (NOLOCK" + (otherHints == null || otherHints.Length == 0 ? "" : ", " + string.Join(", ", otherHints)) + ")"; public string With(params string[] hints) =&gt; ToString() + $" WITH ({string.Join(", ", hints)})"; static public implicit operator string(SqlTable sqlTable) =&gt; sqlTable.ToString(); public override string ToString() =&gt; string.IsNullOrEmpty(Qualifier) ? SqlReservedWords.Quote(TableName) : $"{SqlReservedWords.Quote(TableName)} {SqlReservedWords.Quote(Qualifier)}"; public override int GetHashCode() =&gt; ToString().GetHashCode(); public override bool Equals(object obj) =&gt; Equals(obj as ISqlTable); public bool Equals(ISqlTable other) =&gt; other != null &amp;&amp; ToString().Equals(other.ToString()); } public interface ISqlColumn : ISqlExpression { string ColumnName { get; } string Qualifier { get; } } public class SqlColumn : SqlExpression, IEquatable&lt;ISqlColumn&gt;, ISqlColumn { public SqlColumn(string columnName, string qualifier = null) : this(columnName, null, qualifier) { } public SqlColumn(string columnName, string alias, string qualifier = null) : base(string.IsNullOrEmpty(qualifier) ? SqlReservedWords.Quote(columnName) : $"{qualifier}.{columnName}", alias) { ColumnName = columnName; Qualifier = qualifier; } public string ColumnName { get; protected set; } public string Qualifier { get; protected set; } public override SqlExpression As(string alias) =&gt; alias == ColumnName ? UnAs() : new SqlColumn(ColumnName, alias, Qualifier); public override SqlExpression UnAs() =&gt; new SqlColumn(ColumnName, null, Qualifier); static public implicit operator string(SqlColumn sqlColumn) =&gt; sqlColumn.ToString(); public bool Equals(ISqlColumn other) =&gt; other != null &amp;&amp; base.Equals((ISqlExpression)this); } public interface ISqlExpression { string Expression { get; } string Alias { get; } SqlExpression As(string alias); SqlExpression UnAs(); } public class SqlExpression : IEquatable&lt;ISqlExpression&gt;, ISqlExpression { public SqlExpression(string expression) : this(expression, null) { } public SqlExpression(string expression, string alias) { Expression = expression; Alias = alias; } public string Expression { get; protected set; } public string Alias { get; protected set; } public string Descending() =&gt; Ordered(SortOrder.Descending); public string Ordered(SortOrder sortOrder) =&gt; sortOrder == SortOrder.Ascending ? $"{Expression} ASC" : sortOrder == SortOrder.Descending ? $"{Expression} DESC" : ToString(); public virtual SqlExpression As(string alias) =&gt; alias == Expression ? UnAs() : new SqlExpression(Expression, alias); public virtual SqlExpression UnAs() =&gt; new SqlExpression(Expression, null); static public implicit operator string(SqlExpression sqlExpression) =&gt; sqlExpression.ToString(); public override string ToString() =&gt; string.IsNullOrEmpty(Alias) ? Expression : $"{Expression} AS {SqlReservedWords.Quote(Alias)}"; public override int GetHashCode() =&gt; ToString().GetHashCode(); public override bool Equals(object obj) =&gt; Equals(obj as ISqlExpression); public bool Equals(ISqlExpression other) =&gt; other != null &amp;&amp; ToString().Equals(other.ToString()); }
I haven't read any of the books, so I'm not sure how qualified I am. If you are going to start work on a big .NET project, I would advise the "ASP .NET Core In Action". It seems like the other two books have overlap with general programming experience, while that book has a lot of advice specific to the .NET frameworks. &amp;#x200B; Reading books is such a wonderful approach to starting a new job, and I'm sure you'll do a wonderful job!!!
&gt; 99% of the time only the basic features of a container are used Not doing this is the most common abuse of DI that I see. Auto-magic factories, proxies, composite chains, etc.. bad idea. Every time I've seen that done it ends up being an undue maintenance burden versus simply writing your own little Factory/Provider/Builder and injecting that.
CLR via C# by Jeffery Richter is a great start, but can be a bit dry
&gt; 4.5, 4.6, and 4.7 were HUGE changes that really defined a new type of .NET I don't think I'd agree with you there. 4.5 was fairly significant with the introduction of async/await, but 4.6 &amp; 4.7 weren't particularly notable. The truly significant divisions in .Net (full framework) fall right on the major versions - v1, v2, and v4 - as far as "types of .Net" go, those are where the hard incompatibilities between runtimes lie.
4.6 was the earliest available framework for many .NET libraries and 4.7 introduced compatibility with .net standard. Although yeah, the 4.6 generation is probably the least significant of the big .NET releases.
Yes and no. If you know there is only going to be one implementation, why do you need an interface and DI? Most of the time it is not needed. However, I do like that if you follow the pattern, all the dependencies of the class are passed in the constructor. This makes it easier to figure out other people's code. It is nice to see if a class sends an email or uses the database just by looking at the constructor. In that regard, DI, is helpful. But is it helpful in that it the loosely coupled code is easier to maintain, probably not...
If an Interface is only going to ever have one implementation, why do you need an interface and DI?
Thank you for the detailed and honest response, and for the encouraging words! I‚Äôve been leaning toward ‚ÄúASP.NET Core in Action,‚Äù but wanted the advice of fellow .NET‚Äôers
Hmmm dry can be okay. I‚Äôll check it out. Thanks!
Thanks for the info. I just made my first package here: [https://www.nuget.org/packages/Towel](https://www.nuget.org/packages/Towel) :) Was easy like you said. I think I did it right.
Just made my first Nuget package. :) Figured I would reply here you since you mentioned it: [https://www.nuget.org/packages/Towel](https://www.nuget.org/packages/Towel)
Testing. I'll test the implementation of that interface. I'll use a mock in a test that tests the consumer of this interface.
Sometimes this is helpful, but often not. If you need to test a consumer of an interface but can‚Äôt actually implement it and need to use a mock instead then you have a valid reason for the interface and DI. This is not often the case though. DI is so easy now, why not? But to add complexity to an application to improve the test ability is debatable...
Thanks. I probably won't use it like this, but it's food for thought. Maybe a T4 template just to validate at compile time the stuff that uses a lighter weight ORM.
If you want to use dependencies inside the implementation of the interface then you would want to resolve that interface through the DI context. Even if the interface only has one implementation. If you don't have the instance resolved then you won't be able to add dependencies easily later.
Effective C# Bill Wagner
I can't second this strongly enough. If you want to know what's going on under the hood, this is the book for you.
It's just an warning... Or is it an error?... üòÖ
Get a pluralsight subscription!
Get a pluralsight subscription!
That‚Äôs on my list! I‚Äôm currently finishing my degree, but once I‚Äôm done, I‚Äôll do this!
Since you are a math dude... You might be interested in my project: https://github.com/ZacharyPatten/Towel It has generic mathematics in C#. Granted, you sound like you need to learn more C# basics before you are ready to jump into much coding yourself.
Reading ASP.NET core in action myself. Great book. Can‚Äôt recommend Mark Seemann‚Äôs book enough. It‚Äôs absolute must read. Haven‚Äôt read .Net core in action, so I don‚Äôt know about that one. Also, have a look at ‚ÄúRx.Net in action‚Äù and ‚ÄúConcurrency in .Net‚Äù by Ricardo Terrell. It‚Äôs very interesting, but a bit advanced. Make sure to have a look at ‚ÄúDomain modeling made functional‚Äù by Scott Wlaschin. It‚Äôs F# based, but teaches it along the way, and as a developer you will need to know what domain-driven design is. And last, but not least, make sure you watch ALL Zoran Horvat‚Äòs courses on Pluralsight. That will teach you proper OOP etc. Very important. Zoran also has some stuff on Udemy, but I have not watched it. I would advise against reading ‚ÄúClr in C#‚Äù until inner workings of .net and performance tuning becomes your primary concern. Good luck.
Depending on what you've already read, I'd recommend reading Clean Code by Robert Martin before any of these. It won't teach you the specifics of .NET. in fact the examples are in Java, but it teaches and makes you think about how to write the cleanest, most presentable code.
I feel like DI is not a Cargo Cult. However, DI Frameworks and Containers are definitely Cargo Cults in many cases. You can achieve much of the same functionality by just knowing the principles and coding to that. This can work for many small and medium sized code bases pretty well. I especially don't get the DI frameworks in the client side like InversifyJS/tsyringe/Angular's DI. I understand why larger companies would want to use them, but it's always felt a little contrived to me.
Do it while you‚Äôre a student as you get discounts I believe.
You don't need an interface to do DI. The minimum requirement is... well, nothing. The minimum requirement that actually has a benefit is some virtual methods that can be overridden for unit tests.
Resolving the whole dep tree is nice indeed, but you can register and resolve concrete types also.
I love MVVM. the fact that i can use it in Blazor is amazing. I can even share Viewmodel logic between my Xanarin project and Web UI so both my App and Web front end can have the same code. It's very convenient.
Is this really MVVM if it doesn‚Äôt make using of binding? Why is this not simply MVP or MVC?
Like most design patterns, its purpose is to help _manage_ complexity, not to add complexity. I have seen design patterns overused in ways that were not solving problems but just adding unnecessary complexity. _Once_ it was DI and a developer who felt it should be used for everything -- you don't need DI for something that can be a simple four line static utility method that will never change in signature or purpose. Most other times it wasn't one design pattern being overused per se, but a mix of a too many unnecessary patterns that made it hard to figure out where to find the code responsible for what you are trying to change. Jumping through layer after layer of indirection can be annoying, especially when you expect to take a short detour at each layer to try to figure out why that layer of indirection was added only to give up after spending too long without finding any reason for it.
I'm thinking more of areas of an application than an entire one. If you are working on something internal to an assembly (being it a layer in a multi-layer architecture or a library) I think it is overkill to put interfaces when writing pure functionality, as in just ordering something and without data fetching.
I use ‚Äúsoft leak‚Äù for memory leaks which you could technically clean up somehow (because you still have some kind of reference to it) and ‚Äúleak‚Äù when I couldn‚Äôt do that since the memory address is not stored somewhere anymore (I‚Äôm working with C++ so it‚Äôs a bit easier to forget an allocation).
There are high enough level abstractions that it's not an issue. You literally do a few API calls and let the microsoft written libraries securely build your token with the certificate you give it, then you just distribute the public key to other services. The only insecure part is whether you correctly give it the right claims in the token.
This is a good point when something has a dep on an external data source. However above that point you could strive for _low coupling and high cohesion_, maybe have a pipeline of objects rather than a deep composition.
RedisDesktopManager is great for navigating Redis, although it craps out on large enough hash tables.
What pluralsight courses do you advise? I have access to the website but can't find any interesting courses. (I'm looking for advanced courses, I have 5 years of experience in .net programming)
Adaptive code second edition. It's pure gold and the quickest way to become a senior.
I don't think that's the case in general, though I may agree that pulling in external dependencies isn't needed and may be overkill for a lot of the simpler projects.
Saying ‚Äúthis thing about my code will never change‚Äù just isn‚Äôt a good thing to do.
Yes, Asphostportal does support latest .net core 2.2. If you really need .net core 2.2 to run, then you can always consider this provider.
What about when, yes, an interface has one implementation, but that implementation depends on 3, 4, 5 other services? Are you going to create them by hand? What about their dependencies? What about lifetime scope? Sometimes you want singletons, others you want a new instance per reference. Others you want to maintain the same instance while some criteria is true: http request, database transaction, and so forth. And, more importantly, what about CHANGE? I mean, if you‚Äôre coding a prototype, a proof of concept, yeah maybe DI is not needed. But if there are any expectation of maintaining that code, if it is going to change, be tested, improve, evolve, then I‚Äôm really sorry but you do need DI.
Is there anything in development that doesn't have cargo cult status with at least a subset of developers? I think it's abused rather than overused. You don't need an interface for everything. You only really need mocks for types which operate on the boundary of an application, it's healthier to test a SUT with concrete collaborators rather than mocked ones. And one final one as I'm not rewriting my blog post, just because the class is instantiated automatically does not mean you should just dump more functionality in and extend the ctor.
People are talking a lot about interfaces, which are used with DI a lot, but that's not what the pattern is about at all.. at it's core, it's literally just injecting dependencies up front, either through constructor injection or property injection.. I don't think it's a cargo cult at all, almost any project of any size can benefit from structuring your code in this way, it helps prevent spaghetti code; classes are up front about their dependencies and they can be up front about checking those dependencies validity, which is one of the best things about it! Fail early!
LINQ is great but sometimes it can be difficult to get right. It's very to accidentally make something really inefficient or put together queries that are an unreadable mess. Can make debugging harder sometimes too. With lots of practice it does get better.
100%. My pet peeve are devs who write these enormous queries all on the one line. Gives me a headache üòÑ. At least break it up across multiple lines. Better to assign meaningfully named variables along the way to attach some meaning to help with readability. Like you say, performance won't be affected unless you're ToList'ing too early!
Seems to be an industry wide problem with LINQ. I made the same mistakes at the start as well. Would be great to see training that focussed specifically on writing good LINQ queries.
Which should still be interfaced for unit testing, even if you don't have a DI container.
I don't think so. Even if I don't "need" it half of the time, I use it anyway because it makes everything consistent. Only place I avoid it is when creating reusable Nuget libs. You absolutely should not add dependencies to a particular DI framework there, and preferably have a single entry point that configures itself.
[removed]
Why does everyone use books so much? Get inspired, and just wrote code. Look at the documentation when you need it. It‚Äôs much quicker, cheaper, and easier.
Head First design patterns is really good. The code samples are Java but should be no issue for you as a C# developer. I'd stay away from the gang of four book, it's quite dry and difficult to get through.
I‚Äôve found my tactic round this is to tell the team, cover your method with tests and if it doesn‚Äôt execute in under X seconds it doesn‚Äôt get merged back in
Unit tests are there for code stability. No tests equals wild west. Don't write code like it is the wild west. Debt over.
I‚Äôve used https://healthchecks.io/ in the past as an alerter if something doesn‚Äôt check in. Also shout out to https://apichecker.com/ which I came across from someone building it on reddit
Noted, thanks!
Thanks for the thorough response. All things I‚Äôm going to take into consideration.
&gt; Once it was DI and a developer who felt it should be used for everything -- you don't need DI for something that can be a simple four line static utility method that will never change in signature or purpose. As long as you're aware of how minimally your utility interacts with the rest of the system. If it's a utility which needs to accessing a resource, say a file on disk/network, or it changes the state based on the given time of day, then you want to slap an interface on top of it so that whoever uses your utility can test their class without dealing with an unnecessary prerequisite or unreliable behavior.
Agree I don't usually bother with interfaces, but having everything resolved with DI makes it a whole lot easier to add new resolved dependencies with the correct lifetime (scoped or Singleton) as I need them without worrying about passing them around.
Thanks! I actually went with digital ocean.
If you're not mocking stuff and writing tests it may not be worth the overhead. But you should be writing tests.
Is it free past the 1 year trial period? Haven't used it in a long time but when I last tried, it tried to charge me for an instance
This article, while moderately useful, has one major typo - you don't migrate from **TFS** to Git, you migrate from **TFVC** to Git. TFS is much more than just source control, and it can even host its own Git repositories.
Yes. I don't pay anything for it and I'm using it privately for over a year now. There are some limits, mainly with build minutes, but they're so generous that I haven't hit them so far.
Yay DataVisualization is back!
Can you compare? From my brief experience with Brew, I thought Apt and Chocolatey are more capable.
I didn't say you did. Is every single class in your application only ever going to have one implementation?
so in .Net Core 3.0 we will have the the good ol' EF6 but cross-platform, so what is the purpose of EF Core now?
Thanks for all the info. A ton of leads to follow up. After reading a few more examples that showed things done multiple ways, it became clearer. Kind of a two step process to read (proc &lt;-&gt; oop) examples and then (C++ &lt;-&gt; C#) examples. &amp;#x200B; 25% downvoted? That's interesting. I wasn't poking fun at OOP, honest. I was describing my utter bewilderment and humbling of the process. &amp;#x200B; Thanks again!
This is not only a choice of which tech helps you to build it the fastest. It also absolutely depends on what the future plans of your client are regarding the expansion and maintenance of the site. As you describe it, it sounds to me that non functional requirements like maintainability and supportability are important since the site is quite complex. Choosing a well known spa framework like angular would be a good fit. Very good documentation and a proven track record. Also as a .net developer I found it quite easy to learn so your learning curve should not be too steep. Hth
I don't have much experience with Brew and was only going on all the guidance I see--tutorials seem to use Brew a lot more on macOS than they recommend Chocolatey on Windows. So I assumed that Brew must be richer, either with greater package coverage or by capability.
Seems risky to use Blazor for production. IMO, any technology or framework that‚Äôs as new as Blazor is should be approached with caution. It‚Äôs possible it could change quite a bit in a year or so and create some re-work, or it could not take off and be dead in a year or two creating a maintenance headache. If you use React, Angular, or Vue, you have a good chance that it‚Äôll be supported in the next few years, have a large community to people to ask questions to, and be able to find developers to maintain it.
Thank you. I thought I tried that before and it wasn't working. now it Is (probably had something off).
Wait, wtf? Fuckin Microsoft...
The Nuget part, thank you! Maybe the primary reason why I posted the question was libs with a container baked-in or libs that make you register a dozen types before you could call a method. In my opinion usability suffers extremely in these cases. A reason for this DI choice is given in the form of "_but we need to remain SOLID_" however, as others pointed out in this discussion, you only **need** OOP for that. Therefore it sounds like a cargo cult to me.
You mention React and Vue, but has your team ruled out Angular? As an enterprise developer with an affinity for the backend and a distain for the frontend, I‚Äôve found Angular to give somewhat sanity to the wild wild west that is JS frameworks. If you‚Äôre comfortable with .NET, slapping an Angular UI on top of your backend might be the better choice, as you can leverage Typescript and the design paradigms the framework nudges you towards. We‚Äôre rebuilding one of my company‚Äôs most high profile applications in Angular 6/7, and I‚Äôve found the development experience to be quite enjoyable, as the framework is a traditional take on convention over configuration, reducing a lot of the complexity that would eventually arise building incredibly large high traffic and complicated business applications.
Keyword vs CLR type (int.Parse vs Int32.Parse).
EF Core tends to perform much better and generally has a cleaner / more modern architecture. Some things are also easier in EF Core than EF6 still (like unit testing), and EF Core will continue to evolve while EF6 is in maintenance mode. This is primarily a backwards-compatibility move.
Pretty sure he meant breakpoints
Amen. After .Where(), I often like to throw some .Select() into the mix as well
I had a similar decision recently, choose react because of speed, react is just blowing it up right now, just as .net core, speed right now matters
No worries.
The article linked to is using binding between the razor page and the ViewModel class. Blazor uses one way and two way data binding so MVVM on the client is very easy to do.
You naaassty ;) Everyone down tools, we've got a new one to settle!
I wouldn't use blazor yet. As a primarily back end c# developer, I like angular the best.
Yeah and I said you can split the transformations up to make debugging easier. You put a breakpoint on a function and it will hit. &amp;#x200B; var discountedProducts = products.Where(ProductHasDiscount) &amp;#x200B; ex. do it on ProductHasDiscount and it will hit, if you need to do it by a specific iteration, then add in the index parameter and only hit it then. &amp;#x200B; Or you could create an extension method like Tap or Debug that just logs out the details of the collection. &amp;#x200B; ex. &amp;#x200B; var discountedProductNames = products.Where(ProductHasDiscount).Debug().Select(GetProductNames);
One way to accomplish this is to [re-generate the DBContext](https://www.entityframeworktutorial.net/code-first/code-first-from-existing-database.aspx). This will create a new DBContext, modify any existing POCO's, and add a new POCO for your new table. I create a new one then delete the old and then rename the new to the old name - kinda a pain but is the best way I have found to generate an updated DBContext and get my POCOs synced with my schema.
Just open the model diagram, right click -&gt; update and save.
&gt; because of speed https://medium.freecodecamp.org/a-realworld-comparison-of-front-end-frameworks-with-benchmarks-2019-update-4be0d3c78075 In real life React is the slowest framework in all the framework you named.
When do you need to make a decision buy and what are the timelines for starting development and completing the project? Based on working with [ASP.Net](https://ASP.Net) Core 3 preview 3 and preview 4 I have already made the decision to move to Blazor for my line of business application. However I'm in a position where I get to make the technology decisions as well as determine the schedule. If your client wants something soon then Blazor probably won't be ready in time. If you have an extended timeline you could potentially build up the entire back end first with [ASP.Net](https://ASP.Net) Core 2.2 Web API and make a decision about your front end technology after further investigation. My current plan is to migrate all of our existing WCF web services to Web API now, then build the Blazor client. We will potentially go live with server side Blazor that will release with .Net Core 3 and then migrate to client side Blazor when it releases. We had initially planned to go with Angular but after working with the Blazor preview my developers were faster and more comfortable working with C# and Razor views. I am glad that I do not have to have something new in production in the next 6 months or I would have had a harder decision to make.
Maybe it would hep to use System.ConfigurationManager and the App.Config?
You might need to check the box next to the table name, if you are only including certain tables in your diagram!
Yes we are using it, and it's been quite stable. The main benefit for us is on AWS the Linux instance costs half as much as a windows one, so we can run one that is twice as powerful instead. We do have an issue on our test server where the mssql service occasionally stops, but never on production. I think it's because the test server doesn't have enough RAM.
&gt; When do you need to make a decision by and what are the timelines for starting development and completing the project? I need to make a decision within the next couple of weeks just so I can get started. It's a side gig to my full-time job though so it will be a long term project that will be in development over 6 months or so. My primary job uses ASP.NET MVC 5 (server-side razor as the front-end with CSS/JS) and some abomination routing system using angular (don't know why we didn't just use MVC routing with a purely MVC project). &gt; My current plan is to migrate all of our existing WCF web services to Web API now, then build the Blazor client. We will potentially go live with server side Blazor that will release with .Net Core 3 and then migrate to client side Blazor when it releases. This was very much a consideration for myself as well. I figured that we could probably get away with using server-side Blazor components and just port them over the the Blazor client when it is ready for production loads. By the sound of it, there should be little to no rewriting in this case. &gt; We had initially planned to go with Angular but after working with the Blazor preview my developers were faster and more comfortable working with C# and Razor views I can understand the discomfort. I've tried all three of the major JS frameworks and Angular was by far the most convoluted in my opinion. It felt like there were extra unnecessary steps to achieve anything, but that could be user error on my part.
As it is just me working on this and I get to call the shots, I haven't ruled anything out just yet. My limited experience with the three major JS frameworks tells me that Angular is the worst choice because I found it unnecessarily complicated and a lot more work than the other two. It's very possible that it was just how I was using it though. As a side note, both React and Vue can leverage Typescript as well. What I do like from what you've mentioned is the design paradigms and the somewhat rigid conventions. I very much appreciate a tool that has a sort of built-in direction like that as it's much less thinking and work for me to leverage that design that is already put in place.
&gt; It also absolutely depends on what the future plans of your client are regarding the expansion and maintenance of the site There really isn't one, the plan as of right now is for me to finish the site and then I'll just be brought in for the odd update here and there if it is needed. I'm not too concerned about using Blazor because very few people are familiar with it yet, as it's very unlikely anyone else will be touching it in the near future. My concerns are more around whether or not it is a good development tool at this point in time. I think the answer is "yes," but it won't have the same availability of feature-rich libraries, documentation, support or help that the JS frameworks have.
If I remember correctly, there are 3 types of db migration configuration: 1. Code first migration (my personal favourite) - you will write entity classes in C# code and then generate C# based migrations which define the creation of tables and indexes (that's your likely scenario since you are on .net core and I think that's the most common one used there). 2. Model first migration - you have a model file in your project (it's XML under the hood) and you can make changes to the schema diagram when you double click on it. Once you make the changes they can be propagated to the database and to newly generated C# code. And lastly 3. Database first migration but I haven't used it personally as it defeats the purpose of code reusability and db decoupling. Good luck, hope this essay sized comment helps somewhat.
Thank you for your input. It seems that everyone on this thread prefers Angular to the other two. I have briefly used all three and I must say that in my very limited experience, Angular was the least pleasant to interact with due to its seemingly unnecessary complexity. May I ask for your perspective on what it is that draws you to Angular over the others? I don't feel that I have enough experience to pass a fair judgement here so I'd love for you to change my mind if I am mistaken.
I‚Äôm using Angular as well. The best part of it is how integrated everything is. Your tools, the way you make http calls, dependency injection... it‚Äôs all built in and you don‚Äôt need to use other peoples libraries (besides angular) to get it to work for the most part. With React, my experience was constantly juggling libraries and changing configurations. It was way less pleasant.
I absolutely agree that new technology should be approached with caution, I started this thread in the hopes that I was either going to find out I'm being overly cautious, or get a harsh reality check or some horror stories from someone who has done something similar in the past and regretted it. &gt; It‚Äôs possible it could change quite a bit in a year or so and create some re-work Very true, that could potentially be quite a pain. I would prefer to not be bogged down by that. &gt; or it could not take off and be dead in a year or two creating a maintenance headache This is a great point. I think the worst case here would be that the components would need to be ported back over to server-side though as Blazor server-side components are going to be a staple part of .NET Core 3. I'm currently leaning towards the JS frameworks though, simply because it is likely the option that will cause me the less grief in the long run.
That does sound very appealing. One of my biggest hates for the JS workflow is installing 500 packages just to get a "Hello World" up and running. This felt like it was even worse in Vue than React (although I believe this is intentional as Vue is meant to be very lightweight). Considering every single .NET developer in this thread seems to prefer Angular, I am pretty sold on it if I decide to go with a JS framework (which I'm currently leaning towards).
Unfortunately, database first seems to be the only option for certain projects where the production database has already existed for a long time. Perhaps I'm missing something, but I don't think there is a way to convert that to a code first approach? If I'm mistaken there I'd love to know how to do it though. The database first approach does have some merits though. It allows for a quick mapping of the DB tables to POCOs, Linq to SQL, and all the other good stuff you get with EF. Personally I prefer that over writing the POCOs myself and handwriting the SQL.
You can also try Razor Pages. It‚Äôs pretty easy to port over older Asp.Net code. I suggest Todd Mottos ultimate Angular course if you want to learn Angular. It‚Äôs my favorite
I'm using it as far as I can tell its perfectly stable. Haven't run into any troubles but we really don't do anything critical with it (lots of read write) SSO solution which also runs in docker along side it.
Razor Pages does interest me, but it is my understanding it is a server-side rendering solution. I would prefer a proper client-side solution, so I think Angular will be my best bet here.
The book Dependency Injection Principles, Practices and Patterns has really helped me. It's quite new as well so there's recent examples.
While the approach you described is the one I follow myself, there are absolutely merits to using courses or books (provided they are well written and not outdated). Many of the things you may not pick up from Stackoverflow and Google that can be found in books are good design principles, conventions, framework nuances, etc. I would almost always expect a more well designed architecture and better code from someone who has studied a framework properly from a book, than someone who just dove in with no prior knowledge and constantly applied band-aid fixes from Stackoverflow throughout the duration of the project.
Select is just so beautiful. I love being able to change: `List&lt;int&gt; placeIds = new List&lt;int&gt;();` `foreach(Place place in places)` `placeIds.Add(place.PlaceId);` To a simple: `IEnumerable&lt;int&gt; placeIds = places.Select(p =&gt; p.PlaceId);` Plenty of other great examples out there as well, but it's just so much nicer than having to manually recreate lists all the time.
Hey Jammb, is the cost reduction just due to the Windows license on the OS you're no longer paying? I assume the SQL Server license cost itself is the same whether its Win/Linux. Thank you!
2 things, 1 with db first you have to write POCOs yourself and you need to write the SQL code too, now that I think about it there isn't such thing as db first. If you want to be able to write Linq to SQL code then I'd recommend converting to Model first approach, you can generate the EF Model from an existing database, you just have to be mindful of any existing stored procedures that could eventually be converted to Linq queries.
EF has scaffolding functionality that will generate the POCOs and DbContext for you, which you can then use Linq to SQL with, so you definitely can do a DB first approach. You can simply re-scaffold each time you make a change to the database. The only thing I'm not sure on is whether or not you can scaffold once, then change to a code first approach from that point. I see no reason one couldn't though, I just haven't ever tried. Where it does get a bit tricky is when the stored procedures come into play as you say. Unless you rewrite them all in Linq, there won't be any standard access to these through the scaffolded entities.
Only real downside is not SQL Agent or replication. But there are other means to those ends.
but the db context needs a model to follow, right? Isn't that based on the generated EF Model and generated cs file? (Aka model first migration?)
Yes correct, we have our own mssql license and the pricing is the same for windows &amp; linux. But the hourly rate for a windows m5.4xlarge to run it on is $1.504 while a Linux one is $0.78
I may be getting my terminology incorrect here, the scaffolding tool will generate the POCOs directly from the schema of the database connection and then create a DbContext from those POCOs. There may well be a model step going on under the hood that I'm unaware of, but there was no step in which I had to manually create a model, which is why I presumed this was referred to as database first. My apologies if I've got my definitions wrong.
SQL agent is supported on Linux. Maintenance plans arent though, you have to write your own and schedule them with SQL agent.
What is weird is I do not see the ADO.net Entity Data Model as an item? I'm guessing it might be because my project just is a web application.
I'm doing the third approach because I'm modifying an existing application. Unfortunately, I can't completely rewrite the structure of the database.
My project falls into that category.
AppData is in the user folder. Is the windows service running as that user or the system user? Are you running on .NET Framework or .NET Core? If on .NET Framework, using the &lt;service&gt;.exe.config and configuration manager is easiest in the short term. The config file would be in same directory as the exe. If on .NET Core, be sure the account the windows service is running as has permission to where the config file is.
As for passwords, be sure to use correct ACL on the file so only the service account can read the file. It is very difficult, if not impossible, to protect against someone else that has local admin rights on the machine. Don't use shared accounts. Enable security audit on logins, file access, etc.
This would depend on a number of factors. Does the app need to scale? Does it have latency concerns? E.g maybe the server is just next door / floor / same city so Server side blazor might suffice (SSB) for now as that's going live along with core 3 earlier than client side Blazor (CSB). Do you need it up and running for prod immediately? If that's the case Blazor might be too early and won't be in time for your requirements. Are you willing to fill in the gaps (e.g 3rd party components) and also the chances of fixing breaking changes as the previews is getting polished. This should be at least a good starting point to ask these questions. On my end we've convinced management to go for SSB for our old internal app rewrite. The users all live in the same city so scaling isn't an issue, and we're willing to rewrite our inhouse Angular components to Blazor for reuse for future Blazor projects. This rewrite also serves as a proof of concept for future Blazor projects so we can assess the framework early on. We plan to structure the app so its compatible to CSB in case we need to scale and also assess how easy switching is. The app is still on the planning phase so we've got plenty of time for SSB to go live. The full stack code sharing productivity boost Blazor provides is a big potential we're willing to bet on. If you need the app now i can vouch for Angular as it's quite opinionated and has batteries included so you'll have less time configuring settings or finding compatible libraries to get up and running. This is important to us since with many developers working on a project it can get quite messy without proper code reviews on flexible frameworks like Vue or React. I recommend using the cli for this to ease up scaffolding and wiring up components. Also the DI system and typescript usage (e.g libs are built with typescript in mind and not just an afterthought) will be quite helpful as it'll feel somewhat like C#
[removed]
Thank you for the detailed and well written response. &gt; Does the app need to scale? It needs to be reasonably scalable as if the product is a success, we will need to be able to handle the amount of users that are trying to use it. In terms of project size, Blazor probably wins out there due to the Client/Server/Shared code sharing structure, but Angular wins over SSB simply due to less load on the server. &gt; Does it have latency concerns? The target audience will all be in the same country, so it's not too much of a concern, but moreso than if it was for an Intranet or the likes. &gt; Do you need it up and running for prod immediately? Not at all. Development needs to start shortly, but the rewrite is expected to take at least 6 months so there is no rush to get it to production. SSB should be out by then, but I doubt CSB will be. &gt; Are you willing to fill in the gaps (e.g 3rd party components) and also the chances of fixing breaking changes as the previews is getting polished. These two things are probably my biggest deterrents at this time. Fortunately I consider my strengths in front-end development so I often find myself extending or recreating controls anyway when I can't find something that is a perfect fit for my vision. While I would miss having a vast array of third party components, I think I'm okay with not having them. On the other hand, breaking changes could be a pain in the rear, but I can't foresee anything too massive happening between now and then that would require a huge amount of rewriting. Perhaps that's just naivety on my part though. I appreciate your insights on your plans to move over to SSB, that is almost exactly how I wanted to try implement this if I were to go ahead with Blazor over Angular. With the old version being old ASP.NET (i.e. server-side controls) we are already running server-side anyway. The client is happy with the performance of the current site, so I can see SSB being a viable option in that regard. I am now completely set on Angular if I do go with a JS framework though, so it's really just down to making the call between Angular or Blazor. I would dive into SSB, but I'm just not sure that 6 months (keeping in mind that development needs to start within the next couple of weeks) is going to buy me enough time.
I'd go the custom route as the built-in configuration system is too restrictive for what you are doing. Go with your second choice exactly as you have stated it except you could use JSON (or even YAML) instead of XML.
Could not agree more. TFS and git is amazing.
I'd steer away from Angular. It's a huge mess of a framework. And ironically TypeScript support in Angular is really poor.
I have made a Windows Service that's currently running in production and I'm just using the registry to save the settings. This includes a connection string, but no passwords.
&gt;choose react because of speed Any references as to how you concluded that React is more performant than the other popular frameworks?
This is some fancy stuff. I can‚Äôt believe this really works. Everyday is a day to learn something new I guess.
You were so close until that tripe about Dark theme. Everyone knows that Light is superior!
I switched from web forms to MVC. There is nothing better about either, I'll go back Web forms or do MVC the same. A yahoo will be thinking that is doing them a favour by changing from one to other, unless want to write it on the resume. If I ain't broken don't fix it.
I'm not 100% sure where the m prefix came from, but I see it in java a lot. It went away because it reduces code readability and its usefulness has been succeeded by intellisense in most IDEs (for example, Android studio will make class members bold in java, removing the need for the m to differentiate). It also has unintended consequences, like screwing with alphabetical ordering, generating getters and setters can produce ugly things like "public void setmName(string mname)" etc. Best not to use it at all unless it is already in place on the project you're working on.
Probably an opposite of what you have asked but there is nothing particularly wrong with using web forms except the feel that it‚Äôs not the coolest kid on the block. Plenty of people still use it successfully. There is a huge number of articles online discussing WebForms vs MVC, and slightly fewer WebForms vs MVC vs Razor pages. Most of them conclude that all have pros and cons and it comes to the personal preference. That said, I did work with WebForms and MVC and prefer the former. Haven‚Äôt had a chance to play with a sizable Razor Pages project, but from what I saw it looks pretty neat and since Microsoft has now made it a default option it would eventually get more support.
Why not using an Azure sql db? It‚Äôs always the latest version and you don‚Äôt need to care about anything for issues like scaling, backups, operating system and so on. You will have it probably with guarrantied up time and safety of your data. It‚Äôs extremely simple and I believe money saving in the long run.
Pipe down, commie.
The heck? Linux is ahead of Windows? What rock have I been living under, I thought it was still less popular than MacOS. Glad to see that's not the case.
Am I looking at the pricing calculator correct? It‚Äôs saying Azure SQL Database would cost ~$3,000 a month.
Shouldn‚Äôt be that costly. Play around with options and spec and you‚Äôll probably get it down significantly
No! the original is in microsoft v academy which is getting retired. I don‚Äôt care about that youtube channel. But the video is one of those few free and practical courses on this matter.
I started to never use relative paths in my applications. I define a data-path global variable that is used throughout the app using Path.Combine(dataPath, "relative/path/inside.png")
&gt; Since there's no way that I can tell to run both ASP.NET Web forms and something more modern like Razor Pages in the same app This should be straightforward to do.
Is it? I've looked around and it seems like you can't integrate the two of them together. Maybe my Google-fu has failed me.
My number one concern would be finding good developers to work on it in the future. Most would prefer to work on a modern stack. You may have to make it worthwhile for them to work on old tech ($$$).
That's my own concern as well. The team currently is all offshore other than the manager (who is remote) and now myself. I think longterm doing it this way is causing more problems due to the technical debt it's incurring being designed the way it is.
I never understood the point of maintenance plan anyway
We moved from JIRA to TFS with Git and it has been working great. Actually, I prefer TFS over JIRA.
Are you looking at the managed version? That's the wrong one, try the normal Azure sql should be mutch cheaper!
Bullshit, Ms are uploading to YouTube now, I've seen this channel reupload content a lot.
Thanks! I try not to form a strong opinion against something unless it has specifically caused me pain.
I've been reviewing Angular, React and Vue (and knockout, ember, and a few other libraries before them) for the past few years now and making small demo applications. Here's my 50k foot view: 1. Blazor is at this time a mistake. CSB is a leaky abstraction of a .NET application model running in a browser. For CPU blocked tasks it is slow. For network based stuff it forces you to use types that are little more than the underlying JS apis renamed and do not match the types you expect in the rest of .NET. Despite the hype I found in UI code I still needed to write JS several times to do analogous things to my current work. SSB makes nearly everything a network transit (noticeably laggy on my 4g phone) or makes you write the JS you would for a normal app anyway. 2. Angular forces you to write considerable boilerplate to enforce various conventions they have decided on all over the place. These conventions make the classes and files in an Angular app quite recognizable and maintainable but they have an up front cost of increased dev time at the start of the project. 3. React is chaos. Every time I look someone is talking about some new library or which dozen or so you want to use for your new project. You can quickly throw together a React application but I'd be worried about maintaining one. 4. Vue seems quite nice. It is sorta like Angular in the style of various object types but it doesn't enforce conventions as much. That said it feels smaller and less featured than either React or Angular and less used as well. I'm on a fence somewhere between Angular and Vue. If it was just me working I'd probably go with Vue. But I quite like Angular's conventions and I'd basically wind up writing an Angular app in Vue anyway. And the several other devs who are impacted by my decision don't tend to make the most maintainable decisions and would be helped by having a number of the more basic decisions made for them so that I don't have to review every code change myself. We are slowly moving forward with Angular and are expected to have a demonstration app for July of a subset of our current product. The only decision we have actually already made is that we are going to be providing a fully documented api to our clients and allow them to write user facing stuff if they want to and try and get out of the fully customizable front end business ourselves, limiting us to a feature set that allow us to white label front ends in a scale-able fashion (our current arch lets us bring a new customer up in 6-8 weeks of back and forth and we want to get it significantly under an hour).
Just an FYI, I am huge fan of Vue. Doesn't completely take over your front-end, and just feels cleaner to me. Others feels much much heavier imo.
Again in plain English: I don‚Äôt have anything to do with that channel. Report the channel and redirect people to the original content.
One of the legacy apps at work does this. It's not great but if you wanted to slowly improve something to a more modern stack then that'd be a good start.
Quick note here, you shouldn't be using WebClient, should probably be using HttpClient.
Storing images in database sometimes considered an antipattern. Why don't you want to store images on disk and paths in database? Check out this SF thread: [https://stackoverflow.com/questions/3748/storing-images-in-db-yea-or-nay](https://stackoverflow.com/questions/3748/storing-images-in-db-yea-or-nay)
Which database are you using? See if you can use blob storage, or convert the image to base64 and store the result. You could also just store the location of the image in the db and store the actual image on disk
To be honest, im kinda new to this and have no idea how to store the data on disk
To be honest, i have no idea how to store them on disk ..
Im using simple SQL to do it, which one of those methods do you think that is more efficient?
I made a simple statement about where they get their content, if your not debunking that then don't comment like you have.
Don't store images in the database - store the images on disk, and store the images' file paths in your database instead.
If you have an image in an Image or Bitmap object, you can call .Save() to save them to disk. You would want to have a folder somewhere designated for storage of user images and you'd put them all there, and probably you want to generate filenames based off of some pattern. If you have the raw byte\[\] or a MemoryStream you can write the bytes to a FileStream using .Write or .Pipe (respectively).
Most just store it on in something like S3 and save the path in the db
https://docs.microsoft.com/en-us/aspnet/core/mvc/models/file-uploads?view=aspnetcore-2.2
I will second or third the idea that you store them on disk and store paths in the database, however, I would caution against storing full paths. You may someday want to move that file storage location to a new set of disks and you won't want to perform a massive update statement to fix them all. Instead, in some part of your app's config, store the first part of the storage path that all images will have in common. Let's say that's something like \\\\fileserver\\appstorage\\nameofmyapp. Then in the database, store the rest of the paths like \\somefolder\\somefile.jpg. Then concatenate the two together in your app when you need to display the image. &amp;#x200B; Then, five years from now when you are asked to migrate your 1.8TB of stored images from the old SAN to new SSD-based storage, you can perform a background operation to copy it all over and then flip the whole app over to the new location by updating that prefix in your config file. You'll thank me for this then, trust me.
You can get file stream from HTTP request object and then store on disk. Make sure that your application has permission to write to the folder you are saving to.
The risk involved is dependent on how critical your application is and how broad your browser support needs to be. Personally for something with a little lower visibility, like internal line of business applications where your audience is relatively small and you probably have some ability to limit the supported browsers, I'd be comfortable adopting Blazor given that Microsoft has put their full weight behind it.
This is the whole purpose of the powerapps, flow, sharepoint lists, and maybe even azure services like automate, project, one dirve, on-prem and azure sql, teams and powerbi ecosystem. Check out office 365 licensing, you'll want to start at e3 level and perhaps even e5 if you can put a plan together to take advantage of all the extras (you can.)
Very simple example but I suppose it‚Äôs a good starting point if you‚Äôre not familiar with setting up a .NET Core Web Api with Swagger.
I'm really surprised so many people are saying store them on disk. I'd put them on blob storage straight away and avoid storing them on your web server.
Look at blob storage to store the images, you can use s3 from aws or azure storage from Azure. Google has an offering too but I can't remember the name off the top of my head. Let the user upload the image to that service from the clients browser and then store the reference to the blob in the database.
If you can't justify it yourself, why do assume your opinion is right?
Angular
It's also worth noting that Azure SQL is running on Linux. It can get expensive but you just have to take care to optimise for DTUs, which comes from normal optimization anyway. If it doesn't have to be SQL, there are also plenty of nosql alternatives that are generally a lot cheaper but can sometimes be a pain to work with. Cosmos is probably a good balance of ease of use vs price.
Thanks, im using asp.net core actually
It's like a personal project, so don't think i would have that much data
That is the developer equivalent of saying ‚Äúsure, I smoke, but I can stop any time I want‚Äù. ;)
U got me lol
Careful, Microsoft's Application Insights may be collecting info about you and your projects for marketing purposes. I haven't verified this, but please keep that risk in mind.
Keep in mind that anything is subject to being stamped "obsolete" at a moment's notice, including any current "cool" or "in" tech or tool. There's a balancing point between keeping up with the Joneses and the cost of transition and confusion of starting a new stack every couple of years. It's a tricky one to weigh.
Very cool
If it's not "separating" anything of importance often enough then it's not worth adding as default because it just adds **cross-module wiring busy-work**. There should be a decent probability of usage of the separation before separation is actually added. It sounds like it's fairly to easy to add a controller if and when later needed in Razor Pages such that pre-adding of controllers may be overkill. (I haven't tried Razor Pages myself, but others have said this.) It may depend on shop style and habits. Does anyone have a feel for what kind of situations or projects starting with controllers pays off versus initially skipping them because the need is too rare?
Thank you all! I'm going to try saving the settings on the "configurator" application and starting the service from this application using arguments for the connection data. The extra settings I can just save in a XML o JSON file somewhere in AppData. If this works, I'll be good enough for now. &amp;#x200B; Do you know if these launching arguments are being logged on any events or log files?
Image column type. File store. Though I generally avoid this. Kinda depends on the planned size.
I didn't think it supported the control of private member conventions?
The two main libraries in use ere Swashbuckle and NSwag. Both are fairly good.
Angular seems very popular with .NET people. If this thread were a poll it would look like this: Blazor: 3 cautious maybes Angular: 12 React: 1 Vue: 1 maybe
You can find an article for every argument so I prefer to look at who's using what, and downloaded the react browser extension. You can see netflix, reddit actually and some sites that want to be speedy moved to react recently. But don't take my word, try the extension and go to the sites you look up to in terms of code, check what they use, cheers
i'd say most .net developers like angular. as its a framework that gives you a lot for 'free' just like .net. there's no way really around node packages sadly. one heads up for a SPA is look into doing change detection "on Push" (its like INotifyPropertyChanged), instead of the black magic auto way. otherwise as the app grows it's performance will suffer a lot.
There is some great documentation found [here](https://docs.microsoft.com/en-us/visualstudio/ide/editorconfig-code-style-settings-reference?view=vs-2019). I think [this](https://docs.microsoft.com/en-us/visualstudio/ide/editorconfig-code-style-settings-reference?view=vs-2019) is what you are asking about.
So server side is pretty much WebForms
Except there is no viewstate being passed back and forth and you can refresh parts of the page.
I can't believe people keep asking that question. It is incredibly important for unit tests
So, where is the page's state kept? On the server? Is that really better solution?
Yes, it‚Äôs kept on the server, and how is that not better than transferring it over the wire constantly?
On the server. At that point the webpage is more like a dumb terminal with everything running remotely.
React and Vue are only difficult to install if you're trying to use it along side MVC on the same solution, hosted on the same server. The templates provided by Microsoft are not the typical way you'd run a SPA and they are configured very specifically to work with the .NET pipeline. The ideal way to build a SPA would be to have you .NET solution on one server as an API and your React/Vue app on a separate server just rendering the static HTML/CSS/JS and pulling data from your API endpoints. If you HAVE to use either on the same server, I'd recommend just serving a static index.html from your wwwroot folder and installing Vue or React (create-react-app) through the CLI and configuring it's build output to the wwwroot folder. Then configure your routes to serve everything that's not prefixed with /api to the index.html file so the client router can take over. Both CLIs are super easy to use and guide you through the project creation. It doesn't really get any easier.
Maybe try pair programming for a few hours a day with some of your co-workers who are .NET devs. I bet you would learn a lot not just about .NET, but also about how your company's architecture works.
Server Side Blazor is great for business applications with low number of concurrent active users (we got &lt;100) and high rate of feature change. Tests show the server load increase is acceptable and wouldn't increase costs. This way the system is fully controlled on server side, no code transmitted to terminals or BYODs. Easy update without worrying about browser's cache. We are waiting for authentication/authorization for SignalR connection which will likely appear in preview 5 and give it a go. For massive use consumer apps Client Side will be better choice to offload the UI and limit number of active server connections.
*conspiracy intensifies*
Not only that, but due to the web sockets connection it will have real-time performance at the cost of scalability. So a better description would be "Real-time WebForms with low/mid scalability". I think Microsoft should be more transparent about the way Server-side Blazor is implemented internally since it's an essential factor in deciding what projects it's a good fit for. I didn't know these technical details until I read this article (or maybe I just lived in a cave for this past year).
Have a look at this, it's really going to make your life a lot easier to move to a code first approach in the future, especially when it comes to keeping track of your changes etc through migrations. https://docs.microsoft.com/en-us/ef/core/get-started/aspnetcore/existing-db
&gt; I did not check it for myself but you should do us all a favor and check your outbound Network traffic Yea lad...
I have also been using SQL Server in prod for over a year at this point and I have not run into any major issues (or even minor really). I've been able to easily maintain thousands to tens of thousands of reads/writes per minute as a single SQL server and it has yet to ever crash or do anything out of the ordinary. The biggest issue I've had is upgrading the SQL server when they introduced the SQL Agent. All it took was a few commands and all was good. Although, it's a simple setup - it's just a single server, no replication. There are also daily backups scheduled via the SQL Agent. I've also been running it locally for development and staging, and I haven't run into any issues there either aside from lack of support for Ubuntu 18.04 (I think they might have added support for it now?)
&gt;I think Microsoft should be more transparent about the way Server-side Blazor is implemented internally Agree. I really think they should separate the two more clearly. People were interested in Blazor because it was running .NET in browser. Not because it is connected to a server in real-time with .NET running there. The two are just too different to be lumped under single name.
I started with Udemy. Find courses by Mosh Hamedani, he's excellent at teaching typical concepts.
The relative path should be stored in config IMO. No part of the path should ever appear in a database.
So you have no proof they are doing that, but you're going to say it anyway. How is that at all helpful?
Agreed that it might just not make sense for the team to change tech. Get yourself out of there before you become obsolete too.
I was hoping it wouldn't come to that. I like the job, I've been here for almost 4 years. I wasn't too thrilled with being moved to this team (I enjoyed doing the SQL work, but there wasn't a lot of C# work), but I didn't get a choice in the matter it was "We think this is the best move for you"
&gt;Yes, it‚Äôs kept on the server, and how is that not better than transferring it over the wire constantly? its not better or worse, but it moves the load to the server. possibly increasing server costs. It would give you more control in some ways but also has its down sides.
\&gt; Moving to server side hosted Blazor is just a matter of changing some configuration. Otherwise the application code is identical. I was able to port over the client side demo application in about 10 minutes, which is great! Yes, and that is awesome. What I worry is that the reverse, moving 'server side blazor' to client side blazor \*wont\* be that simple. People keep waving their hands and saying, the components run anywhere! ...but when I see examples of 'server side blazor' that \*literally use [System.IO](https://System.IO)\*, and direct database connections, I feel the urge to bang my head against the desk when they blandly turn and say, 'but its just a configuration change to run it on the client'.
Yep. A couple of years now with no issues.
&gt;.but when I see examples of 'server side blazor' that literally use System.IO, and direct database connections That's the part they always glance over in demos and it's a bit disingenuous. Client side Blazor will be great to replace something like an Angular app, but you'll still need a layer of server side APIs for the UI to access data.
I was personally interested in both, specifically server-side for our use-case at work on an intranet portal. That being said, I think both could be useful for sure. But I agree that the names are too similar, I have a feeling searching for "client side" vs "server side" blazor resources is going to be kind of a PITA because everything will be lumped into a search time "Blazor" making it hard to find exactly what you want quickly.
It really wasn't. I did figure it out though. You just use the regular ol' Microsoft.ApplicationInsights package. Then you just it all up manually and don't forget to flush the telemetry before quitting.
Can't you simply make your middleware configurable by passing in options when registering it? See these articles for examples: https://adamstorr.azurewebsites.net/blog/aspnetcore-exploring-custom-middleware https://tahirnaushad.com/2017/08/29/passing-parameters-to-middleware-in-asp-net-core-2-0/ The first article is the most helpful one, while the seconds improves a little on the info from the first, due to illustrating the differences between (what the author calls) *instance types* and *function types*. There's nothing preventing your options class from having a list of `IProcessor` instances, so you could simply create and add whatever processors to the options when configuring the middleware. The middleware the iterates through the list when and does whatever it wants with them.
I just jumped straight into it. The first few months were a freaking pain, but I had very little web experience. I literally google everything and struggled with things that seems simple now. &amp;#x200B; Honestly, I did pluralsight mvc 5 course and it left me with little understanding. I suggest going through a book, as that has worked very well for me. The little .net core book is a good start and free.
That is really great point! I wish I could upvote you more! To me, server-side Blazor feels like a cop-out. They realized that making client-side work will be PITA, so they took a shortcut and moved the processing to server and now they are promoting as if Blazor was already a finished thing. Just with minor final touches to make it work.
Noted, and corrected the content. Thank you.
You‚Äôre right. This is the best solution. You can upload images to Aws s3 instead of storing it as byte array in database or storing it on the disk. As far as i know, storing them in S3 does not charge you. Aws charges you for GET requests. You can use Aws Cloudfront as your CDN to handle catching, CORS,etc... If you don‚Äôt wanna lose your time learning Aws, store them on the disk. If you wanna scale your application in the future, it‚Äôs better to use a cloud provider.
Backblaze B2 with Cloudfront in front of it is practically free, too, though if you use a ton of bandwidth Cloudfront's going to require you to upgrade to a paid plan or get restricted. &gt; If you don‚Äôt wanna lose your time learning Aws I would say that putting images, js, css, etc. on blob storage to feed back out on web pages is about the easiest thing you can do on the cloud. OP, if you do this - or really however you do it - make sure your HTTP caching headers are set correctly. Ideally, you want the same url to always point to the same content and use 1 year cache length. Use a new file name or cache-busting query string parameter if the content changes.
Just wondering, how exactly do updates and versions work on managed databases like this? Do you need to update your apps to ensure they support the latest db version if they are constantly updated? Or are you able to stay on an existing version and you just get security updates?
I've stored PDFs and Images in the database, and it was a great decision at the company I was at. 1, because we were not allowed to use the cloud, 2, the internal cost for 1gb on a flaky network drive was the same as 1gb on a database server which had a higher uptime. Everyone hated us for it until the network drive would crash for an hour because of some weird DFS bug with how it was setup. With that out of the way, don't store files on disk. If they are on disk, and you are serving them straight from the web server, you have to start watching for content type and someone uploading a reverse shell. Store them in Azure Blob Storage or S3, keep all the files private and authorize each request for an image with a Signed URL (what S3 calls it). Solves a lot of issues, and keeps people from hotlinking the images on other domains because refer headers can't be trusted these days.
Honestly, this would be an awesome option if we weren't a small team that's already pretty overworked. I'm the senior front end developer, so most of my time is spent pair programming with others to help them, I don't see much time in the foreseeable future to do this to benefit me, but I'll definitely ask our Architect, as he's the one I'd want to learn from.
Awesome, I'll check him out!
I've tried playing around with the template projects in VS and generally understand them. I just feel like our architecture at my work is super over-engineered. It's very complex, especially with all our microservices, and doesn't follow the same structure as a templated .NET Core app. I know our junior .NET guy has had a hard time adjusting over the past year because of it. "Jumping into it" is what I've done for the past year, but without being focused on the back end specifically, the only knowledge I've really picked up is specific to certain things I need to add or change, not the entire ecosystem. There are things I know better than the .NET guys because of it, but that definitely doesn't make me full stack :P
All the updates are backwards compatible, I believe.
same issue here for me, not sure how to resolve it. Even gave docker CE 16GB of my host ram and 4 cpu cores
If you wait until the Build confrence (May 6-8) they'll announce the release date of Core 3/Serverside blazor then, which may inform your decision.
&gt; at the cost of scalability can you please elaborate why websockets are any less scalable than alternatives?
Read more about web sockets. They're not your bare bones HTTP. They keep a constantly open connection that allows for real-time full-duplex transfer. This takes a heavy toll on the server resources so it can keep a lot fewer open connections at a time. In contrast, with HTTP you can have hundreds of thousands of concurrent users at a time on a mid-range server machine without any issues.
Also, one should keep in mind that when performing an update all the POCO classes will get overwritten. This means that if one used data annotations, all of that will be gone. A solution is to move data annotations to a partial class. This is something I wish I knew sooner.
" I would caution against storing full paths " hit me right in the feels man. I have made that mistake.
I have just accepted that it is what it is and don't use docker while debugging.
Yes I was wondering if anyone else was good with the IDEA of storing docs / pics in DB, I have been storing items in Databases for years now, it was especially nice once SQL Server added support for support doc type full context searching ... then the users were able to do search for all supported doc types containing certain information, I got big kudos for that they thought it was only available with expensive document imaging software ... Also everything was backed up with the database backups... also one less place to have security on, I can deal with a peprson who has no security on Shares (Exaggeration) but I get to lock down the Database so no one can get to the Pictures without going through the app or getting a copy of Database and restoring somewhere else and extracting the Binaries if no encryption is being used.
I started developing crappy not mission critical enterprise apps straight out of school. I had very little guidance, therefore, I had to research everything on my own. &amp;#x200B; I actually found plurarsight to be a weak resource. I had a much better luck with books and trying to find discussion on topics that interested me on stackoverflow. &amp;#x200B; I can recommend: * The little .net core book (free and available online) * [ASP.NET](https://ASP.NET) CORE in action * Entity Framework Core in action (if you are going to use EF for data access) * Pro [ASP.NET](https://ASP.NET) Core 2
Precisely, anyone can glue some code together, but to go back and make changes in that code in a year or two is another story. &amp;#x200B; I don't want to judge parent comment but "just writing code" can be really expensive and can lead to catastrophic problems if the applications are mission critical.
Precisely my point. I store enough in the database to differentiate the image from others in the store and I keep the root part of the path in config. Works like a champ.
Agree.
I chose swashbuckle over nswag for my most recent API but I liked Nswag. The only thing that really made me switch was the better documentation surrounding oauth2 for swashbuckle. &amp;#x200B; I'm guessing it's implemented in nswag but i didn't see a great tutorial for it.
thank you very much for this. I am trying to think a lot more "DevOps" and work at a company who do things in a very late 2000's kind of way. Most DevOps stuff online revolves around Linux and I know the 5 videos (hopefully just so far) in this series are focused on the code rather than infrastructure - but I'm glad I have a few hours of content to watch and hopefully gain insight from!
But Server-Side Blazor will be officially launched as Razor Components in 3.0, leaving Blazor to once again only refer to client side using WASM and remain experimental while things like performance are worked on more. Comparing Blazor (client) now to something like Angular or React and the performance isn't quite there (think there is still some debugger stuff to be done too, but could be wrong as I've not looked at it for a few months). Think that is the key thing really as it is a comparison. May as well wait and do it right to be properly competitive against the current frontend dynamic
So how would I accidentally write a logging to file in an exception handler that puts me back into the try block? This was planned.
I found reading textbooks THEN going to a pluralsight course is much more beneficial. I find it hard to learn something new when i have to pay attention to someone speaking and typing at the same time.
I have never met someone who benefited from the certification itself. I have benefited greatly from studying for the exams. I just don't bother taking the exam itself most of the time.
I was in a project having issues with performance. So previous developers added more logging to identify what is the root cause. It turned out that NLog config had a synchronous target to file and each request was waiting for access to append log
Do it, pay the exam separately thou, no courses, the content is knowledge like mentioned but completing it shows discipline and that you reach your goals, it helps with selling your soft skills basically, but tech wise its just a start
That's a good idea, did you use the Microsoft Learning Partner Network to prepare?
Maybe ask that guy: [https://iamtimcorey.com/ask-tim-which-certification/](https://iamtimcorey.com/ask-tim-which-certification/). I have never been certified but I intend to do so in the near future, no for the certification itself but to prove to myself what I am capable of. To that regard, /u/grauenwolf advise is on point.
Nope. Mostly MS Press books
Certifications are greatly appreciated in the IT/sysadmin world but can actually hurt your odds in the developer world. It's so rare that it makes people skeptical and suspicious. I'm not making this up. I have never seen it benefit someone outside of devops related tasks like database/cloud-service certs.
Certs for developers are generally only good for marketing materials to a consulting shop. If you are short on real work experience, it might help your resume. But having a cert with less than 2 years experience probably won't get you hired over someone with 5+ years (everything else being equal).
Eh, my previous employer required me to get these certifications for raises. It definitely hasn't hurt me, and it gives me an interesting conversation piece to talk about in interviews. (What I learned, how it improved my skills as a developer).
There was a huge rash of 90-day MS certified dev courses in the late '90s/early-2000s. People would come in to interview and would clearly not know anything at all. It got to the point where, to me, certification on a resume was a red flag.
I got it to work by omitting the unwinding: _routes.Aggregate() .Match(r =&gt; r.Id == routeId) .ReplaceRoot(r =&gt; new { r.Buses }) .ToListAsync(); This should give you: { "Buses" : [{ ... }, { ... }] }
i can offer you a solution that uses MongoDAL, which is just a wrapper around the c# driver that hides most of the complexity of the driver. ```csharp using System; using System.Linq; using MongoDAL; namespace BusRoutes { class Route : Entity { public string name { get; set; } public bool isActive { get; set; } public Bus[] buses { get; set; } } class Bus { public int capacity { get; set; } public string time { get; set; } public string direction { get; set; } } class Program { static void Main(string[] args) { new DB("busroutes"); var routeA = new Route { name = "Route A", buses = new Bus[] { new Bus { capacity = 15, direction = "Inbound", time = "8:00:00"}, new Bus { capacity = 25, direction = "Outbound", time = "9:00:00" }, new Bus { capacity = 35, direction = "Inbound", time = "10:00:00" } } }; routeA.Save(); var query = routeA.Collection() .Where(r =&gt; r.ID == routeA.ID) .SelectMany(r =&gt; r.buses); Console.WriteLine(query.ToString()); var busesOfRouteA = query.ToArray(); foreach (var bus in busesOfRouteA) { Console.WriteLine(bus.time.ToString()); } Console.ReadKey(); } } } ```
lmao no 9 years working , never once seen a certification in .net worth the paper to wipe your ass with
I don't know why I didn't think about that feature of unwind. I'll make sure to try it. Thanks!
That's a very nice approach. I'll give it a chance as soon as I get to my computer. Thanks for the help!
The process of learning for the cert has value IMO. Microsoft's programs are usually pretty good. Sometimes they throw some trivial MS-centric stuff in there, but it's often good features that are just terminally underutilized and commercial products take over due to marketing...
Signed, I've learned a lot from the MS Press books and the process of studying for some certs. At the same time, you also learn a lot picking up good books in general. I don't see the cert series as necessarily better or worse, but taking a test gives you a motivation to study properly.