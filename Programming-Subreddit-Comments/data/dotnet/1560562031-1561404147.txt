first, raise you hand if you actually do TDD as its prescribed ;-)
I know it' not much, but .NET Framework 4.8 now uses the same JIT engine that .NET Core 2.1 uses. But granted, there's no guarantee Microsoft will do the same with future releases.
I have yet to work anywhere that did it in any consistent way at all, or in most cases at all. Where I recently was for a short while we had an agile coach. I was the only one the team actually wanting to listen to him and see how we could improve things and we worked a bit on a mock up TDD I think with NUnit. I'm sold. Now I'm looking for a new position and they are all asking so I want to get good enough to at least talk intelligently and not stumble around too much when I start. So what's the most popular framework or best? Poking around a little I'm getting the idea core has one built in..xUnit or something. Yeah, I'm a little confused. Maybe which doesn't matter as long as I have the concepts down a bit better.
Too many people would raise their hand. It was a real eye opening experience for me when I paired with people who practiced TDD...rather than what can only be described as ‚ÄúFirst, write tests that verify the exact implementation details I already have in mind.‚Äù
https://github.com/dotnet/coreclr/blob/master/Documentation/building/android.md
&gt; Now I'm looking for a new position and they are all asking As a heads up, many ask, very few ever do it properly if at all. Be sure to know it to talk on it and be able to walk the talk but dont be surprised if once you get there the TDD policy is lip service. It is a great idea that works best with codebases developed with it in mind from the very start. A large majority of projects are older than that with a lot of legacy holding them down. In these code bases you'll be lucky if you can even run a unit test.
Does VS 2019 for Mac have the same option you need to enable for preview builds of .net core sdk? https://stackoverflow.com/questions/56327404/how-to-enable-net-core-3-preview-sdk-in-vs2019
It does not. It‚Äôs supposed to be an automatic change once you switch to the Preview channel.
Front end rendering is faster when you switch between pages. SSR is better for search engine optimization. But this is not totally true anymore
We're using xunit and it's working pretty good for us. Trying to do TDD where we can, but really just trying to make sure we're testing at all.
Sad. They had a lot of potential since there was a clear need for an ecosystem updates podcast. I wish them all the best.
&gt; Is it just depending on whether or not you want to build a front end onto the application? Yes, that's pretty much it. A "web app" is an application, meaning it has a user interface; an "API" is an Application Programming Interface, meaning it's meant for other applications to communicate with (not a user).
Is it worth creating an API project outside of a web app for other applications to access your data or would it be better to just create an API route off of the web app?
I‚Äôve used xunit extensively. Using it with AutoFixture makes writing and maintaining thousands and thousands of unit tests bearable, although it is still a lot of work.
Client-side Blazor will help to develop the Full-stack with C#, Hell Yeah!!
I use comments in the JSON configuration just fine.
You don't execute a solution, you only build them, the build output is executable. Solution file is a VS concept so it only works in VS for builds msbuild does not understand solutions so you either tell it what projects to build or you just build everything you find.
lblFade is taking in an Object. While your form is an Object, an Object is not your form. What i mean is, lblUsername does not exist on the System.Object definition and can't be compiled. You can change lblFade to take the type of your form. Or you can cast the frm variable to the type of your form. Or you could create an interface and use that instead of the Object class as your parameter type.
* Azure DevOps * Atlassian JIRA * Trello My preference is Azure DevOps
Am I reading this correct: currently authentification &amp; authorrization only work for server side blazor?
thankyou manitoor!!
I've just had to setup Azure DevOps for our team and it was a breeze to install and setup. We have have it installed in house, rather than in the cloud. Definitely one to consider.
Github for code and issue tracking, Azure DevOps for CI
&gt; msbuild does not understand solutions Sure it does.
well I'll be dammed, its supported now.
At least since 2013 already..
Has not worked for ages, setup a CI system back in 2015 and this would not work at all, don't remember the details of the issue but I ended up building projects. TBF I was working with a massive codebase that was a mess, it may have been part of it.
We have recently switched to something called Clickup after doing some research. We were previously using Monday. It's a very nice tool.
If you're willing to pay a bit and have own server infrastructure - Bitbucket Server + Bamboo Server (all hosted on your servers) are quite cheap for small teams (&lt;=10 people). You can boundle it up with Jira for whole stack. You have ticket/work management system, git code repository, and build server. All easily link together. That's what we use in our company. Another product you can use is Azure DevOps - as others said - it's a full package, containing git, ticketing system and build server. I'm not sure about the pricing, especially for builds. I've used it a bit for personal use, at free tier, but I was running out of free build minutes very quickly.
I've used azure devops and think it's pretty great. It's got source control, CI, CD, some wiki options for documentation, etc. For work tracking, it is definitely more on the feature rich side, but you can just use it as you wish, no need to use all the bells and whistles. It's nice to grow into. Source control is great, pretty full featured git workflows.
Yep. You can still hack your own Auth for client side. But not really worth it if they are going to make it soon anyway
Jira ftw
We just switched over to Notion for wiki/notes/design docs/etc and are loving it so far. And we use Jira Cloud for our bugs/tasks, although none of us really like it very much.
What you want is the industry standard for .net and likely the most versatile and powerful of the mentioned Options: Azure DevOps, formerly branded as Team Foundation Server (TFS). You can either go for Azure DevOps which is hosted in Azure therefore requires a subscription or for Azure DevOps Server which would be hosted on prem in your Datacenter.
Sta away from Jira. Try the bukt in trackers from your CI or code platform. We've used target process with mixed results.
Currently using Github for VCS and PR tracking, CircleCI for CI and JIRA for issue tracking in the company I work for. My personal preference would probably be to use Azure DevOps for CI and Github for everything else. JIRA is improving but still a UX nightmare.
Azure DevOps for sure, fantastic for small teams.
Have you thought of having some kind of message based solution?
Jira
Here's another vote for Azure DevOps For actual time tracking and invite integrative, workflow max and Xero
Thats the catch though. As an experienced developer you use patterns. Those patterns are cemented in the process of writing test, which makes it very hard to break out and do them differently. The cool thing is, you have the tests so you can refactor when it feels dirty.... Amazing that you got to experience TDD at all, people thing im a bloody alien when I mention it.
Testing framework? Couldnt give a rats arse, they are all the same. Stubs v mocks? Stubs rule, mockists like making their life complex...
Throwing Gitlab in, wondering nobody mentioned it yet. Full pipeline.Git, CI, Docker Reg, Issue Tracking, etc.
What is CI?
Use \`.HasFlag()\` when on netcore2.1 and newer. Else, \`!= 0\` is better, simply because it is shorter imo
Why not dev ops for code and CI?
we use Jira, but we sync tasks to TFS with tfs4jira (it mostly works) for commit tagging only.
For us it's because we prefer githubs style of issue tracking and plugin marketplace. We actually moved our code from Azure DevOps to github to take advantage of the marketplace and just the general support most other platforms have for github.
Ok will check it out, thanks
Continuous Integration. If you're not familiar with that, it means things like running tests on each new commit, so that the code is constantly checked for quality.
Thanks
Hangfire.io
Ignore talk of speed. Sure it might be faster but the difference would be negligible and almost certainly imperceptible.
At work we use Redmine for our biggest client (which they host + have access to), and a custom/internal system for everything else.
We use Jira and it sucks. I wish we were using Azure DevOps.
My issue with BitBucket is that you don't get the developer metrics that you get for free with Github and Gitlab.
The atlassian tools are great due to the integration between wiki, stories, code, and day to day workboard.
We use jira and its pretty shit.
Targetprocess is great when you have people who know how to make and manage boards and most of it's features. It's enterprise-size of a software though, with insane amount of features, most people won't need on day to day basis.
What do you mean by this? The reason to use Async await is to avoid spaghetti. Go uses messages in a clean syntax though.
I spent nearly a year with Pivotal Tracker recently. There are some things I don't like about it, but it gets out of your way. It works well for a lean approach as it is made by a company that places a lot of value in iterative problem solving. Not sure what the pricing model is like.
Backed by database üôÇ The syntax is inferior to Async await and Nintex workflow engine. The users will not accept that. But then my users do not want to type await. Premature optimization. We could modify hangfire.io to a better syntax and compile that to. NET. We do not want to create a product. Open source is fine.
We use jira at work and I love it. Been using it for, what, 8 years now. What don't you like?
The massive complexity and setup time. And the performance is pretty bad.
It would be pretty useless if you couldn't. Utf8Json is still faster, and you can customize that about as much as you want.
For anyone else reading this is a valid answer. It does a lot and can be used for probably anything you need but that complexity comes with a cost. Few people in an org will understand how to set it up and if you‚Äôre the guy you‚Äôre always undoing people‚Äôs screw ups or handling random requests for them. What it has is great. I use it and it‚Äôs good for what we need it for, but it also has a ton of stuff we need. And it can have its performance moments. Also, I‚Äôm ‚Äúthe guy‚Äù so that sucks.
In my opinion, async/ await and workflows are different beasts. In workflows you typically don‚Äôt await for anything (not in the sense of async/await). You usually have a workflow engine that deals with scheduling of specific tasks, persisting the state of the workflows and sending them to sleep when there is a task that cannot continue (for example requires intervention), awakens them when some conditions happen (for example the intervention has been done). Internally the workflow engine and the tasks can use async await, but in your code, outside of the engine or the tasks you don‚Äôt await them. If anything, I think the way to deal with continuations / notifications could be more messages and events based Hangfire is an engine for scheduling tasks, but AFAIK it‚Äôs not for complex workflows I remember learning some time ago Windows Workflow Foundation, that was precisely for that. However it has been discontinued, and I don‚Äôt know of alternatives
We are using JIRA, works great for us. We integrate it with our repos so we have automatic tracking for commits and stories and our support team also use it so we can connect it with work.
Seconding DevOps. Been using it for a few months from Jira and it's a night and day improvement. Integration of all your tracking, repos, and CI is wonderful compared to how Jira was separate services that had to be loaded up.
Totally agree with Azure DevOps for a .Net shop. Last team I worked with used it in the cloud, but by current workplace likes to keep things on-prem. So I installed Azure DevOps on an internal server and it's great. The automated build and release pipelines are a boon and everything ties in together nicely.
https://www.wikiwand.com/en/Continuous_integration
You really sound like you have no idea what the words you are using mean.
Look into something like a message bus (rabbitmq), there's no spaghetti in using asynchronous events when properly implemented
 yeah maybe I don‚Äôt like the name of that Byte Code of . NET. Intermediate language or so. I have seen people transpile to JS to C# and to asm. Or to C. Maybe Byte code is to bare metal.
So why did we get Async await in JS then. At least I was told JS got it. I know it from C# and have to support old browser. Implementation is always the same. Only syntax gets more readable. Message Bus? This Gartner Consulting stuff? It‚Äôs like any bus. Sometimes a lot of components are similar. Sometimes not. Atari 8 bit wanted a bus. But that was just an idea. In reality only secondary low performance expansions sit on the bus. I feel off topic...
Windows Workflow foundation is supplemented by nintex. It is lacking lots of functionality. But mostly I could not print out the workflow. I really love collapsing in code editors, but the editor for windows could not open multiple sections at once. Lots of clicks. Lots of wasted screen space. Lots of words paraphrasing, but ELI5 the difference? I mean sometimes I want to get our consultants into coding. And it has to pop ...
We moved from Azure DevOps to youtrack, bitbucket server, and teamcity all hosted on prem. We got tired of the downtime and data loss on Azure.
Does azure make improvements over TFS?
That‚Äôs really weird. I‚Äôm that guy too but I barely need to change anything and usually it only takes five minutes to adjust anything. What sort of things did you have to change that is burdensome?
We‚Äôve grown so we have more teams now and each team has slightly different requirements and processes.
If they‚Äôre each operating on a different board, I‚Äôm still not sure where the trouble comes in. If they‚Äôre on the same board, you can create different ticket types for each one then?
Azure devops is really great, the pricing is suitable for small teams and you have everything in one place code, issue tracking and ci cd GitHub has also great offers now they changed the model for private repos so its worth taking a look but the issue tracking is far away from azure devops The last one is maybe just a personal thing for me but gitlab is the worst tool a team can choose. I used it extensively in 2 jobs (and using it currently at my work) there are a lot of lacking features the ci/cd is illogical for everyone I know so I say choose anything but gitlab. Keep in mind that if you want a good workflow with github and gitlab you need a decent ci (Jenkins for example) and some decent issue tracking like jira and integrate them all which is too much work compared to a simple azure devops registration. (And you can modify the templates later in azure devops even write some extension if you have some special needs, I have personal experience with a highly customized enterprise project in azure devops and its working really great for that company so there won‚Äôt be a problem if you don‚Äôt like the defaults)
There's no such thing as an industry standard for .NET tooling. There's plenty of other systems with high adoption as well that aren't made by Microsoft and have high adoption rate.
It depends on the application but most web apps also have an API to support them. For example, a SPA (Single Page Application), as might be written with Angular, will have very few actual "pages" (usually just the one to launch the initial UI) and then everything else is driven by AJAX requests to the API. In that case, you absolutely want to host the API at the same site as the application because you'd otherwise have to deal with cross-origin requests (if you host the API and application on separate sites).
If you're using the cloud version it couldn't be easier to set up...
[removed]
So much this.
TFS doesn't exist anymore, it's been rebranded as Azure DevOps Server.
Man. Throw in Microservices for no good reason.
Yeah it‚Äôs more we have like 70 boards and everyone thinks they need something specific or custom. So one person goes in and changes a transition that they don‚Äôt realize is shared by 30 other workflows and now some automated process is broken. It‚Äôs easy to diagnose but there‚Äôs a lot of humbling of people. Is this a permissions problem? Probably. But it‚Äôs also that we don‚Äôt have a real JIRA owner because no one wants to be the JIRA owner. My point wasn‚Äôt to push people away from JIRA. It was to show that it‚Äôs a powerful tool and you get out of it what you put into it. It always bothers me when people shit on it. Usually those people are ignorant of what it can do.
You would essentially have to do something like they do with Azure Functions. That is design your code in a way that you can just re-execute it at any time from the beginning, and cache/store all intermediate results. But an event-based solution would be definitely much much cleaner.
For the specific ask of project management and bug tracking, I would recommend Trello. It gets the job done without the fluff of larger systems.
I was just wondering about your situation, that's all. Sounds hectic.
That is related to my question, yes.
Oh sorry if it came off negatively. Was outside running. Totally just about sharing. I genuinely think JIRA is great, with a few minor performance/UX issues here and there (sometimes it gets stuck in this weird view where the issue preview is constantly loading). Wasn't trying to be aggressive! Peace and love, PEACE AND LOVE!
haha agreed
I work in .net core and .net framework and love it. One of the main draws with .net core is that it is open source and can be ran on Linux as well as other machines now which wasn‚Äôt the case with .net framework.
I had never looked into an on-prem solution but that's nice to know it's an option. Besides the obvious protecting yourself from internet outages or cloud outages, why does your team not use cloud for ado?
I have written a small SPA using events in ko.js. And I definitively do not know how my code works. I optimized performance using try and error. Most events still trigger.
.net Core is fairly new so the transition from .net framework to core at real companies takes time. Where I work we are just now starting to use it. It is very nice.
I recently saw a job offering from a quite large bank to build next gen internet banking using .net core. Adoption will take some time, but signs are here.
What do you consider interesting? I live deep in the woods and even here there are 92 .Net Developer jobs within 50 miles of me. Ranging from space shuttle/missile development, to game development, and medical research. Those seem pretty cool to me. Try searching for .Net Developer rather than [ASP.NET](https://ASP.NET) and that will broaden the listings. It's hyped because it's now cross platform, does everything JavaScript can and more, plus you don't have to learn a new framework every week. My work uses Angular on the front end and [ASP.Net](https://ASP.Net) Core on the backend. However, with the Blazor preview release, we have had drunken coding sessions and almost remade our frontend with not a single line of JavaScript. Once Blazor hits 1.0, we won't have any JavaScript. As an extra bonus, our Jrs were able to jump right in(drunk of course) on day one since they are .Net Developers and we didn't have to teach them JavaScript. &amp;#x200B; Watch this and try it out. It's fun. [https://youtu.be/y7LAbdoNBJA](https://youtu.be/y7LAbdoNBJA)
&gt; I'm assuming most people DON'T want to be working for Old School Tech Companies if they had a choice, the key being if they had a choice. Better pay, better benefits, less likely to suddenly fold, larger projects. Why would someone want to work for some tiny startup that may not even make payroll next week?
Well since I already have a Tech company SWE job I have the right to be more picky at my next job. I personally don't want to work for any of the types of companies you listed. I am more interested in consuming facing web apps using JS, Ruby, and Go. Judge me if you want but that's what I'm genuinely interested in.
That place I was with the agile coach was one of the most legacy places I'd been in ages. I hear after I left it came down from up top that *every* team must be agile, and use tdd and etc etc...and of course those making the decisions had no clue. They brought more people in to try to force it, never understanding what their real issues were at all. It's probably a cf now.
Sounds like the reason why you don't understand the hype is because you have a very limited idea of what is interesting.
Why do you associate Tiny Startup with what I'm trying to say above? I'm talking about a Trendy Tech Company that isn't a startup like Uber or Lyft. They are literally passed the IPO stage and are at this point a Tech company.
We have a licence for DevOps server which is part of our msdn subscription. If we went down the cloud route it would be an expense so it makes sense. Plus we are a government organisation so we need to make best use of the money we have available.
Totally agree. I‚Äôd take GitLab over any other solution. It‚Äôs totally cloud platform agnostic from what I ever had to use it for. You can configure runners for any type of workload and you don‚Äôt have to use the cloud ones as registering and spinning up a few runners on any docker infrastructure is a piece of cake and free if you have hardware at your disposal :-) As you said wiki and issue tracking can be activated at repo level.
Dude. You really need to look into messaging. RabbitMq or similar. You put a message on a queue and let some other service handle the messages. You don't let a http client await for long running tasks. I would say if task is running for more than 5 seconds, you should be looking at messaging.
The basics are you need to convert it into a console app, and set up a system unit service file. Some more advanced stuff you can do look is sig term handling, integrating logging into systems journal etc. I think this library can help https://github.com/tmds/Tmds.Systemd
Yeah, I have no idea why people think start-ups are a good idea. I don't know about u/foreverwantrepreneur , but I like getting paid.
The title is like a bot posting, being sarcastic about buzzwords
TPL probably tries to match threads to physical cores. So something like 100% CPU then wait 30% duty cycle can be interlaced 3 threads. So 8 HT physical cores become like 24 Tasks. 1000 users with 3% CPU are better served by ? Service??? I want to stay single process (Kestrel) Single shared RAM . Just some extensions to TPL for 2 Generation Task Objects. Then when some task in the workflow gets automated, the code stays the same. If we use some traditional message library, we could instead recommend SharePoint. Workflows are said to run online. We have many trainers. My last App was slow on the MS SQL Server. One Query takes 5 s. ASP. NET was Lightning fast.
What you read on Reddit and HackerNews are not what is happening in the real world. The real world is mostly Java with Spring boot. Probably 5x as big asp.netcore
It does. I'm a TFS admin in transition to Azure DevOps and there are a ton of improvements. The new build/release functionality uses YAML scripts, letting you source control your project's CI/CD chain. That's one change I'm really excited for. There are tons more though.
Keep in mind I don't use an orchestrator like Kubernettes, etc., which might change my opinion on this at some point... ENV variables have worked good for setting some "global" settings for me. Specifically, I usually use one like "ASPNETCORE_ENVIRONMENT" set to "Development" (default) or "Production" that I read in to set some global config stuff, or read a config override file. var environmentName = Environment.GetEnvironmentVariable("ASPNETCORE_ENVIRONMENT"); if (string.IsNullOrEmpty(environmentName)) environmentName = "Development"; // Setup config var config = new ConfigurationBuilder() .SetBasePath(Environment.CurrentDirectory) .AddEnvironmentVariables() .AddJsonFile("appsettings.json", optional: false) .AddJsonFile(Path.Combine(Environment.CurrentDirectory, "config", $"appsettings.{environmentName}.json"), optional: true) .Build(); This gives me the following benefits: 1. I have a default config file so all my config values are defaulted. 2. There's a default config template someone can use to create an environment specific config 3. I can have a Development config that is git ignored that I can use for local debugging 4. I can mount a config file into the container for each environment, and still be sure that if someone forgets to, there's a default config there so I know at least nothings going to blow up due to missing config file 5. If I want to use ENV variables instead, this config lets me set things EITHER WAY, ENV var or config file. It does mean you have to manage config files on each env, so in a larger orchestrated environment I'm not sure what that looks like, but I know managing 20+ ENV variables by command line would be annoying... but the benefit above to my config is that if you WANTED to set all that by ENV variable instead, I COULD... I just like the idea of being able to have an actual file. As for YAML vs JSON vs XML or whatever you want to use for config files that's up to you. Personally I'd stick to what the "default" is, which is gonna be JSON nowadays. Any deviation from default is a deviation you have to manage / explain forever to anyone who comes on that isn't familiar. Its usually better to not try to reinvent unless you really need to.
Remember , Microsoft is basically sun setting [asp.net](https://asp.net) Framework , causing all Microsoft houses to plan on moving to new microsoft way of developing. Also remember , every time something new comes out in the devleopment community Ruby on Rails for example was the best thing since slice bread for about two years, Jquery was the end all be all of web development etc. it happens.
If you follow /u/[UK-sHaDoW](https://www.reddit.com/user/UK-sHaDoW/)'s advice and convert your service to a console app, you may be able to keep it as a windows service as well by using the [Top Shelf](https://topshelf.readthedocs.io/en/latest/configuration/quickstart.html) package. That way you can deploy on both platforms relatively easy.
LMAO you are typing "ASP.NET" into the browser, wonder why only "old" companies are using that then asking here why there is hype for ASP.NET Core? You serious?
That title is just a vomit of buzz words
I could double my pay if I joined one. But I turned them down because it was contract so I would not know week to week if I even have a job.
What about Rails or Laravel or Django/Flask?
[removed]
Yeah. Not to mention the rest of generic garbage that comprises this post.
Does the browser need anything downloaded to run Blazor?
–°–ø–∞—Å–∏–±–æ, –î–º–∏—Ç—Ä–∏–π. Do you have an example of it's output against an API?
Atlassian Jira
This question comes up on a fairly regular basis here and I'm sure on the rest of the internet.
Again it's not about loving the framework. I'm talking about the kind of companies that use ASP.NET Core are not the ones that most aspiring web developers want to work for regardless of what framework they use.
Or...maybe you should consider that a lot of people genuinely don't want to work for Medium Sized Traditional Enterprise Businesses in general regardless of what technology stack they use.
For the last time, you can be a non-traditional Enterprise Tech company without being a small startup. Are Lyft, Uber considered small startups? No they are trendy Tech companies not traditional Finance/Government/Medical companies. I think it's a fair bias to not want to work for those kind of companies as a 22 year old living in a Tech Hub.
Have you considered Microsoft as an influencer in marketing .NET Core to their developer community?
Uber and Lyft have never made a dime, are quickly burning through cash reserves, have no significant assets, and a business model that is easily replicated. It's only a matter of time before their ponzi scheme comes crashing down. If you want to use an example, find a viable company.
O.O Dude chill...I was just using that as an example lol What are "viable companies" in your opinion?
A lot of factors go into that, but a good starting point is not losing money on every sale.
You still haven't answered my question: Can you give me an example of a good company that fits YOUR criteria?
Silverlight... Nope, thats why it has a lot of people excited. plus I dont need to choose between 789,000 different javascript frameworks to do the same thing.
Such as???
There are people like that, but that doesn't mean they don't have a very limited idea of what interesting is.
Whether or not they have a limited idea of what interesting is is irrelevant since it doesn't matter...IT'S THEIR DECISION. You can't force them to decide on a broader area of what interesting is. If I was interested only in developing Mobile Apps in Swift, you can't tell me that you would be the guy who likes shoving in their face: LEARN XAMARIN. LEARN XAMARIN. EVERYTHING ELSE SUCKS. No, it's their decision. lol
I think your misunderstanding comes from the fact that companies like Dell, Microsoft, and any other old school tech companies (oil based companies come to mind) are not jobs people aspire to work. Plenty of up and coming web developers would love to work at any of those companies since they pay well and have lots of great benefits. Just because you don't think it's nice to work for those companies doesn't mean others won't either. &gt;I don't understand why there's an overhype of the TECHNICAL MERITS of the language, when in the real world business case, there aren't a lot of work done in ASP.NET Core for really cutting edge Tech Companies? Thoughts? What data do you have to back this up? A simple search on Indeed.com showing older companies using .Net framework doesn't support this conclusion. Are you seriously saying Microsoft for example isn't a cutting edge tech company?
Azure Dev-Ops. You can delete the thread now.
&gt; Plenty of up and coming web developers would love to work at any one of those companies since they pay well and have lots of great benefits. You're missing my point. The point I'm making is saying that IF given a choice, the average Web Developer if given an offer from Google vs. Exxon Mobil/Random Old-School Enterprise Tech Company will likely choose Google if their end goal was Web Development. Exxon Mobil is an Oil Company that has an IT department that does Software work. Google is a SOFTWARE-driven company that has far better pay and benefits than a traditional Enterprise company. This is not conjecture. This is fact. You clearly do not have the ambition to work for a Big N tech company, and that is perfectly fine. But please don't misunderstand the point I'm making.
&gt; You clearly do not have the ambition to work for a Big N tech company Of which Microsoft is one.
Or..maybe you should consider that the majority of web developers don't actually want to work for Google, Facebook, or Amazon.
I'm not here to argue whether or not if Microsoft is actually a TRUE Big N, but typically when people say Big N they are referring to FAANG (Facebook Apple Amazon Netflix Google) and SF Bay Area-oriented companies. Microsoft is a great company with fantastic development tools (like VS Code, TypeScript, etc.), but it's not necessarily in the same Tier as Google or Facebook. But that's besides the point. Microsoft doesn't care if you know C#. My friend had zero C# experience (only Python and JavaScript) and got tested on Leetcode problems at Microsoft in his language of choice. Typically, smaller companies or traditional corporations that use ASP.NET / C# or ASP.NET Core would test you more on domain knowledge and less on Leetcode style problems. So Microsoft is an exception, not THE rule.
Sure, if give a choice between those two companies. But what does that example have to do with .Net Core? **Remember your base question was asking why are people hyping to learn .Net Core.** Not, "Which tech stack should I work if I want to work for Google/Amazon/*Insert Big 5 company here*?" If your initial question was that, then sure, maybe .Net Core isn't the only framework you should focus on learning. I'd argue that whatever framework you learn for those companies doesn't matter in the slightest. Working for Google takes a lot more skills and knowledge than just knowing a certain framework. They look at the impact you create and the potential you will be. If you make tons of projects that generate lots of impact and showcase good software engineering principles, then whether you did that in .Net Core, Nodejs, React, Angular, or whatever doesn't matter. But going back to your original question, why is .Net Core hyped? Well it's a solid framework that adheres to great software engineering principles and has tons of potential for employment. Your chances for getting a job are a lot higher if you learn something that thousands of software companies use compared to focusing on the few companies that are the either the Big 5 or startups.
Yes, but again my situation is different than most people. I apologize that I didn't specify that before. It was my bad. For MY specific situation, I am currently already working at a well known Tech Company as a Full-Time SWE. My tech stack has been JS, Python, and Go. I have not had to even touch Java or C# at all in my career. So wouldn't you say I have the right to be "extra picky" for my NEXT job for my specific situation?
The point I'm trying to make is your comment is essentially MEANINGLESS for MY SITUATION. I'm sure it'll be helpful to some people who have those goals, but for me it's meaningless since I specified the criteria of Google, Facebook, and Amazon, and it's a totally different perspective than your's.
Pluralsight.com
ASP.NET Core Middleware system is very similar to Express so you will feel at home. - The official documentation is very good https://docs.microsoft.com/en-us/aspnet/core/?view=aspnetcore-2.2 - If you want to play around with working samples, check out https://github.com/dodyg/practical-aspnetcore
That is fine, those people just aren't really going to understand the hype around [ASP.Net](https://ASP.Net) Core.
Depends on the situation really. If you get fired and become broke then you should go for any job you can get.
[https://sharegate.com/blog/sharepoint-2013-and-windows-azure-workflow](https://sharegate.com/blog/sharepoint-2013-and-windows-azure-workflow) seems to be about sandboxing. You get a workflow engine for free (included with the base price), already running on a SharePoint client (not on the server), but only limited capability. All potential harmful C# has to go on a third server running a webservice. Potentially harmful here means: Has flow-control instructions !? Can't we have something like sandboxing of JS in modern browsers? You can do sooo much, still mostly not harm the user machine. Okay denial of service is a problem with endless loops in JS..
Ideally, you want to be debugging in a container too, so it‚Äôs as close to live as possible. You can do this fairly easily in VS by making a docker-compose file with build targets and using that as your start project (though in practice a little more fiddly to get working). Marshall all values that will actually be different per environment into env variables, as per 12-Factor Application design principals, and these can easily be fed into docker-compose as .env files at deploy time. Also, in something like kubernetes you‚Äôll probably be using the networking to communicate between container services, so that‚Äôs even less that‚Äôs going to vary between environments.
&gt; I'm assuming most people DON'T want to be working for Old School Tech Companies if they had a choice, the key being if they had a choice. &gt; most if not all of the companies are at: Old School Tech Companies like Dell, Microsoft shops, Consulting companies, and a few Medium-Sized Businesses. &gt; there aren't a lot of work done in ASP.NET Core for really cutting edge Tech Companies You're making an awful lot of unsubstantiated and short-sighted assumptions here. What makes old school tech uninteresting? I prefer casual environments, but if I'm paid enough and there's AC, I'll suit up for work if asked. Why wouldn't I want to get paid well and have a stable job? Dressing nice isn't a *bad* thing. I just don't want to blow money on nice clothes if I'm not getting paid enough to cover wear and tear on the suit. The thing most people hate about old-school companies is the politics in management. And the politics show up in *all* companies with growth and money. You either learn how to dodge the politics, or find a company where they'll shelter the people that want to stay out of it. Or you could hop startups when the politics jump in and burn yourself out. In the end, we want to get paid. Fulfillment is a nice, optional luxury for the privileged. Old school dev environments are a lot more accepting of leaving your work at work and being mercenary about getting paid. They can offer a better work/life balance. Startups frequently want to guilt you into accepting low pay and bad hours for the betterment of society. And what's "cutting edge"? "Big Data", "Machine Learning", "cryptocurrencies" and "block chains" haunted my feed last year. The last two are rarely useful in real life, and the first two are specialized hype hammers swung at problems that normally don't need them. There's libraries for all of that if you really want them. And plenty of shops use multiple languages. I've done several solutions using both .NET and Node code. Most problems have been solved, but very few problems have been completely solved in a user-friendly way that adjusts well with modern life. That last 20% matters a lot more than people think. And some solved problems can become interesting when you combine them. The fusion of old and new tech makes for some really cool things, and can really innovate in an industry. &gt; I'm assuming Austin has a similar Tech Hub environment as SF and NYC and Seattle. Tech hubs follow tech trends. The current trend is full-stack javascript/node development. It's easy (and cheaper) to hire for, and a lot of new libraries and movement comes out for it. It doesn't mean that it's better, just that it's more popular and trendy. And hiring and overworking one full-stack SWE ends up being cheaper than properly staffing and coordinating different departments. That's two hype trends in one: javascript turtles all the way down and forcing your staff to take ownership of everything with a minor pay increase. Which is why it's kind of odd that you're working in the land of the hype in an over-hyped position using the most-hyped language complaining about another language being over-hyped since you can't see it in your hype bubble. But lets tackle the question seriously. Why do people use the languages they use? Some companies stick with PHP because that's what they've always done. It's known. It's a "safe" bet that it's not going anywhere. There's lots of libraries and templates. Some companies follow the current tech trends and use that bleeding-edge schtick for marketing. It also makes it easier to hire young, gullible employees and underpay them. Some have enterprise interests that tend to make enterprise stacks (Java/.NET) popular. And as the size and scope of the project grow, quick and dirty solutions become less attractive as you'll end up implementing all that extra "bloat" you didn't need at the beginning. Javascript frameworks have seen this phenomenon a lot with Angular/Ember/Vue/Mythril. It happens at lower levels, too. In the end, if you're never very successful, it doesn't really matter what language you use. If you do get successful, you'll have to start tuning your costs to increase profits. Which means performance and maintenance burdens start to matter. Lots of popular development stacks get weeded out at this point. Different companies handle this in different ways. Twitter dropped Rails and switched to Scala on the JVM. JVM stuff is really popular as it had the best runtime performance for many years. .Net Core is catching up, but I don't think it's there, yet. You'll also see people moving to implementations on more mature runtimes (e.g. Jython and JRuby on the JVM). And you'll see some companies build transpilers (e.g. Facebook with HHVM). But as a startup you want what's cheap and trendy. Which is usually javascript. Unless you're the first in the door, you don't get to pick the stack. So startups in tech hubs are most likely to be javascript shops. After some time, the startup will fail, pivot, or take off. At that point, development and runtime costs have a much stronger influence than they do in the beginning of a startup. And you'll probably have the funding to rewrite if you have to once you hit it big. So you might as well follow the trend that gets you the most starry-eyed applicants at the cheapest rate. That's probably why you don't see as much .NET in the startup hype bubble. It's not the ideal choice for the MBA reality-distorters running the show. Other answers for why people prefer .Net Core that you might not see: 1. Desktop and server development have different needs where javascript becomes *much* less attractive. 2. .NET now has community momentum *in addition to* the enterprise support that's brought people in. 3. Desktop interop needs language and runtime support, and older languages have a lot more weight in those areas. Not everyone wants web apps. 4. Having a strongly-typed language is *really* nice when your project grows. 5. There's been some major public flubs in JS land - npm meltdowns, node package installers, etc. They happen in enterprise frameworks, too, but not as frequently. Having compiled builds is a real plus when you look at the dependency tree for a node project. 6. The Javascript ecosystem currently places a rather unreasonable burden on developers to stay relevant. Especially full-stack engineers. .NET has a *lot* less churn, and what churn there is has a really good reason for being there. That gives you a lot more time to either get your actual work done, or live your life. The hype is mostly about the new community collaboration. The platform stability has always been there. It's just that now we don't have to wait in the basement for Microsoft to toss the scraps down to us anymore.
I looked at the website, but I do not get it. I used the message broker in MS SQL Server. customers turned that thing of as a first step when trouble shooting, so there must be something difficult is writing such a broker. trouble is, the customer did not yet specify workload. I do not think I have to scale. Also: As a physicist I -- in my mind -- separate quality and quantity. The quality of Jupiter and an apple is being governed by the law of gravity. The mass is vastly different. Radio and X-rays are governed by Maxwells equations, the frequency is vastly different. So to memorize TPL and workflows in my same head I have to store them as same quality, but different quantity. Timescale in the ¬µs rang vs timescale of weeks (yeah we usually have slow customers). Still only a quantitative difference. &lt;insert reference to Stalin here &gt; This quantitative optimization is premature for a programmer. The runtime should decide that.
I think your in over your head. Or simply trolling.
I made this some time ago, should still be working &amp;#x200B; &lt;% Class MailChimp &amp;#x200B; public function Subscribe(email) Subscribe = AddToList(MailChimp\_ListID, email) end function &amp;#x200B; public function AddToList(list\_id, email) Dim data data = "&amp;double\_optin=false&amp;email\_address=" &amp; email &amp; \_ "&amp;id=" &amp; list\_id AddToList = PostToMailChimp("listSubscribe", data) end function &amp;#x200B; function PostToMailChimp(method, data) dim sEndPoint, sAPIKey &amp;#x200B; sEndPoint = Mailchimp\_EndPoint sAPIKey = MailChimp\_APIKey &amp;#x200B; data = "output=json&amp;apikey=" &amp; sAPIKey &amp; data &amp;#x200B; Dim xmlhttp Set xmlhttp = Server.Createobject("MSXML2.ServerXMLHTTP") [xmlhttp.Open](https://xmlhttp.Open) "POST", sEndpoint &amp; "?method=" &amp; method,false xmlhttp.setRequestHeader "Content-Type", "application/x-www-form-urlencoded" xmlhttp.send data resp = xmlhttp.responsetext Set xmlhttp = Nothing PostToMailChimp = resp end function End Class %&gt;
This is one of those problems that is always more challenging than people think. We use Quartz a lot when tasks need to be run on a schedule but won't cause a fire if they don't. Windows service when it's critical but they are annoying to maintain. Console app plus windows scheduled task avoids installing services but is also a maintenance headache because we always forget they exist. Systemd would be awesome!
I‚Äôm a big fan of https://purecss.io/
There is absolutely no need for any third party libraries to accomplish these tasks. This article is misguided.
I think material design looks pretty nice. css only: https://materializecss.com/ Razor pages / Blazor https://www.matblazor.com/ Angular https://material.angular.io/
Totally. Sounds simple, but isn't. Does the new scheduler allow a functionality like "kill the task if it doesnt complete in X second?" That's another issue I always have, is I have some tasks which can potentially have an issue and I really want to make sure they are stopped if they get hung for whatever reason.. but I'm really sick of having to throw things in new threads to ensure killing it and handling that.. cancellation tokens are not always an option, or I simply dont want to take the time to implement them properly.
Did you use TypeScript at all?
Not really, I messed around with it for a few hours but that‚Äôs about it
I‚Äôll give it a try thanks
I‚Äôll definitely look at these thanks!
Well, .Net 5 will be .Net Core so he‚Äôs not necessarily wrong.
The naming is already confusing as it is, it will only get more confusing, and he using the wrong name now already does not help.
Your Java experience is going to be better than your node experience here. You might find some similarities between the new `dotnet` commands/tooling in usage alone but everything under the hood of aspnet and .net core is very different than node/java. But you sound young and you know other languages so just tackle C# and aspnet as you would a complete beginner and you will be fine. Also smart move going into aspnet and c# and core right now. They are very hot technology a lot of companies are using. Theres no shortage of jobs. And core is a pleasure to work with.
Call me simple but IMO Bootstrap is where it's at. It's massively popular and gets the job done.
Hell ya bootstrap it up! Easiest way to get something nice and modern, really fast.
React https://material-ui.com/ Vue https://vuetifyjs.com/en/
The article invited critique on how to handle the configuration of fiddler, and I personally dislike compiler flags and prefer to use dependency injection and an IOC container to provide different implementations. If I were to configure the usage of fiddler, I'd rather use a MediatR request handler abstraction to dispatch the requests between a DoSomething and a DoNothing implementation based on an IOptionSnapshot boolean value loaded from an IConfiguration backed by an optional appsettings.json with defaults to dispatch to the DoNothing implementation so that if I forget to start fiddler until after I start debugging I can just toggle the value in the JSON when I'm ready to connect and requests then begin being dispatched to the DoSomething implementation. In development I would configure the IOptionSnapshot to reload on each dispatch, while in production I would configure it to cache the configuration to avoid I/O bottlenecks.
I'm not going to make your argument for you.
&gt; &gt; But please don't misunderstand the point I'm making. There's a reason why I stated you should ask for what you want. &gt; Remember your base question was asking why are people hyping to learn .Net Core. Not, "Which tech stack should I learn if I want to work for Google/Amazon/Insert Big 5 company here?" If your initial question was that, then sure, maybe .Net Core isn't the only framework you should focus on learning.
There is a reason so many websites these days use Bootstrap. It's become ubiquitous with clean and fast development. Plus it really isn't that hard to skin it how ever you want anyway.
I meant things other than our own DTOs. Things like NodaTime types. I don't think this is possible at the moment, but on the roadmap.
No
Even on external monitor the sql query screen flickers and hangs VS. you need to pull it out. even then sometimes it flickers.
Nope, what's the CPU doing? It sounds like a machine issue tbh. Are you running it on an SSD? By it's nature VS very file access dependent so it really likes running on fast SSDs (for program files but especially for source files). I also tend to exclude my Source file directories from real time virus scanning (lots of small files are very intensive on disk and CPU for virus scanners. Other than that the usual answer is 'are you running extensions'?
I have VS running on 3 different PC's. It hangs on all of them. Yes, they all are running SSD's.
been using since preview, never experienced such issue
Nope. It even works fine (albeit a tad slow) on a 2007 Core 2 Duo laptop with 4GB of RAM.
Did you install any extensions?
Not experiencing this on any build of 19. I have the regular build and the preview builds installed side by side. Even switching back and forth I‚Äôve never had any problems. Are you able to capture any of the dumps when it does?
This is really well done! As somebody who has done this in a project I can say this is close to what I came up with. There were a lotta gotchas that I ran into that your article did a great job of making clear. Only suggestion I would have is to show how to integrate this with Azure SignalR :)
No.
Debug it and give us the details?
Or have one app that runs every 5 seconds that uses MEF to scan for job dlls implementing a custom interface
Bulma isn‚Äôt enough? It‚Äôs really good for layout stuff then you just skin it.
Yeah I used Bulma in a pet project and I really like it!
No issues here! VS2015 was a freezing nightmare for a while but 19 is treating me well. Try reinstalling it, maybe some settings got mangled.
Rails is basically dead and django is probably is some smaller shops but isn't used in large applications, there it's all Java on the backend.
I still don't see why it's so hard to just give an example of a company that you described above Like would a Microsoft fit the bill? What about Dell?
Yes, and any job I can get doesn't have to be ASP.NET Core specific jobs since JS still has more than enough jobs to choose from. You make it sound like JS is on the decline. Lol
Yeah and the people who complain about bootstrap are a bit ‚Äúpurist‚Äù in my opinion. Yes your website doesn‚Äôt look totally unique but it doesn‚Äôt have to. I think commonality between websites actually helps users acclimate much better
Look man. I think anyone has the right to not want to work for old fashioned companies. It's a personal decision. I think that's fair game and nothing wrong with that decision. You can't expect to force everyone to want to work for the same type of companies as you.
I was talking about in general. Sometimes needs must.
I was experiencing it, especially when debugging. It was my AV/EDR agent.
Odd, by a 'hang' do you mean becomes 'irrecoverably unresponsive' (so never unfreezes?) or 'becomes unresponsive for a short time'? I've seen the latter (something locks the UI thread but eventually returns) but the former is super rare for me.. However you really should send feedback to the team if this happens regularly for your configuration(s). It shouldnv't.
Same! I‚Äôve used it on 3 projects now. It‚Äôs so easy to use and manipulate
&gt; You're making an awful lot of unsubstantiated and short-sighted assumptions here. Summed up the OP in one sentence.
What do you use to view structured logs?
Try to first make wireframes in photoshop or paint.net Then you can start implementing that in css
Absolutely bootstrap. If you build and Angular website then use Angular Material and Angular Flex. Otherwise bootstrap is king.
Before you modify your app at all * Invest some time into learning about 50% - 75% of bootstrap by creating example pages outside of your app. These can be plain html documents that reference the CDN version of bootstrap. * Create mockups on paper or in software for each page. Since you learned bootstrap already, you will have a good idea of the building blocks you have to work with. * Do an analysis on your models/views. Are they going to need more information to handle presentation logic? Do you need to pass css classes or theme information into the view? Maybe you need to swap out some of your models with viewmodels to handle this and keep your views simple.
Great job! I'm really looking forward to where Blazor will take. Net
&gt; It's a personal decision. This is true. But you came into this thinking that no one works for an old-fashioned company by choice. Remember? Here's your quote. &gt; I'm assuming most people DON'T want to be working for Old School Tech Companies if they had a choice, the key being if they had a choice. Which is also subtly treating the people who work there as dumb or incompetent. Because no one would actually *want* to work there, so they must be an idiot or too terrible to work at a better job, right? Backtracking to "it's a personal decision" when you devalue the decisions others make is a defensive move people make when they get called out on being passive aggressive. &gt; You can't expect to force everyone to want to work for the same type of companies as you. Very true. It's kind of weird that you didn't already know this yesterday when you asked your question. It's one of the reasons why I said your assumption that everyone wants what you want was unsubstantiated and short-sighted. You had an uninformed opinion based on ignorant stereotypes about companies and the people who work there. Several people have been making efforts to give you the information to correct that bias. I was more blunt and turned your words around to show that your career decisions have been driven by at least as much hype as anyone else. And also pointed out that your disdain for the life choices of others is a mark of the privileged life you lead. That's why I said &gt; &gt; In the end, we want to get paid. Fulfillment is a nice, optional luxury for the privileged. I think full-stack positions devalue wages in the marketplace. It hurts the workers - the software engineers - in exchange for a little more corporate profit. It turns two jobs into one job and pays that person somewhere around 110-125%. It also increases the likelihood of important oversights when you give someone too many responsibilities. I don't think it's a position that should exist in a well-funded company. But, at the same time, "we want to get paid". I don't blame people for taking a paying job. Ideals like solidarity and progressive employee rights tend to be less important than having food and a place to live. Not blaming them for a selfish decision is different from letting them strut around like they're somehow better than everyone else. And honestly, your question was super dismissive of the *technical merits* of the language. Which is one of the major reasons people choose languages and stacks when they can. Because it makes their job easier and more interesting. Remember that? &gt; I don't understand why there's an overhype of the TECHNICAL MERITS of the language, when in the real world business case, there aren't a lot of work done in ASP.NET Core for really cutting edge Tech Companies? Yeah, that's you. Super classy. Hype is when people market something based on things other than technical, functional merit. Hype is marketing. The real question is "Why are the *technical merits* being treated as hype and the cargo-cult JS programming circle-jerk not?" Is it really that surprising that people would want to just focus on the technical aspect of solving problems and would rather avoid living in a hype-filled tech hub overflowing with self-righteous self-promotion? After all, as you said, &gt; You can't expect to force everyone to want to work for the same type of companies as you. You're welcome to live the kind of life you want to live. Not that you need permission or validation. But you'll get a lot more respect from others if you at least *try* to be tactful about treating them like fools and idiots for thinking differently. You might think you're changing the world in your ground-breaking startup. It's possibly true. But you're also changing the world by arrogantly dismissing people who have different priorities and lifestyles as you. And that's the kind of change that we don't need.
Go look at your original question. &gt; &gt; &gt; &gt; &gt; So where's all the hype coming from for ASP.NET Core? You're literally asking people why they're excited about something that you're not excited about. You're asking for help understanding something. Why would you ask for someone else's opinion of why they think the way they do just to throw it in their face? It's extremely juvenile and rude. &gt; it's a totally different perspective than your's. Yes, a perspective which **you asked for**. Even if you disagree, your opinion is still safely your opinion. No one's making decisions for you. If you wanted to know why *you* should pick .NET Core, then you should have asked that question instead. It'd be way better than these narcissistic attacks on people after you solicited a genuine opinion from them. Don't get so worked up when people give you honest answers. It's embarrassing to watch.
Let's start with the basics. Can you answer this question for me? Let's forget about everything that I've said in the past and start with a clean state. If I were a complete beginner who wanted to learn Web Development in 2019, would you honestly tell me to my face: Screw JS. JS sucks as a language. Focus on C# and that alone? Or would you tell me: I would learn Full-Stack JS so you at least can learn Web Development in one language and you probably will need JS on the front-end anyways. Only learn C# when you need to for a job? Fundamentally speaking, that is the type of question I was asking. It has nothing to do with prestige or whatever. Let me give you an example. Let's say I got a job at IBM in SF Bay Area as a Full-Stack SWE. Now, IBM is definitely not Google or Facebook. If anything, it's an old-timer traditional enterprise company. You might assume that the average New Grad SWE at IBM will likely be working on Java (Java Spring/J2EE), maybe C#. IBM is hiring Full-Stack JS Developers for New Grad SWE roles. JavaScript. Python. Node. Flask. Isn't it shocking to you that Java or C# isn't even mentioned in those job roles? Why do you think that is? This is IBM, an old fashioned enterprise company. The purpose I'm saying is, even older corporations are adopting Full-Stack JS, Python, Flask, AI/ML work. Most of the ASP.NET / ASP.NET Core roles are for companies like Liberty Mutual Insurance. Fidelity Investments. Blank Medical Center. These are fine companies to work for, but for the average BRAND NEW 22-YEAR-OLD Developer, I'm talking about the YOUNG developers (not the mid-career, older developers who have families), The Hungry Young Developers / Millennials living in a Tech Hub and have the resources to do so would rather work for Google than for Fidelity Investments. I don't think this is an unfair statement to make, since Young Developers want to be working on Web/Mobile Apps more than likely wanting to be working for Enterprise Banking App if they had a choice. Yes, there are exceptions. Those exist. But I'm not saying any path is good or bad, and if I did in the past, I strongly apologize.
If you actually read the POST and not just the HEADLINE, you would know the actual question I was trying to ask - FOR MY SITUATION, why would I want to learn C# and ASP.NET Core, i.e. Does the HYPE apply to me? It's a simple yes or no question. We don't need to take this personally dude. You need to chill the heck out.
Kibana
&gt; FOR MY SITUATION, why would I want to learn C# and ASP.NET Core, i.e. Does the HYPE apply to me? That's not what the title of your post says. Like I said, you should ask for what you want.
&gt; You need to chill the heck out. That's at least twice you've said that in here. Count how many times you have SHOUTED at OTHERS. Seems like you've already made up your mind and are just trolling, if you weren't from the start. Go away.
You tried turning off your Antivirus temporarily?
&gt; Seems like you've already made up your mind and are just trolling, if you weren't from the start. I do not think he is actually trolling. I think it's pretty much [what this guy said]: &gt; You're asking a question, then arguing against every answer given to you. It seems like you want to appear knowledgeable, and that's more important to you than considering the answers people are trying to give.
Or that :) The vast amount of negativity but "oh i'm not shitting on it" even back to the OP was my thinking.
&gt; Or would you tell me: I would learn Full-Stack JS so you at least can learn Web Development in one language and you probably will need JS on the front-end anyways. Only learn C# when you need to for a job? I would tell you to learn Javascript (but I already told you this a million times) because Javascript is the language that is used on the front-end. If you do any sort of front-end work, you're most likely going to use Javascript. That's why they teach Javascript at bootcamps. Any bootcamp worth their salt is teaching Javascript in their curriculum. Also, that is not the question you asked. The question you asked is "Why all the hype for C# and ASP.NET Core?" and "So where's all the hype coming from for ASP.NET Core?"
The point is not whether or not I've made up my mind. I THINK I know how to approach the problem, but I'm not 100% sure if it's 100% right or not. That being said, telling me to learn ASP.NET Core without giving me a specific explanation of why it would help MY SPECIFIC SITUATION is the issue here. All the responses have been generalizations based on your experiences rather than something like this: "Since you mentioned that you wanted to do this, I think that sticking to this would help you more than learning this." Instead, the responses are: "We think ASP.NET Core and C# has these advantages." That's fine and all, but they are two completely different points. If I had the ability on Reddit to change the Title right now to ask a clearer question I would. But until that feature is added to Reddit, please just take my actual question into consideration, and forget about everything else.
Dude, I see your posts clear and center. I understand your points on Haskell and all that. I see your posts. I'm just looking for an alternative opinion. It's a fair game concern. You might say: You sound a little bit erratic and unstable. Fair enough, but again if I'm not breaking any rules, it's fair game. Just let it happen man.
&gt; I'm just not sure why it would be good FOR ME. This is why I specifically told you to ask for what you want. The title of your post is `Why all the hype for C# and ASP.NET Core?` not `Why would learning C# and ASP.NET be beneficial for me?` You asked a general question, so you got general answers. Ask for what you want. As in the title of this post should have been `Why would learning C# and ASP.NET be beneficial for me?`
Yes understood. I'm not blaming anyone nor do I have the right to blame someone for not understanding the question. I'm just setting the stage now that my point is why would learning this be beneficial for me specifically.
I experience complete hangs on startup, 0% cpu usage, about 20% of the time.
I found that Defender slowed it down significantly. I disabled defender, and it stills freezes and crashes a lot‚Äîjust not as much.
Can confirm, but it depends on the project/solution. I have a medium-sized ASP.NET Core project with TypeScript, and it has serious performance issues on all machines. Disabling Defender helped with some I/O slowness, but it still crashes constantly (‚ÄúNot Responding‚Äù dialog), and it gets increasingly slow the longer I go without restarting. I have to restart VS multiple times during a typical workday, assuming I manage to avoid a crash. I tried 16.2 preview hoping it would be better, but the issues have only gotten worse. Additionally, oftentimes when I open a file, it just won‚Äôt parse fully: type names won‚Äôt have the correct colors, IntelliSense will be missing, incorrect, or incomplete. Some types just never have IntelliSense to matter what I do‚Äîthe ValueTuple types, for example. I don‚Äôt have any extensions, but the solution I‚Äôm working on does use the Roslyn FxCop analyzers via NuGet. I suspect they may play a role.
This was a good read! I‚Äôm starting to venture out into ASP.NET MVC and right now I‚Äôm overwhelmed by all the components. Looking forward to reading more articles like this
You could open a bug on it, short of that just use VS2017. Maybe by the time VS 2020 is out, VS2019 will be release quality.
I did read the post, and quoted it, too. Here's your entire post as of this time. &gt; I currently live in Austin, Texas as a Full-Stack SWE, working on Full-Stack JavaScript work at a large Tech Company? &gt; I'm assuming Austin has a similar Tech Hub environment as SF and NYC and Seattle. &gt; I often hear that ASP.NET Core is one of the hottest new frameworks to learn, and it's a better framework than Java Spring. &gt; However, if I type "ASP.NET" positions on Indeed, most if not all of the companies are at: Old School Tech Companies like Dell, Microsoft shops, Consulting companies, and a few Medium-Sized Businesses. &gt; So where's all the hype coming from for ASP.NET Core? I'm assuming most people DON'T want to be working for Old School Tech Companies if they had a choice, the key being if they had a choice. &gt; I don't understand why there's an overhype of the TECHNICAL MERITS of the language, when in the real world business case, there aren't a lot of work done in ASP.NET Core for really cutting edge Tech Companies? Thoughts? &gt; Note: I'm not saying ASP.NET Core is a bad framework. If anything, I think the technology in C# / ASP.NET is far superior to Java. I'm just not seeing as much INTERESTING jobs from a business perspective in ASP.NET Core as in other technologies in the Tech Hubs. None of what you just said about this being all about *you* and why you should learn it is in the actual post. Instead, you asked other people the reason for the hype and their thoughts on it. Which is why people don't think well of you when they tell you their "thoughts" like you asked and you attack them. So the person who needs to edit their post so that it actually says what it meant and chill the heck out is you. You're *literally* getting what you asked for (people's thoughts) and overreacting to *everyone*.
docs.microsoft.com has been useful. I'm learning asp.net core mvc from there and Pro ASP.NET Core MVC 2 (Apress). For C# you could also use docs, but Jeffrey Richter has a great book for learning threading. You will want to know about threading when building asp.net apps that scale. The Pro ASP.NET Core ebook does more explaining of some topics than docs providing more insight into subjects less easy to understand. View components is pretty cool and new in .net core, check that out. Model binding, Razor, Views, Routing, Tag Helpers. So many subjects to learn, but learning and using each one is empowering. awaiting async functions is very fun. Can't get enough of it.
I've been through the path of trying to get a windows service working with quartz, pulling my hair out with the start up exceeded it's execution timeout, so I ditched it and went with a windows scheduled task. No bs much simpler. How does Coravel's Task Scheduling compare to quartz? From looking at the code, it looks much simpler. What are the pros and cons of each? Otherwise this is awesome, time to rewrite some of my scheduled tasks and explore this
Make an exclusion for devenv.exe and msbuild.exe, also change the number of build processes to half the number of cores you have on the machine. These three things are a must for any VS2015+ install. Also I typically turn off CodeLense and auto temp save of changed files.
Can u pls share me any link to create systemd thanks
Building isn‚Äôt the issue, at least in my case. That‚Äôs just about the only reliable component. IntelliSense will be confused and claim there are errors everywhere, but it‚Äôll build just fine.
[removed]
&gt; IBM is hiring Full-Stack JS Developers for New Grad SWE roles. JavaScript. Python. Node. Flask. Isn't it shocking to you that Java or C# isn't even mentioned in those job roles? Why do you think that is? This is IBM, an old fashioned enterprise company. The purpose I'm saying is, even older corporations are adopting Full-Stack JS, Python, Flask, AI/ML work. I know people working at IBM, and many of them wonder every year if they're going to get caught up in the annual layoffs. Even the employees don't know where the company is heading. I wouldn't recommend *anyone* work there, as their managers use the cost-cutting strategy to boost their stockholder report figures. It's not a place that's recommended for a career among traditional computing companies. Same with Oracle. Ever since they stopped offering pensions and started the layoffs, they've been demoted to nothing more than a stop on the way. IBM does work with all sorts of languages. They have several products written entirely in Java that they support. Like the nightmare that's WebSphere. And Java is a huge part of their consulting arm. There are plenty of old-style dev shops that aren't IBM or Oracle. I'd recommend people avoid *any* company that fosters too much competition between co-workers. &gt; Let's forget about everything that I've said in the past and start with a clean state. Alright. &gt; These are fine companies to work for, but for the average BRAND NEW 22-YEAR-OLD Developer, I'm talking about the YOUNG developers (not the mid-career, older developers who have families), The Hungry Young Developers / Millennials living in a Tech Hub and have the resources to do so would rather work for Google than for Fidelity Investments. &gt; If I were a complete beginner who wanted to learn Web Development in 2019, would you honestly tell me to my face: Screw JS. JS sucks as a language. Focus on C# and that alone? No. I wouldn't tell anyone to focus on any one language. I wouldn't even get to that point in the conversation. I've actually given a lot of advice to people considering development at younger ages than yours, and I'm pretty consistent about what I say. First off, I don't pigeon-hole them to web development. I recommend that they learn the basics of it because web dev is a common, useful skill. And there will *always* be openings. But there are lots of other options, and they should review them all before settling down. I don't tell them to chase any particular language. I lay out the most common career paths: 1. Web development (frontend/full-stack) 2. Backend/server development 3. Embedded development 4. Desktop/App development 5. Game development 6. Data analysis and development (schema design, dataset training with ML, etc) 7. Management They're all booming careers, but they need different skills and tend to lead you to different places. I usually spend some time warning the younger ones about how predatory game development can be, as it's really popular for kids interested in computers. Many developers burn themselves out and ruin their health in that industry. Which is why it's the only one I warn against. New developers need to know that crunch time should be very short when it pops up. Then I give examples of the different paths and point out likely salary ranges and potential companies they might work at. Rather than picking the best name, I recommend the best salary+benefits when compared to the cost of living and saving what they can. And when you factor in the cost of living, working in a tech hub can actually be a less attractive option. Rather than authoritatively telling them what they should do with their lives, I point out the languages that are popular for each path. I emphasize that the programming concepts are more important than the language, and to not get caught up in language, syntax and stack wars that waste everyone's time. They're tools, not religions. If they can learn one language, they can learn two. And if they can learn two, they can learn any of them. I usually recommend a goal of being familiar with one OO language, one scripting language, one SQL variant, and one functional language. That usually leaves them prepared for most interviews and job-hopping. It's okay to have a favorite tool, and you don't have to use or hunt for the "best" tool. Sometimes the one you're more familiar with is the best tool for you. I have tools that I like, and I have reasons for using those tools, but the audience is not me. So I give them some options and recommend some tutorials so they can find what they like for themselves. I point out common technologies they should be familiar with, like VMs, containers, databases, web servers, REST/GraphQL/gRPC/SOAP, JSON/XML/YAML, WebAssembly, regex, Git, AWS and competitors, etc. They don't need to be experts, but they shouldn't be lost if it comes up in an interview. I warn them that the office environment is more important than the company's popularity. Many big companies (Amazon, Intel, Microsoft, Facebook) have had departments with extremely cutthroat office politics and insane work expectations. Really skilled people have had really poor experiences at those companies due to management style. I honestly state that they're great to have on the resume, and if they want to chase it that's fine. But it's more important to be happy than to be successful. If the high-octane office intrigue life thrills them, then go for it. Chase your dreams. But it's also okay to work in a low-profile place. It's not shameful or less prestigious. And it's okay to change your mind if what you picked wasn't what you thought it would be. Computer careers change a lot. Adapting and pivoting is part of the industry. So they need to stay relevant, and it's okay to change gears if they don't like where they're headed. For general tips, I point out that making friends in other departments as it can lead to new job opportunities. Even "irrelevant" people like secretaries and marketers can be good friends and great leads. I recommend against trashing other people's code to make yourself look smarter. I recommend getting salary over stock options (especially in startups), and usable benefits over the equivalent salary increase. I tell them that if they haven't hit the salary cap, they should be getting a 3% raise every year to combat inflation. And that they should seriously consider finding a new job every two years, as it's generally the best way to get a raise, given HR policies about raise caps. So any one company isn't going to make a huge impact on their career in 5-10 years. After they leave their first job, they should start negotiating more in interviews and asking about the office environment. At the end, I tell them it can be really scary, but it can be really fun. And they'll meet a lot of interesting people, and work on interesting problems. I'd definitely take a time to point out that *every* problem is interesting once you start tackling it. If a problem seems boring, it's just because you haven't actually thought about solving it, yet. So, no, I wouldn't tell them to do what I do. I'd tell them the things that they might not know, give them options, and let them decide for themselves what they want to do. Most of the problems developers really struggle with over their careers aren't about the language or the platform, but about the socialization and labor aspects. It's the same advice I give to you. And, just like with them, it's up to you if you want to make use of it. Advice is offered to help, not control. Gotta let people decide.
Fair enough. I'm 100% in the wrong. Can we move FORWARD now? I want to clarify to you and everything that my INTENTION overall is to ask what is best for ME. That's it. You now know.
FYI, I work at IBM. I've been on the Internal Job Board. I know exactly what kind of jobs IBM is currently hiring for. There aren't a lot of pure Java jobs unless you want to do Consulting work. Most of the product/development work is in Python, JS, and Go. This is a fundamentally sharp turn than working at Fidelity Investments, where a lot of the stack is Java Spring or ASP.NET. Let's say hypothetically that I joined IBM, and all I knew was JS, Python, and Go. Nothing else. I don't touch Java and C#. If I told you my end goal is to be a Full-Stack Web Developer working for a Trendy Tech Company, what would you recommend I focus on? Should I drop everything and start learning C# from scratch, a language that 1) I don't even need in any near future, 2) Is just one out of many alternatives for Backend Web? That's what I'm trying to get at. If you told me upfront: "I think you should focus on Full-Stack JS, only worry about learning C# if you need it" there would absolutely be no issue on my end at all and that's a great response to my original post. That was the type of answer I was looking for.
Yup, already migrated the project to .Net Core, yet it still doesnt work on OS platform other than windows, cos the Winforms portion of the code is only supported on Windows
.Net Core 3 DOES support Winforms, however there's a catch: it still only runs on Windows.
tried that, it crashed and the debugger itself is so buggy.
Save it for yourself, if you can't give any positive opinions, then don't
Yup, i took some of you guys advice, and i really ported my winforms app to dotnet core, the thing is that i felt so disheartened when microsoft stated although winforms can be run on .net core 3, it still only works on windows os.
I still have this tab open from when this was posted about a week ago.
it will work with dependency injection (singleton, scoped)? It will work with dbcontext (entity framework)? I had the same problem with quartz (cannot use dependency injection with dbcontext - entity framework) and force me to use CreateScope -&gt; ServiceProvider.GetService
I have a 450+ projects in a single solution and the only freezes are caused by Resharper, but not frequently. No freezes whatsoever if I disabled Resharper. I did disable all CodeLens features as I find them useless and visually annoying. Apart from that, all the other settings should be default or with only few changes.
Resharper caused even more issues with this particular solution, so I had to remove it, but that was the case even in 2017. There‚Äôs something about particular projects‚Äîmaybe even files‚Äîthat really trips up 2019. It doesn‚Äôt seem to be related to the size of the project/solution.
Extensions and resharper are the only things that have cause any issue for me in VS2019. Beyond that, could there be some library you are using in your project causing issues?
I second this. I'm going through the path right now and the videos are great.
That's the problem I have. I've transitioned from Android to .NET(started directly from Core) in a small company around a year ago. Now I don't really have any job opportunities unless I want to work on some .NET 4.x legacy software with WPF and stuff(which I don't want to). I really like Core, it's just hard to imagine next few years in it. Especially in my country where adoption will probably be even slower.
I had a play with it the other day and you can definitely do DI.
Now we just need System.Text.Xml ;)
&gt; FYI, I work at IBM. I've been on the Internal Job Board. I know exactly what kind of jobs IBM is currently hiring for. It's a big multinational company. They just posted two weeks ago for a new [microservices developer](https://stackoverflow.com/jobs/272922/application-microservices-developer-ibm) using Java spring boot. Sure, JS hires will be more numerous. But they're maintaining lots of stacks for themselves and for clients. &gt; If I told you my end goal is to be a Full-Stack Web Developer working for a Trendy Tech Company, what would you recommend I focus on? Budget 2-4 hours a week on suitable resume fodder until you get your dream job. Start with things from the job posting requirements. Switching stacks won't get you any closer to being a trendy FSE. If you weren't full-stack, you'd need to spend your time learning about how to do that. But you're already full-stack, so you could already do the job. You just have to convince them that they want to hire you. Most of your efforts should be on soft-skills and presenting yourself like a good fit. For that, just follow the trends. Contribute on Github. Blog about new tech stuff you try. Avoid non-anonymous online conflicts. Pick up a trendy hobby (e.g. craft beer, bicycling, cooking, roller derby, hiking, hockey) if you don't already have one. Pick a few hole-in-the wall bars or restaurants to call your favourites. If you've got a pet, take a cute picture and take it with you. Have some hobby pictures, too. Practice phone/webcam interviews. You can probably swing an hour a day working on this stuff. If you're still not trendy enough, good news. You're in Austin. There's more than enough trendy examples around you. Hit up bars, buy people drinks and ask if they mind you practicing socializing for an interview. Maybe they already work where you want to go. Join community discords/slacks and lurk for a bit to figure out where you should go. None of this stuff is really secret. You've got an idea of how the people who do the job you want act. Go be one of those people.
I've been using VS19 since it came out and haven't had a single issue with it, runs flawlessly for me and most of the time I use it on a VM.
I see. I have mostly vanilla old-style C# projects. No ASP or even WCF so that might explain the difference...
Can you share me how to use DI with Quartz. I've issue when use DI (entity framework dbcontext - scoped DI) - can not use with Quartz
Nice troll Google is worth $750 billion Microsoft is worth $1 trillion
Shouldn't `AddEnvironmentVariables` be last? I think the order mattered in terms of what can overwrite what, and you would want to let environment variables overwrite your configuration.
I am glad to hear that you are considering GitLab! :)
It's without the 'Framework' part in the name, right? Just .NET 5
There's some confusion here, maybe intentional by Microsoft - but .NET 5 is just the next version of .NET Core 3. If you're still using .NET Framework, you'll be expected to stay on .NET Framework 3.5 or 4.8 which will probably get some minor security updates essentially forever. But people won't just be able to bring forward existing .NET Framework apps to .NET 5 and just expect it to work...
https://github.com/davybrion/nhibernatetraining
Thank You so much!! I'll look into it soon :)
Are you the author for these? Because I am now reading through the whole history this guy's posts. Good stuff.
Try here [https://andrewlock.net/creating-a-quartz-net-hosted-service-with-asp-net-core/](https://andrewlock.net/creating-a-quartz-net-hosted-service-with-asp-net-core/)
&gt; a specific explanation of why it would help MY SPECIFIC SITUATION is the issue here Dude did you even read what your own post? You never asked for advice at any freaking point. You just said you didn't understand the hype and they are trying to explain you why. How obnoxious fgs
The webapp could also use the API. The webapp could deal with the layout and all that stuff, and then use ajax calls to the API to actually fill in data. Let the webappand mobile client be two separate front ends to the API.
Ok, the problem as I see it is that a workflow engine isn't something that fits that well inside the Web server request / response paradigm. Yes, there will be times that whole workflows or tasks would be instantiated as a result of an HTTP request. But most of the time, actions inside the workflow run completely outside of requests / responses. They can be triggered in an async way from a plethora of triggers. For example, figure an expenses or holidays approval workflow, for example. When there is a new request it is routed to someone. But if that someone doesn't answer in some time, it gets routed to someone else. Do you see? it's not that async / await is not good. But the whole task instantiation, routing, happens outside of the context of the original request (the holiday request). So you need that engine. I would recommend you to check workflow engines
100%, unless you work at a place where you have dedicated UI designers you should be using bootstrap. Makes things consistent across web and you don't have to swear when your CSS is crap and things overlap :).
Heh. Thanks. I had made my own one of these. Thing is way too tied to MS DI.
why not?
yeah, I've seen it used both ways but I think the proper way is just \`.NET 5\`
Correct, it's just .NET 5. It brings all the different .NET technologies all together under one umbrella and starts the numbering at 5 to avoid confusion with .NET Framework (since it was already using 4.X).
Link doesn't work for me :/
I was thinking with the freedom in Kestrel in Core more stuff is possible. Like running task arching over multiple requests. I do intranet web. One Server 100 Users. No scaling. I was hoping to use Async await within these background tasks so that users can write them. Anyhow, apparently they want to follow workflows manually. We suggest MS Teams to them. I read in Reddit that it is good. Why are they even asking us then? We are developers.
&gt; So where's all the hype coming from for ASP.NET Core? I'm assuming most people DON'T want to be working for Old School Tech Companies if they had a choice, the key being if they had a choice. You're coming into a room full of enterprise developers and starting out by insulting enterprise developers.
This is unrelated to Serilog, but to Windows Event logs: https://docs.microsoft.com/en-us/windows/desktop/eventlog/event-identifiers#message-definitions
ASP.Net CORE. Not ASP.Net.
Waiting for something like SwitfUI/Compose, xaml ? hmm nah
Well, where's the message format 41556 (or whatever is the event id) supposed to come from?!
It was generated automatically using the logger, I did not do anything specific to make that change.
Thank you for sharing this, but I am unable to understand the problem I am having from this.
This is the best answer. Very good response!
I know! I noticed the same, we used a "fixed" event id provider, but that's not how that's supposed to work!
Removing dependencies does not traslate in execution being faster. Why would I use it?
Should work. SOAP web service can be consumed by any platform.
I'm not sure why this interests me so much, but it does. OP, are you the author?
!remindme 4 days
I will be messaging you on [**2019-06-21 19:53:18 UTC**](http://www.wolframalpha.com/input/?i=2019-06-21 19:53:18 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/dotnet/comments/c1nvsf/xaml_islands_v1_updates_and_roadmap_windows/erf6cyi/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/dotnet/comments/c1nvsf/xaml_islands_v1_updates_and_roadmap_windows/erf6cyi/]%0A%0ARemindMe! 4 days) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! ____id____) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
Yes
For better testability.
Just so you know, you can get 1 month for free from [Visual Studio Dev Essentials](https://my.visualstudio.com/Benefits).
[HttpClient](https://docs.microsoft.com/en-us/dotnet/api/system.net.http.httpclient?) is not thread-safe (except Async methods) why do you want to share a static instance?
It all seems a bit confusing with winrt, uwp and now WinUI
Xaml in Web, here we go again. Some thing are just not meant to be
I'm only using SendAsync, so it should be thread-safe correct?
Let me expand. BaseAddress is not being set. We're creating a new RequestMessage for each request we need to make and pass that into SendAsync.
Yep, just moved some code to standard for this. You need to delete the reference to System.ComponentModel and add it again via nuget. Message me if a problem and I can provide more info.
It is rather intended for async/await pattern. Reusing a single instance isn't good idea in general.
It's an API. The entire thing is an async/await pattern from the controllers to the route handlers.
Everything I've read states you should not dispose of HttpClient, so why would you create new instances for the application. Now, if I were spinning up the API each time I needed it, then maybe that's a different story.
Ah, good point. Shows how much I use environment variables that I never noticed. It depends on how you want to use them, but given my description above, they should indeed be at the end.
Ya I think I did the 3 month or 6month free a while back but I‚Äôll definitely try and get in on the 1month too
&gt; Everything I've read states you should not dispose of HttpClient In a single thread, you should reuse it. I think the answer is just study its source code, there will be some shared state.
I'm not changing the properties that are shared and are not thread safe. They stay consistent throughout the life of the instance.
I mean there is some hidden shared state in the class implementation.
I'm not using Core.
I think it will perform the same. It's a bit more useful if you are running a console app without [ASP.NET](https://ASP.NET) dependency injection. For example I have an [Akka.Net](https://Akka.Net) application which has no dependency to [ASP.NET](https://ASP.NET) stuff. It already works with Windsor and I don't feel like introducing all [ASP.NET](https://ASP.NET) stuff for a relatively simple feature. Btw [Akka.Net](https://Akka.Net) is a great framework. There is a lot of interesting stuff that can't be easily done with ASP.NET
I've been watching this project for a year or so and it looks like it has lost some steam.
Ask and ye shall receive: https://github.com/microsoft/referencesource/blob/master/System/net/System/Net/Http/HttpClient.cs `SendAsync` is supposed to be thread-safe so I don't believe that's where your issue is coming from. That said you should consider using an `HttpClient` instance per *thread*: https://stackoverflow.com/questions/40228146/httpclient-singleton-implementation-in-asp-net-mvc/40228347#40228347 If you have found a bug, though, don't expect Microsoft to fix it though. If it isn't Core and it's not breaking for everyone, they aren't interested.
I feel like I need to see a demo. This is sort of compelling.
Have you read about configure await (false)? Might help you.
The [Summer of NHibernate](http://summerofnhibernate.com/) video series was very helpful when I was learning long ago.
Thanks every one for your help !
Yawns. Another set of crutches released...
Put lock objects over the entire request. If it's a threading issue the problem should go away. Then, slowly start removing locks until the issue returns.
use HttpClientFactory, it will handle any necessary pooling for you. https://docs.microsoft.com/en-us/dotnet/standard/microservices-architecture/implement-resilient-applications/use-httpclientfactory-to-implement-resilient-http-requests
Yep, there are plenty of crawlers/indexers, including the very handy [https://www.fuget.org/](https://www.fuget.org/)
Because giving a shared, basic component a hard dependency on a dependency injection framework is the ultimate form of irony.
Removing addictions DOES not traslate in death penalty living thing quicker. Wherefore would I use it? *** ^(This is a bot. I try my best, but my best is 80% mediocrity 20% hilarity. Created by OrionSuperman. Check out my best work at /r/ThesaurizeThis)
Go away.
I fully expected that to be an angry site saying "fuck you NuGet".
Yeah, that naming is suspect, but I love the site
The ecosystem.
The good news, if there is any, is that you can reproduce the issue. There is something being shared and the bug probably isn't in HttpClient.SendAsync().
Both are fine, imo. If I am returning the image with JSON, I'll base64 encode it, or you can return File(imagePath, content-type);
Either way works, but base64 is less space efficient. On the JS side, you're looking for `Blob` and `FormData`. You can get a blob from the canvas, no need for base64.
Ahhhh Thank you kind redditor. I wasn't aware canvas a could return anything but a blob!! Very helpful.
Isn't top shelf deprecated now with the host builder?
I... have never heard of these before. Who uses them?
Yes. After validating the login username and password with usermanager, you can build a claimsprincipal with all the claims you want the user to have. Pass that claimsprincipal to the signin manager who will sign in the user and issue the cookie.
If you're using ASP NET Core, you can scaffold out the login page. [Go here to read about scaffolding] (https://docs.microsoft.com/en-us/aspnet/core/security/authentication/scaffold-identity?view=aspnetcore-2.2&amp;tabs=visual-studio). If you're using old school MVC, find the Account controller and Login action. Once there, the solution is the same. Instead of redirecting to the returnUrl parameter after a successful login, redirect to your application specific page or controller action.
&gt;I'd never heard of it until now, so no. I meant the browser's HTML5 storage. We have a custom method, dixie has been solid in production and I recommend it, the actual indexeddb api is really bad
I think about writing a Nuget crawler often for analysis, which means there are more than 50 people who already did it.
Can't say about any others, but I use fuget because it builds out decent docs from the XML comments docs in the packages, which is often easier than tracking down docs in different formats in github repos or whatever.
You can create a service that fetches the info from your app, then inject it into the profileService, and add whatever claims you want.
If you have a CI pipeline set up to build something that uses that package, it will download it once every time your CI is kicked off.
You see the same thing with NPM.
Use an artifact repo for proxy! But yes, you're probably right
Even though I pronounce NuGet "new-geht" I'm definitely pronouncing FuGet "fuggit"
Oh jeez, that sounds easier than I thought. Thanks a lot.
I do not think you are dealing with a "shared, basic component" anymore if you need to inject a HTTP client factory.
When dealing with high number of request new-ing a new HttpClient each time will result in socket starvation.
You are assuming injection? Is that pertinent? In terms of using HttpClient, HttpClientFactory is a good idea for any at-scale usage of the client given the oddities of how it behaves and how its lifetime needs to be managed.
 I'm not against using the HttpClientFactory I just don't consider that the previous comment was the best argument for using this library. Regardless if you inject the HttpClient or just use the factory you are now dealing with a component that is specialized.
Not sure! I used top shelf not long ago, and it was a great developing experience. I havn't tried using the host builder for a service style application, only for web applications.
No. You have no idea what the class does internally, and how it manages its state.
Your post has been removed. Self promotion posts are not allowed.
Thanks! :)
Bots Take a look at the insane download numbers of VS Code extensions. It has to be bots all the way down.
It's not one of those you have mentioned, but Sonar~~P~~Qube is pretty awesome - and also does the HTML/CSS/JavaScript/etc in your source control. It runs on a server and has a web interface - it emails and assigns people issues/bugs/smells/etc they have created. It also does this for merges, which sucks. The rules are configurable. There's also the SonarLint Visual Studio extension. It will use CPU resources similar to Resharper, but is handy to identify smells before check-in. https://www.sonarlint.org/visualstudio/
Do you have any leads as to how it can be fixed? Does using fixed event id provider work?
i really want this on top of blazor
I second SonarQube. We use the VS extension and TFS task at work; it catches a lot of stuff.
Yeah, i made a shitty small library just to learn something and was puzzled when it was downloaded so much. &amp;#x200B; although, it does get a couple of downloads a week outside of new versions, so maybe \*someone\* is using it...
I decided to use [https://github.com/QBurst/signalr-load-simulator](https://github.com/QBurst/signalr-load-simulator)
If you don‚Äôt give a model to `Page()` then the model is null and you‚Äôll get an exception trying to use it.
[removed]
my point exactly :-)
This is the plan to show how to migrate the windows service to something Azure cloud native like web job or Azure functions or Logic Apps.
I will write a blog post about Topshelf and compare. I am not saying it is a bad technology or something. I am just pointing out how to create a simplest possible windows service application. The reason is because people start to over complicate things right from the start and don't understand that there is a simpler solutions and we should start to use any other frameworks only when it is necessary.
I dont agree. In unit test I would mock the HttpClient because I just want to test my code. In integration/e2e test I would test the system from the outside. I dont want to test MS code.
We use SyncFusion. How many devs? You can get the SyncFusion suite free if it's less that 5 and the company is &lt;1m revenue.
How much memory do you have, wound like Swapping... you really probably need atleast 16 gigs if you running Win 10, SQL server locally and VS. &amp;#x200B; Ran on 2 machines since preview on one and MSDN release on another with all the every other day updates ;-).... One machine i74790k , 32 gigs of ram and discreet graphics DIY machine, 1 machine an i7 6700 with 16 gigs of ram intel IGPU HP z240... all SSDs quality and cheapo, microsoft Virus Protection and Traps virus protection. Win 10 &amp;#x200B; Compiles OLD multi Project .net application circa 2001 with "wilson master pages" it's so old lol, up to new Vs2015 vanilla template projects ... that have been converted up to 2019 projects... Some with Telerik , and the old Microsoft Enterprise data layers etc. so various mixed web application &amp;#x200B; You may look at just wiping you machine, after fully updated Win 10, then install Visual Studio 2019 , test it if no freeze you know it is something else, VS extensions, other Application ... and suck as it is to say could also be just a Windows Network... I don't know why but where I work being on the Network really seems to slow the machine down too, Randomly once a week I get to 97% memory usage , sometimes over the weekend of the machine literally just sitting after reboot. I am told "its just you developers" ... but I remind them my home machine doesn't have this problem.
Yeah about that, how the fuck do you issue a cookie for a credential scheme? I'm new to identity and I'm totally lost with this.
Hi, &amp;#x200B; you can read the following documentation on NHibernate: [https://nhibernate.info/doc/](https://nhibernate.info/doc/) &amp;#x200B; I work with this daily so if you need any help implementing it please feel free to DM me and Ill help as best as I can. Other than the official documentation I do recommend downloading github projects to see what they did to start out the project. &amp;#x200B; A word of advice if you are working with MVC, make use of the Unity containers they do make the process of implementing Nhibernate a lot easier.
https://blazorise.com/
As /u/tulipoika said, you're not providing a model when you call ```return Page()``` when the ModelState isn't valid. Calling ```return Page()``` (or ```return View()``` for that matter) will invoke the Razor Engine and cause it to start rendering the associated Razor view to the response stream. If your view definition expects a model object (it more than just static html), then you'll need to pass in an object of that model type when calling ```return Page()```. If you don't, you'll receive that ```NullReferenceException``` whenever the Razor Engine attempts to access any of the properties defined on the model. Simply calling ```return Page()``` because ModelState validation failed doesn't automatically wire up the model to be used by the Razor Engine again.
Hey, thanks for the links.. I'll be working on a project already developed using NHibernate... it's a maintenance project of sorts... I'll surely contact you in case I need help!! Thanks :)
Thank you, does that not automatically happen then then you declare the `@model` on the Razor Page then?
Awesome man! Goodluck with that, NHibernate is quite tricky to figure out but works like a charm when you do!
Here is another. ClrHeapAllocationAnalyzer https://github.com/microsoft/RoslynClrHeapAllocationAnalyzer
Why can't you just use the native [GzipStream](https://docs.microsoft.com/en-us/dotnet/api/system.io.compression.gzipstream?view=netstandard-2.0)?
It felt like stylecop was a little dated. We‚Äôve been using Rosylantor for several months and that‚Äôs completely replaced ReSharper for us.
[now you do.](https://github.com/dotnet/corefx/blob/master/src/System.Net.Http/src/System/Net/Http/HttpClient.cs)
Google your nuget package and you'll already find it hosted on alternative nuget repos.
We are using sonarqube currently, I didn't know they have a linter as well, I'll check it out, thanks!
Didn't use anything for CRUD, but if you need grid component, I would go for http://mvc6-grid.azurewebsites.net/ if you render server side and https://datatables.net/ if on client side. If you are using react/vue/angular, they should have their own specific libraries.
It worked for us at the cost of being primitive: there was no structured data, just one big blob of text. So meh. But we didn't have anything better before, so...
The `@model` declarative just declares what type of model will be used on the page.
Every time an extension is updated, it counts as a new download for everyone who has it installed. Check out the install counts for an accurate number.
While they have some similar analyzers, they are made for different purposes. StyleCop aims specially on style, i.e. how code looks, what language constructions are used, spaces vs tabs, braces position, etc etc etc. On the other hand, Roslynator aims much wider area. It has style and formatting analyzers, but it also has optimization analyzers, suggestions to use shorter code, etc. So you can use both analyzers, it will work perfectly fine (maybe you'll need to configure some similar analyzers).
The cursor will spin for a couple of minutes until I finally kill it and restart.
I am running 16gb. I might just do a wipe and re-install.
Just my 2 cents for people finding this thread via search like me: I disagree. Just buy the MS-recommended practice exams and spend two days cramming and learning the way the questions work. Google the terms you are not familiar with, but only read just enough to know the key fact that is mentioned in the practice exam. If you are professionally building [ASP.NET](https://ASP.NET) MVP applications, you can learn the stuff when you need it. If you aren't, learning about which tier of what azure service supports what feature is pointless. Do what it takes to pass the exam, then spend your time learning about stuff that is more relevant to your career and interests. Disclaimer: This will only work if you are an experienced dev who has built some kind of web app before. A newcomer won't be able to do this.
After going back and forth a few times with SonarQube I have to say I'm not a huge fan of doing a ton of style or bug catching in build pipelines after pushes. It can slow down the development process, especially once you are the one person who pushes a class past a complexity limit and don't know until the end of your day It's a nice tool and I understand deeper analysis takes more resources and can be slow, but I'd rather use a command line tool on demand locally when it becomes too much to do realtime (i.e. resource hog like Resharper can be). I'd even rather something like that that catches less, or else it becomes too annoying and process slowing and stuff gets disabled over time.
Yep, while I have no idea how, the whole point of a web service is that it doesn't care who makes requests as long as the client is authorized and it speaks the same language (SOAP in this case)
But I thought it requires a full copy to memory before it can zip and be used by another process. That won't work for us. We need to ingest a stream, have it compress and be read by another process as the same time without any intermediate memory copy. Seems that only the Xceed Real Time Zip library can do this from all that we can tell.
You need an action method for it. When user click call the action method and set the view bag there
Use query parameters. &lt;a href="otherPage.html?flag=1"&gt; Setup the method on the otherPage controller to accept a flag parameter, then you can set the viewbag.
Just make an action result and do your work there. Then you can easily set anything you want to the viewbag. Or am I not understanding your question? Are you trying to emulate a QueryString?
Yes you can. I've done this before for my work. I used the WCF client libraries ([https://github.com/dotnet/wcf](https://github.com/dotnet/wcf)) and used svcutil (start the Visual Studio Developer Command to have access to this command) to generate the corresponding SOAP classes based on the WSDL.
What would be the best method to use to do this? I have created a public ActionResult in my controller, public ActionResult SetFlag() { ViewBag.flag = 1; } But I get an error: Not all code paths return a value.
You understood perfectly. I am still in the very early stages of learning .NET. I am having trouble creating an action result however, please see my reply to u/DispersedAvenger
If I did it this way, what .net method would I use to read the param?
I've been using DevExpress for about 10 years and it has always been well worth (my employers') money! As for open source, I know of nothing worthwhile beyond a few javascript/jQuery plugins. Datatables is a ncie one for grids. To style standard HTML controls, use Bootstrap.
 [https://docs.microsoft.com/en-us/aspnet/mvc/overview/older-versions-1/controllers-and-routing/aspnet-mvc-controllers-overview-cs](https://docs.microsoft.com/en-us/aspnet/mvc/overview/older-versions-1/controllers-and-routing/aspnet-mvc-controllers-overview-cs) Take a look at listing 3. You define your parameter as a variable and access it in the controller like any other variable.
Your method is declared to return an ActionResult (correct), but you're not returning anything. You could use Redirect(), which returns an RedirectResult, which is a subclass of ActionResult so you can return it there.
You need to return the view to the page you want to open e.g. ‚Äúreturn View(‚Äú{path/to/html/page/otherpage.html}‚Äù);
The constructor takes a Stream to write the (de)compressed data to. That doesn't need to be a file, it could just as easily be a network connection. And the data being written can be written piecemeal as well. So for your case, something like this: using (var gzStream = new GzipStream(destinationStream, CompressionLevel.Fastest)) { ingestedStream.CopyTo(gzStream); // or if you prefer: // await ingestedStream.CopyToAsync(gzStream) } looks to be a good start.
I made these videos on FNH a long time ago. You might enjoy them: - Intro: https://vimeo.com/7274194 - Classmaps: https://vimeo.com/7297437 - Conventions: https://vimeo.com/7339508
You know if no one has mentioned it , just for the hell of it in option try unchecking the "save auot recover information ever": option, I think default is like 5 minutes... might also try uncheck "detect when file is changed outside environment" maybe one of these 2 options can point you into direction of what might be going on.
&gt; But I get an error: Not all code paths return a value. I mean this with all due respect: If you don't know what this error means, you might want to step back and learn the basics of C#.
I changed it to a void as I don't need it to return anything. Now I am trying to figure out how to call a .net function from the cshtml. This what I have so far, but it doesn't seem to be working. CONTROLLER: public void SetFlag() { ViewBag.Flag = 1; } CSHTML &lt;a href="otherPage.html" onclick="SetFlag();"&gt;link&lt;/a&gt;
It seems like you're having a tough time because you lack an understanding of how a website works (client-side vs server-side). Extremely simplified: HTML/Javascript is on the client side, and as such, cannot interact "directly" with any of your server-side code. This means that your onclick cannot change a viewbag value. The only way is making a new request to the server that you'll receive and do something server-side.
Right, because the `onclick` attribute is only for Javascript functions. The browser doesn't have access to your C# code. The way we run C# code from the front end in MVC is by going to a URL that's mapped to an action method on some controller (which is taken care of by default in a new project). In order for your method to be called, you need either replace your `&lt;a&gt;` element with `@Html.ActionLink(...)`, or you need to replace the value of the `href` attribute with `@Url.Action(...)`. And for your method to be usable as an action method, it needs to return ActionResult or a subclass of it. Either way, the `onclick` attribute has to go, since the method you want to run is on the server side, and not the client side.
&gt;I changed it to a void as I don't need it to return anything. this contradicts what you originally wrote; &gt; I need to set a flag in the viewbag when the user clicks on a link to go to another page &amp;#x200B; Do you actually want the user to click a link and go to another page with the viewbag preset, or, do you want the user to be able to click SOMETHING, which calls a method server side and does SOMETHING with some data from the clientside? These are all different things, you need to be careful to articulate what you want to happen rather than what you think you need. The problem I can see from your post right now is you're trying to get things working without understanding how the framework comes together. Take a step back, do the tutorial work from the ground up and learn the framework so you aren't trying to learn as you go and constantly find yourself getting stuck in rabbit holes.
Ahhh, I see. Thank you so much for your help! So would I do something like this? CSHTML @Html.ActionLink("link", "SetFlag", "relevantController"); CONTROLLER public void SetFlag() { ViewBag.Flag = 1; Response.Redirect("..Other/otherPage.html"); }
You want your link to go to the SetFlag controller action: @Html.ActionLink("Other page", "SetFlag") Then, when the person clicks that link, they get sent to SetFlag, so there you want to set the flag and then redirect to wherever the link was supposed to go: public ActionResult SetFlag() { ViewBag.flag = 1; RedirectToAction("OtherPage", "Controller") }
Read your comment out loud to yourself. If I offended you in any way, I am sorry that was not my point at all. Just trying to say "it is hot stove, don't touch it", but you can burn your fingers all you want.
why not just set a parameter? &lt;a href="otherPage.html?flag=1"&gt; &amp;#x200B; then have an int flag parameter on your controller
Unless you set some cache for your Nuget packages on your CI pipeline.
If it's already dotnet mvc why not route parameters?
Route parameters are fine as well. OP seems like they actually might need to do a POST request though instead of setting up routing, but hard to tell based on their description :/
It seems most of the commenters here have missed the obvious: even if you were to assign a view bag variable on page A before sending someone to page B, the view bag only exists in the request so it'd be lost immediately. I think you're probably either wanting to persist the value (e.g. To session or database) or apply it to the destination page (e.g. You've clicked a record and want to open the extended view). In any case, as others have pointed out, you really need to learn the fundamentals - your action link is going to perform a request to a controller and that controller is going to receive all the route and query parameters. If you want page A to receive your value, direct your action link there and at the end return a RedirectToAction directed at B, otherwise just make sure your destination page B has the appropriate method to handle your link parameters.
I really think that ms is going in the right way lately, especially with the core and .NET 5. Hope we see a good future.
So I think the problem here is the ingestedStream.CopyTo. Doesn't that assume the whole stream has already been received, thus filling up local memory? Xceed Real Time Zip can compress an incoming stream AS it's being received and at the same time write to a another stream without using much local memory. In your example, to compress a 500 MB file would mean the ingestedStream will take up 500 MB before it can compress. With it Xceed, it might take up only a steady 2 MB as it's compressing the stream while being received and marshalled to the destination stream. There is no CopyTo.
We have 4 devs but &gt;1b revenue so we fall out of most free software situations.
Need to add TPT to EF Core though. So many applications that can't be migrated without it.
I didn't realize the devs who created the class were using a class field to store the response message. Once I refactored to remove that field and create a new instance and dispose of the response message as necessary, my issue disappeared.
Thanks a ton!! I'll check them out soon
Sorry to bother you again, but I've noticed that my claims remains even after calling SignOut on my signInManager so when I log back in the claims remains the same. Is this normal behavior? I'd personally prefer to clear it since the value of the claim that I want to add will change based on which login is used and what option the user select.
If the method is unauthenticated, ANY application can implement that client side solution. You can make it a PITA by mucking the format around, but that's just going to make your life more complicated for a problem that you might not even have evidence exists or affects you. Other apps are also probably really unlikely to use your Web API because they don't control it, have access to the documentation, nor have sufficient reason to use it. Consider that there are already a shitload of well-documented weather APIs, is this something that you _actually_ have to worry about? INFO: Are you worried that they'll just build a better frontend over your backend or are you concerned they'll make calls on your API for their own application? https://github.com/stefanprodan/AspNetCoreRateLimit might be of use
From all the comments . I think your basics are still weaks. Please visit tutorialteacher.com to learn MVC or we also have official Microsoft site to learn. It will help you alot
The server side is important because any web assembly DLL that goes down can effectively be decompiled (you can see the DLLs in the browser tools). Not a huge issue if you know not to put code you don‚Äôt want out there in it. Frankly I think the whole thing is pretty cool and I‚Äôm glad it‚Äôs going to be a first class citizen.
Only the web assembly DLLs. If you go straight client side there is a few megabyte footprint but all that caches. That footprint is also supposed to shrink in the future as they refine it.
MVC6-GRID was exactly what I needed. Thank you.
I have low expectations for this not being a pain. If it works well without a ton of plumbing I‚Äôll be happy (some of the controls are pretty slick). The thing that annoys me with UWP is you get tethered quickly into a set of Windows releases. If you use the community Toolkit they support like, two Windows versions back (oh, the newest version fixed a keyboard accelerator issue, but the amount of users I can distribute that to is small while I wait for them to upgrade Windows, wut)? So your new versions always require mostly new versions of Windows. That‚Äôs not all bad but consider this. I found a 3.5 floppy disk in my garage the other day, had a .Net 1.1 exe I wrote in like 2003. That damn thing ran on my Windows 10 box without a hiccup. UWP on the other hand borrows from the Apple forced obsolescence model which aggravates me as a user and a programmer (why can‚Äôt I distribute the updated pieces and/or why must they be tethered so annoying tightly to Windows releases?). TL:DR - I have a love hate relationship with UWP. I‚Äôm excited and skeptical about XAML islands.
I think it really depends on what your application is going to be doing, and who the target is.
Use CORS. https://en.m.wikipedia.org/wiki/Cross-origin_resource_sharing All modern browsers and spa frameworks support this.
**Cross-origin resource sharing** Cross-origin resource sharing (CORS) is a mechanism that allows restricted resources on a web page to be requested from another domain outside the domain from which the first resource was served. A web page may freely embed cross-origin images, stylesheets, scripts, iframes, and videos. Certain "cross-domain" requests, notably Ajax requests, are forbidden by default by the same-origin security policy. CORS defines a way in which a browser and server can interact to determine whether or not it is safe to allow the cross-origin request. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/dotnet/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
 UWP is win 10 only. WPF is not. So, if you don't care about windows 7 and 8 users you can go uwp.
As others have said, CORS may be an option. You could also look at the Referer header on incoming requests and only allow the request if it is coming from the SPA path?
If the application needs to be touch enabled. I would choose UWP.
Can you confirm that the sign out actually logged you out? You shouldn't be able to hit anything with an [Authorize] tag on it, and the cookie should disappear when you look at it in Chrome Developer Tools
No, you can just write to a network stream with no trouble at all. I use it to download, compress and upload 80+ GB datafiles on a VM with only 2GB of memory without ever hitting the disk.
No, that's not how [Stream.CopyTo](https://referencesource.microsoft.com/#mscorlib/system/io/stream.cs,295ec16c77d4fafb) works (that links the source code for that method). It calls [this private method](https://referencesource.microsoft.com/#mscorlib/system/io/stream.cs,98ac7cf3acb04bb1) which just does byte[] buffer = new byte[bufferSize]; int read; while ((read = Read(buffer, 0, buffer.Length)) != 0) destination.Write(buffer, 0, read); with `bufferSize` == 80*1024 bytes (80 KiB) (though that could change in the future of course, as the default buffer size isn't documented). So it reads up to 80 KiB and then writes what it read to the destination, and repeats that until nothing can be read anymore. Top memory consumption for uncompressed data is therefore on the orrder of 80 KiB plus whatever internal buffering the `GzipStream` does to make compression more effective, but shouldn't be anywhere near hundreds of MBs.
UWP if you want to target different device types and want to distribute the application through the Windows App store. WPF if the two statements above don't apply for you application.
VS2019 Enterprise is "freezing" a bunch for me if i try to do simple "ctrl dot -&gt; add using statement" often it just won't add the using, i continue to type the line and i have to reissue the command a bunch of times. &amp;#x200B; Also a few times the mouse pointer gets stuck in the "push link" mode. I have to manually fix this using "Ctrl + hover over any declaration"
It‚Äôs also worth adding that in general control libraries etc. are more widely available on WPF mostly due to the fact that it‚Äôs been around for longer.
But this is fairly easy to overcome. Just throw in a proxy that calls the web API instead of doing it directly from the browser.
Yeah, agreed, but OP is looking for solutions that don't require authentication, so any workaround for this will have flaws.
This has been asked before and answered in better detail. Personally, I'd go with WPF. More features, more mature, better support. * https://docs.microsoft.com/en-us/windows/apps/desktop/choose-your-platform#platform-comparison-uwp-wpf-and-windows-forms * https://www.reddit.com/r/csharp/comments/9ficj2/the_current_state_of_uwp/ * https://www.reddit.com/r/dotnet/comments/81qwtf/uwp_or_wpf_for_rich_desktop_applications/ * https://www.reddit.com/r/csharp/comments/9mom53/uwp_or_wpf_for_enterprise/
here is the blog that talk about the server-side blazor in signalR service. [https://devblogs.microsoft.com/aspnet/whats-new-in-azure-signalr-1-1-0-preview-1/](https://devblogs.microsoft.com/aspnet/whats-new-in-azure-signalr-1-1-0-preview-1/)
I used the weather API as an example because that‚Äôs the controller that comes with the template. My API will actually provide data that you would normally have to pay for. So the real reason is not that I am worried about a better implementation of my FE but rather a because I don‚Äôt want to be getting lots of calls from clients that are not my app. Thanks for the RateLimit middleware, that might be an option to ensure there is no abuse, but I would still not want someone calling my API every 30 seconds and having access to a 30 second delayed version of my data.
Exactly, that being said it proves CORS is not the option right? CORS can be configured to allow browsers to do cross-origin resource sharing. In my case I wouldn‚Äôt want a CRON job hosted wherever it might be to call my API and have access to a delayed version of my data. Unless there is a way to setup CORS so that requests from https://hosted-cron-job.com cannot be able to make calls on my API (https://mynetcoreangulartemplate.com/api/*)? The only allowed client should be my client app https://mynetcoreangulartemplate
I just realized I replied under the bot, oops
See my answer just above please. CORS might work but from ehat I understand I don‚Äôt know if it would apply.
For the Referer header I thought about it but anyone could just edit the referer header to make it like my SPA path? I tried it with postman and I can juste set it to anything
Yes, correct. That's why you really need some form of authentication and authorization to have a bullet proof solution.
Okay, well if you have to _pay_ for the data, you NEED authentication. Otherwise you can't verify who has paid and who hasn't. Outside of that, you can set a rate limit with a range of like 30 or 60 days on a client IP with a max number of uses that seems enough to demo the software.
If your scenario is like this: * No user authentication * User interface runs in a process that does not require any secret information from you during installation of the process's executable * You use a publicly available API end point with a standards based protocol Then you basically cannot disallow anonymous usage. You have 2 options: * Add a user authentication * Use something like mTls to identify the client's process. Option 2 requires you to use client certificates and this implies some kind of setup. Option 1 can be done in different ways. * Require the user to authenticate each time a session is started * Do a one time auth and store the result in a cookie for as long as possible
I just found another option: [https://docs.microsoft.com/en-us/aspnet/core/security/ip-safelist?view=aspnetcore-2.2](https://docs.microsoft.com/en-us/aspnet/core/security/ip-safelist?view=aspnetcore-2.2) Is there a way to bypass this? If my IP safelist only contains IP addresses that are used by my hosting provider, I should be fine?
Well I am paying for the data, but I am exposing it for free through my app. What I would not want is someone having access to that data to build another app (using my API). Users should **not** have to login to use my app. Maybe that's just not possible with a SPA + API architecture.
Thanks, I'll look into mTLS, I really don't want to force users to log in
Tpt?
I realize you said your UI is angular, but if you used some kind of server side rendering of the web page, or even just of that data and had the rest of your page be rendered by angular, you could restrict access by ip.
Table per type. Table per hierarchy is a non starter for many real world dbs
You are right for the first request, however when the user changes page it‚Äôs just gonna be an API call. The server-side rendering only happens on the first request or on a page refresh. As soon as the javascript bundle is loaded there is no more ssr. You are right about scraping. Maybe I am just worrying too much and rate limiting (as suggested above) might be enough.
In my office we use angular often. It‚Äôs great, but really it all depends on what your app is doing. If there isn‚Äôt a whole lot of dynamic content then the extra work may not be worth it.
I'm currently using Vue and Typescript, but to answer your question, it will depend on what you're building. There seems to be a trend towards SPAs over server side rendering, but sometimes it seems like it's just because it's newer technology and avoids using too much Microsoft tooling. I just don't think client side is the best architecture for some applications. Out of the main frameworks, I prefer Vue due to its loosely coupled design. It also seems to render faster than other frameworks. Also, Typescript is a must for me since I'm building a large scale app that need to be supported for many years. If client side blazor was close to production worthy, I would consider it for this use case, but it's quite a ways out. Switching to a SPA framework is going to start off much slower than razor, but once you get past the learning curve and have the basic structure, the inner loop time using HMR is much more productive imo than razor so things pick up speed.
The first thing I noticed was you committed bin and obj dirs. The first file I opened was a bunch of date logic with no comments.
Are you allowed to share the tech-challenge pdf file? DesignCrowd likely owns the copyright of that file.
Some considerations: * Use enums instead of magic ints (Rules) * don't repeat `.ToString("dd/MM/yyyy"));` over and over again. Save the date-format in a (class-)variable so you can reuse it * dont "`try-catch`" on `DateTime.Parse`, instead use `DateTime.TryParse()` and notify the user about valid input format * make rules extensible by using some sort of `Command` or `Strategy` pattern (should remove the need for `switch-case` inside `for-loop` and make code a lot cleaner) * Document special calculations that need to be done *that* way * rules should be a dependency of a `BuisnessDayCounter`, so create the appropriate constructor / methods to add/remove/clear Rules
Your solution could be considered "messy" because you do a lot of intricate calculations. Try instead to break the solution down into small components. So, to find the number of business days between two dates, you could - create a function that returns the dates between two given dates - create a function that determines if a given date is a business day - combine the two previous functions and count the number of resulting dates. Something like this: https://gist.github.com/ibsenrune/7e630ded4bc93f1f8c30a8ad3e4c57e2 I think you will find that if you write your code like this, it is much easier to convince yourself that the code is correct.
The biggest issue I found is that you missed this requirement &gt;Design a data structure or hierarchy of structures which can define public holidays in a more complex fashion than simple dates. I think they were looking for a new class or structure that you could initialize with a constructor that would create new "holidays" that you pass in as a collection to the method. Instead you used "magic numbers" to represent the type of holiday.
I'll try not to go over what others have but things that jump out to me * The try-catch part at the start, you should be using `TryParse` as others have mentioned. Also seems little point in just exiting, why not go back round in a `while` loop or something similar until it's correct. * The `WeekdaysBetweenTwoDates` is just messy, and hard to follow without comments. If it wasn't for the function name, I could not very quickly tell you what it was doing. As someone else mentioned the one thing that really strikes me is that it's a bit "manual" for lack of a better word, you could really do with a function to determine whether a given date is a business date or not and then loop.
Very cool. But this does nothing to change my personal strongly held belief that SignalR is close to black magic. (But is wonderful!)
It's a long long time since I did anything like this, but we used DirectShow, and build the desired filter graph. Someone else my have a more modern solution. https://docs.microsoft.com/en-us/windows/desktop/directshow/directshow
Thanks mate, i'll have a look at that.
Good point. If you are not sure, I'd recommend you remove it and instead provide a summary of the task you had to do. Since your repository is public, any future recruter/employer might think twice before giving you just a technical assignment.
Angular, vue, ASP.NET MVC and plain .NET CMS platforms, depends on the project.
&gt; I'd recommend you remove it And purge it from the history as well.
Since most of the others already pointed out alot of things I won't address them. However \` WeekdaysBetweenTwoDates \` contains according to my calculations alot of unnecessary code: var totalDays = interval.Days - 1; var fullWeeks = totalDays / 7; if (totalDays &gt; fullWeeks * 7) The if statement above is never going to execute because \`fullWeeks \* 7 always == totalDays\`. Because \`fullWeeks = totalDays / 7\`. Which means that the whole if statement can be removed.
Pluses for UWP: \- installations and updates are handled easily via the store \- native AOT compilation Pluses for WPF: \- better reach with Win7 support (still 20% of Windows is Win7 here in UK) \- probably more controls available, but narrowing But in a year and half, the choice will not matter much: \- WinUI 3.0 controls will support UWP and WPF. \- With .Net 5, WPF will have some AOT compilation. \- Win7 will be completely irrelevant. I would still give UWP the edge because of better update management with the Store.
This is just not true. The type of fullweeks will be int due to the division being on two ints, meaning any digits after the dot will be dropped. 10 / 7 = 1.
I see a lot of good advice ITT so I won't repeat it. Instead, I would like to point out that it is awesome that you are opening yourself up to critique like this. It is hard to take our ego out of our code, but it is an essential step to growing (no matter where on the path you are.) Keep your spirits high, and you'll go far, methinks.
We are using ASP.NET Core for REST API, Angular6 (with Bootstrap 4) for the front-end and Dapper for Data access layer. At a higher level, our architecture is like this, ASP.NET Core talks with our Service layer where we have our business logic and then Dapper in the Data access layer that talks with SQL Server. On the Angular side of things, we have components that communicate with Services (where our logic and HTTP calls to Rest API happen). We have a pure front-end guy who does help us in CSS and customizing the Bootstrap. Coming from ASP.NET MVC (also old web forms) and general .NET experience we prefer Angular compared to React or Vue. From my general expereince, and talking with my other developer friends, I observed .NET people usually prefer Angular.
I someone do something similar once, and we used HandBrake CLI to do the heavy lifting (starting the process from a desktop app).
Have you tried Heroku?
Personally given that as part of the challenge they mention they are looking for tools, libraries, etc I would make the solution based on a standard third-party library that fits the bill, like Noda time or Nager.Date and submit it back to them with a note saying that this is the most straight forward solution as you're leveraging existing open source libraries that have community support behind them rather then reinventing the wheel and adding technical debt to the project, but if they want you can go and implement it from scratch you totally can do that is what they are testing for. If a candidate did this on my interview they would definitely score significant bonus points.
Id be looking at bindings to ffmpeg (which I believe is also used by handbrake). Searching for ffmpeg on nuget throws up a bunch of stuff including this [https://www.nuget.org/packages/ColinChang.FFmpegHelper/](https://www.nuget.org/packages/ColinChang.FFmpegHelper/)
Some people may disagree with me, but I think there's an overusage of var for things that have an absolute return type. I'm not saying your lazy, but it could come off to a potential employer as lazy. Again, this is IMO. You also sometimes use it inconsistently: public void ThirdTestForWeekDaysBetweenTwoDates() { var result = bdc.WeekdaysBetweenTwoDates(new DateTime(2013, 10, 7), new DateTime(2014, 1, 1)); Assert.That(result, Is.EqualTo(61)); } [Test] public void FourthTestForWeekDaysBetweenTwoDates() { int result = bdc.WeekdaysBetweenTwoDates(new DateTime(2013, 10, 7), new DateTime(2013, 10, 5)); Assert.That(result, Is.EqualTo(0)); }
Think of it this way: Your client is public. Also your client is mostly just a shell wrapping the functionality, and if that nice UI shell was stripped away, it would still technically work. So no matter what you do, someone is going to be able to take that shell, strip it down, and replicate that functionality, bypassing any client-side limits/protections you may have. There is no way to tell if the client is coming from a browser or if it's coming from a custom application, because a custom application's requests can be made to look exactly like whatever a browser would do. The only protection "you" get is CORS, and it's not really intended to protect you. It's intended to protect the front-end of a malicious site from sending an authenticated request straight from the browser to your site and having the malicious site skim the user's potentially personal information. There's still nothing to keep a malicious site from depending on your API at the back-end layer using their own custom requests to your service. And this is an architecture-agnostic problem. Whether it's SPA or MPA, you're not going to be able to validate the client. Anti-forgery tokens in a MPA are a similar concept: they're intended to protect an unsuspecting user from having a malicious site act as an authenticated proxy to do malicious things to the your user's account. They aren't intended to protect *your* data in general. Like, I use fiddler to spoof requests to the sites I develop all the time, and it works just fine on both SPAs and MPAs. It sounds like you just have some design decisions you need to make on how you want to control your back-end's calls to the API (and if the calls that cost you money are made directly from your front end, NO. BAD. Never do that lol). It's very likely to involve some sort of user authentication, though.
In one part of your code you iterate through a dictionary and then you have a switch statement that has a case for each key. There is no difference between that and actually writing out code serially for each key in the dictionary. The loop isn‚Äôt adding anything here. Loops are for when you want to repeat the same code for multiple iterations. The fact that you are even trying to run code for every value of the dictionary means you are doing something wrong. You need more practice developing algorithms and writing code. It‚Äôs clear from reading your code that you don‚Äôt have a clear idea in mind of how to solve the problem. Do some google searches for code challenges. Write yours and then look at other people‚Äôs solutions. Here is how I would have thought of it: - find the number of weekdays by iterating through days and ignoring saturday and sunday for the count. - iterate through the holidays and check for each one if they are between the first and second date. If so, subtract one from weekdays. At the end of the loop you will have business days. Now code that. It should be much simpler than the code you displayed.
I agree with this! What you did was brave--especially on the internet. :) But opening yourself up to this will be what makes you a better coder.
Agreed. This speaks a lot to your personality OP to open yourself up for critique and learn from this experience. Good on you. You'll get the next one.
I got one project using Blazor at the moment.
I appreciate you‚Äôve gone Angular, but what about trying Blazor in core 3? That has a server side page rendering option, so that would hide your api from the outside world?
It's working fine. Just right lick on "Connected Services" and off you go.
To be honest I don't think the mTls will be a solution for your requirements. You write about a SPA for the front end which is not a type of application that supports mtls right now (AFAIK)
* Your `WeekdaysBetweenTwoDates()` function is literally [the first solution on Google](https://stackoverflow.com/questions/1617049/calculate-the-number-of-business-days-between-two-dates), and the first answer on the SO post. The fact that you're copying off the first answer on SO without improving on it (there are better, cleaner answers) is laziness and does not show *your own* problem solving ability in any way. * The data structure you designed (Dictionary) is really simply and a lot of shortcomings which are pointed out in other replies. Nitpicks that might have contributed: * You do not use the Visual Studio .gitignore file, which is why bin and debug are uploaded * Your code has inconsistent formatting. Also, the fact that C# allows if-else blocks without parenthesis does not mean you never use parenthesis. I think some functions would be more readable with parenthesis. I think this problem statement is inspired from [this issue](https://github.com/nodatime/nodatime/issues/6) in the NodaTime library. You could certainly take some inspiration from that issue page.
You could look into sending a session cookie in the response of the request to the web page that hosts your SPA. Then use that session cookie in your API requests. This means that at least the anonymous party has to make a request to your web page before it is able to make a request to your api
I recently failed a couple of tech interviews for .NET roles too. My skills are a bit out of date RE: ASP .NET core! My condolences to you my friend, it's tough out there!
As stated in a previous comment SPA dev cycles speed up when you develop longer on it. Also complex user interaction is tough using razor pages. A simple thing as a modal popup that has a return value to be used in the page that open the page requires you to set up Ajax calls, include JavaScripts etc. Yet another advantage that frameworks like angular have over jQuery is a good separation between application logic and logic that interacts with the Dom (the layer is done by the framework). This helps you a lot in cross browser compatibility and browser version differences. My go to solution right now is .net core as back end API and angular as front end framework
The newVersion needs to be the version you have
 If you have 10.0.3 installed, then your redirect binding line should be &lt;bindingRedirect oldVersion="0.0.0.0-10.0.0.0" newVersion="10.0.0.0" /&gt;
There is a lot of good advice here. I suggest you take it, refactor the exercise and resubmit it to the recruiter. A couple years ago I interviewed a guy that did rather poorly on a technical exercise in the office and asked me for a second chance to work on it at home and resubmit. He ended up being a great hire.
Check which version you have in references
Okay, that is my bad. I had to update the csproj files as well to point to 10.0.0. The problem is, something in my framework needs Newtonsoft 12.0.0. I ended up just upgrading to 12.0 and it is progressing further than before. Thanks for the help.
Welcome to the dependency hell.
&gt;Personally given that as part of the challenge they mention they are looking for tools, libraries, aka, free code for their own projects :P
Really cool stuff, but I think Blazor will eventually have the upper ground.
Thanks for you detailed answer. The API calls that cost me money are done by a cron job I have running every 60 seconds and the results are stored in a Redis Cache. My backend has access to that cache and the client side app has no knowledge of that data, it just calls my API which handles everything on the server. As you have stated my issue is more of a design issue. Rate limiting is the best option for my needs right now. Again, thanks for your insight, it is appreciated.
I have already taken a look at Blazor, but for the sake of development speed I chose Angular for the time being. About Blazor, after the first print is done using SSR, how does the client app fetch more data from the backend? I think there is a websocket connection is that right?
implement a token generation algorithm that your application and API both use based on other data in the request. App generates the token, sends it to the API who generates the token again and compares them. Not foolproof - but probably good enough.
We don't touch in razor and jquery. Nor in mvc in .net projects (for more than 3 years already). We prefer to have the frontend and backend independent. In the frontend we use Angular(latest version available).
I concur with this. One of the things I try to gauge in interviews is the ability and willingness to learn. If you can take feedback and then incorporate that into your program / learn from it I see that as a huge plus. All of us are learning all the time. Keep your head up, you're on the right path.
I have to the disagre with the win7 part. It has about 35% market share and won't die that fast. Just like windows XP took his time (and still not dead). Just for that reason, I would go WPF.
This is an important answer. It's OK to use SO, but don't pass it off as your own code in an interview. Use it as inspiration or guidance if you need to, but write your own code. They want to know what you would do.
Let me share a metaphor for what UWP can be like. You want to create a SQLite query editor. You write 20 lines of plumbing code required get permissions to use a file and you put it in your future access list. But.. SQLite requires a file path and not a StorageFile that the permission file pickers return. Then you learn, you can only use a file path if it's in your isolated storage area EVEN if the user gave you permission to access the file. You're only option to open the database is to copy it to your isolated storage area and then copy it back out when you're done with it. Depending on your app you will run into one headache after another that you won't have in WPF. There are a lot of cool things about UWP but it can be death by a thousand cuts.
is it production ready, though? I have a feeling this would be super easy to implement if you're already familiar with .net / jquery / javascript / C#
Definitely. In software development, if someone else has done it, leverage that rather than attempting to do it yourself. Also, if you can think of it, chances are somebody has done it. Just be sensible that they have done it right. Libs like the aforementioned NodaTime are fine. Some code from Github with only a handful of commits 8 years ago followed by radio silence and a ton of open issues is probably not.
Read other people's code. This includes project templates that come with dotnet, any blogs or tutorials from the microsoft team, and numerous github projects. Your goal should be to learn how to write idiomatic code in the dotnet world.
For what it's worth, I would not have failed you based on your submission, unless you're applying for a senior level job. The fact that it's a copy of the first SO answer would be a bit worrying, though, so I would have to have you in for another, monitored challenge (fizzbuzz or similar with someone looking over your shoulder). Other than that, there's a lot of good advice here: Split up the long functions, give the variables and consts meaningful names (in general, spend more time on the naming), and I think you should just code more in c#. Having a better grasp of C# as a language would lead you to discover .TryParse instead of try { .Parse }catch{}, etc.
I think it would be very valuable for you to see how someone else accomplishes this same task. Perhaps someone here would be nice enough to do the assignment so you can see another way of accomplishing it.
Just to give you an idea of how over-complicated your code is, here is the solution two challenge 1 as written by someone competent in C#: &amp;#x200B; private static int WeekdaysBetweenTwoDates(DateTime firstDate, DateTime secondDate) { return (firstDate &gt;= secondDate) ? 0 : Enumerable.Range(1, (secondDate - firstDate).Days - 1).Select(day =&gt; firstDate.AddDays(day)).Count(day =&gt; day.DayOfWeek != DayOfWeek.Saturday &amp;&amp; day.DayOfWeek != DayOfWeek.Sunday); }
while I agree with you here, I just wanted to mention that the dictionary values are not single holidays, but lists of holidays. &gt; IDictionary&lt;int, IList&lt;DateTime&gt;&gt; rules
I've used [this FFmpeg binding](https://github.com/Ruslan-B/FFmpeg.AutoGen) very successfully in a live broadcasting application. It'll do everything you need.
Also your methods are way too long! * Main - 36 lines long * WeekdaysBetweenTwoDates - 37 lines long * BusinessDaysBetweenTwoDates - 91 lines long &amp;#x200B; So how long should they be? That is subjective. Some say as short as possible (around 5 lines long) others say no more than 20 lines long. Personally I think if you shoot for somewhere between 12-18 lines long you're ok. But for sure anything over 20 lines long you should probably start breaking up the logic into other methods. &amp;#x200B; Don't feel bad we all started out the same way. Read "Clean Code" to learn better coding techniques. Good luck!
Sounds pretty dangerous. Can‚Äôt imagine they are 100% compatible?
I've been researching this extensively and it sure does seem like there is little true case for one outside a "cool" factor or SPA. Being a developer for business apps, I can't come up with much of a business case for one, especially once it's time to deploy to servers.
Ive never encountered problems with Newtonsoft.Json, but yes thats correct (more compatible than not redirect binding, which id refusing to start your app at all)
Depends in your use-case and what your customer wants. In most cases. net core + razor pages is enough. However Frameworks like react or angular are better for large applications which should have rich customer experience like "app-like" behaviour as they feel much more native compared to just a webapp. Furthermore for frameworks like react there is a large ecosystem of community made npm-packages which are free to use and so on. In most cases it more or less depends on your/ your teams know-how and predicted complexity/ size of the application. If your team is rather small and there is mostly .net knowledge and the use case is limited, than go with just plain .net core and JavaScript. Otherwise .net core + react/ angular/ vue.js is the preferred choice since its is considered as state of the art and offers much more potential, albeit at the cost of a higher complexity.
Yet a random runtime crash that can happen at any time is worse, IMO, than a compile error, and this is what can happen with a binding redirect.
Pretty close.
Does it bother anyone else that the spec states to make BusinessDayCounter a class? There doesn't appear any reason for the 2 methods to be instance-level methods. Seems like making them static methods would be better. Thoughts?
Unfortunately necassary when working with .NET 4.6.2 and netstandard2.0 libraries, and many nuget packages autogenerate them on install (Newtonsoft.json is very well behaved under version mismatches, I wouldn't be so care-free with other packages tbh)
Is this site live and getting traffic? If so, then you should be able to calculate costs if you would host via Azure. If the site is not live yet, using the free or basic tiers on Azure would be very cheap.
Does anyone mind to post what the challenges were? GitHub link not working anymore...
Yea ill just bite the bullet and stick with azure. The platform is the best
&gt;They want to know what you would do I would copy it from SO. Rewriting code that is easily copied from SO is essentially stealing time from your company. Unless the code is garbage, in which case just don't use it.
You would do that in an interview?
 using NUnit.Framework; using System; using System.Collections.Generic; using System.Linq; &amp;#x200B; namespace ConsoleApp1 { class Program { static void Main() { void assert(int expected, DateTime first, DateTime second) =&gt; Assert.AreEqual(expected, WeekdaysBetweenTwoDates(first, second)); &amp;#x200B; void assertWithHolidays(int expected, DateTime first, DateTime second) =&gt; Assert.AreEqual(expected, BusinessDaysBetweenTwoDates(first, second, new List&lt;DateTime&gt; { new DateTime(2013, 12, 25), new DateTime(2013, 12, 26), new DateTime(2014, 1, 1)})); &amp;#x200B; HolidayRule anzacDay = new AnnualSameDateHolidayRule(month: 4, day: 25); HolidayRule newYearsDay = new AnnualSameDayPostponedIfOnWeekendHolidayRule(month: 1, day: 1); HolidayRule queensBirthday = new AnnualSameNthDayOfWeekInMonthHolidayRule(DayOfWeek.Monday, occurence: 2, month: 6); &amp;#x200B; void assertWithHolidayRules(int expected, DateTime first, DateTime second) =&gt; Assert.AreEqual(expected, BusinessDaysBetweenTwoDates(first, second, new List&lt;DateTime&gt;(), new List&lt;HolidayRule&gt; { anzacDay, newYearsDay, queensBirthday })); &amp;#x200B; assert(0, new DateTime(2013, 10, 7), new DateTime(2013, 10, 8)); assert(1, new DateTime(2013, 10, 7), new DateTime(2013, 10, 9)); assert(5, new DateTime(2013, 10, 5), new DateTime(2013, 10, 14)); assert(61, new DateTime(2013, 10, 7), new DateTime(2014, 1, 1)); assert(0, new DateTime(2013, 10, 7), new DateTime(2013, 10, 5)); &amp;#x200B; assertWithHolidays(1, new DateTime(2013, 10, 7), new DateTime(2013, 10, 9)); assertWithHolidays(0, new DateTime(2013, 12, 24), new DateTime(2013, 12, 27)); assertWithHolidays(59, new DateTime(2013, 10, 7), new DateTime(2014, 1, 1)); &amp;#x200B; assertWithHolidayRules(3, new DateTime(2019, 4, 23), new DateTime(2019, 4, 30)); assertWithHolidayRules(0, new DateTime(2017, 1, 1), new DateTime(2017, 1, 3)); assertWithHolidayRules(1, new DateTime(2019, 6, 9), new DateTime(2019, 6, 12)); &amp;#x200B; Assert.AreEqual(1287, BusinessDaysBetweenTwoDates( new DateTime(2010, 1, 1), new DateTime(2015, 1, 1), new List&lt;DateTime&gt; { new DateTime(2012, 4, 4), new DateTime(2014, 2, 13), new DateTime(2011, 3, 2)}, new List&lt;HolidayRule&gt; { anzacDay, newYearsDay, queensBirthday })); } &amp;#x200B; private static int WeekdaysBetweenTwoDates(DateTime firstDate, DateTime secondDate) { return BusinessDaysBetweenTwoDates(firstDate, secondDate, new List&lt;DateTime&gt;()); } &amp;#x200B; private static int BusinessDaysBetweenTwoDates(DateTime firstDate, DateTime secondDate, IList&lt;DateTime&gt; publicHolidays) { return BusinessDaysBetweenTwoDates(firstDate, secondDate, publicHolidays, new List&lt;HolidayRule&gt;()); } private static int BusinessDaysBetweenTwoDates(DateTime firstDate, DateTime secondDate, IList&lt;DateTime&gt; publicHolidays, IList&lt;HolidayRule&gt; publicHolidayRules) { return firstDate &gt;= secondDate ? 0 : Enumerable.Range(1, (secondDate.AddDays(-1) - firstDate).Days) .Select(offset =&gt; firstDate.AddDays(offset)) .Count(day =&gt; day.DayOfWeek != DayOfWeek.Saturday &amp;&amp; day.DayOfWeek != DayOfWeek.Sunday &amp;&amp; !publicHolidays.Contains(day) &amp;&amp; !publicHolidayRules.Any(rule =&gt; rule.IsHoliday(day))); } &amp;#x200B; protected abstract class HolidayRule { internal abstract bool IsHoliday(DateTime datetime); } &amp;#x200B; private class AnnualSameDateHolidayRule : HolidayRule { protected readonly int \_month; protected readonly int \_day; &amp;#x200B; internal AnnualSameDateHolidayRule(int month, int day) { \_month = month; \_day = day; } &amp;#x200B; internal override bool IsHoliday(DateTime dateTime) =&gt; dateTime.Month == \_month &amp;&amp; [dateTime.Day](https://dateTime.Day) == \_day; } &amp;#x200B; private class AnnualSameDayPostponedIfOnWeekendHolidayRule : AnnualSameDateHolidayRule { internal AnnualSameDayPostponedIfOnWeekendHolidayRule(int month, int day) : base(month, day) { } &amp;#x200B; internal override bool IsHoliday(DateTime dateTime) { var holiday = new DateTime(dateTime.Year, \_month, \_day); if (holiday.DayOfWeek == DayOfWeek.Saturday) return holiday.AddDays(2) == dateTime; if (holiday.DayOfWeek == DayOfWeek.Sunday) return holiday.AddDays(1) == dateTime; return holiday == dateTime; } } &amp;#x200B; private class AnnualSameNthDayOfWeekInMonthHolidayRule : HolidayRule { protected readonly DayOfWeek \_dayOfWeek; protected readonly int \_occurrence; protected readonly int \_month; &amp;#x200B; internal AnnualSameNthDayOfWeekInMonthHolidayRule(DayOfWeek dayOfWeek, int occurence, int month) { \_dayOfWeek = dayOfWeek; \_occurrence = occurence; \_month = month; } &amp;#x200B; internal override bool IsHoliday(DateTime dateTime) { if (dateTime.Month != \_month || dateTime.DayOfWeek != \_dayOfWeek) return false; return Enumerable.Range(1, [dateTime.Day](https://dateTime.Day)) .Select(dayOfMonth =&gt; new DateTime(dateTime.Year, dateTime.Month, dayOfMonth)) .Count(day =&gt; day.DayOfWeek == \_dayOfWeek) == \_occurrence; } } } }
Thanks for the idea! It might indeed make it a little bit harder to find out, but the JavaScript code is available for anyone to see and use. How would you try to ‚Äúhide‚Äù it?
This is why I use automatic binding redirects instead of listing them all in the config file.
https://www.amazon.co.uk/Clean-Coder-Conduct-Professional-Programmers/dp/0137081073/ref=asc_df_0137081073/?tag=googshopuk-21&amp;linkCode=df0&amp;hvadid=310913487979&amp;hvpos=1o1&amp;hvnetw=g&amp;hvrand=14303364949321251743&amp;hvpone=&amp;hvptwo=&amp;hvqmt=&amp;hvdev=m&amp;hvdvcmdl=&amp;hvlocint=&amp;hvlocphy=1006979&amp;hvtargid=pla-435427786523&amp;psc=1&amp;th=1&amp;psc=1
I disagree :p The use of var's let me easily refactor my code in the future.
Sure, it is... but it should obviously be avoided as much as possible. &gt; Newtonsoft.json is very well behaved under version mismatches Yeah, that's actually a bit annoying, honestly. In the sense that I'd prefer they use semantic versioning so one is able to reason about this.
I think the idea is that you use it for clients that can‚Äôt support Blazor natively (but you can force all clients to do so), so the client executes JavaScript locally and it‚Äôs connected to a dedicated thread on the server using signalR, then each event result is server side rendered. To the point where you technically don‚Äôt need an API because your on the server and can access resources natively. Though then things will get messy and you should retain the decoupling.
I would do it in an interview, yes (In fact I literally did it today, while the interviewer was watching and was complimented for it) - however as the poster above has said I wouldn't just pick the first answer I came to, I'd read the other responses and pick whatever the best solution is for my needs (Which might be a mixture of them or none of them). As long as you're not just blindly copying and pasting, as long as the code you're using is suited for your needs and you fully understand it then there's no issue. There's no sense in reinventing the wheel _just because you didn't write it_. In the real world we're solving real business problems, not trying to solve the same problem in a slightly different way because....well I'll be honest, I don't understand why you'd do it differently just for the sake of it. That sounds like a good way to write obfuscated code. Given this was an "at home" test (I'm guessing, as it's on his github), I would fully expect someone to use all of the resources they have to hand - including stack overflow. Hell even in person I would expect someone to be able to use the internet. I wouldn't expect any developer these days to be capable of coding perfectly in isolation, without an internet connection, particularly in an area that's absolutely _prone_ to mistakes (like literally anything involving dates and time). I'd much rather they did research first, so all the previously-solved problems are done quickly and you can focus on the business requirements instead.
This seemed like a fun challenge, so I created a functional solution to the problems in C#: [https://gist.github.com/maroth/7ee36c44f98d73792142ff571f497658](https://gist.github.com/maroth/7ee36c44f98d73792142ff571f497658) &amp;#x200B; OP, don't try to copy this style of coding. You are not ready for this.
There's lots of great feedback here, but one thing I _also_ haven't seen mentioned: Your git history (or lack of). You made a first commit, then pushed everything else up as one giant commit. That's not good practice at all and something I'd look at if I were reviewing your code. Make lots of small, specific commits. If you have a rich history of everything you've done, every singular choice and change, then you can easily go back and remove specific bits (Undo). It also helps you experiment and iterate on your code as you're going to naturally think about smaller chunks rather than get lost in the big picture (Which I think is what's happened here). That history would also show a lot about your approach - what did you do first, what were the issues you encountered and how did you resolve them. The history can tell a lot about a person.
 [https://gist.github.com/maroth/7ee36c44f98d73792142ff571f497658](https://gist.github.com/maroth/7ee36c44f98d73792142ff571f497658)
ahh, then compute the value on the server when the page is requested based on information in THAT request and ensure that information is included in the request to your API (along with some other extraneous information that you do not use).
I was just talking to my intern about this. I abide by the 20 line rule.
Praise the Heavens üôè Finally!!
You'll notice they've added three issues, which may give you some ideas of the problems. As someone else mentioned you have all the binaries in there, there should be a git ignore. All your tests have names like "SecondTestForSomethingThatDoesn'tDescribeWhatTheTestDoes". Tests should have names that explain what is being tested. I'm guessing you also wrote the tests after writing the code. Correct? Employers have a hard on for TDD. &amp;#x200B; WeekdaysBetweenTwoDates could be broken down into distinct methods. Currently it's a long series of if statements which is hard to read. &amp;#x200B; BusinessDaysBetweenTwoDates has a commented out line that adds no value. There's no exception handling anywhere. BusinessDaysBetweenTwoDates has a comment about something making LINQ easier to use. this is redundant, while other businessy things are not commented. really the code should explain itself, but you've got loads of nested enumerations which could be extracted into separate methods to make it easier to read. SeedData has comments after the method name instead of using /// comments above. Actually that's true for all the methods, usually no comment. Also put the comments in SeedData above the line it pertains to. We usually want lines to be shorter than some arbitrary max length for readability. SeedData should probably be a static class. &amp;#x200B; I only really looked for structural and good practice stuff. I didn't check the veracity of the code or read the PDF, but look at their issues list anyway.
First thing I see is you used only those two provided methods. That's I guess what they refer to in their mail. Just because they tell you these are the starting methods, doesn't mean you are not allowed to create more. Also I see magic numbers everywhere.
Yep. I once did a "filter out the morons" written test, a fair few years back as it would be online these days. One of the questions was about how I would solve problems and I put Google in there. If I was doing this in a one on one coding interview I'd ask if it was ok to google the answer first, and write tests to assert that it worked. If they're asking you to do FizzBuzz, I'm guessing (if you haven't already walked out in disgust) that googling that one isn't going to go down well.
Hahaha, I used to give FizzBuzz as a test for candidates to do but it was entirely done in person and I only wanted to see what their approach/thought patterns were. _So many people_ failed that test, but it sure did weed people out. These days I'll give a more open-ended exam and ask them to spend an evening or so on it, using whatever resources they want. Basically, like what OP had to do. Realistically, I just want to know: 1) Can you actually _code_ but most importantly: 2) Can you solve _problems_
Id probably provide two solutions, extract the class definition out to an interface and do a NodaTime version and then a hand coded version. It shows that you understand the importance of NuGet, but also that you can research and solve problems and structure code correctly. Finally i wouldn't add a dependency to a library where I want six lines of code from it. It bloats the fine deployment size and you risk problems later with versioning of libraries. JSON.NET is one that has caused me problems in the past. So do leverage NuGet, but wisely.
Oh goody, a single .exe that's over 70MB in size üòÇ In fairness, I believe future builds are going to trim some unneeded fat from the final output so this is still a great step forward.
Hanselman used something called Warp to get it down to 13mb: https://www.hanselman.com/blog/MakingATinyNETCore30EntirelySelfcontainedSingleExecutable.aspx
:) I've watched a few coding interviews online where they use one of those screencast/collaborative coding tools. Some are better than others, and I find it hard to decide whether I'd hire someone on the basis of their answers. When I interview developers I don't give a coding test, I just ask questions. It gives me the option to go off on tangents, dig deeper and you can work out if their answer is based on book smarts or experience smarts pretty easily. I interview sometimes and get quite pissy if a whiteboard comes out. Anyone who uses a whiteboard to prototype code is doing it wrong, so why do it in an interview? How am I supposed to copy paste stuff around? Developers don't always think in a linear fashion and I'm not taking a circular saw with me in case I need to reorder my code. Ooo, one other point. I also get pissy if I'm expected to spend an evening coding something up. I might be interviewing at half a dozen places in a week, roles always seem to come up in batches. I had one company send me a spec which could have taken a weekend to code up so I told them to sod off. It's an unnecessary incursion into my life. They either have very specific expectations which allow them to assess the code in 10 minutes, or they're not going to assess it properly. The former is inflexible, the latter is just a waste of my time. I totally get what you're saying though, my expectations are pretty much the same when I interview developers, but I've found if they know how to structure code properly, and can answer questions on the how and why of it, they never have problems solving specific problems. I also try and assess how well they will collaborate. The worst kind of developer is the one who will spend a day on a problem rather than an hour and then asking for help (or the kind who won't offer to help).
Lots of company I interviewed for and the current one when I do the interview consider copying code and plagiat as a single reason to reject a candidate. While being able to find answers or tips on SO or similar websites could be a strength, the point of an interview is to figure out your technical skills. Original code is preferred especially since I, as an interviewer, will always ask follow up questions. Most people who just copied code, even if they understand it, will fail to answer those questions. On the other hand, people who wrote their own code, even if it is incorrect will have more ease to work out improvements once I have made my observations.
As a note you you could always do this with ILMerge by combining assemblies or by using a tool like Fody to add references as embedded resources.
It's dumb I that it has to extract all files to a temp directory. It should be able to just let the assembles from the EXE image.
Congrats .Net Core team - you've finally caught up to the capabilities of Turbo Pascal circa 1983 :)
This is an excellent article wrapping together things I knew in isolation as an overview.
You already solved the issue but one tool that can help you solve more complex dependency problems is fuslogvw.exe. it is a log of every assembly resolve that happens and the steps it takes. It will show you all burning redirects and every path it looked for it. Super useful.
It‚Äôs big because the self contained exes are framework independent. They include the runtime with them.
I am learning Reactjs. I have started by using the built in template for React and Redux. Its great. But I might actually create a stand alone React App and just use APIs to bind it together instead of in one package. That way I am not stuck in the niche area of using ASP's terminology and structure when googling for help.
The same thing. The only difference is I'm doing that to AI, imaging, and kubernetes. It's just as monotonous and just as boring, but in different ways because half the tools you need don't exist or are many versions behind and incompatible.
&gt; It should be able to just load the assembles from the EXE image. What benefit would it provide? .Net Core has had self-contained deployments for some time now. This is a step further. 99% of anyone could not care less that it does this. I am not saying this to be confrontational. *.app packages on OS X aren't a single executable file, binaries on *nix machines rely on shared libraries.
I enjoy doing CRUD *when* the tools make it smooth. Users thank you when you make their work lives easier. But it gets unpleasant when forced to use lousy frameworks or tools because they are "in style" etc. Office politics makes it hard to reign in buzzwords and bad stack decisions. I've dabbled with AI, music composing software etc. at home. If you do it on your own, you can do it your way on your time, not your boss's. I've even kicked around ideas to make money off of such, but then I'd have to deal with angry and deadbeat customers &amp; vendors, and it would then feel more like work.
This is neat, but as someone who uses Visual Studio, what's the deal with the different styles of command-line arguments? &gt;dotnet publish -r win-x64 -c Release --self-contained &gt; &gt;dotnet publish -r win-x64 -c Release /p:PublishSingleFile=true Just in these two commands, we've got single-hyphen, double-hyphen, and forward slash. Is there a reason for this?
If you did your AI well enough, your bot would take over your job and you'd be on a tropical beach right now.
I tend to write up different .NET Global Tool apps that handle some of the redundant stuff I have to do regularly. Usually code generators using Roslyn or manifest generators for assets and that type of stuff. I am open sourcing some of it when time permits.
&gt;Just in these two commands, we've got single-hyphen, double-hyphen, and forward slash. Is there a reason for this? /p:ParamName=value is usually msbuild.exe parameters that will get passed through.
I have never messed with code generators that sound pretty cool. I have heard of Roslyn but not sure what it did.
It's actually two styles, the dashes are UNIX-style where a single dash indicates a one-character option and two dashes indicates a full name. The slash is MS-DOS style, which is historically more common on Windows. I think it's because the `/p` option is a [MSBuild option](https://docs.microsoft.com/en-us/visualstudio/msbuild/msbuild-command-line-reference?view=vs-2019), as opposed to an option of the `dotnet` executable.
TIL a double hyphen looks like an equals sign, but two consecutive hyphens is not a double hyphen. https://en.m.wikipedia.org/wiki/Double_hyphen I am not being pedantic, I genuinely just googled double hyphen for giggles. It was Schrodinger's Double Hyphen prior to my search for me.
Desktop link: https://en.wikipedia.org/wiki/Double_hyphen *** ^^/r/HelperBot_ ^^Downvote ^^to ^^remove. ^^Counter: ^^261924. [^^Found ^^a ^^bug?](https://reddit.com/message/compose/?to=swim1929&amp;subject=Bug&amp;message=https://reddit.com/r/dotnet/comments/c2n8jm/net_core_now_has_a_way_to_package_your_entire_app/erlnttw/)
**Double hyphen** The double hyphen (Ôºù or „Ç†) is a punctuation mark that consists of two parallel hyphens. It was a development of the earlier double oblique hyphen (‚∏ó) which developed from a Central European variant of the virgule slash, originally a form of scratch comma. In order to avoid its being confused with the equals sign (=), the double hyphen is often given as double oblique hyphen in modern typography. The double hyphen is also not to be confused with two consecutive hyphens (--), which are often used to represent an em dash (‚Äî) or en dash (‚Äì); that practice arose due to the limitations of typewriter character sets which did not have both hyphen and dash. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/dotnet/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
Data acquisition and logging services, HMIs for some industrial stuff, variety of tools for some engineer types, few game tools made by communities and some other much smaller utilities.
Probably a big improvement. Some of the way you do things I find to be very difficult to read. You're cramming a lot of logic into a tiny space. Don't be afraid of variables and curly braces :)
&gt; It should be able to just load the assembles from the EXE image. &gt; 99% of anyone could not care less that it does this. Well, it is extra I/O to write a file to the filesystem. I wonder if they can embed the dependencies into the executable as embedded resources like what Fody Costura does.
Glad they finally added this functionality previously relegated to third party libraries.
This is akin to Java's JAR correct?
Never got it working with .NET Core though. Fody was handy with Framework apps.
Interesting. I wonder why Xceed claims to be the only library able to zip without an intermediary file or memory? Sounds like this one does exactly that. I'll give it a shot. Thanks!
Seriously, java has had this forever
&gt;Well, it is extra I/O to write a file to the filesystem. While I like this move from the .NET Core team, this is an important thing to consider in Windows. NTFS and the NT kernel have some pretty notable performance defects regarding mass file I/O with lots of tiny files. If you're deploying to Linux or Mac, you shouldn't have to worry much about the overhead this will generate (unless you want to be kind to SSD users, of course).
https://help.genesys.com/cic/mergedprojects/wh_tr/mergedProjects/wh_tr_web_administrator/desktop/Win2016_Install_IIS_and_ASP.NET_modules.htm
I guess the fact that UWP
Very cool. Thanks!
Check the Application Pool settings
Is there a way (or is it planned) to create a package with external dependencies only (things like Json.NET...), in the case of the user already having the framework installed?
I'm a little bit in love with NestJS and TypeORM. It manages relationship mapping in a way that makes more sense to me than Entity Framework.
Generally speaking, I'd like my programs to run from trusted locations. %TEMP% isn't that. %TEMP% is the... exact opposite of that. At $DAYJOB, regular users cannot run programs, scripts, etc. from user-writable locations. This means that if I package up a self-contained .exe and publish it to their program files directory, I can run the executable initially, but then it's likely to just explode when it tries to execute things out of the temp directory. (Yes, I'm aware that this is a somewhat contrived example as I could just choose to not build the self-contained app, but I can see a vendor providing their application to us using this format, which would then break everything.) After all, "running a program -&gt; binaries appear in a temp location -&gt; programs are suddenly running out of said temp location" is more often than not called "malware." This is a really bad implementation of this functionality. I'm sure they had their reasons, but there is ample room for improvement here.
So users don't have to install the .Net framework?
Have some upcoming internal apps developed with Blazor (server-side) anticipating for .Net 3.0 GA, the API backend already exists so it was possible to share most of the code for the front-end. Most of our apps uses Angular 6 through cli with some React Apps here and there.
Ehhh, not really the same. The best solution is a custom runtime image and that's not a single executable. And an executable jar still relies on Java to run it.
Hmm not really... You still had a jar and not an exe.
I'm the lead developer, CTO and co-founder of a startup. Doing all kinds of stuff. Building and maintaining a lot of web crawlers and have amassed a huge database of information about building materials. Internal tools, web and console applications, to enrich and match. A web application for analytics for B2B customers. A web application for price comparison and purchasing for B2B customers. A web application for price comparison for consumers. All done in .NET and running on Azure, and we're two developers. Right now I'm deep diving into AI and Machine Learning to improve our enrichment and matching capabilities. I'm using Python but also trying out Microsoft's ML services. Before I did a lot of work for large organizations and then it's a lot of boring and tedious work. Also did projects as a consultant and the sad part was that I often got in when tech and such was decided and left before I got to see the result. Building a company is sometimes a pain and it's a lot of work but I've never had as much fun. So if you have a chance to join, or start, small startup just when it starts, take it. I was 43 when I did it so it's never too late.
Yes
Not quite. JARs still require you to have Java installed. This packages the entire framework so that the exe is entirely self-contained.
**Pardon the interruption.**
You can you the same with Java since ages, by packaging JRE directory with application. And since Java 9, there is support for linking, with allows to create an application specific runtime, removing everything else. So now there isn't any JRE any longer, the official way is that Java apps should package the framework tailored to their scenario.
That's already possible today. It's called framework dependent deployment. It will act like how .net frameworks run today. It will use an existing .Net core runtime installed globally and if it doesn't exist it will not run. The article uses Self contained deployment and it seems the single file switch uses it as well, though I'm not too sure if it's possible to use a single file Exe for now with FDD.
yeah, ILMerge doesn't work with dotnet or "new" PDBs
Also because you can chain the single switches together, a double hyphen indicates that it's a single switch in itself not a combination of single letter switches
To add to that, unlike the /p style parameters which are msbuild parameters, the dash style parameters are dotnet CLI parameters
&gt; Keen eyes will notice something about the above screenshot. The file size. It‚Äôs over 70MB! That‚Äôs crazy for an application that does nothing but print Hello World to the screen! This is solved in Preview 6 of .NET Core 3.0 with a feature called IL Linker or Publish trimmer that omits DLL‚Äôs that aren‚Äôt used. But that‚Äôs a whole ‚Äònother post! There's already tools to get this to 10 or so MB , but that's still gigantic. Old linkers for statically linked code (which how this is called in the other universes) are able to eliminate **everything** that ain't called, down to the very last function (whereas here, it says "will remove unused DLLs", which is primitive, comparatively). The other aspect is: once I have many of these running on a system, there will be copies of same code in each process, putting load on it. This is primitive, too. (Point being: shared DLLs are good for your system.) Last time I measured, a do-nothing .net Core program was quite a bit slower than the Framework one (7msec vs. 12). There's two reasons for that that I can think of: * the thing with shared DLLs * NGEN, which is done for the Framework stuff.
Write, then read it.
Hmmm... maybe it's your own %temp% (which is... not so bad?)
Addressed right in the article. &gt; Keen eyes will notice something about the above screenshot. The file size. It‚Äôs over 70MB! That‚Äôs crazy for an application that does nothing but print Hello World to the screen! This is solved in Preview 6 of .NET Core 3.0 with a feature called IL Linker or Publish trimmer that omits DLL‚Äôs that aren‚Äôt used. But that‚Äôs a whole ‚Äònother post!
Do you take me for a mutable state moron? I am of the functional master race! /s &amp;#x200B; Yeah, I wouldn't hire me for that code either. It was fun to write, though.
Amazing! I can hardly recognize the C# in all the functional awesomesauce!
Even a C++ hello world isn‚Äôt that small if it would include the Visual C++ Runtime libraries.
&gt;I would think Java, Python, NodeJS frameworks have something equivalent but I am not sure. This makes me wonder why are these languages so popular. Am I missing something? What a weird statement. Half of the popular .NET NuGet libraries come from ported Java libraries. Where do you think we got the famous nHibernate from? Every library starting randomly with the letter "N" is a Java port. Hibernate is the original ORM written for Java. Also, most frameworks have ORMs. Entity Framework is nothing special in that regard.
And this is one of the reasons why microsoft developed System.Text.Json - Json dependency hell, especially since about every framework that deals with Json uses [Json.NET](https://Json.NET) albeit with different versions, ranging from 3 to 12
also x86 builds (anyCPU defaults to it, even on x64 cpus) run faster than x64 for .NET FX you can't really compare a language than contains a dynamic runtime, runtime code generation, and a gc with C or C++. &amp;#x200B; you can not "strip everything that is not called" when there is reflection, you need all the metadata you need. Now you don't strip the reflection part, but hey, you stripped "`SomePlugin.ClassJsonWriter`" because it was never called in any code path. &amp;#x200B; Uh Oh! Someone did some reflection over `pluginBaseName + ".Class" + pluginWriterClassName`. ("`SomePlugin.ClassJsonWriter`") Now this plugin and all code that calls it are broken. Especially DI-Frameworks use tons of reflection and runtime code generation that suffer from linkers and don't allow for AOT compilation in many aspects (some parts can be AOT compiled, others not)
&gt; What benefit would it provide? For the users the obvious benefit would be that the executables would take two times less space on their disks. This zip solution is a quick dirty disk-eating hack; if Microsoft thinks it's okay to deploy solutions like this, no wonder that Windows eats dozens of gigabytes for nothing.
But it still lacks possibility to easy declare ManyToMany relation between two entities. In Django it is enough to write: voters = models.ManyToManyField(User, related\_name='voted\_products') How to write it in [ASP.NET](https://ASP.NET) Core?
You really should get started with command line. You could write some scripts to automate deployments. UI clicking doesn't scale
Newtonsoft does use semver, they are just really strict on what constitutes a breaking change. Some api that'sbarely used canges behaviour in a breaking way when called with these specific arguments? Major version.
[https://github.com/rainglow/vs](https://github.com/rainglow/vs)
You can mark namespaces or types that are needed for reflection purposes. If you are loading external code such as plugins, then tree shaking doesn't apply anyway.
You could use attributes to tag things that should never be stripped. It is a hassle but probably worth it for people that want both small deployment and reflection.
The ILMerge method seems much nicer than extracting files like it is done now.
Where did you read that? Authorization Code flow is for server-side applications or and PKCE is meant for mobile/native apps that can generate an extra secret to prevent the interception of the code exchange. Neither work for a purely client/browser hosted app without a backend component. You need to use the implicit flow because there's no "secure" place to store anything on the browser anyway. The user can always access it, whether it's in local storage or in cookies. Here's the walkthrough for IdentityServer using implicit flow via a javascript app: [http://docs.identityserver.io/en/latest/quickstarts/6\_javascript\_client.html](http://docs.identityserver.io/en/latest/quickstarts/6_javascript_client.html)
Thanks for the comment. Already working on mew article about Azure SignalR and kubernetes
Yes, but people tend to focus on the extremes. Technically, if you're using a frontend framework to generate the entire UI then it doesn't matter what the backend is so you can use whatever framework you want. Angular is very opinionated, has lots of standard functionality, and is written in typescript (strong typing + similar C# syntax) so it's a very good choice for [asp.net](https://asp.net) core apps. Vue and React also work well, but might require a little more work with React being the most flexible since it has almost nothing "standard" other than some simple state management. There's a vast middleground though and it's rare that an app needs to be a full SPA. Razor/MVC give you tons of functionality that you'll start to miss with even simple things like routing, forms, API calls and the rest. In my experience, it's much better to have server-side pages and then load JS on top, a pattern called microfrontends. Basically your server-side page can be as heavy or light as you want, maybe even completely empty to just handle routing and access control, then use a JS app on that page that renders the rest. Vue makes this very easy and is know for it's "progressive enhancement" so you can create interactive areas on the pages that need it. [Gitlab.com](https://Gitlab.com) is a good example of this. React can do the same although not as simple, but Angular is probably too heavy for this. There are also lots of libraries like [https://github.com/turbolinks/turbolinks](https://github.com/turbolinks/turbolinks) or [https://intercoolerjs.org/](https://intercoolerjs.org/) to help add AJAX/interactive functionality without any fancy framework. Building a SPA is a big departure from server-side pages and you will move a lot slower if you don't have much experience and tooling. The benefits for the end-user are also debatable because it can mess with the browser navigation and a single JS error can crash everything. Very few apps need all that interactivity so evaluate wisely.
Containers makes this easy. You can run on AWS Lambda or GCP Cloud Run or Azure Container Instances for pennies. Azure DevOps is free to build and deploy your app for personal projects.
http://docs.identityserver.io/en/latest/topics/grant_types.html?highlight=granttypes "Note : For JavaScript-based applications, Implicit is not recommended anymore. Use Authorization Code with PKCE instead." I don't know what they mean by Javascript-based application, if not a SPA like my front-end. However I tried the workflow in the example you gave, and the issue is what I described ; it's not served by node but by the dotnet engine. Any advice ?
[JSON.NET](https://JSON.NET) has nothing to do with API responses. It writes and parses JSON from streams and text, using typed classes or \`dynamic\` or almost any other interface, supports custom data type and model converters, schema checking, cyclical reference handling, multiple ways to map object properties, etc. There are tons of features if you need to deal with JSON beyond just transforming it to and from a simple object.
If you know what you're talking about then you should realize that it's completely dependant on the context of the application. It's much faster and uses far less memory which might not make a difference in an internal MVC app but can make significant impact in high-throughput scenarios. We do billions of requests a day and it makes a difference for us.
There's an extension called Color Theme Editor that will allow you to customize pretty much everything. It can be a little tedious but you can tweak things just the way you like.
Authorization code requires a backend. Implicit flow gets all the token in the browser so it's always been "slightly less secure" then having a backend running but if you're not using that then you have no other option. They're talking about Javascript with a backend API (instead of server rendered pages). Here's a post for more context about implicit flow security: [https://leastprivilege.com/2019/01/18/an-alternative-way-to-secure-spas-with-asp-net-core-openid-connect-oauth-2-0-and-proxykit/](https://leastprivilege.com/2019/01/18/an-alternative-way-to-secure-spas-with-asp-net-core-openid-connect-oauth-2-0-and-proxykit/) The example shows an HTML page with the javascript you need to call identity server and handle the auth flow. You can render/serve that with Node if you want, you don't need .net for it. The backend you use can also be whatever you want. Start at the "*Add your HTML and JavaScript files*" section.
mmm. All that's already there. The good site is on the same iis.
Their both using the same Application Pool .NET v4.5.
I hear what you're saying but take it all with a pinch of salt. If you can show real world examples e.g where an end to end response time is quicker and uses less memory and cpu, I'd love to see it. Even at scale I doubt you'll notice a difference. Your JSON serializer is not the bottleneck in your application.
Rails (Ruby) has ActiveRecord and Django (Python) has South. Both are much easier (and more fun) to use than EF.
I probably express my situation wrongly. We DO have a backend api. Our project looks like this : --VueJS SPA as a front-end, run by node --WebApi Core 2.2 as a back-end, run by Kestrel --IdentityServer4 + WebApi Core 2.2 for user registration. The whole debate on "How to store it in the browser" is exactly why I've been looking into this : apparently, storing it in a httponly cookie is better, but I'm currently unable to achieve that. I'll read the blogpost you linked and see if it's helpful. Thank you.
And it is super slick ? LOL, 70mb for hello world is what you call slick ? This is why we can't have nice tech, because people like you are unable to hold strong opinions therefore when we have bullshit like this mess, you still here and applause while many of us are moving to either GO or another language
It says a lot when you have to use a third party app to fix their bullshit Who is responsible of designing .net core ? i have few words to tell him.. that's not gonna be pleasant, for him
Did you read the last sentence? It's already real-world. We notice a difference.
this is the result of their bad management, 70mb hello world, similar commands for different stuff, and they can't listen to user feedback
Next time someone tries to witeboard me I'll ask whether it has syntax highlighting and intellisense built-in
&gt; When this is executed, the dependencies are extracted to a temporary directory and then everything is ran from there. It‚Äôs essentially a zip of our previous publish folder! Well, or you could use something like 7Zip self extracting executable... I thought it would be something similar to Costura.Fody.
Holiday calendar probably needs to be an array internally so you can BinarySearch for the start + end index of holidays in the range; super fast even if you need 100 years of holidays
Here's a good overview: https://docs.microsoft.com/en-us/dotnet/core/deploying/ * Framework-dependent deployments (FDD) - As you say, they already exist and produce "small" packages. However, they need to be ran with the `dotnet` CLI. This method does not produce executables, but on the other hand, are cross-platform. * Self-contained deployments (SCD) - Produces these 70 MB packages. Includes the entire runtime, the whole thing, so that's why. These do produce executables, but with that, they also need you to select the target platform in advance. * Framework-dependent executables (FDE) - New in .NET Core 2.2! Combines the two above: depends on the .NET Core in the target system but still producing executables. So they're small, but as usual with executables, you need to select the target platform in advance.
Lol. Or just tip the board over and say it crashed :)
Maybe they have punchcards I can write it on?
Warp does the same thing that .net core does now, if I recall they actually got the idea from Warp. Self-extracting to a known location at first run and reuse the extracted dir on subsequent runs. The only difference here is that the one above wasn't ran by an IL linker while the example of Hanselman was already linked, you can see the MSBuild property tag `&lt;PublishTrimmed&gt;true&lt;/PublishTrimmed&gt;` there which runs the runs the IL linker.
I see.
Oh, that's great news then. FDE seems the perfect fit at least if you know your target audience will have the runtime installed, bonus benefits would be you'll get free improvements / fixes once they update a minor .Net Core version. Though is a double edge sword as those updates can break your apps at times like .Net Framework does now, but luckily you can state a supported version range at least. I'd rather not people throwing around SCD apps everywhere on the net imo which the size will add up. Maybe provide multiple binaries would be nice at least.
The bulk of that reduction from 69 MB is done by ILLinker trimming it down to 28 MB (`PublishTrimmed` in the XML in that blog post). Then Warp simply compresses it and adds a stub in front of the exe so that it'll find its payload, much like good old UPX.
hacks on hacks on hacks definitely not something i want
You gotta give him props for single-handedly creating a framework though
Nope, they took the worst decisions ever when rewriting .net framework, they didn't thought about deployment and not even about AOT They are now trying to fix that, but the solutions doesn't look that great or promising..
Why isn't this higher
NET CORE WEBAPI NET CORE MVC ANGULAR POWER BI Some part of Azure (App Service,DevOps, SQL Server, Vitural Machine, ...)
I'm preparing for the crawl project. Which .NET library do you use to crawl?
Web Application for a legal directory. Mostly CRUD stuff but there's lots of interesting integrations.
Finally, Go style deployment. One binary to rule them all :)
We're using the Abot crawler https://github.com/sjdirect/abot
I recommend Visual Studio IDE for C# and .NET. Visual Studio Code is way superior when it comes to JavaScript.
isn't this just an executable zip file? That's has been around like forever
Maintenance of an old Outlook addin. Internal tool for log viewing/filtering/searching. Web service, which operates with Office 365 API. Library for working with the custom properties in the files (mostly Office documents and PDFs). WPF app that shows the user some contextual information related to his work in the specific cases/moments. Internal tool, which creates summaries from the output of the static analysis of our C++ codebase and distributes the relevant info to the people, who made the changes that resulted in the new warnings.
It's a preview version and the fix is coming before it's full release, calm yourself.
I‚Äôm lazy, could this work to produce a self contained DLL?
The OPs mind is too puny! His intellect to weak to even understand the basics of this code. You are a god among men, a divine inspiration to all who dabble in the magical arts of c#.
Oh my god I can only get so erect. This code is astonishingly arousing.
no.
Totally trivial, but fun fact: Originally, the `getopt` program, which was made to generically handle argument parsing, only supported single dash "short options", which could be grouped together (`-abc` is the same as `-a -b -c`). A GNU enhancement to the `getopt` program later added double dashed "long options".[1][1] At some point, the shell command `getopts` (notice the `s`) was added to the POSIX standard, intended as an improvement upon the original `getopt` program. The original `getopts` didn't support long options, but a Solaris enhanced version of it did.[2][2] Each version has it's own limitations, and you can't ever presume which version of either `getopt` or `getopts` will be used. Overall, it's one of thise lovely religious debates. A lot of people even suggest implementing parsing manually as being a better alternative, since this way you'll always get consistent results. Figuring all of this out, when you're first getting into shell scripting is, quite frankly, a big fucking pain. :) [1]: https://en.wikipedia.org/wiki/Getopt [2]: https://en.wikipedia.org/wiki/Getopts
It's not an isolated binary. &amp;#x200B; It's a zip file, that extracts a stand alone into a folder, which it then re uses for future runs (somehow?). That's stupid. If I wanted a zip file of a stand-alone binary, I can already do that, using zip. &amp;#x200B; You've basically achieved a 'business solution' to a problem without actually solving the problem. How do I run my static binary in a container which doesn't have a file system? &amp;#x200B; What problem did they imagine people were struggling with? Seriously, you thought the problem was that people didn't know how to zip the folder up? come on\~
Glancing at the design docs for this feature, it looks like the files are extracted to the app's base directory. In a versioned manner too, allowing a user to keep multiple versions of the need, or want arises.
&gt; Lots of company I interviewed for and the current one when I do the interview consider copying code and plagiat as a single reason to reject a candidate. When I interview, I would also consider this a deal breaker. I would politely thank them for their time and show them the door. It's like asking someone to show their writing skills and having them show me the first page of the Princess Bride (the obvious pinnacle of writing skill ) and saying "this is an example of excellent writing."
Did you get that job?
According to the design docs, the proposed solution is that the extraction occurs once. I'm not sure it's worth worrying about if I get a guaranteed runtime that's known to work and a better deployment process. I haven't used Fody very much but I would expect that it's doing something similar. Maybe doing extraction every time in memory... Not sure, but the references have to get loaded sometime.
It bothers me as well that it is a completely common practice to just execute *anything* from %TEMP%. I feel like there should be some sort of application level isolation for this folder. Maybe App Store apps solve this problem and I don't know it.
Looking at the design docs, I didn't see mention of anything being compressed so I'm going to go out on a limb and say this current implementation doesn't use much if any extra disk space. Just because you must *extract* files, doesn't imply that they are compressed. You extract files from tar archives but they are compressed after being archived with gzip or similar
I got an offer this morning but I declined it in favour of another offer I'd been given earlier this week üòä
Eh, that's arguably better than %TEMP%, as it doesn't follow the most common malware path. However, any user running such a program from program files... probably wouldn't be able to. Which really does mean that this feature is not designed for the "app installed on a machine" use case, but rather... I'm really not sure. I wouldn't want to distribute a "portable" app with this, as it's just going to litter the working directory with stuff that I wouldn't want a user to see.
I do love the scaffolding... Visual Studio does feel like it's on a different level than other development platforms.
What, why wouldn't you be able to run the application if it's only extracting to its current directory? Are the file permissions that granular and restricted that it only has access to its current executable? How is anything able to run in that case?
&gt; You do not use the Visual Studio .gitignore file, which is why bin and debug are synced to GitHub. Not production quality. Is there one? I use visual studio and have *always* had to add my own by hand. Any suggestions?
&gt; What, why wouldn't you be able to run the application if it's only extracting to its current directory? Running the application requires read access. Writing requires.. write access.
1) As mentioned in my earlier post, the environment that I'm describing belongs to $DAYJOB, in which users cannot run programs from locations that they can also write to 2) By definition, this means that these apps can be run from either a user-writable location which would be blocked, or a location that the user can't write to (such as Program Files), which would break any app using this functionality entirely
&gt; According to the design docs, the proposed solution is that the extraction occurs once. I'm not sure it's worth worrying about if I get a guaranteed runtime that's known to work and a better deployment process. But I sure hope they verify that the already extracted files match... And that involves reading those files again.
When you create a repository using GitHub Desktop or GitHub for VS it will let you add a gitignore from this repository and default to vs gitignore https://github.com/github/gitignore/blob/master/VisualStudio.gitignore
&gt; Go has had this forever. FTFY
When user extracts files, they now have two copies of them: one in the original archive, and the actual executable uncompressed variant.
Absolutely
I am lead developer on a Clinical Quality Measure calculation engine. It uses a Windows Service background agent to perform all of the calculation. The front end UI is ASP.Net WebForms currently being migrated to MVC (then to core). All of our greenfield projects are dotnet core. For the service we use TopShelf which can turns a console application into something that can also run as a Windows Service. The application processes *very large* amounts of data in the course of running a report. Imagine a hospital having 50,000 patient visits in a year with tens or hundreds of medications each with all sorts of events. Most developers don't realize the absolute revolution taking place in healthcare IT. Standardizing data formats has been a huge push lately (eg. FHIR).
We're all pretty much making LoB applications. Let us know if you manage to get on the team building Skynet.
[Here](https://github.com/dotnet/designs/blob/78f7c44e9c4b8e1e91849af5270d739c1a480835/accepted/single-file/extract.md#extraction-requirements) are the requirements considered for this extraction scenario. [Here](https://github.com/dotnet/designs/blob/78f7c44e9c4b8e1e91849af5270d739c1a480835/accepted/single-file/extract.md#extraction-configurations) are current options for configuring extraction location. &gt; it's just going to litter the working directory with stuff that I wouldn't want a user to see. To me this seems like a rather silly worry. Why are you concerned about a user seeing the dependencies? Pop open `C:\Program Files (x86)\Microsoft Visual Studio\2017\Enterprise\Common7\IDE`, you've got tons of stuff in there. Many of us here use VS all day, and never concern ourselves with anything but `devenv.exe`. At the end of the day I still think that this meets what people need for a single exe deployment. I am also confident that this will be all that is available when 3.0 drops later this year but I would be surprised if this is the final implementation.
In .net we've been able to make platform specific executables for a while, this improves the story by allowing a platform agnostic single file binary.
So I am not sure what exactly I was thinking earlier. You're right that you would have the original archive and the extracted files. That aside, the design docs include the [plan](https://github.com/dotnet/designs/blob/master/accepted/single-file/staging.md) they intend to take in implementing this functionality. The folks working on this seem to be aware of the fact that this extraction is not ideal. (see Stage 2+)
Do these offer scaffolding?
Yup.
Some of them have scaffolding built in and some have third party libraries for it.
?
Tree shaking is hardly a hack. It‚Äôs removing things your application is not calling. What do you want? A smaller runtime? That‚Äôs a trade off for less functionality out of the box.
Jar requires the jre
The orignal parent comment got probably messed up by autocorrect, there was no mention of jar files
It would be faster for sure but it is also a bit finicky.
As a counter argument - comments are rarely needed in code; meaningful method and class names make 99% of comments redundant. I mostly only use comments to explain severe edge cases or when the codebase integrates with a whacky API
Read Microsoft tutorials!? Absolutely not. They‚Äôre not clean or concise 90% of the time. I would suggest reading Code Review Exchange.
Absolutely disagree because any consumer will still get a compiler warning, it‚Äôs also compiled to the intended type (https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/classes-and-structs/implicitly-typed-local-variables). It‚Äôs a style choice, not laziness. What would bother me more however would be those test names which tell me nothing about what they‚Äôre testing.
Since no one else seems to have picked this up. Unit test classes should mirror the names of the targeted classes You can combine all your tests into one test with TestCases (https://nunit.org/docs/2.5/testCase.html) pass both dates in and the expected result Unit tests themselves should be properly named not just FirstTest, SecondTest etc and follow a uniform pattern (Given_When_Then) e.g. GivenTwoDatesAreSpecified_WhenBusinessDaysBetweenTwoDatesIsCalled_ThenTheExpectedResultIsReturned
Rails and Laravel actually have even more robust scaffolding - just console based
httponly cookie only works if your backend + frontend are on the same domain. If that is the case, just host both on the same domain and you can absolutely share cookies. Dotnet core implements httponly cookies so you can package your vuejs app into a core application and have it work that way. But if its separate, you'll need to use Authorization Code with PKCE instead. If you use the JS library https://github.com/IdentityModel/oidc-client-js, it handles PKCE flow out of the box. Just go through the IS4 docs and implement the appropriate callback pages with the associated scripts needed.
&gt; What do you want? A smaller runtime? That‚Äôs a trade off for less functionality out of the box. yes, that is excatly what is needed, modularity
Oh I read it, did you read mine? I don't care what you think you notice, like I said show me a team world example e g response time for a proper API request that hits a Db &amp; does some work, using JSON.NET vs. new JSON API.
but don't you also need to have .net installed?
Yeah but the language is lacking honestly. No generics and the heavy use of interface{}. C# is better designed.
https://studiostyl.es/ :)
ehm, this was meant was "this is good news, also, java has had this forever"
Strongly disagree. IMO generics are overused and mostly find real use cases in big, monolithic pieces of software. You‚Äôre also ignoring the performance and runtime implications of genetics. To make them performant, c# relies heavily on jit compilation, which can introduce a lot of overhead, especially on low power machines. In distributed systems, if you find you need generics, then maybe Go isn‚Äôt your language. But I‚Äôd argue that if projects like kubernetes aren‚Äôt hampered by the lack of generics, then perhaps you just need to rethink your implementation or invest some time learning a code generation tool. I‚Äôd also disagree pretty hard with the notion that c# is better designed. You‚Äôve got 50+ language keywords to learn in order to be effective, along with a bunch of sugary language features like linq. Go has 24 keywords, and eschews almost all sugary constructs. It may make your code verbose, and maybe it will take a smidge longer to write, but it will be easily readable, even to language beginners. You write code once. It will be read hundreds of times. I work in a .net shop and new developers *struggle* with c#, even the ones with a strong academic background in Java. My team writes Go and I can have a new dev producing solid, performant Go code in like 1/3 of the time. Also, fuck off with the downvotes man. I didn‚Äôt even start by trashing c#. I just pointed out that this feature that java I guess sorta has and that c# now has, was built into Go from the beginning.
Reading comprehension problems, huh?
It's hard to face the truth right ? that's different from biased positive comments right ?
Yeah but that's the issue: I have no clue how to implement authorization+pkce flow.
Dude I didn't downvote you, I didn't even respond to you until now.
Sorry, I just assumed based on the score of my original comment.
From the article: ‚ÄúKeen eyes will notice something about the above screenshot. The file size. It‚Äôs over 70MB! That‚Äôs crazy for an application that does nothing but print Hello World to the screen! This is solved in Preview 6 of .NET Core 3.0 with a feature called IL Linker or Publish trimmer that omits DLL‚Äôs that aren‚Äôt used. But that‚Äôs a whole ‚Äònother post!‚Äù
Just a note, you can distribute a WPF app through the Store as well.
Do the themes work with versions of vs that are newer than 2015?
ASP.Net Core is where Microsoft is putting its development resources, and it's what you should learn, unless you have a legacy application that you can't migrate to .Net Core. Since you already know C#, then what I suggest you learn are foundational web technologies (HTTP, HTML), and Entity Framework Core.
Thank you for reply!! i know HTTP and HTML but i dont know Entity Framework Core, as i understand from your comment i just need to learn Entity Framework Core to begin with [ASP.NET](https://ASP.NET) CORE ?
Or, you know, just use Serilog and Slack for free.
The other way around. If you learn [ASP.NET](https://ASP.NET) Core sooner or later you will come over some topics regarding Entity Framework Core. But they are no must for [ASP.NET](https://ASP.NET) Core. You can start with a simple API which holds it's values just in some variables and later on look into Entity Framework Core and such when you want to persist the data somewhere.
You're full of assumptions. We know how to measure. Saving a millisecond on response time isn't the only factor; lower resource usage, higher throughput, and less GC pauses are all important performance considerations. At peak we have 250k requests per second with deeply nested JSON payloads in both requests and responses. It's a material difference in CPU, RAM and GC. The [asp.net](https://asp.net) core team didn't spend time on this for no reason.
Pretty much, yes. Entity Framework Core isn't technically necessary, but since almost any application you make will hit a database at some point, it's worth investing some time upfront, so you don't have to juggle between its concepts and ASP.Net Core's at the same time.
well done explanation, thank you very much
Thank you ! i was really confused but now i am know how to start now !
Keep in mind Entity Framework is far from the only or the best option to access a database in .Net. It is just the de facto Microsoft provided solution.
C# -&gt; .NET -&gt; ASP.NET Core
yup its like Hibernate in java spring
have a look at a suggested dev roadmap here for other things to go with asp.net core... https://github.com/MoienTajik/AspNetCore-Developer-Roadmap
I work for a medium organization under 1k employees. I did some CRUD but now working on a warehouse management system, which I guess is also mostly CRUD now that I think of it. &amp;#x200B; Ain't the most exciting work but it pays the bills and the environment is mostly chill.
!remindme
**Defaulted to one day.** I will be messaging you on [**2019-06-21 22:15:24 UTC**](http://www.wolframalpha.com/input/?i=2019-06-21 22:15:24 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/dotnet/comments/c31ctt/aspnet_core_learning_prerequisites/ero5j8w/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/dotnet/comments/c31ctt/aspnet_core_learning_prerequisites/ero5j8w/]%0A%0ARemindMe! ) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! ____id____) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
Ok mate. Good luck ü§£
That is the goal. This implementation is just stage 1 or 2 of an 8 stages plan as per the design documents.
Why not just make your MVC `DependencyResolver` explicitly implement `IDisposable`? IIRC, all objects that implement that interface will be disposed after a request ends.
You can filter out specific images from the linker. I assume this goes for this as well.
The overall goal is just that just a bit everything. It's a multi stage project and they are in first half of the implementation stages.
Yeah I get that, they are already doing a lot of good work.
You need to configure both IS4 and oidc client library for that. IS4 configuration is straightforward. https://damienbod.com/2018/04/25/oauth-authentication-with-pkce-for-a-net-core-console-native-application/ covers IS4 setup. On the client side, literally all you need to do is set response_type in the oidc client configuration to regular authorization flow (i.e. code). The library handles the rest. You might be best off going through some blogs on how to setup oidc client on the client side - it's not complex.
Prerequisites are to go for it!!! It's a great framework to build on
Thanks for the suggestion. I actually tried that, but it never gets called. The API DependencyResolver does get called.
Stop. At the top of your controller classes just make private readonly iDependency = new Dependency(); So what if you have to modify 30, 50 or 100 files if you change the implementation to a new library. It‚Äôs still easy. Don‚Äôt add all that complexity to your code base unless it adds REAL business value. Thank me later.
The reason we've gone down this path is to leverage HttpClientFactory. We're using HttpClient heavily (and frankly, probably incorrectly in a number of places) and would like the HttpClientFactory to manage the clients safely. The real business value is application stability by avoiding the pitfalls associated with using HttpClient incorrectly. For context: [https://aspnetmonsters.com/2016/08/2016-08-27-httpclientwrong/](https://aspnetmonsters.com/2016/08/2016-08-27-httpclientwrong/) [https://docs.microsoft.com/en-us/dotnet/standard/microservices-architecture/implement-resilient-applications/use-httpclientfactory-to-implement-resilient-http-requests](https://docs.microsoft.com/en-us/dotnet/standard/microservices-architecture/implement-resilient-applications/use-httpclientfactory-to-implement-resilient-http-requests) Unfortunately it appears the HttpClientFactory depends on Microsoft Dependency Injection. [https://github.com/aspnet/HttpClientFactory/issues/148](https://github.com/aspnet/HttpClientFactory/issues/148) Naturally all paths lead to switching to .NET Core, but we aren't in a position to do that any time soon.
Indeed, if you want to go that extra mile. ^^
Forget about ASP.NET. Go directly to core. As to what constitutes good knowledge... - Understand the thread/concurrency model. Node.js crushed traditional ASP.NET because it manages concurrency in a more efficient way for high load. Understand how Core solved the same problem and is now more performant than Node. - Understand what is on the toolbox for Web Dev, like Razor and what is the current model for working with React, Vue.. Node has universal Javascript and most of the modern Web tools are in Node, so understsnd what is the current accepted approach for interacting with Node. - Understand how to build APIs and how to handle authentication. - Understand Entity Framework. - Understand file IO. - Understand how to actually deploy your application to production. Create a very simple app end to end. I mean. Do everything, from styling, to database and deployment. If you finish it, everything by yourself, you will be ahead of 90% of people. For example, I have 12 years of development experience and I wanted to learn next.js and Apollo and I built remoted.io (open source) from scratch and I learned a ton. There is no tutorial that bears building something and deploying. After this point, you should be good to go. If you get a job, you will learn that you need to learn other stuff but then you do that on the job itself because every job has their own stack and specificities.
Thank you, really great explanation
Yup i will go ahead
That helped me alot, thank you
Hello, Sorry for the delay in my answer, I guess we aren't on the same continent. My current setup looks like this : -I have a login page that takes the username/password and uses those to call "IdentityServer/connect/token", and once I've got that token I call "IdentityServer/connect/userInfo", since I need those. If I use the authentication flow with PKCE, my understanding is : --Oidc-Client.js calls "IdentityServer/connect/authorize" --If user is not connected, a frontpage from IdentityServer is shown asking the user to connect (?) --Once he is connected, a frontpage from IdentityServer is shown to ask permission to access data (?) --Once user has granted authorization, he is redirected to VueJs front, which is then allowed to access data thanks to a "code" instead of a token (My take is that code is a cookie) (?) Am I right ?
I am in the same situation like you. Just go for .net core don't worry about asp.net mvc 70 percent concepts are same .after like 3 or 4 asp.net mvc will be dead. Right know everyone is learning core
Maybe an alternative? [https://github.com/uhaciogullari/HttpClientFactoryLite](https://github.com/uhaciogullari/HttpClientFactoryLite)
Working in retail. Cloud/omni channel solutions. Which includes: - POS. On premise and browser products. - Client web portals. - Support tools. - APIs for integrators. REST and SOAP. - ETLs. Analysis server. - Reports. - People counter integrations. - Payment provider integrations. - Finance integrations. - Insurance integrations. All of which are in various states across multiple products across multiple platforms. Some are IIS hosted. Some are using Docker.
I've spent the last couple of years maintaining a number of corporate WPF applications with a messy codebase that has been crying out for a rewrite, and I've just been able to get approval to start looking into migrating them to .Net Core 3.0 so I'm currently using the opportunity to restructure things and throw away some of the legacy convolution that has been plaguing me. It's starting to come together, and it's weirdly exciting to know how much simpler to maintain everything is going to be in the future once I'm done. Actually enjoying my job for the first time in a while!
yes
Correct.
Thanks for this - I'll check it out.
I was just looking into this myself at work. We need more consistent an reliable Http clients in older .NET 4.7 projects. I've only created a proof of concept so far, so you'll need to verify this yourself, but... If you're only doing this for IHttpClientFactory, I belive you can just do: ``` var services = new ServiceCollection(); services.AddHttpClient(); // add more configuration here as needed... var provider = services.BuildServiceProvider(); var httpClientFactory = provider.Resolve&lt;IHttpClientFactory&gt;(); ``` Then just use `httpClientFactory` as a singleton, register it with another container, etc.
in this thread: lots of people who don't know what they're talking about.
"We have a small team, lots of revenue, but don't want to pay other companies for their time and effort." sounds about everything wrong with the software world.
I'm a pretty big .net fan these days, and at first I liked this feature - but after using it further, I'm really not a fan: - It extracts to `%LocalAppData%/Temp/.net/&lt;some random... I guess hash&gt;/` - The working directory is weird. I print out `Environment.CurrentDirectory` and it gives me the path to where I ran the app. eg: `C:\myapp\`. But, if I use `Microsoft.Extensions.Configuration` to load a json config, I get a `FileNotFoundException : The configuration file 'appconfig.json' was not found in &lt;that temporary path for the extracted app&gt;` - Not to mention that after a few builds of this, I have &gt; 550MB of this one application in that temporary folder. To me, this seems too... hidden? This really seems like a somewhat bad hack rather than a solid solution.
Coravel supports true async I/O out of the box without having to jump through hoops like mentioned in [this article](https://andrewlock.net/creating-a-quartz-net-hosted-service-with-asp-net-core/). It's much simpler, ties into .NET Core's DI very simply. I think [the concept of invocables](https://docs.coravel.net/Invocables/) is just plain, straightforward and easy to use. By default, all scheduled tasks use one async thread (so it won't destroy your web app if you are using it within a web app.) Otherwise, in a console app that's dedicated to running scheduled tasks, [you can choose which tasks get their own async thread.](https://docs.coravel.net/Scheduler/#schedule-workers) Since Coravel [comes with an event broadcasting mechanism](https://docs.coravel.net/Events/) too, you can also do stuff like emitting an event on a schedule for more complex scenarios, which can keep them much more clean/maintainable. That's a few that I can think of off the top of my head üôÇ
Yes you can, there's a [sample for that scenario here](https://github.com/jamesmh/coravel/tree/master/Samples/EFCoreSample)
In our environment we are just support services so we are not generating any of the revenue directly. Although our software makes the organization run more efficiently. Unfortunately we are viewed at as a commodity rather than necessity.
In our environment we are just support services so we are not generating any of the revenue directly. Although our software makes the organization run more efficiently. Unfortunately we are viewed at as a commodity rather than necessity.
I read that article about using httpClient wrong before. We changed our code to use static instance of it and haven't had any issues. Just use a static instance of httpClient in your .net framework code and you should be fine.
I don't use a native login screen on my front end app. The whole point of a IDP is to offload your login / logout process to your IDP (i.e. IS4). This also has the advantage of SSO because once you log into identity server, a cookie will be issued to your browser. This can be used for silent renew of tokens for SPAs and in server side apps. In JS, a cookie is not returned, instead a JWT is returned. Oidc-client.js stores the users token in session storage by default. As for your config, it looks correct. I don't have experience with calling individual token endpoints for signing user in. I instead navigate the user to the IDP login page, where the user signs in, and the IDP then navigates the user back (this is why you have redirectUri / postlogoutredirecturi configured for your backend client). The oidc-client library has a service called OpenIdConnectService which has a method called triggerSignIn(). This takes the configuration you provider to the library, redirects the user to the IDP, with all the relevant headers/query string params, and then redirects user back after signin. The same applies for signout, which has a method called triggerSignOut(). It just does the opposite of signin.
This is nice
Rider lightweight? Yeah right... It's a good IDE for sure, but calling it lightweight next to VS Code is... Strange.
I thought I saw something, maybe with git, where a -- option after a - option was a sub-setting for the - option. eg "-a --b" vs "-a -b"
Why would you want a cross platform ide? Don't see Manny developers changing OS all the time.
What can you do with this? Is it like az data lake?
You can specify the properties of your viewmodel in the link with [asp-route-{value}](https://docs.microsoft.com/en-us/aspnet/core/mvc/views/tag-helpers/built-in/anchor-tag-helper?view=aspnetcore-2.2) Let's say your viewmodel has two properties: `name` and `id` and you would like to pass them on to the next page. Your link would look like: &lt;a asp-controller="HomeController" asp-action="DoThis" asp-route-id="@Model.Id" asp-route-name="@Model.Name"&gt;your link&lt;/a&gt; Please note though that any data you pass in the url is viewable by the user and can be changed to the user. So make you sure you validate all user input.
[removed]
[removed]
It's light weight compared to Visual Studio.
Apache Spark is a data processing library and framework (among many others) and has the biggest community. It's written in Java so you had to use JVM languages to interact and program with it so far. This project is a way to create language bindings so you can run Spark using idiomatic C# code.
Alternatively his razor page could have a form and POST to the controller action.
&gt; Please note though that any data you pass in the url is viewable by the user and can be changed by the user. So make you sure you validate all user input. **Always** assume that **any** data sent from the client is visible and modifiable by the user, no matter where it comes from (url, query, header, body).
[learnrazorpages](https://www.learnrazorpages.com/)
Take a look at identity server 4 and aspnet identity. They work together and you can customize the data you want to store. The drop down you can drive by claims or roles coming from identity server.
This
Very nice. Thank you.
Biggest complaint I keep seeing is initial load times and IE 11 problems. Is that accurate?
[Here is the page for pricing](https://azure.microsoft.com/en-us/pricing/details/functions/). It seems to be based on execution time and total executions. Looks like the premium plan gets into memory. I suspect its a fixed size and if you have a lot to load it will increase the execution time and thus the price. If speed is critical you will want the premium plan.
If the 3 in house apps are hosted in different locations and operate independently you could look into creating a fourth app that just authenticates the users, generates a randomized crypto token with the user's info and pass that to the application, which then would decrypt the token and authenticate the user internally without intervention
I second this extension. I use it on every computer that I install visual studio. The only thing I don't like about it is that it has some lag but I typically don't change my theme once I have it the way I like it (I prefer to having one with dark mode with green instead of blue. I don't recommend using the Green Shah one that they have in the the gallery, unless you like having your current line in the text editor highlighted in a bright white.) [Here's the link to it on the market place btw](https://marketplace.visualstudio.com/items?itemName=VisualStudioPlatformTeam.VisualStudio2019ColorThemeEditor)
Oh cool, I never saw this site before. Question - do these styles only adjust the text editor or do they cover the rest of the IDE?
If there were a separate website for each domain, really users could be directed to each separate domain site and then if you use an OpenID Connect / OAuth 2.0 implementation (like IdentityServer), you could have each one set its own redirect url and each would have its own clientID that can be used to generate a separate access token that only works for that domain.
The only thing too many dependencies would slow down is start up time realistically. There are some fairly simple ways around this if you're interested. As for converting a Web API, I'd usually recommend against it personally. Functions have got better recently but without the support of middleware and easy to use authentication, you'll end up banging your head against a brick wall. And that's not to say I don't like Functions, I think they're fantastic. Just not for building a fully fledged API. If you're API is really simple, say a few endpoints, you might get away it. I really wouldn't worry about cost, especially on a consumption plan. They are ridiculously cheap, and you can always move it to a paid app service plan.
What use cases would you use functions for then if not for a website backend? To be clear, what I'd like to do is use it to host a graphql endpoint which would access an azure database. Eventually I'd need authentication. Are you saying that's difficult to do?
@ricardomelogon how will you handle the browser history with this approach, since the token will be passed in the query parameters and it will be logged in the browser history?, so if anyone checks the history he will find the token.
Functions should be stateless. You don't really things that have a lot of startup cost. We use aws lambda to create tax calculator
Check this article from Auth0, it really helps [https://auth0.com/blog/what-is-and-how-does-single-sign-on-work/](https://auth0.com/blog/what-is-and-how-does-single-sign-on-work/)
If it's just a GraphQL endpoint, that could work as there is only one endpoint to model, and probably one of the better uses. For authentication, it's not difficult to do, it's just harder to share between each function, which is usually what Middleware does. It can done with some playing around but it's nowhere near as easy to use as WebAPI. https://www.ben-morris.com/custom-token-authentication-in-azure-functions-using-bindings/ This is an example of someone who has done some custom token authentication which could be bound to each function. --- For your first question though, I use them for basically everything that isn't a web front end. I did an internal email api recently which heavily used Azure functions. Essentially a request would be to a Web API, which would do upfront model validation and then put the message onto queues This would then be picked up by multiple Azure functions chained between different queues to do things like splitting the batch of emails into singles, saving some information to a reporting database, sending the email etc. https://docs.microsoft.com/en-us/dotnet/standard/serverless-architecture/serverless-design-examples These should give you some more in depth examples. You may notice they do talk about functions as APIs however usually with the caveat you have something sitting in front of them. Usually this would be API Management. https://azure.microsoft.com/en-gb/services/api-management/ Given this now also has a consumption plan, it might be something to look into. Without knowing whether the API you're building is purely internal for example, it's hard to be specific.
Read up on Durable Azure Functions. They don't have to be stateless anymore.
Thanks for pointing out that. I will read up about that
I was a developer at msft for a few years and interacted with developers that worked extensively with Azure functions to improve the product and provide feedback to the product group. Azure functions have seen improvement from the release of v2. And I believe they‚Äôve released durable functions which are essentially functions with state. Azure functions are not meant to host a monolithic application or host any long running processes. It‚Äôs meant for short snippets of code that might do some small amount of work like persist data to some storage, call an api endpoint, execute code on a timer, etc. If you try to jam a bunch of packages and long running code then your functions will start timing out. The timeout limit can be configured as an option although I can‚Äôt recall exactly what that limit is. Some scenarios I‚Äôve seen in production are syncing data between 2 storage accounts, pushing data to a queue to be picked up by another service, pushing data to a message bus to be picked up by yet another function listening on that message bus. definitely take a look at the docs, they‚Äôll be helpful!
There are two types of blazor, web assembly blazor and server side blazor (signalr). The server side blazor works wherever SignalR works.
Rob, I created this extension derived from my [previous attempt](https://marketplace.visualstudio.com/items?itemName=dmitry-pavlov.OpenAPIConnectedService) ([post](https://medium.com/@dmitry.pavlov/how-to-add-generated-httpclient-to-asp-net-core-dependency-injection-right-way-fec21b3385f1) about that tool) and you can find the sample of generated C# code for PetStore API [here](https://github.com/dmitry-pavlov/openapi-connected-service/tree/master/docs/samples/Samples.AspNetCoreMvc.ClientInjectedToStartup/Connected%20Services/PetStore).
Thanks this is helpful. Although, it does list my use case as an example of uses. https://docs.microsoft.com/en-us/dotnet/standard/serverless-architecture/serverless-design-examples#web-apps-and-apis However, given what you've said... It actually seems quite limiting. Is there really any point in using azure functions as a backend when I could just use webapi hosted on an app service?
So what does it mean for it to be stateless? Isn't that the same thing in respect to a call to an webapi app? Is it just like a webapi app except you can't use the session state?
Good luck to you
&gt; Is there really any point in using azure functions as a backend when I could just use webapi hosted on an app service? There are a few benefits: * Cost - Azure Functions can be much cheaper, especially under low levels of loads. * Ease of use - For simple use cases where you have just one or two endpoints, they have less overhead. So in your case where you have just the one endpoint, that's a really good use case. * Scalability (on consumption) - Functions on consumption plans can scale pretty rapidly For you it really depends on how many end points you are planning on having and whether the benefits outway the cons. It might be worth you just trying the code out as a function and see how you get on, any code you write should be fairly simple to port over to an API if you find it's becoming a mess. Alternatively if you have lots of endpoints then you could introduce API Management as a layer on top of your endpoints. TL;DR, if you're going to have lots of endpoints, I'd just bite the bullet with a full API. If you don't know, or don't think you're going to have a lot of endpoints, give functions a go. There's no harm in trying and migrating. The beauty of the cloud is that you're basically not locked into anything.
I think it is 5 minutes default configurable up to 10. You can host Az Functions yourself. In that case the timeout can be even longer
Thanks I'll definitely give it a go as I'm building a proof on concept. However I think measuring complexity by end points is probably not a great idea. I mean sure I have one endpoint for graphql but for that one endpoint, I'm going to need a ef core project with defined classes that map to my database and I'm going to need resolvers to define what data to return to my graphql queries. And this before I need to write any custom business rules specific to my application.
The only reason I'm using endpoints as a measure is that every thing you'd usually stick in middleware has to be duplicated across every function. EF Core might not be so bad now because you have proper DI support in functions, so you can just inject your contexts and it won't be much of a problem. Been a while since I've done EF though so can't really be much more help there!
&gt; What use cases would you use functions for then if not for a website backend? Azure Functions are a poor choice for web endpoints, and they're an awesome choice for event based architectures. You can just scale the amount of running functions based on the amount of events in the queue, so all events get handled ASAP.
Started new open source project for that with a bit different approach. So yes, I am going to support Rider as well. https://github.com/dmitry-pavlov/api-client-generation-tools - feel free to support the project - note lovely üß° [Support] button on my GitHub repo.
Client id and client secret are as good as a refresh token as long as they are stored as configuration of your server and never get published to your end user. Also with a refresh token you still have to handle a possible 401 response so no actual difference there. Just have something like Polly (https://github.com/App-vNext/Polly) handle the retry or roll your own solution.
Generally I would say most things can be done with them but they are sandboxes which do provide limitations. I found some libaries which convert PDF to images that use Windows GUI options and they doesn't exist in azure functions. But most the time they can do anything
In Oauth2 when you get a token you also get an expires_in field that gives you the token lifetime in seconds. Simply adding it to DateTime.Now will give you the expiration time. Once you're past that time (with a bit of spare seconds just in case) you can refresh the token before making your request.
To get a refresh token you may need to request the offline_access scope. Though that is more useful with other types of authentication (eg. when you need to supply username / password too). &gt; Is there a way to automate this process by using some in memory data and not relying on 401 response to check if my token has expired? There is probably an expiration of some sort of expiration returned with the token request. I use IdentityModel and it has `ExpiresIn` in the [token response](https://github.com/IdentityModel/IdentityModel/blob/master/src/Client/Messages/TokenResponse.cs), which you can convert to a DateTime with something like `DateTime.UtcNow + TimeSpan.FromSeconds(response.ExpiresIn)`. Then at the top of all my client's methods I call a function that checks the expiration and triggers a refresh automatically.
They are building it in 5 stages, as of right now they have only built stage 1 which is nothing more than a pack and extract, stage 2 will link all .Net core into the binary but require native binaries to be extracted by the final stage which wont be until after core 3.0 is released it should ideally statically link everything. The design document on github explains it all
Don‚Äôt roll your own for this, use off the shelf proven technology. For example IdentityServer OpenID Connect will do almost exactly this, but with all hard things taken care of (crypto, replay protection etc) https://identityserver.io
You can just get an app service plan
static httpClients do not handle DNS changes. So it works 99% of time, but not every time.
The way we do this is we have a cache of tokens and in a background job check every x seconds for tokens that will expire soon and request a new one.
Not bad. We do it with a special HttpMessageHandler that intercepts all requests, and gets a new token at need before letting the request through.
I have something in mind along the lines I i mentioned in my post. I'll post the solution here when I complete it(hopefully). Btw I use IdentityModel as well. Built in class for Authentication Token has proven useless for me as the only properties it has are Name and Value.
I'm talking about client side. I keep hearing client side blazor is slow to initially load, and it has problems in IE 11.
You use a system with a expiration date on the token. Like putting the date in it and checking it on the other side.
Yes, it's always a great idea to use proven implementations of a strategy
&gt; Is there really any point in using azure functions as a backend when I could just use webapi hosted on an app service? IMO, not really. I'm with u/AngularBeginner on this one, app services or containers for APIs, functions for events.
That was my idea as well but how do you access your Token info at runtime? Cache perhaps? I had an idea to override HttpRequestMessages's SendAsync() method in my custom handler class but how would I access my Token info? tnx
If you get your token from there, shouldn't you have the token info at hand anyway? Keep it as a member...
Yup, UWP is great if you can self-contain everything it needs to do or interface with the web. As soon as you need to interact with the rest of the computer, it becomes such a pain in the neck that it‚Äôs easier to just scrap it all and start again in WPF.
Seems like there is a simple solution for that https://byterot.blogspot.com/2016/07/singleton-httpclient-dns.html?m=1 Also I didn‚Äôt say Singleton, but either way you do not need to add all the complexity that OP is introducing to a code base, there are simpler / easier solutions. We use the HttpClient all the time, we integrate with around 30 different vendors and they are all done via httpClient and I‚Äôm not having any issues. We are using .Net 4.7. Granted we don‚Äôt do micro services but IDK, I just thought the original idea was to much complexity to fix an issue I haven‚Äôt even experienced.
You‚Äôll need to add Code Analyzers nuget package (or whatever static analyzers you want to use). You‚Äôre able to check in a .ruleset into source control if you use Microsoft‚Äôs code analyzers. You can find out more [here](https://docs.microsoft.com/en-us/visualstudio/code-quality/analyzer-rule-sets?view=vs-2019)
Does that need to be installed for each project in the solution?
I believe so (mine are)
3 is what I'd use if you are serving a website, but it sounds like this is just a console app or library. You can just hold on to your token and check it prior to every request. if (aboutToExpire()) { this.token = GetNewToken(); this.httpClient.SetBearerToken(token);} // httpclient request...
I use them for webhooks, sending emails and system integrations
I guess that would do but I'm creating a single page MVC app and I want to learn best practices going forward. I'm currently trying to save IdentityModel's TokenResponse object with In-memory cache and use it in my custom HttpRequestMessage handler, trying to recreate a bit of what I mentioned in 3). Think this is a good route for now?
https://caniuse.com/#feat=wasm IE11 doesn't support Web Assembly
I keep mine in a sqlite cache
On my team, we do it in a .targets file (both adding PackageRegerences and .ruleset files), which we import in Directory.Build.targets (or .props, can't remember offhand but either works). Throw that in your source root and bam! All projects adhere to the same rules.
Your assessment is accurate. I understand if you're running UWP on an XBox all the sandboxing, but I get the feeling they'll run UWP into the ground and then send it off into the sunset before they loosen the strings on it. The security aspect is important, but at some point, if the user gives you permission you should be able to do some of these things (without a huge headache and or 20 steps or hacky workarounds). These are the reasons people don't write programs for it and the Windows store is a waste land. What they're doing isn't working.
Even i really like ef core, but orm in .net world always felt like lagging behind other frameworks, where it gets some feature others had for years! Don't forget that it took Microsoft many years and attempts before they built/designed EF Core, and i would even say that all those iterations where copies of some other framework (javas hibernate). Old EF was usable only in ver6, and versions 1-4 were almost a joke. And before that, Microsoft ideas of data access layer were DataSet and DataTable, and helper classes from pattern and practices application blocks.
For a SPA app you have a UI and thus a user. You should probably be using authorization code flow w/ refresh token. Look up OIDC authorization code flow. Here's a brief overview of Oauth2 and OIDC: https://medium.com/@robert.broeckelmann/when-to-use-which-oauth2-grants-and-oidc-flows-ec6a5c00d864
I'm not aware of one, seems most people copypasta from SSMS. Autocompleting SQL is a bit tricky to do usefully without inspecting the schema. An alternative might be to embed .sql text files into your solution and use another (better) editor to actually work on them.
A lot of freelance projects are unfortunately prototypes or "throwaway" simply because that's what the market will pay. You might find dotnet to be a little rigorous for that kind of work. Something like node or python might be more cost effective. That said, it's a great language and if you're proficient then that can offset a lot in terms of theoretical productivity.
Aren't Brave extensions written the same as Chrome extensions? If so, then that's primarily r/JavaScript.
Thanks, I already went through all Oauth2 and OIDC documentation but I need to create this simple app that gets data from amadeus and pulls data from one table from wikipedia, enabling just a *userless* experience for searching for the cheapest flights, if I can call it that.. It's for a job interview, and creating authorization flow wasn't mentioned. To be honest I think I'd already long past this point if it really *did* require OIDC because I've spent couple days implementing oidc solutions before I fully grasped what the hell is going on LMAO. After all, this is my first time encountering getting data from API, working with any type of authentication besides forms authentication and working with .NET Core after I did MVC in framework for couple of months. Oh all the concepts I had to learn in a past week! Gotta admit I had days when I wanted to quit but I think I've steadied the ship. Cheers
I'm really asking how much ASP.Net is there likely to be out there which is relevant to solo freelancers. Obviously not as much as PHP but I wonder if it's a relevant technology outside of working in a team.
Let‚Äôs say you personally work on a linux machine but have a day job where you‚Äôre working on a windows machine. Being able to switch between the two is very convenient. Source: me
I mainly use Windows with visual studio. But I like to play with Linux with Rider and VS Code. I can't see why it's important to use exactly the same tool on each OS.
I think ReSharper does this now? But I don't generally use SQL in C# so I'm not 100% sure.
I think it can be, but only on api services or larger projects
Personally I spend a lot of time customizing my editor for my workflow. I‚Äôve used Webstorm for a long time so I have my workspace, file watchers, color scheme and shortcut knowledge down to a science. I‚Äôm very efficient when I use Jetbrains products. When they released Rider it was a miracle for me. I can work quickly in visual studio but it‚Äôs not the same. Being able to use the same tool with the same look, feel and shortcuts is very important for me. I use Rider for all of my web projects. Which is primarily .Net and Node. I use vscode for all notes and quick edits or if I need to paste a quickie snippet to review. Being able to transfer my knowledge of the editor to any language or platform is huge and efficient.
So not your typical small/medium-sized business with no tech staff? That's a typical punt for PHP so does ASP.Net not compete in this market segment?
So not your typical small/medium-sized business with no tech staff? That's a typical punt for PHP so does ASP.Net not compete in this market segment?
At our projects we are using sql files, which are attached to project as file resources. With this approach we have syntax highlight and even some sort of intellisence if we are using ms sql database. So the main approach is like this: - create .sql file within you project - add some code - add file to project resourced through project menu (if you are using visual studio) - use your sql file as string with Resources.your_script_file_name .
fuck you, you stupid ass
Well I've done it for the last decade so 'pretty good' (remote, self employed) ? However as a freelancer maximising your value is always a positive thing. I'd ensure I also had a good level of JS knowledge as a lot of apps now have relatively 'fat' client side pieces too.
I‚Äôd suggest adding a sql project to your solution and moving your sql into stored procedures. Having inline sql makes it easy to accidentally open your application up to sql injection attacks and while stored procedures don‚Äôt provide complete protection they do make it a bit harder to screw up.
Azure functions are incredibly cheap though. The cost is pretty much nothing. I was calling them a few times a second, and over the course of a month the bill was like $50. Application insights does get expensive, but that's optional.
When starting out with an application, start with a monolith. Just make a single API. Microservices increase the complexity and you should only use them if the monolith is getting unwieldy, like there's a very large team working on it.
Are you sure you need someting that complex? Maybe something as simple as this could work? IQueryable query = context.Cars; if (uiOption.HasWheels) { query.Where(car =&gt; car.Wheels.Any()); } if (!string.IsNullOrEmpty(uiOption.Color)) { query.Where(car =&gt; car.Color == uiOption.Color); } var result = query.ToList(); Maybe I'm completely missing the issue here. Could you provide some code snippets to elaborate?
In my particular case the car.Color is optional as well but perhaps my whole approach is wrong? Let me start at the beginning. I have code that builds a SQL query based on items that a user selects from a UI. &amp;#x200B; Lets continue the car example. The user selects the car query and returns Car name,color,Engine Type, and manufacture date. Perhaps the user only intended to look at Car Name and color but decides later to also look at names and mfg dates. Also, maybe they want to count some of the cars and filter data after the initial query. My grand idea with this is that we pull possible items from the database and if the user decides to look at something else in addition to what they originally needed they don't have to go back to the database to collect the extra info. It just needs to be processed slightly differently. In comes Linq. var query = Worktable.AsEnumerable().AsQueryable().Where(b =&gt; b.Field&lt;string&gt;("Date").Contains(datestr)) .Where(a =&gt; a.Field&lt;string&gt;("Name").Contains(sgs)) .GroupBy(a =&gt; new { Date = a.Field&lt;string&gt;("Date"), Interval = a.Field&lt;string&gt;("Interval"), }) .Select(b =&gt; new { Date = [b.Key.Date](https://b.Key.Date), Interval = b.Key.Interval, Children = b.ToList() }); // foreach (var c in query) // { // newtbl.Rows.Add([c.Date](https://c.Date), c.Interval, c.Children.AsEnumerable().Select(a =&gt; a.Field&lt;int&gt;("callsoffered")).Sum(), c.Children.AsEnumerable().Select(a =&gt; a.Field&lt;int&gt;("anstime")).Sum() / c.Children.AsEnumerable().Select(a =&gt; a.Field&lt;int&gt;("ACDCalls")).Sum()); // } &amp;#x200B; The above linq query works perfectly but if I want to implement this kind of flexibility to rework the data then I would need to have several different queries and make a decision on which query I want to run. I believe that the expression trees will get me a lot further down the path but I am having a REALLY hard time figuring this out! &amp;#x200B; Thanks for the reply and I hope this answers your questions.
You may want to look up expression trees. [See also this](http://www.albahari.com/nutshell/predicatebuilder.aspx).
&gt; Having inline sql makes it easy to accidentally open your application up to sql injection attacks No it doesn't. Modern C# (and Dapper in particular) have plenty of SQLi protections that are easier to use than the traditional, vulnerable, concat-ing strings and vars together. There are other options like storing SQL in resources, which offers read-only access at runtime and has the advantage of being version controlled alongside the code that calls it.
Probably why I do not find a ton of simple written examples out there that. The fun part is that I will need to do this for the select and group by portions of the query too. &amp;#x200B; All of this could be avoided but I can't afford to hit the database every time someone wants to see data for column 2 if they only selected column 1. There could be dozens of users doing this all at once and it would be HORRIBLE on our database :D
Okay, so I think I understand but still might be off. Let's try again. I will be basing it off your code. // first bit, set up initial query with common query parameters var query = Worktable .AsEnumerable() .AsQueryable() .Where(row =&gt; row.Field&lt;string&gt;("Date").Contains(datestr) &amp;&amp; row.Field&lt;string&gt;("Name").Contains(sgs)); // middle bit, optional parameters here if (!string.IsNullOrEmpty(uiOption.Color)) { query.Where(car =&gt; car.Color == uiOption.Color); } // wheels, // doors, // engine size, // etc. // last bit, run query query = query .GroupBy(group =&gt; new { Date = group.Field&lt;string&gt;("Date"), Interval = group.Field&lt;string&gt;("Interval"), }) .Select(group =&gt; new { Date = group.Key.Date, Interval = group.Key.Interval, Children = group }) .ToList(); In this scenario you can do your custom query with optional parameters in the middle bit, but if you want to return different kinds data I guess you could do the same for the .Select in the last bit as I do for the .Where's in the middle bit. Or just return all data and filter it in the GUI.
Why are you calling AsEnumerable and AsQueryable in the same query ?
Honestly it seemed that sometimes I wasn't able to use a particular function w/o the asqueryable in there but I have been trying a lot of different things to make this work and I think I just left it in there. :/
ok! this is making more sense. Add portions to the query from each UI piece if it's present. That is quite easy to understand and apply to my particular metrics. The select and groupings can also be fairly fluid though. In my simple build there can possibly be four groupings. (for context) Date, Interval, ACDName, and Skill How do i apply that same logic to the select and group by?
Jetbrains Rider does this.
The linq method syntax/lambda is chainable. So you'd do exactly the same thing I did in the middle bit, but with groupby and/ or select instead. So from the above example you'd replace this: // last bit, run query query = query .GroupBy(group =&gt; new { Date = group.Field&lt;string&gt;("Date"), Interval = group.Field&lt;string&gt;("Interval"), }) .Select(group =&gt; new { Date = group.Key.Date, Interval = group.Key.Interval, Children = group }) .ToList(); with something like this: // not the middle bit but also not last bit if (something) { query = query.GroupBy(group =&gt; new { Date = group.Field&lt;string&gt;("Date"), Interval = group.Field&lt;string&gt;("Interval"), }); } if (somethingOrSomethingElse) { query = query.Select(group =&gt; new { Date = group.Key.Date, Interval = group.Key.Interval, Children = group }); } // etc. // last bit, run query query = query.ToList();
No, pretty slim pickings. But when the client doesn't have a technology preference, then you could give them the site built with ASP.NET MVC Core and hosted on Linux. ASP.NET/ASP.NET MVC is more popular in government.
Ok. It is my worst nightmare. I am going to HAVE to learn the lambda. This particular tool is going to have an option to pull data from several different tables with potentially dozens of columns. This hurts my head thinking about doing it this way. &amp;#x200B; I wanted the users to have the flexibility to refactor the data without going back to the database because some of our tables take quite a bit of time to get data from. &amp;#x200B; I really appreciate you taking the time to work that out for me. Thank you!
Just imagine it's a SQL query and you pretty much have a handle on it for the most part. Also it helps to remember that you can keep building the query for as long as you want until it is executed, which normally happens with a To list, or other To*.
Brave is built on chrome. Same documentation.
Directory.Build.props and a recent version of visual studio (&gt;=15.3 I think) is what you'll want to use. That way you can define global packagereferences for projects in the folder and below.
FYI you‚Äôre still ToListing() the original query instance, you need to do query = query.Where(...)
Agreed. Dapper has great options for parameterization. You can even pass parameters into TVFs with dapper.
I don‚Äôt disagree, but a SQL project in VS would still sit right beside your code in version control. You also get schema-aware intellisense, and DACPAC deployments are light years ahead of the ‚Äúold‚Äù way of deploying changes to databases. Inline SQL isn‚Äôt wrong or bad by any means, though. Especially if you don‚Äôt own the DB you are working with. I tend to use SQL projects for greenfield work and inline SQL when working with existing, shared databases.
You are right, of course. I did notice and fixed it in the proceeding examples :)
Ha, awesome. It‚Äôs pseudocode anyways just wanted to make sure the guy asking for help knew :)
Have you looked at dynamic link queries?
The difference between the two is *very* important. When you‚Äôre working with an `IQueryable`, you‚Äôre composing expressions that will be translated into a SQL query and executed on the database. If you allow the method cabin to decay to an `IEnumerable` (or explicitly call a method like `ToList()` or `AsEnumerable()`) then the SQL call will be executed at that point, and any following calls will be executed in memory. You really have to be aware of this if you want to write performant LINQ queries with EF. You‚Äôll almost never see performance issues running locally no matter what you write (local db, single user, small amounts of data) but bad queries will quickly fall apart when faced with production amounts of traffic and data.
Man, thank you for the great explanation. Right now all of the sql queries are handled separately. Only local datatables are exposed to the linq business and my attempts to format the data.
I have been tinkering with a dynamic query but Im having a really hard time getting the data out of the dynamicClass that is getting created. I can SEE the bits i want but i cant touch it! Very annoying.
I've been using Dapper for the first time at my current contract and man it seems like I'm reinventing entity framework. What is the appeal? I don't get it.
preference of sql over learning a new tool. sql can do more than entity framework. and the raw speed. not everything can me mapped in entity framework for real world scenarios.
I'm curious, where is this big performance overhead of generics? It might actually help a lot to avoid boxing. Overused? It's a tool/feature, and as such can be overused, but that doesn't mean it can't be highly efficient when used properly. It also gives you a lot of design time help and strong typing.
IMHO the best way to handle SQL queries in dapper is to have a separate SSDT database project with stored procedures and functions. Then execute procedures/functions in dapper. This gives you full intellisense support, syntax and schema errors at design/build time and of course a code base like that is much more manageable than SQL files in class libraries or, the worst case, keeping raw SQL queries in strings.
About not being simple as go. Well, you can use it "dumbed" down but you can also use it with features not present in go. But if you have developers that struggle with it, then go with go out whatever they are familiar with. I fail to understand why anyone would struggle with a language (well designed as c# is) though. Libraries might take a bit longer to learn, true.
Maybe this will get downvoted but, vs code. I use it on my MacBook at home, windows laptop at work and use it from time to time on Linux VMs. It‚Äôs nice to have all the VS and rider bells and whistles but for the past few months have actively tried to just use vs code for all my .net core development and it works really well. The only thing I miss is ef core power tools, but that‚Äôs really a convenience thing I suppose.
What‚Äôs Fb2?
I think this: https://en.wikipedia.org/wiki/FictionBook Which sounds like a terrible ebook format.
**FictionBook** FictionBook is an open XML-based e-book format which originated and gained popularity in Russia. FictionBook files have the .fb2 filename extension. Some readers also support ZIP-compressed FictionBook files (.fb2.zip or .fbz) The FictionBook format does not specify the appearance of a document; instead, it describes its structure. For example, there are special tags for epigraphs, verses and quotations. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/dotnet/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
Well, not that terrible. It's XML under the hood, so it\`s relatively easy to work with. Epub, instead, is an archive file format, with lots of smaller files inside, for images, text parts etc. So, imho, fb2 is good enough to use it)
Hey, the videos aren't downloading, do you have any alternative?
I‚Äôm not sure I understand? Dynamic class? You can see bits?
What is returned by the dynamic linq comes back as a dynamicclass1 and cannot be iterated through with a normal foreach. What you see when you do is something like "Date=6/15/2019,calls=15000" when you iterate it and only lets you tostring it. I will post a screenshot and my query later if you are interested
This is how my co-workers do it. Seems to work. static void Main() { try { ... } finally {} }
Why would you want to swallow some critical, application crashing error?
r/woooosh
top tips from me.. \- handle exceptions when you need to, and not 'cos you \*think\* you should \- bubble them up as much as possible, so you don't repeat yourself \- never catch simply \`Exception\`, unless ofc you are trying to work out what type of \`Exception\` an exception is ;) \- be specific with the type you **are** wanting to handle. \- don't swallow things - better to leave them unhandled!!
My first job had a guy named Klophaus, who was famous for empty catch blocks. We called it a Klopblock. He was also famous for the Klopstar, which was a `SELECT * FROM ...` in a stored procedure backing a TableAdapter. If the columns ever changed, the TableAdapter threw its hands up. But you wouldn't know that, because it was wrapped in a Klopblock. :D
At my job we have plenty of times where we swallow exceptions (in addition to logging the exception), but they are related to critical sections where the operation we're doing is allowed to fail (such as a caching operation failing).
I'm not sure I understand your meaning. The documentation you linked to even suggests using a single instance of HttpClient for the entire application and that SendAsync is 100% thread safe to use. If he is using SendAsync 100 times at the same time in parallel no race conditions will occur within HttpClient itself, it will happily handle all 100 requests.
Suggests, but it apparently doesn't work :-)
This is a premature optimization that will just make an already confused developer even more confused on what is going wrong. 99% of the time you should not be programming async code with threads in mind. The HttpClient [documentation](https://docs.microsoft.com/en-us/dotnet/api/system.net.http.httpclient?view=netframework-4.8) even advises a single HttpClient per application, in addition to declaring SendAsync thread-safe.
Really? I'd love to see your source on why the recommended and documented single instance pattern for HttpClient doesn't work. I run a framework used across thousands of services in a dozen environments where every single REST call is done using a singleton HttpClient with zero documented race condition issues. The only issue I've ever had with HttpClient is handling the stale DNS problem.
The original post?
Wait, you're seriously going to make the assumption that his issue, which he hasn't provided source code for, is not because of his mistake but due to a wildly used Microsoft library with over a decade of use across millions of developers?
I don't know, but there is apparently an issue.
Yes, there obviously is. And instead of trying to confuse the poor guy with trying to blame it on the standard library, which given its level of adoption and accompanying documentation that asserts that it's thread safe, lets focus on what's wrong in his own code, where the problem almost certainly is.
AFAIK, most ASP.Net work is done in medium to large companies, but that doesn't mean a solo freelancer can't find projects. There are tons of smaller projects in those companies, after all. Clients looking for PHP contractors also tend to be very price-conscious, so that's a strike against it. Lastly, technology popularity can have a surprisingly strong regional component, so knowing your local market is important, even if you keep an eye on global trends.
&gt; There‚Äôs no excuse for your methods to provide return values which hide the details of why something went wrong. Couldn't agree more. My co workers, not so much.
What would you do in a situation where you have a critical piece of code, and you want to add some non critical logic to it? For example, say you have a main event loop that runs an entire system, and you are tasked with adding a feature that calculates the rolling average event time and periodically prints it to a log file. But if for any reason the average logging fails, you need the event loop to still keep going. In my opinion, you should first catch any exception you know how to handle and handle it, but you should also be catching Exception and logging it, while still proceeding with the event loop, since the code you have the catch around is just a "nice to have" log message and not related to the functionality of the system in any way. How would you suggest you change the above approach to make sure this optional code never throws (even if another developer were to modify it and make it have the possibility of throwing new types of exceptions, and not updating your catch handler) without catching Exception somewhere?
I ran the code, the attached picture is the results of the query and what it looks like in the watch. https://imgur.com/aZ2NjAe
&gt; where the problem almost certainly lies. LOL. I've seen already many hidden bugs in .NET library code.
So you‚Äôre getting back a dynamic object you mean? In that case it sounds like you need to create a model that the data can be mapped to, just a POCO (plain old c# object) then you can iterate through and do whatever you need to do.
My first job had a guy who did this all the time because he was used to using DBase/Clipper. I don't know if the Xbase languages have better ways of handling exceptions, but it felt really strange.
You mean you want more information about why something failed other than just false ?
you had me at klopblock ü§£
Maybe it‚Äôs because I‚Äôm on mobile but that image is super blurry.
is this an interview question, also sounds really specific! üòÑ Your approach is a fair shout, and probably one of the only situations where you want to catch \`Exception\` - to protect critical code, from a non-critical failure. I actually had a project right now that does this (and here is where i say that i wrote my little list straight off the top of my head.. on my phone.. on the bus ü§™), which processes batches of events, and if one of the events fails then it needs to continue processing the other events. Lots of already handled bugs are caught with lovely error handling, that is super robust these days, but sometimes, just sometimes, you get something really weird (maybe a platform failure, it's hosted on Azure), and we need to catch, and log the Exception to Application Insights, so i agree with you üëçüèº
I‚Äôm working on a project right now where the guy who set up the stack decided that the ‚Äúpattern‚Äù we were going to use was wrapping every single service method in a catch-all try/catch, which would attach a cute little failure message and flip a success bit to ‚Äúfalse‚Äù on a generic wrapper object if the code entered a catch block. All stack traces (unintentionally, I‚Äôm sure), were discarded completely during this process. By the time I joined the project there were hundreds of these methods in place, and I was afraid to change many of them because the cute little messages made their way all the way up the stack to the actual API level, and I had a fear the front end app was actually keying off of that data in some spots...good luck debugging a service call on production that calls thousands of lines of code based on a single string failure message without a stack trace... This article has great advice though. There is almost _never_ a good reason to wrap a chunk of code in a catch all try/catch. Exceptions exist to help you find problems...discarding all of their useful information and doing your own thing is almost always a recipe for disaster.
I've come across several bugs in the .NET code, and the most commonly used and open source portions are almost always documented, so it's best to first assume your own code is wrong before jumping to conclusions on it being the standard library that is both open source and used by millions of people.
Weird.. i will edit it when i get home :/ sorry
There are xbase languages? I'm currently dealing with this at work and it's a freaking pain. I've tried all the typical oldb/odbc drivers, Python, C# and Java libs, but they all just crash and give up. &amp;#x200B; The guys making the software that uses the dbase files apparently decided to just ignore any and all standards, so you get some tables with 500+ columns. That's where the Microsoft drivers give up, can't have more than 256 columns. Next up are is the version which is a mix of 3 and 4, combined with possible dbt memo files that the other libraries just give up trying to understand. Luckily the format isn't exactly complicated so I resorted to just studying the xbase format and writing my own library to read it - basically repeating what thousands others have done before me, but at least I gave myself permission to ignore memo files instead of insisting and then crashing.
Sounds like what I had to deal with, granted, not 500 columns bad. But it really felt like the DBase stuff didn't encourage people to normalize tables. As far as your question goes, there were a lot of DBase descendants. Clipper, Visual Fox Pro, Visual Objects among others. To my understanding, they all kind of died though due to stuff like Delphi, Java, VB and C#. There were a couple of attempts to bring it to the net stack as well. The only one that I know of that is still maintained is XSharp. I don't know if it can use the old DBase files but I suspect it can. You may want to look into it. Its open source btw.
Yeah, I think using Polly is your best bet in this case. I am doing something similar when interfacing with Google and [I wrote a blog post about this approach](https://www.jerriepelser.com/blog/refresh-google-access-token-with-polly/). In my case, I get a refresh token and use that to obtain a new access token, but the same principle is still valid to you. It is just that in your case you will request a new token using the client id and secret, instead of using a refresh token.
I don't see the need for that, enlighten me? Why not just keep it in an in-memory cache? Keeping tokens persisted on disk also sounds less secure to me.
It's no more insecure than keeping your connection string in a web.config. The sqlite cache means my tokens persist across restarts.
My assumption about this is you keep it up to date after using the template. If you're using Git, there's certainly no reason why you should be concerned about it, considering that you can just reverse bad changes.
That's absolutely fine. Hell, by logging it, I'd say you're not even swallowing the exception. You're properly handling and recovering from it. That's really what a catch block should be doing (unless the exception is unhandle-able, then it should throw) in my opinion.
The author uses a pet peeve of mine on doing a .ContainsKey(), followed by the index operator to "safely" access an IDictionary. I much prefer a .TryGetValue() call. First, it only requires one lookup operation in the Dictionary. Second, if you're worried about thread safety and ever want to switch to a ConcurrentDictionary, I believe .TryGetValue will happen atomically, while that Dictionary's state could change between the check and the access. Here's the suggested code from the article. &gt; // check first, no try ... catch required var letter = alphabet.ContainsKey(27) ? alphabet[27] : "&lt;not present&gt;"; Console.WriteLine($"27th letter of alphabet : { letter }");
Create two separate projects. 1. .net core api 2. Angular 8 using angular cli Set up cors and call it a day.
Yup. Unless of course the result is a Boolean. User.IsAdmin() can return a true or false value. User.MakeAdmin() will probably need to return something more meaningful if the role elevation fails (DB connection error, permission denied, request queued for approval, etc.).
Thank you thank you thank you. Don't know why I didn't just take this approach to begin with haha.
Make sure to have VS Code installed. I'll run my js frontend app code in vs code and my .net core api code in visual studio.
My approach was to use the net core cli template, but then regenerate the ClientApp folder using the angular cli. That gives you a project structure where the compiled output of the angular production build can be treated as static files to be served from the net core web project.
[removed]
That just complicates the mental model, IMO. It could also get screwy when it comes to node dependencies, etc. By separating, it also makes your frontend flexible, so in a year or so, you can swap it out for whatever js frontend tech that is getting all the rave. Plus, when you host, you'll likely have your angular app on domain.com and the api on api.domain.com. It also makes it super easy to host with docker-compose. Just a few thoughts.
I can definitely see the case for separation, and the way you are describing is the way I set it up with my last Angular project with a Scala Play Framework backend. But now I'm at an enterpise shop and I like avoiding the CORS requirement for policy reasons. The "domain.com" part is actually only an API gateway that delegates to the actual implementing API services.
And me lol
Download Sololearn to learn c# syntax fairly quickly. The syntax is similar to Java and C++ (hence the # in C# is supposed to look like C++++). Download VS2019 community. Start doing console projects in both .NET Framework and Core to get familiar with how it works (Core is the future). Learn what NuGet packages are, and their compatibility with Framework/Core/Standard for your specified project. Incorporate frameworks such as Entity Framework and LINQ to learn how to work with databases on .NET before moving into front end work. Then finally start doing projects with ASP.NET. MVC template is a great place to start if you understand the MVC pattern. WebAPI is nice if you are running front end frameworks such as Angular/React.
Asp.net is a big subject (web forms, mvc, webapi being the top level determinants), ask your prospective employer for some further pointers (if they don't think the question is constructive then that will set the tone for the internship and probably better avoiding them). Ask what is the rest of their stack (e. G from controller/codebehind through to database/network I/O. Otherwise don't stress it, learn what you can and remember there is no correct way of doing anything, just various shades of right and wrong.
&gt; hence the # in C# is supposed to look like C++++ Source?
https://www.computerworld.com.au/article/261958/a-z_programming_languages_c_/?pp=2
Thank you.
Yes. The part I was missing is that you're supposed to have a login screen on the IDP server and not on your front-end app. We will look into that, cause it's not how we understood it, and I don't like to expose the back end :/ (I understand it's what it's made for and that it's a perfectly normal use-case).
I don't know why these god awful templates are so popular and I blame the VS team for pushing them - they almost never use the appropriate CLI tool for the given framework and are therefore "ejected" and automatically hard to maintain, outdated, not following best practices, etc.
Not even need for cors if you setup proxy in angular.
Indeed. I now use Rider daily having used VS for years and it's an order of magnitude lighter, especially when it comes to installation!
[https://github.com/AvaloniaUI/Avalonia](https://github.com/AvaloniaUI/Avalonia)
My work takes place on 2 different linux distros and windows as my daily driver. Keeping my workflow standardized is a pretty big productivity increase. So I use rider instead of visual studio. VsCode is cool, but requires way too many plugins and futzing around vs a curated fully featured IDE out of the box (+ standardized interface / workflow for c++, python, c# and java is nice)
 [https://visualstudio.microsoft.com/xamarin](https://visualstudio.microsoft.com/xamarin)
Your post has been removed. Self promotion posts are not allowed.
https://github.com/mono/xwt
They have no plans of bringing WinForms or WPF to other operating systems.
I haven't tried this tool in VS2019 but the best experience that I have had for theming VS is using Dainty-VS https://github.com/alexanderte/dainty-vs
Xamarin.Forms is the way.
 My first two jobs and the first four years of my career I never really encountered well-written code, and I spent so much effort agonizing over when to break things into functions, and how to write good variable names. That's important, but I wish I had just worked on a code base early on that showed me the *real* right way to do things. Have a domain project, a data repository project, a services project, a test project and an application project. Write all classes to interfaces, and inject those interfaces. Once you know how to do it's pretty straightforward, and you don't have to fight refactoring battles anymore.
Does it support macOS 64 bit?
If .Net Core, go through ASP.NET Core in action. For C# I recommend, C# in a Nutshell (I read 7.0). For SQL, you can try w3c school, it's not perfect but its I think its a decent start. Otherwise, I would recommend "SQL Practice Problems: 57 beginning, intermediate, and advanced challenges for you to solve using a ‚Äòlearn-by-doing". &amp;#x200B; Otherwise, I have learned most of the stuff on the job, generally most employers expect very little from interns or juniors. Just be cautious, if you are unsure about something go ask or at least google it. If you see a concept that is unfamiliar to you don't accept it as magic, look it up. &amp;#x200B; I would give more detail on advanced topics but I think just going out of your way to be ready for the internship will put you ahead of most interns.
It's not going to be dead, WebAssembly is gaining speed rapidly as all kinds of developers are looking to use their existing code and languages to deliver applications to the web. Microsoft's recent news about .NET 5 consolidating all the frameworks together is only further good news that WASM will be a viable target for the future.
One of the communities I belonged to tested Gtk# on .net core and it works like a charm, Xwt uses Gtk# on Windows, Mac and Linux. As well as WPF on Windows. This library might be basic, but it is really brilliant.
Just make sure you actually need a "service", because there is coding and operational overhead associated with such.
are you sure that in server side this exist: '[http://localhost:53702/system](http://localhost:53702/system)' ?
I wouldn‚Äôt necessarily put them all into separate projects, as there‚Äôs no logical reason to do so. Like maybe you‚Äôd want to swap out a repository layer for a different db, but you‚Äôre most certainly not going to swap out all of your services or domain objects. Domain, services, repository / repository interface, and application should all be in the same project. Test should definitely be separate.
Service layers should never be skipped. It‚Äôs simply bad practice to not have one. The overhead is laughably negligible for the readability and separation you get back.
Yes, I own that endpoint and I have logs written that is accepts the request. Also it responds.
just checking, in the server it has the same port?
What if you have to exchange the WinForms client with a WPF client? ;)
The page currently gives and error 500..
Thank you! Ill get on that asap. You sir are a gentleman and a scholar.
Okay, thank you for the advice. I thought they seemed like they did until i starting looking into asp.net and how it looked so vast kinda got me lost on where to start. Thanks again!
Thank you!
This doesn't answer your question; it's just a tip. When debugging or benchmarking, don't use `DateTime` to measure how long something takes. Instead, use the [Stopwatch](https://docs.microsoft.com/en-us/dotnet/api/system.diagnostics.stopwatch?view=netcore-2.2) class, which is designed for this purpose.
I would use neither of those things. If a situation calls for a desktop app, I much prefer using a micro-flask server and a webview. I don‚Äôt understand the appeal of WinForms or WPF. Both way too out of date to be used.
I figured it out. Will post once I get it all tidy.
Have you tried running any sort of performance profiling on the application after deploying to Dev? Something like ANTS, ReTrace, dotTrace, VTune. Nothing looks obviously wrong at a glance and it's very strange. Only other thing I can think of doing to definitely make sure this is just your code that's the issue is to wait some time and then do the call on the box through Postman or something to see if that replicates it.
I agree with you in some cases, but in other cases i‚Äôm definately not. Repository layer is ‚Äúglue code‚Äù. It is not necessary to implement in a layer. UI/Presentation layer and data access layer is just a plug-in to business rules. It has to be separated. If you write the whole projet in one layer it will be very tough to separate them in the future...
It can be helpful to make sure that the domain layer doesn't try to access the service layer, because it won't compile with circular dependencies.
Well, that's your personal opinion, but doesn't answer the question. :D
UI/Presentation &gt; ViewModel -&gt; Services -&gt; WebControllers -&gt; Services -&gt; Domain -&gt; Persistence That stack has put together several successful projects for me.
Thanks
Postmon and Browser calls do not replicate the issue. I should have included that in my summary.
Winforms and wpf have a few advantages when it comes to desktop development. I don't understand the point in putting a web based ui on a desktop application (I did it once and regretted it, it's not something I would do again). There is a lot that is undesirable when it comes to web development and if you are going to bring in dependencies on multiple js libraries and frameworks then there had better be a pretty good reason for it. I agree with the idea of many projects being overkill though, the seperation is nice but you don't need to have several projects for that. I've toyed with having a repository implementation and seperate projects for different types and it's nice that you can just build the right repo and have it change data store but in a given system you need to consider how often this would happen versus how much complexity it adds. If you are making the application harder to maintain for flexibility then that flexibility has to be justified.
What? If your domain objects are handling persistence, communication, and validation on top of business logic, you're going to have a mess of a code base. Services are just classes that handle orchestration of a particular need. It could be persistence of a particular domain model, a type of file I/O such as CSV, etc. A really basic example is a service that wraps CRUD operations for a domain model that takes in a DBContext via DI.
Is it really localhost?
No problem, judging by your other posts look like you've solved it which is good! Interested to hear what it was.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/dotnet] [GitHub - FormHelper: Form &amp; Validation Helper for ASP.NET Core (Compatible with Fluent Validation)](https://www.reddit.com/r/dotnet/comments/c4t1by/github_formhelper_form_validation_helper_for/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
If your data access interface doesn't care how the info gets to and from the database, then you might was well communicate directly to it rather than go through JSON etc. If you later need it to go through JSON, then in theory you could switch the implementation as needed. But in practice, "just swapping implementation" is easier said than done because there are always enough nuances to muck up straight 1-to-1 conversion. If your infrastructure is set up well to handle a JSON-centric way of communicating with the database, that's fine. But have that in place first rather than force it per project.
"Readability" tends to be subjective. &gt; and separation you get back. Excess separation has a cost. One should spend their time writing business logic, not interfaces to marshall everything back and forth. That's wasteful busy-work.
Answer if it is running in IIS: IIS "parks" an application if it is not used for x amount of time. This causes the first request to be slow as it needs to spin up the parked application. This is, at least, true for classic asp applications. I'm not 100% sure if this is also the case for .NET Core, maybe someone can confirm or debunk this.
I‚Äôm sorry, but that‚Äôs absolutely terrible practice, and what leads to spaghetti code. Tech debt is real, so start off correct. You won‚Äôt ever have time to refactor an entire application down the line.
 private void ConfigureHttpClients(IServiceCollection services) { var httpClientHandler = new HttpClientHandler() { UseProxy = false }; services.AddHttpClient&lt;ISystemClient, SystemClient&gt;() .ConfigurePrimaryHttpMessageHandler(x =&gt; httpClientHandler); } Setting the **Userproxy = false** in HttpClientHandler resolved the issue. It appears that the HttpClient was attempting to resolve a proxy in some environments but not others. This attempt was taking 20+ seconds because the proxy was not there. Now, as to what IIS/network configuration was setup on one server v another I have no idea. In addition, WTF Microsoft? Why does it take 20+s to identify there is no proxy?
this is still true but you can turn it off.