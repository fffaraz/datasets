tnx, will check it out.
With good reason.
You should actually be focusing on ASP.NET MVC 2/3. Vanilla ASP.NET is outdated and really bad at this point.
I have been doing JQuery -&gt; API w/ ComponentOne mostly for the last year or so... which has been pretty entertaining. Last time I looked at ASP.NET MVC it was a disaster (just before 2.0 came out).
With good reason.
You should look again. MVC 3 is far from a disaster. It's what ASP.NET should have been from day one.
&gt;Last time I looked at ASP.NET MVC it was a disaster (just before 2.0 came out). It's only a disaster if you're used to using components and controls. If you want full, to-the-metal control over your markup, and are well versed in HTML/Javascript development, then MVC is perfectly suited for you.
Tnx guys - I'll go back and take a look. If it'll open up more contract work then I'm in... 
Great way to handle those exceptions
ಠ_ಠ Same version number for a new version of the framework? Facepalm. It'd be one thing if there were no changes to the core assemblies and were just new classes, etc added but this is just silly.
Are you willing to move? There is a company in San Luis Obispo, CA that is hiring classic ASP coders like crazy. Private message me if you are interested.
I was excited about it until I heard of the same version number business. Looks like I won't be able to mess around with async at work. Won't even install side-by-side.
Not looking to move - really looking for something I can do from home (after work and on weekends).
Crashes every time. Suggestions?
&gt;Last time I looked at ASP.NET MVC it was a disaster (just before 2.0 came out) ASP.Net MVC has never been a disaster. It has gotten from good to awesome. I've found it works best if you use ViewModels instead of just passing Models around.
[how to import it into vs](http://beyondrelational.com/blogs/jalpesh/archive/2011/07/24/visual-studio-2010-styles.aspx)
Let me know if you'll have too much work, I'd love to make some additional money (I'm best with asp.net, asp.net mvc, sql, average with html, css, jquery)
I wonder if #2,000 will be that WPF is deprecated in favor of metro-style applications.
By the way, that password isn't really my password.
Nice, but IMO it should be even better than this. This should do everything for you for something so trivial. [NotifyChange] public string FirstName {get; set;} or [NotNullable] public string List&lt;Orders&gt; {get; set;} However, the best would be able to specify an external/internal set of functions to replace the get &amp; set with new bodies using some kind of special syntax/attribute. Possibly keeping the use of 'value' but make it available in getter as well so you can do lazy loading without having to write the boilerplate logic. This would allow people to write suites of the common implementations for the majority of properties. The best thing about this would be the lack of major compiler changes. This would be part of the first pass, inject the templates, then continue like the code actually existed. 
Bout time...
Inotifypropertychanged sucks. 
Why use WinForms? It hasn't been updated in like 5 years. It's practically a dead technology.
IMO the attribute is far more exciting :)
For compatibility reasons, also because I didn't find an equivalent for the Chart control on WPF. If you want an app that will run on Windows XP, Vista, 7 and 8 you will use WinForms.
This is true to some extent, but what's also true is that Metro-style applications written in C# and VB use XAML, so a lot of skills from WPF and Silverlight should carry over.
I saw an app once that had a messagebox pop up (after clicking through) saying &gt;Wow, you just read the EULA in 1.54 seconds, which absolutely shatters the world speed-reading record! Way to go!
It's common with all MVC update so far. Phil Haack is aware of it. It will be fixed eventually.
They know we don't really want to read all the stuff.
I believe it. Judging by interviews I've been on and interviews I've conducted. Hard to believe, but its true.
What does you performance profiler tell you?
I have to wonder is EULAs presented in that fashion are legal. Though it hasn't been tested yet, that sounds like the kind of shit courts dealing with contract law frown upon.
I guess it's time for me to look for a job then.
Dallas is insane, I've approached this level where I've stopped taking any shit at work because I have a constant stream of other offers. I will say having conducted interviews, there is no shortage of .NET guys out there. There is a shortage of .NET guys out there who actually know what they're doing. The massive pool of "other guys" is what gives the profession a bad name.
Here in Boston, we've been trying to hire anyone. Senior, junior, entry-level, and have a hard time getting anyone remotely competent. I get emails and phone calls every day from recruiters. If I didn't already have a great job &amp; employer, it wouldn't take me long to find a new one. 
Put your resume out. You'll get lots of calls. 
Same thing here in NYC, it's kind of a bummer liking my job so much
.. You prolly didn't dispose your SqlCommand/SqlConnection/SqlDataReader properly resulting in your pool getting filled up and only releasing new connections to you when they are disposed of by the GC.. 
Well, I checked the code and it is being disposed properly. Plus if that was the case it wouldn't have starting working slow out of the blue. Weve had them up for a few months already and they were working fine before.
Another "here too" post... I live in Indianapolis, a recent graduate (though 'experienced' at 31), and I literally get 3-5 calls and/or e-mails a week about .NET Development openings. I took a position as a C#/.NET Developer 4 months ago (right after graduation) so I'm not "really" in "the market" for a job right now, but I definitely like seeing that there are that many opportunities out there and hearing what all is available.
I've seen something like this before, and I ran SQL 2008's 'dbe engine tuning advisor' and it went away. 
The Starter Kit has arrived, delivered by FedEx. The components come in a plastic case in individual bags and no accompanying documentation. The [official site's documentation](http://www.ghielectronics.com/catalog/product/297) is a list of stuff, and nowhere have I been able to find a simple idiots guide and "Hello World". Nothing to panic about, though, as I'm a smart guy. To be continued.
Anyone wanting to sponsor a kiwi .NET dev... ;)
Sounds interesting and intimidating but I'm sure as they get more popular there will be tutorials and whatnot. Thanks!
This. Freedom to grow / do meaningful work &gt; money (within reason, of course)
cool, I'm looking to use memcached on a project right now. My main issue to stop from just dropping it in is that it doesn't natively support cache dependencies.
Commanding is a really simple concept if you look at it the right way. ------------------ Problem: I want an way to combine the questions "Is this button enabled?" with "What happens when I push this button?" Solution: Create an object that implements ICommand.CanExecute and ICommand.Execute. ------------------ Problem: There are lots of copies of this button. When this button gets pressed I need to know which bit of data is associated with it. Solution: Set the CommandParameter property on the button. ------------------ If you don't have the problems listed above you probably don't need to care about ICommand.
After some searching, I've found a basic page on [Getting Started](http://wiki.tinyclr.com/index.php?title=Gadgeteer), and after 10 minutes I've connected the camera, LCD display and button to the mother board and have produced a c sharp app that has been deployed to the board and I can now take pictures of things. This is funky, and now I've got things up and running, it's quite easy as it's just a bunch of classes and events. It costs about £200GBP including shipping, by the way.
Being a .NET developer, I approve of this message. All those linux guys who laughed at me and called me "not a real programmer". LOOK WHOS LAUGHING NOW BITCHES!!! MUHAHAHAHAHAHA!!!!!!
Atlanta here, and same deal. My company has been looking for more competent .NET guys for a long time, and I'm constantly getting approached by other companies, even though I just graduated last year. It's a really great time to be a .NET developer, that's for sure. So easy to find jobs, so hard to find good devs. 
Geez, I wish I could *find* some of these companies. It seems like everybody I talk to hears that my current job is all .NET, and they immediately ignore the fact that I also do C, C++, and Python, instead assuming that I'm some kind of idiot drone.
Are the different pages using the same DB/Stored Procs? Might be an indexing problem in your data layer.
There's an absolutely fantastic talk by John Papa on MVVM and advanced architectural concepts called Kung Fu Silverlight. It's where I learned a lot of the cool MVVM stuff I use today and I recommend it to everyone. Linky: http://channel9.msdn.com/events/PDC/PDC10/CD50 (I know it's Silverlight, but everything important is almost directly transferable)
I've also been teaching myself WPF and MVVM as of late and this is what I've understood of it. You've got a button on your view which you need to write some behavior for but you'll need to write it in your ViewModel so that the logic is testable, separated from the View, etc. What do you do? You bind the `Command` property of the button to a property in your ViewModel that implements ICommand. So let's say you have the following xaml: &lt;Button Content="Save" Command="{Binding SaveCommand}" /&gt; Now the button declared above is bound to a property called `SaveCommand` in your ViewModel. Here's the declaration of that property. public ICommand SaveCommand { get; private set; } Few things to keep in mind: * Make sure the property's access modifier is set to `public` otherwise the View won't be able to see it. I made that mistake one too many times and since you won't get an Exception at run-time telling you the SaveCommand is inaccessible or not found, this can be an annoying problem. * Notice the property has a type of ICommand. You could also have it set to something that implements ICommand. * I made the setter private since you really don't need it to be public anyways. Ok, so now what? Now you need to give the `SaveCommand` a value. But there isn't a class that you can instantiate that implements ICommand. Looks like you're going to have to make one. Here's [an implementation](https://gist.github.com/1271914) I found on a tutorial about [the MVVM pattern](http://msdn.microsoft.com/en-us/magazine/dd419663.aspx). Ok, so now that we have a class that implements the ICommand interface, let's give the SaveCommand property a value. We'll do this at the constructor of the ViewModel. this.SaveCommand = new ActionCommand(() =&gt; System.Windows.MessageBox("Save!")); Notice that the `ActionCommand`'s constructor takes a `Func` as a parameter. This parameter holds the logic that should take place when the button is pressed. I currently just made a message box popup but you could instead make a call to a method which holds all the necessary logic. The ActionCommand also takes a second parameter which is a `Func&lt;bool&gt;` which will decide whether or not the command is executable. This will automatically disabled the button if it returns false. Pretty cool. And that's it. If you've got your View wired up to your ViewModel somehow, that means now when you click the button, a message box should popup with the text save. There's lots more to talk about but this comment has gotten long enough as it is. If you found this comment useful and would like to hear more, let me know. Although I think we covered everything already.
Two points: 1. Here in Houston, most of job offer are contract like 6 months. 2. Aren't we at yet another down turn? I've heard companies are cutting down. I wonder if both are related. Downturn = contract job. I don't think there are any permanent .Net job in Houston.
It's just an update. The full install comes with a full-size window. 
So, how do I become a guy who knows what he's doing?
Cool, looks like it works as advertised.
There is some truth to the comments. I have been a cross-tech guy since the beginning of my career. Up until about 4years ago I had pretty much equal time working in .NET and Java stacks. Java teams WILL NOT hire me any more. The attitude I get is that by working with .NET i have become unclean and will not be able to handle the "amazing" world of Java. At first I was frustrated now I just ignore any Java jobs. Interestingly enough only Java dev shops have this problem so I'm sure the main devs who are worried about switching to .NET are also Java devs. At some point Java became a religion among it's users. I haven't seen quite the same fervent and blind adherence and ceremony in any other stack except for some of the more obscure and older systems. 
don't stop learning, dig in and become better through practice and knowledge. Truth is it to be really good at software takes a certain kind of mindset and a certain way of thinking. I'm of the opinion that not all humans are inherently wired in a way that allows them to grasp some of these concepts intuitively. Also you can't be the guy who thinks he can work 9-5 and then turn off the computer side of your brain. You have to really love technology, you have to want to be immersed and be ready to do that for a few years at least to bring your skills up. All the best people I have worked with in the last 15 or so years have nearly all had the following traits: * Obsession with technology * Operated Basement labs, personal server clusters, cloud instances for fun and personal projects * Hacked on the nights/weekends for fun * Writes programs for themselves to make both work and home life easier * CTPs of new technology stacks makes them giggle like kids and run to the new compiler to start playing. * Does not care as much about the technology platform in a religious sense, is most interested in what that platform can do to solve real problems effectively. * Dreams of having 6 months off to write their X killer. 
You can do that kind of thing today with AOP such as PostSharp (see the comments on the blog), but unfortunately it seems like AOP will never be built into C# http://www.sharpcrafters.com/blog/post/AOP-in-C-Over-Anders-Hejlsberge28099s-Dead-Body!.aspx
See where you can get with real time systems or really large transactional systems where speed is a huge factor. You tend to get C or C++ work for those components down in the guts. They still stick a managed code application on top of it generally though. EXAMPLE: Oil rigs delivering data to shore based systems process data in realtime from PLCs. The C++ components are built to pump that data into an RDBMS store for analysis as quickly as possible. Every year more inputs get added to these streams making them an interesting full time challenge for some folks I know. 
I have found this to be true here in Houston. The only long term job opportunities that have a good future are the ones offered internally within companies.
Ah. I have to disagree a bit. I don't think there's anything particularly magical or special about the underlying qualities of a programmer. It's just practice. Practice, practice, practice. I contend that you don't even have to like the stuff. And yeah, I also contend that having a normal life outside of banker's hours is what keeps a programmer from becoming a burnout who's devoted so much of their lives to work and programming that they never bothered to develop any other aspect of their lives. But yes, lots of extra reading on the side and perhaps a project on the side - maybe (but not necessarily). Access to good training like from university extension classes. I think these are all much more important than finding someone who has a certain genetic makeup or has some innate skill.
If you wish to remain a programmer sure, programmers can sling code all day. I've met many a good programmer that still does not grasp the concepts they are dealing with fully. I've worked with programmers with 10 years of experience that can take a spec and code the hell out of it. Give them an original problem to solve and a blank slate to do it in and they are lost. This is the difference between a programmer and an engineer. The thing is, we need more engineers and less programmers. I would like to think ANYONE can do it, anyone can learn to code sure. Not everyone can really understand it. Just like I don't think I'll ever wrap my head around some of the areas of expertise others are in. 
People conducting interviews and making hiring decisions are at least as bad as many of the horror stories you get about some coders. There's a ton of things wrong with how tech departments hire new people. But subscribing to this religious BS about being "unclean" now that you know .NET is stunningly moronic.
I love these blanket statements about what it means to be a "good programmer." Love it. Can't get enough of it. Of course, this is also the mentality of hiring managers who won't talk to anyone who's currently unemployed. A situation that is troubling and illogical.
The right question to ask :) Keep learning and be genuinely interested. Being that coder isn't a 9-5.
I tend to agree. It's rather disturbing but up untill a few years ago when I gave up going for java jobs I would sit in interviews nail questions about patterns, best practice, use of tools etc etc. Almost every time there would be references my .NET experiences and even off-hand comments (sometimes randomly insulting the platform, what?) it was certainly odd. Every time the hiring manager or the recruiter would talk to me afterward and i would get almost the same line every time: "The team feels that since you don't only do Java that just won't have the skill set" - It mattered not how well I handled the technical side of the interview. The funny thing is now. My java skills ARE stale as a result. Sure I can pop in and make changes when I need to, fix a broken OSS project but I haven't kept track of the tools or projects in that community (except the big ones) since I gave up. Personally I am of the opinion that if you only do 1 language you really aren't doing your job. Exceptions for really specialized stuff of course. 
kiwi .net dev here too. Move to London. You can pick up a 2 year working holiday visa. You'll be in a job within a week. 
Take advantage of a golden age while you can. Things aren't forever
move town
I can't. All the .Net job offer in Houston = contract.
yes you can :) 
Contract work == more money. Also, stop going through the recruiters. You need to market yourself more to gain the attention of the companies that hire the recruiters.
I've found his [previous article about object caching](http://deanhume.com/Home/BlogPost/object-caching----net-4/37) to be more interesting considering how it could be used in many more places. Although I've always thought users would be weirded out if they saw old values appearing after they made a change. Looks like it'll be up to the developer to remove the old item from the cache whenever it's updated. More code to write but in the longer run, it beats having to hit the database every single time you need the value.
Huh. At my school, we have junior and senior projects. For each of them, you get a 1-2 paragraph problem description and a client (typically a small business run by an alum). Throughout the year we meet with the clients, find their needs, write a ton of requirements and other documentation, and then finally build the product for them. Do no other schools do something like this? o.o
I'm not talking about schools, I'm talking about what I've seen in the real world in professional environments. Some schools are of course better than others when it comes to these kinds of things and I would not be surprised if you could chalk a lot of it up to different ways schools teach but by the time someone has been doing this kind of work for 10 years I would expect more but I'm surprised every time when I don't find it. Honestly it may be the dotBomb; many people ran to the tech sector to get rich quick not because they love technology. Now they are just stuck. I would bet that most people going through technical courses these days actually do love the tech as I have seen some more promising juniors in the last couple years. 
I have a plural sight subscription which I use to keep current. It's not for everyone though. That being said, 9-5 isn't realistic in the sense of 5pm rolls around and you turn off your PC. Almost every day I work a little past or so, it's not a matter of commitment, it's a matter of recognizing the mindset that leaving your current though halfway through and unfinished will put you at a disadvantage the next day. I'm not saying work 90 hrs a week even though I've done that, but expect to work over the standard 40 just out of your own sense of wanting to finish something.
Well my point is, I feel like what we're doing in school is pretty close to a real-world professional environment.
maybe it is maybe it is not. I'm sorry to say that most schools ive seen woefully miss the mark. I wish I could tell you which yours is but I would need to see the actual curriculum and a few hours. 
I do that, or rather, part of it, already. I work in a shop that designs and prototypes big printers (as in, printers used for printing everything from billboards to golf tags). They have a number of real-time, embedded boards controlling things like temperature, pressure, head voltage/fire rate, motion safety, and other similar systems, and the connected PC has a .NET app (mostly C#, with some C++/CLI underneath) that sits on top of all that and handles the parts that aren't dangerous or super time-critical.
I'd love to, but I need to have a job before I move.
I've been having success using AutoHotkey scripting to this end.
http://en.wikipedia.org/wiki/Microsoft_Active_Accessibility should give you a starting point.
If you have Visual Studio Premium or better there is a built in coded-UI test suite that does exactly this. I'm not sure what is out there cheap/free however.
I've also used this quite a bit in the past to automate some things in some install scripts. Pretty easy. Has nothing to do with .NET though - not quite sure what the OP is trying to ask or why its here.
[AutoIt](http://www.autoitscript.com/site/autoit/)
thanks, I'm looking this one, seems to do what I need
I've never used autoit, but I have done a lot of that type of thing with p/invoke. I agree with enkafan's sentiment that this doesn't really have anything to do with .net and should be asked elsewhere (like /r/programming or /r/windowsadmin if that exists)
thanks, I honestly had no idea so I thought if there wasn't software to already do this .NET would be the way to write it myself...
Is this your article? I hope so, otherwise what I'm about to say is going to sound very silly. I've been using OpenGL in my windows apps (WPF and Winforms) for a few years now. I'm was just curious what SharpGL is going to bring to the table that OpenTK currently does not, or Tao.NET did. I think people really need to read this for the 2nd half of the article, as the first part can already be done with OpenTK. &gt; This is some fairly complicated logic (creating the framebuffer etc), the purpose of which is just to create an OpenGL render context. SharpGL does in fact support rendering to a DIB, or a Native Window, or even to a Hidden Window (which in Windows XP can then be blitted to the screen). As each way of rendering is different, we have the concept of a RenderContextProvider - an object that will handle the internals of creating, resizing and cleaning up an OpenGL render context and its supporting objects. This is why in the earlier example we used the RenderContextProvider property of the OpenGL object to get the pixel width and height. The fact that you have provided a simple way to render fully featured to a DIB is what has me excited. Even if you don't have a complete implementation of the OpenGL Library, being able to establish the context and do heavy lifting with OpenTK is very cool. This meets about 75% of my needs as is. I have a thread in /r/OpenGL which has gotten plenty of votes, but no responses. http://www.reddit.com/r/opengl/comments/kwold/render_to_video_overlay_in_windows/ If you could take a few more steps and create a video overlay context, I'd be willing to pay a bounty for that functionality.
It's not my article, but I don't think you sound silly, I just thought it was pretty interesting. I'm sure he'd like to hear from you, though!
I sent him an email, I hope it doesn't get stuck in the spam filter.
Thank you all so much. This all makes quite a bit more sense. 
Regardless of the CanExecute and CommandParameter attributes, ICommand is a much better and more abstract binding between UI and logic than event handlers. 
Think about what you are saying for a moment. Setting aside the questionable assertion that ICommand is "more abstract", what is the actual problem you are solving? ICommand isn't free, at the very least you have to allocate an object to hold it. And then there is the indirection between the Execute method and the code that is actually being executed. Before you pay the cost make sure you have a reason to use it. 
&gt;ICommand isn't free, at the very least you have to allocate an object to hold it. You have to allocate *one* object for each command. That is absolutely trivial for the type of GUI applications that it is targeted at. Do you have any notion of how many objects are allocated simply by most WPF/Silverlight controls themselves? &gt;And then there is the indirection between the Execute method and the code that is actually being executed. The level of indirection is roughly the same amount as a traditional click handler. There's very little "cost" associated. What you are arguing is an extreme case of premature optimization. Do you use `For Each` in your code? Have you ever unrolled that and seen the truth of what that does to performance (particularly WRT explicit casting?) But why would you? It's an explicit cast every single iteration, but its cost is negligible in almost all cases. Do you use LINQ? Do you use any sort of ORM? Do you use yield? Do you use WithEvents? Etc. It's a very small price to pay for decoupling your interface from your logic. It only seems useless or "not worth it" if you look at ICommand without considering a framework or model placed underneath that uses it in conjunction with databinding to really give you a clear and solid decoupling strategy. You don't get that with classic event handlers. You don't even get databinding.
&gt; It's a very small price to pay for decoupling your interface from your logic. Decoupling? If anything you are making it easier to move view-specific into the view-model. If it doiesn't belong there, which is often the case for UI events, you end up increasing the coupling between the two. &gt; You don't even get databinding. Now that is at least a real argument. 
&gt;If anything you are making it easier to move view-specific into the view-model How? The view-model has no access to the view layer and no way to get access to it without deliberately fighting the framework. What sort of thing are you thinking of, for example? &gt;If it doiesn't belong there, which is often the case for UI events But that's part of the abstraction. Commands aren't UI events. They are commands (in this context, they are actions to be taken on the ViewModel.) 
&gt;If anything you are making it easier to move view-specific into the view-model How? The view-model has no access to the view layer and no way to get access to it without deliberately fighting the framework. What sort of thing are you thinking of, for example? &gt;If it doiesn't belong there, which is often the case for UI events But that's part of the abstraction. Commands aren't UI events. They are commands (in this context, they are actions to be taken on the ViewModel.) 
Not being US citizen (I'm EU) how much experience would I have to have to get calls from recruiters every day? I'd love to work in NYC for a few years, but I still have less than 2 years of .NET experience. Any possibility for remote work?
&gt; I put all the pages on my own dev server and its working fine. Using the same DB server?
Oh yeah, that's totally obvious. &lt;/sarcasm&gt;
Lesson learned: even though languages often look alike, every language has hidden details that can occasionally give you a gotcha. 
This is why it's difficult to be truly productive in the latest and greatest language/db/etc if you're not that familiar with it. Even if the syntax is ultra intuitive/you read the documentation back and forth, there will always be caveats. In some ways, it's better to have the bugs/qwirks you know than those you don't. I'm all for innovation; don't get me wrong. It's great to learn other languages to expand your thinking/patterns and simply for fun. But, this post is a small example of why the second coming probably isn't near.
Next up, [banker's rounding](http://msdn.microsoft.com/en-us/library/3s2d3xkk.aspx)...
NSFW
I disagree. I mostly write in C#, and I was productive in Python the same day I started using it. I decided I wanted to edit some mythTV helper script I found on the internet. After doing no more research than reading the script, it was extremely clear what it did, and how it worked. The same day I was able to fix a bug, add new features, and with very little research, even support command-line arguments, where it did not before. The lack of closures, and the straight-forward systax make it so simple to read: if foo in bar: #How could you NOT understand this? Now take something that *should* be easy to grok, coming from a c-like language, JavaScript. var foo = function() { //WTF? Why would I do this? or if foo === bar //Because '==' is almost always the wrong choice. 
Do you have any indexes on your tables? I would check that first. 
I'd argue Python is a fairly established language. It's something I've gotten into in the past year as well. I meant people pushing the more en vogue (namely functional, though I do like F#) languages.
I agree 100% with that. I remember the first few years of .Net. You always knew it was a .Net application because it performed terribly, and you couldn't use it for more than 10 minutes without running into the .Net exception dialog. Actually, considering that, I'm a little concerned for Windows 8 apps. Let's just hope the exceptions are *really* pretty.
I have some faith in Anders (C#) at this point. I don't have a lot of faith in WinDiv though. As much as the idea of Metro app abuse makes me want to run for the hills, the new C# features like `async` keyword are promising. 
Checkout MVVM Light toolkit (Galasoft, free of use). They have the [RelayCommand](http://blog.galasoft.ch/archive/2009/09/26/using-relaycommands-in-silverlight-and-wpf.aspx)
&gt;Console.WriteLine(Math.Round(4.5)); // 4 &gt;Console.WriteLine(Math.Round(5.5)); // 6 ಠ_ಠ
It's been my experience that the best way to weed out people who interview well but couldn't code their way out of a wet paper bag is to give them a short contracting job. If someone can actually do what they say they can do, you'll know after 3 to 6 months at which point, hire them or let their contract expire.
Good article. Thanks for posting.
Wow, sweet!
This is pretty cool. I've been using the [chirpy](http://chirpy.codeplex.com/) Visual Studio extension for my minifying and bundling needs.
Any more information than that? Not going to get many downloads if you don't provide any info.
I second this, I just installed it via nuget the sample code didn't even compile. More documentation please!
&gt; I'm not "really" in "the market" No need for quotations. It's how its called and handled.
Time to fall in love with the 'await' keyword.
I wish I could use this in the project I'm working on right now.
If you're willing to download the CTP, you can. Whether that is permissible in your work environment is another story. 
Yea... No way I'm using this in a production environment yet
What's even worse is that .net 4.5 can't be installed side-by-side with .net 4.0 due to them both having the same version number v4.0.30319. Probably won''t even install in the office PC for a while till I'm sure code I write in visual studio using .net 4.0 on a machine with .net 4.5 installed is portable to machines that don't have .net 4.5 installed but have .net 4.0.
Be especially careful using this in production. We have found a couple different Microsoft updates actually break the Async CTP, at least they break it in the IDE and you can no longer build the projects until the updates are removed. http://social.msdn.microsoft.com/Forums/en-US/async/thread/c16a07a2-91dd-488b-a106-643c4310bf66
I tend to refrain from using AutoHotKey simply because its creation was unauthorized from AutoIt source code obtained unethically near the 3.0 release, specifically to remove the restrictions the AutoIt team implemented in order to keep their software from being declared a virus/keylogger/etc engine permanently. 
TCP sockets never drop data, you must be doing something wrong. Better place to ask these questions is StackOverflow.com. 
This is what I thought as well, I just have no idea where to look for the problem. Anyway thanks, I'll give StackOverflow a try. Edit: http://stackoverflow.com/questions/7780739/vb-net-asynchronous-sockets-packets-getting-lost if anyone wants to check it out.
There are simply too many things that *might* be wrong to start taking shots in the dark at it. If you can post a little bit more of your code, from both the client and the server side, I might be able to help.
[Here's the client code in PasteBin](http://pastebin.com/iLUmpeyr). It shows how the client connects to the server and then sends 100 messages in a For loop to the server. [And here's how the server handles the connection](http://pastebin.com/xiky5Hbe). I couldn't paste the full source as it's hundreds of lines long so let me know if it's missing any mandatory parts and I'll upload them as well. When the client connects to the server, it sends 100 packets to it but after I check what the clientPacket's value is, it only contains a few of those packets.
Let me be sure I understand what you're trying to accomplish. 1. You want a client app that will connect to a server and send *N* lines of text. 2. You want a server app that will accept connections from *X* clients. 3. As each client sends data to the server, the server should collect the data into a buffer for that client. 4. The server must respond to any client from its connected list immediately, even if it's waiting for data from other clients. Does that pretty well sum up what you're expecting your code to do?
This is exactly what I'm trying to do. The connections work fine so far, except when the clients send too many packets too fast. I mean, the server can already handle multiple clients and all that. The only problem is that the server cannot receive all the packets if they are sent too fast. I have no clue what could be causing this.
It looks like your problem is in the way you invoke BeginRead on the server: client.GetStream().BeginRead(New Byte() {0}, 0, 0, AddressOf Read, Nothing) That line is creating a new byte array to hold in the data that was read, but isn't passing the data into your Read method. Your read method is then creating a stream-reader for the client, which will continue to try and read until an end-of-stream: Dim reader As New StreamReader(client.GetStream()) Dim unparsed = reader.ReadLine() So you're actually using BeginRead, and then causing the child thread where the read work should be happening to block because of the creation of the StreamReader. Also, the StreamReader won't necessarily dump data into the string you're using to collect the messages until it "decides" its buffer is full enough to warrant a flush. Give me a few minutes and I'll write up an example of the way I'd implement it. 
(Sorry for the delay. Software deployment day at work, so I'm herding cats while I do this. ;)) These examples are in C#, because that's fastest for me to write. You shouldn't have much trouble following them. If you do (due to my coding style, lack of comments, etc.) just gimme a yell. Here's the [client](http://pastebin.com/sWqbbyVd) Here's the [server](http://pastebin.com/Rs8Eebhu) Hope that helps! **EDIT:** I also replied to your stackoverflow question.
Thanks a lot for this, it makes sense. I'll let you know in a few hours if I get it to work.
It took me a while, but I finally got it to work. It's still a bit unclear to me how it all works so I'll need to play around with it some more, but you sure cleared up quite a lot for me, thanks! Would you mind taking a look at my [server code](http://pastebin.com/qcqxvwsD) and see if it's all good now? (It currently doesn't handle any errors, I'll do that later.)
It looks good! Glad I could get you going on the right path. Feel free to ask if you've got any other questions.
Oh, one thing. Could you pop over to StackOverflow and mark my answer as accepted? Since I finally created an account, it'd make me feel good to have my first answer marked. ;)
Sure thing, I really appreciate all your help! This was giving me a headache, I just couldn't figure out what to do with all those callbacks and stuff. Now this all seems to be pretty easy, hah. **Edit:** Actually, I do have another question. Guess this isn't easy after all. If the client unexpectedly crashes, the only way to know it is by sending the client heartbeats and see if it replies, am I right? **Edit 2:** One more (sorry!). What I want to do is make the server constantly receive new messages from the client(s) and store them into clientPacket string. The problem is, when I add *Me.clientPacket &amp;= data* to the DataReceivedCallBack function, the program memory usage increases every single time I call that function even if there's no new data. Why does it happen?
I think you could have actually escaped this using a "literal" string, like so: [TestMethod] public void FailingTest() { var date = new DateTime(2011, 11, 11); var expected = "2011/11/11"; var actual = date.ToString(@"yyyy/MM/dd"); Assert.AreEqual(expected, actual); } Notice the @ in front: @"yyyy/MM/dd"
not sure how this is a 'gotcha'... it's exactly what the language says it will do. Create an instance of DateTimeFormatInfo, and pass it to your ToString(). using System.Globalization; //... var fmt = new DateTimeFormatInfo(); fmt.DateSeparator = "--"; var date = new DateTime(2011, 11, 11); Console.WriteLine(date.ToString("yyyy/MM/dd", fmt)); //writes "2011--11--11"
No, it isn't so. This behaviour is specific for DateTime format strings (and DateTime.ToString()) so string escaping doesn't change anything.
Well damn, now that I think about it, I think you're right. Props.
&gt; Now this all seems to be pretty easy, hah. Yeah, once you've got the concepts, it all becomes much clearer. :) &gt; Actually, I do have another question. Guess this isn't easy after all. If the client unexpectedly crashes, the only way to know it is by sending the client heartbeats and see if it replies, am I right? You can just check the "Connected" property. If it's false in the read callback, then the client TCP connection closed either due to the client calling "Close" or crashing, and you can clean up that client object. &gt; The problem is, when I add Me.clientPacket &amp;= data to the DataReceivedCallBack function, the program memory usage increases every single time I call that function even if there's no new data. Why does it happen? Well first of all, since you're collecting data your memory usage *must* increase every time you get data from a client. ;) I assume you know that, however, and are just surprised by how much it goes up every time. You're actually going to see an exponential increase in memory usage the longer the app runs, because strings aren't really meant for collecting data the way you're doing it here. Mostly, they're used to hold onto un-changing values that get referenced a few times then discarded. Every time you call *Me.clientPacket &amp;= data*, what's actually happening is that the CLR is creating a new String object that contains a copy of the contents of the old object as well as a copy of your data string, then "forgetting" where it put the old object and assigning the new String object into the variable. Even if *data* is empty, you still end up with a new copy of the clientPacket data in memory, and the old copy will hang around until the garbage collector decides it's time to clean house. (This could be a LONG time if you've got a lot of memory on your box.) As for what to do about it...well, there are a couple of solutions. If this project is just for learning, then you should be fine just leaving it as-is. If the application runs long enough for the memory growth to be a problem, then the GC will eventually get off its butt and remove all of those unused strings. What you should do for a real application, though, is to create some other storage mechanism for your data packets. A first pass might be to change the *clientPacket* variable from a String to a List. Then, instead of creating an ever-growing string with the full contents of your collected data, you can just drop the *data* variable into the list and ignore it; that way you won't be duplicating data every time you get a new message from your client. Then, when the client disconnects you can iterate over the list and do whatever needs to be done with the individual packets, whether that's concatenating them into a single large string, or just printing them out on separate lines, or whatever. **EDIT**: Typos
&gt; You can just check the "Connected" property. If it's false in the read callback, then the client TCP connection closed either due to the client calling "Close" or crashing, and you can clean up that client object. The thing is, Connected property always says True, not only on my version but yours as well. &gt; Every time you call Me.clientPacket &amp;= data, what's actually happening is that the CLR is creating a new String object that contains a copy of the contents of the old object as well as a copy of your data string, then "forgetting" where it put the old object and assigning the new String object into the variable. Even if data is empty, you still end up with a new copy of the clientPacket data in memory, and the old copy will hang around until the garbage collector decides it's time to clean house. (This could be a LONG time if you've got a lot of memory on your box.) Oh, never knew that, that would explain it. Would it solve the problem if I only called *Me.clientPacket &amp;= data* when new data is available? I'll have to try that.. Or I'll just do as you said and use the List variable. &gt; If the application runs long enough for the memory growth to be a problem, then the GC will eventually get off its butt and remove all of those unused strings. Well, I did leave the application running for about half an hour and the memory usage had increased by over 15 times. &gt; If this project is just for learning, then you should be fine just leaving it as-is. It's pretty much both; It's a real application as well as a good practice since I've never done socket programming before.
&gt; The thing is, Connected property always says True, not only on my version but yours as well. You know, I thought it was doing that on my machine at work. It's working as it should running under Mono on my macbook, though. Figures. :/ I'll have to play around with it some more; I know I've used direct Socket objects and had the Connected property work correctly, but I typically don't use TcpClient -- I prefer the extra control I get from a raw Socket. You might want to try that, actually. Use AcceptSocket instead of AcceptTCPClient, then directly read and write on the Socket object. Might make the Connected property work as it should. &gt; Would it solve the problem if I only called Me.clientPacket &amp;= data when new data is available? Eh...not exactly. It'll *improve* the problem, but the only way to eliminate it will be to use a list so you're not doing so a string concatenation every time you get new data. Honestly, though, unless the machine you're running it on is really memory constrained, it's not worth fooling with until it starts to be an issue in production. The memory usage *will* drop when the GC runs, it'll just continue to grow until the system thinks memory is "dangerously low", whenever that might be.
&gt;yoursite.com Completely unrelated to the content, I wish more people would adhere to RFC 2606.
&gt; You know, I thought it was doing that on my machine at work. It's working as it should running under Mono on my macbook, though. Figures. :/ I'll have to play around with it some more; I know I've used direct Socket objects and had the Connected property work correctly, but I typically don't use TcpClient -- I prefer the extra control I get from a raw Socket. You might want to try that, actually. Use AcceptSocket instead of AcceptTCPClient, then directly read and write on the Socket object. Might make the Connected property work as it should. From what I read on the Google, it doesn't work correctly. It changes to False *after* the program has failed to read or write to the stream. I don't know if it's true or not, but I'll give it a try anyway. &gt; Eh...not exactly. It'll improve the problem, but the only way to eliminate it will be to use a list so you're not doing so a string concatenation every time you get new data. Honestly, though, unless the machine you're running it on is really memory constrained, it's not worth fooling with until it starts to be an issue in production. The memory usage will drop when the GC runs, it'll just continue to grow until the system thinks memory is "dangerously low", whenever that might be. Sorry, that's what I meant (improve). I doubt it's an issue on the machine I'm using, but being the perfectionist that I am, I'd like it to not have the issue in first place. **Edit:** It's working great! Now I'll just need to think of a way how to store the received data efficiently. StringBuilder seems to be good. **Edit 2:** I got the data send/receive, StringBuilder and everything working except for the disconnect. If the client or server disconnects, it throws an exception so it's easy to detect the disconnect. But if I close the socket handle, the server/client starts to loop through the DataReceive function **Edit 3:** Apparently the server sends empty data to the client when it wants to disconnect, so reading the client's buffer for empty data tells if the server has disconnected from the client.
&gt; From what I read on the Google, it doesn't work correctly. It changes to False after the program has failed to read or write to the stream. I don't know if it's true or not, but I'll give it a try anyway. It's arguable whether or not that's a "correct" behavior. The MSDN documentation actually says that the status is only valid as of the last I/O operation. Meaning the application can't know the status of the connection until you try to read or write. Still, it should be updating, because the BeginRead method *is* attempting an IO operation, which means that if the client has disconnected, the property on the object should update. From your last edit, it looks like you've got it sorted out, though. =) Glad I could help, and happy programming!
&gt; It's arguable whether or not that's a "correct" behavior. The MSDN documentation actually says that the status is only valid as of the last I/O operation. Meaning the application can't know the status of the connection until you try to read or write. You're right, I should have said it doesn't work *as I wanted it to*. &gt; From your last edit, it looks like you've got it sorted out, though. =) Glad I could help, and happy programming! Thanks! I would've been so lost without your help.
There needs to be an article for this? Your ASP.NET app is a WEB APPLICATION. It's job is to service user requests. If you want to do back end processing that is not directly related to fulfilling current end user requests (batch processing, DB cleanup, ETL, whatever) then you have an application dedicated to dealing with that. Do not try to make them one in the same beast. It only leads to regret and shame. If for some reason you are stuck on some inflexible host then make a 2nd application to handle batch. This way some horrendous batch failure or long running processes does not suck resources from your end users (except for DB/IO contention which can be managed) 
I recommend the following [blog post](http://blogs.msdn.com/b/dotnet/archive/2011/09/26/compatibility-of-net-framework-4-5.aspx) for those who would like to learn about .NET 4.5 compatibility.
Better solution: Create a new IIS website with a url of http://static.yoursite.example and *do not enable ASP.NET on it*. Use IIS for what it's best at -- serving up static content. 
does someone just have some sand in their vagina...? No one assumes they know _every_ situation possibly faced by a web developer. I for one thank Phil for his post so that if i'm ever in a time of need, i'll know where to go.
blah blah, the article is fine and I have no problem with the content never said I did. It's a core best practice, just don't do this, if you have ANY other option do it DO NOT try and build heavy processes into ASP.NET (or any web stack front-end). Signed. A guy who has come across this very pattern and had to unwind the terrible. 
Can't wait to abuse the hell out of this at work!
Link to code on github: &lt;https://github.com/davidebbo/RoslynRazorViewEngine&gt;
crazy. can't imagine what I would ever use this for practically but it's gonna be fun to mess around with.
You can write your own code analysis rules and have them show up in the IDE. 
&gt;A guy who has come across this very pattern All the more reason someone needed to write an article about it apparently. Plus it's nice to read *exactly* despite being a more or less obvious anti-pattern.
That's so freaking elegant.
This isn't gotcha because the code has a bug in it. It should specify the culture info like here: var actual = date.ToString("yyyy/MM/dd", CultureInfo.InvariantCulture); Same thing with any other compare. If you don't specify the IFormatProvider you are going to shoot yourself in the foot.
Nobody tell him about false sharing.
I fail to see what that has to do with the concurrency abstractions discussed in the post. None of the standard concurrency abstractions address false sharing.
But they also exhibit it less than CAS-based lockless synchronization typically does. The kernel calls which back all other synch primitives never try to promise concurrent execution; they lock, but try to get out of that lock quickly. False sharing doesn't matter, since nothing is attempting true sharing. Consider these methods in terms of reading/writing to cache lines, and you'll see how concurrent execution could be prevented at the hardware level. I haven't spent a bunch of time with your code, but I did see that you handed off your thread-local structures in a way that would have them read and written by multiple threads. That makes them candidates for false sharing. Often a little memory padding is all it takes to fix, though. The other two main approaches to this involve either the usual unordered Monitor Enter/Exit, or explicit ordering and awaking everyone through PulseAll. If you're interested, post comparison numbers.
&gt; I haven't spent a bunch of time with your code, but I did see that you handed off your thread-local structures in a way that would have them read and written by multiple threads. The only thread-local structure accessed concurrently is the kernel wait handle, and this is never written, only read. The 'next' pointer of this structure is written by one thread, so you could pad the space between this and the wait handle, but so what? I'm not sure what this has to do with conveying the essential structure of the approach. It's merely an optimization. &gt; The other two main approaches to this involve either the usual unordered Monitor Enter/Exit, or explicit ordering and awaking everyone through PulseAll. If you're interested, post comparison numbers. Perhaps you don't realize, but Monitor uses almost exactly the approach I demonstrated in this article to implement locking. It uses a CAS to try to acquire a lock in the invisible object header, then spins for a bit continuously trying, then dynamically creates a wait handle to block the thread after queuing itself on a wait list rooted at the object header. The only difference is that my approach: 1. exposes this wait list to code to allow candidate selection to be overridden, 2. needs only create the wait handle once at thread creation, 3. makes the enqueuing process more rigourous to enforce proper ordering.
Automapper seems like it would get you into more trouble than it's worth. Post Sharp is cool but I've had performance issues with it every time I've tried it. The configuration section designer looks interesting but I'm not sure that stuff is as much of a black box as the article makes it out to be.
&gt; and you [I] want to know about No, I really don't.
Reflector is pretty awesome, I'm surprised it's not on the list. It's not free anymore ($35 these days), which is sad, but I (luckily) saved the old 6.8.2.5 version...
My services team uses Automapper and it is a royal pain in the ass. Besides the obvious question, "Why are you using Automapper instead of returning the ORM objects?", it tends to obscure the error messages. 
Automapper is useful for mapping view models to business objects (ORM objects). In fact for large applications, you really don't want to expose your business objects directly to the web layer. This is especially true for asp.net applications. Automapper works pretty well in this scenario.
Depends on where you define your business logic. Personally for UI rules I like to put them in the view model builder and handle the rules from the business object itself. Typically I'll map from a DAO to a business object, do my processing business rules on it and then perform the UI rules inside the view model builder. But that's my personal style, I'm sure for other styles automapper could work well.
You aren't making much sense. First of all, view models are never mapped to business objects, view models *contain* the business objects, a.k.a. the models. Now I can see the need for mapping a DTO into a Model for MVVM/XAML-style applications. In that case need to have rich objects that support stuff like property change notifications and internally validated objects. But ASP.NET? There is absolutely no reason to hide your business objects from you web layer. They are all within the same security boundry and presumably the service/data tier was written specifically for the web site. Now I will admit that I've seen people write "view-models" for ASP.NET MVC. Invariably they were a waste of effort, as a small tweak to the object they were getting from the service/data tier would have eliminated the need to create whole new objects. 
Other things... Don't use MVVM Lite, it leaks memory all over the place. (Even in places where the documentation specifically says it won't leak memory.) Don't create child view-models that get wrapped around every single object in a collection. Don't use shadow properties in view-models. (This is where you have a one-to-one mapping between properties on the view-model and some other model object.) Again, unwinding these is painful. Don't shove a bunch of UI logic into the view-model. If it deals with the UI, leave it in code behind. Don't shove a bunch of business logic into the view-model. If it doesn't involve a service call or UI element, leave it in the models. 
Yes I was using the term View Model to mean DTO or "view-model", however View Model is also a class that contains the business object and other data needed by the view. In the case of ASP.NET, it's useful to hide your business objects from the web layer, in particular if you are using asp.net mvc. In such a scenario you only want to expose those properties that are needed by the view and more importantly modifiable by the view. In asp.net mvc it's considered good practice to only model bind the fields you need (yes I know you can use an Bind exclude attribute). A smart use can try to overbind by passing in extra form parameters, a view-model can mitigate that. In addition, it also offers a nice level of abstraction in that view-models can accurately represent a view, even when that representation is somewhat different from a business object. 
As a services dev, I would still prefer to only give the controller, and thus the view, the fields it needs from be beginning. 
I agree completely. The problem lies in the fact that the model binder will try to find any field in the model. So if you expose the model directly to the web layer, even if the page doesn't have fields for certain properties you want to hide, a sophisticated user can still try to overbind by sending values to attempt to bind to those fields.
I'm just getting in to WPF and MVVM. If you don't mind a few questions, your response would be much appreciated. &gt; Don't use MVVM Lite Do you have a suggestion for a better/non-leaky MVVM toolkit? I'm using MVVM Lite and quite like it, but have noticed a slowdown in my program; at least on startup. &gt; Don't create child view-models that get wrapped around every single object in a collection. What's the alternative to this? I've not seen anywhere that addresses this and cannot think of a different way to handle this.
[dotpeek](http://www.jetbrains.com/decompiler/)
Looks more like an advertisement for #3 in the age of social media to me.
&gt; Do you have a suggestion for a better/non-leaky MVVM toolkit? I seriously doubt that you actually need a toolkit for MVVM. But lets say you do. What specific functionality are you using in MVVM Lite? 
&gt; What's the alternative to this? Smarter business objects and *not* insisting on zero code-behind. The vast majority of the time your UI elements are going to be data bound directly to the models. (The VM is just there to find those models in the first place.) Generally speaking there are four things I see in a view-model 1. Service calls 2. Formatting 3. UI Manipulation 4. Business logic Generally speaking service calls can be moved into the main VM. When you invoke the ICommand associated with them just pass the object to be saved as the CommandParameter. Formatting should be done with value converters whenever possible. If that isn't possible, considering having the model expose the formatted value directly. (I do this especially for calculated values like Entity.PointsAvaialble - Entity.PointsSpent). UI Manipulation doesn't belong in the view-model at all. A major reason for having a view-model is to make your code unit testable, which you lose if you have to build a UI. If you need to mucks with specific controls just use code behind. Business logic. This one can be tricky. If the logic is generic and not service related, shove it into the entities. It is only applies to the one view-model, that is to say other view-models using the same entity would be broken by the logic, then you are kinda stuck. 
In the common usage, a View Model has much the same role that a Controller does in MVC. They define the logical application layout. As a term, it really can't be used interchangeably with DTO/DAO, as those are just dumb versions of Model objects which can be used to communicate with services in a type-strict sort of way.
Moq FTW
HAH! Frameworks suck! They're all like, "Use me! Use me!" but we know they're just dressed up in fancy clothes because they have no redeeming qualities. They probably still live in their parents' basement! I mean, I've never seen one that could even dress itself! ... *re-reads the titile* OH! You mean it's a link to an article about .NET frameworks used to create testable mocks for interfaces. Boy, is my face red! ;) I'll give my actual opinion in another comment, since this one is off-topic. I just couldn't resist.
Agreed. And Machine.Fakes is my favorite interface into Moq. It's an excellent high-level abstraction around mocks that ties in nicely with the Machine.Specifications testing framework. Oh, and if you don't like Moq, Machine.Fakes supports several other common mocking libraries, including Winsor and RhinoMocks.
This presentation is actually pretty bad and not very informative. He uses an hour to explain things that can be understood by a ten minute read. If you're interested in this subject I'd recommend you look for better articles/presentations.
Thanks I'll have a look at that tomorrow. A new hire is nuts about m-spec, will ask him about it
I like to use Foo.Stubs as my abstraction layer around Machine.Fakes, though I have to admit that it isn't always abstract enough.
I suggest you post this over on Stack Overflow. You'll get a lot more people looking at that way.
&gt; I am willing to share the source code, if you like. I'd like to take a look at that.
It's really useful with ASP.Net MVC so you can map your ViewModels and model entities. Using the ORM entities directly with the model binder is just asking for trouble. It's also great if you are serializing data and don't want to send all the data in a instance by using DTOs.
Why are you fetching ORM entities? You can use LINQ to pull back projections that only contain the fields you need, and projections are not nearly so dangerous.
[This post](http://stackoverflow.com/questions/1509983/object-initializer) says that they're faster only in Debug mode. Definitely Lippert that said it? 
The smartest MVP I know told me he read this from Lippert's blog, so I believe him. I simply can't find the article he was talking about. He said something about the first option happening immediately in the stack.
That works on read but not on write. Also ViewModels can contain validation and other sorts of decorations (like field labels from resource file) as supported natively by ASP.Net MVC.
I am so glad I'm not the only one.
And now we are back to the question, "Why use ORMs?". Replacing the so called "object-relational impedance mismatch" with an "object-ORM impedance mismatch" doesn't seem like progress. 
Im not sure about the article, but taking the two examples and opening them up in ILDASM should give you an idea on what code is being generated
I'd be very curious if this is indeed the case. The "smartest MVP" can still have a poor memory, mind you. Or at least mis-remember things! Eric Lippert is often very subtle in his posts, no doubt.
Why? To allow me to easily get data from a DB without having to write all the plumbing and having to check everything as the requirements mutate wildly with rapidly approaching deadlines. Check out the MVVM pattern. it doesn't fit all cases like any pattern but it certainly has it's uses.
If you are worried about the performance difference between those two cases, then you are probably worrying about the wrong thing. **edit**: I just checked with ILDASM anyway, the IL generated by the C# 4.0 compiler is identical in both cases.
(apologies for the length - the source code makes this a rather long post) The IL indicates that this isn't true. Given the following source: using System; static class Program { class MyFoo { public String A {get;set;} public int B { get; set; } public DateTime C { get; set;} } static int Main(String[] args) { Attempt1(); Attempt2(); return 0; } static void Attempt1() { MyFoo foo = new MyFoo { A = "Hi", B = 1, C = DateTime.Now }; } static void Attempt2() { MyFoo foo = new MyFoo(); foo.A = "Hi"; foo.B = 1; foo.C = DateTime.Now; } } Compiling with full optimization results in the following IL: .method private hidebysig static void Attempt1() cil managed { // Code size 36 (0x24) .maxstack 2 .locals init (class Program/MyFoo V_0) IL_0000: newobj instance void Program/MyFoo::.ctor() IL_0005: stloc.0 IL_0006: ldloc.0 IL_0007: ldstr "Hi" IL_000c: callvirt instance void Program/MyFoo::set_A(string) IL_0011: ldloc.0 IL_0012: ldc.i4.1 IL_0013: callvirt instance void Program/MyFoo::set_B(int32) IL_0018: ldloc.0 IL_0019: call valuetype [mscorlib]System.DateTime [mscorlib]System.DateTime::get_Now() IL_001e: callvirt instance void Program/MyFoo::set_C(valuetype [mscorlib]System.DateTime) IL_0023: ret } // end of method Program::Attempt1 .method private hidebysig static void Attempt2() cil managed { // Code size 36 (0x24) .maxstack 2 .locals init (class Program/MyFoo V_0) IL_0000: newobj instance void Program/MyFoo::.ctor() IL_0005: stloc.0 IL_0006: ldloc.0 IL_0007: ldstr "Hi" IL_000c: callvirt instance void Program/MyFoo::set_A(string) IL_0011: ldloc.0 IL_0012: ldc.i4.1 IL_0013: callvirt instance void Program/MyFoo::set_B(int32) IL_0018: ldloc.0 IL_0019: call valuetype [mscorlib]System.DateTime [mscorlib]System.DateTime::get_Now() IL_001e: callvirt instance void Program/MyFoo::set_C(valuetype [mscorlib]System.DateTime) IL_0023: ret } // end of method Program::Attempt2 Same number of ops, same ordering, so the JITter should emit the same set of machine code and hence identical performance. Also, I checked against a debug build, and the method using initializer syntax is actually *longer* than the non-initializer method by a couple of instructions, primarily due to stack manipulation (so the debugger can have something to hang breakpoints off of, maybe?). 
It is often easier to mutate stored procs than an ORM. As long as you keep the API the same, you don't even need to recompile the appication. [+1 procs] When new columns are added, you have to change three places. The database table, the stored proc or ORM, and the model. [even] Except when dealing with bound reports. In that case you change the stored proc, hit refresh, and the new columns immediately appear on the screen. [+1 procs] This last one is huge for business applications where the users constantly want new reports. Where I used to work the BAs would ofen spend all day tweaking the stored procs for the reports, freeing the developers to do real work.
I mostly had CRUD scenarios so for reports you are certainly right. For read/write a view-model is certainly more useful as I'm binding to it.
Finally! The SDK is available, so now I can try to bring the Agent Smith plugin back from the dead again.
Export Settings! YES!
Hope it fixes the performance problems I had. While I love this tool I have yet to work on a project where I could keep it installed until the end; at some point the code base just becomes too large for it to handle and it slows everything down to a crawl. 
I did the same thing, http://www.facebook.com/v/10150317849661785 only difference is i used getpixel(), it's very slow for some reason ie 1 frame per second until i disabled aero.. i now get ~7fps, I may rehash my code now.. are you streaming to serial? ooh also what did you use to parse the stream.. i rigged up an arduino which works quite well!
Why would anybody use this over a queue? I understand making it thread safe, but you can already do that to a queue with the synchronized method. http://msdn.microsoft.com/en-us/library/system.collections.queue.synchronized.aspx All this does is keeps objects from garbage collecting longer than they need to.
From: http://blogs.msdn.com/b/microsoft_press/archive/2010/02/03/jeffrey-richter-excerpt-2-from-clr-via-c-third-edition.aspx And a great way to load your assemblies stored as resources: In ApplicationEvents.vb add: Private Sub Myapplication_Startup(ByVal sender As Object, ByVal e As Microsoft.VisualBasic.ApplicationServices.StartupEventArgs) Handles Me.Startup AddHandler AppDomain.CurrentDomain.AssemblyResolve, AddressOf LoadDLLFromStream End Sub Private Function LoadDLLFromStream( _ ByVal sender As Object, _ ByVal args As System.ResolveEventArgs) As System.Reflection.Assembly Dim resourceName As String = "YourAssemblyName_CaseSensitive." &amp; New AssemblyName(args.Name).Name &amp; ".dll" 'had to use this line to debug and figure out why it didnt load at first Dim resources() As String = System.Reflection.Assembly.GetExecutingAssembly().GetManifestResourceNames Using stream = System.Reflection.Assembly.GetExecutingAssembly().GetManifestResourceStream(resourceName) Dim assemblyData(CInt(stream.Length - 1)) As Byte stream.Read(assemblyData, 0, assemblyData.Length) Return System.Reflection.Assembly.Load(assemblyData) End Using End Function 
Better yet, gzip those dll's to save space: ref: http://blogs.msdn.com/b/bclteam/archive/2006/05/10/592551.aspx Imports System.Reflection Imports System.IO Imports System.IO.Compression Namespace My ' The following events are available for MyApplication: ' ' Startup: Raised when the application starts, before the startup form is created. ' Shutdown: Raised after all application forms are closed. This event is not raised if the application terminates abnormally. ' UnhandledException: Raised if the application encounters an unhandled exception. ' StartupNextInstance: Raised when launching a single-instance application and the application is already active. ' NetworkAvailabilityChanged: Raised when the network connection is connected or disconnected. Partial Friend Class MyApplication Private Sub MyApplication_Startup(sender As Object, e As Microsoft.VisualBasic.ApplicationServices.StartupEventArgs) Handles Me.Startup AddHandler AppDomain.CurrentDomain.AssemblyResolve, AddressOf LoadDLLFromStream End Sub Private Function LoadDLLFromStream(ByVal sender As Object, ByVal args As System.ResolveEventArgs) As System.Reflection.Assembly Dim resourceName As String = "YourAssemblyName_CaseSensitive." &amp; New AssemblyName(args.Name).Name &amp; ".dll.gz" 'had to use this line to debug and figure out why it didn't load at first 'Dim resources() As String = System.Reflection.Assembly.GetExecutingAssembly().GetManifestResourceNames Using stream = System.Reflection.Assembly.GetExecutingAssembly().GetManifestResourceStream(resourceName) Using memStream As New MemoryStream Using gzStream As New System.IO.Compression.GZipStream(stream, CompressionMode.Decompress) gzStream.CopyTo(memStream) End Using 'ref: http://blogs.msdn.com/b/bclteam/archive/2006/05/10/592551.aspx 'The data in the MemoryStream is not complete when ToArray is called before the GZipStream is closed Return System.Reflection.Assembly.Load(memStream.ToArray) End Using End Using End Function End Class End Namespace 
I'm very fond of [Jurassic](http://jurassic.codeplex.com/) as well, which supports Silverlight, as well as .NET 3.5 and 4.0.
I'd like to see the source. Nice work!
&gt; This is where we pick two random high quality parent monkeys from our population for a potential future monkey. So this doesn't seem to be the classic Infinite monkey theorem.
Well, if you haven't seen the [101 LINQ Samples](http://code.msdn.microsoft.com/101-LINQ-Samples-3fb9811b) I would recommend looking at those. And as always [StackOverflow LINQ-tagged questions](http://stackoverflow.com/questions/tagged/linq) are a good source of problems.
This article makes a poor argument. If the interface is implemented with both type parameters on one class, there will be two different implementations of each method in the interface. If both type parameters are the same for a given instance and one of the interface methods is called, which method is executed? C# seems to want to stay far away from undefined behavior, and it would be clumsy to add code to allow one to be chosen over another. Also, each time something like this is added there is a massive amount of thought and testing needed to make sure that it doesn't conflict with any other current or planned language feature. Even if there were a neat way to solve the problems, there have to be features with higher priority than this.
See the other reddit thread which addresses your concerns: http://www.reddit.com/r/programming/comments/ma7z6/type_unification_forbidden_more_cclr_irritations/
Looking forward to async!
What, nothing for F#??? It's the best part of Visual Studio. FYI, A lot of the stuff that's new in C# has been in F# for quite a while now.
Entity 4.5 * Enumeration Support. Finally! This is my biggest problem with Entity. 
Yeah, I read that just after I made the comment. I still think the point about compiler testing is a valid one. People from the compilers team have talked about the amount of testing that every language feature must go through in each of the official .NET languages, and the effect this has on the decision to add support for a given new feature. I've come across problems and inconsistencies in C#/XAML which I'd much rather have a fix for than this. That's not to say that other people don't have different priorities, but it does mean that not everyone is going to get their pet problem fixed in a reasonable time frame.
I agree there are plenty of more pressing issues with C#. I linked to a bunch of them in that article, and I have plenty more. This was just the most recent in a long line of frustrations.
Multi-diagram EF models, yay!
The poster says: **F# 3.0** Type providers. Query expressions (LINQ). Auto-implemented properties.
I guess the bitching from the F# community worked. :)
This is not the answer you are looking for but Roslyn is Microsoft's solution for .Net compilers used as services. I have doubts it works for Iron Python. http://msdn.microsoft.com/en-us/roslyn
I have actually been following Roslyn, but it doesn't seem like it has code window components I would be able to use in my own program. I could certainly write something myself, using reflection and what not, but I feel like this is something somebody else should have attempted by now.
Given a string[] of the lines of the following string Jeff,2 Eric Ron Ron,1 Eric Sue,2 Olaf Jeff The format is the following, repeating as necessary Name,Number The person "Name" is accusing the following Number lines of people as being criminals. Using the string[] of lines, in one linq chain, print out the person's name, a comma, then the number of times they themselves were accused; ordered by count desc, then name asc. Remember, even the print must be in the chain. Also it must be forcefully evaluated. I have the solution if you need it :) **NOTE: This is for practice. Don't fucking do this in production code. You will learn a ton.**
I recently saw an example of how Roslyn allowed the new VS2011 C# code window. I doubt it's an from-the-shelve thing but it seems to make it possible.
[Actipro](http://www.actiprosoftware.com/products/dotnet/windowsforms/syntaxeditor/default.aspx) SyntaxEditor has support for python.
wow. $350 for a license is pretty steep.
If it's just for a personal app, sure 350 is a lot of money. But if you look at what they offer and how long it would take somebody to build something with an equivalent feature set, I think 350 is incredibly cheap for a commercial application. If all you are looking for though is syntax highlighting you could probably port something like [highlight.js](http://softwaremaniacs.org/media/soft/highlight/test.html) to C#.
You're right, if I push out 35 copies at $10/each, that would more than pay for itself.
Stack overflow is a much better site for stuff like this.
Probably, but I thought I'd ask around here as well.
You don't want to do this. Remember SRP. Sounds like you need one hardware class, which could be a singleton, and another which mediates between this and the outside world.
I don't think I'm familiar with SRP. Or, at any rate, I don't know the acronym.
It is short for "single responsibility principle" and usually means "I don't like what you are doing, but I can't be bothered to give a real reason why".
Odd. What I'm trying to do doesn't actually impose any other responsibilities on the object, so I guess I don't see what he was talking about.
And now you know why I directed you to stack overflow. Reddit is great for philosophy and blowing off steam, but not for getting work done.
YAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY!
MVVM in WPF is a gateway drug to Prism/Unity.
IMO, official documentation is no place for sarcasm (e.g. " But if we’re going to play that game, C# is technically unnecessary. You could write all that code in IL. ")
custom control structure implementation is probably not the best way to introduce people to the language how about giving a logging implementation as an example of usefulness of pass-by-name ?
Bind: In other monads (not identity) Bind can elect to do other types of things before/after binding to the next function. ToIdentity: This is not a class method. This is a static extension method that lets you turn any value into an Identity encapsulated value. So instead of this: new Identity(3) You can say this: 3.ToIdentity() 
LINQ *budam chish* /jokes I know there is no LINQ in Scala (some similar libraries exist)
Yes, imho LINQ should be covered. It looks like this in Scala: persons filter (_.age &gt;= 18) groupBy (_.lastname) ... I guess the main thing to mention is that the naming is different, while Scala (map, filter, ...) stayed close to the original, C# invented its own naming (select, where, ...).
What's even better is when a contractor does this, and nobody touches the code for 4 years. Scumbag developer... uses unmanaged resources in a sealed class, doesn't implement IDisposable...
Add more RAM!
And yet that's better than some of the code I've come across in my day, like the "if/else substitution" try { if(!some_condition) throw Exception //do something } catch { //do something else } Or this genius use of rethrowing bool doIt() try { try { if(!some_condition) throw Exception() //code that could also throw exception } catch(Exception ex) { throw ex; } //Repeat above code seven or eight times catch (Exception ex) { throw ex; } return true; } try { bool success = doIt(); if(!success) Console.WriteLine("Generic error message") //Not that success will ever be false.. } catch(Exception ex) { Console.WriteLine(ex.Message) } 
That made me cry a little
I've seen this in our legacy code many times, and I rewrite it immediately, even if it's just to capture the exception content to a logger. The bastards who wrote this mess aren't employed here anymore so I can't punch them in the throat for doing it.
adds GC.Collect But doesn't realise the reference is still used and not disposed of.
Sometimes you do just want to catch the exception if only for logging. Simply pass the exception object to Log4Net or something to that effect.
Resharper will tell you that success is always true :D
Actually, resharper didn't in this case (the code was actually from a programming assignment for hiring people in my company), but then I also only wrote the gist of the doIt() function. In reality it did create a variable for the return value and then assigned it depending on conditions and returned the variable. It just so happened that all code paths that would return false also threw an exception.
Scumbag programmer... ---------------------- Architecture attempts to separation concerns... Puts all code in code-behind events. ------- Has utility method to reduce code reuse.... Copies code to five different places. ----- Is tasked to fix a bug... creates three more. ----- Doesn't understand architecture or technology... Tosses code, rewrites entire feature. ----- This could go for a while. 
Probably won't go on as much as "Scumbag Users" :p
Or "Scumbag SME"
The one time I've seen a legitimate use of a empty catch block is for logging in your "last-chance exception handler" (e.g. ASP.NET Application_Error). For example: void Application_Error(object sender, EventArgs e) { try { Logger.Log("some error details"); } catch { } } Otherwise you could end up with infinite recursion if your logging method throws for some reason.
Scumbag programmer... Doesnt want to write the same code twice. Makes socket responding application in VB for production code instead of using the companies existing C# WCF services. - No shit my lead developer did this.
or doing something trivial with it, like only logging it or something.
I believe if an exception occurred in the catch on Application_Error it would not raise the event again but would generate an ASP.NET application error that would get logged into the event log. Not 100% certain but I believe that's how it works.
The stupid logic seems to be "I don't want my program to crash just because it's can't read this critical file". I ask them how the hell the program is supposed to continue without critical data... Jezzz, just let it die in those cases. I want a big ugly error to bubble up to logging or at worst to the end user.
[RemotingServices.Marshal is what you're looking for](http://msdn.microsoft.com/en-us/library/system.runtime.remoting.remotingservices.marshal\(VS.71\).aspx)
I honestly can't think of a time where I would prefer to use string builder over string.format or string.join...
I'll call it the Pokémon anti-pattern. Gotta try-catch'em all!
where I work, most of the bugs were written by ghosts, contractors who came and left, and didn't even bother to leave an email address in the comments.
"Catching exceptions is for communists" - Source unknown.
So it is! Bless you, my son.
Considering that LINQ stands for Language INtegrated Query, and in SQL those are the keywords used, I sincerely question your assumption that C# "invented" the naming scheme, and that one is more correctly "original" over the other. I doubt even the zealots of functional programming would claim that SQL stole all its ideas, and is forever in its debt.
Probably Larry Wall
The ITask interface already exists in .NET. It is called Action and has one method named Invoke. And since it is a delegate interface rather than an abstract interface you get syntatic support as well.
The original idea of providing such monadic transforms comes from Haskell. Just count how often the LINQ paper mentions Haskell.
I love the Action and Function delegates. They make my world go round.
Language INtegrated Query. Not Language INtegrated Haskell. The goal and ideas came from SQL, and they implemented it similar to Haskell.
Can you expand on this? Action is just a delegate. I've never heard of anyone talk about such a thing as a "delegate interface". How would using a delegate like Action be akin to implementing an interface? 
First a note on terminology. An "interface" is just a contract via which one piece of code invokes another piece of code. An "abstract interface" is a special type of interface in .NET and Java that other types can explicitly implement. Another type of interface one should think about is the "public interface" that all classes expose. That's the one that is important here. Action&lt;T&gt; is in many ways just a normal type. It inherits from System.Object and exposes methods such as ToString and GetHashCode. But it also exposes what I'm calling the "delegate interface", which in the case of .NET 4.0 is a public interface that includes the methods "Invoke", "BeginInvoke" and "EndInvoke". Now it is true that the delegate interface is neither abstract nor polymorphic. But that's ok; we have other ways of achieving reusability such as composition. Or in other words, one simply creates an instance of the delegate and populates the properties Method and Target instead of creating a subclass of some abstract interface. Going down the list: * TaskNull changes from a type to an instance of Action. * TaskComposite is essentially a mutable version of MulticastDelegate, which is fine because Action also inherits from it. * TaskPredicated is simply becomes a factory method that accepts a Func&lt;bool&gt; and an Action instead of a constructor accepting Func&lt;bool&gt; and ITask. The one place where delegates really fall down is when you want something that works across a variety of different delegates. For example, something that caches the results of Func&lt;TResult&gt;, Func&lt;T1, TResult&gt;, and Func&lt;T1, T2, TResult&gt;. This cannot be done with delegates, though really it doesn’t work with abstract interfaces such as ITask either. P.S. I know that I'm wandering into some pretty esoteric stuff, but I really do believe that it is important to understand that the concept of interfaces is not limited to Java/.NET style abstract interfaces.
Maybe this is bad programming practice, but I use empty interfaces as metadata, especially for doing game design. like this. public interface Tag_Destructable {} public interface Tag_Flotable{} public interface Tag_AffectedByPhysics{} public interface Tag_Pickup{} Then I have my abstract base entity class, and other game classes public abstract class BaseEntity { ... } public abstract class BaseEnemy : BaseEntity { ... } public HealthPack : BaseEntity, Tag_Pickup { ... } public VolatileHealthPack: BaseEntity, Tag_Pickup, Tag_Destructable { ... } public Groundling: BaseEnemy, Tag_Destructable,Tag_AffectedByPhysics { ... } public Flyer: BaseEnemy, Tag_Destructable { ... } In my game loop, I can do something like this. var pickups = (from x in entities where x is Tag_Pickup select x as Base Entity); And in my game editor, I can use reflection to catalog by tag. 
I'd say it's a bad practice (that's what attributes are for) but for game development (almost) everything goes when performance is a priority. It looks better than checking for attributes, I give you that. ;)
I may be misunderstanding you but you should read up on ASP.Net *MVC* which is where cshtml files come in play. They can cohabit with aspx files no problem but to make them work you need a controller. In ultra-short: an ASP.Net MVC page's lifecycle starts at a method (the action like "View(int id)") in a controller ("books") that handles the request parameters ("id") and does the data fetching before switching to the view (you cshtml). Unlike ASP, there should not be any business logic in the view. First you fetch and process data, then you show.
Yeah, no, I love the MVC way of things. Problem is, porting our classic ASP to ASP.NET (in the form of single .aspx files) isn't going to go that route. It's going to be pretty tough to get everyone switched over to something like MVC, so I'm trying to find something else (preferably in a single page format, unlike MVC) that will make the transition easier. Does that make sense?
Am I the only one who doesn't considering changing the extension to be "converting" from Classic ASP to .NET?
You could use Razor pages with Asp.Net Web Pages. It's much closer to the single page model of ASP than Web Forms. Mvc and Web Pages can work side-by-side in the same application which means you could consider creating new pages in Mvc if you feel like it. Of course unlike the Web Forms "conversion" you are attempting to do now, converting plain ol' Asp to a Razor page would be more involved.
You're going to have to rewrite a lot of things, my friend. God-speed to you!
Eh, if it was just me it wouldn't be a big deal.. but it's not.
Problem is, it's not just me. I'm super flexible and can switch between things simply.. other people, not so much. So I'm trying to find the easiest, least friction solution for the conversion, and then pages going forward.
Regardless of whether you go with standard ASP.net WebForms or go with ASP.net MVC with new pages, you will have some bad habits to overcome. Make sure you are using the separation that ASP.net offers and make the "views" (i.e. the aspx pages) as "dumb" as possible. Where classic ASP mixed markup and logic, you want to avoid that as much as humanly possible in ASP.net. Keep your business logic in your code-behind files / controllers / or even separate BLLs. And make sure you understand the full page lifecycle in ASP.Net and use that to your advantage. If you don't do this, you might as well stay with classic ASP and just keep referencing external DLLs to do the "fancy" stuff. [edit] Also, if you want to stick with WebForms instead of MVC, but you like the separation that MVC offers, you could use a design pattern called [**MVP**](http://msdn.microsoft.com/en-us/magazine/cc188690.aspx) with webforms.
Feel free to PM me if you have any questions. I've rewritten quite a few classic asp sites to asp.net webforms/mvc.
I disagree. If the other devs are used to classic asp with VBScript (assumption), going in to razor and mvc would be a much better route than a Web Forms conversion. At least they wouldn't have to learn all the nuances of the web controls and the whole event-based postback debacles. I would also assume they would know enough about html markup to know how to create their own partials and controls.
It's not just me, though. There are several others here and getting them up to speed isn't going to be the easiest, which is why I'm looking for something similar to classic ASP but running on .NET.. the only reason we're switching is some new software we're getting requires .NET to work on the web.
As the OP said, the way they are converting the classic site is by simply renaming the extension to .aspx and correcting errors. I assume this route does not involve controls, just emitting strings via Response.Write from your page. Not saying that's correct, but it certainly is a lot less work than rewriting it using Razor.
Then, I would say just run your ASP pages side-by-side with ASP.Net instead of "converting" them. Then, build new pages to consume the new .Net library you're getting and use the best-practices with the ASP.Net pages. That way everyone doesn't need to be perfectly up to speed at the same time. Then you can take the time to get everyone on board properly to the ASP.Net way of doing things. This is the eventual ASP -&gt; ASP.net migration strategy that [Medicare.gov](http://www.medicare.gov) is doing. 
Oh, here's the rub. The old pages are what need the library.
If you make the library in .net and make it COM friendly you can call it from ASP. Best of luck. I wonder if your best course of action should be to seek a better colleagues.
Tricky, tricky. If the library is being used to render or build content just used in the classic ASP pages, you could build an ASP.net page that consumes the new library and does a partial render, which you could pull into your ASP page. Also, there are ways for ASP to consume libraries built in ASP.net (building and registering a COM wrapper for the ASP.net library). Pulling in legacy ASP into .Net pages with developers that are not willing or incapable of adjusting to the .Net "way of things" is just going to cause you maintenance headaches. I went through the exact same thing you're going through at my last job. The last 14 months I was there, I was working to help migrate web applications from ASP to ASP.net as part of a huge team of developers that mostly only knew ASP. Fortunately, they were willing to learn and caught on pretty quick with the help of some regular, informal training. Honestly, I think getting buy-in from management and doing brown-bag type presentations on .Net might serve you better than any of the bending over backwards to make sure the "new stuff" is as close to the "old stuff" as possible just to appease the developers. 
Well, only you and every other sane person in the world, which I like to fantasize includes me as well. After having just read this (or hopefully imagined I did), I'm experiencing newfound doubts on that score however. Edit: Ah yes, [this guy](http://www.reddit.com/r/dotnet/comments/mlh9o/converting_classic_asp_to_aspnet_got_some/c31w37t) probably got the explanation right. I'm oddly proud that I didn't even consider that option.
It's time to man up and learn some new stuff, otherwise you and your team will get dinosaur'ed out of existence. This is tech, where 2 years old is ancient, and 10 years old (classic asp) belongs in a museum. If your team has trouble adjusting to a new programming language/environment you're in big big trouble. I don't know if this is your company, or if it's a small/big one, if your boss is a dick or your fellow employees are unexperienced... but if they are absolutely unable to adjust to new technology they don't belong in this line of work. In any case, if you're moving your operation over to .NET then at least take a week off to allow employees to learn about the new system. If that's not possible, assign a small team to work on the conversions and have them learn what's needed. Good luck, and enjoy .NET, you will love it once you get to know it. Edit: If it's a one-time-thing (rewrite and never touch it again) consider hiring a contractor for the work. there are plenty of good .net programmers out there.
I &lt;3 log4net!
Your best option would be to go with one of the tried and tested paths, such as webforms or mvc. You'll find the most help and best communities surrounding these paradigms. BTW community is an area where asp is noticeably lacking. I think that should help incentivize your team. It sounds like your team is overwhelmed by the task of conversion because they see it as one big task. I'd recommend coming up with a plan. Break down your application into functional groups, such as these pages all deal with CRUD for the same entity. Will you need database support? Entity framework is worth a look. Will your users need to login to the web app? Will you need forms-based or windows-integrated authentication? What about permissions? These are common aspects that you have to do yourself in asp. In .net there are common solutions to these issues with lots of community support. Lastly there are lots of open source asp.net apps out there. If you're stuck on a problem you can always download some open source web apps and learn how they solved the issues.
Putting .aspx on the end of a file doesn't stop it being classic ASP. Classic ASP should be considered as a page littered with VBScript or similar. Consistency is the key in any project. Dancing between classic ASP, ASPX and CSHTML will be confusing and end up on the daily wtf if you're not careful. Maybe it's better to think whether or not you really 'need' to use ASP.Net, or whether your time is better spent on something else or rethinking the solution using MVC or another such framework?
Have you looked into [this](http://aspclassiccompiler.codeplex.com/)?
They should rename the goals to something other than achievements or put quotes around the word. A disturbing number of the achievements promote some really stupid practices. I'm pretty sure the jokes on me though. Certainly no one is going to actively attempt to gain these achievements on a serious project.
The idea is from games where you can earn achievements. Some of those achievements can be silly (e.g. fell 30 feet or more to your death).
I prefer this list of Achievements. http://www.reddit.com/r/programming/comments/f8phd/what_if_visual_studio_had_achievements/ And Channel9, MUST reference the original link!
I realize where the idea is from, my gripe is how the achievements seem to be promoting some pretty stupid practices. * Use of the goto keyword * Write 20 single letter class level variables in one file. * Write a single line of 300 characters long Granted, the above 3 I mentioned aren't worth any points and many could be earned along the course of developing some large project, but it doesn't bode well what their future achievements will consist of with considering what made the list currently.
Care to explain why you don't want to use WCF for this?
Because at the moment, I can't. The system involves custom external hardware, and the connected PC (which can't be updated by orders from on high) doesn't have anything higher than framework 2.0 installed.
Coming next: Bring all your achievements to the interview process!
Ok, that makes sense.
Elmah - enough said.
based on that post I posted a question on this on the [programmers stackexchange](http://programmers.stackexchange.com/questions/39990/should-an-ide-include-a-gaming-element) a while back. Didn't really take off.
Absolutely awesome. My scripts are currently minified on build using an external program, but that can cause issues with certain scripts being combined (e.g. Jquery and nicEditor which both use $)
I have to agree. These seem more like a joke. I could think of a dozen that would promote good practices and actually mean something. 
Most of these should give the programmer an electric shock for being so stupid.
Additionally, the new Task Parallel Library has a Task class. Having an ITask interface in use could confuse the intent of what is meant by a "task".
You could search for SQL query practice problems and do them entirely in LINQ. 
Why not have a Tags enum? var pickups = (from x in entities where x.Tags.HasEnum(Pickup) select x as Base Entity); 
because at some point down the line, if I decided Tag_Pickup needed to implement some methods, say... OnPickedUp or GetRespawnTime, it would be easier to refactor Tag_Pickup to IPickup. 
Hard to argue against that.
There's also [Strokes](https://github.com/jonasswiatek/strokes).
Ads on the asp.net site? What are they thinking? Why the nickel and dime microsoft?? 
Looks like a pretty cool tool. Is there a demo version to try?
There's a 60 day free trial - click download button on www.bugaidsoftware.com
I'm pretty sure resharper helps protect against this but I did not remember to investigate why last time it hinted at this... Thank you. 
Thank you, I missed it the first time around. Installed and trying it out now.
Are you aiming for Webforms or MVC? aren't .cshml for MVC3?
I converted an WebForm project to an MVC3 project. The conversion was not that hard. I crated a new project, then copied over the file and assembly references. The new project was ready to go and I had my web form files working side by side with mvc files.
[relevant](http://www.reddit.com/r/programming/comments/mz6wh/phps_justification_for_not_including_finally/)
My favorite: TestDriven.Net If you are using NUnit, it makes it so easy to right click on the test and say "run in debug"
I've heard so much about Reflector and how great it is. However, by the time I got around to looking at it, it was no longer free. Out of curiosity, when you find yourself using this tool? In my 6 year career as a .Net dev, I never had to decompile another assembly. I'm I missing a better way of something something?
Best article I've seen on reddit in quite a while. Thanks!
The only thing I see is you gotta pay for it. Which defeats the purpose IMO. Pay for good devs and you don't need a machine telling you trivial shit.
If you have Standard or Premium VS2010, you can download it [here](http://msdn.microsoft.com/en-us/devlabs/dd491992) for free.
Greg's talk on [DDD, CQRS and Event Sourcing](http://www.infoq.com/presentations/Events-Are-Not-Just-for-Notifications) is quite interesting too.
Yet the video says nay to professional? 
This is true, once you pay for VS2010, you get it for free. I think this is the same with Pex too. If this interests you, [Spec#](http://specsharp.codeplex.com/) might be of interest to you.
If I have to pay for a compiler to tell me their problems, while all along we have the tools to weed them out, then yes it is trivial shit.
&gt; This is true, once you pay for VS2010, you get it for free Free what? It said if you **pay** for pro, you get nothing. That is why he had to do the demo on someone else's machine. This is thee primary example why MS just doesn't get it. Damn I've been a supporter for a while, but this is just pathetic. "If you don't shell out an extra $5,000, your $15/h workers won't be great!"
Cool stuff, but the guy giving the presentation is coming off more like a used car salesman than a technical presenter. *"How much do null reference exceptions cost your business?! How many CPU cycles are being wasted checking for nulls?!"* Yeah, we get it asshole.
Jesus, we get it...you LIKE RESHARPER....
That's because he worked in high-frequency trading for a bit, so null reference exceptions probably cost a whole lot more than you would think
Who doesn't?
This guy is very technical. More than me and probably more than you. As for this "asshole", using ad hominem attack doesn't really grant you the higher ground in this kind of argument. 
Seriously? This is Microsoft Research. It's never been approved for production environment. Those are the kind of tools you will find in future product. If they say it requires a specific version is most likely due to a lack of functionality in the version of the IDE. They are not saying "pay $5,000 and you get the tool". What they are saying is "here is what we can do with this tool but for now it only work in VS2010 Ultimate and Standard". What are you expecting them to do? Modify VS2010 just for a Research project? If the project gets roots and interest, it will be in all versions of VS.
Why the is "standard" less than "professional"? That's retarded and one of the biggest criticisms against Microsoft. We pay thousands of dollars for these tools but they always want more. Microsoft has become Oracle! It is just like the resharper comment. How can a developer deal without paying thousands for our product and still survive when they could be paying hundreds more to make it 'easier'? Money, money money, and no substance. 
I think their headline "dethroned" is a bit dramatic and over-stated. But it is interesting that C# has steadily grown to the point where it will soon surpass C++ in this well-known index.
&gt;Money, money money, and no substance. That's the way the world spin. Beside, you don't need to use MS's platform. There are a lot of alternative to MS's stacks. Also, if you work on the MS stacks. You already made enough money to cover the cost. Either way, it doesn't really matter.
Who prefer CodeRush.
Other videos of Code Contracts. http://channel9.msdn.com/Events/PDC/PDC08/PC49 http://channel9.msdn.com/Tags/code+contracts And look at PEX tool. (Automated unit tests) http://www.infoq.com/presentations/Pex-and-Moles http://channel9.msdn.com/Tags/pex 
...and soon after to be dethroned by Objective-C. The hockey-stick-like curve of the chart reveals our future with IOS.
Someday if you are given a Microsoft-based project, spending $1000/year will give you all of their software (MSDN Premium) with unlimited dev licenses and 3 production support tickets, which isn't a bad deal. I always wonder about developers who never buy any tools. I get the whole open source thing but sometimes there are great products to use which aren't free (like Visual Studio).
Code contracts should be expressed declaratively as much as possible. It shouldn't require three lines of code just to say parameters x, y, and z cannot be null. Instead we should have attributes for all of the common cases. The second problem is the utter lack of support for reflection. There is no way to programatically determine what contracts apply to the public API on a class. The third problem is that it is an all or nothing proposition. Because contract violations crash the application you cannot safely mix contract and non-contract code in the same program. Had they choosen to use standard concepts such as ArgumentException and InvalidOperationException this wouldn't be a problem. In short, the design of this is just plain wrong. They need to go back to square one and rethink how contracts should be expressed and enforced. 
&gt; Code contracts should be expressed declaratively as much as possible This would prevent invariants and contract requires/assures from containing complicated logic. &gt; utter lack of support for reflection. &gt; no way to programatically determine what contracts apply to the public API on a class The trick here is to use the ContractClass and ContractClassFor attributes between the Interface and the abstract container class. &gt; you cannot safely mix contract and non-contract code in the same program. Generics can be used for runtime generation of specific exception types when pre/post conditions fail. [This](http://channel9.msdn.com/Blogs/martinesmann/Code-Contracts-and-Pex-Power-Charge-Your-Assertions-and-Unit-Tests) long video addresses many of your points. If you don't have ~2 hours to kill, [here](http://download.microsoft.com/download/C/2/7/C2715F76-F56C-4D37-9231-EF8076B7EC13/userdoc.pdf) is the user documentation, although I do suggest at least trying out the video first. ** On aside: check out [CQRS and Event Sourcing](http://distributedpodcast.com/).
&gt; This would prevent invariants and contract requires/assures from containing complicated logic. I said "as much as possible", I did not rule out offering both. &gt; Generics can be used for runtime generation of specific exception types when pre/post conditions fail. But that's not the default, so if you miss one place you are back in the pit of failure. We don't don't even need the full power of code contracts. Just basic support for nulls would dramatically improve the base line code quality in languages such as C# and Java. I know MSR is just doing research, but someone on the primary teams needs to start delivering stuff we can use today.
Code Contract support is baked into the .NET 4.0 framework, production ready. Things like: public int GetRandomFromRangeContracted(int min, int max) { Contract.Requires&lt;ArgumentOutOfRangeException&gt;(min &lt; max, "Min must be less than max"); Contract.Ensures(Contract.Result&lt;int&gt;() &gt;= min &amp;&amp; Contract.Result&lt;int&gt;() &lt;= max, "Return value is out of range"); return _generator.Next(min, max); } ..looks to be quite useful. Another good article on it is [Here](http://devjourney.com/blog/code-contracts-part-1-introduction/). Try to learn more about it before you make up your mind.
I've used it extensibly in the past and I am talking from experience when I say that the patterns for the normal use cases are far too clumsy. Sometimes you need to imperative contracts, but the vast majority of the time they are over kill. 
But I admit that you have kicked me enough to try it again.
ha. You might get a kick out of the "Emit contracts into XML doc file" feature and automated Pex TDD tests.
Not sure why you're being downvoted. If the trend continues, that'll be the case in only a month or two. Assuming the same growth next month as the previous month (i.e. no further acceleration for either language): C#: 8.205% + 1.52% = 9.725% Objective-C: 6.805% + 3.56% = 10.365%
On a side note, I thought a decent amount of people actually use Mono to compile natively on iOS? I recall hearing an estimated 10% of developers on iOS or something like that. I still feel like if Windows 8 does well, and a lot of people are saying it's a nice platform relatively speaking to develop for touch, C# (or VB.NET if that's your thing) will still be the best .NET language since it's basically like the C#/WPF we already know (even though MS keeps harping on HTML5/JS). 
What exactly are you trying to accomplish? Are you talking about getting data from business objects through a data provider + ADO?
Yes. I'm talking about the specifics when developing a 3-tiered .net application (presentation, business objects, data access layer)
Check out the repository pattern.[Repository Pattern](http://martinfowler.com/eaaCatalog/repository.html) along with [Entity Framework Data Annotations](http://msdn.microsoft.com/en-us/library/gg197525(v=vs.103).aspx). I currently use CodeSmith to generate all of the code, but T4 templates would do the job as well.
Ok, so you're asking about just how to do a multi-tier design basically. And I find that any multi-tier design that involves a database usually needs to start with a discussion around technology first. I guess if you haven't read about [Object-relational mapping](http://en.wikipedia.org/wiki/Object-relational_mapping) (or just ORM), then you'll probably want to start there. Using an ORM technology is a very typical way to start these days, though it's not really mandatory. So, if you have a design where the ORM gives you objects that sit on top of the database tables, views, stored procedures, etc. that can form your database access layer (DAL). While the DAL is largely going to be generated, you can also have custom code in here as needed to deal with anything your ORM generator or templates cannot handle. Then an ORM can also give you some basic business level class stubs as well. These classes are typically going to have your custom business logic in them and they'll normally consist largely of the code you've written. From there, the basic idea is that your user interface tier will talk to the business objects. The business objects will talk to the database. And everyone is happy. :) Well.... almost. Because there are many other considerations that go into multi-tiered architectures and many considerations that go into choosing an ORM, knowing how to work with it, etc. It's a multi-faceted set of decisions that encompass business domain, security, performance, scalability, etc. There are a lot of ways to screw this up, so if you're just learning about this for the first time then do yourself a favor and study something like [CSLA](http://en.wikipedia.org/wiki/Component-based_Scalable_Logical_Architecture) to get some exposure to the issues. As for actual tools, I think the easiest way to start playing with these ideas is to just ramp up on an ORM technology and play with it. My long time favorite .NET ORM is [EntitySpaces](http://www.entityspaces.net/Portal/Default.aspx). Microsoft is currently backing Entity Framework and that's a good choice as well. I think [Telerik](http://www.telerik.com/products/orm.aspx) makes a good one too, but I haven't used that one, though it does look nice. CSLA apps typically use CodeSmith with the provided CSLA templates. CSLA isn't as popular anymore, but the books around it really provide the best discussion of all the issues that I've seen. Anyway, PM me if you really want to seriously drill down on this and explore options. 
I've heard of entity framework but haven't learned it. I know about ORM. I guess I should ask, is writing the DAL myself and all the stored procedures/sql to communicate to the database a waste of my time? Does ORM still lead to good application development but with faster time to value?
I'm currently using Petapoco for small projects. Its fast and I haven't been able to fault it yet. It even has a T4 template to make your POCOs. http://www.toptensoftware.com/petapoco/
Treating data access as a layer is a bit old school imho. Think of your business entities as shared contracts between your data access services and application services.
Probably is a waste of time. There are simpler ORMs out there than EF or Nhibernate. Something like Dapper may be more appropriate
MVVM has nothing at all to do with Entity Framework or Enterprise Library/Unity. MVVM is just a way of dividing up the UI silo. Aside from making the view-model the one-true-place for putting hooking together the front and back end it says nothing about how data is actually accessed.
I like the two-silo approach. In silo one you have either MVC (web) or MVVM (WPF/Silverlight). In silo two you have your choice of ADO+stored procedures or ORMs. (I think ORMs are only appropriate for trivial work, but many will disagree with me.) At the top of silo 2 is your "repository interface" with methods like "LoadCustomer(int)" or "SaveCustomer(CustomerModel)". This should all be run through whatever integration tests you can muster. Returning to silo 1 we have the "models" which are fully unit tested business objects. Then we have the "controllers" or "view-models" which have access to the repository interface. These are harder to unit test because they need mocks of the repository, but it can be done. In diagram form View | Controller/View-Model &lt;-------&gt; Repository | | Models ADO or ORM or Web Service What's really nice about this pattern is you can easily divide the work between front-end and back-end developers. 
Writing the DAL yourself will probably be a waste of time from a productivity standpoint, but would be a good learning experience and give you an appreciation for what a good ORM will provide. It will be fairly time consuming though to really explore all the issues. ORM is all about productivity. The flip side is that you will occasionally run into performance issues. Just like with SQL itself, It really doesn't excuse you from understanding what's going on under the hood, so just be aware of what you're asking for at every step of using it. If something seems like magic, then you should probably dig deeper to understand what's going on underneath, else you'll find yourself in a world of hurt when it comes time to troubleshoot the solution in production.
You sir, do not have a clue what you are talking about.
We've been using [EntityFramework](http://nuget.org/packages/EntityFramework) along with [Migrations](http://nuget.org/packages/EntityFramework.Migrations) for a project we recently started working on and use the MVVM pattern like the one you've drawn. Some aspects of what I liked about using EF: * Rapid prototyping: It's incredibly easy to make changes to your query \ populate business entities etc because all you do is modify code. * Unit testing: I'm not particularly well versed with how close other ORMs get, but with EF we were able to essentially test the SQL code path because we wrote a wrapper over EF's context and mocked those out in our unit tests. * Migrations: EF migrations makes it incredibly easy to keep track of db schema changes in code. I've only worked with handwritten SQLs \ stored procedures prior to this, and at times it does worry me with the kind of queries it generates. But I think the way to go at it would be to use an ORM to start with and swap it out with handwritten queries once you profile the generated queries and identity ones you could do a better job at it. 
I think my biggest problem with ORMs is that there is no API boundry between the code and the database. It seems like the same people love talking about "programming to the interface", "separation of concerns", and "encapsulation" completely ignore all those guidelines when designing databases. And since databases tend to outlast applications, it needs more design work than anything else. But yea, for rapid prototyping go nuts. 
The way you are describing it is how I do it. Web app talks to Business Objects, which talks to a DAL (returns datatables or datasets). I have each of these as separate projects.
Upvoted for the link to http://www.joelonsoftware.com/articles/fog0000000043.html The whole joel on software site is a decent read, although i have only just come across it from your post.
CQRS is a nice way to simplify the writing and reading of your entities by seperating the writing (simple Events to FIFO aka Event Sourcing) and your read model (your ORM or denormalized tables). [Here](http://abdullin.com/cqrs) is a great resource for learning this new technique. It is optimal to use Domain Driven Design with CQRS
Amazing Pascal is still on the list and Logo is on the rise.
Building your own DAL or a minimal ORM implementation can be a good exercise, if you use this time to get into how a *real* ORM works. I did it... and now I'm an happy NHibernate user! :-)
I've been running adblock so long now that i forget about ads on sites.
A 10K jump in salary usually is enough to push me along.
Anybody out there actually using Xamarin in production? I am considering it for a project at work at the moment. How does it compare to native Java on Android? How is the compatibility with a .NET on WinPhone7? 
The ability to use ASP.NET MVC instead of webforms ;-) 
http://www.sql-server-performance.com/2009/new-controls-in-aspnet35/ in 3.5 the update panel and trigger control for partial post-backs.
[Extension Methods](http://msdn.microsoft.com/en-us/library/bb383977.aspx) and [Lambda Expressions](http://msdn.microsoft.com/en-us/library/bb397687.aspx)
I knew that was coming! Born and raised on web forms, gonna be hard to convince to abandon it...
Take the plunge: Try it out for a small project.
Entity Framework 4. My whole team uses it for all data access now. That plus Linq on all collections is a huge time saver, plus the resulting code is more maintainable. 
I was as well, but I'm not going back for ANY reason now. After jumping to MVC I can't believe how horribly bad WebForms is, I just didn't see it until I mad the jump. Also, something else you can use in web forms: Routing. 
I think the biggest hurdle for WebForms developers would be that they no longer have all the "fancy" controls to use. 
Came in here to say the same thing. You don't have to use EF, but unless you're Facebook or Stackoverflow, you probably should. If you aren't using Linq, then you are still working with stone tools. 
The [Task Parallel Library](http://msdn.microsoft.com/en-us/library/dd460717.aspx). In many cases, with a few simple keywords you can turn a sequential loop into a multi-threaded process that takes advantage of multiple CPU's. Since most web servers have at least 2 cores, it's easy to see benefits quickly. 
Once you come to the realization that Webforms are a complicated abstraction that pretends to give you a stateful application while hiding what is just HTML and Javascript, then switching to MVC can be liberating. 
Once you start using MVC you'll be convinced. It also gives you a way into other, similar frameworks in different languages (especially when coupled with EF and different viewengines etc.), e.g. Ruby on Rails and Python w/Django.
I've had a need for something like this for a current project I'm working on. Thanks for the info!
Stackoverflow was actually built with [LINQ to SQL](http://blog.stackoverflow.com/2008/09/what-was-stack-overflow-built-with/). Why do you think they shouldn't use something like EF?
Don't drink the koolaid just yet. I did try MVC on a project and found it much much more time consuming, and much less testable than using webforms with a pattern like MVP. I was actually shocked at how much more untestable code was needed with MVC compared with webforms and MVP based on how test-friendly it's supposed to be. If you really need 100% total control over your output, or your webapps are not very transactional (complicated forms/grids), then MVC might be better, but after trying it, I know it would not help my team in 90% or more of the projects we work on. I feel like the guy saying that the emperor has no clothes, but it's definitely worth trying and learning for yourself and to see if it applies to your situation.
I agree here. 
No one has mentioned LINQ? I use it a lot lately. It's great (in my situation) when we can easily get some data that isn't exactly how we'd like it to be shaped. With LINQ we can easily change it a bit, filter it a bit, sort it, join it etc.
Mostly the Grid. Everything else is pretty easy to replace. If you have a client that insists on editable grids, where every row is in-line edit (like excel), and that is the first thing you have to do...then it is a bit daunting to convert. The next step is actually learning JavaScript/JQuery -- which is what drove me off of WebForms in the first place. JavaScript/JQuery coding was MUCH harder in WebForms than with MVC.
they don't use it anymore
Yeah, they use [Dapper](http://code.google.com/p/dapper-dot-net/) - a micro-ORM they wrote.
I am a convert, and will never look back. MVC is MUCH easier to work with, test and separate. Plus, the skills are highly in demand and pay much, much better.
MS Ajax 4 has some good stuff if you're looking for a grid replacement. Two way databinding is amazing.
And Dapper is like 50 times faster than EF. Personally I am using PetaPoco. We have used EF in some big projects (with existing databases) and its not the fastest ORM I can say that much.
Yeah, EF is a dog. Workmate had a chunky query which EF took close to 5 mins to complete - he profiled the generate query and it was spawning huge joins creating an absurd number of rows and columns. He's now using PetaPoco. I quite like the rise of these new micro-ORM's - it's kinda like MVC: we've moved back closer to the metal, but without the hacky boilerplating bullshit.
What did you struggle testing? You taken a look at MVCContrib? Were you following a particular pattern with your views/viewmodels/controllers and services/repositories etc?
Lately, for me it's been "LINQ ALL the things!!!!" :) I mostly use the extension methods, not actual linq statements.
Try a project. Just play with it. Trust me.
A shorthand 301 redirect in 4.0: Response.RedirectPermanent
While I think MVC is the right choice for public web sites, I would definitely recommend Web Forms for internal applications where functionality and turn-around time trump performance and appearance.
ORMs are for toys and prototypes. Until they fix some fundemental flaws like needing to do a SELECT * before an UPDATE or DELETE you should to stored procs for serious production work. EDIT: Lots of downvotes, but I'm willing every one of ORM users are loading an whole entity by ID just before you delete it.
Couldnt agree more! Micro ORM's are a great improvement from say IDbConnection but gives you full control of the sql. And it doesnt feel like your writing a VB Macro in Excel to connect to a Fox Pro db. :D roadhouse
Plus.... expando! (in mexican accent)
Definitely. Also, someone else here mentioned routing which when used properly can give you a beautifully stateless user experience.
What's wrong with just having every dependency be IDisposable, with empty dispose functions?
Exactly
As far as I could find, there was no way to test the routing. There was no way to test (without doing UI testing) the view, and there of course is no easy way to test a lot of the javascript based interactions with the server that are typically used (and we used) with MVC. So that left us with testing JUST the model. Call some action with some inputs, and get back a model that looks like it should, or not, and test it. That is a very limited scope that is covered by automated unit tests, and when compared with MVP, it led us to having a much larger amount of hard-to-unit-test code. Compared to MVP it felt like a big step back in terms of covering our code with tests. With MVP we almost always get almost all of our code into tests. The only stuff that isn't tested are very simple things like, in page_load calling the controller.Load, or in SetErrorText(s) setting txtError.Text = s correctly. Very simple stuff that like. With MVC there were a lot of non-simple code that seemed untestable in a simple manner. With MVC you tend to have more "code" (razor code) in the view. We found some tricks to get our build server to compile the views, which helped a little, but every function, or if block you have in the view isn't being tested in an easy way. I've never had an asp.net form accidentally posting back, either in or out of bounds, to the wrong location, but when you are writing your own routing pattens and using jquery to build URLs in MVC it's quite easy to screw up something and postback to a URL that doesn't work right. This is very hard to test in any automated way. To answer your other questions, I hadn't seen MVCContrib before. I don't think we adhered to any specific pattern. We already have a pretty well developed business object layer, so we didn't need to created anything there to deal with data access. We mostly used an MVVM pattern with the MV either being a business object itself, or more often something that contained 1 or more business objects and page-specific properties. 
Unless I'm missing something, this is retarded. Dependency Inversion allows us to construct object graphs and dispose everything in the graph deterministically, using an external controler / container.
What's wrong with the existing serialization classes?
This seems silly when you can do roughly the same thing with Queue&lt;Action&gt; ProduceAsync( Action a) { Task.TaskFactory.StartNew( ()=&gt;{ Produce(a); }); } Produce(Action a) { while(_myQueue.Count &gt; Queue_Buffer_Length) Thread.Sleep(0); lock(_myQueue) { _myQueue.add(a); } } Consume() { lock(_myQueue) { int itemCount = Queue_Buffer_Length; if(_myQueue.Count &lt; itemCount) itemCount = _myQueue.Count; for(int i = 0; i &lt; itemCount; i++) { _myQueue.Dequeue()(); } } }
Compatibility with services that use protobuf
I agree... the serialization classes in .NET are quite good. What makes this better?
Speed, size, lack of any cross platform compatibility. Pretty much the bullet points at the top of the page
I'm not in Texas but I'm pretty sure you just want an INSTEAD OF UPDATE trigger. http://technet.microsoft.com/en-us/library/ms188601.aspx http://technet.microsoft.com/en-us/library/ms175089.aspx
Wow, that's very interesting. Thanks for the links. I'm going to see if I can figure out how to implement this.... Edit: At this point I'm not looking for someone in Texas - just someone who can work with me over IM/TeamViewer to get this knocked out.
It is lock free and can handle millions of transactions per second on a single thread at low latency. Huge difference. [Here](http://www.infoq.com/presentations/LMAX) is a presentation on the main Java version.
Sorry, I'm not local (not even close) and I don't want to waste your time or anything but if you don't mind, I'd like to ask you questions about the problem. I don't quite get what you're going for and hope you can clear it up for me. It'll help you perhaps better articulate the problem to whatever dev you do find if he doesn't quite understand the problem as well. Here are the bits the are unclear to me. &gt; So here's the issue: without changing anything in the database, I need a CRUD that manages the tblOverides table - BUT, it must display a distinct list of ALL locations in tblPeople, regardless of whether or not there's a value in the table. &gt; Creating a VIEW for this is really simple - basically pulling a distinct list of locations from the people table and left joining the tblOverides table. However, the issue is performing an update. Because the query has a distinct/aggregate clause in it, you cannot perform update operations against it. 1. A CRUD that manages the tblOverrides table? So you'd like to be able to do CRUD operations to the tblOverrides table, right? 2. Why do you need to "display a distinct list of ALL locations in tblPeople"? 3. What do you mean "whether or not there's a value in the table"? Which table are you referring to?
How are you accounting for overriding with locations that are not yet in tblPeople?
This is an impossible situation as the locations in tblPeople is based on a LOV from another database.
1.) Yes - except it needs to be joined to tblPeople so that the user can see whether or not they have an override. Basically the user will see a distinct list of locations and either a value if there's a corresponding value in tblOverrides or nothing if there isn't. 2.) See 1. 3.) Also answered with 1. Here's where the project is currently at: The MVC project displays the SQL view as a table and that works fine. What I need is for someone to add an UPDATE form that, when the user adds a value to the form, instead of it trying to perform an insert against the view, it just does it against the base table instead. I was able to create a trigger on the view based on cjg's suggestion above, and it worked great in SQL, but the MVC app doesn't work with it. I just don't have enough knowledge to update the MVC app to work properly. 
Ok, let's break down the CRUD app into it's separate pieces and walk through it. We'll have five basic CRUD operations: * An Index Action and associated View giving us a full listing of all items in tblOverrides . We can have it paginated so we don't have thousands of records in one page. *A Details Action and associated View for one particular record in tblOverrides . * A Create Action and associated View to add a new record into tblOverrides . * An Update Action and associated View to update a particular record in tblOverrides . * A Delete Action and associated View to delete a particular record in tblOverrides . The Index Action should be simple enough. Just a listing of tblOverrides. You could tweak the query to have the results be joined with tblPeople if need be. The Details Action should also be simple enough since we're just reading data. The delete action will be exactly the same as the Details Action except it'll have an extra http post action that will activated via some button somewhere that will remove the record from the database. The Create Action would involve inserting two values into tblOverrides: the original location and the new location. The original location should be presented as a drop down list populated with all distinct locations in tblPeople and the new location should be presented to the user as an empty textbox. The chosen item in the drop down and the value typed into the text box will then be inserted into tblOverrides. Sounds simple enough to code. Finally comes the Update Action. This would entail presenting the user with a form that looks exactly like the above described Create Action except the current original location would be already selected in the drop down list and the current new location will be already filled in the textbox. The drop down list will be populated with all the distinct locations from tblPeople and the user can then change the original location or change the text value in the new location and click the update button which will then change the values in database. Is this how you need it done? If so, great! Your needs are kind of specific though with regards of having to do this via teamviewer and I would have preferred writing the code out and giving it to you rather than doing it over teamviewer. You sure you wouldn't be able to figure it out on your own if I just write a small application that works as described above and give you the code?
I'm an ASP.NET MVP. What arguments is keeping you to WebForms so much that you won't touch ASP.NET MVC? Honestly curious here. WebForms has an horrible basic framework to enable you to test. MVC is built around the use of a Service Locator (another debate for another time on this one) that allows you to inject dependencies at pretty much every level. However, I can't convince you to try it if you can't tell me what you love about Web Forms. :)
For the routing, I would recommend that you take a look at [Route Debugger](http://nuget.org/packages/routedebugger). It's not testing but you should be able to set a few tests easily and see what works or not. Otherwise, I would recommend not messing too much with the default routes. Any applications can work easily without touching the default routes. MVC is not testing "Just the Model". What if you return a partial view? What if there is an error? Do you redirect? Those are all "ActionResult" that you want to test for. You are testing your controller for certain result. Of course, you need to interest with your model but in the end, it's the controller you are testing. Then comes the code in the views. No code other than the one for displaying data should be in your view. The rest should be in your controller/model. What you typically find in Razor views are loops (to generate equivalent of grids or list), and if or two and then lots of data binding by just doing "@Model.Id" and stuff like that. If you have logic in your view, of course it's not testable! Do you have logic in your ASPX? That too won't be testable. Overall, if you put the logic at the right place, use your views for what they are meant to be used... your application will be more testable than any WebForms application. The only difference is that in MVC, the ground work of the pattern is already setup for all controllers all around. For WebForms, you have to build it every time all the time. With MVC, you must truly adhere to a stateless web because, of course, your request can come from anywhere at any time without any prior validations done on the client side. Stateful web applications are not the way to go. If you have any questions about MVC, feel free to ask me. I did multiple live projects with it and regularly present it to user group and MS sponsored conferences. Would love to get you up to speed if there is anything that you don't quite get about MVC. Cheers mate.
Why MVC for public sites? Both ASP.NET MVC and WebForms perform the same in speed. Functionality can be given by both MVC and WebForms. One however offer an already implemented pattern to facilitate testing. WebForms, you have to build it on your own everytime. Why rebuild the MVP pattern everytime for each internal web application? I'm curious as to what your arguments are.
MVC allows for fine-control over the HTML being generated. This in turn gives you the ability to fully leverage HTML 5 and create really nice web sites that work correctly over all screen sizes. Unforuntately this takes a lot of time so you need a good reason to justify the cost. Internal websites, on the other hand, don't need to look particularly good. But they do need to be filled with countless data grids and simple CRUD-style forms. Which is exactly what Web Forms excels at. Of course you don't really have to choose. People can and do mix both in the same application. &gt; Why rebuild the MVP pattern everytime for each internal web application? You don't need the MVP pattern. A simple forms-over-data architecture is quite suitable for most people. But if you do want it, look at this project: http://webformsmvp.com/ http://www.infoq.com/news/2011/06/WebForms-MVP 
Thanks. Data grids and CRUD forms are definitely a scenario WebForms is still very strong at. However, I don't like to expose my SQL tables as Web Tables and have the client edit them without business logic. The problem with those CRUD interface is that it's very data centered and not very action centered. "A client address has been changed" is something. Issuing a "Client has moved" order is different. The first one is done with grid and is quite hard to grasp the action that happened and why. The second scenario is pretty clear as to what is changing and why it's changing (business rules). However, the second one is definitely more expensive to implement. It's all about setting priorities. If something internal is being developed, it's to save money. The question remains, can you save money by doing it right even if it's more expensive? Debugging, troubleshooting, etc. is always more expensive and is never planned in the initial budget when creating an application.
I don't actually recommend in-grid editing. It is easier to just have an actions menu that opens task specific forms. If you did want direct table access you might as well autogenerate the whole site. MS has tools for just that scenario. 
In-grid editing is an horrible idea. Always has been, always will be. It's very specific to very few scenarios. Personally, I don't particularly like grids. Even for internal applications. Grids have a tendency to accumulate too much details and become hard to manage. It's always about "One more column" or stuff like that. That's mainly why I choose different paradigm to display data rather than just show a list. Once grids are taken off the equation, suddenly MVC becomes way more easier to work with and way more testable. Then, of course, there is the easy part that is IoC, model data binding, etc. with MVC. I've turned my back to WebForms for most scenarios. I've found that MVC actually separates my concern way more easily and allow for the "Pit of success" way more than WebForms.
We solved the one more column problem with grids bound directly to stored procedures. Once set up the BAs can crank out as many damn reports as they want just by fudging the SQL.
I'll let the BA work with Reporting Services. None of them touching my database directly. Best case, I'll have a data warehouse database where they can hit as hard as they can without impacting me. Most of the time, if it's for reports, they don't care about the web. They want to print it. They want to email it. PDFs or Excel spreadsheet are ideal for this specific scenario. SSRS kind of gives a lot of value at that point. Also, less UI work for me and they are not messing up with my database.
Where I worked the BAs were all expected to write a non-trival amount of SQL. In many ways it was their database and us app developers were the guests.
Interesting. In those scenarios I would normally have a write DB upon which the website depended upon. This DB (and website) would be in total control of the IT/Dev team. Nobody can modify anything unless you are part of the dev team. Then, there would be a read-only database where the data was duplicated and upon which any BI could unleash hell if they wanted. Reports? Saved in their section of SSRS. No bothering anyone, not breaking anything for anyone unless they run a query which runs the server into the ground. The SSRS way of writing queries is pretty similar to SQL Queries except that it's more user friendly.
Our BAs weren't just your normal paper pushers, they had extensive domain knowledge and were responsible for most of the business logic. Rather than trying to explain things in english we communicated in terms of table diagrams and SQL, even if the code would be ultimately implemented in VB or C#. It worked out remarkably well.
Hey, thanks for your reply. I just posted an edit - was able to get it figured out pretty easily after sleeping on it and getting someone to point out a few things over TV.
I really wish C++/CLI was usable with Mono. I realize that this is a similar solution to the problem of bridging C++ and C#, but C++/CLI is already defined and built, and there's a good amount of tested code for it. A new language solving the same task is going to take a long time to mature. I think the main problem comes down to the nature of C++: you can't count on all compilers implementing the ABI the same (name mangling and suchlike), and there's no way to know what compiler was used on a library after the fact, so interoperability becomes a complete nightmare.
I'm right at the start of evaluating this myself but in the demos I've seen people seem to be using entity framework 4 with mvc. Might be a good place to start looking for the new patterns. 
Check out the codeplex project mentioned here: http://weblogs.asp.net/shijuvarghese/archive/2011/01/06/developing-web-apps-using-asp-net-mvc-3-razor-and-ef-code-first-part-1.aspx
Ok happy to help out here, been doing lots of projects with MVC2 and MVC3 over the last few years. My latest is a large system using MVC3 so I've seen a number of configurations. A couple things to know right away: * Your ASP.NET Webform user controls and UI/URI tricks are now useless Any user controls for ASP.NET will most likely not port to MVC without some work. If the controls rely on the ASP.NET page lifecycle events, view state or postback they will not work without modification. * If you followed best practices for your business and data code you will love MVC MVC gives you a very clean way to integrate in existing re-usable business and data components. What ever you do today will likely have an easy translation to MVC with less code and more control. So now on to a practical example. When you get on the web and look for examples you are going to run across samples that look like this: public class SomeController : Controller { public ActionResult Index() { //Here I am just creaing an instance but you could be grabbbing data from anywhere really var model = new DataModel { MyValue = "Hello World!" }; return View(model); } } public class DataModel { [Required] public String MyValue { get; set; } } Now this is all fine and good until you start thinking "hey, I don't want these MVC specific annotations on my data" There are a number of solutions such as buddy classes, wrapping and model translation, what you use it up to you and just depends on how much you want MVC crossing into certain domains. Generally you want to carry some view specific data around with your interactions as well. You can do this by creating ViewModels that include your primary data model and then any other values that are important to the view or you can use the ViewData collection which will pass an object or value for the view to consume. Also keep in mind that MVC is meant to be highly extensible, if you take the time to learn about model binders, filters, custom routing, custom base controllers etc you can even create very clean integration between your business/data API's and MVC. Typically you start with what is easiest to get working then move to more advanced capabilities as your needs and understanding of MVC grow. The biggest thing to get your head around for many people is routing, be sure to pay careful attention to how naming conventions work with the routes in your application class to create URI's in your application. Don't allow MVC to force you to develop you back-end differently think about how you can use MVC with some solid patterns to effectively leverage your existing classes as much as possible. Now if in that process you find your back-end lacking, well then you may want to think a bit differently. If you have any specific questions I will do my best to answer. 
The common examples are a bit misleading at times IMO. They use Entity with the basic repository wrapper example offered for entity. This has you using LINQ or lamdas all over your controllers to query the stores directly. Depending on how you organize your application and how big the app is this may be OK. However for larger applications or where there are increased chances of feature re-use (say user functions) its best to implement at least a repository pattern between any direct calls to entity and your application. This gives you 1 place to change key data calls that may be used more than once, this also gives you once class to rip out should you decide in the future you prefer nHibernate or some other data store method. 
Manitcor gave a pretty good explanation of MVC, but I wanted to add a few more things * ASP.NET MVC is database agnostic, you can use any data access technlogy you like (ADO.NET, Entity Framework, NHibernate etc). All it cares about is receiving back a model or collection of models to facilitate the transfer of data between the different sections (model-&gt;controller-&gt;view) * People use the term Model to refer to model classes in small applications, but in larger apps "Model" is used to refer to the entire business layer including entity classes and tiered data access. * Personally I don't keep any models in the mvc project, I have different projects included in the solution for data access, business entities, etc and reference them from my mvc project. I like to keep controllers thin and have controllers reference service objects (business rules live here), service objects depend on repository objects, in the repository object is where my data access code lives. * MVC is much MUCH better suited for unit testing, unit testing webforms is hard because it requires a web server. You can unit test mvc apps without a web server
I definitely agree - n-tier architectures are still the way to go for long-term projects even on ASP.NET MVC. I am using an 3-tier architecture for instace.
Thanks for the info. I should have been more precise when talking about just testing the model. What I meant to say was, when we made our mvc app, the only thing we could test was the result of calling a method on the controller. We can already do this with MVP. We strove to have as little logic in the view as possible, but we ended up with a lot more than we would have in an aspx page, even if still very little. This project was several months ago, but I remember we would have if/else blocks, for loops, and some simple in-view functions for doing basic formatting of some values. For example, maybe we had a numeric value we wanted to display, but if it was negative we wanted to surround it with () instead of using "-". We would write an in-page function to do this. This is code that would have been unit tested in MVP, but not in MVC. Maybe we should have put this code and other similar code into the controller, but that would have meant that we couldn't have used our preexisting business object as the model for this page, and would have had to build another class for that. But even excluding this stuff, we still never had if/else or for-loops in our aspx that we needed to test. But this is a very minor point. In our app, we ended up making use of a good amount of javascript/jquery to achieve stuff that was supported by the webforms framework by default. The more code we wrote, the more bugs crept into the scripts, and none of this was testable in an automated way. I never need to test that an ajax component works right in webforms, but with MVC we were rolling our own jquery code to achieve the same results. We also ran into issues where controls on our page had a typo with the name of a control in the view that we were trying to use to hydrate a model when the form posted, or there was something slightly off with the URL path that was being used, either with javascript or straight from a hyperlink. These are things that we can't test in MVC or MVP for that matter, but in MVP these are never a problem, so they are a liability to our product in MVC and we can't test for them. What I mean is, in webforms, I've never clicked submit on a form and had the textbox values not available in the codebehind, but this is exactly what would happen if we had a typo in our cshtml. If you take our mvc app and an mvp app, and you look at how much code could go wrong, and how much of it is testable, I think MVP has a much higher %.
Let me solve a few problems that you had and that will save you time in the future. Negative values can be formatted using the CultureInfo. Look for NumberFormatInfo.CurrencyNegativePattern. It's where things are set. You only need to set this once in your application and every convertion that you will do by default will have the new pattern. Better, you can store a custom CultureInfo NumberFormat instead and use that everytime you format a number. This will allow you to test it without pushing that in your views. As for the name matching, were you using the Html.TextBoxFor and other helper methods? They normally ensure that your naming remains consistent even when they change. As for Urls, there is a helper in Views that is called Url.Action that allows you to generate urls that match your routing. My main problem with MVP is that most of the component that comes out of the box are set in a certain way with no way to adapt them if it wasn't planned that way. As for MVC, well... total control. Of course you need to do a bit more but by using jQuery UI for most of my controls, I've never had a problem with a date picker and other stuff of that kind. Overall, I think that MVP has it's place but I think you went in MVC and maybe weren't aware of everything that would have helped you save time and debugging. I'm planning on doing a series of screencast on MVC and how to setup a real-life project and make sure everything works fine. Otherwise, if you are interested... take a look at the MVC StoreFront by Rob Conery. Very interesting stuff. 
&gt; Now this is all fine and good until you start thinking "hey, I don't want these MVC specific annotations on my data" Most of those annodations are not specific to MVC, I used them for WPF and Silverlight applications as well. And the next version of WebForms should also honor them.
&gt; but in larger apps "Model" is used to refer to the entire business layer including entity classes and tiered data access. I have to disagree with that statement. While I have seen that mis-use of the term, a real model object should not have any external dependencies. It should just have data and business rules that act directly upon that data. I suspect the misconception comes from thinking that MVC is an application architecture. It's not. MVC is really just a description of the UI or Presentation tier of an application. As you say, it is agnostic to how you build the data tier. 
&gt; I like to keep controllers thin and have controllers reference service objects (business rules live here), I would modify this to say "business rules that cannot live in the models" or "business rules dealing with the services". I find that most of the so-called business rules actually live inside the models, which is great because models are easy to test.
I would stay away from ORMs in general. Besides having horrible performance, you end up mixing storage logic into your application instead of keeping it in the database where it belongs. Fortuantely ASP.NET MVC doesn't care how you access the data. 
Models are nothing but data and business rules, same as any other application. In fact you can use the same models library in WebForms, MVC, WPF, and Silverlight. Controllers are suppose to make service calls, either directly or through some sort of repository. The service can be a database, a distributed cache, or anything else you can imagine. The view is... well you know what that is. So your top tier is the Views and Controllers. Your bottom tier is the database. If you need to throw some other tiers in the middle, go for it. 
True but in an ideal world you still don't won't that kind of meta-data in your core domain. Of course that all depends on where you see your code going and how long you expect it to be running for. 
Not terribly related, but I escaped the .NET ecosystem for RoR about 9 months ago and I haven't heard the word "architecture" since.
&gt; *A new language solving the same task is going to take a long time to mature.* I don't think there is a new language here. It looks like CXXI generates .NET binding libraries for native libraries written in standard C++. It does not extend the C++ language like C++/CLI.
I wonder how this handles the mismatch between garbage collection and deterministic destruction. Are all native classes exposed as an IDisposable?
Yeah, after reading some more, it looks like that's what's happening. The CXXI compiler is generating a proxy library, as opposed to extending C++. I stand corrected, but I still wish I could use C++/CLI in Mono.
Good question. I've always wanted to talk to an MVC guy about this, so here it goes... **What I like about ASP.NET Web Forms:** 1. The event-driven model. It's easy to follow and it just works. I realize some people don't like the overhead that this involves (i.e. viewstate) but with careful resource management these issues can be reduced. (For example we use Telerik's RadCompression to significantly reduce our page's footprint.) 1. Server controls. I love the built-in controls, (some of) the Ajax Control Toolkit, and especially the controls from Telerik. People complain about not having control over your HTML but frankly I think that's just laziness. I've never not been able to style a control with CSS. **What I don't like about ASP.NET Web Forms:** 1. Writing tests is difficult. Not impossible, but difficult. 1. SEO. Easier with MVC, but with 4.0 Web Forms is catching up. 1. Postbacks in general do not lend themselves to a good user experience. Again, there is plenty you can do to mitigate these issues. I also use jquery extensively with Web Forms and have no trouble whatsoever. A good developer can work around the few shortcomings that Web Forms have and still present a result that is visually pleasing, useful, and maintainable. What's always been funny to me is how much MVC people talk about testing. "It's so easy to write unit tests! We love to write tests! Testing testing testing!". I have to call bullshit. I've never met a developer who likes to document his or her code much list WRITE a test. Granted, if you are *required* to write tests, MVC is an obvious advantage. It's also clear with 4.5 that MSFT is making a big push to get Web Forms caught up to MVC in certain areas. And let me be honest: MVC feels like classic ASP. I don't WANT to write so much javascript. I want my GridView. I want to let the framework do the nitty gritty HTML for me. But that's just me. 
First of all, I'll just start by saying that I agree with your main points and that I won't be bashing on you in this reply. :) ##ASP.NET Web Forms The Likes: ###Even-Driven Model Have you seen what the [Page Lifecycle](http://msdn.microsoft.com/en-us/library/ms178472.aspx) looks like? It is not easy. It's tightly bound to your IIS instance in lots of case. You shouldn't have to use 3rd party tools to achieve basic performance. However, lots of this has been fixed in ASP.NET 4.0 and more will be fixed in ASP.NET 4.5. Overall, the page lifecycle is just too complex and can cause problem easily in the long run if you don't stick to patterns. ###Server Controls Built-in controls are easy way to plug-in a feature and have it work right away. However, it's at the cost of flexibility. When those features are abused (most of the time by junior dev), they become incredibly hard to customize. Another problem with those controls is when there is new web standard evolving. You will have to wait for 3rd party ($$) controls or Microsoft (can take a year or more) to implement those new standards. As for the Telerik controls, they are a huge burden on older browser like IE7 and IE8. We had performance issues with that this year and by removing them we gained a massive amount of performance. Overall, if a control can save me time (think Grids) I'll build a WebForm page to host the grid and have the rest in my MVC application. ## ASP.NET WebForms The Dislikes ## Tests As previously mentioned, the main reason why tests are difficult is because everything is tightly linked to the HttpContext (god-class that is highly untestable). You will need to implement the MVP pattern (or use tooling to do that). ## SEO Agree with that. Lots of improvement in ASP.NET in the last few years around that. ## Postbacks Postbacks were the answer to convert WinForms developers to WebForms. They had to persist state (hello viewstate!) and allow an easy conversion of Desktop developer to web developer. However, those never worked flawlessly because the Desktop is stateful and the web is stateless. You never know when your user is "not there" anymore. Postbacks were the easy way to handle form posting but allowed to have grids with lots of feature. ## The rest ### jQuery I'm using jQuery every day with MVC. It's an awesome tool. I've did the exact thing you do with UpdatePanel but with jQuery in a few lines of code. 3 for jQuery and 2 more in the controller to give myself a partial view. ### MVC and Testing The main reason you hear that is that there was craving for tests by developer but no frameworks that scratched that craving. WebForms is not easily testable. With MVC, our controllers (equivalent of a page?) are by default parameterless and need to be. However, if you setup a DependencyResolver you can start to have constructors with parameters and inject your dependencies (Interfaces, Abstract class). This is the most basic but it allows you to have the Infrastructure code in one place only. The other thing that makes MVC testable is that I can "new" a controller and call one of it's method without having it crash. I can test for redirect. I can test for PartialViewResult. I can test for JsonResult, etc. This is why you hear a lot about testing. ### Testing I would read "Clean Code" by Robert C. Martin. You are never *required* to write tests. But if you are a professional, you want to write tests. Period. ##Conclusion Overall, WebForm has caught up to a lot of it's lil'brother MVC. But lots of the main friction point of the former are absent in the latter. So even if grids are missing in MVC by default, people still use it and build great applications with it. More questions? Ask away!
Sure I do. If I didn't have them as an attribute then I would implement them imperatively in a validate function. 
You will probably still have to manually call the delete method. OpenGL comes to mind. You still have to call gldeletetextures under opentk.
I envy people who get paid money for working on trivial projects.
No I agree with you completely, the model (business entities) should not have any external dependencies. What I mean is that when people talk about MVC as a presentation layer pattern, the Model is not only used to refer to a single model object but the entire teired hierarchy that consists of entities, repositories, service layers etc. Essentially when talking about ASP.NET MVC, some people refer to the Model as the entire infrastructure that is in the business layer and infrastructure layer.
It's just my style but I like to keep business rules outside the model and abstract that away to a different layer. I try to keep my entities as clean as possible.
Even for simple stuff like FullName = FirstName + " " + LastName or that LastName is always required?
&gt; some people refer to the Model as the entire infrastructure that is in the business layer and infrastructure layer. While I agree that some people do say that, I think it is a mistake to do so.
lol. This is why the people think what they do about .NET developers.
That's not surprising since RoR only allows for one architectural style. Why talk about something when you don't have a choice in the matter?
Fullname = FirstName + "" + LastName to me isn't a business rule and I would put that in the model. As for LastName required that's a validation rule, business rules are more like "can't enter a new order on saturday" or "customer can't view invoice history until the invoice has been processed"
That's the problem with using terms like "business rule", no one agrees on what it means. Of all four rules we mentioned so far, I can't think of one that doesn't need to be implemented at multiple levels. 
Thanks for the insight. I figured we'd be able to maintain the 3 tier architecture we've been building upon, but I wanted to make absolute sure -- and what better way to do that than ask people with real world experience in it. I'll probably throw together a sample project to show it off at home. Thinking about doing a table top RPG tracking site. I've already started this project at home for a fun project. Just gotta transition it over to MVC and I should have something to show for it. One thing I think they may be hesitant about is that we implement DevExpress WinForm user controls in our pages quite often, and from what I've seen the transition to MVC would mean the end of the use of those user controls for us. *EDIT* though upon further inspection it does look like DevExpress has a suite of MVC extensions.
Losing ASP.NET usercontrols is the biggest barrier for transitioning an existing ASP.NET app to MVC IMO. DevExpress along with many others (as you have discovered) are releasing MVC versions of their control sets. Review them carefully however as they may not be as mature on the features you rely on from the ASP.NET versions of the controls. 
writing enterprise software with ruby is like trying to cut down a redwood with a Dremel.
One benefit you gain with MVC though is that a lot of controls that you used before tend to be open, since they are essentially rendered in HTML now. If you look at most of the vendors, they provide their MVC control sets for free with caveats that limit the support/updates that are available or the type of projects those controls sets can be used. 
You gain convenience with using ORMs but as you pointed out, performace suffers quite a bit. You are basically trading abstraction for performance. I do like the recent trend towards Micro-ORMs though. They get you closer to the metal while still retaining a good balance between ease of use and functionality.
The sad thing is that it doesn't have to be that way. There is no reason something like Entity Framework couldn't also have bulk operations. There is little difference between generating the SQL for a SELECT and an UPDATE or DELETE.
Aren't the classes in System.Collections.Concurrent also lock-free? Might be useful if you're still on 3.5 and don't want to use the back ported version of the reactive extensions though.
you could try GWT if you are fond of the HTML / JavaScript abstractions. did you? tell me what you think 
Sure would be nice if they fixed [Visual Studio 2010 first](http://amplicate.com/hate/vs2010). 
Great post. I received a couple bug reports recently that described a similar issue. There's a good number of services we use that may have been having intermittent problems(all test environments). Thinking back, that could have very likely been the reason. I'm going to go through our outbound requests to make sure. Thanks!
Then why would you upgrade?
You don't know if the pain will be there until you're there. I don't usually early adopt new versions of VS, but that's what the client and larger team preferred and there was not, at the time, any reason to not do it apart from it's being new. On top of that, I haven't had these kinds of problems with any version of VS EVER. I swear VS 4 was more stable than 2010. 
I don't have any of these issues. Is it your whole team? How much memory do you have? Running any extensions?
I have used a few of these in my own libraries.
Whole team. 4 GB RAM on Windows XP and it doesn't seem to matter what extensions are running. Particular issue seem to be mostly around TFS, multiple monitor support, video driver sensitivity (yes, really), and we have had really bad experiences with the designers - especially the web and reports designers. The former causes all sorts of crashes and the latter just doesn't draw properly most of the time. Very very frustrating. Perhaps Windows XP is the real issue because they haven't tested with it adequately, but I don't think that's our fault.
I've never understood why more people don't use the extension methods. They're way easier to read an write IMO.
Almost forgot to mention this - but VS also has a horrible tendency to freeze up for half a minute or more quite often. This usually happens during debug sessions, but it can also happen just when switching between panes/windows in VS. It seems to be worse when using multiple monitors and stretching VS windows between them, but it's definitely not limited to that.
Neat idea to clean up private reflection code, but I don't know...I'd almost prefer the ugly and complicated method, just so it'd stand out more and have that extra little boost to the barrier of entry; make it too simple to use and folks will use it, even when there might be a "better" (architecturally, that is) solution available.
I use dynamic now anytime I need to call a generic method via reflection. So much easier.
Have you given Delegate.CreateDelegate a try? Both faster and arguably cleaner if you wrap up the call in a func-factory.
no because it's fairly infrequent calling and i don't store the delegate
Ah, fair enough. For anyone who makes a lot of reflective calls, I can't stress it enough - especially when called in any looping scenario, like a custom serializer. It's like a 10-50 x speed boost.
In my opinion using business objects as 'models' for your view is a big nono. You want to separate your business logic from UI. Use view models whose job is to only carry data from controller to view.
That's an amazing breadth of stuff.
That's why they should be in your View-Models and not the data itself.
From one aspect, it is good that .NET was slow to OSS in that (hopefully) new projects will have learned from previous generation projects and one-up them.
I get the feeling this is an answer to the other side of that coin: if the container you're using doesn't have deterministic lifetime management, whose responsibility is it to dispose? Not saying I agree with that as a good solution, just playing devil's advocate
Possibly. But it's a poor solution in that case too IMO
How so? Don't the paid plans just let you have private repositories and collaborators?
Personally I'd rather just use something like DotPeek if I'm poking around. Much easier.
Yes there are various versions on the web. Some done with the reference source, some are reflected. You can find them by searching for a class filename, e.g. http://www.google.com/search?q=networkcredential.cs
I bought a license for Reflector when Red Gate took over. It's great, but there's no named symbols for constant values and this is a particular pain in WinForms as I don't have all the window message values memorized.
1. Install Windows 8. 2. Create a new Windows 8 Metro style application. You'll see this in the project templates. Note: Unless you are using p/invoke or COM to directly call native DLLs there is no reason to set the target CPU. Your application is going to compile to the same IL code no matter what CPU you target. Note 2: To the best of my knowledge there is no way to use the full .NET framework on an ARM processor. You have to choose a subset such as Windows 8 Metro, .NET Micro, or (maybe) Windows Phone 7.
grauenwold - So in order to make .net programs run on arm architecture I need to install windows 8 for my operating system, then install .net 2011 developer preview then compile them as a metro app? Or install windows 8 as the os and install .net 2011 and remake the app as a metro app? I am confused?
Yeah I am super confused too. Do i have to write the program in windows 8 operating system? Or can I install whatever framework is needed intow my current os which is windows 7 pro?
Just so you know, you can click "reply" below someone's comment, that way comments make more sense and it notifies the poster that you replied to them.
so it will basically be emulated by JIT, to whatever architecture the device is using?
The act of JITing produces machine code. On an ARM CLR it will produce ARM machine code while on an x86 CLR it will produce x86 machine code.
Just imagine the kind of fun a guy could have trying roll out a real system on a platform that practically has the guy with first-class access to its developers in tears. It sounds almost as fun as SharePoint. Edit: Stray apostrophe removed with extreme prejudice.
Sort of -- if you want to make a Metro-style application, you need to be using the Windows 8 developer preview. It comes with a preview of the new version of Visual Studio which works with the new-as-of-Win8 WinRT (Windows Runtime), and WinRT UI (XAML based development framework for metro-style applications). WinRT UI is how you code the UI for Win8 metro-style applications using C#. These, when compiled "Any CPU" should work across x86, amd64, and ARM. Additionally, when running as a metro-style app, you're using the "Windows 8 Profile" of the .NET framework. This profile doesn't include some assemblies, classes, or namespaces that are either duplicated by WinRT or inappropriate for metro-style apps. The API reference is here: http://msdn.microsoft.com/en-us/library/windows/apps/br230232(v=VS.85).aspx The API reference for WinRT (which you can use within your C#) is here: http://msdn.microsoft.com/en-us/library/windows/apps/br211377.aspx
Thank you, do you know if visual studio (vb) .net will work on arm as well or just C#?
No argument here
Using a background indexer could achieve fast fuzzy searching.
Are you talking about "LINQ to SQL"? LINQ (to objects) just lets you filter / alter / sort / join objects and collections in your code. Nothing specific to database access.
Good point! I had a very particular fuzzy matching in mind. What I was thinking about was when I search for "summarize" the code search engine should also return the class "Summarizer" or even uses of the word "summarizing". This way I don't have to think about either using regular expressions (which works in this case) or other annoying details such as different forms of a word (e.g., "running" vs "ran"), etc. To your other point, I can imagine that many developers doing greenfield development don't need to search much, as they are the creator of the system and know basically where things are. However, for those of us stuck doing maintenance on other people's (sometimes crazy) code the ability to do a proper search becomes important.
When factoring code into a separate method to control when it's JITted, you need to remember to use MethodImplOptions.NoInlining http://msdn.microsoft.com/en-us/library/system.runtime.compilerservices.methodimploptions.aspx
Slideshare presentation is here http://www.slideshare.net/mindthebird/what-is-new-in-net-provider-trace-support-cancellation-and-more
.Net development of all types ranging from .net application development to .net web development, from custom .net development to .net framework development; avail services at affordable prices from best .net development team of India. Email at: info@applicationdevelopmentservice.com
If it's an addon, it won't run on VS Express. So yeah the title is wrong but all versions that are used professionally and academically are supported.
I thought it would go without saying. Express doesn't support any extensions, full stop, so there's no reason this would work either. Putting it in the headline would make it a bit long :)
I'd hope you would know all that well before you start calling yourself senior...
And yet at the same time knowing those terms doesn't really say anything about your actual programming skills. I knew one "senior" who loved quoting design pattern books but couldn't understand how Nullable&lt;T&gt; works.
This should be expected out of juniors.
This article is useless. 1) As others mention in this thread, this is something I'd expect even a brand-new college hire to know 2) It doesn't give examples of how these can/should be implemented in .NET. It mentions MemoryStream/StreamWriter/Stream only in passing, without getting into any detail. [This article from 2001](http://msdn.microsoft.com/en-us/library/ms973803.aspx) does a better job than that blogpost, at least for inheritance and abstraction.
I was asked all those things in my interview for a junior position...
This is a bit more than knowing the term, it is understanding the concept. And as we are seeing, the consensus is that this is a fundamental concept.
Then perhaps they are not actually fundemental concepts. 
##You just made JUNIOR. you have 0 credits. insert a quarter to continue##
Did anyone bother looking at the later parts? They're a bit more advanced than the basic stuff in part 1 (still not what i'd call senior level, but seniors should know it none the less) Part 2: SOLID - http://trycatchfail.com/blog/post/SOLID-Things-Every-Senior-NET-Developer-Should-Know-Part-2.aspx Part 3: IOC - http://trycatchfail.com/blog/post/Inversion-of-Control-Containers-Things-Every-Senior-NET-Developer-Should-Know-Part-3.aspx 
Just conjecturing here: Maybe you have custom controls that have "render this way in design mode" code that's crashing? Maybe open up a second instance of VS and attach it as a debugger to the first, with break-on-exception enabled.
[Link for the lazy](http://www.bugaidsoftware.com/)
It didn't even throw an exception (edit: at least, not one that the VS debugger caught). It went straight to "Microsoft Visual Studio has encountered a problem and needs to close", followed by "Microsoft Visual Studio has stopped working" with the options to debug or close program. Choosing the debug option, I got: Unhandled exception at 0x76c0b9bc in devenv.exe: 0xE0434F4D: 0xe0434f4d. Hitting continue from there (rather than break): devenv.exe has triggered a breakpoint Hitting continue on that simply closed the program. So... now what? Edit: after a bit of google-hunting, this seems to be a really common error (0xE0434F4D: 0xe0434f4d), with no real known cause. I have no idea how to proceed.
Shucks, I was hoping that it would break on an exception somewhere in your own code. Well I've got no further ideas.
Update: the problem appears to have fixed itself. I have no idea how or why, but I'm not one to question a good thing. Thanks for all your help :)
I had this happen to me. Make sure that in your constructor and load for your custom control, you aren't loading up a thread or anything silly like that.
Not too expensive. I wouldn't use it on greenfields covered by tests but on brownfield covered by poo... yeah.
Also, please, please, please, use the load or some other event to do custom logic that doesn't need to be done on creation. DesignMode isn't set yet. I hate loading up a test harness for a control in an assembly where someone wrote database access code in the ctor for a completely different and untouched control. ctor-&gt; Load-&gt; check for designmode. They have no idea that their code is executing when visual studio sets itself up. I on the other hand, constantly get their failing Debug.Assert crap in my face every time VS does its thing.
instead of checking for design time, they need to check the name of the executing process.
Try [rebuilding the resx file](http://www.knowdotnet.com/articles/rebuildresx.html) Failing that, if you have code in the default constructor then that could be killing it. If you do, try wrapping it in an if (!DesignMode) block (I think that's right)
Thank you for the feedback. I will look into that.
Don't unnecessarily couple yourself to an unrelated detail lime the name of the executing process. I prefer to use IoC for testability with mocks, and then check for design mode to set up design time data.
The problem is that design time checking only works when you are looking at that control by itself. If your custom control is nested, it's switched over to execution mode. That's how it handles the layout, etc. If you check to make sure that the name of the executable isn't "devenv.exe", you can be 95% sure you aren't executing in the designer. For 90% of controls, this isn't an issue. If your control uses threading or does work in the constructor or load, you might lock up your IDE.
The new SQL CE (Compact Edition) 4 is a contender these days too, with Entity Framework support, visual studio tooling, and other good things. It would be cool to see a shootout between the three (and the other ones we haven't heard of!)
You can check a shootout http://blog.cincura.net/231742-firebird-embedded-in-comparison-to-sql-server-compact-edition-4/
Great links!
using try catch forces it to use more registers (in this particular case). Very interesting.
I don't think you understand the [purpose](http://msdn.microsoft.com/en-us/library/b2s063f7.aspx) of summary tags...
Yeah it's annoying. We ran into this issue at the last company I worked for because we wanted to use the summary comments to generate documentation but they were a pain to read. What we wound up settling on is making a two slash comment above the summary tag with at least a general description. When you collapse it, it always shows the top line of a comment block, even if it's a mix of two and three slash comments. It's a little more work but gets the job done.
i understand how it is used for documentation. but since it takes up so much space (visually) in the class, it might as well be used more optimally there too
how generous! have an upvote seriously though, that's a pretty good idea. i hadn't considered it being possible to modify it through a theme. maybe i'll check it out
This is one of the reasons I think code folding is a bad idea. After bad experiences maintaining code that made heavy (ab)use of the #region directive, I always turn outlining off.
that's a reasonably simple, low effort solution. thanks!
I agree that just seeing &lt;summary...&gt; over and over again adds a lot of visual noise, and I'd also make the same comment for attributes. Both are useful of course, but once you start getting a lot of summary/attribute tags everywhere the collapsed code isn't much easier to navigate than the regular uncollapsed file.
Fun story: I *just* removed all the Code Contracts references in one large-ish section of our codebase because of the requirement of premium or ultimate wrt the visual studio integration, literally the day before they opened it up to professional as well. FML.
the highlighting of black text (function names) is brilliant. i'm adding that to my text colorings when i get to work monday. :D the rest might be possible in 2010 if you're making or modifying your own code view window... not sure if it's worth it since there's the workaround above.
How about ninject?
There is an interesting follow-up from Eric Lippert.
And, you are right! That's the main reason why it's under a separate DLL and packaged under **Microsoft**.Web.Optimization. For those not aware, it's a pretty common pattern for new libraries from Microsoft to make their way into the Framework. First under Microsoft and finally under System. Also, it's important to note that the NuGet package has literally no integration. I hope however that it will be more integrated when released in 4.5. :)
The guy behind this upcoming bundling stuff (it's currently beta) Mads Kristensen did a session on this at the Build conference: http://channel9.msdn.com/Events/BUILD/BUILD2011/SAC-837T
This is why I generally collapse method bodies, but keep documents open. It's a pain to scan through though. While on the subject of documentation comments, does anyone else find them annoying to read with all the XML tags? I really wish it would be possible to use javadoc-style comments instead and just have them compile to the XML-format it is now when you compile your app/library. Easier to read, and programs can still use the easy-to-parse XML file.
Yeah and it was the only easily findable "How to" that I could find on how to do it. I don't remember the video but the code I wrote show you how to dynamically register the HttpModule without messing with your Web.config or Global.asax.
Yep. In the first example, you're actually only storing the query itself, not the results of it, which means every time you go to do something with the results, you have to pull them again. A corollary of this is that the data pulled by the same query may be different each time you go to use it, so you shouldn't ever be doing what you were trying to do in the first example.
Well... time to go change everything. 
If you're just checking if an IEnumerable has items, you're generally better off using prods.Any() rather than prods.Count() &gt; 0. Count() will enumerate over the whole list, while Any() will stop once it can determine if there is an item in the collection. For a smaller collection, it's not really a big deal, but could slow down performance with a larger set. There's a couple of exceptions, but it's worth considering. http://blog.donnfelker.com/2009/06/22/linq-any-vs-count/ http://stackoverflow.com/questions/305092/which-method-performs-better-any-vs-count-0 Thanks for your tip though, I'll keep it in mind from now on. I never considered that before. 
In this case he needs to pull the items anyway so he would be better off doing the ToList() before doing a Count()/Any() on it and it shouldn't go to the DB.
Or, ya know, understand how linq to sql works (by design).
BTW, Ix is still experimental. However, it won't always be.
Except this particular issue isn't specific to link to sql. The LINQ code will behave the exact same way in EF. It's about the difference between IQueryable and IEnumerable. This same issue will come up with any ORM, it's not an error in fact. Just a misunderstanding on how LINQ and IQueryable works.
Thanks for pointing this out! I thought "oh, it's just LINQ to SQL, I'm using entity framework so I'll be fine!" Well, time to go change some code.
If you're then paginating the results you're better off having 2 queries.
How about this: You have an MVC application with two different types of views: big screen and little screen. We're sending a User model to this view that has basic customer properties, but 3 of those properties are IEnumerable. Something like Tweets, Friends, and Page Views. In the big screen view, we simply load everything, where the small screen version only loads the currently selected tab. The current tab is selected with a url parameter (Detected by a Razor control/helper). In this scenario, lazy evaluation would be a useful optimization tools because you wouldn't have to change the controller interface/logic to accommodate the needs of a view.
those still using System.Web.Caching might want to take a look at [System.Runtime.Caching](http://msdn.microsoft.com/en-us/library/system.runtime.caching.aspx) in the 4.0 framework.
I've been using [MemCacheD](http://memcached.org/) with the [Enyim client](http://memcached.enyim.com/) to cache across multiple applications. There's a 1MB limit on the size of objects you're caching. I think some clients have ways to split larger objects across multiple cache keys to get around that limit, but I've never needed to. 
That's one of the reasons I ask the question. What factors made you choose the solution you have, did the decision end up working out, etc...
IIS isn't going to be the problem in most situations where you need to cache data. IIS is actually going to be sitting idle waiting for data from the database. The performance hit is the time it takes the db to grab the data from disk as opposed to just pulling it out of memory.
I will try to hit this the best I can for you. If you are in a single server scenario and NEVER care to do anything else in the near term (say next 12 months), and have memory on the system running the site to handle your estimated persistent data load then System.Web.Caching used AS-IS should be fine. Here are things to consider if you move beyond any of the above restrictions: 1. If you think you may change caching strategies during the life of the system - You will want to put a simple pattern around your caching API calls. This will allow for easier upgrades or changes to other caching options in the future. Since caching api's tend to be build for that cache system and there is no standardization you want to do this to insulate yourself for big regressive changes across your code base when you switch from System.Web.Caching to say AppFabric caching. 2. If you plan to have a web farm with more than 1 box serving the same application and you are not using sticky sessions. In this case you will want to move to a external cache store like AppFabric in order to give all systems in the farm access to the same data. Even with sticky sessions you may want AppFabric as you can use it to decrease common data loads and opens up the possibility to move to stateless web applications later. 3. If you need very tight control over caching (such as TTL, expiration, sliding rules, update rules etc) then you may want to look at a more robust caching system than plain System.Web.Caching. 4. If you want to do things like pre-load data on application start or even have backend systems capable of updating cache data that the front end system is using live then you will want something more powerful and flexible than System.Web.Caching. I am sure there are some more I can think of given the time. If you would like a suggestion on what you can use please give me a somewhat high level idea of your application and what you are trying to do. A bit about me(doing this to be taken somewhat seriously): 15+ year enterprise systems engineer and architect using Microsoft development tools and technologies since 1994. Currently working at a financial company with a 3-million user system based on MVC3 and .NET 4 with AppFabric in a web farm environment so this stuff is kinda at the top of my head right now. 
I've been playing around with memcached and enyim recently too, but will probably have to ditch it because we need cache dependencies. I tried implementing the algorithms myself but I guess I'm not that smart =)
Why do you say it is a dead product?
This may be my entry level experience speaking here, but didn't some people use WeakReference as a way to cache small amounts of data?
I haven't seen any reason to alter my opinion of the situation since I wrote this in 2008. http://www.infoq.com/news/2008/11/DLINQ-Future 
Thanks for citing a source. That was an interesting read.
I'm pretty sure that this depends on the concrete class because the extension methods are only called when the class or it's base class(es) do not have that method. So for Count() on System.Collections.Generic classes you are right, but I'm pretty sure that the IQueryable implementations in linq2sql or EF translate that statement to SELECT COUNT 
Have a read of [this article](http://imar.spaanjaars.com/476/n-layered-web-applications-with-aspnet-35-part-1-general-introduction).
Redis is an interesting caching solution. If re-populating cache is expensive, Redis persistence (or memcacheDB) is an excellent &amp; highly performant way of doing so. I think the question of what to use really depends on the organization. Some shops will only use MS-certified solutions. Others are more open to OSS approaches.
I recommend taking a look at Cassette instead. It's much more polished. http://getcassette.net/
This was essentially the reason I created a blog back in the day. I kept running into new issues that had no solutions online that I could find (before SO). I would do a post with all the [non-helpful] error messages and then post the solution on how to fix it. 
Sorry but, I do not get the point the OP is trying to make with post. This is fairly common as the person himself answering for his question. Check the link below where you will find the some questions which have been answered by the the person asking himself. You can tweak the query to filter the question which have accepted answers by the same person also. http://data.stackexchange.com/stackoverflow/revision/60622/61973/answered-by-the-submitter
Oh, one last thing: The Global Assembly Cache (GAC) is evil incarnate. DO NOT USE IT until you understand it thoroughly, and have a sincere desire to drive yourself mad. Keep packaging your libraries yourself in the project directory. Just...trust me on this. :)
As a career .Net developer, I concur...
AutoFac is another popular DI framework. For data access, Entity Framework is the current hotness. I say "current" because Microsoft [can't make its fucking mind up about data access strategies](http://www.joelonsoftware.com/articles/fog0000000339.html). Well, for more than a couple of years at a time.
That article is over 10 years old and still relevant tiday.
Other popular (code only) dependency injection frameworks: Autofac and StructureMap. You don't need Fluent NHibernate anymore if you want to use code only mapping. NHibernate 3.2 has built-in support. Syntax isn't as good and documentation is lacking but otherwise it works. I wouldn't recommend using plain WCF if you need to offer tru RESTfull interfaces. Luckily there is [WCF Web API](http://wcf.codeplex.com/wikipage?title=WCF%20HTTP) which is really good at that. All the power without any of the hassle (configuration, proxies, bindings).
I prefer MVC endpoints for web services these days. Unity and Castle Windsor are solid IOC Containers that have a DI side to them.
Use generic collections and learn to use LINQ pronto. Read Jon Skeet's book called "C# in Depth". 
Download this free book by Rob Miles - Its a great starter book that covers .net and C#. Including things like generics and LINQ. http://www.robmiles.com/c-yellow-book/Rob%20Miles%20CSharp%20Yellow%20Book%202009.pdf EDIT: He also has a free book for Java developers switching to C# http://www.robmiles.com/c-yellow-book/C%20Sharp%20from%20Java%20Orange%20Book%202009.pdf
&gt; If you consume web services, PLEASE, for the love of all that's holy, learn how to use the ChannelFactory and ClientBase classes directly. DON'T use VisualStudio's "Add Service Reference" wizard unless all else fails. It'll be a pain in the ass to begin with, but you'll save yourself hours of configuration misery in the long term. Can you expand more on this point? I recently had to use the "Add Service Reference" menu on a project cause my manager felt it was the simplest way to get two of our apps to communicate. I've since removed it since I kept encountering exceptions due to having a some max file size config value too low. Although, I'd like to have some better more solid reasons to give him next time he asks me to "infect" my projects with service references.
Sometimes I feel I'm the only guy left writing ADO.net code and not hating it.
Lol...I'm actually rolling in a pre commit hook to try and detect/prevent references from the gac....
That link goes to the 2009 pdf. If I'm not mistaken, there's also a 2011 version of the book.
Kinda off-topic but what would you recommend to a .net developer trying to get to know a little more about Java?
Sorry about that. You are right..[there is a 2011 book](http://www.robmiles.com/c-yellow-book/Rob%20Miles%20CSharp%20Yellow%20Book%202011.pdf) I had the 2009 one still bookmarked. 
Changed sample rate which removed the whine
Dunno if you're a fan of Minecraft, but decompiling it and messing around with the sources is a great way to play with Java, while getting instant gratification from your experimentation.
This just about sums it up. I'd only add that there are .net ports of many popular Java libraries. They almost always have an "N" at the start or their name. (eg. NUnit = JUnit, NHibernate = Hibernate, etc...)
Totally, Scott Guthrie is Mr .Net and one of the main reasons that many of the highlighted frameworks are so well adopted in the .Net ecosystem. 
ADO.net is under everything.
Just a couple of rebuttal points: * Entity Framework : One of the downsides to EF is that you can't use plain old CLR objects (POCOs) as your domain models. You're tied into the classes that EF generates for you. With NHibernate and other OSS-based ORM solutions, your domain models can be retroactively wired into a database without any changes except a liberal sprinkling of "virtual" keywords to support dynamic proxying. In addition, changes to the database or business logic are exceedingly easy to manage since you don't have to re-generate DAO classes every time you turn around. * TFS : Why would anyone ever use a for-pay source control and CI system when there are so many proven OSS alternatives? (Unless your company is paying for a fully hosted and managed solution, that is. If that's the case, more power to you!) Git or Mercurial are both free and awesome DVCS systems, and I've never met a developer worth hiring who didn't have at least some exposure to SVN. If you're after it for continuous integration, I highly recommend looking at TeamCity or CruiseControl.NET. They're both well supported by the community, and have hooks into every major version control system. 
Not to be pithy, but pretty much the reverse of what we've recommended to the OP, I think. :) What kind of .NET developer are you? Web apps? Desktop/WPF? Core services? The OP said he/she was a system architect, so that gave us a little information on what kind of frameworks could be recommended. Give us a little info about your interests and job experience, and I'm sure someone around here can throw out a few good suggestions.
The sole purpose of GAC is to appease people who are nostalgic for DLL Hell.
Newer versions of EF (4.1?) support POCOs.
I use it as a stepping stone. After I generate the proxies for the first time I manually strip out all of the garbage.
Lots of great things in this thread. One thing I would say is that don't get stuck using MS-provided tools and libraries. A lot of them are good but there are, in some cases better, alternatives. The problem is that most of the samples/documentation that you will see will be based on MS technologies since that is what most people use. Here are a couple suggestions: * Web Framework - Definitely go with ASP.NET MVC. There are alternatives like OpenRasta, Nancy, ServiceStack as well. * ORM - Personally I am not a big fan of Entity Framework but it's good enough for most uses. I would look into Micro-ORMs such as Massive, PetaPoco and Dapper though if your needs are simpler or performace is critical. * Unit Testing - MSTest sucks. Use mbUnit or xunit. * IoC/DI - Autofac, Munq are both pretty good (and fast) There are a bunch of other tools (MSpec, ELMAH, Moq, etc.) as well but the bigger point is that the .NET ecosystem is not just MS-centric. Unfortunately too many people don't know this and just use whatever tools that come out of MS without doing any research. Don't be one of those guys. 
It's handy writing Android apps that's for sure. 
Re: EF - That criticism would have been fair a version ago. But you miss out on other low hanging fruit you could criticize instead, so ... I guess we'll leave it at that. EF is hardly the worst one could do where an ORM / DAL is concerned. Re: TFS - As far as pure VCS concerns go, I agree. However.... TFS provides many more capabilities than just that. You certainly can get to CI with products on type of FOSS solutions but.... most shops won't. It's just that simple. 80% or more them just won't in my experience. If you're living in FOSS nirvana and have never used TFS, and have never felt the lack, then my hats off to you - but it will be the exception by far.
Thanks for the info. Back in university, I hated programming and I account that for a lecturer who taught us to build swing apps on notepad. I have no idea how I passed those classes. The only reason I suggested a gui crud app because I wanted something simple where I could experience typical java development like creating classes, using some 3rd party packages, connecting to a database and let's not forget the factory factories. I've already built some simple console apps on a text editor and tried out the basic programming idioms found in every oo language. Do you think it's best for someone like me to skip to Spring? By the way, I read a while back that [Heroku supported Java](http://blog.heroku.com/archives/2011/08/25/java/). Can a Spring app run on Heroku? Their example tutorial uses servlets and xml and maven and it's all going over my head.
&gt;Unit Testing - MSTest sucks. It's actually pretty good if you use ReSharper, but that's an expensive tool. My preferences are NUnit and MSpec. &gt;...but the bigger point is that the .NET ecosystem is not just MS-centric. Unfortunately too many people don't know this and just use whatever tools that come out of MS without doing any research. Don't be one of those guys. This. A thousand times this. Microsoft has come a long way, especially in the past two years, and they make some excellent tools. But .NET developers who limit themselves to Microsoft tools and frameworks are basically joining a footrace while wearing a potato sack. :)
Clever! What sort of license are you attributing to this, out of curiosity? I can think of a couple uses for this (maybe after tinkering with the N*M part)
Much thanks. Heh, I sort of wish I knew about your library for a project I was doing 6 months ago. 
Sasa.Dynamics is the reflection assembly you're referring to, and is already separate. I think it depends on Sasa.dll though, although I don't recall now whether that's strictly necessary. I'll keep your suggestions in mind as I prepare the next release. Thanks!
Same here. Actually using this on Amazon AWS. Abstracting caching so as to move between no cache (local/testing), in memory cache (by environment) and external caching (staging and production) seamlessly was a must. The default caching system is not abstract nor configurable for these purposes. 
The sad truth is that in land of the blind the one eyed man is king and such kings are never in short supply.
Kinda crappy that it wants you to +1 just to see it.
Windows...meh. Windows Phone...meh. But VisualStudio, SQL server, TFS are all gold. After using SQL Server you'll wonder how you ever muddled through using Oracle. The same goes for Visual Studio. Vim + shell + make + gdb were good enough for a while, but they don't hold a candle to visual studio. You can apply edits to your code while you are sitting at a breakpoint in the debugger, click 'set next statement' to your new edit, and see how your fix works, all without restarting the app. Try doing that in gdb. It's possible, but painful. And then there is intellisense. While vim has omnicompletion, it just doesn't compare to intellisense. 
Thanks all, For your patience and willingness to help, I feel a bit retarded in this space. The business uses Access, Excel and SQL server to manage data. I'll be brought in to bridge the web gap and tie everything together. So there will be Pointy Headed Bosses that want to use Excel and Access for reports, and folks in the field that want to use their phone to enter data. The Express packages seem to be limited to specific deployments, Visual Web Developer, Visual C#, Visual C++ Express. Seeing as I need to bridge the Office Applications on the network with a database populated by the web, should I just pop for Visual Studio Professional or will the Web edition suffice at first? I think I want to move into C# but tbh I can't make sense of what's available in any given deployment or tool or what the trends are, for example, is ASP.NET essentially php using C# as the scripting language or is it another iteration of the VBA VBS stuff of the past? And what, exactly is .NET, seriously it's so obtuse I think it's some golden omniscient parser/compiler but can't seem to find a simple answer, will I be focusing on C# for web, desktop and CLI development or are there different paradigms? I spent some time in the past hooking into windows on a GUI level and all I remember is that they seemed to change their minds on things an awful lot, leaving lots of dependencies on legacy stuff and since I'm starting fresh, and will be given a lot of freedom, I want to avoid that. 
Also, if the company he's working at is worth anything he'll be put on an MSDN subscription.
True. Closing the browser tab also takes care of it. Which is what I did.
Get your work to shell out for the Professional edition. Visual Studio is an all-encompassing tool: it contains your editor, compiler, testing, deployment etc. It handles your full development process, in a tightly integrated way. Use C# - it's the most widely used language. .NET is just a huge library and a virtual-runtime. Think of it like C++, you get a huge range of libraries to use - anything from web to robots and it compiles down to machine code. .NET is very similar. ASP.NET is a web framework; a subset of libraries from .NET that allows you to create web-specific projects. ASP.NET is strongly typed, far cleaner and more powerful to use than PHP IMHO. Finally, just to confuse you even more there's two ways of creating your web-projects: 'Webforms' and Codeignitor-like MVC. 
Well, in a nutshell, .NET is the MS JRE. Code is compiled (be it c#, f#, vb) into CLR code and that is executed by the core framework. Do you have any experience with Ruby on Rails? MVC might be the best option for you if you're looking at a web based environment. I don't know how it would work for you just starting out but I absolutely swear by my http://www.pluralsight-training.net/microsoft/ subscription for keeping up with emerging technologies. They've got a lot of low level tutorials I haven't watched but generally everything I've seen on there has been good stuff.
Wow, thanks so much! This is essentially exactly what i was looking for and makes me feel more at ease with the transition. I'm actually a lot more excited about digging into the IDE now. Thanks again.
If your work won't shell out for it, it's [$549 retail](http://www.microsoftstore.com/store/msstore/en_US/list/size.24/ceid.172935600/categoryID.50804700/parentCategoryID.50804600/sort.listPrice/order.down?WT.mc_id=vssitebuy_buy). If you make money writing software, it's worth owning. 
why in the hell is this getting downvoted?
you fear loss of control. Have you ever used a make file? The Visual Studio equivalent is a .proj file. Visual Studio also has special flavors for its different languages, such as a .csproj, or a .vbproj, to take advantage of the difference in the compilers for each language. Have you ever used a shared object library? The windows equivalent is the .dll file, and a .net assembly uses the same format, albeit with different internals. You don't have to use Visual Studio to develop C#, but you're losing out on a *lot* of convenience. You can do everything you need with the free compiler and notepad. Visual Studio will just help you organize your many many files. Look.... It's a different world from *nix, but if you look close enough, you'll see that the differences are really quite superficial. Like two sides of the same coin. Don't fight the differences. 
Hey now! daemontools and multilog are pretty nice to have when you've got a cluster of lowlevel services set up! But yeah, notsomuch
Immensely infuriating! :|
Don't forget that Microsoft gives these away to start ups. Check out [bizspark](http://www.microsoft.com/bizspark/).
&gt;So there will be Pointy Headed Bosses that want to use Excel and Access for reports What a waste. SQL Server's Business Intelligence suite is fantastic. Unless they're using the Express version, they should really be using Reporting Services for their reporting infrastructure. This applies for SQL Server 2005 and up. 
That doesn't really explain why I can't render directly to the WinForms control, though. The Paint event is literally never triggered when I Invalidate() the control. I whipped up a sample app to show you what I mean: http://pastebin.com/HEqW08Rs The pictureBox_Paint method is called once when the grid is loaded, and that's it. pictureBox.Invalidate() doesn't refresh it, nor does a grid1.InvalidateVisual().
This is very interesting. However, give what I know about NHibernate, there is probably some other funkiness to creating sessions.
There are likely some static values being stored for CreateSessionFactory() as well. If you want to play more I would suggest getting the source: https://github.com/nhibernate/nhibernate-core. Source files aren't as organized as I normally like but the logical structure is fairly easy to navigate. 
Can we have an EF vs NH argument now please?
I'd also love to hear someone that is using it in production - especially code first development. Until this release I've never considered it something I'd use. No real reason, it just didn't feel right to me
Excellent comment. Microsoft is promising Enum support in 4.5 (finally!). The rest of your points stand. I've had some funky results with many-to-many associative tables with extra properties.
Looks nice, I'll give this a try in work tomorrow. thanks !
Have you seen this question on StackOverflow? http://stackoverflow.com/questions/21229/visual-web-developer-express-setting-document-root-for-dev-environment
Beware Rx, we went down that path, and just finished taking it out of our code base. Perf isn't there, and IMHO suffers from an unclear API and lack of execution control.
Incredibly cool post, yet stackoverflow closed it. God damn infuriating. Brogrammers....
Yep
Had a try, and found it was incompatible. However, shouldn't be too hard to get going. Keep an eye on the project.
Yeah, they closed it to reduce noise on the thread.
So I guess it needs to be asked but what's up with all the VB? Why aren't you drinking the Kool-Aid? Don't you want to be Kool?
Does it work with facebook?
Sounds vaguely like the NuGet Project Uncovered - http://elegantcode.com/2012/01/22/nuget-project-uncovered-an-introduction-to-the-series/ 
You can not create DLL's in Express. You can use them but not compile them - actually there's work-arounds but probably not in keeping with the terms of the LA. Other than that.. pretty much yeah, im not sure if you can do unit testing with express either. -- also, not that ive checked, but can you create libraries using VBC if you have express installed? 
Comming from a java/php background I would have thought C# would be a good start for him too ... BUT The difference between C# and VB.net is almost totaly syntactical, there are but a few differences. I notice OP has also used VBS / VBA in the past so he might want to try that too. You can easily convert between the two using tools like sharpdevelop. 
It's mandatory at work. That being said, both C# and VB.*Net* target the same framework and have almost identical syntax, except for control characters (or lack thereof) and declaration order. The differences are so trivial and the similarities so overwhelming, you can write a pretty decent converter in a couple of hours. I try pushing for C# every 6-12 months, but after the years I learned to not be a language snob and just appreciate it when I'm using the right platform for the job. Besides, if I wanted to be cool, I would have written a wrapper in D to consume in F# :)
Try Googling "c# linear regression". Here, I did it for you: http://beyondrelational.com/blogs/niladribiswas/archive/2011/09/10/excel-s-linear-regression-in-c.aspx
Relevant http://www.reddit.com/r/dotnet/comments/pvl4d/telerik_justdecompile_vs_ilspy/
if you can get your hands on a SAS licence, there is an API. http://support.sas.com/documentation/onlinedoc/guide/customtasks/ but you could probably do the same thing in R for a lot cheaper. 
&gt;The problem was the too generic exception handler. According to the MSDN documentation, Convert.ToInt32 only throws ArgumentException, FormatException and OverflowException. So, those are the only exceptions that should be handled. If people actually read the article they should get it. But yeah, an "open file" example would have been more to the point specially considering that try/catch in conversions is something that should be prevented. Exceptions shouldn't handle common user input validation so I'll agree the example is not the best.
thanks so much for your input.
Personally, it depends on the type of project. On one of the projects at my work, the db was a straight-up CMS so we went with code first. However, another project we did was heavily dependent and interacted with Dynamics GP data. In this case, we did everything model-first, since we had to do a lot of complex work that could only be done on the SQL end. So for the DAL, we just kept everything model-first to keep things consistent. This has been then pattern too for most of our SQL heavy projects, but for no-nonsense data storage, we just dive in with code-first and it saves alot of time.
If we have at least 80% of the requirements up front, we tend to go database first. Thinking about it at that level tends to help us come up with a much better design than code first.
The size and complexity of the database matters too. A database with hundreds of tables, sprocs, joins, etc. is potentially going to bog down the designer. For small, simple databases model-first works well; but I personally prefer code first as it let's me focus on my classes and business logic.
Prefer going Database First with our projects, for the same reasons that vsoul mentioned. We feel that it gives us more control than Code First does. Code First, on the other hand, works really well when you want to get something up really quick - like a prototype or an MVP. That's why you see most of the tutorials, blog posts use Code First. 
Whatever works for you is fine, but designing your models does not preclude designing your entities at the same time.
I'm a db first kinda guy. This works out for me normally, unless I get the greatest idea ever midway through the code, lol
Free. Otherwise, ILSpy. 
To me the best feature is the automatic handling of Mobile output. I just implemented a small app and was stunned just how simple and fast it was to write.
Only one? Must be an early adopter.
Do you prefer fighting a designer or working with code? A designer sounds like a good idea on paper but on the long wrong it bogs you down. With the latest EF you can even generate your Code First from an existing DB if you prefer to make the DB first. Yeah I know it make the Code First name kind of regrettable. For background, I've been using EF with models for a couple of years and am now very happy with model less (code first) EF.
Migrations look pretty amazing. I'm happy they were thoughtful enough to add command to get a sql script from one migration to another. I'm still going to wait for [EF 5.0 for enum support](http://visualstudiomagazine.com/blogs/data-driver/2012/01/entity-framework-4-3-gets-final-tune-up.aspx) before going EF and never looking back.
We started our latest, large project with CF but switched to model-driven to avoid the code becoming littered with database-specific attributes. We use the POCO generator and keep business logic away from the domain too. I think the model-driven enforces a cleaner, more thoughtful design from the outset, especially in a fast-paced agile project where time is key. We took our existing CF domain and directly ported it to the model-driven style and realised our database was in a pretty bad state, with circular references and unconstrained relationships. That said, you can generate an EDMX from the Code First model afaik, so I guess it's of little consequence really - it's what works best for you. That said, having an EDMX allows dev to get the DBA involved and palm off the boring bits to them :)
That's my question - I found WCF so much harder to get up and running than web services, but I did it because I want RESTful services that can be consumed by anything - server code, javascript, mobile apps. So where does Web API fit in?
&gt;I think the best approach is to use an ORM where appropriate and optimize in the specific scenarios where performance is inadequate. Words to code by. Write *good* code and optimize where it's actually problematic. Oh and if you're not precisely measuring bottlenecks and re-measuring after optimisation, you're wasting your time.
WCF is still the technology of choice for communication between .NET applications and with specialized end points. Advantages * two-way communication * lots of transport options (HTTP, TCP, named piples, message queues, custom) * lots of format options (XML SOAP, Binary SOAP, JSON, custom) Web API is being positioned specifically for public-facing HTTP-based APIs. By giving up the flexability of WCF you get features that are more specific to REST-style communication. 
&gt; Its built completely on WCF I heard the opposite, that it is a new technology stack that doesn't use WCF's foundations. 
You might try ASP.NET Web Pages as a stepping stone. It is basically the V part of MVC and is remarkably similar to classic ASP.
The problem with that philosophy is it fails when faces with systematic performance problems. If every query is inefficient then you can’t point to any one and say it’s the bottleneck.
http://wcf.codeplex.com/wikipage?title=WCF%20Web%20API%20is%20now%20ASP.NET%20Web%20API The wcf web API team about the name change.
Unfortunately it doesn't say anything about the relationship between the 'real' WCF and WCF/ASP.NET Web API.
If every query you are writing is inefficient, either you are writing bad code or the tech doesn't fit your scenario. Your architecture is the bottleneck. As the article says, a layer on top of ADO.Net will always be slower than ADO.Net (obviously). But there are a ton of scenarios where this performance hit is quite acceptable in exchange for a big productivity boost. I've read a lot of EF performance nightmare stories that I simply never had to experience. I suspect most of the cases are people that don't picture what kind of SQL is being produced with their LINQ or simply people that don't know proper SQL. N+1 problems that could be solved by an Include() or two and other horrors. That said, I've seen so many horrors done in plain hand-written SQL that no matter the tech, bad developers will be bad.
Meh. Might have been worth reading ten years ago. I mean, &gt;Try to use StringBuilder when creating complex string manipulations and concatenating strings multiple times. No shit! Really?
It's an interesting idea, and would be a lot faster than a HAAR cascade. But I can't imagine this would be viable across all skin colors.
were very bad. You won't be missing out on them. Sorry for the split post, my iPhone typing skills suck.
Darn, the only talk by Bart that's uploaded discusses WinRT. Looks like I'll have to wait. Thanks for the tip on the Dutch talks, guess I'll feel better that I'm not missing out on much.
This article has clearly been copied from some old website to their blog to help promote whatever it is they're trying to flog. Marked as spam.
Hopefully you'll like MVC. I love it. Whereas Web Forms feels like a native Windows app forced in an HTTP jacket, ASP.NET MVC fits that jacket like a glove.
Have you tried [Git Extensions] (https://code.google.com/p/gitextensions/)?
Just an FYI - You can use MVC and WebForms in the same project. So if you wanted to, you can develop any features in MVC and have all the existing stuff in WebForms. Same with Razor too.
No, build was marketing for windows 8. While you can't write metro style apps for windows 8 in .net, you can still write desktop apps in .NET and more importantly ASP.NET isn't going anywhere.
&gt;**Only** supports SQL Server Express Edition (which we’ll install for you, if you don’t have it) I still find the limitation understandable.
Uhg, Metro. Microsoft's own research suggests tooltips are a bad UI element because the user must hover the mouse to see them, and they've been toning down their usage ever since. Out comes Metro, where entire swathes of the UI are inaccessible unless you hover your mouse over random spots of the window. I'm looking at you Zune and Windows Live Messenger. I really hope Visual Studio doesn't follow Zune and Windows Live Messenger. Visual Studio is their best product and they could easily ruin it with poor Metro usage. What's next, a Ribbon?
Interesting to see they're going back to battleship grey. Windows forms from 1999 aren't gonna look outdated next to this anymore!
As long as it's a theme and not actually Metro, I'm ok with this.
I'm still very much stuck in the ExecuteDataSet and stored procedures way of doing things. Does anyone else stuck there for a while have a good tutorial for EF getting started? The ones I've seen are like trying to drink from the firehose. I feel like my skills are atrophying. 
I like the looks of my VS. What's with all the grey? :-\
Honestly, it looks like crap. I like the pretty environment. I am usually staring at it for hours on end. My code window is very colorful as well because the colors aid in my ability to parse text very quickly.
For extremely high transaction systems that have to handle high levels of contention and concurrency problems (that will use a RDBMS) go model first. These systems are almost always focused on the data and there is not much actual behavior. What behavior there is takes a back seat to data operations. And much of the business logic should actually be in the DB. Foreign keys, stored procedures, triggers, UDT and UDF etc control what happens. The code will be focused primarily on display and getting data into and out of the DB. Those types of systems are actually quite rare. They are typically not determined by how much data but instead by the velocity of change. When code does do a bunch of actual stuff it is usually on data that is static. In these cases usually there are warehouse type dbs/tables set up that the code will work on. All other systems, and these are the majority, I go Code/behavior first. Keep the DB as simple as possible. Only introduce foreign keys, triggers, SPs, unique constraints only when I must. Really the only thing I add are indexes to support support faster data look up without killing inserts and updates (and I rely on the RDBMS profiler tools for that). But most modern DBs with even mediocre hardware can support many users with moderate inserts and updates. I rely heavily on Active Record and Unit Of Work. The Unit of Work will make all the DB changes in a transaction. I do keep the db fairly normalized. Not only for performance reasons but also because it keeps my Active Record classes much simpler. The key is do everything you can to to put business logic either in the RDBMS OR the code. Understand your system and choose one. If you don't your life will become hell. Logic in code will have to jive with DB business logic and vice versa and this is hard. Way harder than it has to be. 
They seriously need to drop the all caps tabs and such
Posted this over in /r/ASPNET but [RequestReduce] (http://requestreduce.com/) and [Cassete] (http://getcassette.net/) are also good options to look into if you are interested in bundling solutions. 
I don't understand all the the hate for the new design. Do people actually use all the toolbars and icons? I can't imagine anyone that uses VS reguarly not relying on keyboard shortcuts. Plus all those toolbars take up valuable screen space. Personally I prefer my VS to be as clean/simple as possible. 
Setup a repo on Github. It will be much easier to track things and you can setup multiple versions, if necessary. I use the template from here as my starting point and customize it to my projects: https://github.com/github/gitignore/blob/master/Global/VisualStudio.gitignore I recommend checking it out. 
Hopefully it won't be the memory sucking vampire that 10 is.
[2 of 4](http://www.youtube.com/watch?v=RO3sGvu3LeA) [3 of 4](http://www.youtube.com/watch?v=VVbVeTRuJ2g) [4 of 4](http://www.youtube.com/watch?v=aRmTSn0CugU)
Oh nice! I already have a git repository. Fun as hell! :-) 
Blog page crashed already. Can anyone point to a copy somewhere? Google doesn't seem to have it cached.
Weird.. it's still not working for me. And I get this super weird error: &gt; undefined method `&lt;=' for nil:NilClass Looks like a Smalltalk error. Not sure why that's coming up though.
Are you kidding? Having used a lot of other IDEs, Visual Studio is doing it right. Moreso than anyone else
Thank, good sir! And thank you even more for not pitch-forking me that it was only a simple google search away!
Well he does say free. I have nver used code compare so can't comment but will add a positive for those that need svn support. http://ankhsvn.open.collab.net/ AnkhSVN is very good. 
Needs more VSVim.
If you're willing to pay for it, check out textcontrol.com. I bought this component to use as an HTML editor I could plug into an online survey application I'd written in .Net. Survey creators could use the editor to change the apperance of the questions on the website. This was used in the back end desktop application (Winforms). The time/expense it would have taken to write something like this from scratch was far more than buying a license for the component. 
NCrunch
It does but I prefer hitting a chord in VS to run my tests. I currently set Ctrl+~,Ctrl+~ to run my test. That's much easier than Alt-tabbing into nUnit and running my tests. The less friction involved, the more the tests are run, the faster I notice failures.
What about [PinEdit](http://www.pintexx.com/Products/Text-Components/pinEdit/Getting-started)? It's not perfect but I've found it to be the best of a bad bunch.
I'm not sure if NUnit has a command line form that would let you do this or even if VSE would allow it, but you could make it run tests as a post-build action. Just a thought...
I like it :) Although I'm using my real name for my account so I'm probably going to try to avoid the bad achievements (if I went for them it would be just to get them and I'd promptly remove the code). I hope I never have to work on a solution with 50 projects. Or build a class with 10 levels of inheritance. Or... curse words? Really?
I'm not married to it. My boss is, though. So for now I'll just be happy it's not causing me all the problems you were having :) I'll keep P4 Merge in mind though just in case issues start cropping up.
Policies are pretty much based around registry settings. Group policy objects are based around text files downloaded to the local machine to define domain policies which set the registry keys within the policy areas of the registry. I wouldn't recommend programatically setting GPO's, they should be centrally managed and tested before release into production. However ... [1](http://blogs.msdn.com/b/maxv/archive/2009/07/22/working-with-group-policy-objects-programmatically-determining-registry-values-to-enable-disable-set-a-specific-policy.aspx) [2](http://www.microsoft.com/download/en/details.aspx?displaylang=en&amp;id=14536) [3](http://stackoverflow.com/questions/981010/how-do-i-configure-group-policy-using-c) 
I made the mistake of downloading VS 2010 beta and when the final came out it was an ordeal to get it to install. I can wait until the RTM comes out for now.
From the link, "use a WebBrowser control in edit mode". OTOH if you only need rich text formatting (bullet points, bold-italic-underline, colors), simply convert the rich text to HTML. 
I'm installing it all inside some VMs Windows 8 + Visual Studio 11 Windows Server 8 + TFS 11 If any of that works, I will be amazed. Also, did they previously use Akamai on these big release days? This stuff downloading SLOOOOOOOOWWWWWWW.
I thought it might be for a non commercial product. I just get irritated by commercial companies using crufty looking libraries just because they're free.
The 'running with scissors' achievements [don't gain you any points](http://channel9.msdn.com/achievements/visualstudio), though.
Is there a good reason for it to be set up that way? That sounds like a terrible way to organize a solution from my experience, but I suspect it's possible there may be occasions where this is necessary or the best option. I can't imagine what those occasions might be though.
Another option... if you have SQL Server 2008 available you can include the charting libraries from there. Microsoft bought Dundas a few years back and then pretty much included them as is. 
Lots of third party integration, it's also a client/server solution and since we wanted a very lightweight client we offloaded pretty much all the heavy lifting to the client, so there's model/provider/interface/transport projects for each integration. Our PM believes in strongly namespaced lasagna code. Luckily I spend the majority of my day writing lightweight reporting solutions to pull metrics from this beast and don't deal directly with it for the most part. Also, I just got to work and checked, the server solution is up to 310 projects now.
Good question. We've been using Infragistics since 2003 so we're quite happy with them and haven't considered moving our entire app to a competing set of controls. They do look good and are competitively priced. 
This sounds great but looks like a steep learning curve. I'd appreciate any tutorial info you may know about. 
I think it has something to do with how we do our server api versioning (fallthrough to unmodified dlls), but I'm not entirely sure.
Part 2 available at http://www.reddit.com/r/dotnet/comments/qd501/building_expression_evaluator_with_expression/
i don't see separation of concerns as having anything to do with whether or not classes are in the same assembly. can you elaborate?
I love MSMQ and have used it since the pre-.NET days, but one thing you pretty much just have to resign yourself to is the occasional inexplicable error that takes 10x too long to track down and ultimately turns out to be something trivial somewhere. System.Messaging in particular is guilty of only showing HResults instead of actual useful errors. I think the WCF APIs are a little nicer, but at some level, you just sort of have to plan for this sort of nonsense to happen occasionally when MSMQ is involved. I've found that the best way to troubleshoot MSMQ is to either build your own tools around it or to get 3rd party stuff like QueueExplorer. I don't necessarily recommend building your own version of QueueExplorer, but you're going to find that most problems boil down to things like queue level Windows permissions, message serialization or encoding, etc., so it is typically stuff you can write an automated test for if you want to build a tool which you can just run when something is going wrong and have it check common problems.
They tried with the [WPF Toolkit](http://wpf.codeplex.com/releases/view/40535), but it leaves a lot to be desired and documentation was pretty lacking the last time I checked.
Putting code in different assemblies requires you to be explicit about your dependencies. So, for example, your business logic assembly should not reference your UI layer assembly. But your UI layer assembly probably does reference your business logic assembly. Assemblies / assembly references are not the only way to enforce this separation and layering, in .NET you can also use namespaces or convention. The most fundamental thing about assemblies are that they are units of deployment, units of versioning, units of security, and units of scope. Contrast this to classes are smaller units of security and scope. Contrast this to methods which are yet smaller units of security and scope.
Ok first performance hits are a non-issue so don't worry there. Generally you want to be a lazy programmer. Which means you don't want to write code 2x if you can avoid it. In general you want to section off commonly used code into their own libraries so they can be re-used easily in other projects. This also allows you to easily update only part of your program when you need to change something. For example it's not uncommon to see programs broken into a UI, business logic and data access project (sometimes one data access project per data system). This arrangement allows developers to update just the UI or just the data access layer without rebuilding and pushing everything. This is also good general practice as it forces you to think about how you should separate your program and enforces cleaner integration between reusable code. For small programs this is generally unnecessary however for larger more complex systems it should be done to help keep things organized, make updates easier and to improve re-usability of common code. 
from what I've seen so far, Telerik's libraries have FAR more of a native WPF "feel" to them. With Infragistics, the only reason I would have stuck with them is because I knew the object model from WinForms, and that isn't the same.
Programming is one of few professions where your boss rewards you for figuring out new ways to avoid work.
my only real beef with msmqueue is that it's really good at silently failing.
will microsoft allow for the replacement of knockout? i'd rather be using backbone.
http://thevalerios.net/matt/2008/11/microsoft-chart-controls-released/
You should cross post this to [/r/ASPNET](/r/ASPNET) 
I didn't know that! Thanks man. Upvoted you.
I agree, but I don't think it is WebForms' fault that someone created a component library. There are a couple of minor issues with regards to the ScriptManager, but nothing bad enough to justify adding a component library.
The GAC has it's place. Side by side deployment alleviates the maintenance hell so long as you version your assemblies.
Specific cases. It is not the first recommendation I would make. 
that is good news if so, i talked to a microsoft developer/evangelist and he said it takes some surgery to get it to work. (from the sample application he gave anyways)
Of course you need some surgery but from what I've seen in the Beta, it's not complete.
The other option is to parse Environment.StackTrace, I guess, from inside the callee...
Incredibly expensive to do that on every log call.
Farewall System.Reflection.MethodBase.GetCurrentMethod().DeclaringType, we hardly knew ye
Combine this with the [Conditional attribute](http://msdn.microsoft.com/en-us/library/4xssyw96(v=vs.90).aspx) and you've got yourself a pretty handy addition to a logging framework
If you are open to queue technologies &amp; have some flexibility in your environment -- look at RabbitMQ or other AMQP implementations. They don't have the restrictions on message sizes that MSMQ has, clients can ship with a binary (vs. installing MSMQ locally), you have great HTTP APIs and web management tools, and it's inter-operable with other languages. My MSMQ debugging days are long behind me &amp; I'm a firm believer in AMQP as the best queuing solution available today.
regarding the negligible startup cost of separate class libraries (and I want to reiterate very negligible, and non issue especially for web apps), that you can use ilmerge to merge into a single assembly if you really cared.
&gt; you could just inject a Func&lt;DateTime&gt; in the constructor I wanted to avoid injecting anything for such a simple operation. &gt; you might set the global for a specific test, and then the next unrelated test is also affected if you forget to restore the original at the end That is true. I think it depends on the unit test runner you are using. I've been using nunit/ms unit test framework and I haven't had any problems. I tend to initialize the "common" mock objects (e.g. ILogger) before each test. I added note about the issue one might have.
To avoid the hideousness of applying attributes to my Action methods, I simply have a specific ViewModel for each View. There isn't anything in my ViewModel usually\* which I don't want my use having access to. \* - I say usually because there may be situations where that isn't the case but I certainly would take responsibility if I screwed up somewhere and not blame the framework.
Ok a couple things here. In general it's not a good idea to expose mid-tier objects to your UI layer anyway. Why does your data object have fields and/or methods in it that your view does not need? Also you may want to look into model binders. I am no Ruby geek but in MVC you can define custom model binders for any type. You can then include code to block binding on critical elements. This would be highly suggested if you are planning to use mid-tier objects at the UI layer. Finally I cannot find it at the moment but I recall that the form security features used in ASP.NET WebForms are also available to MVC. The mechanism includes an encrypted key and hash in a hidden field that is designed to prevent tampering. If a form post does not match the fields it was sent out with then the request is ignored. 
I'm actually a career ASP.NET MVC dev but the thing I wanted to focus on was this issue also exists in ASP.NET MVC as well. Sure there are ways around it and sure there are other ways of doing it HOWEVER almost every example of ASP.NET MVC from Microsoft and co is usually using the domain object directly. Even NuGet.org does this. It's just something I wanted to make sure people were aware of.
Something everyone should be aware of, just because an example does it that way or because an ISV does it does not mean it's the way you should do it. Of course this all depends on how secure you need to be and what that particular form is doing anyway. However I would be interested to see where there is a microsoft example of using model binding on a membership provider object instance. Another important thing to note is that this highlights why it is important to desgin your classes correctly. Make thoughtful use of getters and setters. Leverage interfaces and abstract inheritance to allow one data model to easily serve two masters without having to propagate read/write concerns on your object up to your controller. A perfect example I did recently was a data class for managing user security and settings. The core model had more fields than I would want in a post. I had a version of the class that the UI and interaction layers used and only allowed writing to "safe" properties and then a more open version of the class that was used by the business layer once the process got past a certain point. Since both classes utilize the same base it is only a few lines of code in each to define the differences. I have started to play with dynamic typing some in hopes of simplifying this but so far I find this to be the most safe way to allow mid-tier objects to be used upstream. This also removes any dependency on your UI layer to enforce core business/tech rules allowing you to change out your UI layer easier. If you look at most microsoft API's this tends to be the case in thier desgins at least in concept. The exposed properties on thier objects are very carefully thought through as to what you can read and write. Now with MVC they have started to give you much more power in this arena however you will notice that context is extremely important and they still rather strictly control from where you can access what and when. This is mainly done to keep the developer from doing silly things that would break the lifecycle (as if there arent plenty of those as is). You want to take the same kind of tack when developing your mid-tier. Don't assume you are writing the top tier code (even if you are), write your mid-tier like the developer consuming it will mess it up and look for where those mess ups can create security holes (among other things) like this and code defensively to protect sensitive members. Do not expect your framework to do it for you as this injects a shadow dependency on that protection provided by a UI layer API down into your mid-tier business and processing layers.
I used the Visiblox API. It's a very in depth library, with quite a few features, and provides an excellent free version. I've used it for quite a few personal projects. Link: http://www.visiblox.com/ Features (free vs. premium): http://www.visiblox.com/feature-matrix-features
In my experience, WebForms were a complete clusterfuck. Sure, you can create a form pretty easily, but when your pages become really complex, it is really hard to change things and to maintain the code. &gt;However, it lacks proper support for reusable components. (MVC) I disagree. Have you created any HTML helpers? They are by far easier to create than Controls for WebForms. Your conclusion only attempts to bandaid an inherent flaw in ASP.NET WebForms - that is, it was meant for WebForms developers to transfer to the web world. You might as well just switch to MVC. WebForms is going to a die a slow and painful death. Slow, because there are many systems out there that currently use it. Painful, because it is a nightmare to maintain. 
&gt; MVC forces separation of the code into distinct layers nah. In practice everything get's cramped into the controller anyway. 
&gt;But I'm not convinced that HTML helpers are powerful enough to replace webcontrols because they seem to lack a cshtml template and a controller. You've never build an ASP.NET WebForms control, have you? Or are you confusing Components with UserControls?
As a longtime Web Forms developer I have to agree with the bulk of this post. MVC certainly has its place and I think it has indirectly improved the Web Forms model. I've always felt like most of the Web Forms complaints have to do with the fact that some Web Forms developers are fucking idiots. I routinely integrate jquery with my Web Forms apps (made especially easier with .net 4). It gives me the best of both worlds - server controls when I don't care about the markup and my own custom shit when I do. People really need to get over the fact that one is "better" than the other or how Web Forms will be deprecated in the future. These are two models developed in parallel that Microsoft fully supports. How many VB.NET developers out there were told to move to C# or perish? If you're comfortable with MVC, great! If you're comfortable with Web Forms, great! Everyone's a winner!
&gt; For example, if you click on "poke a friend" on your social networking site, it should trigger a "poke a friend" event that the server responds by increase the poke count on the target record, or perhaps create a new poke record. &gt; If you do the alternative, you'll end up with a big update function on your "user" controller that checks what kind of update is being performed, and passing that off to various subroutines which may end up doing things like creating a new poke record. What are you talking about? You don't make one Update action and then pass in a shitload of arbitrary parameters to guess what kind of update you want. You make a *new* action. ie: public ActionResult PokeUser(int id) {} That's it. Then you have a link or a form or something that posts to Controller/PokeUser/1. 
This is the exact problem a lot of developers have after using webforms. I led the charge where I work to move from webforms to MVC3 and some people would get upset about not having a "gridview" control. 
So are you saying that it would be counter to MVC philosophy to have a GridView HTML Helper? Because they're essentially the same thing. "MVC" is about improving the separation layer between the view and the controller and promoting a stateless architecture. AFAIK, it is NOT about discouraging the use of reusable components.
Yes, my bad. Most of my knowledge on the web "MVC" architecture comes from Ruby on Rails, and that seems to be a common way of doing it. So, between proper actions and a proper architecture for partials, it seems to me that ASP. Net MVC &gt; ASP. Net Webforms &gt; Ruby on Rails.
This^ MVC is cool, for the cool kids to get excited over. It's not better, or more powerful, it just is what it is. Trying to take on the ruby crowd and bring them over to the Microsoft world so Microsoft can get their foot in that door like everything else. That's likely why they put it together. My work involves not just doing stuff via CRUD and data manipulation. We build business apps which interface with external API's through web services or DLL's. I'm not really sure how that fits into the MVC side of things, if it's possible at all. If you're just building a simple(ish) site which has a single backend DB to persist the data, then I'm sure MVC is great. Beyond that basic pattern, how great is it? So in that case, this is relavent: *[The best advice I’ve seen so far is that WebForms is the platform of choice for building web applications, where MVC is more suited to building web sites. This is still a bit abstract since there’s no clear definition of web applications, but I think it’s safe to say that if you’re building a web version of a win client application, you’re building a web application. If you have a ‘grid’ in your page for purposes above that of just layout, you’re building a web application.](http://weblogs.asp.net/tonylombardo/archive/2009/06/23/mvc-vs-webforms-a-clear-loser-emerging.aspx)* 
That's what I did. It went well. It takes some time to wrap your head around certain concepts but there are good tutorials and documentation (not to mention books) that help.
Thanks for this insight
seems faster for small stuff. nicely done.
Sure, nothing wrong with that.
Yes this is a common pattern in an ASync event. A complete event will fire if things go well and a failure event will fire if they do not. Often the failure event is a custom type with additional args or properties that contain information about the failure. This allows you to easily create Success and Failure methods separately for each event as you may want to do very different things in the case of a failure. 
Works the same way, sounds to me like the OP is trying to treat an ASync API in a synchronous manner. It's a file upload service which means you likely have a request/response with some kind of security/certificate pattern. Very rarely are these done as pure Synchronous API's and even if they are available the API developer generally encourages the consumer to leverage the ASync API.
You are correct, "Visual Basic .NET" specifically refers to VB 7 and "Visual Basic .NET 2003" is VB 7.1. All other versions of VB are officially known as "Visual Basic X" where X is a number (versions 1 thru 6) or a year (version 8+). But why are we talking about marketing terminology from nearly a decade ago?
Unless you've a background in VB6 there isn't much point in choosing VB.Net over C# at this point in time. Microsoft only created it as a carrot to the huge crowd of existing VB6 developers to get them to adopt the .Net ecosystem. You can easily access the few VB.Net-specific features by just adding a reference to 'Microsoft.VisualBasic.dll' to your C# projects. Personally I find VB-style language syntax awkward and verbose to parse, but I'm used to C/C++/Java style syntax.
&gt; XML literals I really don't see the need for XML literals. Can you give me some examples where use of literals has some advantage over using the existing libraries for parsing XML? &gt; declarative event handling In VB this is really just syntactic sugar so that developers don't have to worry about assigning stuff to multicast delegates, but again it doesn't really offer any significant advantages over how events are declared and delegates assigned in C#. (I also feel that the WithEvents/Handles keywords mask the real functionality, meaning that it is easier to develop without having a good fundamental knowledge of how events behave in .NET - some may interpret that as a Bad Thing). &gt; a switch statement that doesn't suck VB's switch statement is the outlier here, it is syntactic sugar for constructing limited and rather unwieldy If statements. Let's take a look at the [TIOBE Programming Community Index for March 2012](http://www.tiobe.com/index.php/content/paperinfo/tpci/index.html) (a measure of popular programming languages in the industry). Bold items use the `switch` convention used in C# (a 'C-style' switch): 1. **Java** 2. **C** 3. **C#** 4. **C++** 5. **Objective C** 6. **PHP** 7. Visual Basic 8. **Javascript** 9. **Python** 10. **Perl** Clearly the C-style switch is sufficient. I would even go so far as to say that VB's switch statement is dangerous, as it allows programmers to shoehorn logic into a switch structure, because they think it is a better construct when it would in fact be much more appropriate to use an If/Else instead. &gt; iterator lambdas I'm struggling to find examples where C# would _need_ this feature. It seems like more syntactic sugar - although I'm probably just ignorant - can you post some examples of usage in VB.NET? &gt; paramterized properties C# supports parametrized properties through [indexers](http://msdn.microsoft.com/en-us/library/6x16t2tx\(v=vs.100\).aspx).
I agree. I got my start in VB6. And I got my start in professional development when (as a network admin) I proposed ideas for VB programs that could help in our office. My boss pushed me to learn C# instead of moving up to VB.NET and I thank him for it every day. I find the C# syntax so much more elegant than VB. Not that there's anything wrong with people who choose VB. The last thing I want to do is create yet another "my language of choice is better than yours" pissing contest. But if you're looking to do it professionally, your life will probably be a lot easier witch C#. When I graduated from that job to a development position I saw very few VB specific postings (yes, they compile to the same thing, but it helps to work in the same language as your team).
I've coded in both VB and C for years and write code in both VB and C# now. And for all my new projects I prefer C#. &gt;declarative event handling Have you ever had the handles come off? Literally there are many cases where VB will loose the all the "handles" for a certain control. This never happens with C# and Event += EventHandler. Also I love the fact I can just Event -= EventHandler to stop handling... you can't stop handling events added with the Handles statement in VB. You can AddHandler / RemoveHandler which is basically the same as C# anyway. &gt;switch statement that doesn't suck Don't you mean Select... Case. It's not even named right in VB :P. Functionally there is no difference between the Select case in VB and a switch statement in C# except the fact that in VB you don't have to Break. In fact I prefer C# because you can have cases fall through to the next state when appropriate. 
If there's a better sub-reddit for this... let me know. 
Check out [Visual Web Developer 2010 Express](http://www.microsoft.com/visualstudio/en-us/products/2010-editions/visual-web-developer-express). It's free. In the project properties when you open the web site, you can set the IIS configuration settings to connect to your local instance of the web site. You can right click the site to publish to a location and copy that onto your site (or copy directly, but be careful about your Web.config). You can also compile libraries in that, or in [Visual C# 2010 Express](http://www.microsoft.com/visualstudio/en-us/products/2010-editions/visual-csharp-express), also free. I could take your money, but I don't mind helping you do it yourself for free. Don't PM me. Keep the comments here so others that might happen to run across it can learn something too, maybe.
If you have the site running in IIS: * "File" * "Open" * "Web Site" * Choose "Local IIS" * Find your site If not, you can still locate it on your file system and use the development server that comes with VS to compile and run it.
Thank you. I have VS 2005 running. I'm having a difficult time "opening the web site". When I go to "File &gt; Open &gt;" I see "Analysis Services Database", "Project / Solution", and "File.." I connect to my website usually by placing my files here \\172.16.10.11\c$\Inetpub\wwwroot\KenticoCMS\
I don't know anything about Kentico CMS and a cursory glance at their website didn't reveal any details. Do you know if your module that you are attempting to compile can be compiled using .Net 2.0? This is all that VS 2005 can handle. You will need an express version if you need .Net 4.0. If possible could you link to the module you are attempting to install?
Congrats on being the first person tagged by me as "ass" in this subreddit.
I'm told we are running .NET 4 so yeah that would be a problem. I'm installing the express version now. This is the module I'm attempting to install: http://devnet.kentico.com/Marketplace/Modules/Banner-Management.aspx It's extremely well documented for someone who knows what they are doing. (My version is the 5.5R2 for Kentico, not the 6.0) Edit: waiting for someone to reboot my remote computer to get Express going.
&gt; I really don't see the need for XML literals. Can you give me some examples where use of literals has some advantage over using the existing libraries for parsing XML? Go try to do any sort of dynamic XAML work in WPF or Silverlight and get back to me on that. You don't see too much of that from the C# junkies; I'll take the XML literals over a bunch of XElement and Xattribute constructors any day. &gt; I also feel that the WithEvents/Handles keywords mask the real functionality, meaning that it is easier to develop without having a good fundamental knowledge of how events behave in .NET How often do you need to do anything beyond basic add/remove event handling? If you do, don't use WithEvents. Simple as that. Also, it was very amusing to see optional parameters and late binding being heralded as amazing new features in C#, when they've been in VB forever. I like C#, I learned .NET in C#, but way too many developers act like they're close to the metal because it has semicolons. They're just as abstracted away as VB. 
Sadly I have to agree with you. Don't get me wrong, there are plenty of jobs that use VB in key markets like health care and finance, but C# is the language of choice for any new MS technology.
Xamarin is the company, Mono is the product... I do ASP.Net development using Mono regularly. The last time I attempted to use their mobile (IOS) products there were missing bits of the .Net that made it impossible to go beyond a certain point, but what I did do was far easier than writing a Objective C app. I should note that they've since added the bits that I was missing (Parts of the web services client dealing with authentication), but the client changed directions.
&gt; I would even go so far as to say that VB's switch statement is dangerous, as it allows programmers to shoehorn logic into a switch structure, because they think it is a better construct when it would in fact be much more appropriate to use an If/Else instead. Dangerous? Because you can specify a range instead of having to repeat the variable name twice for each case? 
&gt; I'm struggling to find examples where C# would need this feature. Why do you need anonymous functions at all? Why not just use single-method classes like they do in Java? Here is an example of using it in conjunction with XML literals: Dim images = &lt;html&gt; &lt;body&gt; &lt;%= Iterator Function() For Each fn In IO.Directory.EnumerateFiles("c:\\", "*.jpg") Yield &lt;img src=&lt;%= fn %&gt;&gt;&lt;/img&gt; Next End Function.Invoke() %&gt; &lt;/body&gt; &lt;/html&gt; As you can see, I didn't *need* to do it that way. It's just one more single-use function I didn't have to declare. (And of course it becomes more interesting if that iterator had a closure over other variables in the function.)
Yeah I've read it. I've installed some other modules, and it's a pretty simple process. This one has extra steps though of changing DLL files in visual studio. 
Oh this is making sense now. Now if I can only get my IT guy to uninstall VS 2005 because I believe it's blocking my install of VS 2010.
Question though... I won't be able to look up this file just by searching my local drive. When I upload my files it's to \172.16.10.11\c$\Inetpub\wwwroot\KenticoCMS\. So how do I find that project file to open?
Ah, ok. That makes sense. Well, once you get vsExpress installed, hopefully it will be a pretty simple process of making the changes in code, compiling to a fresh dll (should show up in the bin folder when you click "Build Solution" under the "Build menu), and then deploying it like you would any other third-party module. PM me if you get too stuck and I can give you some tips (I don't know anything about the cms, but I've been using vs for over 4 years).
Kind of. The company I'm doing work for has their own servers. I can only access it from a computer within their network. So I log on remotely. 
VS 2010 should live quite happily with other versions of VS. The laptop I'm on now actually has VS2005, 2008, and 2010 all installed. I could even take this a step further and install express editions of all three if I wanted to.
Proof that a mud ball of features doesn't make a great language.
so what does make a great language, then?
A range or multiple values is not fall through - C++-style fall through serves a completely different purpose. For example, in some cases you execute A then B, and in some cases you execute just B, but you only have to write the B code twice. However, c# explicitly does not allow case fall through either. In any case, finding switch constructs in code is a red flag that says "review this code carefully, it's probably poor",regardless of what language it's in. (not all switches are bad, but most point to code or design that is needlessly complex.)
Needlessly complex? What, are you one of those people who think switch blocks should be replaced with inheritance hierarchies? Now fall through with non-empty case blocks, that's an actual red flag. 
Yeah, to be honest I was quite happy doing VB but I see no harm in developing skills in both - if nothing else I just get a better understanding of .Net itself.
I installed a trial version of VS 2010. I now have the website open... I'm looking at a blank screen though. Here's my first step I need help with: Remove all references to Kentico CMS libraries from the BannerManagement project and replace them with references to corresponding DLL files from your web project /bin directory. a. CMS.CMSHelper.dll b. CMS.PortalControls.dll c. CMS.Staging.dll d. CMS.DataEngine.dll e. CMS.ExtendedControls.dll f. CMS.GlobalHelper.dll g. CMS.IDataConnectionLibrary.dll h. CMS.SettingsProvider.dll i. CMS.SiteProvider.dll j. CMS.UIControls.dll I have all the DLL files. Thanks guys! Edit: Figured it out
Nothing screams "innovation" like an embedded OS from 2004. *sigh*
By the way, do you use weak events? If so, what framework?
I see a "TFS Project" as a repository. I found that one repository was enough for the couple dozen applications I maintained. Look at it this way. Did you have multiple SourceSafe servers? Did you want multiple SourceSafe servers? If the answer is yes, then you want multiple TFS Projects.
I posted an article on my blog a while back on how to do that. Here ya go: http://www.bobthegeek.com/2010/03/easy-jquery-locking-table-headers-they-even-toggle/ I also just created a jQuery plugin for frozen columns if you need it. Hope this helps. 
Have you tried [DataTables](http://datatables.net/)?
Can vouch for telerik controls. Great out of the box but also highly customizable. Fantastic support and user base. Telerik pays for itself many times over on my projects. There are some quirks here or there but the forums usually have you covered.
Fair enough. You can keep up all you want with the bleeding edge of technology, but unfortunately most employers are most comfortable with what's familiar. And ultimately, a job is a job.
This came so close to working. However, the fixed header was unsized and aligned to the left on page load. The worst problem is that rebinding the gridview caused the fixed header and scrollbar to disappear as if it was never applied to the table. A regular gridview with the original headers is generated instead.
I normally do not - in most cases it ends up causing too much friction, and adds more complexity than it removes, unfortunately. As you may be able to tell, I am not a fan of artificial complexity. If only we could go back in time and change the design of .net 1.0.
I don't use them directly, but I do have some framework classes that do. Basic stuff like collections that listen for property changed notifications on its childern. I also have a read-only observable collection that doesn't leak. (I can't believe the docs still don't warn you that the built-in ReadOnlyObservableCollection&lt;T&gt; leaks an event handler.)
I don't like the arbitrary difference between [] and (), but I do agree that =&gt; is a much better syntax. `Function()` is a great teaching tool, but is unusable with MVC's Razor templating engine. 
I fail to see the difference. Perhaps it's just me, but I can't see any scenario where I would use it on top of my existing controllers. So for me, both are software development components which you can use to implement a REST API.
There are different kinds of WCF. I am talking about WCF Data Services, which does not suck for REST at all. In fact it fully implements the Odata protocol, which lets you do all kinds of fancy things such as data queries out of the box. Have a look at this website: http://www.odata.org/
www.servicestack.net - you can thank me later.
I don't know about WCF Data Services, but I already have RESTful JSON services using WCF in an Asp.net application without any problems. I guess they wanted to make it a little easier? With WCF there was about 15 lines of web.config and 15 lines of boilerplate code to get full JSON services to work.
What problems did you have? I found it quite easy after the ~30 lines of boilerplate config and code.
The author has the PUT and POST verbs backwards. PUT is for complete objects, such as an addition. POST is for partial objects like an update. 
Actually PATCH is for partial objects. Which leads me to much confusion as to what POST is.
I do it the same as the author, the reason I use POST for creating a new resource is because I don't control the the URI of where lives at, but once I get the location of the it from the response all further updates are PUT.
Did you post that link from a phone? I ask this because the first letter is capitalized and looks a little off. :)
On a more serious note, is this an alternative to Web API or WCF? 
Yes.
I think Microsoft are doing the right thing, this sort of decision needs to be made so that companies who refuse to invest in infrastructure don't hold back everyone else.
At some point you have to say "enough is enough, it's time to upgrade". There's no reason for most of the companies that are still on XP. Perhaps this will start moving them in the right direction.
If they're happy with outdated things like XP then maybe they're happy sticking with .NET 4.0.
In every company I've been in that used it, their reasons were either money, or legacy software (i.e. money again). That's fine if you don't want to spend the money, just don't expect to have all the shiny new toys.
Of course there's a reason. Times are tough, and things like OS upgrade programmes are expensive. They are being cancelled/postponed everywhere. The danger is for .net to lose its lead on the desktop, if something else comes along. It also does no favours to devs stuck in that kind of environment.
Only if they made it to sp3
Java? Doubt it.
Well that was sort of my point. You appear to think that .Net could lose the lead on the desktop, who do you think it would lose it to?
But still no WPF.
The Channel 9 [courses](http://channel9.msdn.com/Learn/Courses) might help. They also have [C# for Beginners](http://channel9.msdn.com/Series/C-Sharp-Fundamentals-Development-for-Absolute-Beginners) though that might be too "newbie" for you. Microsoft's [C# primer](http://msdn.microsoft.com/en-us/library/zkxk2fwf\(v=vs.90\).aspx). Also, their [Learn C#](http://msdn.microsoft.com/en-us/vstudio/hh341490) portal.
It literally stands for Preinstallation Environment and it's built for custom deployment of Windows. Basically it's a stripped-down Windows, suitable for boot from CD/usb/network. I've used it a lot for system rescue with some special tools.
Try converting some of your old projects from VB.Net to C#. You could get by with using MSDN library, though a c# reference will probably come in handy. I had a project to convert a C# project into VB for one of their developers who had never touched c#. There was a slight learning curve, but it's using the same library, so it's more or less just a syntax thing.
im in the same boat. its really easy. don't fret.
I'm doing this tutorial right now http://www.asp.net/mvc/tutorials/mvc-music-store/
Jon Skeet's [C# series on TekPub](http://tekpub.com/productions/csharp4) is well-worth the $$$.
I'm a fan of the [Pluralsight](http://www.pluralsight-training.net/microsoft/) training videos. They've got a good C# section, as well as a plethora of other instructionals, most of which are Microsoft/.Net oriented. 
His book "C# in Depth" is a good read if you really want to understand how/why C# works. It demystified some things for me like lambda expressions. 
I think the EAV pattern is something that should be avoided. You sacrifice reliability and speed for extensibility. For example all of your values must be saved as strings that get converted into their true data type which makes it more difficult to enforce the validity of your data. It's also more expensive to store and process at the database. That being said, you have a few options to pivot this data: 1) you can use the PIVOT syntax in SQL if there is a definite list of attributes. 2) you can use dynamic SQL to extract the metadata and craft your PIVOT statement on the fly. I've had much success with this method, but you *must be very careful* to protect against SQL injection. 3) report writers such as SSRS have the ability to create data driven columns using the matrix control. I imagine this would be similar to the ReportViewer mentioned previously. 
Not to mention that if you've done much JavaScript you are 90% of the way there on the syntax. The rest is stuff you would learn in Vb.NET anyway.
Whenever I have to write VB code, I use this [VB and C# comparison guide](http://www.harding.edu/fmccown/vbnet_csharp_comparison.html). I've found it very useful.
&gt;I think the EAV pattern is something that should be avoided. You sacrifice... I agree completely. However, the database in question belongs to an enterprise-level application developed by a different company. I can't exactly dictate to them how to build their database. I am merely developing a secondary interface for viewing information. Concerning the listed solutions: 1) While I can certainly produce a list of attributes that exist currently, it is a very long list, and can change at any point in the future. In the application, these attributes are called ASI Tables. They are part of a 'record' template. Multiple ASI Tables can be assigned to a single template. They can have any number of columns, and can be modified at any point. There already exists several dozen different types in our data. 2) This solution may work. I'll have to learn more about the PIVOT statement before I can be sure. Every example I've seen has shown it to require prior knowledge of the column names, but I suppose that's what the 'dynamic' part is about. 3) I would like to avoid using the ReportViewerControl. The whole purpose of the application was to replace a monolithic report. Thank you for your ideas. #2 will definitely be looked at closer.
I started as a VB .Net dev when the framework came out in 2001, mainly because I worked with VB5 &amp; 6. It was a natural conversion and I used it for years. I was lucky as far as switching to c#, because all of the tutorials for anything new were first written in c#, then translated later. I'm a bleeding-edge kinda guy so I always want to play with what's new. A few years ago I noticed that the number of c# jobs dwarfed the vb .Net jobs; my decision to switch was based solely off that. However, as I started looking for a new job I only applied for vb positions. I was hired by a big name company to develop and maintain asp .net web apps. They knew my background and I was hired, just to find out it was a c# shop. I was scared that they must have overlooked my resume or something, and would be let go once they realized their mistake. But they knew and I guess based on both my experience and confidence I showed on the interview it turned out ok. It wasn't a bad as I thought and they threw a pretty difficult task at me right off the bat I think as a test, and my asp .net knowledge saved the day. Before I left I was mentoring the new folks who had more c# experience than me... Go for it...c# seems to me to be so much more "pure" than vb. I know this isn't what you asked for, but before I made the switch, I asked peers who mostly shut me down with the standard "both languages do the same thing, why waste your time" roadblocks. If it hadn't been for me getting hired not knowing what language I would be using, I'd probably still be coding in vb... TL,DR; Not links you asked for, but encouragement from my experience with switching
&gt; It wasn't a bad as I thought and they threw a pretty difficult task at me right off the bat I think as a test, and my asp .net knowledge saved the day. Before I left I was mentoring the new folks who had more c# experience than me.. Shouldn't this tell you that programming in VB wasn't nearly as bad as perceived, and that your experience in VB.Net was actually a positive? I know I'm just tilting at windmills here, but there's nothing magical about semicolons. I get the impression that most people in this thread think that someone who chooses to work in C# is automatically a better programmer than someone who chooses to work in VB.
I'm in your same boat. Upgraded from VB5 / VB6 / "Classic" ASP to .NET and went with VB.NET as the natural / easy choice. Thanks for the encouragement!
I used AVERT, cool stuff! What do you think about using powershell instead of .net if it came to PE?
Microsoft will never open source anything... Wait.. Wat?
Good to them... and especially the open-source advocates within Microsoft who have made this possible; this wouldn't have happened a few years ago. 
.netmf is open source, too. They seem to like open sourcing their .net frameworky stuff.
Who is "we"?
Check out this lovely flame-ridden thread from a few weeks back: http://www.reddit.com/r/dotnet/comments/qlsjy/asp_net_webforms_vs_asp_net_mvc/
&gt; Who wants spare time for his project idea. FTFY
Short answer: * Web Forms: When you want something done now. Internal apps, rapid prototyping, etc. * MVC: When you want full control over the HTML being generated and have the time to do things "right". Public-facing websites. * Web Pages: When you full control over the HTML being generated, but not the overhead of building out a full MVC stack. Blogs, mini-sites, rapid prototyping 
so much for the relevance of FUBU mvc project.
I've never really understood this view. The only thing I can think of is that MVC is confusing at first. From a development perspective and getting going I find ASP.NET and MVC comparable. The only advantage ATM is webforms has a much larger ecosystem of 3rd party controls available for UI. As far as basic development its the same as webforms with some different nomenclature. Where you get into serious differences is when you want to do more advanced things with routing or custom server controls. Even in that world you can still stick to good old user controls with simple code-behinds (as long as you don't rely on viewstate/postback; which can be bootstrapped to MVC not that you would want to) until you are ready for something more robust. From a testing perspective MVC actually saves me time because I can easily automate the testing of all my main features at compile time without creating MVVM or MVC pseudo-patterns with webforms. 
Testability, code portability, better control over application and request lifecycle and no postback/viewstate crap are the primary factors for me.
&gt; The only advantage ATM is webforms has a much larger ecosystem of 3rd party controls available for UI. That is why I recommed it for internal applications. You don't have to think about the HTML if you don't want to. Sometimes I build whole sites dynamically just by manipulating control trees. But that isn't really the only advantage. Each Web Form is more or less fully encapsulated. You can just start building a page without worrying about the rest of the application and you know exactly where to look when trying to do maintenace. With a MVC setup your code is scattered all over the place. Even on a small project I find myself constantly jumping back and forth between the various controller, view, and model folders. And then there is the monster routing table. Preventing this from becoming a nightmare requires a huge up-front investment. 
&gt; From a testing perspective MVC actually saves me time because I can easily automate the testing of all my main features at compile time without creating MVVM or MVC pseudo-patterns with webforms. That's a myth that people are constantly going to be burned by. When properly separated, low level code is testable, period. It doesn't matter if you are using MVC, Web Forms, or raw HTTP modules. In fact, all three should be using the same underlying libraries for data access and business logic. But the low level code is also the code that needs the least testing. Most of the time calling a stored procedure either works or it doesn't, subtle bugs are rare. The part that is most likely to be broken is the part that is hardest the test, the actual generation of HTML and the interaction between you client-side and server-side code. No amount of unit tests is going to replace rigorous UI testing. 
This is just blog spam anyways. I reported it
+1 for nuget, -1 for lack of resharper and linqpad
All .net developers.
No with MVC you can write direct clean tests against your controllers, routing and event code. This is stuff often stuffed in code-behinds and ends up being a mess or stuffed into another pattern. I am not talking about data access or business rules. I'm talking core user interaction functionality that can be tested atomically. 
For me it was the ability to have exact control over the HTML being generated. I still use Web Forms as my default, reserving MVC for important projects.
"Implement Cache support." is still on MonoRail's to-do list. That doesn't sound promising to me. EDIT: Oh look, they also have the same mass assignment vulnerability that we see in Rails. And they don't even bother warning about the risks. http://www.castleproject.org/monorail/gettingstarted/crud.html
Now imagine it with all the resources that went into mvc instead distracted to monorail.
&gt; In fact, all three should be using the same underlying libraries for data access and business logic. Did I miss something in the past few years? It seems like this simple separation-of-concerns concept mentioned above gets reinvented every year or so in both web and thick clients, and that whatever the pattern or concept of the day is becomes the only accepted one; I didn't seem to catch this vibe as much when I first entered the industry about 10 years or so ago. On the actual topic, I've done next to nothing with MVC, but on Web Forms, I always tended to stick with regular HTML server controls and simple controls like the repeater; gave me the most control over the HTML. 
Who has spare time?
My extension list: * **Disable Mouse Wheel Zoom**. Since my Ctrl key would register for a split second after Ctrl-S saving, immediate scrolling attempts would sometimes zoom instead. * **Disable Regions**. Because fuck regions. * **Indent Guides**. Shows &amp; highlights vertical lines for indentation. * **PowerCommands**. There's a handful of cool things in there, like "open containing folder", and "email codesnippet". * **Productivity Power Tools**. I love the "document well" settings and the ability to locate my tabs on the left and have them autosorted by project. * **Spell Checker**. Checks comments. * **Visual Studio Color Theme Editor**. So I can ditch the blue hippie crap and go back to having a light gray window theme LIKE GOD INTENDED. 
One thing you can do is use the profiler, and take an instrumented trace. That will give you the number of calls to each function, and might put it on a timeline so you can get something like a log of what called what when.
Yeaahh... Btw, I want to run this for a 14 project ASP.NET solution. Any other ideas?
You're looking for the StackTrace and StackFrame classes in the System.Diagnostics namespace, I think: http://msdn.microsoft.com/en-us/library/system.diagnostics.stacktrace.aspx
Normally that is done with INotifyPropertyChanged.
Well, WebAPI is more about building "RESTful" webservices which you would then consume (possibly via javascript). As far as where to start...I personally like "Javascript:The Definitive Guide" as a great all around js book, but it's probably going to move a lot slower than you are going to like. You might want to look at CodeAcademy.com if you prefer to start by jumping in with both feet.
[This](http://nathansuniversity.com/jsreview.html) popped up in my email yesterday. Might be a good place to start.
You really need to know JavaScript before you can write CoffeeScript.
I like where your head is at. 
Thank you! I am currently learning WCF and I would definitely look into it. Looks very exciting. Will this work on Mono too?
Yes, battle tested on Mono!
I'm on my phone at the moment so can't round up all the links for you - google 'servicestack mono' and you will find what you seek. also check the google group, Demis has posted his linux setup as have others.
Alright, thank you very much for the help!
the [effective c# book](http://www.amazon.com/Effective-Covers-4-0-Specific-Development/dp/0321658701) probably has what you are looking for
What helped me the most was the first chapter of [SICP](http://mitpress.mit.edu/sicp/full-text/book/book.html). Learning the design patterns is more valuable, I think, than anything specific to c#. Something a lot of .net tutorials seem to miss is the way lambdas capture variables, so you can make a function which accepts some parameters and returns another function containing those parameters. 
Rick Strahl is one smart cookie.
http://www.amazon.com/Functional-Programming-Techniques-Projects-Programmer/dp/0470744588
Great link, thanks for sharing!
Thanks! It's nice that they included why they are recommended. 
This Zach Shaw character comes across as a bit of a bellend. Some good info in there though, cheers.
If you're dealing with a long, writing is atomic on all 64 bit systems already. Reading is atomic on any architecture
It looks good, but do they *really* have to tie it to a Windows upgrade?
honestly i normally just use some basic xml serialization instead.
I negotiated for a portion of my week to be dedicated to learning new stuff, but the rest of it is just having to fit it into when I'm commuting and in the evenings. 
I used to as well. By hand configuration sections are a pain in the ass till someone showed me CSD. It's quicker than XMLSerialization and it allows your configuration to be managed by production support through the IIS management tools if the application is deployed in that container.
I'm in the same boat. As much as I love programming, I'm often so mentally exhausted at the end of the day I that I don't have the energy I wish I had to work on side projects. I'm often worried that my technical proficiency is going it to make me a dinosaur faster than if I was at a slower paced job. My only solution is to subscribe to as many job related sub reddits as possible. So I read Reddit while my development system is compiling, booting up (can be a 5 minute process), etc to try to intersperse learning throughout my day.
&gt; I negotiated for a portion of my week to be dedicated to learning new stuff. I'm going to have to remember to do this one next time. I've learned is that most companies never have time or money allocated for employee skill improvement, even though it often has the biggest payback.
I'll go into more detail. We run two 30 minute training sessions (three presenters in rotation) for the entire team each week where I pick a topic and do a short presentation on it. If it only takes 20 minutes then it only takes 20 minutes but it can never exceed 30 minutes. The training sessions are set in stone and are not moved and people can not claim a work emergency and leave (this applies to me as well). Normally I pick something about our product or environment that people might not know very much about. The real purpose of these sessions to to help people identify what they didn't know they didn't know. 
I keep up by creating projects in new technologies. I'm learning MVC by building a client's site in it. I learned jquery by that lovely "fake it til you make it" technique, having confidence in myself to be able to learn it and saying that I could do it. I'm learning server admin because I'm team lead, and nobody else knows how to do it, while I'm the only one willing to give it a shot. I have personal projects on the side, sure, but they don't eat up all my spare time or anything. You really just have to jump right in and start building something with the new technologies (prototypes first to ensure you don't waste a ton of time finding out it's not the right tool for the job). Practically ALL of the companies I've interviewed with and worked for said during the interview process that they offer resources for their employees to learn. Be that books, seminars, other devs, etc. 100% of them lied through their teeth, and offered nothing of the sort. Hell, I just had an annual review a couple months ago, and when my boss asked what I'm needing from him / the company, I asked for a simple single book. "Sure thing! Whatever will help you continue learning." I've asked about the book 4 or 5 times, even offered to pay for it if I could get reimbursement. Still nothing. You really have to do things on your own if your company won't pitch in.
Thanks for the feedback. I got a simple demo working with dropdowns. http://pastebin.com/nt8yVQ13 It is still kind of a mystery how it works. Could i put an entire form in a jQuery modial box or sliding tab and submit without refreshing the page? can webforms be converted to MVC or would i need to start my next project as MVC? 
Powershell - we'll make a really powerful scripting language and then go ahead and bury it under a level of verbosity that would make a Java developer cringe.
I have a very similar opinion to the point where I think IronPython might be a better fit for many of the cases where I'd consider using powershell.
I buy whatever books I need and just present the expenses claim with the attitude that they're going to pay for it. I think the few hundred quid a year I spend on books is well worth it. So far I've discovered that when presented with a bill for a legitimate business expense it's never a problem.
&gt; I have nobody around to learn from, which makes it hard work when I could do with someone to ask questions and provide guidance myself. How do you feel about the various .NET communities out there to ask questions of? Besides the humble [/r/dotnet](/r/dotnet) and [/r/ASPNET](/r/ASPNET), there's the Stack Exchange sites [Stack Overflow](http://stackoverflow.com/) and [Programmers](http://programmers.stackexchange.com/), or the somewhat popular [MSDN Forums](http://social.msdn.microsoft.com/Forums/en-US/categories) or even Quora or Twitter. That said, I have enough time here and there to work on personal projects that push me and my knowledge quite a bit. I don't rush them and often take big breaks from working on them. And when I feel I need outside help I have turned to these sites in the past, or to reading some key persons in the .NET community (the Wintellect guys, Eric Lippert, Jon Skeet and a few others) for ideas. I don't mind in my personal projects if the ideas take some time, and the process seems to help my professional work.
I keep reading articles about the power of Powershell (and it really is pretty powerful!) and ultimately, I keep going back to straight up DOS batch files and calling out to Python/Ruby for my more exotic scripting needs because the interface to Powershell is SO FUCKING UGLY. Looking at Powershell, I find myself pining for the terse grammar of COBOL.
&gt;How do you feel about the various .NET communities out there to ask questions of? Besides the humble /r/dotnet and /r/ASPNET, there's the Stack Exchange sites Stack Overflow and Programmers, or the somewhat popular MSDN Forums or even Quora or Twitter. Yeah, I use other online sources frequently, but sometimes it'd be nice to discuss and walk things through with someone. At times it's hard to get across what you're trying to say technically, online. This goes both for questions and answers.
wringer
Continue to learn. That's the best advice I can give you. I hate working with people that refuse to change something because "that's they way we do it" and no other valid reason. Also, WebForms are dying but not dead there are many companies that have large sites that they will most likely want to keep updating rather than rewriting the whole thing to use MVC. Check out http://www.asp.net/mvc the tutorials will get you up to Speed on EF, MVC3/4 and everything else you said you've been missing out on. The plural site videos on the side I have found to be really good as well. I should note that I am in a similar situation supporting a very large WebForms site.
Have you considered contracting in your off hours? With your own company you can dictate that you use the newest technologies.
Aside from all the good advice above, double check you don't have a local .NET community group that meets regularly. In Indianapolis, we have indynda that meets monthly. That can hook you up with some local mentors and at the very minimum keep you plugged in on what's current. But, you won't gain the in depth knowledge you need w/o getting into some code weekly in your off time.
All the blogs out referenced here are great. In addition I have a subscription to pluralsight which I am rather fond of. It's been good for me and I was able to get my employer to cover it (cheaper for a year than going to a single conference). Granted it's all on my own time but these days if you don't do it, you get left behind.
&gt;I have nobody around to learn from Have you ever thought of visiting a several days long .NET conference? I appreciate the possibility to meet other developers and talk to the speakers. Particularly smaller converences with a familiar athmosphere are good to come into conversation with the other attendees.
Yes, definitely the fast track way to learn
Yeah, I came across that namespace and I can list the running applications. My goal is to resize all the running applications. Any pointers on how to get-size/resize current open windows? thanks.
I was working for the same company for eight years, and felt myself stagnating the same as you. I got laid off, and it was the best thing that could have happened. Five years later, I work for a development shop that's constantly working with different clients (hence different technologies and codebases), and it's wonderful. Update your skills. Write that pet project you've been meaning to get to using new technologies so you have something to show prospective employers, and move on to bigger and better challenges. 
This is exactly what I do, I get a lot of exposure to tech that I would never otherwise get to try out.
This introduces a dependency on the DAL method to return a lazy enumerable. Any change to the strictness of its result could alter the threading behavior of its callers. That'd be a great thing for C#'s type system to help you with by having any "yield return" methods produce a more specialized, compiler-only interface (ILazyEnumerable&lt;T&gt;?), but without having that invariant in the type system it has the potential for trouble. At minimum consumers of presumed-lazy lists should assert the place up. And second, it'd be cooler to see an example with asynchronous paging to a virtualized grid (i.e. running queries for rows in a given range when the user scrolls the page into view). Not blocking the UI for the query is good, but you're still dumping hundreds of thousands of items into the UI, and the DB is running the full request even if the user only looks at the top 20. Developers seem to be uniformly too lazy to page their queries, and the more RX can help with this, the better. Third, how certain are we that this can't leak a DataReader? If the query is ended early, will RX always clean up the underlying enumerable? What about exceptions in a callback? I'd hope they handle this well, but for the time being I still get anxious when I see "yields" in a "using" block.
In my experience anything dealing with government IT is pretty cushy. If you don't care about the latest and greatest and/or you want a will paying job with good benefits and low stress, then stay. However, if you want to learn and grow, then challenge yourself. You sound like you fall into the latter so I would tell you that you should get yourself up to speed first. Get involved in some open source projects on GitHub and CODEPLEX. That last bit will give you experience and a public portfolio to share with potential employers. Best of luck in whatever you decide! 
Thanks for the comment. This does introduce dependency on lazy DAL. If you want to avoid that you can have your DAL return a datareader and convert it to an Observable using Observable.Create method. You are correct that the database will run the full query even if the user looks only at 20 rows. For me requirements where that user might want to export all rows so loading all data had more sense. As for rx cleaning the enumerable when using ToObservable rx will dispose the underlying enumerable when the subscription ends (even if it is ended prematurely) So if the user clicks stop button it won't load all rows from the database.
I was in pretty much the same boat. I(we) realized thst wr could start integrating mvc &amp;4.0 without the customer knowing or caring. Is it your own company telling you what tech to use? Our govt contract doesn't specify the tech to use, does yours?
I can definitely relate to this... I'm in sort of a similar situation. My advice is to utilize your downtime the best you can: learn new technologies, and consider doing a personal project or two. When a new project comes up at work, volunteer your services and use your newly-acquired skills to implement it.
I was in your shoes 6 months ago. I worked for the government and was making a decent salary. I spent most of my time doing 2.0 and 3.5 web forms parsing out XML for web. Once I realized there would be no moving to new technologies I decided it was time to move out to the private sector. I didn't want to be in the same place in 10 years and then get stuck in a situation where I didn't like my boss (or general work environment), and then be 10 years behind the curve. I'd be stuck. I'd be making a really nice chunk by then but how much is that really worth? I moved to the private sector. I now develop touch screen apps, mvc 3 (even 4 beta), java for android, and way more. 6 months ago I'd be lucky to write my own class statements and namespaces. I can't say that in working for the government I would have ever learned any of this without any real need to. I hope this helps.
Simple. If you aren't challenged, leave and find a challenge, or go stale and become more unemployable as time goes on. 
We actually do use MVC, LINQ, .NET4, jQuery, etc and I feel the same way. 
Of course you could still use vs2010 &amp; compile it to 3.5. I'm guessing they probably wouldn't want you putting mvc on the server either then. You might be able to get around that with ' bin deployment', which is basically deploying your mvc dlls with your project. We had a lot of trouble with that also. Luckily we are admins on the server so we can get the stuff on anyway. Btw, I thought the 4.0 framework got on our servers through a windows update.
This metric is based on search results. The only thing it measures is how much a community likes to talk about their language of choice. It could be that Java programmers are just a bunch of chatty Kathy's. Secondly looking at the chart and stats you can clearly see the long term trend is that it's gaining popularity ever year. Here's a link to the chart: http://www.tiobe.com/content/paperinfo/tpci/images/tpci_trends.png The chart shows year over year growth. The only other language that shows that kind of growth is objective c. The blog post makes the claim that c# "is declining" based on 2 cherry-picked data points. Additionally it actually moved up a ranking while looking at those dates. 
Based on the end of the article, feels like author is just feeding his confirmation bias.
mods should really ban this user from this subreddit. All of his content is from techrights, which has nothing to do with technology or people's rights, and everything to do with bashing Microsoft. I don't care about the Microsoft bashing, but this user contributes nothing useful, only spam. 
This. Not only do you have the opportunity to learn but most of the projects that you are working on provide the perfect opportunity to apply those skills. It's not just .NET frameworks either (even though there is a lot there, especially the new Async stuff), but even stuff like JSON, REST, MVC, NoSQL, all of those matter. 
Yeah, see the edit I've just made on my original post.
This is an excellent idea. I'm going to have a pop at it also.