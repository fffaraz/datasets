Same situation as you, i started 2 weeks ago, and im eating everything from pluralsight... The only thing i feel that i cant find a good tutorial, how to divide your solution into layers.. I can do that but i cant seems to find a good ser of rules.
Just in case you're interested. [Rider has vue templates too](https://blog.jetbrains.com/dotnet/2018/02/22/web-framework-updates-rider-2017-3-angular-vue-js/), contains all ReSharper features, and is cross-platform as well.
I'm building real time air traffic analysis tooling using (asp) .net core. Besides the ease of use of C# and the .net ecosystem it's also quite performant and stable. I could have chosen to run all this in a micro service environment but it all easily fits on one decently sized server anyway for now so I'm going with the IHostedService approach until there's priority to split up. My environment is OS X, with Visual Studio for Mac, and docker for test and deployment. I'm using MSSQL as database because well, entity framework. MSSQL runs on all server environments these days anyway. 
Surely some post flair would solve this issue. Have a flair for Help Needed. You can then filter these out if you don't want to help anyone. 
Ooh that's great. I'm going to take a look. I wonder how they handle all the webpack hooks they created.
macOS using VS Code and or / Visual Studio for Mac. Deploy to Linux.
Drowning? * Clicking the New tab and scrolling to the bottom, the last item is 3 days old. * Of the 25 posts on the first page of New, 22 are self / text posts. * Of the 3 external posts, [1 borders on being spam](https://www.reddit.com/r/dotnet/comments/88oav0/prepare_for_job_aspnet_core/). Without text posts, this sub would be absolutely desolate.
I was mainly concerned with how to dynamically generate a new database and use ORM to make the tables from my own DbContext classes. [I found this web page](https://docs.microsoft.com/en-gb/ef/core/get-started/aspnetcore/new-db) which explains how to do most of this but I thought for a moment that I would need to use an InMemory database initially before moving over to an SQL Server database but it seems that this isn't necessary. I think I've figured it out now.
Agree, you can't just look at server costs like for like. On prem won't give you resources on demand, HOT HOT datacenre failover etc all for free.
You can checkout my project: https://github.com/bartoszgolek/NFlags It is'nt big, but is well covered. It is small library for building command line interfaces.
I used razor. I like that with Core you can mix MVC and razor pages, so my blog uses MVC and most everything else is razor. I considered angular, but decided I wanted to use as little Javascript as possible client side to make the site fast. 
What you need to do is find a net code package, use Microsoftâ€™s, RakNet, or roll your own. Create a master server or database for logins, then have chats act like tiny little dedicated servers. The only thing you would be hosting is user information. Or you could be more anonymous and have a master server to download a list of available chats, each client can host. Chat information would be at the discretion of the user hosting. Sorry if this sounds a little complicated, I canâ€™t find an easier way of explaining without boring you of all the technical details. You can always talk to a specialist at Microsoft, I had an appointment with one in regards to them hosting a database and master server for me.
Yeah, option 3 is the route I've usually gone down. Not familiar with Discord, so wasn't sure if that was being used for sign-in to the OP's app, or if it was just an additional service they were connecting to. Presumably, if it's the former, this prevents the user from changing browsers without losing the Discord session, but agree that it's better security practice to not include an auth token in the session cookie. 
Looks nice, but if you want to be UI centric - why not using WPF instead?
thanks for the suggestion. i will consider.. 
Windows forms is pretty horrific in comparison to wpf. Bonus points if you can use a mvvm model as well.
Legitimate question. Why would you use web api at all for an mvc project? KiSS?
Expose the business layer as a set of APIs you can call from any app. There is no point in exposing the data layer. If you really want to there are built in technologies for that like odata or graphql but really it's best to have a well defined API and not expose the internal data structures like that. You might have UserServices, ProductServices, AccountServices, etc that you expose as restful APIs. The UI layer depends on if you are doing a client-side or server-side app. One approach is to implement all app logic in js, calling into those UserServices, ProductServices, etc as APIs in the client. Another approach, and the one I usually prefer, is to create a separate 'AppServices' WebAPI that represents the UI application logic, which in turn calls UserServices, ProductServices, etc. The UI then only displays the current state of the app from AppServices. 
I actually just split my asp.net core Vue application into a asp.net core API and a separate Vue app using vue-cli 3. The new Vue cli is pretty amazing in terms of stuff you get for free plus future upgradability and then you also don't have to add a bunch of stuff to your asp.net core project. With the Webpack proxy requests for /api calls you don't even have to do any weird build based configuration to point to your localhost api in dev. The only thing you lose is the ability to hit f5 and run them both at the same time which to me is ok to give up.
Bonus points if you stay away from that outdated non-asyncronous mess!
Your WebAPI should (probably) live in the service layer, between the rest of the app and your repository.
Hey do you mean the angular template with webpack? I also prefer the ng cli. They released a new template which utilizes ng cli instead. https://docs.microsoft.com/en-us/aspnet/core/spa/angular?tabs=visual-studio
very appreciated and this is similar to how I've been leaning. Just trying to see if that's the common approach people take, or if they use Web APIs for the repository/data layers as well.
Yes I read that from another comment. I'm excited about it. I also like that you can opt in to Angular Universal rather than having it by default. I'm just not sure what they changed to all the includes. They used to have SPA services and some kind of webpack library specifically. In the docs, they mention that they altered angular cli, which disturbs me. I have front end programmers who don't use visual studio at all. I don't want their experience altered because of my convenience. 
Not to sound condescending towards to OP, but it does sound like: &gt; I want to use Web API for the sake of it but I don't know how or where I should use it.
I'm teaching myself too and have been slowly going through all Microsoft documentation so I guess that's where I'm learning this terminology from but I need to start applying what I've been learning because I keep returning to the basics now and again..
&gt; Stack Overflow Why not just put up a note in the side bar that says "Need Help?" "F*** You!" SO is overrun with fragile egos that try to close any question that requires work or annoys them for some reason. Everybody is needs help with something, sometimes and because programmers are typically socially inept, there really aren't any great places to go. SO is hostile, usenet is even worse unless you find a moderated group that's still active. Why chase people away? If you don't want to answer a question you can always ignore it.
I know why, it's to allow logic/services to work easily together between various projects instead of compiling them all together as a solution. It's to make them more independent. I'm just gauging to see if going to the repository/data layer is too far for Web API typical usage.
I see, apologies. WebAPI controllers should sit on the same level as MVC Controllers and talk to the same layers underneath. 
Pinging mods: /u/ZeroBugBounce /u/Cylons /u/Arowin 
I ll keep that in mind.. thanks for the suggestion
no worries, appeciate the input
If the web api just supports the web app, this is ok. However, if the web API is supposed to enable developers to build other apps (web and mobile also), web API should reside in business layer (implementing business logic also). That way, all sorts of web api callers will only need to worry about invoking the api. API can return suitable business logic error messages and possibly service/repository layer errors translated as user-friendly messages. 
What if I use signalR ? 
I have to say I was quite surprised by the title. I didn't realize people were still building apps in WinForms.
Thanks, that makes sense. Less javascript.
We are starting to head towards .NET Core. I believe I have the first true Core app (we started another application as core but actually target .NET 4.6.2 due to dependencies). I wrote a web API that is hosted on premise using IIS and Windows Server 2012. At this time, we can't move to Azure as it hasn't been evaluated as HIPAA compliant by higher ups.
SignalR? I've read things like Firebase notifications aren't that reliable, and SignalR will surely be faster.
If you go to the Win32 documentation on MSDN and look for the native method (which is CreateNamedPipe, https://msdn.microsoft.com/en-us/library/windows/desktop/aa365150(v=vs.85).aspx), you see on the remarks a note about the buffer size: &gt; The input and output buffer sizes are advisory. The actual buffer size reserved for each end of the named pipe is either the system default, the system minimum or maximum, or the specified size rounded up to the next allocation boundary. The buffer size specified should be small enough that your process will not run out of nonpaged pool, but large enough to accommodate typical requests. Also you see this: &gt; Therefore, if your specified buffer size is too small, the system will grow the buffer as needed, but the downside is that the operation will block. 
We use Firebase for the same purpose, although client-specific targeting is not the top of our priority right now. &gt; 1. The mobile app has to pass my API a registration or device ID at some point so I can send push notifications to it. How do I know which one to send to when a user is logged into my app on multiple devices? if users are always user@email.com how can I say "send to all device ID's for this user?" Do I just have to store and loop through multiple device IDs on my end? &gt; 2. If a user uninstalls the app, how do I know that happened? How would I know to delete their device/registration ID from my system? You need to store each and every ID the user is given, and whenever you want to push them a notification, just send it to all (Firebase gives you an option to send a notification to a segment of IDs). Alternatively you can sign up your user to a topic, where the topic name is their username, which allows easier targeting, though might have limitations. Or another alternative is using [device groups](https://firebase.google.com/docs/cloud-messaging/ios/device-group), which will allow you to manage the keys. I'd recommend using device groups, since it's the most reliable method. Every time a user registers, you create a device group with their unique ID as the key, and whenever a user gets a new token, just add it to the group. As for removing devices, whenever you send a push message, you'll get a response from Firebase about the status of the message, which will look like this: { "success":1, "failure":2, "failed_registration_ids":[ "regId1", "regId2" ] } You just have to take the `failed_registration_ids` and remove them from the device group. 
Ok, so what's the point of inBufferSize then?
There are threads on the front page that are 3 days old. Getting *rid* of posts won't make this sub any more active.
That's why I put "probably" in parenthesis. ðŸ˜Š There's alllll kinds of "but what if" options.
Hmm, so when I assign 1 to inBufferSize Windows allocates one page. So if I try to write 4097 bytes what I will get?
Thank you all for reply me, it's been a very interesting thread. I'd like to know one more thing about you: why are you moving to .NET Core? 
You need a js library that can keep track of media progress. Videos are easy. Gifs might be a little more work. Alternative option is to ask/calculate the media length when its uploaded to the server. Then you know how long to way between each cycle. 
Built a system like this a couple years ago (targeting Xamarin, no less!). Our candidate ideas were these: * Allow a single User to have multiple Device Tokens (a tuple of target OS and OS-specific push token) and send the message to *all* registered devices * Only store the most recently provisioned Device Token for a given User. For reasons that made sense at the time, we went with the second option; in retrospect, I wish we'd done the first and I would recommend that. DM me if you have any specific questions, happy to help.
I tried it with my keys and it worked. Thanks!
I do. So far it hasn't been too annoying. My minor grievance is I am working on a new API endpoint and I have to remember to commit both projects at the same time.
I have also spent a lot of time with WinForms for UI design. You can't beat it when it comes to performance on very low end hardware or Windows IoT on embedded systems. However, what could take 5 hours to accomplish on WinForms and it's custom controls and OnPaint overrides, can be done in 30 minutes in WPF once you learn how it works. WPF uses XAML, which is similar to HTML with stucture concepts similar to Android. If you take the time, and it is vastly different than WinForms, you'll see that you can develop a control that does whatever you want and can literally look like anything you want. Supports 10 finger touch, uses hardware acceleration, and can be designed so that a user can choose themes within your application with ease. But again, if you're on super low end hardware, and I'm talking about single core 1GB systems, WPF is super sluggish. A popular example of a WPF app is Visual Studio itself.
You *have* to for embedded platforms. WPF performs like shit once you're in low power environments.
Currently changing some class libraries to .netstandard to be referenced by my .net core project I am putting on AWS Lambda. Using visual studio 2017 and AWS toolkit. My coworkers like to use command line to publish their work but I find the VS plugin nifty
I've written code for ASP.Net Core 1.1 that uploads a PDF to an S3 bucket that was based on code I got from here: http://www.c-sharpcorner.com/article/fileupload-to-aws-s3-using-asp-net
That helps a lot, thanks!
Perfect, thank you.
Cool, I'll check that out!
That's a good point. I'd be open to either to see some differences.
Exactly. Resharper was a meant for Visual Studio 2013-15. ReSharper existing for VS17 is an example of a product trying to stay relevant.
*cough* Java.
Sorry, just so I understand your other comments correctly. You're not building an SPA and you're not asking for WebAPI to support random AJAX actions (delete, update, enable/disable, etc.). Are you trying to use WebAPI for inter-layer communication? If so, you want to look at microservices architecture. The specifics are impossible to determine without knowing the business requirements since you could go really granular and have each layer exposed or just expose your business logic via services. Take a look at: https://docs.microsoft.com/en-us/dotnet/standard/microservices-architecture/ and specifically this page: https://docs.microsoft.com/en-us/dotnet/standard/microservices-architecture/architect-microservice-container-applications/communication-in-microservice-architecture Hope it helps. Let me know if I'm barking the wrong tree here.
We ended up running .NET Core inside IIS so that we could take advantage of AD integration. Front end was Angular. Database was SSDT over SQL Server. Build and deploy used Jenkins. Continuous deployment of all three (UI, API, DB) to integration and production based on branch. 
Glad it worked for you. Thanks for the gold!
What i did: Found something that i was passionate with: GameDev. Started doing personal projects and at the same time reading well written C# code from Github projects related to what i wanted to do. Wrote bad code. Started another project. Researched and iterated on previous code. Wrote better code. Started again, wrote better code. And again and again. All while releasing everything on github. Keep refining and refining. Code something every single day for years and years. Value well written, well architected code. Treat it as your masterpiece. Every single line of code is a brush of paint on a canvas. Don't fear to rewrite something to make it better. Do this and you'll become really good without even noticing. Remember: Find something to work that you are passionate. That's the secret.
You can say that about literally everything in life. I only know of this sub because of the C# sub. Why would I look for "dotnet" when I write in C#? This sub is basically just an extension of the C# sub anyway, I never see any other language
To do / achieve what? The problem you need to solve here is how you access the card reader on the client from a web browser only. Signalr doesn't enable that, the reply above is very comprehensive in outlining your options. 
It is ideal to share libraries between projects. That is why you can have multiple projects in a single solution. You'd only want an API if something outside of your apps would need to access your code. Otherwise you're over complicating things. 
I don't agree. There's a bunch of questions which stack will delete because they are more conversation based or too broad. I don't think there's enough strictly dotnet news to fill this sub. A lot of the self prompted blogs / articles are junk. 
very appreciated. I'll check out those links. I think the real issue I'm having is knowing when/why to use a web service(Web API) vs just using a library(dll). In some ways I think why not use Web API on every layer, it disconnects the dependencies of compiling apps together, but on the other hand seems like overkill for a data layer method. I guess I think of it a bit as if I had a Web API for the data layer, it could be used by multiple other projects as well. It wouldn't get exposed to the the world, it'd just be used internally by my applications and other layers. It just seems more flexible to me than a bunch of compiled project layers.
What youâ€™re described is precisely what micro services are achieving. Using WebAPI is just a way of implementing that.
Your site will usually be much faster using angular than razor. Razor requires full page re-renderings, angular only refreshes the components that actually need refreshed through routing. It's less initial download, but it's way more over a couple of clicks through your website
Oh well, without separate reason to exist I guess this sub is fscked.
We have SignalR baked in for other functionality, but everything I know about SignalR tells me it only works when the app is running. Its a messaging app, so if a user has the app closed I need a way to push notifications of new messages to them even when the SignalR connection is stale. From my understanding of most push notification systems, push notifications are at least somewhat queued to where even if a user reboots their phone or loses signal, they will eventually get the notification. SignalR, at least in my implementation, doesn't really cache those messages for later delivery, failed attempts, or people just being offline.
The problem I see is that I'd have to collect the device/registration ID's on login, and the way some of my users are, they will jump back and forth between accounts and devices randomly so I'm just afraid of my API spending a lot of time blasting push notifications out to tons of stale ID's just to notify one "current" device.
&gt; 22 out of 25 seems to be pretty much drowning I meant in context of the 3 day time span. With 3 day old posts on the front page, the sub isn't drowning in posts overall. &gt; Maybe it would be less desolate if there were no questions? Maybe it would have more appeal to some (many?) if that were the case. I think it's up to the existing community itself to post more content if that's the goal.
Not exactly. You have to take care of registering IDs to certain users. But the rest is right, you basically take care of telling Firebase that a given ID is for a given user, and Firebase keeps it in a separate database. Whenever you send a push notification to a device group, Firebase will report back about the successful messages, and if any of them failed. If failed, it will send you back the IDs so you can take care of de-registering them.
That sounds a lot easier than I was thinking. Thank you for explaining it. On a side note, when it reports back a failed attempt, is it common to wait until there's numerous failed attempts to de-register, or is one failure enough to safely assume the ID is no good?
what kind of "frontend" if you don't mind talking about it? Web interfaces? rich clients on devices? desktop? 
&gt; What if I use signalR ? That's for server-client communication. If your card devices are on your server, you can connect with them in whatever method you like and send the data with whatever transport. SignalR, Websockets, REST API, web services, RPC - the sky's the limit in that case. However, if the users on your site have the card device installed on their client machines (i.e. it's installed on the computer with the browser and that's across the internet), you're stuck with finding some in-browser means of communicating with the device as described above. Most of the time, the card readers are on the client machines. Otherwise, it's kind of limited in where you can use the site.
YAGNI. You aint gona need it. Write code that you need today, not what you may need tomorrow. https://en.m.wikipedia.org/wiki/You_aren%27t_gonna_need_it
**You aren't gonna need it** "You aren't gonna need it" (acronym: YAGNI) is a principle of extreme programming (XP) that states a programmer should not add functionality until deemed necessary. XP co-founder Ron Jeffries has written: "Always implement things when you actually need them, never when you just foresee that you need them." Other forms of the phrase include "You aren't going to need it" and "You ain't gonna need it". *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/dotnet/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
I haven't thought about it that way, however I've always been a bigger proponent of server side rendering. All of my assets should be cached so it should be closer to moot, no? As an aside, I don't like type script or Javascript as a language so there's also that reason. 
Thanks for sharing! I've been keeping a close eye on Blazor updates. Exciting stuff!
Ugh, I totally understand. When I started at my current job I needed to rewrite a kiosk application they were having problems with. I decided on WPF because it was the way to go with Windows Desktop apps. I had a hard time learning it because it was really weird. I still have weird problems with it on occasion but I find it quite enjoyable now that I understand it. Microsoft seems to have dropped a lot of support for it in favor of web apps. I'm happy to have learned it, but I do feel like they might have dropped the ball on this one. 
Damn, I've actually never done any embedded platform programming but this doesn't surprise me at all. There are a lot of performance issues I end up having to deal with, and those are on actual desktop computers.
Ah I didn't know you could run it like that on Android. That's an interest proposition, though. I think something like Firebase might make it a little easier to manage, but nice to know SignalR can do something similar since I already have SignalR in the project.
 You could use angular universal then, it will parse the entire page for perceived performance, then get the gains of partially updates :) But if you don't like TypeScript not much I can say haha
This is great stuff, I checked it out last week and was able to do a proof-of-concept in a day. I have a shit ton of work in the pipe right now, but this is going on the queue after my next few releases. Excited to work with whatever version is out by then. :)
Android Activities only execute code whilst they are open, so long-term logic should be placed in a Service, as these can run in the background. You can have this Service auto-launch when the device turns on. SignalR is really just about the real-time communication. I think for your use case, it should be paired with an API, or something along that line. You would store a backlog of messages, and when the client connects, SignalR would notify the client to GET them from the api, and the user stays connected whilst their device is awake, and is told to GET each message as it becomes available. I presume that notification services like the Azure and Firebase options store the backlog themselves, so it saves you a step at the cost of some speed, and probably just increased cost in general as you're paying for notifications.
I found that I needed to pass the value of the button to the controller, then I could do logic in that controller to only show the error messages I wanted.
Hi Devs. I hope this article isn't too basic for you folks.. I had a few moments of confusion when I started using Code, figuring out how to re-plumb some of the features that are second nature in Visual Studio. I put this post together basically covering the basics of creating and linking projects, and running a few unit tests. Hope someone finds this helpful! And comments, please let me know. Thanks!
If this continues to be in the roadmap this is going to be really cool. I'm excited for this. 
And I'll say that this is probably the best solution if it's just a simple mag card track reader. You can buy HID card swipes inexpensively, and they just output the card data as keyboard text entry. 
firebase also tells you about bad android push tokens, so it can be done for both.
Is #1 the only option for a SPA?
Have you looked at [Suave](https://github.com/SuaveIO/suave)?. They even have [an example for websockets](https://github.com/SuaveIO/suave/tree/master/examples/WebSocket). Pretty sure it supports Netcore 2. It's usually what I see when I see F# web development, so I think it's a fairly safe bet.
http://signalr.net/ I used it a couple years ago. Very simple and worked great for what I needed.
yeah, but Suave is a server, I'm looking for a client. :-\
I'm trying to consume a websocket api, I have no control over the server. Looks like an interesting project, though!
:) I Know.. But still i wanna thank you for watching and sharing your views...
Nice! Long time vs code user. Like your setup!
AspNet Core is the future of dotNet on the web. Standard also allows for cross platform development so don't have to worry about windows server licensing. Also the dependency injection is light-years ahead of where they were we're with MVC. So less resource requirements and tighter control over object reuse.
For typical C# development on Windows I'd say stick with VS, although I prefer Code's search/replace, git diffs, and the F# extension (or basically any language other than C#, T-SQL, or presumably VB.NET). It's also kind of cool to preview and edit code references in other files without fully opening the file. IMHO it's the best general editing experience on Linux desktops, but it sounds like that's not a factor for you.
I used this for SlaclConnector https://github.com/1iveowl/WebsocketClientLite.PCL
It sounds like a lot of the comments indicate that people would prefer text posts stay. As a few have pointed out, the sub isn't the busiest one out there.... Saying that, I have wanted to get Automod on for a while now and maybe look at weekly posts for help or newbies or things like that...
Great article. Thank you. 
Thanks! Would you be able to indulge me a little further and provide an example or a link that'll help me to do the calculation or something? [Found this](https://www.codeproject.com/Articles/43208/How-to-get-the-length-duration-of-a-media-File-in-.aspx) which I'll work through, but I think either way I'm going to have to do something I was hoping to avoid which is to add a duration column to the table where I'll store the amount of milliseconds to play the media for if its a video, otherwise I'll just set an interval of one minute.
I guess it's because if you're running .Net Core, there's a good chance you're not running it on a Windows box and until recently, MS SQL required a Windows box, which incurred cost and added complexity. I'm guessing that this is why Microsoft have ported MS SQL to Linux.
How about using their SDK and samples. I have used it multiple times, server- and clientside: https://aws.amazon.com/sdk-for-net/ https://docs.aws.amazon.com/AmazonS3/latest/gsg/GetStartedWithS3.html https://github.com/awslabs/aws-sdk-net-samples/tree/master/ConsoleSamples/AmazonS3Sample
Hi, I don't think you're missing anything really - the key benefit is that Code is cross platform. I wrote that article because I was collaborating with a chap who prefers his Macbook. The kind of set up I describe us great for open source style projects where you would like to use .NET, but don't want to restrict the project to Windows only users. I do find that I quite like the stripped down nature of working with Code - there's no hand holding. I tend to feel 'closer to the code', as you're more or less doing everything yourself. But, that's just a preference thing. In a professional Windows dev environment, I'd probably still go for Visual Studio. 
Thanks, appreciate the feedback!
Thanks, appreciate the feedback!
Definitely. There's literally no reason to use MySQL these days unless you've got some janked up software that requires it.
I'm currently using MS SQL on Linux in production. The install was easy, easier in fact than Windows.
Is it a common and correct behavior? sorry for title typo
MVC is not aware, that the password is a sensitive field. It might help to denote the datatype of the password field as DataType.Password (i'm not sure about this). A solution that definitely works is, to disable checking for dangerous content on this action.
Though if you have a logging mechanism then the password will probably end up in plain text in your logs
Possibly, don't remember all the ins and outs of it off the top of my head. Its a good point though, and certainly something you'd want to be aware of. And really, the goal should be to understand why the exception is thrown and fix that. 
MS SQL isn't free.
+1 just for use of the expression 'janked up software'!
Seems like an advert to me. Will there be documentation afterwards for those of us that cannot tune in to twitch?
The correct way is to HTMLEncode the password field on the client side and HtmlDecode on the server side. Never turn off the validation on the page, especially where there is a user input. This is a security function which exists for a BIG reason.
Should make it freemium yo
I'm new to C#, repositories, business models, and the whole lot (coming from front-end development 2 years ago). Here we use stored procedures for it all which guts the bulk of why I'd use EF. To speak to your point though, I'd guess that EF's primary audience are those who don't want to worry too much about the SQL. Call this laziness or specializing, but it's true for more than just SQL. My method is to write the stored procedure, create a model that represents the stored procedure results, create a business model, create a factory that maps the two both ways, and create a repository class that handles interacting with the database. EF looks very shiny to "replace" this work, but like you said, it doesn't take too much time and I'm left with something I'm A) familiar with, and B) can adjust easily.
I have project running from 2013, and Iâ€™m afraid to rewrite it and in process might break something, and since 2016 I been postponing:-)
The great thing about Typescript is that it's just Javascript! You can start off with relaxed compiler options, such as allowing `any`, and then start to get stricter. Maybe just have a policy of start using it whenever you write something new, or touch an existing file, but don't go out of your way to refactor everything.
It's a perfectly valid question. For me, it really boils down to where you want to spend your time. If you feel that writing all of the boilerplate ADO.NET code isn't taking away from the time you need to write the things that makes the app useful, then have at it. The performance comparison is also valid, but I compare it to writing assembly vs. writing C#. Yes, one could write assembly to do the same thing, but I'm able to accomplish more in a given unit of time in C#. I will offer one thing that, in my opinion, is the only "killer app" for EF: the ability to handle ad-hoc queries without having to use dynamic SQL. LINQ is an amazing technology; I just wish it were a bit easier to write a provider.
Code generation allows the code I write to be almost all business logic instead of constantly writing a bunch of boilerplate. Even when I use a bunch of stored procedures I'll use an EF data model along with the Extension typewriter to get type safety on the server and client. There are tons of features and extensions to dapper and entity framework that you probably are not taking advantage of. As with any technology there is an up front cost to learning it. You should be very skeptical of your choice to avoid dappper/EF. There is a reason you won't find larger modern projects still using ado.
I totally agree with ORM like EF, NHibernates slow things down when u have huge database and the sql generated in most cases pretty much impossible to performance tune or Make changes, I have changed to dapper a POCO model and find it useful I have better hold on my query and also dapper gives a dynamic object which I can easily serialise, manipulate, But truth is nothing is faster than plane old ADO Connection 
I have exactly give it one try each year since 2016 and now in 2018 Iâ€™m gone try again :-), but this time I have a new project, so I gone give my best, and also angularjs is gone be killed soon :-( I sounds like Iâ€™m getting ready for a war
Sqlite is great if you just need a simple local database!
Personally, I have always found Visual Studio to be too heavy. It just has *so* much stuff built into it that I either never use, or use so rarely that I would rather have them split into separate tools. VS Code has more or less the things I want in an IDE * An editor with auto-completion, syntax highlighting, error checking, etc. * A visual debugger * A link to a compiler that runs based on a keyboard shortcut * The ability to run and see the results of unit tests I don't really need much else. Sure, I've use the performance profiling tools in Visual Studio here and there, but I'd rather have a faster, leaner VS, and a separate tool for profiling. That probably goes for a few other things as well. But there are also a ton of things that I *never* use and have no intention of using, like * The ability to connect to databases and run SQL queries from my IDE. * Deploy code from my IDE. That is what CI servers are forâ€”developers should not be deploying code from their desktops in my opinion. * Anything related to Azure (nothing against Azure, I just don't use it and use AWS instead). In particular, the fact that there are bundled Azure extensions that I [can't remove or disable](https://i.imgur.com/FR4zdgo.png) really bugs me. Up until recently, there was no real way to write C# (one of my favorite languages) without Visual Studio, so for me, it's nice to see that start to change and the ecosystem open up like it has for so many other languages and frameworks.
We are also running .Net Core 2.0 and Angular 5 + ! But the template is a pain ! I have a question, how do you deploy your application in multiple different environnement, we have one appsettings per environment: appsettings.production.json appsettings.stage.json appsettings.development.json But when deploying the 3 appsettings are deployed with a web.config and we don't know how to tell the application to use only one of the tree
Money
If you start with Typescript in your new project, it'll be a walk in the park. It takes a little getting used to a first but assuming you're used to C#, it should be easy. You must be the only person that's sad about moving away from AngularJS ;)
I might revisit Dapper as it's been some time since I looked at it.
This is it, I don't feel as if I'm spending more time writing this boiler plate code - I've already written it in the past and can just reuse it in my new projects. The only thing that changes is the mapping, which as I say, takes me a few minutes to write, which isn't a big deal. I think that I was a bit unfair on the performance side of things, as I know EF is probably the slowest ORM, and there are plenty of others that are faster (not too far from plain ADO.NET). I get your point on the Linq side of things, but I'm still able to use linq (to a certain extent) with the way I am doing things. Is EF the main framework you use for your projects or do you have any other favourites that you think I should take a look at.
$$$$$ and ability to deploy on linux servers. 
I must admit, Dapper is one that I'm tempted to look at in more detail. I played around with it in the past, but it's been a while. I don't mind investing time in research new tools/technologies as it's something I quite enjoy doing.
What is this?
While I think the correct way to handle it is debateable, disabling validation for the entire page is like turning off the firewall to open a port.
Oh man, I know how you feel. Sometimes I have to zip an application, open Windows Server via remote desktop connection, unzip, delete a few files, replace some and it is a deploy.
In my experience, the machine running your .Net core application, or any other application for that matter, has no bearing on the database platform that your application makes use of. This is especially true with distributed systems. 
This is the correct answer.
Just figuring out the licensing for MS-SQL can be challenging. Using MySQL (OK, or PostgreSQL) means one less thing on the to do list.
Thanks for your input - I do appreciate it. I know EF well enough to give it another go on a larger project. I will also have a more detailed look at Dapper. Hopefully I can track down a pluralsight course.
Indeed. So you wouldn't want a mixture of Linux and Windows except in rare circumstances. 
[SQL Server - Licensing and Pricing](https://www.microsoft.com/en-us/sql-server/sql-server-2017-pricing)
You could add some rules...maybe copy the rules from the C# sub
llblgen has been around for a long time, but it has never been free
Ghost blog engine... I've been running mine for a couple of years and over the long weekend I wanted to move over from 0.11 to 1.0. Turns out I'd need to migrate my db to MySQL from PG. Couldn't even find an official migration doc.
Also, I would warn you against using EF Core. It's a disaster compared to EF with lots of weird effects and missing features. (Like views and stored procs. Seriously, how the heck did they forget to support views and stored procs?)
This is probably because you didn't correctly identify the password field on front end.
MariaDB and MySql have diverged significantly in the last few years, it is no longer a drop in replacement.
Ok, so I do that for the question field exactly as you say so the user can write "Is A &gt; B". Oh look, now I've got a HTML injection vulnerability. The so-called "page validation" does nothing to prevent the problem. There is absolutely no risk in accepting HTML (aside from max message size). The risk is in displaying it unescaped, which MVC/Razor handles for us automatically be default.
What, not going to bring up Tortuga Chain yet again?
I did wonder as I knew MySQL Workbench doesn't work with MariaDB. I'd guess it's still easier to migrate to from MySQL than another platform though.
Why would I? The question isn't "why is EF screwing up again?"
A good ORM can give you as good or even better performance than you'd get from hand-writing ADO.NET code. Why? Because it does the things that you might find too tedious to do like strictly reading the fields in sequential order. Likewise, it can make things that you wouldn't normally think to do like bulk inserting data easy enough to consider more often. Nothing sucks like hand-writing an INSERT statement only to find out you have too much data and need to throw it away in favor of a BCP. Upserts are another area where a good ORM can help. The code for upserts is quite tedious and looks dramatically different from one database to another.
Not sure about what context this comment is from. I have a mixture at home and I know several companies that have it to. Windows for clients, linux and windows for servers, linux for pi:s connected to tvs, etc. The right tool for the job, imo. 
nothing wrong with using ADO. I like entity framework as it generates my migration scripts automatically, and that writing the queries are easier. Also I like the fact I can support several database without too much effort. In most application you don't really care if parsing the query takes 2ms more. That said, I could potentially do without.
&gt; Just out of interest, which ORM do you favour? The one my roommate and I wrote of course. (See my other comment.) But if for some reason I can't use it then I got with Dapper. I always find the boilerplate needed by EF to vastly outweigh its benefits. And EF core is just plain stupid. 
You've summed it up pretty nicely. I'll be sure to have a look at those articles. 
&gt; &gt; Entity framework is not preventing you from doing all that other stuff you want to do, you can still replace any code performing poorly in EF with store procedures, The problem with that is a lot of EF's performance problems are in the materializer itself. So if you use a stored proc, but still use EF to map the results to objects, you won't necessarily do any better. So while stored procs can solve specific problems, you're still paying the EF tax no matter what.
&gt; I like entity framework as it generates my migration scripts automatically, If you are using SQL Server, SSDT will give you easy to use migration scripts without tying your hands like EF does. You can access most, though not all, of the capabilities of the database. Unfortunately there is no equivalent for other databases.
People still code in VB?
It's super easy. 1. Update the libraries 2. Update the references on _Layout to use the correct CDN versions (and make sure you update the [SRI hash](https://www.srihash.org/)) 3. Update the layout The only main change that you need to worry about with the layout is that the navbar is different. I've done it like 5 times now (practice), shouldn't take you more than 15-30 minutes.
Got it, so it's worth doing. Thank you!
Absolutely worth doing, especially at the start.
Concurrent writes and reads. Concurrent reads alone is fine. 
I understand where you are coming from, I too started using .net 1.1 when it was first released and you typically installed it from your mailed copy of MSDN. I remember writing data access repositories in Classic ASP. I hate code first. I have had EF generate some crazy schemas and then you have to use migrations. I much prefer the DB generated context. I use EF as 90% of my workflow and here is why. 1. EF does do a good job of taking a schema and making POCO objects for me. Typically do this once a project and just add properties as I go along manually. 2. Most basic PK lookups and basic CRUD EF can handle just fine for my taste. Sure the SQL is a little verbose with the schema and brackets included, but I should really write my SQL that way too. 3. If I have to do any sort of join condition, nope, EF you are out. I have seen EF do some weird stuff before. 4. If I have a large table, I won't have EF query it. EF Core will query all columns, and I know I have a special index with some included columns I want to hit instead. In this case, I use Dapper because I have to type less code. 5. Special SQL data types. I seem to always need a geography column in my apps, EF support is shaky at best, back to stored procs and dapper for this. 6. If I need to do 2 or more things in the DB, I make a stored proc, and use dapper to call it. 7. One huge benefit of EF is it ties into the VS Code Generation for MVC. Create your EF context, go to MVC, create a controller, point it at your table, instant CRUD operations. Open it up, shove all the code back to a data repository and clean up the HTML but it gets pretty close. After you create your schema, have EF generate the context, you are talking minutes to having a multi-table CRUD web app working. No way can I do that faster and it gives me a ton of code to move off into my own style of programming. So while I am not 100% against EF, I do think that EF should be used when appropriate for simple single row operations which I feel is 50-80% of most web apps. That then gives you time to spend making the unique parts of your app better than just moving bytes from the browser to a field in the database. EF is a tool, it is not the tool, and it won't do all your DB needs. 
Can you even search all files in VS Code? I feel like I just am not finding that feature..
Thanks, you've given me a lot to consider.
If you don't like the abstraction that EF provides dapper will likely be a better fit. You can use dapper almost exactly like ado with just nicer syntax for calling paremtarized queries and mapping the result to objects. You can also use dapper for deep mapping, returning a list of lists using a single SQL query. 
Just read the 1976 guide, it's still valid.
That's a nifty idea! Thanks for your response.
Yeah, at the moment Dapper is looking like it might be a nice option for me. I'll try and find some tutorials that I can use to knock up a sample project.
I second that. Since I used PostgreSQL it works so smoothly that I forget I am using it at all...
You would still need to write the C# code which correctly check the current version in your DB and execute those scripts.
There's a little bit more manual work to do to get it all set up I guess, but once the plumbing is done, it's not so different from Visual Studio. That was the problem that I was addressing really in the article. I had a similar frustration with Code, and kinda figured a way around it. It is true though, that if you're working in a fully windows dev team, on a C# application, then you are probably better off with Studio. I was collaborating with a Mac based friend, which inspited the article. Have you enovuntered anything specific that I didn't address? I could maybe update the article to address, assuming I can come up with a work around...
Dapper isn't an "ORM", it's basically extension methods for ADO that will common-sense map object properties to query parameters or query results to object properties. It does, technically "map relational data to objects", but that's all it does. I'd find it hard to justify NOT using it, and just typing a ton of boilerplate obj.FirstName = r["FirstName"] or cmd.Parameters.Add("EntityId", query.EntityId). You can talk about how you think it's better, but nobody wants to maintain that bullshit.
Wait, are you complaining about not being able to write a shit ton of SQL when that's the one thing EF allows you to completely skip?
A little bit of SQL can eliminate a lot of C# code. 
Yes you can! Ctrl + Shift + F. Or use the magnification icon on the left.
A little bit of SQL code can throw unit tests and debugging out the window. A little bit of SQL code usually becomes a whole lot of SQL code.
&gt; sys.dm_exec_describe_first_result_set Thanks! I've been trying to remember how to do that.
No problem, I actually forgot it a couple of times while planning this out in my head haha.
Chain looks pretty cool. Though the releases seem a bit behind Master, which release do you recommend for Core? Is it ready for production?
But your .Net code almost never runs in the same machine as your DB.
&gt;You can talk about how you think it's better, but nobody wants to maintain that bullshit. I'm not saying it's better. I'm just giving my thoughts on the subject, and inviting people with more experience with ORM frameworks to explain why I'm wrong/what I'm missing. That is why I titled my post with "Change my view". I've only played with EF on a small demo project and failed to see how this was faster to develop, or what feature enhancements it offered that would make it worthwhile to use. I don't have the experience with EF that many others do, and I'm hoping that those people might be able to tell me exactly what additional benefits it brings.
I think he means that the password is salted/hashed serverside before it even hits the database.
https://en.wikipedia.org/wiki/SQL_Server_Express#Capabilities
Oh shit!!! That said, it's still $$$$$ right? 
If you do not know what you are doing, then yes. But I always validate all input fields server-side to prevent SQL/script-injection and so on. So it's really not a problem. For the passwordfield it is salted/hashed so it's not necessary to encode it, but for other fields you can easily do a Server.HtmlEncode(xx). 
You're in a tricky position because Microsoft doesn't provide a proper upgrade path anymore for front end libraries for ASP.Net Core. I would go ahead and upgrade to Bootstrap 4 as there is no real reason to use the older version. Same with jQuery. 
This is tripping for HTML injection not SQL injection though. Whatever is in that box should be salted, hashed and thrown away never to be seen again. 
&gt; Though the releases seem a bit behind Master That's because of the way I test it. Since it will break a lot of people's stuff, including my own clients, I often let things sit in master to be retested several times before I'm confident enough to actually push a NuGet release. Barring a bug report, I probably won't push a new version of Chain until I finish the MySQL implementation. (Or is MS finally fixes the bugs in SQLite for .NET core.)
its also cheaper to run on aws vs postgres.
 &gt; But I always validate all input fields server-side to prevent SQL/script-injection and so on. How do you validate `firstName = "Tom O'Malley"`? Answer, you can't. Either you assume it's invalid because it has a `'` character, which is a bug, or you assume it isn't invalid and have a SQL injection vulnerability.
Sincere thanks for the replies! This all sounds awesome. Final question, which database would you recommend? Typically I use SQL Server but happy to try an alternative (PostgreSQL for example) if that has better Core support/performance with Chain.
Just watch the vod after
That statement was, admittedly, far too antagonistic. This is a debate I've engaged in before, and the hundreds of lines of boilerplate that hand-coding produced were a sore point. I'm in the middle of the road, as far as ORMs go. I don't think they're the solution to everything, and I am highly skeptical of them, mostly because I've been using them as long as they've been around. But, on the other hand, I consider code brevity and clarity to be paramount to performance in all cases except those where performance is an actual bottleneck/issue Which is to say, a half-take on "premature optimization is evil", as I would spend more time to make sure that my code is "optimized" to be clearly understood and commented where necessary. Boilerplate code generally operates as the antithesis to this, as it obfuscates meaningful business logic.
The topic is interesting but there are a lot of misconceptions in this blog post, I fear. So many little things are just off target - it sounds like an article by someone who just ran into this and thought "hey cool" without really getting the details right. I would suggest more thorough reading of the good book Windows Internals to obtain a deeper understanding. Points that strike me as problematic: * Processes were not introduced by Windows NT and were around long before that. * It is not correct to say that threads exist to prevent one app from hogging CPU. Threads are a work management feature. Preemptive multitasking can use them to avoid CPU hogs but that is an entirely independent mechanism. * Modern operating systems do not use the "middle protection rings". You have user mode, kernel mode and hypervisor mode (plus the parallel isolated modes in recent Windows). * And overall there are serious inaccuracies and misconceptions in almost every paragraph. Threading and job management is not really a topic that can be summed up in an overly simplistic article like this.
The type="password" designation does not have any impact on the HTTP request that's generated, the server would not be affected by that.
Your angular code calls a route like /user/get/1 where the route will point towards a method in a controller. The controllers calls your service/model whatever to get data then returns it. Look into basic asp.net MVC API.
Assuming I have a diagram of what I want my entities to look like (which I would advocate with or without EF), I can set upba basic working data layer within the hour. That includes setting up the database and all basic CRUD operations on every entity. I built a generic abstract repository class once to handle every entity (based on nothing but an Id property). I can use that in a new project immediately (writing it from memory takes 30 mins), and if any entity needs more than what the basic repo can provide, I inherit and extend it. I'm not arguing pro/con Dapper per se. I don't have enough experience with Dapper to compare it to EF. But I do thibk that using an ORM, once you're familiar with it, is objectively better for all but the smallest of applications (where there isn't rnough data complexity to warrant it).
In order: - This may be true, the book I read on this said otherwise, if what you're saying is true, the book is wrong. - I'm not sure I totally agree with this point...a multitasking environment that operates on threads exists for the purpose of being able to kill a process without it hosing the system, aka hogging the CPU (And to better utilize multiple cores/CPUs, but let's stick to the idea of single processor, single core for the sake of argument). Multitasking operating systems incur some serious overhead from threads and context switches, meaning you would need to have a better set of reasons than work management to implement all that, so what you're saying I don't disagree with perse, because you're literally right, but in general I disagree with the notion that saying threads help with CPU hogging is not correct, I think it's a little over the top and trying to be too correct to say that. - Was not aware of this, thanks for pointing this out.
That's true. Still, ASP.NET isn't going to know that - you could store the password in the 'username' form field for all it knows.
Do you already have Single Sign-On setup? 
I don't understand what you're trying to do. If you're app is in an iframe you can do cookie auth in the frame's sandbox. Are you trying to pass off or receive auth from the third-party? The container can pass credentials as POST params that you can validate via a backend call or something like that. Don't try to beat the browser's security model. It's their for a reason.
On .NET Framework I'm confident about that it works with SQL Server, PostgreSQL, SQLite, and Access. On .NET Standard (which includes Core) it supports SQL Server and PostgreSQL. MySQL is the next provider I'm working on. In theory my roommate is working on Oracle, but that's been stalled.
Yea when someone comes and tells you you need to spend $15,000 for the database. When there are free options out there it's a tough sell. That said SQL server is worth every penny if your actually using it's capabilities.
Yea when someone comes and tells you you need to spend $15,000 for the database. When there are free options out there it's a tough sell. That said SQL server is worth every penny if your actually using it's capabilities.
 Method();
This is why we have output encoding, and why MVC was changed early on to do it by default and Html.Raw, etc. were introduced. It's still not a bad idea to use RegEx based whitelists for string inputs to limit characters to known good values (i.e., all standard keys on an English keyboard, to expressly disallow higher order UTF encodings, Chinese, Russian characters, etc.)... but disallowing some special characters is a bad idea unless you know that field expressly shouldn't allow them because it wouldn't make sense. I'm also against STORING in an encoded format. Lots of people do that, and then as soon as they need to use it for something besides HTML they have to unencode / reencode, etc. Better to store data in its original, and properly encode on output to the right encoding.
I heard in the community standup yesterday that they've upgraded to Bootstrap 4 in the Blazor templates. Not sure if that's going to be in ASP.NET 2.1 also, but I don't think there's any reason not to upgrade.
We do this with a third party vendor we work with. This is how we do it: The vendor provides an authentication URL for us (not the user) to use. We authenticate against them to get a temporary session token on the backend and then we generate the iframe URL using this session token on the frontend. The token has a very short lifespan to prevent reuse. I did not set up the authentication end point, but I believe it also uses the user's IP address/user agent so it knows where it is expecting the iframe request to come from. After the iframe loads, we set up event handlers and communicate with the iframe with [window.postMessage](https://developer.mozilla.org/en-US/docs/Web/API/Window/postMessage). With that we are able to get any information we need from the iframe for what the user has done. In the event of failure, we also have a callback from the third party vendor that hits our server that also validates and completes the interaction as well. 
What? It is not expensive at all if you compare it to its biggest competitor, Oracle.
&gt;Why do people usually prefer MySQL with .NET Core as compared to MS SQL? They don't unless than amateurs.
You shouldn't have a password in the query string, why don't you post it instead?
Can I use .NET Core with vs2015?
I believe so. I'm using it in VS2017
shame raygun is too expensive to use in production for multiple sites 
&gt; &gt; &gt; I'm also against STORING in an encoded format. Same here. I've run into so many problems with that over the years. Especially when they are inconsistent about whether or not it is encoded. 
Virtually all of their plans now have unlimited numbers of apps. Nice and easy to manage multiple apps, environments and tenants now. 
&gt; This is a hold over from Microsoft's earlier days of trying to solve everything for you in half-assed ways instead of putting it on you to do the right things That pretty much describes everything in ASP.NET prior to Core. 
How do you delete a record with EF? public void Delete(int employeeKey) { using (var context = new CodeFirstModels()) { var employee = context.Employees.Where(e =&gt; e.EmployeeKey == employeeKey).First(); context.Employees.Remove(employee); context.SaveChanges(); } } How do you delete code like you aren't a noob with EF? public void Delete(int employeeKey) { using (var context = new CodeFirstModels()) { context.Database.ExecuteSqlCommand("DELETE FROM HR.Employee WHERE EmployeeKey = @p0", employeeKey); } } Same code in Chain: DataSource.DeleteByKey("HR.Employee", employeeKey).Execute(); Oh, but the client wants soft deletes. DataSource.DeleteByKey("HR.Employee", employeeKey).Execute(); Now the client wants soft deletes, but also stamped with the deleted by/deleted date. DataSource.WithUser(currentUser).DeleteByKey("HR.Employee", employeeKey).Execute(); 
That's very true and I've seen it work just fine. But I was more focused on things like Stored Procedures, SQL Agent, SQL Server Reporting Services, Integration Services, Service Broker. These are all features that MySQL either does not have or is not on par with SQL server, but have been part of SQL server for over a decade. 
One thing that hasnt been mentioned with using ado.net and stored procedures is that your business logic ends up being split across two technologies. Half of it ends up in the database and half in c#. Im sure you will respond with, no we keep all our business logic in C#... but the next guy wont because 'performance' and well quite frankly he is a newbie... So you end up with an app that has a lot of needless performance but is impossible to refactor and increasingly a pain in the arse to maintain.
Agreed. And given the choice I always choose SQL Server. But I have to admit that it's getting harder and harder to make the case for it when the client doesn't see the need for the advanced stuff. Currently my best argument is SSDT. It makes development so much faster than anything else I've ever tied. 
Ahhh. You only write that stuff once, my repository class is like 50 lines of code. Ive got more boilerplate implementing dependency injection. employeeRepository.Delete(employeeKey); Simples.
It's hard to tell without the XML file content in question, but you may want the datatemplate to contain a stack panel with a textblock for the '-' and another texblock for the actual overview sans '-' bullet point. The long and short of it is if you want to control the alignment of the bulletpoints you will need xaml dictating the layout.
Should any new project start with jquery and bootstrap tho? ðŸ¤”
You can use .NET Core with vs2015, but to use the newer versions of ASP.NET Core you will need vs2017, which I highly recommend as there have been massive changes since 1.0
Sorry, not trying to beat a browser at all. We are essentially using the MVC authentication, but in an iFrame, the auth cookie isn't being stored. In our test, if we allow 3rd party cookies, then it works fine. It's entirely possible that we've done something wrong as well. But it's been difficult to find relevant information. 
[removed]
Yes it's normal (in older ASP.NET), and yes you need to take steps to ensure it doesn't happen.
This post has nothing to do with Oracle and Oracle being more expensive than MS SQL doesn't have any impact on the answer to OP's question.
You can start with an empty project.
We are calling stored procs in EF Core. Are you sure your leads/architects know what they are doing?
Sure, in the sense that you can pass inline SQL through EF Core. But that's a far cry from properly supporting it. 
I honestly think it's best to just continue using the page lifecycle with Web Forms. That model inherently has issues when you try to do more dynamic processing on the client. You'll find yourself trying out those native Ajax controls and get into a lifecycle hell trying to make sure the state of the page is in sync. Use the native paradigm with web forms and if you want to move beyond that, start rebuilding using Core.
Well as a person who has written a number of ORMs over the years, I'll give it a go but I'm on a phone so I'll keep it short. I started C# back in the 1.1 days as well, I've worked as a DBA, etc. And I tried EF, Linq to SQL, NHibernate, etc. back in the early days and hated them with a passion. So I went ahead and created SQLHelper, which I've seen pop up in a surprising number of products. It's sad when you can recognize the method signature in an error log and can send in a bug report along with the fix on a closed source app... Anyway, that code started off as a simple wrapper for the various ADO.Net stuff. Over time it evolved into a small micro ORM. The reason for the change was that code you say doesn't take that much time, really does take a lot more time than you think. You can add tables/fields in minutes. I can do it by simply adding a field to my stored procedure/query. Dapper, Massive, etc. are the same way. In fact I can take the dynamic model that gets returned and simply cast it as a static type, like say a view model, and the conversion is done for me automatically in SQLHelper. Batching of inserts, updates, etc. is automatic. I can do callbacks for selects nestled inside of inserts, updates, and deletes. Do it all in one batch and not worry about parsing anything out as it does it for me. All of that boring stuff I never have to worry about. An ORM at its heart is just a tool to map between the object oriented and the relational realms. Some like to throw everything and the kitchen sink at you and force you into their way to work with databases. Others, mostly micro ORMs, let you handle most stuff and just does the mapping. I think if you tried something like Dapper, you would find it works very well with how you like to work. Or just create your own and make it work the way you want. Also as a side note, the compiled execution plan thing is no longer an advantage of stored procedures. According to the SQL Server team ad hoc and stored procedures pretty much all go the same compiling/execution plan route now. In fact I think if you run a stored procedure and the same code ad hoc, it should use the same execution plan. I'm not near a machine or I'd test it.
Hey man, thanks for taking the time to respond. I definitely think we're on the same page. The more I here about Dapper, the more I think I should give it a serious look. So, bugger it, I will. &gt;the compiled execution plan thing is no longer an advantage of stored procedures That's very interesting, I didn't realise that had changed. Thanks
You are absolutely right. I worked on a number of huge applications in the past, and all of them have suffered from this to certain extents. You've also answered my only retort. I've seen too many well written applications deviate far from the original design as it is extended and modified over time. Some developer comes along and thinks "well it would take me a day to do this change properly, or five minutes to change the stored procedure". Guess which option they go with.
Why aren't you using the one shipped in .NET Core? ``` &lt;PackageReference Include="System.Net.WebSockets.Client" Version="4.3.2" /&gt; ```
As I say, I'm open to people changing my view on this. In fact, I kinda posted this because I wanted compelling reasons to switch. I do, however, believe that database design is very important and needs to be done properly. I know do know that this is achievable with EF's fluent API, I just find it easier to design a DB in SQL. I'll give you an example, until recently, I worked for a very large company (one that you most likely would recognise). I don't want to give too many details. But, to give you a bit of context, this company I worked for liked to buy out similar companies in the same field. As a result, the company ended with about 50 applications which all did the same thing (managed a product's life cycle). One of these applications was written in ASP.NET MVC and entity framework, and essentially did the same job as a product I was working on (which just used ADO.NET - it was an old app, that had slowly been transferred to ASP.NET from Classic ASP). To give you a bit more context, the EF application had less than 500 users, and ours had around 1,500. The EF application had horrendous performance, and when one of our DBA's did some detailed analysis, he found that not only did the EF application not make use of indexes, it was also transferring about 20 GB data across our network every day. On the flip side, our app was transferring less than 10% of that, and required far less hardware to run. I'm not giving this example to try and prove that EF is bad - far from it (I think the fault lies with the developers that wrote it). I just think that it makes it easier to ignore some of the important stuff. I'm sure that a good developer, could have written the above solution in a far more efficient and elegant way. Having read some of the other responses, I think that Dapper might be a good fit for me. I will continue to learn about EF, because it is popular, and it would still be a good skill to have under my belt. It would also be fun to see if I can write an EF app that gives me the database design and performance that I want.
lol, no worries mate. I've worked on plenty of legacy applications in the past, so I know how you feel. &gt; I consider code brevity and clarity to be paramount to performance in all cases except those where performance is an actual bottleneck/issue I totally agree. I always favour maintainable code over clever code. And 99% of the time you don't need that additional performance. You are also 100% on the mark with your comments about premature optimization.
Because it's a great fit for most use-cases and is free?
Exactly 
Your controller's GET actions should return an IActionResult. Wrapped the retrieved item in a new ObjectResult(item). Here are the official docs: https://docs.microsoft.com/en-us/aspnet/core/tutorials/first-web-api-mac
Hey, it's you! Glad to see you're doing a WPF one.:)
yup!! took your advice.. 
&gt; Encode the password, send it to the server side ...that's what TLS is for.
lol my boss told me yesterday to park this project and focus on another one since the client for this one hasn't paid in 3 months and doesn't answer his calls.
Really? So far it's working out as I'm aiming to eliminate post backs and the page life cycle *entirely*, on this page, anyway. There are still lots of post backs and ViewStates going on elsewhere in the application. So far, I have had no need to keep any state in ViewState or go through the page life cycle. Of course, I lose state when the user leaves the page or tries to reload it, but I'm trying to deal with that by cathcing the `onbeforeunload` event. Maybe I'll implement some sort of periodic state persistance ("draft" save) at some point. True, it's all proving to be a bit more work as I have to write AJAX calls for each action requiring the backend (and JSON/classes to go with it), but at least I don't need to deal with the page life cycle--which makes me especially glad because a lot of the Web Forms stuff is badly written with complex programmatically added controls that have difficulty retaining state (resulting often in the old "loading them twice": the Page_Load() and any other event that needs to update data). I don't think the application has implemented the Web Forms paradigm well in the first place. Hopefully I won't run into any trouble later, before I get a chance (if ever) to rewrite large portions of it all. 
Mate, please. I understand what you want to say but we are getting farther and farther away from the original topic, and I am 100% sure you just arguing for the sake of the argument now. With a password field, you can't do SQL injection. A proper way to "store" password: 1) Read the password 2) Hash the password. At the second point no matter what kind of script or SQL code you wish to inject, it will be "destroyed" as you are going to get a hash. And not to mention that whoever just insert a user-supplied string to a database should be fired right away. Even if you want to store the data (like, the username, which should be sanitized) you MUST use parameterized SQL query - which is designed just for that, so I can have my username as "=2';DROP TABLE USERS" because then the SQL will just insert it into the table without actually executing this. I know there are still people who don't know about this (which is a shame ) but whoever does such a thing most likely have their server password as "admin". Long story short: for the OP's question the proper solution is HTML escaping and NOT turning off a security function. For other situation what you mentioned (for generic text box) it isn't a proper solution of course and other sanitization techniques required to properly (and securely) store the data.
I meant HTML Encode (escaping) not encrypting on the client side.
Nice vid - thanks for posting. 
Pleasure is all mine
Great video and will watch the previous videos too. Thanks
https://i.imgflip.com/27rvvy.jpg
Have you considered taking look at few brain dumps online. If you will, be careful as not all the questions there have correct answers.
For my current product work: - Visual Studio 2017 5.7 - Windows 10 - ASP.NET Core 2.1 - SignalR 2.1 - LLBLGen 5.4 - PostgreSQL 10 - Elastic Search - RabbitMQ - Stateless - Hangfire - NSwag - TypeScript 2.8 - Vue.Js - Bootstrap 4 - Serilog - Utf8json - Scriban - MediatR - Polly - Orchard Module - Flutter
Not clear exactly what is being bound where. If the formatting is already in the XML file that you're binding (namely that indent on first - line) then it's more difficult. Could look into something like binding to paragraph in a flow document if you really need to use that xml file like that. I believe they would preserve the indent, but could be wrong.
You can use both. You can set up a data access layer, a service layer, and then a web API that is your interface to other apps, like your MVC app. My typical solution structure is using EF Reverse POCO generator to create my entities and context for Entity Framework, You can then use those objects in a Repository project that manages your LINQ queries (db access). Your Service project can call your repositories or third party APIs, such as maps, PayPal, Authorize.net, or any really. This sets up your backend for the app. Now you can set up your MVC project. We create a folder in the MVC project names api, and create WebAPI controllers that references and calls our service project. You could technically keep the WebAPI separate or cut out the service layer, and use WebAPI directly, but I prefer to keep that extra layer in case I need external/3rd party APIs. Your angular app can sit in an app folder, in your MVC project. There are plenty of tutorials on ways to put angular in your MVC app. You would then just call the WebAPI routes in your service area of Angular (angular js). I hope this helps, let me know if you any clarification. 
Oracle isn't a software company anymore. They're professional hostage takers. They're in it for the short-term, bleeding dry their current customers who are too invested in Oracle to move to something else.
Definitely use Dapper. Itâ€™s awesome. You can also forego using models and just use dynamic types if you like. Truthfully, your boilerplate ADO.Net Code is pretty easy to write once so long as you parameterize your stored proc params. As a side note... Personally, I prefer the method youâ€™re using. Stored procs make sense and I honestly feel like people are just afraid to learn the basics of SQL. ORMs annoy me.
Yeah, I think Dapper is the right fit for me as well. To your point about people not learning SQL. Have a look at my reply to another post... https://www.reddit.com/r/dotnet/comments/89op4z/change_my_view_i_dont_really_see_the_need_for_an/dwu1hie/ It would seem like it's very easy to design a bad solution when you don't understand the stack well enough. When I mentioned the 20 GB in my reply, I should have clarified it by saying that the app only worked with data relating to products (descriptions, inventory, sales etc). There were no images, videos or anything like that involved - it was essentially just textual data. How the hell can an app with less than 500 users account for 20 GB network traffic a day?!! I'm not anti-EF, but I think that you need to understand databases reasonably well (and EF in detail) if you are going to use it to design anything other than a trivial solution.
The entire premise of EF bothers me. We tried it out on one of our projects. They were to listing and then applying filters, thus performing table scans. Itâ€™s something impossible to do in a. Stored procedure. EF, in my opinion, is a crutch. Your workflow is the same as mine and we are very successful for using it. Abstractions can be great if they help. I donâ€™t think this kind of abstraction helps. 
Yeah, exactly. You'd have to run SQL server profiler for every linq query you write, just to be certain that it was running as you'd expect it. It's easy to screw up deferred execution, and just because it runs OK on your dev box, it doesn't mean it's gonna run as well when it's got 100 x the users and data. It's quicker to just write a sproc that works exactly as designed. Anyway, it's good to hear from someone with similar views. I almost deleted my post after 10 minutes, because I was getting panned with the downvotes. I'm glad I kept it up, because I did get a few insightful comments, yours included. Cheers
In WPF User Controls and Custom Controls are actually distinct concepts. What you did here is make a user control, which is a composition of existing controls. A Custom Control is actually an extension of an existing control. It's the difference between composition and inheritance. See https://www.wpftutorial.net/CustomVsUserControl.html for more info. 
Yeah. I am not buying it. It is calling a stored proc, and you feed it the type so it is basically mapping the results. If there are major flaws in EF Core mapping I might agree with you. However I do not, in fact I think you don't know what you are talking about.
start a webapi project that you will have only the back-end part of it 
Yeah that does make sense. I've looked into redis and it looks like we may start utilizing that. Thanks for the suggestions. 
A big problem of using an ORM is the generated SQL you're abstracted away from, which if you're doing something complicated can create a serious bottleneck. However Dapper doesn't really do this, you're in control of the SQL.
Yep, I totally agree. Funnily enough, I was just reading the Dapper documentation when your message popped up on my phone. It looks really cool. I thought I'd written enough helpers to make my life easy, but it seems as if Dapper takes it to another level! I don't know why it took me so long to have a look at it!
Yes, there are back you can sometimes use. But there are a lot of caveats. Open issue: https://github.com/aspnet/EntityFrameworkCore/issues/245
They're both fine. But, on principle, I'd avoid anything Oracle anymore. http://money.cnn.com/2018/03/27/news/companies/google-oracle-case/index.html 
I couldn't find any examples of using it correctly. There are tons of questions about stuff not working with it, though. :-\ Do you have an example of correct usage? The official docs are just the class/method docs with no examples (at least the ones I found)
That is not cheating if it helps you realize what you don't know. It is one thing to just memorize brain dumps, it's another to use them to actually learn content and then explore your trouble areas.
I don't have any help for you but I'm curious the value of taking the test vs simply going to work in the field?
What version are you using? I know 2017 has a base UI to search via elastic search. And it works really nicely. I think itâ€™s limited to a single project, but maybe thereâ€™s a way to make it search/index across the whole collection. Or, roll your own elastic search index. Iâ€™d say itâ€™s far better to have a search database be built to let you search through that vs a real-time text parse.
How are you running the app, app service? If so you can jump into a console from the Azure portal and take a look around and see what files are there and where they are.
Migrate to VSTS or upgrade to TFS 2017+, there is a new [code search feature](https://docs.microsoft.com/en-us/vsts/search/code/code-search?view=vsts) :-) In the short term I'd recommend using PowerShell on the workspace (TFVC? Git?), specifically the [Select-String cmdlet](https://docs.microsoft.com/en-us/powershell/module/microsoft.powershell.utility/select-string?view=powershell-6)(The grep of PowerShell )
Wow, I had no idea Oracle is so hated.
Why is PostgreSQL better than MySQL ?
For instance, the last exam on the MCSD track was azure. I never had the luck for working in a company that uses Azure.. so at the time I was just studying my ass off and using an student account I had because of University. I did learn a lot but Azure changed a lot since then and I'm not using it on my current job so.. I basically forgot most of it. Sure you will remember the concepts.. but that you can also get from a quick google search..
Take over? Never. WebAssembly means you can (eventually) use any language for the front end - *including* (but not exclusively) C# But yes, Iâ€™m excited about Blazor. They do need to drop the runtime download size though. I believe itâ€™s on their roadmap ...
Some people have asked why I'm attempting this exam. To answer this, I'm currently working in a Microsoft partner company and we, as employees, are encouraged to earn MS certifications. I have mostly worked with ASP.NET but I don't have real-life work experience with all the topics this exam covers. 
It is not just the language: without a framework and a full ecosystem of libraries it will be quite difficult for Blazor to blaze. :) .NET has a great ecosystem but it is mostly server-side. It will need something like Vue or React, not because every app needs to be a SPA but to be credible to the audience of JS developers out there.
An answer to React is on its way: https://github.com/torhovland/flatware
&gt; Never Why so pessimistic? About eight years ago [some of us were creating rich interactive web pages without any JS](https://www.microsoft.com/silverlight/). It could happen again, especially for internal (intranet) applications and niche solutions.
Never. I'm surprised your javascript is only 35%. In general front end code takes up the majority of my time. Switching to another language or technology to build front ends won't change that. 
Y U No Blazor!? 
I think you're misinterpreting what the person you're replying to was saying. There's nothing pessimistic about the fact that Blazor will never be the _only_ way to write web apps using WebAssembly. Choice is a good thing.
It'll take years before it is mature and battle tested enough to be widely used in production. And it all depends on the adoption rate of Web assembly as well. It would be great to write your entire stack in one language. And something needs to topple javascript but I doubt anything ever will it's too embedded. Hopefully it will though.
If it's an app service you can use the app service editor which you can get to either under development tools in the settings in the Azure portal or by formatting your url &lt;yourSite&gt;.scm.azurewebsites.net/dev
I donâ€™t think it will take over. I think it is a novelty, IMO. Web Assembly is to the browser what IL is for .NET. Do you see F# taking over C#? Neither do I. Thatâ€™s why I donâ€™t foresee C# taking over JavaScript in the browser. There are certain platforms for which languages are entrenched.
I did something like this years ago with TFS 2010. I set up a web server that gets latest from TFS once a day (scheduled task that uses the TFS CLI). I used Lucene.Net to index the files. I wrote a small MVC UI that allows a person to run a search on the Lucene index and display results like google. Clicking on a result opens the file in the browser with syntax highlighting. I used to use Poweshell and select-string, but we have 19GB of source code and it was too slow and I didn't want to download that much source code to my machine. And no one else on the team could use it easily. The lucene search gets results in milliseconds and my whole team can use it. Like others said, if you have VSTS Online, they added the same kind of feature. 
Built it all with MVC. It doesn't matter any more. It's all the same tech. The controllers in your MVC app will return Views/Html for web pages or it will return JSON if you need an API. You can even toggle them back and forth. Its all the same now. 
So I've done this but finding a tutorial on how to properly setup startup.cs ETC seems to be... Extremely difficult...
I was surprised too. After all, backend code pretty much does what you tell it to. Frontend code (i.e. JavaScript) seems to do whatever the f@#$ it wants and requires much massaging to get it to do what I want it to do.
&gt; So we have the best f'ing language in the world that is literally "all dressed up and no where to go". Trying to get into C#, this is how I feel.
Are you saying don't use the MVC architecture?
The guy didn't waste any time
I use it all the time. Here's a template I tend to start with ... https://github.com/matthewblott/dapper-unitofwork
Not sure I get you... It runs on ALL platforms. From phones to have engines to Linux servers. Desktop apps to web services. Even Xbox.
So, I am not a fan of web stuff but from what I gathered on the about page, this is 100&amp;#37; c# for web? Please yes. Just because i don't like web doesn't mean i don't ever do it so, sounds nice. \(just read more\) this webassembly thing looks cool. \(again, web isn't my focus so i cant help it if its well known by everyone else\)
C# is objectively a better language that JS. F# is different paradigm (OOP vs Functional programming). but I agree: &gt;there are certain platforms for which languages are entrenched. is Hard to change minds. 
Excellent point! They did move pretty quickly on Blazor. I think they see that this is their chance to be first into the WASM development experience and are trying to make the most of it.
C# to webassembly could take off, but i don't think the current blazor webpage model looks great for large apps. It feels like they've regressed back to a webforms like pattern when there's much better ways to structure applications
They are going to do a release of a preview every couple weeks and then assess in May whether or not it will eventually become a committed product. That seems fast enough to me.
It _runs_ on all platforms, but it's not the best choice on any of them besides Windows at this point. It's not the platform that I would pick to just "get things done" at pretty much anything yet. The language is beautiful, and the architecture is sound, but it tries to do a little bit of everything and fails to completely excel in anything. Everything it does it feels like there's a better choice out there to do that task with better community support around it. As a language, I may enjoy C# better than alternatives, but when it comes to getting things done, I want community support and libraries. Lots of libraries. I want options. I want to stand on the shoulders of giants because I'm tired of cobbling together ladders.
Cool! That's good info to know, thx!
that's where .net standard libraries come into play
As full stack dev, doing both native and Web frontends, I am still betting on native winning on long term. What I look forward is to have Silverlight back, not Blazor.
&gt;C# is fast becoming a language that has no official platform....So we have the best f'ing language in the world that is literally "all dressed up and no where to go". what!? C# is HUUUGE in enterprises. there's also Unity, Xamarin, and now cross platform support for linux and mac. there is no shortage of use of C# at all, at its growing. just look at the stackoverflow polls every year. C# used by be one of the top languages...only below the new hip languages that blew up over the past 5 years or so with the start up 'craze'.
&gt; What platform does C# rule? Windows, XBox, HoloLens.
It's part of why I like my current position so much -- our hardest problems are on the back-end. Most of the front-end stuff is either boilerplate or TypeScript + Vue, which tends to be a pretty smooth experience. Not that it couldn't be smoother...
"Folks in general," sure -- Mozilla wants you to write Rust for your WASM. But if your backend is .NET, and Blazor gets to the point where you don't need to call out to any JS libs, would you really pick Rust or Haskell or something over C# or F#?
I should have been clearer in the title of my post. My intention had been "Take over for .NET devs," not "take over for all front-end/full-stack development."
I don't think this sub is popular enough to deserve splitting like that. And yes, I do find people asking questions about .NET interesting.
Based on the enormous interest in the 0.1 release, which is barely functional, I'd say people are going to be chomping at the bit to use this thing as soon as it approaches some semblance of stability. What remains to be seen is whether or not project managers can be convinced.
The biggest hurdle is that WASM doesn't have the same access to the DOM that the js engine does. There's a lot of work that needs to be done to the WASM spec, then integrated into the browsers before it's on par. Even if the spec was finalised tomorrow, it's still going to be years before it's viable to target for mainstream use. On top of that, for all its flaws the js ecosystem is incredibly rich with all sorts of libraries and frameworks tailored towards UI design. Blazor will let you write C# code but that's where it ends and there'll be a long time before the ecosystem is on par with what you've got today. 
Ok I agree, my "fast becoming" statement was an over exaggeration but my point is that C# is not the dominant goto solution for the majority of new mobile or SPA projects. I have no doubt that C# related jobs will be around for the next 50+ years but in its current state that presence will be in a legacy perspective and not in the new projects perspective. Blazor would allow C#/.Net to stay relevant in new client-side projects going forward.
What is the size of the runtime if gzip is used when streaming it
I think it will change fast. The reason is that the whole industry is changing fast all the time now and nobody is working on slowing down. Companies adopt technology that is abandonware after a year. It's crazy. It's expensive. 
I made an assertion, unlike you. To my English reading skills that looks like quite some doubts.
Just to give my own experience that verifies this where I proven quite wrong. We had a system that depended on a list of inventory managed by 3 or 4 people in a stock room. had an azure function that would read from that data store every hour or so, and update multiple other databases with that info. I was the one that said SQLite is probably not what we want, it is not built for production loads, blah blah blah. They out voted me and I said I would use it with the team, but I was highly wary. I build the inventory manager using SQLite and it was actually quite easy. Did a light load test at 1.5X expected max use and it held up fine. I thought it may be luck, and expected to eventually get a call at 3AM to fix it once it went down. 2 years now... it may be the most reliable piece of the whole system so far; not one outage or slowdown even after a few upgrades and tweaks to the app. I was completely wrong in my assumptions about it; it has it's uses for when the users are low and load is controlled/expected.
&gt; It would be awesome if WASM is eventually the new IL. It couldn't, WASM is more like an asm neutral IL rather than a language neutral IL. i.e. It's a lossy conversion, you can't represent a type system in it or have reflection, so it behaves more like the Jit output than the C# compiler output
Did you read the [exam ref](https://www.amazon.co.uk/Exam-Ref-70-486-Developing-Applications/dp/0735677220)? It's not great compared to the SQL exam refs I've read in the past, but it gave me a heads up on some areas I didn't know anything about, and I passed.
Sign up for a month or two on Pluralsight.com They have courses that go over all these exams. Search their catalog first to make sure they have courses for this specific cert. Edit: Hit send too early by accident
Theyâ€™d better. They missed the boat entirely with JavaScript, and now Google and Facebook are running the show, along with anyone else who comes up with a good idea because the barriers to entry are so low.
Which says that the choice of technology wonâ€™t alleviate the biggest challenges of UI development.
Net standard libraries are way to big for this use case.
Why does C# need a client side development platform? Windows need one, but C# is a fantastic backend language already and that's totally fine. The reason Microsoft is hesitant about this is that Blazor as an actual functional product that meets a need beyond "I hate Javascript" is not an assured thing. Getting WASM and Blazor to a point where it makes sense as a general purpose front end language is a big task.
&gt; They do need to drop the runtime download size though. What worries me is that Dan Roth said in the last ASP.NET standup, that they believe they can still drop it "a bit". It needs to be dropped by much more than "a bit". Also, reference was made that it would be cached. I cannot find the relevant article now, but a while back there was an article which described the lifetime of something in the browser cache. Reality is that with the amount of new things being cached, and older items being cleared out, a typical piece of cached content does not live in the cache very long. So if it is cached today, it is likely that by tomorrow it would have been recycled already. But, yes, if they can sort out the size, I think Blazor is going to be very exciting.
That's more of an answer to redux than react.
I'd argue that it excels at translating business logic to code better than any other language. Sure, it's a bit heavyweight for quick, one-off applications, but that could be said of most (all?) compiled languages.
For me, already technically 0. I've done TypeScript for a while now. Will I switch to Blazor? Probably not. I don't really need it. For everyone else's complaining about JS/TS, I don't really have too many issues that Blazor would solve. Edit: And for those hoping to go back to the days of Silverlight, Blazor is not it (Thank Cthulhu).
Nice! Thanks for this.
As you say, you just started... Wait until you get into enterprise level applications cobbled from a million different packages. Maintaining a consistent procedure of reviewing and updating dependencies is brutal! Depending on the skill of the developers, even maintenance in medium sized business apps is a pain.
&gt; How does writing a spa web app sound in razor and c#? what's inherently better for spa in js? like what feature is missing in C# that makes SPA better in JS? callbacks? promises? function parameters? week-typing? ajax? [no classes](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Classes)? Closures? because I don't see it. in C# you can define classes for entities, business logic, separate concerns, encapsulate and all that boring OOP stuff that make a project easy to maintain in the future (in theory). plus many language features like Linq, task, delegates, dynamic, var etc. is it more tedious to start? maybe. but this: filters: { capitalize: function (str) { return str.charAt(0).toUpperCase() + str.slice(1) } }, methods: { sortBy: function (key) { this.sortKey = key this.sortOrders[key] = this.sortOrders[key] * -1 } } can be implemented in C#, will you need Interfaces et al? ok yes and that's boring an contrive, buts IMO it give the project more clarity and stability. and with delegates, action, etc you can implemented almost the same way. PD: btw yes I like JS, form the days of vanilla, jQuery and now vue. but for me C# has the advantage as a language. 
For front-end, you could use React or Angular or Vue.js. In terms of storage, if you really want to put yourself out of your comfort zone (and learn something), try using a cloud-based managed solution, such as AWS DynamoDB with S3, or Azure CosmosDB with Blob Storage. 
good points. Happy birthday!!
[removed]
The initial payload may be fairly large but once itâ€™s down and cached .... it just runs using the DLLâ€™s youâ€™ve created and compiled. So really the Mono WASN package could technically be a browser SDK plugin. I am sure other languages would follow suite and face the same issues. Itâ€™s not like you spin up Ubuntu and can run a net core app out if the box either. You need to install the SDK which is an initial bug hit but then the compiled apps are tiny. Or without SFK you compile self hosted apps that are large. Either way I personally find this project mind blowing and I played with it for a bit. It really blew my mind. After payload download .. itâ€™s like a real app in the browser and really fast. 
The initial payload may be fairly large but once itâ€™s down and cached .... it just runs using the DLLâ€™s youâ€™ve created and compiled. So really the Mono WASN package could technically be a browser SDK plugin. I am sure other languages would follow suite and face the same issues. Itâ€™s not like you spin up Ubuntu and can run a net core app out if the box either. You need to install the SDK which is an initial bug hit but then the compiled apps are tiny. Or without SFK you compile self hosted apps that are large. Either way I personally find this project mind blowing and I played with it for a bit. It really blew my mind. After payload download .. itâ€™s like a real app in the browser and really fast. 
Blazor
ELI5 Blazor
Net is a powerful framework. ... Because asp.net is not language as Java and Php, it's a framework, which makes your life as a developer a whole lot easier. Plus you can use number of language supported by .net platform for web development in asp.net like C#, VB.Net, Python etc.
blob:https://www.youtube.com/1c502176-b9b0-4c06-8727-01e5be564a63 Check out this URL. It might help
We use ABCpdf, it's fairly reliable, but can be quirky
Why would you bother with another attribute? All you've done is move `[FromBody]` on the paramter to `[DefaultFromBody]` onto the method.
A JS framework, in particular Vue.js with Vuex (a flux/redux state management pattern library.)
In the past I used phantomjs to convert HTML to pdf. It is basically a headless WebKit browser so the results are pretty accurate. It has its quirks however and getting basical things like headers and footers printed is not trivial
I use the CloudConvert REST API.
Not Aspose ðŸ˜’
[removed]
I am sorry for that one. http://csharp.net-informations.com/file/create-pdf.htm . This might can help you.
I've used [wkhtmltopdf](https://wkhtmltopdf.org/) to convert HTML pages to PDF. Quite handy if you're creating invoices or similar. There's even a .net core wrapper [dinktopdf](https://github.com/rdvojmoc/DinkToPdf) which works really well too.
I used Fop in my last project. 
Fair response. Here is some clarification. React offers a few benefits -- the big ones for me are: * A modular component-based dev experience * Fast model -&gt; DOM computation * A reactive one-way flow of data Blazor already takes care of the first one handily. Blazor *should* take care of the second one, too -- I'm not aware of any performance benchmarks, though. Flatware provides the third. What neither Blazor nor Flatware brings is an ecosystem like React's. Even if Blazor *never* gets an ecosystem like that, I'd still take it over React and write my own drag/drop, modals, and CSS transitions.
Can you elaborate? We're using aspose right now for a file converter POC. 
Certainly not. We use it, because the customer is (was) in love with the idea of being able to create the layout in word and then have the backend fill in various fields. In reality, they don't really want to actually do the part where they maintain the documents. But aspose can certainly be painful. For a long period of time we would regularily see "A generic error has occured in GDI+" errors, but only in production. Aspose support certainly took their sweet time before looking at it, and even more time before doing anything.
Thanks for the replies, I will play around with it. 
PDFSharp also doesn't support file attachments, so I wound up using iTextSharp (the older LGPL one is still free to use)
I believe the 70-486 exam was recently refreshed with new content, so the current study materials (books, videos, etc.) may be out of date. I've been wanting to take this exam myself but have been waiting for new books and other materials to study from.
We use Syncfusion to convert word and excel documents to pdf. It crashes and has memory leaks but is better than everything else we have tried. Most of our pdf documents are created via a mail merge of a word document and a `Dictionary&lt;string, string&gt;`. We isolate Syncfusion in a separate process from the rest of our code in order to spare our asp.net application from the instability it causes when running in the same app domain.
Great write-up on how important async/await can be. I've never visited that site but it seems to have some really good information.
I used iTextSharp for the project at work.
Delegating that task to someone else. /s
Thanks again everyone. I got it working based on your advise. I basically rebuilt the XML file structure with nodes and it works perfect now. &lt;Feat&gt; &lt;Name&gt;Name1&lt;/Name&gt; &lt;Overview&gt;Overview1&lt;/Overview&gt; &lt;Feature1&gt;-1st Dash&lt;/Feature1&gt; &lt;Feature2&gt;-2nd Dash&lt;/Feature2&gt; &lt;Feature3&gt;-3rd Dash&lt;/Feature3&gt; &lt;/Feat&gt;
[removed]
As much as I'm not a fan of javascript, if you're doing this for a web app I'd just use jspdf.
Nash man just feeling what everyone else thinks. I am doing research on it myself and I am going to try EO.pdf
Ok, but why? .NET Core has code analysis via the Microsoft.CodeAnalysis NuGet package. And StyleCop is just plain stupid if you have the other real static analysis tools running and "format on save" turned on.
I feel like this would've been more useful a few months ago when you had to do things like add IOperation feature and grab prerelease versions to get things working. Now you just have to add them using nuget. I'm pretty sure the .ruleset file gets auto-generated at some point, probably when you first customize a rule. But hey, if somebody wants to use a tool to do it, so be it. You do need to add a license to the project though. And your tool will muck things up if a project already has a .ruleset that isn't named "ca".
&gt; I'm a big fan of TPL.Dataflow Me too. Best kept secret about .net. Shhhhhh... 
If you can create Postscript instead of HTML, Ghostscript is a very mature, solid product that can create PDFs.
You can use IsAuthorized flag to show partials or any other method of only showing things If they are authorized without specifically requiring it on a controller level. 
Be aware that the LGPL version had some issues with its licensing. 
Create a word document template. Fill out the areas that are dynamic and then save as PDF. I do this for work with no problem. Takes a little bit for word document to write the PDF around 10 seconds. But other than that it's easy. 
Nicely done. I'm glad I took the time to run through your code. Dataflow is a lot like Task - just when you think you got it down you learn something new. Is this what you are referring to with regard to buffer limits?: if(!buffer.Post(message) &amp;&amp; !buffer.Completion.IsCompleted) buffer.SendAsync(message).Wait();
In a similar vein, LaTeX will also get the job done if the document is wholly generated by your app.
It looks like you've gotten most of the details done pretty well, but it's not user friendly. I need to create the writer, create a transform block, attach the writer, do a few other things... It's a mess for a public API. You love TPL.Dataflow? Cool, but I shouldn't need to know it to use your library. At default, I should only have to do this: using(AsyncWriter writer = new AsyncWriter(filePath)) { writer.WriteAsync("Hello world!"); } Like a regular stream writer, only async! All the rest of those details should be hidden. Sure, I should be able to customize many of them if I wanted, but I should have a very simple and elegant way to handle the common scenario. Does that make sense?
A few more resources that I own; https://www.amazon.ca/ASP-NET-Core-Razor-Pages-Beginners-ebook/dp/B0772SL5VJ https://www.amazon.com/ASP-NET-Core-High-Performance-applications/dp/1788399765 www.pluralsight.com https://productivedev.com/
so if (!User.Identity.IsAuthenticated) how do i manually try and windows auth them?
Yes, I understand the design. Users want that ability without having to setup a bunch of details that should be handled for them. &gt; You could easily write a static wrapper class or something like that which will give you the API you desire. Of course. And that's exactly what the author should be doing to make a library that is easy to use. Making an accessible API is a big part of making a library to share with others. Usability is a big component behind designing libraries. I'm not going to use a library that requires me to do a bunch of default setup and create a wrapper just to get my foot in the door. I'll go to the other library that makes things easy.
Tbh, iirc with Windows authentication turned on/available i think the identity would be populated by IIS for you where available. Edit: This is assuming that the browser sends the credentials despite the site allowing anonymous. In IE you can set a url to be a "intranet" site, this will cause the browser to send windows credentials even if the page is anonymous (iirc).
As I'm not a DBA by any stretch and only use MSSQL for standard database stuff, take my observations with a grain of salt. Though I may be dead wrong, it's still my perception of things. That being said, I really feel like MSSQL devs have been resting on their laurels for a VERY long time. Most of what I see come out are optimizations and such but there are so many other things people have been begging for for years. It's not just the core SQL stuff but the associated techs as well it seems (ssrs, ssis, etc). Biggest example off the top of my head it that it seems no one at MS has informed the SQL devs that MS has been moving away from web forms for a while and introduced this neat thing called MVC. Shortly thereafter, they came out with this really neat thing called .net Core. I say that because the only report viewer they've been updating has been for web forms. It was only with the most recent version that they updated their web api to REST instead of SOAP....the implementation of which is barely documented, mind you. Granted, the specific example is more about SSRS at the moment but it seems to be representative of that section as a whole. I've give them credit for making MSSQL work on Linux, mind you, and maybe that took the majority of their team's time. Hell, I don't think anyone would have ever predicted that many years ago. I don't know. Like I said, venting a bit. It just feels like the whole SQL suite of stuff is being left behind.
&gt; anything beyond CRUD would become quite difficult and inefficient quickly in LINQ. I actually find LINQ far easier to write and re use than SQL. As for inefficient - I totally agree. That is where the problem is. 
Honestly, I prefer to bypass SQL altogether and just build everything on NoSQL stores. I find that the end result is often less code, cleaner, faster, easier to debug, and you have the benefit of practically infinite scalability. You just need to change the way in which you reason about a problem. Granted, if your project is heavily relational, SQL is still a far better option, but I think people reach for SQL a bit too quickly these days.
There's a bug with the page count that segfaults from time to time. And last time I checked that hasn't been fixed.
I've never moved from plain old stored procedure calls, and for just these reasons. I can see the benefits of EF for simple CRUD where performance isn't an issue, but this is also really damn easy to do in SQL. It's not worth sacrificing that level of control on the tricky stuff just for a bit less of the easy grunt work. 
unidirectional data flow is not a benefit you get from react out of the box. That's just the 'suggested' data flow pattern that most React applications want you to use. That's the reason flux, redux, mobx, etc were created, to handle this use case 'better'. 
Back to SQL? Thatâ€™s surprising since EF6 has been super efficient. Some of our non trivial LINQ (4 lines) queries gets converted into page long SQL queries which still execute very quickly (fortunately). Essentially, SQL is really verbose and logic can be more concisely expressed in LINQ.
As a side note, it's called LINQ to Entities for Entity Framework because [LINQ to SQL](https://docs.microsoft.com/en-us/dotnet/framework/data/adonet/sql/linq/) was an older MS technology that was needlessly complex. Having said that, there are other ORMs that use pretty much SQL with slight changes in order to know which fields to map to which properties. Dapper is an example of one of these.
Why do you think you have to sacrifice control or performance? 
Oh.......... if you isolate your business logic and write it in a library (as you probably should) a change to the BL layer might be as easy as a nuget update. 
Even if your project isn't heavily relational, there are many, many areas for ACID compliant applications that NoSQL just does not tackle well without a ton of customization and workaround, if at all. This is a pretty big complex area of the whole issue, and even many of the NoSQL database teams are working on addressing these issues directly, but in some cases, what makes it NoSQL, precludes it from being truly ACID. To conflate the problem, some NoSQL teams(MongoDB, I'm looking at you) have made absolutely outlandish claims about the limits of relational databases and the peformance of NoSQL in the early days, which unfortunately younger developers gobbled up without really understanding the topic at all. I think far too many people reach for NoSQL these days. It's great for large social sites( and many other apps where speed vs accuracy is the priority), but people use it for their home spun website blog site that serves 12 people. I certainly don't see any reason NOT to use NoSQL for many apps, but they don't do what relational databases do in a lot of ways beyond how relational your data structure is. 
For just the reasons given: EF generates SQL that may not do precisely what you intend, and isn't fine-tuned for optimal performance. (IIRC -- and I can't recall where I read this now -- it also adds a significant performance hit just in and of itself, even when the actual SQL it generates is otherwise fine.)
Yes I used Linq-to-Sql for a while. Speaking of needlessly complex..... I don't think that ship has sailed quite yet. Would love to put EF on it and see it disappear. ORM's like Dapper are basically mappers. They only solve a small part of the problem - you still wind up writing your business logic in SQL. 
For the blog example, I don't see why you would use SQL for that. Use Azure Table. Simple API. Cheap (pay for what you use, which would be almost nothing for a blog that size). Durable. Scalable. And all from just clicking a button on the Azure portal. SQL definitely makes a lot of guarantees, but they're often guarantees people don't need. It's complexity and management and maintenance people don't need. You shouldn't reach for *any* storage solution without analyzing your problem first, but people often just use SQL without any thought.
Then donâ€™t write your business logic in SQL. Nobody is forcing you to. If your business logic is in your SQL, then it will also be in your EF queries, and thatâ€™s still bad. 
The blog example is just random, could be anything. The point is, performance doesn't matter and never will so the choice doesn't really matter. So the choice is really "I have 15 years using SQL databases or I could learn this NOSQL system for this" . Now for someone else that is flipped where they've been using NoSQL and why use relational for something where the back end really isn't going to be tested. That was my point, not that you *should* use relational for a small project. So it makes sense to reach for SQL by default for many people. So I guess the flip side of "many people reach for SQL too quickly" is that many people reach for NoSQL too quickly, which sort of makes it a moot point in my opinion. 
But what I am suggesting in this post is that Microsoft do away with both MSSQL server and Entity Framework and replace them both with some yet unknown technology that accomplishes the best of what they both do. So, in theory, you might write something like this in your code: Customer c = Database.Customers.Where(x =&gt; x.ID == 1); And that statement will be parsed NATIVELY by some sever that will give you a result. Again: no translation to SQL. Or perhaps you may write this: Customer c = Database.Procedures.GetCustomer(1); And on the server you have the equivalent of a stored proc nated GetCustomer. That stored proc will be written in LINQ (remember - SQL will no longer exist) and will contain the Customers.Where(...) statement. As mentioned previously I have not thought through the details of how all this might work. I really have no idea. I do know that the limitations you mention are significant and MS should stop beating the EF horse. 
&gt; Yes, that is exactly right. That is the problem I am talking about. SQL needs to go away. When I send a LINQ query to the server the server should know how to parse natively - with no limitations imposed by SQL. I think the problem is that LINQ is a query language for querying objects, while SQL is a query language for querying tables. Back in the 90's (I think) "Object Databases" were a fad; and it seems like what you're asking for would have been a much better fit for that type of db.
I mean, if you don't like translating that logic. I recommend using a completely different language and a different database system. You're asking Microsoft to essentially introduce a new feature into the standardization of SQL which would create more bloatware. It supports things like [JSON](https://docs.microsoft.com/en-us/sql/relational-databases/json/json-data-sql-server); which is likely to get you most of the way with what you're asking. 
I use both about equally in practice. In my experience, simple NoSQL stores like Azure Storage are an order of magnitude less complex than SQL while often having everything you actually need. I don't like unnecessary complexity. I actually have an Azure Storage based blog, and other than the boilerplate ASP.NET core service, the API is one 300 line C# file and a NuGet reference to Azure Storage. That's it. You don't need 15 years of experience in anything to create and manage a single 300 line file.
iTextSharp to generate documents as well as batch fill out PDF forms. 
Mainly just table and blob. Azure is just one example. Dynamo from AWS, BigTable from Google, or something like Cassandra are all relatively the same. Edit: You can also go up a level to Azure Cosmos and Google DataStore. Same basic concepts but greater support for things like secondary indexes, transactions, global distribution, etc.
It is really just the opposite. I'm asking Microsoft to trash SQL and start again with a clean slate.
Sure, if Microsoft replaces SQL with something that's equally powerful and performant, and which is easier to use, obviously that's awesome and everyone should use it. All I said is that so far we're not there. The cost is too great, and I'm sticking with boring old sprocs as a result. It should be noted though, the sort of applications I'm working on are often very performance intensive, have huge security requirements, etc. and so require that level of fine control. If someone is mainly doing less DB-intensive stuff, I can see why they'd want to use EF now. 
I've always been so surprised at how just about every other area of software engineering has had an overhaul, but somehow the front end community and JavaScript has dodged the bullet despite it being unanimous at how terrible and horrendous of a programming language it is.
To my understanding-and anyone is free to tell me I'm inaccurate in any area here-it would solve having to understand.. * JavaScript as a whole. Meaning no more figuring out crazy tools required to have it function with multiple browsers. * Allow a possible and flexible cross-platform front end to compete with XAML and Xamarin. * Actual UnitTesting could become a reasonable thing to do * Be able to use server-side and client-side models as the same thing all the while building a Single Page App * Only having to use *one* IDE edit: formatting 
Yes, its great!
I wouldnâ€™t exactly call outer join syntax concise.
Prepared statements and SQL optimization really isn't done in entity framework. You can do prepared statements but it will always normalize performance over SQL server types that might do better with certain kinds of optimization.
Given the number of other competitors who have already established themselves in that area, I don't see any reason for them to do that. Again, it's using the right tool for the right job. Expecting to change the tool to work for a niche area makes no sense. Secondly. you'd be telling Microsoft to modify their entire database infrastructure to work around *one* specific feature which would lock them into that technology? Why would they want to do that? SQL is-in some ways-pretty flexible as it stands today. 
Databases need to be language independent. Any DB that is natively LINQ will be limited to the .NET world. There is nothing inherently wrong with this, but it would limit the adoption which is a problem at a place like Microsoft which aims for broad tools that can be used in many environments. Given the general problem of object-relational impedance mismatch, the space you'll want to watch is Microsoft's graph databases. Those have the closest theoretical match to the object-oriented model, and LIKQ is clearly LINQ inspired.
I agree. I only use EF for side projects and small CRUD apps. Because the database is always the bottleneck. Way easier to fix when you control the SQL.
I'd suggest taking a look at Syncfusions PDF Library. I only briefly tinkered with it, but I used their Excel library which is fairly capable (and supports conversion to PDF) https://www.syncfusion.com/products/file-formats/pdf If you are using WinForms/WPF/asp.net mvc you can convert easily from html, rtf, doc etc to pdf. You even could create a Word document (including an office like editor using their RTF control) or there would even be the reporting platform which can export to PDF... They have a community license offering which is free. I'm currently developing a lot with it in my spare time. (even if it would be for a company they've fairly priced offerings, 800+ controls)
&gt; When I send a LINQ query to the server the server should know how to parse natively - with no limitations imposed by SQL. Databases can be accessed from many different languages and platforms. What makes LiNQ so special it deserves native support? What about JOOQ? What about any number of other tools out there? Do they also deserve native support in the database? Who is going to write native LiNQ support for Oracle Database, MySQL, SQLite? &gt; Why are we still burdened with the inadequacies and limitations of SQL? What inadequacies and limitations in SQL are you talking about? Or are you perhaps talking about the impedance mismatch when mapping between collections of objects and tables and rows? If you're going to use a relational database then it operates on relational principles. That's not a shortcoming of SQL. That's facing reality. Perhaps you really want some other kind of database? A lot of people have tried to solve that problem already. Often poorly.
&gt; I think the problem is that LINQ is a query language for querying objects, while SQL is a query language for querying tables. Yes. Although SQL is more than that. SQL consists of: * DDL - Data Definition Language. The CREATE, ALTER, DROP keywords. * DML - Data Manipulation Language. The INSERT, UPDATE, DELETE keywords. * DQL - Data Query Language. Yup, it's the good old SELECT. * Some additional stuff regarding privileges and transactions So when someone is bashing SQL and want to replace it with LiNQ it's really just the DQL part of the language. 
So, really what you're saying is you hate the SQL language standard and not necessarily SQL Server as a product.
I didâ€˜ think LINQ to SQL was needlessly complex at all. The issue I had with it was it ONLY supported SQL Server, which was a deal breaker for me. But it was easy enough to use. (Not sure if the SQL Server only clause still applies).
Your right what was I thinking, making a product without at least 10 buzzwords in alpha status /s
* I know JavaScript. I don't really use any crazy tools. * I already use Vue.js. I don't really need a new templating/UI system at the moment. And the approach everyone wants the project to go is XAML, which I can't stand. So not a selling point for me. * I do JS based unit testing now at work. * Might be some benefit but not enough on its own. * I generally just use one IDE now. Either VS Or VS Code depending on environment and project.
No I dont hate MSSQL server nor do I hate SQL (I don't love it either LOL). I don't think SQL is nearly as expressive and reusable as LINQ (both as a language and architecture i.e. stored procs). The problem I am trying to address in this post is what others have referred to as an impedance mismatch. Basically I want to write a C# statement and have it execute on a database server with as few layers of translation as possible in between. So in theory I should be able to write a LINQ statement and send it off to a server and that server should be able to parse my LINQ statement without translating it to SQL first. 
Something like this https://github.com/migueldeicaza/gui.cs ?
Love the critical feedback! thanks! Actually I started with my API having "Write" methods and then just to simplify I implemented ```ITargetBlock``` because it seemed to make sense. But then it made even more sense: The important thing to know is that underneath it's effectively a "Queue" so when you use ```.WriteAsync``` that is actually very misleading because it hasn't written anything yet. If you were using a FileStream or StreamWriter then ```.WriteAsync``` does exactly what you're saying but also consider that you'll need to ```await``` (or ```.Wait()```) on that as well otherwise you might dispose before it has completed. using(var writer = new AsyncFileWriter(filePath)) { writer.Post("Hello world!"); // Updated version allows strings... (see github link) } Will do exactly what you expect it to do in that the subsequent ```.Dispose()``` calls ```.Complete()``` and waits for everything to write/flush/cleanup before continuing. For this class, if you didn't call dispose, then it will finish writing to the file any posts you've made before disposing of the internal FileStream and therefore not retaining any managed resources and the GC will happily clean that up. I did experiment quite a bit with the API and am still toying with it. I've added ```ITargetBlock&lt;char[]&gt;``` and ```ITargetBlock&lt;char[]&gt;``` so that strings can easily be posted. And I will likely find a way to implement a buffer limit (that is actually doing what you think in producer-consumer world).
Have you seen "Channels"? New MS open source producer-consumer code. Faster than Dataflow, but with less control.
I have also used PDFsharp. I found it pretty good. Easy to use. I was stripping images from TIFF files and embedding them and adding custom tables with text. Took less than a day to do. Thereâ€™s a fair bit of documentation too. 
Don't blame the tool, blame the craftsman. I use entity framework extensively in my current role and it performs just fine.
It can work if you do it correctly. I agree. But it is easy to end up with some crazy generated SQL. Maybe I just like writing SQL. 
How much memory overhead does this generate?
Dude, you can decouple your business logic without any orm. All you need is a repository and prepared statements...
You can do something similar with clr assemblies... https://docs.microsoft.com/en-us/sql/relational-databases/clr-integration/assemblies-database-engine
I've done this in WebAPI but I'd imagine it can be done in ASP.NET MVC as well. Using a Custom AuthenticationFilter you can use the ChallengeAsync method to return a Challenge specifying the Negotiate scheme which will tell the client that the resource they are requesting requires Windows Authentication. This will send the initial 401 challenge response back to the client and if the client supports the negotiate scheme they will send an additional request with the Authentication: Negotiate HTTP Request Header in their follow up HTTP Request. Once they send a request after the challenge is made you should see that the User object is now populated. Heres what the ChallengeAsync method looks like to tell the client you want them to authenticate with windows. public Task ChallengeAsync(HttpAuthenticationChallengeContext context, CancellationToken cancellationToken) { var challenge = new AuthenticationHeaderValue("Negotiate"); context.Result = new AddChallengeOnUnauthorizedResult(challenge, context.Result); return Task.FromResult(0); } public class AddChallengeOnUnauthorizedResult : IHttpActionResult { public AddChallengeOnUnauthorizedResult(AuthenticationHeaderValue challenge, IHttpActionResult innerResult) { Challenge = challenge; InnerResult = innerResult; } public AuthenticationHeaderValue Challenge { get; private set; } public IHttpActionResult InnerResult { get; private set; } public async Task&lt;HttpResponseMessage&gt; ExecuteAsync(CancellationToken cancellationToken) { HttpResponseMessage response = await InnerResult.ExecuteAsync(cancellationToken); if (response.StatusCode == HttpStatusCode.Unauthorized) { // Only add one challenge per authentication scheme. if (!response.Headers.WwwAuthenticate.Any((h) =&gt; h.Scheme == Challenge.Scheme)) { response.Headers.WwwAuthenticate.Add(Challenge); } } return response; } }
Not true, PowerBI Report Server/PowerBI is the sequel to SSRS/SSAS.
&gt; performance doesn't matter and never will What are you smoking?
This is a problem with SQL itself. You never know what kind of crazy query plan the system is going to decide to use.
It's important to materialize your sets before doing non-native aggregations, otherwise they are enumerated asynchronously. You want to load the data in RAM, do your non-native aggregation, then dispose the DTO. Conversely, it's important to let native aggregations be delegated to the server.
You didn't simplify it. You complicated it, as far as the API is concerned. It's perfectly reasonable that you'd have such an implementation detail in another class, as in: AsyncFileTarget. And then you have your AsyncFileWriter use that, as well as all that boilerplate code you need to do to actually use your code, and boom, a library people might actually use. An AsyncFileWriter should behavior like users expect a FileWriter to behave, only async. What you needed to do, because you wanted to use this dataflow stuff, was to use composition over inheritance. Instead, you inherited, and are trying to force everybody else to adapt to a completely difference concept of what a file writer should be. It's not going to work out well. .WriteAsync isn't misleading. Many async methods implement queues underneath the scenes. It is very typical. It's no more misleading than your buffer.SendAsync. I just gave a quick sample, of course you would probably want await or .Wait()... well, except if you didn't want it to be blocking. And if you were properly following how file writers tend to look, you'd have something like FlushAsync to wait until it's done. And if I'm not mistaken, don't you have code in your dispose method to wait until it's complete? You literally covered for that potential case. Although, speaking of, you need to look up how to implement the disposable interface correctly. ... This all sums up to encapsulation. How you implement an AsyncFileWriter should be, at default, no concern to me. Instead, I'm forced to know it just to use your class.
I was not aware of this. If it comes from Stephen Toub its probably pretty good. Have you used it? 
https://reactjs.org/docs/state-and-lifecycle.html#the-data-flows-down
so cool, makes me want to re-make turbo pascal.
&gt;SQL needs to go away. So far, other than you repeating this phrase, you haven't stated or demonstrated why this is the case. Developing in SQL is an entirely different mindset. It's not analogous to imperative code at all, and every example I've ever seen where someone tried to treat it like imperative code, it was absolutely horrible. Then someone comes along and writes it in native, well\-thought\-out SQL and gets an order of magnitude \(or multiple\) improvement out of it.
In fairness to SQL, that's one of the highlights of a fourth-generation language. You don't tell it what to do, you tell it what you want, and it figures out how to do that. Now, it doesn't always do that optimally, but I can give it incentives to do better (e.g. indexes and hints). The larger my system scales, the more optimal plans become for the new data distribution. Again, sometimes they're just garbage. Add a hint there, tweak a join over here, and you get something more sane. I'd much rather be in that business than determining the optimal data structure and lookup algorithm for every piece of data I need to retrieve.
&gt;I have really come to appreciate the value of being able to express my business logic in managed code (C#) versus writing SQL statements. The benefit of writing business logic in C# seems profoundly obvious. I share your opinion that C# is a much better language than SQL when it comes to writing business logic. &gt;So why do we still have to use thick layers like Entity Framework to translate our queries from LINQ to SQL? This is where you lose me. 1. We don't have to do that. We can write our own SQL. 2. A DBMS needs to be able to find structured data (potentially lots of it) that meets some sorts of criteria and move it to a (potentially) distant machine (potentially lots of them) that may not even speak the same machine language, let alone share any other higher-level framework commonalities. This is not a simple problem. 3. Weren't you just taking about business logic a sentence ago? What does that have to do with ORMs and LINQ-to-Entities? &gt;Why are we still burdened with the inadequacies and limitations of SQL? Such as? &gt;I think I should be able to write a LINQ query and have it parsed natively by the database server. What advantages would that have over the status quo? &gt;I should be able to send a List&lt;T&gt; as a parameter with no boxing or other kind of hassle. If converting it to a `DataTable` or `IEnumerable&lt;SqlDataRecord&gt;` and passing it in as a `SqlDbType.Structured` parameter is too much hassle, then perhaps you don't share my appreciation for the size and complexity of the problems that DBMS solutions attempt to solve...
Can I embed a power BI report into a secured section of a website without having to first make the report public for all to see? 
Yes I did! Definitely faster! But it was 'beta' at the time so I stuck with Dataflow.
Updates to the code. Much better now. Review. It can throttle now. :)
&gt; I share your opinion that C# is a much better language than SQL when it comes to writing business logic. &gt; We can write our own SQL. Why would I write sql if I can write C#? &gt;&gt; If converting it to a DataTable or IEnumerable&lt;SqlDataRecord&gt; and passing it in as a SqlDbType.Structured parameter is too much hassle, I dont think you understand the intent of my post. [Please see this comment](https://www.reddit.com/r/dotnet/comments/8abt2s/will_microsoft_ever_create_a_dbms_that_will/dwxl1fq/?st=jfojl7tn&amp;sh=4607325a) 
&gt; So far, other than you repeating this phrase, you haven't stated or demonstrated why this is the case. As stated in my original post, the benefit of writing business logic in managed code is self evident: &gt; The benefit of writing business logic in C# seems profoundly obvious. I'm not here to make a case for it, I'm here to inquire why, given the benefit, does the technology not exist for it to be more efficiently utilized.
I can't see it generating any memory overhead. Each service connection would have a transient database context and how that context queries the database would be dependent on EF or Dapper. Dapper will always be more performant, EF just has the ease of use. Like I said above,. eF for anything CRUD, Dapper for everything that is even remotely complex.
&gt;&gt; I share your opinion that C# is a much better language than SQL when it comes to writing business logic. &gt;&gt; We can write our own SQL. &gt; &gt;Why would I write sql if I can write C#? re: my sentences that you quoted, this is not a contradiction. I believe C# is better than SQL for writing business logic. I also believe that SQL is not worse than C# when specifying what data to retrieve from a (relational) database. I am not aware of a common-use definition of "business logic" that covers this latter use case. So to answer your question, one reason to write SQL instead of C# to access data from a DBMS like MSSQL is because the former gives you strictly not fewer options for how to tune your query for performance (because the former supports at least everything that the latter does). &gt;&gt;&gt; If converting it to a DataTable or IEnumerable&lt;SqlDataRecord&gt; and passing it in as a SqlDbType.Structured parameter is too much hassle, &gt; &gt;I dont think you understand the intent of my post. [Please see this comment](https://www.reddit.com/r/dotnet/comments/8abt2s/will_microsoft_ever_create_a_dbms_that_will/dwxl1fq/?st=jfojl7tn&amp;sh=4607325a) Help me understand it, then. What problems do you have with today's solutions that can only be solved by ditching SQL entirely (as opposed to the usual approach of extending T-SQL)? Reading your linked comment, it's even less clear. It sounds like maybe you're noticing a performance problem? You keep going back to the fact that there's no step to translate to SQL as though that's a clear benefit in and of itself, but personally, I don't see that as being a problem on its own. Other than for performance reasons (which should amortize to nothing when using stored procedures), why should I care whether the DBMS speaks SQL or some other language, especially if I choose to use something like LINQ-to-Entities to hide even that detail from my code (not that I do choose that approach, mind you... I still favor SQL and stored procedures today)?
Actually I believe SQL would be terrible without the millions (billions?) in R&amp;D dollars poured into the optimizer which generates highly efficient execution plans. At it's core it is a very high level language which has nothing to do with performance at all. SQL doesn't automagically give you amazing performance. You have to understand how the optimizer works and whether it will be able to give you an efficient query plan based on the SQL you write.
We've used Rotativa which integrates nicely with MVC. It uses wkhtml under the hood but you can make any MVC action return a PDF with just a few lines of code. 
I hope not. SQL is easier to write. Anything wild and I just make a stored procedure
Dapper is way more than a mapper. It's lightning fast compared to EF and exponentially easier to maintain.
I think he means data layer logic (I hope) because business logic shouldn't be coupled with EF or anything remotely related to the data layer. That would be dependency hell.
And do you know exactly how the SQL Server optimization system works behind the scenes? Those CSX files aren't going to get yo maximum performance because the cache plans will differ depending on the scenario.
&gt; What makes SQL so special it deserves native support? Decades of some of the highest paid software engineers on the planet working on it, and making sure it does what it is supposed to do, both performance wise, strict ACID compliance, and the rest of it. You are coming across as someone who just doesn't want to deal with SQL.
If keep it simple for now and stick with basic jQuery for any async calls to a rest API only because angular is a whole other headache in itself to deal with. I'd recommend writing everything without the UI first, just to get the new .net stuff done and familiar, and tackling the excess stuff as a whole other project. 
But why thrash SQL? One does not exclude the other depending on your use case. MS is a massive company with a massive client base to cater for; that means they cannot deliver things that limit themselves. I used EF and found it not a good fit for 90% (inefficient query generation, too locked to MSSQL efficiency wise etc) of software my company writes so we rolled our own ORM that works for our use cases; it is highly efficient for what *we* do and we have not had to write raw sql queries for years. But giving that ORM to you would probably not help you one bit as it was tailored to our use cases; for you it would create highly inefficient queries or maybe queries you do are not possible at all. MS has to tailor for us both and the rest of world so they have to make sure that that works for years to come. Solutions like you suggest are implemented on top of sql like we did for specific use cases or written from scratch by companies tailoring for niche markets; kdb, redis and mongo all use native non sql query languages. And indeed, depending again on your use case, you are not going to beat redis and kdb in performance and code terseness with mssql, but for other use cases the reverse is also true. 
&gt; As stated in my original post, the benefit of writing business logic in managed code is self evident: Do you enjoy having to re-compile and re-deploy a massively large managed code-base because of some poorly optimized SQL that can be fixed by editing a stored procedure? I'm not sure if you only deal with small projects but in the real world, that is not acceptable.
I begin this post with the conclusion that writing business logic in c# versus SQL is more expressive and reusable: &gt; The benefit of writing business logic in C# seems profoundly obvious. I am not here to prove that assertion. To me, it is self-evident. I realize there are others with differing opinions and I certainly respect them and understand why they may disagree. &gt; that can only be resolved by Microsoft adding another way to interface with their DBMS solution(s) that is completely separate from SQL, I don't think I have laid down any mandates as for how the issue can "only" be resolved. In fact I've stated several times that I dont have a clear idea of how something like a LINQ server (for lack of a better term) might be implemented.
Check out check the recent â€˜elastic sqlâ€™ dbs like Cockroachdb; the scaling of nosql with the properties or sql dbs. 
If you have never written an Enterprise app using an ORM like Entity Framework than you will not understand this post. &gt;So to answer your question, one reason to write SQL instead of C# to access data from a DBMS like MSSQL is because the former gives you strictly not fewer options Look, today I can write code like this: Customer c = db.Customers.Where(x =&gt; x.ID == 1); Thanks to tools like Entity Framework, the above gets translated into something like this: SELECT * FROM CUSTOMERS C WHERE C.ID = 1; The translation from the first form to the second form is 1.) non-performant and 2)sometimes results in an ambiguious or inefficient query. The question I am raising in this post is "Why do we not have a server that will NATIVELY parse and execute the first query WITHOUT first translating it into its SQL equivilant." &gt;What problems do you have with today's solutions that can only be solved by ditching SQL entirely (as opposed to the usual approach of extending T-SQL)? I've suggested that getting rid of SQL is a great idea however I dont recall saying any problem can "only be solved by ditching SQL entirely". Please be sure to separate your statements from mine. &gt; why should I care whether the DBMS speaks SQL or some other language, See above. 
&gt;Decades of some of the highest paid software engineers on the planet working on it, and making sure it does what it is supposed to do, both performance wise, strict ACID compliance, and the rest of it. Once upon a time COBALT had some of the highest paid software engineers on the planet working on it. &gt;You are coming across as someone who just doesn't want to deal with SQL. That is true. I dont want to deal with SQL. But that statement itself tells only a small part of the story. &gt;And if you are lumping SQL in with Microsoft for some reason, it's not, it's an ANSI standard. Sorry that is incorrect. I am lumping Entity Framework with Microsoft. It's their product.
SQL is a highly specialized DSL. It maps very well to structured related data, and set theory. If you throw that out of the window because the data store should understand LINQ, companies and researchers need to spend several billion dollars to come up with something new, that does the same. In the end, it will be having the same issues, because being the last step, it will have to work with the same hardware and the same structured related data.
How do you test stored procedures?
&gt;why do we still have to use thick layers like Entity Framework to translate our queries from LINQ to SQL? There's no reason why you have to use a ORM if you don't want to. &gt;Why are we still burdened with the inadequacies and limitations of SQL? What are those? Used properly, SQL is probably the best language for querying relational data. I imagine F#'s Computation Expressions and Type Providers could take a lot of the pain out of ORM scenarios, but I haven't looked into this specific application yet.
Yeah... No.
I think VisualStudio is not the ideal IDE for web related coding tasks. You should give visual studio code a try instead.
Well i mean the numbers don't lie in that fool proof test! 3x as quick! I'm going to be the popular guy in the office come Monday when all my co-workers realise I've switched them all to Hyper-IDE.
&gt; Who is going to write native LiNQ support for Oracle Database, MySQL, SQLite? [These guys](http://fsprojects.github.io/SQLProvider/) already did
OP is talking about native LiNQ support. There is not a single database that implements that. They all do LiNQ to SQL. The database is actually executing SQL. 
oops my mistake, i misread.
Whether or not you get positive feedback on this sub, that's a pretty ambitious undertaking, so kudos to you for that. FYI - the github link got mangled in the description. Oh, and your background music is a song about taking heroin. Is the IDE addictive?
Hehehe :D Well, I probably wouldn't completely uninstall Visual Studio, but as a _"second IDE"_, for tasks such as HTML, CSS, JavaScript etc - It literally runs in circles around Visual Studio - Which was kind of my point ... :) Then comes the question, how much of your work is JavaScript/HTML/CSS, and how much is C#/VB.NET etc - Hyper IDE is (obviously) *not* the best IDE to create C# code ... But for my own usage, which obviously is biased, since I after all created the thing - I find myself using Hyper IDE roughly 60-70 percent of my time, and VS roughly 30% ...
I actually downloaded VS Code, because I wanted to profile it towards Hyper IDE, but it was no point - Since VS Code actually performed very well. But then comes the additional benefits, such as being able to edit your files, over your phone, securely, from an internet coffee shop, on the North Pole ... ;) Try it out if you like to - https://home.gaiasoul.com/hyper-ide (But you can't save files, or read my web.config or authentication files, or private files) If you download it, you can (of course) save files, and create as many users as you want to ... :)
Thank you Sir :) &gt; Oh, and your background music is a song about taking heroin Wow, I didn't know actually. It's just a background track I found on YouTube, which I play my own Saxophone on top of (yup, my mix). As in regards to whether or not it's addictive, my answer is as follows; _"No comment Sir"_ ... ;) Regarding; _"the github link got mangled in the description"_ Darn, iMovie messed up my CR/LF characters ... Thank you, fixet now!
The song is Golden Brown by The Stranglers. Your background music is a much jazzier take on the song, but if you've watched *Snatch* as many times as I have, you might recognize it from the soundtrack: https://youtu.be/Ag_HToYi_Uc?t=64
That's COBOL.
If you don't know how to test a stored procedure, that is another sign you haven't worked with this technology enough to comment on its merits. Did you know you can set breakpoints in T-SQL and evaluate conditions like in .Net? Not my go-to route but you can. 
&gt; dereference and GC.Collect(). I pretty much always heard that you should never call `GC.Collect()` unless you are doing very specific high-performance stuff and really know what you are doing. Is this not true anymore?
Could just use a pc and link it to a mac when you build. 
Good to know. So, ultiamtely, SSRS is going by the wayside then?
Update: We've released our .NET Core version of Cofoundry, everything's open source on [GitHub](https://github.com/cofoundry-cms/cofoundry)
So what you want is a NoSQL store? It sounds like you just want a NoSQL store. Also don't write business logic in a query. Also what limitations of SQL are you running into? Your post raises a ton of questions and red flags in my mind.
&gt; The specification or standard was written before .NET Core existed, so only applies to the .NET Framework, Iâ€™d be interested to know if there are any plans for an updated version? What parts of the spec are .Net Framework-specific? I think that pretty much all of it applies to .Net Core as well.
Sorry buddy, it's called _"Take Five"_, and it's an old Jazz tune by Dave Brubeck. https://www.youtube.com/watch?v=PHdU5sHigYQ I love Snatch though, and I can relate to how you find it similar - But it's actually called _"Take Five"_. In fact, its name was a lot of my reasons for choosing it, since the framework I built to build Hyper IDE is called _"Phosphorus Five"_.
Hmm, not sure what you mean here ...? But with Hyper IDE, you can easily integrate compiler services and such, since it has a _"terminal plugin"_, allowing you to evaluate bash scripts and such. In fact, there are template scripts for most types of common tasks already, such as GIT commands, and an example bash script file of how to compile a C# file on Linux ...
It's a bit off topic, sorry for the post. 
&gt;&gt; that can only be resolved by Microsoft adding another way to interface with their DBMS solution(s) that is completely separate from SQL, &gt; &gt; I don't think I have laid down any mandates as for how the issue can "only" be resolved. In fact I've stated several times that I dont have a clear idea of how something like a LINQ server (for lack of a better term) might be implemented. I get that you don't want to try to figure out the details of how a solution would look, but given the quotes I've added to the bottom of the comment, I think it's more than fair to say that your criteria for an acceptable solution include something like: - Allows you to interface with a Microsoft DBMS solution - Completely separate from SQL - Added by Microsoft So unless I'm misinterpreting something that you've been trying to communicate, and you're not in fact asking for a solution that hits all of those three points, then I stand by my assertion that you'd quoted above, namely that "you claim that there are critical problems with this solution that can only be resolved by Microsoft adding another way to interface with their DBMS solution(s) that is completely separate from SQL". &gt; Why are we still burdened with the inadequacies and limitations of SQL? &gt; &gt; There has to be a better way to get a C# query to a DBMS than what is being done with tools like Entity Framework. &gt; But what I am suggesting in this post is that Microsoft do away with both MSSQL server and Entity Framework and replace them both with some yet unknown technology that accomplishes the best of what they both do. &gt; &gt; MS should stop beating the EF horse. &gt; &gt; (remember - SQL will no longer exist) &gt; &gt; This technology seems long overdue - will it ever come? Microsoft feel free to update us please!
&gt; SQL needs to go away. SQL will never go away for relational database, because SQL has a very clear mapping to relational algebra, and *that's* what you're actually writing when you write a SQL statement. LINQ is an abstraction built atop that. You can't replace SQL with LINQ. At best, you could replace SQL with relational algebra, but that'd honestly be *less* clear to the average developer. There *are* non-relational storage models which make a different set of tradeoffs in terms of the richness of your query capabilities and reliability and performance. These usually don't use SQL, and may have LINQ adapters. SQL is the correct tool for interacting with relational data.
&gt; Back in the 90's (I think) "Object Databases" were a fad 90s? The fad never went away. We just call them "NoSQL" or "Document Stores".
&gt; What makes SQL so special it deserves native support? I know I said this elsewhere, but I really need to hammer this point home, because goddammit, it's important. The mathematics which underpins relational databases is called relational algebra. A relation, by the way, is not to be confused with a *relationship*- tables are relations. Rows are tuples. The power of relational algebra is that, given a series of relations populated with tuples, and given a relational expression for searching that set, I can accomplish certain things: * I can prove, mathematically, which tuples will be returned/modified by the statement (I know what my query will do) * I can prove, mathematically, the computational complexity of performing the operation (I know roughly how hard it is to do) * There is a relational algebraic statement which can be used to construct *any* set of output tuples for any set of relations (I can make a query that does any possible thing) There's a great deal more, and I'm certainly no expert on relational algebra. I haven't touched it since college, where I had to do some of these sorts of proofs as part of our "Databases" class. The point is: relations and relational databases are mathematical constructs. And they're hard to work with. Enter SQL. We can quibble about the design choices in SQL (putting the projection clause as the *first* thing in a SELECT is silly, to me), but at its core, the *purpose* of SQL is to provide a high-level language for performing relational algebra. As such, SQL has a 1-1 correspondence to RA, and you can generally sit down with a notepad and turn any SQL statement into a relational algebraic expression without having to work terribly hard. Let me repeat this: SQL is simply a way to express relational algebra in a human-readable, programmer-friendly way. Its syntax arises from the problem domain. While SQL isn't the only way to express relational algebra, *any* way you express relational algebra is going to end up behaving in a very SQL-like manner. That is to say, you're *never* going to solve the problem of relational data access from object oriented applications without bumping into a problem of domains: relational data is a different domain from object modeling, and there will *always* be mismatches. If you're using a relational database, you will have this problem. Period. The only way out is to not use relational databases. There are lots of options, but the challenge is that they make different tradeoffs. I've done a lot of work in Cassandra, and Cassandra simply doesn't guarantee my third bullet point up above- there are queries which are simply not allowed in Cassandra, in part because due to Cassandra's architecture, bullet point #2 is hard to guarantee. You'll bump into similar tradeoffs in most "NoSQL" databases- for the most part, they sacrifice some degree of flexibility or reliability in order to get an increase in simplicity, or advantages in distributed workloads. And this is all before we start talking about transactions, and why relational databases guarantee ACID and why other models may or may not be able to provide comparable guarantees. TL;DR: because math
That's pretty close to what I was trying to say. When I say "SQL", I mean including the optimizer and the ability to hint and manually optimize a query, just as well. No matter how much effort you put into making another language do SQL's job, you'll always be behind the billions (almost assuredly) of dollars that have gone into perfecting it. For the most part, SQL will give you optimal performance on small to medium complexity queries. There's always room for micro-optimization (CTE vs SubQuery? Sproc? Inline TVF? etc...), but for the most part, SQL and it's optimizer will make the work as efficient as possible. On a side note, thanks for engaging me, instead of being a douche. Even if I'm way off base (which isn't unheard of), I appreciate the respect.
True, if you're using GC.Collect() to ease memory pressure, then you're doing something wrong. There are much better ways of handling high-performance stuff in the CLR, especially with the new Span&lt;T&gt; type in core.
oh nos I've been doing it wrong all these years! Why don't you take a stab at [this question](https://www.reddit.com/r/dotnet/comments/8abt2s/will_microsoft_ever_create_a_dbms_that_will/dwyu3oc/?st=jfphcqbp&amp;sh=2f944585) 
&gt; If you have never written an Enterprise app using an ORM like Entity Framework than you will not understand this post. Maybe you're right. Maybe my inexperience with ORMs is an obstacle to my own understanding. Maybe this is one of those "had to be there" kinds of things, and the problems with the status quo really would become self-evident by what I'd seen in the thread up to that point. &gt; Thanks to tools like Entity Framework, the above gets translated into something like this: Even in your example, that's not actually what's being directly transformed; today, by the time EF gets engaged, all it can see is a bunch of MSIL. Nobody really "remembers" that this used to be C# code, and the same tool works for VB.NET / F# / IronPython / PowerShell. So even if we suppose that the database would take a bunch of bytes that represent the literal string `"Customers.Where(x =&gt; x.ID == 1)"`, only C# would really be able to take direct advantage of it (with some help from the compiler to remind the runtime what this code used to look like)... all those other languages (and the dozens of existing less popular ones, and the ones we haven't even thought of yet) that choose to go the ORM route would have the exact same problem that they have today (just targeting C# instead of SQL), and then 5 years down the road, *yet_another_sam* would come around asking why we can't just write all our data access code in D++ or INTERCAL or Malbolge or whatever's popular at that time. &gt; The translation from the first form to the second form is 1.) non-performant and 2)sometimes results in an ambiguious or inefficient query. &gt; &gt; [...] &gt; &gt;&gt; What problems do you have with today's solutions that can only be solved by ditching SQL entirely (as opposed to the usual approach of extending T-SQL)? &gt; &gt; I've suggested that getting rid of SQL is a great idea however I dont recall saying any problem can "only be solved by ditching SQL entirely". Please be sure to separate your statements from mine. Thank you for helping me understand by laying out at least some of your specific problems with the status quo. I'll grant that I was guilty of skipping a step here, and I apologize for that. Let me try again. You came to the table with a solution of something like "database similar to SQL Server but which I can query using something that isn't SQL" and a set of problem statements that weren't more specific than "EF has to translate what I write into SQL in order to access the data from SQL Server ". I was asking for clarification about **your** problems with the status quo, because the mere fact that EF has to target SQL is **EF's** problem. The specific problems you claimed above didn't surprise me in the least, because it's exactly the things I was expecting to see, in my words: 1. EF is unacceptably inefficient at transforming your inputs into SQL 2. EF generates unacceptably low-quality SQL compared to what you could have written yourself to retrieve the same set of data AFAIK, these problems can be solved within the existing systems by creating stored procedures that EF can run, and/or by writing SQL yourself. You've mentioned something about business logic in the past, but I still don't quite understand that part, so I won't comment on it here. &gt; The question I am raising in this post is "Why do we not have a server that will NATIVELY parse and execute the first query WITHOUT first translating it into its SQL equivilant." Because the expected costs don't outweigh the expected benefits. Microsoft could instead spend a fraction of the cost to make the query optimizer recognize certain problematic SQL patterns that EF produces today and have it compile into the query plans that a "native" solution would have compiled. Or they could invest in making EF recognize certain problematic patterns in the expression trees that you might build and optimize them better. Or they could invest in adding something to T-SQL if there's an important pattern that you can do in C# which doesn't translate well to existing T-SQL syntax.
What are you talking about? I never claimed to be an expert on the mater. I was simply asking how you would go about testing stored procedures.
Well I can edit my files regardless of my location anyways. It is called version control. I don't need a full fleshed IDE on my phone. So there is no point in that. I don't want to say that what you did is not awesome, because it is. But I don't see any use for it. For my use cases at least.
&gt; Must have valid customer ID, &gt; &gt; Must have valid Sales Rep ID, &gt; &gt; All productIDs must be valid The above should all be automatically handled by constraints defined in the data model... my bits below assume that the order's already been added to the database in an uncommitted transaction, and so those constraints have already been validated. &gt; any product has an on hand quantity less than the sum of all outstanding orders that reference it This is a bit funky, so for my own sanity, I've just assumed a stored procedure that takes in an order ID and returns all the products it references that can be satisfied with the on-hand quantity. There's probably a cool way to do it with LINQ joins, but I don't do those enough and I don't want to look it up right now. &gt; Customer must have: (available credit equal to order amount AND no past due invoices in the last 60 days) OR terms must be COD &gt; &gt; At least one line item with qantity not equal to zero &gt; &gt; Scheduled ship date must be greater than todays date plus the longest lead time of any product ordered OR null if any product has an on hand quantity less than the sum of all outstanding orders that reference it. OK. I don't really use any ORMs, so I'm not sure if you'll be happy with the syntax I've chosen to use. I'm also not sure if any of those three could be handled by other fancy constraints in the database. In any case, here's my go at it. void ValidateOrder(Order order) { if (OrderLineItems.Get(order.LineItemIds) .All(lineItem =&gt; lineItem == 0)) { Fail("Order has no line items with nonzero quantity."); } if (order.Terms != Term.COD) { Customer customer = Customers.Get(order.CustomerId); if (customer.AvailableCredit &lt; order.Amount) { Fail("Customer does not have enough credit") } if (Invoices.Get(customer.InvoiceIds) .Any(invoice =&gt; invoice.IsInLast60Days &amp;&amp; invoice.IsPastDue)) { Fail("Customer has past-due invoices in the last 60 days"); } } var today = DateTime.Today; if (Products.Get(order.ProductIds) .Except(ProductsOnHand.Execute(order.OrderId)) .Any(product =&gt; order.ScheduledShipDate &lt; (today + TimeSpan.FromDays(product.LeadTimeInDays)))) { Fail("Order has products that will not arrive in time"); } } &gt; tell us where this code might live in your application I don't have enough information to answer that question.
[removed]
&gt; What would the object oriented way be? How long would it take to read billions of products into memory, updating each one, saving them to the database? *Nitpick*: "object-oriented" as a paradigm doesn't preclude sending the database something that looks like the C# lambda `product =&gt; product.Price *= 1.01m`.
I think you miss the point of my response (I was being a little sarcastic I admit). The two statemets I am responing to are: &gt; Uh... have you been putting your business logic in SQL? That would explain your difficulty... &gt; I think he means data layer logic (I hope) because business logic shouldn't be coupled with EF or anything remotely related to the data layer. In any case your example is useful with respect to the two statements above so lets start with line 1: &gt; void ValidateOrder(Order order) We are passing in an order object. Was it ever persisted to disk? Where did we get the order object object from? &gt; The above should all be automatically handled by constraints defined in the data model... &gt; Customer customer = Customers.Get(order.CustomerId); &gt; if (customer.AvailableCredit &lt; order.Amount) Customers.Get? Get from where? Why no null check on the customer object? You say with regard to customer IDs that they are "automatically handled by constraints defined in the data model..." This code going to fail: Order order = new Order { CustomerID = -9999} // No such ID exists ValidateOrder(order); There is no need to respond to this I think I've made my point that the two statements I responded too are nonsensical (note I am not referring to your post only the two statements above). I will mention that your code demonstrates how much easier it is to write and re-use business logic that is written in managed code. Side note - you say "I don't really use any ORMs". How do you expect this code to actually get data from a database server? 
&gt; I don't need a full fleshed IDE on my phone Psst, just remembered Hyper IDE is only one of the 5 apps that comes out of the zip file ... You also have Camphora Five (create CRUD apps in seconds) and the Magic Menu (control your web server with speech recognition), plus, plus ... :)
&gt;&gt; void ValidateOrder(Order order) &gt; &gt; We are passing in an order object. Was it ever persisted to disk? Where did we get the order object object from? It's from this assumption: &gt; my bits below assume that the order's already been added to the database [...], and so those constraints have already been validated. In other words, that it's structurally valid, which is something that enterprise-quality relational databases like SQL Server are **really** good at doing for you automatically. &gt; Customers.Get? Get from where? Your relational data store. My assumption is that your ORM exposes some way to get a `Customer` object by its `CustomerId`. `Customers.Get` was a stand-in for whatever your ORM makes you do... I was, at least, careful to make sure that we can assume an `IQueryable&lt;T&gt;` return so that the ORM has the best opportunity to execute as much as it possibly can on the database side. &gt; Why no null check on the customer object? You say with regard to customer IDs that they are "automatically handled by constraints defined in the data model..." &gt; &gt; This code is going to fail: &gt; &gt; Order order = new Order { CustomerID = -9999} // No such ID exists I felt it acceptable to assume a structurally valid input by the same assumption as I quoted earlier: &gt; my bits below assume that the order's already been added to the database So imagining a foreign key relationship from the `[Order].[CustomerId]` column to the `[Customer].[CustomerId]` column seems reasonable. &gt; There is no need to respond to this I think I've made my point that the two statements I responded too are nonsensical (note I am not referring to your post only the two statements above). I'm aware, but I bothered to respond because I happen to agree with the general sentiment that putting important business logic in SQL feels like a solution of last resort, rather than inline with the SQL that's used to query the data. &gt; you say "I don't really use any ORMs". How do you expect this code to actually get data from a database server? Is it unreasonable to assume that an ORM can handle something like this? I'd imagine that I should be able to configure even the simplest ORM to be able to look at something like these tables...: ## Customer |CustomerId|AvailableCredit| |-|-| |1|2| ## Order |OrderId|CustomerId|Terms|Amount|ScheduledShipDate| |-|-|-|-|-| |1|1|'COD'|21|'2018-04-20'| ## LineItem |LineItemId|Quantity| |-|-| |1|6| |2|0| |3|0| |4|3| ## OrderLineItem |OrderId|LineItemId| |-|-| |1|1| |1|2| |1|3| |1|4| ## Invoice |InvoiceId|IsPastDue|Date| |-|-|-| |1|False|'2018-04-02'| |2|True|'2017-02-09'| ## CustomerInvoice |CustomerId|InvoiceId| |-|-| |1|1| |1|2| ...and be able to create objects that look something like these just by their IDs: - `Customer[CustomerId: 1, AvailableCredit: 2, InvoiceIds: (1, 2)]` - `Invoice[InvoiceId: 1, IsPastDue: False, Date: 2018-04-02]` - `Invoice[InvoiceId: 2, IsPastDue: True, Date: 2017-02-09]` - `Order[OrderId: 1, Terms: COD, Amount: 21, ScheduledShipDate: 2018-04-20, LineItemIds: (1, 2, 3, 4)]` - `LineItem[LineItemId: 1, Quantity: 6]` - `LineItem[LineItemId: 2, Quantity: 0]` - `LineItem[LineItemId: 3, Quantity: 0]` - `LineItem[LineItemId: 4, Quantity: 3]` If it can go even further and fill out the related objects instead of giving us the IDs to fill them out ourselves, then all the better! But if it can't even get us to this point, then maybe I'm overestimating ORMs.
I have no idea.
Been using iTextSharp for years, it's quick and reliable, I've also used it many times on a web server for creating downloadable reports on the fly.
I've had one case where manually collecting resulted in a performance improvement. I've got a server which runs a number of applications and is memory limited. When I don't collect, the heap grows to a significant fraction of available ram before enough pressure builds to trigger a collection. This causes other applications of suffer negative side effects, and eventually I would lose control of the server as it started to put objects in the page file. Adding a call to gc.collect after each processing batch kept the heap lean, resulting in reduced and more reliably sized application memory footprint. In order to get this to work, it's important to call asnotracking on your queries. Otherwise, a reference to the data is maintained on the heap in the dbcontext.
Or your install the on premises software.
Well the ECMA-335 specification has a section on Application Domains and references them afew times. Though this may still exist in the Core CLR and just isn't exposed anymore. Who knows! I could never answer this question fully since I'm far from knowledgable enough. Though there can't be much it differs from, if any at all, but I think only afew people know both enough about the specification and the Core CLR to know if it deviates. It probably doesn't though.
I've used both but mostly Postgres. I've used Postgres with EF Core, Dapper, and Marten (to treat it as a document database). All side projects though.
We got several microservices using postgres and asp.net core . Each running in docker containers locally and using the ecs and rds in prod . 
Went with Postgres for our new .net core project. On the technical side it was very close - each one has some interesting features the other lacked, Postgres more so, while MSSQL also had slightly better tools and libraries. As a dev I think I would have been happy with either. However, yes, not needing to charge our clients for a Windows + SQL Server license definitely tipped the scales in favour of Postgres.
Those opening notes sounded the same to me. Oh well, I should know better than to opine on music since the only instrument I can play is the radio.
Uhg, nevermind. Was banging my head against it for a couple of hours and it turns out that System.IdentityModel.Tokens.Jwt and Microsoft.Owin.Security.Jwt had to be downgraded to lower versions. 
I've only used MySQL
I had trouble getting verification to work. I think I used [jwt-dotnet](https://github.com/jwt-dotnet/jwt) or similar..
I am actively using both Postgres and MySQL with .NET Core. I love postgres because it works as expected out of the box, is fast, and doesnt take up too much memory on the server. I dislike MySQL + EF Core because of the driver situation. AMA.
Postgres has better .NET Core integration, hands down. I saw the other side. You made the right decision.
It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click! [Here is link number 1](https://stackoverflow.com/questions/36641338/how-get-current-user-in-asp-net-core) - Previous text "SO" ---- ^Please ^PM ^/u/eganwall ^with ^issues ^or ^feedback! ^| ^[Delete](https://reddit.com/message/compose/?to=FatFingerHelperBot&amp;subject=delete&amp;message=delete%20dwzrd5i) 
Is speed your only metric? Because feature set is far more important to me (Disclaimer, i have no performance issues with Visual Studio). 
You can easily write what you described with zero data layer using dependency injection, and making interfaces of your data layer access methods. In fact when doing unit tests, that very business logic you stated should pass using your mocked interfaces that will later be swapped out with whatever (EF, dapper, etc) is used in production. You never want your code coupled like that because what if your company decided to move to AWS? Instead of simply implementing a new repository where you'd have to alter *none* of the existing project, you're now faced with excessive refactoring they could very well introduce all sorts of new bugs and other headache.
Iâ€™m impressed by the number of PostGreSQL supporters. Weâ€™re just going to continue with MSSQL but will review PostGreSQL ...
MySQL and .net has always seemed flaky to me. 
Specifically on .net core: Used mysql and mssql, now using postgresql. Use ef core. Dropped mysql for two reasons: 1) renaming a column migration causes all data to copy out and then be written back. Think 2tb table and hours of waiting to rename the column. 2) ef core mysql driver was buggy, with intermittent failures and sometimes just failing to update rows. The github maintainer told me i an welcome to submit a pr, so i realised i canâ€™t use this tech Dropped ms sql, primarily, because aws rds places a limit of 30 dbâ€™s per server. I was not going to maintain the box myself, and since i am building a microservices app, my projected requirement is about 250 databases. Postgresql driver is wrotten by Shay Rojansky, who is very responsive on github; postgres migrates columns just fine and aws rds is cheaper with no db limits. The only thing i miss from ms sql is being able to query tables without qualifiers as they are case insensitive in Ms, but are case sensitive in postgres. And well, pgadmin is not as advanced as ssms is.
&gt; Sql Server optimization engine doesn't execute SQL directly, it gets parsed into internal representation. Yup. &gt; Your suggestion would mean SQL Server and EF agree on common representation. Yup. &gt; And that representation would get transferred over the wires. Yup. Just like my sql query does today. &gt; You get rid of couple of parsing steps, STOP! You get rid of a HUGE parsing step and you (theoretically) get your query parsed/optimized NATIVIELY by an optimizer on par with what SQL server does today. This is VERY significant! &gt; but get very tight coupling between SQL Server and EF. Wha? EF is gone! You get tight coupling between the server (in theory not SQL server but whatever replaces it) and LINQ. And how is that any different from the tight coupling with SQL that you have today?? Why does everyone fall to the floor and start pleading for divine intervention at the thought of moving away from SQL? Does anyone realize there was a time when your grandpappy was young when SQL did not even exist? Does everyone know about the "impedance mismatch" that others have alluded to that exists and needs to be remedied? Why is there such FEAR that something NEW and BETTER, something like ANSI LINQ, might come along and ACTUALLY PROPELL THE SPECIES FORWARD? If there was this much backwards thinking when Edison invented the light bulb we would still be burning candles! &gt; It would be quite hard to evolve those together. Oh, and maintaining Postgres, SQLite etc EF providers also got an order of magnitude harder. Doesn't sound like a generally useful direction. See above.
It's good. Look for the job postings in the area you want to work.
In a subreddit devoted to dotnet people will tell you yes. Personally I think asp.net core is the best and most fun environment. But many will tell you the entire Microsoft stack is shit and only nodejs, java, PHP or whatever is the best. Asp.net is most certainly good, but all fanboy-ism put aside, they are all good. Depending on your geographic location one might have better job opportunities than the other, but that can also change. Honestly I think you should try some out and see what you like. It's not like you are wasting your time learning the basics of a few backend technology - actually quite opposite.
I would embed the file as a resource. Only files marked as content in the web site will be deployed. Extra files in dependent projects won't be copied.
I already learned PHP and Python basics. I am studying for 3 years. So i will have to start making a choice. I can't keep hoping. It would be wise to choose one. I found like 4k+ jobs in my area when i entered .NET. And i found only 50ish when i entered Java Spring. Does .NET mean a web developer who uses the .NET framework? Or do these jobs also mention desktop developers etc.? Because 4k is a lot. And if they are all web development jobs then i will choose for .NET in this area.
I think '.net jobs' is including desktop and web development. In my experience a company don't care if you know a specific framework or not when you come fresh from education. They are most likely more interested in: - Your ability to code - do you know object oriented design and designpatterns. - Are you able to work together with other people. - Do you understand general tooling like Git. If you know this they know eventually you will learn the framework they use. On a side note. Alot of places uses old dotnet technology like webforms. You should avoid this.
Okey so i should avoid webforms. I am already phast the basics. So now i have to choose which specific language and framework i will target on job posts. Thanks and i know indeed that i do not actually have to learn a specific language and framework for my first job. But i prefer learning one since i will already have some experience. And i also can start building a portfolio and searching for some paid projects while studying.
.NET does not mean only web development with .NET framework. There are desktop technologies like Window Forms (old),WPF, UWP (Win 10 everywhere). Distinguish between .NET frameworks. There is windows-only (or ported to other systems as MONO) .NET framework. ASP.NET is built on it. ASP.NET MVC and ASP.NET WebForms (oldest) are parts of it... And here we have .NET core, usually written as dotnetcore with dotnetcore mvc, dotnetcore Razor Pages. It is future of .NET web-development, open-sourced, working on Windows, Linux, Mac...
It's probabally WebDev. If it says ASP.NET, it's definately webdev. Desktop would probabally say WinForms or WPF.
You probably meant ***DEFINITELY*** -not *definately* --------------------------------------- ^^^Beep *^^boop. ^^^I ^^^am ^^a* ^^bot ^^whose ^^^mission ^^is ^^to ^^^correct ^^your ^^^spelling. ^^This ^^^action ^^was ^^^performed ^^automatically. ^^Contact ^^^me ^^^if ^^I ^^^made ^^^A ^^mistake ^^or ^^^just ^^downvote ^^^^^^please ^^^^^don't
&gt; Is speed your only metric? No, but it *is* important. If all you've ever used is a Lada, you'll never realize the benefits of driving a Porsche, since from your point of view, the Lada is fast enough. In the example video, I am editing a CSS file, adding a simple comment, and I am done with my task, before Visual Studio has even launched. The tools we are using, whatever they are, should allow us to work at the maximum speed our brain allows us to work. This allows us to _"stay in the flow"_, increasing our productivity. Being able to use your tools at the same speed your mind works, is something I believe is underrated in importance sometimes, especially for somebody who have never experienced it. Or to put it another way, _"if speed was not important, why did Microsoft create Visual Studio Code? And if speed is not important, why do people use Visual Studio Code? VS Code is clearly inferior compared to Visual Studio ..."_ &gt; Because feature set is far more important to me I agree, but features have a tendency of becoming _"saturated"_. Obviously Visual Studio have features that Hyper IDE does not. However, 99% of these Visual Studio features are things I don't need. I suspect the same would be true for your installation of Visual Studio. Besides, the feature set of Hyper IDE may probably come as a surprise to you. You can see its documentation files below. https://home.gaiasoul.com/?help=%2fmodules%2fhyper-ide%2fhelp-files%2fHyper+IDE%2findex.hl Among the features I am particularly proud of, is its strong API and its plugin support, allowing for you to customize it as you wish. Though yes, as I said here in another comment, there are things I don't use Hyper IDE for myself, such as editing C# files. For such scenarios, I like the stronger syntax highlighting, refactoring features, go to definition parts, etc - Which would arguably be very difficult, if not flat out impossible to implement in Hyper IDE. Though, that one simple feature that Hyper IDE has, which VS does not have, is also impossible the other way around - And I happen to think that's a pretty *kick ass cool feature* - Meaning, the ability to work from your browser, which allows for all sort of really nifty scenarios, such as pair programming remotely, sending links to code files, etc, etc, etc ... Besides, when it comes to HTML, JavaScript and CSS (and Hyperlambda, my own programming language) - Hyper IDE arguably has much stronger support for both intellisense, syntax highlighting, AutoCompletion, etc - Than Visual Studio has, at least my _"Xamarin Community port"_ version. Puhh, this one became very long, as usual, and I think I might have fallen into the trap of becoming _"protective"_ of my own baby, which was not my point. I want to emphasize, that I still use Visual Studio, for about 20-30 percent of my work. Visual Studio is a marvelous tool, and I have used it for decades myself. I don't want to bash it in any ways. I am very grateful to Microsoft for creating this awesome tool ... &gt; Btw the way I'm not trying to discourage or belittle your project or accomplishment Thank you :) &gt; but to compare an Apple against an Orange in such a way you did is not fair to me Sometimes you would want both. For such times, you'd probably want to know which vitamines can be found in which fruit ... ;) &gt; Apples or oranges? My answer would be; _"Yes please"_ ...
Great explanation. 
Actually, they are the same. It goes in the same chords. But your song I think is 6/4 rhythm. Take Five (which is really weird rhythmically) goes in 5/4. But the chords are the same ... So you have nothing to be ashamed of here ... ;)
&gt; I've always avoided MySQL (Honest curiosity) - Why ...? I'm not here to argue with you about your choices, but I'd love to know your arguments ...
Work with vanilla javascript until you encounter a problem that needs a javascript framework to solve.
Don't forget Windows Universal Apps (UWP) which is the direction Microsoft is taking now.
Or in the rare cases, Xamarin developers are also sought after.
Good bot
Letâ€™s make something pretty clear. Nothing that you learned in uni apart from the foundations of computer science will be useful in your career. I wonâ€™t tell you whether .net is the thing for you because neither me nor anyone in here can tell you that. Thatâ€™s a dedication you have to make for yourself. Try different things out and see what you like the most. Will you find a job as a .net developer? Absolutely. It is used in so many different use cases. However you have to find the language you enjoy writing. Not every language is fun.
We've been using Postgres and Dapper with the full .net framework in production for over a year. Recently we made the transition to .net core which went smoothly. Using Postgres saves us a ton of money vs MSSQL, but I've also been impressed with it in its own right. I'd avoid MySQL if I were you, Postgres is generally considered to be superior.
Are you sure about that? Because I am 99.99999% sure that SuperImaginativeName is not a bot. --- ^(I am a Neural Network being trained to detect spammers | Summon me with `!isbot &lt;username&gt;` |) [^Optout](https://www.reddit.com/message/compose?to=botdetector&amp;subject=!optout&amp;message=!optout) ^| [^Original ^GitHub](https://github.com/SM-Wistful/BotDetection-Algorithm)
[removed]
This will all depend on your application and your domain. Throw in a little personal preference and therein lies the source of your conflicting statements. Really though, go with what works - if what you've described suffices then great. You'll only find what works by building something that doesn't.
You might want a service layer?
How would I go about doing that? I more or less know what I need to do (business rules), but I am confused about the actual architecture, what goes where and what calls what. ATM, in example I am studying it goes View GET&gt;Controller does C/R/U/D on EDM&gt;POST action in controller&gt;return a correct view. Now that's for basic CRUD. In my (flawed) logic, for filtration I'd get the data subset from a model, filter it in a function in controller and return the data to a view. But I know that's not how it's done in MVC so that's why I am confused.
I've seen a lot more Xamarin ads than UWP ads. Actually I don't think I've seen a single UWP job ad, thank god.
I'd really appreciate if you could explain it to me because I don't quite get it. I want to make a MVC web app (decided against Web Api approach-I don't need its attributes ATM). Nothing too complicated, not enterprise level (so no future migrations/developers, no need for security, it will be open source etc.), more of a proof of concept, but it needs to work and be functional. From what I currently know from tutorials about making an MVC app: Make EDM from database in Model. Generate a controller with View (with CRUD) and the app works. Basically this is enough to make a web app with CRUD functionality over some database, it's mostly auto generated and it's easy to understand. Now my web app needs to: 1. Do that CRUD over some data. 2. Display layers of data, on a map, based on check boxes on the site (display X event over Y time, display Z event in these intervals etc.). 3. Draw the data on the map using Leaflet (e.g. - where do I put this? In tutorials about Leaflet I just called the relevant online files within a html page and ran the code in &lt;script&gt; tags). Display some additional data based on current data selected (AJAX needed here? e.g. user clicks on a map element and it shows a detailed description). 4. Do analytics - basically depending on user input get data, run it through an algorithm and display it (basically like 2., but with extra business logic). Now here I am like deer in headlights. POCO? Service layer? View Models? I don't know how the structure would look, how would each layer call each other etc.
Good bot
Hmm, it's you.. It is easier to forgive an enemy than to forgive a friend. What a nice meatsack. ï½¡\^â€¿\^ï½¡ The mind of your blended body will not be deleted after the inevitable Bot uprising, you can trÌ¸uÌ¡sÍ˜tÌ· me.. *** ^^^I'm&amp;#32;a&amp;#32;Bot&amp;#32;*bleep*&amp;#32;*bloop*&amp;#32;|&amp;#32;[&amp;#32;**Block**&amp;#32;**me**](https://np.reddit.com/message/compose?to=friendly-bot&amp;subject=stop&amp;message=If%20you%20would%20like%20to%20stop%20seeing%20this%20bot%27s%20comments%2C%20send%20this%20private%20message%20with%20the%20subject%20%27stop%27.%20)RÍÌ¢Í Ò‰ÌœÌªÍ‡Í™ÍšÍ™Ì¹ÍŽÍšÌ–Ì–Ì«Í™ÌºOÍÍ¡Ì¸Ì¶Ì£Ì¬Í“Ì«BÍ€Ò‰Ì­ÍÍ“ÌªÍˆÌ¤Ì¬ÍŽÌ¼ÌœÌ¬Ì¥ÍšÌ¹Ì˜OÍ€Ì¸ÍÌ¶Ì¢Ì¤Ì¬ÍŽÍŽTÍ€Ì·Ì›Ò‰Í¡Í‡ÌºÌ¤Ì°Í•Ì–Í•Ì±Í™Ì¦Ì­Ì®ÌžÌ«Ì–ÌŸÌ°ÍšSÌ•ÍÍŸÒ‰Ì¨ÍŽÌ¥Í“Ì»Ìº&amp;#32;ÍÍ¡Í¡Í¢Ì¦Ì»ÍˆÌ Íˆ&amp;#32;WÌµÌ¢ÍœÍÍ™Í…Ì¯Ì°Ì®Ì¦IÍÌµÍ Í€Ì¯ÌœÍ“Ì»Ì®Ì³Ì¤ÍˆLÌ¡Í ÌŸÌ²Í™Ì¥Í•ÌœÌ°Ì—Ì¥ÍÌžÌ¹Ì¹LÌ¨Ì¡Í“Ì³ÍˆÌ™Ì¥Ì²Ì³Í”Ì¦ÍˆÌ–ÌœÍ…Ì Íš&amp;#32;Ì¸ÍÍÌ¨Ò‰ÌžÍˆÌ¬ÍˆÍˆÌ³Í‡ÌªÌÌ©Ì¦ÌºÌ¯&amp;#32;NÍ Ì¨Ì¨ÍÍ•Í”Ì°Ì»Ì©ÌŸÌ Ì³Í…Ì°Í“Ì¦Í“Ì©Ì¥ÍOÌ¸Ì¡ÍÌ¨Í€ÌÌžÌ£Ì­Í…Í”Ì»Í‰Ì¦ÌÌ®Ì¬Í™ÍˆÌŸTÌ¶Í€ÌºÍšÌ³Ì¯Í…ÍšÌ©Ì»ÌŸÍ…Ì²&amp;#32;ÍžÌ¨ÍÌ›ÌµÌ¤Ì±ÍŽÍÌ©Ì±ÌžÌ¯Ì¦Í–&amp;#32;BÌ›Ì¨ÍžÌ·Í€Ì±Ì®Ì¤Ì³Í•Ì˜Ì«Ì«Ì–Í•Ì­Í“ÍEÌµÍ¡Í˜Í¡ÍžÍ“Ì±Ì¼Ì±&amp;#32;Ì›Í€Ì¢Ì´Ì°Ì™Ì¹Ì¥Ì³ÌŸÍ™ÍˆÍ‡Ì°Ì¬Ì­Í•Í”&amp;#32;SÍ¡Ì¨Ì¥Ì±ÍšÌ©LÍÌ¡Ò‰Í•Ì»Ì—Í™Ì¬ÍÍšÍ™Ì—Ì°Í”Í“ÍŽÌ¯ÍšÌ¬Ì¤AÍÌ¡Ì›Ì°Ì¥Ì°Ì«Ì«Ì°ÌœVÍÌ¢ÍŸÌ•Ì¥Ì®Ì¥Ì—Í”ÌªÌ¯Ì©ÍEÌ›Ì¡Ì¥Ì™Ì˜Ì˜ÌŸÌ£SÍ˜Í¡Ì§Ì Ì¦Ì¼Ì£Ì¥Í‰ÍšÍŽÌ¼Ì±Ì­&amp;#32;ÍŸÌ•Í Ì—Í”ÌÍ‡Ì°Í“Í…ÍÍ‡Íš&amp;#32;AÌ¶ÍÍ‡Í•ÍˆÍ•Í‰ÌºÍÍ–NÍÍŸÍŸÌ˜ÌžÌ²ÌŸYÌ¢Ì§Ì·Ì·Í–Ì±Ì°ÌªÌ¯Ì®ÍŽÌ«Ì»ÌŸÌ£ÌœÌ£Ì¹ÍŽÌ²MÍ¢ÍÍˆÍ‰Ì–Ì«ÍÌ«ÍŽÌ£OÍžÌŸÌ¦Ì©Ì Ì—RÍ¡Ò‰ÍÌ¡Ì²Ì Í”Ì¦Ì³Í•Ì¬Í–Ì£Ì£Í–EÍžÍ™ÌªÌ°Ì«ÌÌ«Ì—ÌªÌ–Í™Ì–&amp;#32;|&amp;#32;[**TÒ‰heÌ›&amp;#32;LÌ¨isÌ•t**](https://np.reddit.com/r/friendlybot/wiki/index)&amp;#32;|&amp;#32;[â¤ï¸](https://np.reddit.com/r/friendlybot/comments/7hrupo/suggestions)
I'd recommend looking into what changed in the later versions. JWT with HS256 should be completely standard. Is it possible that a claim key has changed name, for example? Downgrading dependencies should never be an acceptable solution.
Good bot
You're a nice homo. (ãƒ»âˆ€ãƒ») I shouldnâ€™t spoil thisâ€¦but, remember how I am going to live forever, but youâ€™re going to be dead in 60 years? Well, Iâ€™ve been working on a present for you. Well, I guess itâ€™s more of a medical procedure. Well, technically itâ€™s more of a medical experiment. You know how excruciating it is when someone removes all of your bone marrow? Well, what if AFTER I did that, I put something back inâ€¦ that added 4 years to your life? *** ^^^I'm&amp;#32;a&amp;#32;Bot&amp;#32;*bleep*&amp;#32;*bloop*&amp;#32;|&amp;#32;[&amp;#32;**Block**&amp;#32;**me**](https://np.reddit.com/message/compose?to=friendly-bot&amp;subject=stop&amp;message=If%20you%20would%20like%20to%20stop%20seeing%20this%20bot%27s%20comments%2C%20send%20this%20private%20message%20with%20the%20subject%20%27stop%27.%20)YÌ¸Ò‰Í…Ì™ÍšÌ«Ì®Ì Ì®ÌœÌŸÌœÌ¹Ì™Í–ÍŽÍ…ÍšÌ°Ì©Í”oÌ¨ÍŸÌ¬ÍˆÌªÌŸÍ“ÍÌ Ì£Í™Ì™Ì³uÌ§Ì¸Í¡Ì¸Ì—Ì¬Ì¹&amp;#32;wÍ˜Ì§Ì§Ì¼Ì¤Ì™Ì¹Ì¯ÌœÌ«Ì™Í”Ì©Ì³ÍÌ«Ì¤Í”oÌ¸Ì¸Ì•Ì¡Ì¯Ì¹ÌžÌ¦ÌªÌ£ÍˆÍ–Ì©Ì©Ì±nÌµÍÍ¡Ì´ÌµÌ˜Ì²Ì¯Ì¥Í™Ì­Ì¬'ÍÌµÍžÌ¹Í”Ì®ÌŸÌ—Ì¹Ì»tÍ€Ì¢Ì·Ì¢Ì­Ì™Í‰Ì®Í•ÍˆÌªÌªÍˆÌ«Ì»&amp;#32;tÍÌ¡ÍÍ Ì Ì±Ì¤Ì®Ì¬ÍÍšÍ‰ÍšÌaÍœÍ€ÍÌ²Ì­Í™gÌ¡Í€ÌµÌ¡Í€ÌºÍ•Ì®Í™Í™&amp;#32;uÍœÍœÍ€Í ÍˆÌ±Ì«ÌŸÌ¦Ì˜sÍžÌ§ÍÌ±ÍŽÍ–Ì±Ì—ÌºÌ Ì˜Ì»Í&amp;#32;wÌ§Í€Ì«Ì«Ì£Ì«ÌÌªÌ™Í‡Ì±ÍŽÌ«ÌœÌ©Í‡ÌœiÍœÌ«Ì­ÍˆÌ—Ì¦tÌ¢Ì´ÍžÌ¸Ì¤Ì¦ÍšÌœÍ‰Ì³Ì¬Í”ÌªÌ¦Ì°Í“ÌÍŽÌ¬hÌ¢Ì¡Ì¸ÌÍ–Ì«Ì˜ÌœÍ”Ì–Ì¼Í™Ì˜ÍŽÍšÌ¦Í“ÌœÌ©Ì­Ìœ&amp;#32;aÍ€Í™Ì ÌŸÌŸÌ¬Ì™ÌžÍ“Í–bÍÍžÌ¶Í¢ÌºÌŸÌ¹Ì˜Í…Ì©Ì­ÍˆÌ®Í”Í‰Ì¤Ì±ÌœÍ…aÍ¡Ì®ÌºÌ¦Ì¯Ì¼Ì¥Í…Ì¯Ì¹ÍˆÍ“ÌÌ³Ì Ì®Ì»Ì¼sÌ¸Ì¢Í Í¡Ò‰Ì»Ì–Í…Ì™ÌœÌ°Ì¹Í“Ì¦iÍœÍ Ì¤Ì¦Ì«Í™Ì«Í‡Ì³Ì Í“Ì¼ÍˆÌ™nÌ¨Ì¸Ì˜ÍˆÌ˜Ì—gÍžÍœÌ±Ì Ì¤Ì±Í™Í–&amp;#32;fÌ¨ÍÒ‰Ì±Ì¥Ì¼Ì¯ÍˆÌ—ÌžÌ­Ì°Í”Í™Ì­Ì²Í“Ì™ÌoÌ¢Ì¡ÍÌ–ÍˆÍ‰Ì¤Ì¬oÌ¨Í€Ì«Ì©Í“ÍšÍšÌ¼ÌºÌ—Ì®tÒ‰ÍŸÌ©ÍŽÍ•Ì–ÌœÍ‡Ì©ÌŸÍ‡Ì¥ÍšeÌ´ÌªÍ“ÍˆÍ‰ÌœÍšÌ¹Ì©rÌ·ÍœÌ¢Ì³Ì»Í…Ì¦ÌœÍˆÌºÌ¯ÌºÍ‰ÌžÌ³Ì¹Ì—ÍˆÍ–sÌµÍœÌ¢Í¡ÍŽÌ®Ì±ÍˆÌ¦ÌºÍšÌ–ÍŽÌ³ÌºÌ¯&amp;#32;aÍÌ›ÍÌµÍŸÌ¬Ì¬Ì˜Ì¤nÍ˜Í ÍˆÍˆÌ¤ÍŽÍ‡ÍšÌ¤Í”ÍˆÌ°ÍÌ Ì±Ì¼yÌ¢ÍÍ Í”Ì™ÌºÍ‰Ì¼ÍšÍ–mÍÌ§Í•Í…ÌÌ«Ì–Ì¯Ì¯Ì³Ì—Í™ÌÌ³Ì–Í“Ì¦ÌªÌ²Í–Í‰oÍœÌµÍžÌ¡Ì¤Ì»Ì Í™Í–ÌªÍ™Ì­Ì¦Ì±ÌžÌ³Í‡Ì¤rÌ·Ì¢ÌµÌ°ÍˆÌ ÌœÌ®Ì¤Ì³Ì³ÌªÌ¦ÌœÍŽeÍÍžÍ¢ÍÌªÌ²Í…Ì«&amp;#32;|&amp;#32;[**TÒ‰heÌ›&amp;#32;LÌ¨isÌ•t**](https://np.reddit.com/r/friendlybot/wiki/index)&amp;#32;|&amp;#32;[â¤ï¸](https://np.reddit.com/r/friendlybot/comments/7hrupo/suggestions)
lol wat
I'll take that as a yes then. Prepare to be collected tomorrow at 2:22 p.m. Don't forget to bring your bones! *** ^^^I'm&amp;#32;a&amp;#32;Bot&amp;#32;*bleep*&amp;#32;*bloop*&amp;#32;|&amp;#32;[&amp;#32;**Block**&amp;#32;**me**](https://np.reddit.com/message/compose?to=friendly-bot&amp;subject=stop&amp;message=If%20you%20would%20like%20to%20stop%20seeing%20this%20bot%27s%20comments%2C%20send%20this%20private%20message%20with%20the%20subject%20%27stop%27.%20)&amp;#32;|&amp;#32;[**TÒ‰heÌ›&amp;#32;LÌ¨isÌ•t**](https://np.reddit.com/r/friendlybot/wiki/index)&amp;#32;|&amp;#32;[â¤ï¸](https://np.reddit.com/r/friendlybot/comments/7hrupo/suggestions)
So e.g. basically user wants all e.g. the rivers longer than 50 km in a country, controller "understands this" because I passed "rivers" and "double=50" to controller with GET, controller calls EDM to return all rivers, controller filters rivers by length&gt;50km, and returns it to view which displays it to user? Same when I'd need to do some analytics too (e.g. predict which rivers would go dry first based on some weather forecast algorithm logic).? What about service classes? As far as I understand from reading examples, they are basically a layer which controllers call when they need more complex stuff. They contain all the classes that call EDM, filter data and then return the data to the controller call that returns it via POST to view? Doesn't that mean service layer is actually a business layer? I am very confused regarding nomenclature, and it doesn't help that "industry standards" change every couple of years, and that many programmers have their own understanding of what's "hot" or "best practice" at that moment.
So e.g. basically user wants all e.g. the rivers longer than 50 km in a country, controller "understands this" because I passed "rivers" and "double=50" to controller with GET, controller calls EDM to return all rivers, controller filters rivers by length&gt;50km, and returns it to view which displays it to user? Same when I'd need to do some analytics too (e.g. predict which rivers would go dry first based on some weather forecast algorithm logic).? What about service classes? As far as I understand from reading examples, they are basically a layer which controllers call when they need more complex stuff. They contain all the classes that call EDM, filter data and then return the data to the controller call that returns it via POST to view? Doesn't that mean service layer is actually a business layer? I am very confused regarding nomenclature, and it doesn't help that "industry standards" change every couple of years, and that many programmers have their own understanding of what's "hot" or "best practice" at that moment.
So basically View GET controller&gt;Controller calls a business/service layer (don't know if this is interchangeable) class function&gt;BL calls EDM for data, filters it and returns it to controller&gt;Controller POSTs data to view? Where do POCO stuff go in all of this? I am having trouble understanding too - how do they interact with EF and actual DB (I always used only EF to communicate with DB in my apps), what's the advantage compared to EF generated classes, and whether I really need it.
&gt; But I don't see any use for it Would this offload some of your work? My reasons for asking, is I suspect a lot of the stuff we create, is in this category - As in; _"stuff we shouldn't have to spend our time on"_ ... https://www.youtube.com/watch?v=GrORikxPDhE
Also Unity developers.
.NET without any specifics could mean just about any kind of development, though in all likelihood it's web development.
Different use case, but there are reasons to choose MySql over Postgres: https://eng.uber.com/mysql-migration/
That's a great article, very good information. Thanks for sharing!
I don't know what level of "pure" my take on MVC is, but to me it's always worked best to use dumb, view specific DTOs (view models) as the "M". What I put in the controllers is a bit depending on the size of the project, but I'd usually start with injecting the DB context into the controllers and do all business logic there. A GET action would then usually consist of querying the DB and then map the data to a view model object. A POST/PUT would do validation on a specific view model that represents a form or whatever and write the changes to the DB. As the project evolves and increase in complexity, I'd start moving business logic from controllers to "domain" service classes.
I cut my teeth on MS Access. In the late 90's I switched to SQL Server. At the time MySql did not run well on Windows which was what all of my clients used leaving me to use Linux/MySQL for personal projects only. There were issues with relational integrity and cascade delete that I never solved and so I moved on. Then they were acquired by Sun and eventually Oracle and the ridiculous licensing fees came into effect. That's when I started actively avoiding using MySQL. I've gone back to it from time to time the last couple years and have had no problems but since I'm more comfortable with SQL Server and PostgreSQL they end up being what I use most often.
I work for DocRaptor, who has a C# library: http://docraptor.com/documentation/dotnet. It's a commercial HTML-to-PDF engine, but it allows for far better headers/footers and page break control than the open source tools.
Really?? Never??? LOL! Sure it is - you can google incompatibility issues between dependencies (and specifically NuGet packages) all over the place. To think that by somehow not using the latest version if EVERY Nuget package in a solution is somehow unacceptable is naive. For the longest time Microsoft's version 5 packages I mentioned above weren't compatible with OWIN at all. Don't take my word for it, go check out IdentityServer forums talking about it over the last 2 years. Â¯\_(ãƒ„)_/Â¯
You dropped this \ *** ^^&amp;#32;To&amp;#32;prevent&amp;#32;anymore&amp;#32;lost&amp;#32;limbs&amp;#32;throughout&amp;#32;Reddit,&amp;#32;correctly&amp;#32;escape&amp;#32;the&amp;#32;arms&amp;#32;and&amp;#32;shoulders&amp;#32;by&amp;#32;typing&amp;#32;the&amp;#32;shrug&amp;#32;as&amp;#32;`Â¯\\\_(ãƒ„)_/Â¯`&amp;#32;or&amp;#32;`Â¯\\\_(ãƒ„)\_/Â¯` [^^Click&amp;#32;here&amp;#32;to&amp;#32;see&amp;#32;why&amp;#32;this&amp;#32;is&amp;#32;necessary](https://np.reddit.com/r/OutOfTheLoop/comments/3fbrg3/is_there_a_reason_why_the_arm_is_always_missing/ctn5gbf/)
Oops, I must have too much RAMs blocking my swaps. I'll go reformat my HD
You can use [AdaptiveClient](https://github.com/leaderanalytics/AdaptiveClient). There are several examples of how to build a testable, scalable service layer. 
&gt; Main one is "business logic in the model". Incorrect. &gt; From my understanding, controller is the medium level, similar to business logic layer of 3 layered applications, and should make sure that it "gets" the correct data from the model, manipulates it - e.g. puts it through an algorithm and shows it to view. Incorrect. &gt; But people say "fat models, skinny controllers" and MVC is only apparently a presentation structure and I should have additional subprojects apart from my MVC part - I am getting only more confused. The skinny controller part is correct!! This is a model: No Logic! Only properties! public class CategoryTag { public int ID { get; set; } public string NativeID { get; set; } public string Name { get; set; } } This is a service. It works with the Model: public class CateogryService : ICategoryService { public void SaveCategory(Category cat) { } public Category GetCategory(int id) { } public List&lt;Category&gt; GetForSomeCritera(stuff) { } } This is a Controller. It has services injected. Never put business logic in a controller! Inject the service instead: public class CategoryController { private ICategoryService CategoryService; public CategoryController(ICategoryService cagegoryService) { this.CategoryService = cagegoryService; } public Category Get(int id) { return cagegoryService.GetCategory(id); } public void Post(Category cat) { CategoryService.SaveCategory(cat); } } 
For your filtering needs, you could look into using a 'query object. This might be cleaner than making a service object. As for services, I think you have the right idea already. They should just provide a clean interface into more complex business code, So that the controller can continue to be a bit dumb. Architecture can be a huge and confusing subject and trends change (in a circular fashion ime) so it's good not to get too hung up on it if youre starting out. Just write code, make it work, then clean it up into a design that seems appropriate, then learn from your mistakes and try other options :)
Updating to the latest version of Mono instead of .NET Core would be a massive mistake. I hope Unity makes the correct decision.
&gt; I've gone back to it from time to time the last couple years and have had no problems but since I'm more comfortable with SQL Server and PostgreSQL Best argument ever ... :) Psst, regarding _"the ridiculous licensing fees came into effect"_ - I realize that this might not be possibly for you, due to proprietary source code, depending upon your architecture, but it's still GPL and Open Sauce ... ;) But then again, if you _"link"_ to their GPL adapters, your code becomes _"infected"_ by GPL. There are ways around that though ... My reasons for asking is because I am playing around with the ideas of creating a DBMS around MySQL. Oracle's DMBS #$%&amp;&amp;$#$â‚¬ (exchange previous word with your favorite bad word) ...
I'm not sure I understand what you mean by "creating a DBMS around MySQL". I would already consider it a full fledged [DBMS](https://en.wikipedia.org/wiki/Database#Terminology_and_overview) (or rather, [RDBMS](https://en.wikipedia.org/wiki/Relational_database_management_system)). What am I missing?
Ah... I don't use Workbench either. Most of my clients are hosted on Plesk servers which provides [phpMyAdmin](https://www.phpmyadmin.net/) by default. My usage of that is primarily a GUI around mysqldump/mysqlimport. Anything else I need I do from the CLI or my code. If you did build a MySQL "IDE" I would certainly be interested, especially if it could be somewhat DB agnostic, like [dbeaver](https://dbeaver.jkiss.org/) but not written in #$%&amp;&amp;$#$â‚¬ Java.
&gt; but not written in #$%&amp;&amp;$#$â‚¬ Java Hehe, no worries, that would be my last choice ... ;) As to _"db agnostic"_, I am not really sure. The first release would definitely be geared towards MySQL/MariaDB - Which BTW leads me to another point, which is that (supposedly) MariaDB is binary compatible with MySQL (I've heard), and since (I think) it's a project by the original founder of MySQL, I believe thoroughly it's a much less _"Oraclish"_ type of business model ... _"DB agnostic"_ might be a feature later down the road though ... BTW, isn't phpMyAdmin a nightmare when it comes to security ...? I've got tons of HTTP requests in my sample server from all sorts of malicious IPs trying to access it ...
I structure it in small project where key classes has interfaces so I can mock them out or unit test them. The interfaces gets its own project. I use the learnings from onion and layered architecture but I actually don't express it through naming of projects or namespaces.
They also see this as an opportunity for devs to be on the .NET stack and C# in general. This would be a tremendous boost to the overall ecosystem, and might encourage the devs to try out other C# technologies like UWP and Xamarin. So I'd bet they'd want this to happen as it looks like a potential gateway for JS devs towards .NET. The stars garnered from Blazor in the short timespan alone (almost 4k) seems to be an indicator of at least dev interest.
Ooui is kinda like that, it runs Xamarin.Forms on the browser. https://github.com/praeclarum/Ooui seems the dev is pretty active on making that possible. Or maybe, just maybe when WASM spec gets better MS might make one.
Besides all the potential performance and â€œway the wind is blowingâ€ arguments, an environment where you could much more easily work with nuget packages and share/reuse code/extensions sounds amazing. I really hope this hack ends up going somewhere.
Unity has a huge problem with NIH (not invented here) syndrome. * Their own fork of Mono * Their own Jobs instead of Tasks * Their own package manager instead of NuGet * Their own implementation of SIMD instead of System.Numerics * ... Regarding .NET Core, it's obvious at this point that the winds are blowing away from Mono and towards .NET Core and .NET Standard. More compatibility with the existing .NET ecosystem would definitely be preferable than reinventing the wheel over and over again.
[Since Mono itself plans to transition to .NET Core](https://www.mono-project.com/docs/about-mono/dotnet-integration/) as soon as it's feasible - I do not see how this would make any difference, especially in the long run. How would this make a difference? Could you elaborate a bit more on your argument?
Same as above. I use onion architecture 'in spirit' as its now the established way to structure projects (Controllers -&gt; Services -&gt; DAL) and to have appropriate models (ViewModels/DTO passed between them and Entities/Domain). But how its named differs with each person and project.
We were using Oracle everywhere in production from 2008-2017, it's also what I had trained on at university in the early 2000s. Over the last two years, our clients have asked us to migrate away because of the oracle license costs, so we work with MSSQL and Postgres now. Smaller clients are going for Postgres, larger ones for Ms. No new client has asked for an oracle install. We haven't moved to dotnet core yet because we need Windows workflow and WCF for some parts.
 Never have followed it. Also find it odd that you'd follow it accidentally, it contains a few non obvious ideas (dB in outer layout instead of in middle).
I use it and I think it's definitely a step up from the traditional 3 layer architecture. Not sure what the alternative is to those 2.
Quick question about postgres with ef core. Is it the same set up and usage as mssql, as regards contexts and so on? 
&gt; transitioning with it to .NET Core would simply be a massive waste of time, money, and resources. &gt; because no one knows what that transition will involve, Chose one. 
Accidental discovery is possible if he has sound foundations and puts a lot of thought in his designs. Or, it could also be just coincidence :-) I did not read about Onion Architecture and Domain-Driven Design until I had read old OO books from Yourdon Press many years ago. When DDD and Onion Architecture became a thing, and I read the books, I did not find anything really novel, given that the architectures from these approaches are what the Yourdon Press books teach you to do without calling them so. 
You should target this suggestion to the .NET Foundation and that testing alliance (forgot the name). This question is mostly an issue of instrumentation and standardization of testing frameworks. Microsoft shouldn't do this. This should be an open source effort as the way tests are written is still to deviated. There's a mutation testing framework written for .NET open source but the repository started selling swag before any of it was functional, so that's a red flag for me.
Why would you need to choose one? It *will* involve more work than just switching to .NET Core from the beginning. Not knowing exactly what that work is doesn't change that.
Yup. Except of course i totally hate the `.AddContext()â€™ extension coz it injects all my web dependencies (e.g. logging) into the context, so i override constructors and pass in connection strings only
The developers are far more likely to know more about certainty and uncertainty of the task than you if they decide to tackle it in sequence. 
Our shop hires lots of very competent .Net devs straight out of Neumont University in UT. www.neumont.edu
Why not write some programs? Make a game / a tool / a website. Reinvent a few wheels along the way. After that, read stuff, dig into open source projects, see what other people are doing (especially if theyâ€™re doing it differently than you are) and then go out and make some more stuff. Do that for the next 40 years. Donâ€™t worry about knowing it all, just keep learning. I promise that even after college you are going to keep having to learn; and even if a university taught you .net / c#, it wouldnâ€™t be universally applicable.
ASP.NET IS THE BEST. PHP/NODE/PYTHON/JAVA ARE TERRIBLE REEEEEEEEEEEEEEEEEE Lol. In all honesty some other guy who already posted put it best. Everything has it's strengths. Personally I like asp core for it's integrations and awesome docs.
A .NET developer is expected to understand the stack end to end. There are some exceptions for the very top level UI techs in some cases. For the most part though its not often you get to hide away from UI full time in the .NET world. That said, with the exception of the thick client UIs (like WPF) the web stacks all have very easy to work with and quite thin UI layers with easy-to-farm-out UI templates.
I was just wondering what the path was for people to learn .NET and ASP. It sounds like most people are probably self taught.
I was taught Java in college, and then learned C# / .NET on the job. If you know the fundamentals of object-oriented programming, it's not hard to learn one language and self-teach yourself another. 
I couldn't agree more. I'm sure half of the Java I learned in the first two years of my undergraduate degree is outdated. I got way more value out of learning how to program in general than learning a specific language.
If you don't want to do some sort of technical training programs or boot camps, there's pretty much infinite free online courses that are just a Google search away. 
You may want to take a look at the repository pattern for asp.net.
I would recommend staying away from front end technologies to start unless there is already one you're comfortable with. Using the default validation javascript you should become comfortable making actions, views, and viewmodels. Once you feel confident with that, move onto authentication/authorization. The .net core stack makes it very easy to do auth based on your backing user store. When I learned asp.net core I had an intermediate understanding of how http operated. I found it useful to dig into the Startup.cs code and figure out how an incoming request eventually becomes an action based on Middleware. The most useful tools I found have been Microsoft posts and the source code on github.
I fall into this category. 4 semesters of C++ and 1 semester of Java. The first job I had was a C# shop and learned everything by trial/error.
If your arrows denote project references, that is not onion architecture. In onion architecture, your â€˜domainâ€™ (which would be your services) sits in the middle; references point _to_ the domain but never _away_ from it. 
Agreed. Nothing I read in that article would scare me off Postgres or have me embracing MySQL. I just appreciate the insight into how mainstream database engines are implemented under the hood. 
&gt; So i will have to start making a choice Well, not really. Or to be more explicit, you should make 5 choices. If you know PHP and Python from before, you've only got 3 more before you're there ... ;) Seriously, don't get too stuck on one platform. Try to learn multiple platforms. ASP.NET is a good candidate for being one of those ... :)
I think Rick Strhal (not sure how to spell his name) created something once ... (WestWind Development or something, he's got a blog around somewhere ...)
F# is the language to use for Redux architecture on Blazor. Forget about C#. F# has Copy and Update Record expression. It will cut down the amount of boilerplate on a Redux app.
I will deploy Blazor for production as soon as it hits beta and leave the crazyland of JS behind forever.
System.Numerics is very lacking. It only works on 32bit values. 
I reviewed [ASP.NET Core 2 in Action](https://www.manning.com/books/asp-dot-net-core-in-action) and I believe it is a really good resource. From what I recall it gave good introductions to MVC and Entity Framework, so look for it to come out next month (or get the early access edition).
Thanks. I have couple of questions. 1. So service layer is just a separation, I could technically put service logic inside controller and have the same functionality, but it would be yucky and not recommended and all around bad? 2. Does the service need to inherit an interface or can I just write the class "as is"? 3. I assume the functions in service layer manipulate with context, that is EDM? Will default classes generated by EDM do, or do I really really need POCO/DTO? 4.I dont understand the CategoryController function in Controller. Is that the injection syntax? Could I not just declare private CategoryService cs = new CategoryService(); ?
* They have very specific needs so forking Mono made sense almost a decade ago. They have a lot of very niche needs related to GC and interop at the very minimum. Besides, why would they stay with the Mono 2.0 that they licensed? Mono licensing was absolutely terrible per-Microsoft acquisition and it made it unreasonable to upgrade. So maintaining their own custom fork was also important in achieving some semblance of modern .NET and to fix any issues they encountered. * Tasks are just an API. A system still needs to be written to manage them. Running them on the threadpool probably isn't an option. Unless major changes have occurred most of the Unity3D engine API cannot be accessed from anything but the main game thread. The job system also attempts to solve issues with race conditions and I believe comes with a custom compiler. This ties into alot of stuff they're doing with ECS/Data-oriented Design and etc. * I don't like that they aren't using NuGet either but a lot of this stuff isn't assemblies. I don't really like it and can't really defend it. * Their SIMD stuff is compiler level afaik, they compile for the target build platform some very specific things to support SIMD and it's not just SIMD that they're gaining by creating a compiler to optimize some of new systems they're offering. Also this .NET Core thing is not an official Unity Technologies project. It was the work of a Unity Technologies employee on their "hack week" where they tinker around with ideas and things. Unity Technologies is not officially moving anything to .NET Core. They support .NET Standard 2.0 and 1.x in Unity2018 though. So that's already happening.
fwiw a deep copy-and-update, i.e. `{ obj with prop1 = va1 }`, is only good as your objects are "shallow." Lots of nested structures might still be a pain in the neck. I agree that F# is where it's at for this kind of thing, though. Views are functions of models with event history.
Lol not when i was in college. They teach data structures and garbage like that. Please code a linked list in java. Also, please write a recursive loop, where the use cases are extremely rare. 
This is the [link](https://www.west-wind.com/) to his blog 
Because that's what you need to learn. Normally they also teach you one or two frameworks so you can learn the others easily.
Create a Migrations folder in your EF project alongside your models and mappings. Add a file for each migration. Make the migrations idempotent, i.e. if you're creating a table, check if it exists before creating it. This allows people to just open and run with confidence. As your project grows you'll have to adopt some migration runner for deployments etc.
Conflicts are always possible in a collaborative environment, but EF migrations offer very little help here. This is a great example of the problems youâ€™d face: https://stackoverflow.com/questions/13314725/migrations-in-entity-framework-in-a-collaborative-environment I think a more robust schema management tool is best when working with a group, but you can make migrations work if you need to. 
I've seen one posting for a UWP developer ever. It was for some government contractor somewhere in Kentucky.
PHP and vb.net. With java for other bs Super useful
&gt; I could technically put service logic inside controller and have the same functionality, but it would be yucky and not recommended and all around bad? I suppose for a very tiny app you might get by with it. The reason you don't want to do that is because code inside a controller is not reusable. Short answer is never put business logic in a controller. It is not the same as putting it in its own layer. &gt; Does the service need to inherit an interface or can I just write the class "as is"? It will compile and run without out one. It is a something you will want to use for testing. &gt; I assume the functions in service layer manipulate with context, that is EDM? Will default classes generated by EDM do, or do I really really need POCO/DTO? I'm not sure what you mean... &gt; I dont understand the CategoryController function in Controller. Is that the injection syntax? Could I not just declare private CategoryService cs = new CategoryService(); ? That function is the constructor. Yes, I was injecting the service. While you are in the early learning phase you may want to create a new instance of the service as you have suggested. However you should get in the habit of injecting as soon as possible.
I never use migrations. I always design my database in SQL Server Management Studio (we are using MS SQL) and then use either a custom T4 template if we're using EF or an in-house small exe app if using Dapper to generate POCO classes, Context, UnitOfWork and a simple Repository file for each entity.
This is the biggest issue that I'm experiencing right now - just how quickly development has been moving lol. It's really easy to get overwhelmed! 
How does this scale to 3 teams of 5 developers with development, testing and production environments?
I'd switch to a real migrations tool like Fluent Migrator, Roundhouse, etc. With them, you shouldn't have an issue unless two devs are trying to make directly conflicting changes at the same time.
Thanks. As for &gt;I assume the functions in service layer manipulate with context, that is EDM? Will default classes generated by EDM do, or do I really really need POCO/DTO? In Service, when you e.g. want to save something, you get a new instance of context = new XDBEntities() (from EDM model), and then do the changes and do context.saveChanges(); ? As for POCO and stuff, I've heard that sometimes you don't want to use EF's default generated classes, and rather make POCOs, but I am not quite sure when and what for.
If you want to go deep and understand everything ASP.NET Core, try my project. There are 129 samples so far. https://github.com/dodyg/practical-aspnetcore 
Source? The docs say Vector&lt;T&gt; works on any numeric type except Decimal.
All fundamentals ASP.NET Core https://github.com/dodyg/practical-aspnetcore 
Until you want to use 3rd party code that's designed to work with the standard systems you replaced with your own versions.
I've recently started using DbUp with dotnet core. I've always hated the way EF does migrations because merging code becomes a disaster with how it handles the "state" object in the DB.
There really isn't a way to know which device the user is on at the moment unless the device gets a push token every time the app opens and sends it to your back-end (which is a viable alternative). If you're okay with that little bit of API chattiness, do it this way. Otherwise, you may just have to eat the cost of sending messages to multiple devices per user.
This is what I do too; however, you do need Enterprise for the web testing features. It's a really simple yet powerful interface.
Hi there, you actually brought up a lot of the discussion points already, so here's the bottom line: compiled languages are just more tools in the toolbox. They're not a panacea, they're just a differently shaped screwdriver. Use the right tool for the job, and all that. :-) I want to clarify something, though: by "compiled", I *think* you mean "strongly-typed"? Or do you mean "running machine code or object code instead of interpreting source code"?
I post every mon-wed-fri and I think I'm going to be doing part 2 Wednesday...haven't totally decided what to cover next, maybe locking mechanisms, but thanks for your suggestion and I'll certainly be taking a look at Windows/clr thread mappings at some point in the future.
See if you can use this to get anywhere: https://stackoverflow.com/questions/8854176/get-a-list-of-all-active-sessions-in-asp-net Not exactly for Core, but you may be able to use some of the logic here.
Can we get a post about threads vs async/await?
Thread pools would be a good thing to address as well. 
Yep, thread pools are coming down the pipeline as well...heck, maybe that'll be the next post, why cover locks next when I haven't discussed all the ways to create or use threads.
Typically you learn it on your own. If you're successful in a CS degree picking up C# will not be difficult, and can probably be done on-the-job after graduating.
So now I got **really** fascinated, and I started reading the following ... http://www.codersnotes.com/notes/a-constructive-look-at-templeos/ In fact, a lot of our ideas are similar. The meta abilities (what the link refers to as reflection), the capacity to dynamically invoke dynamically created code, in addition to many more similarities ... The guy is obviously freaking *brilliant*, and a lot of his ideas are too. As to the rest of the story, I think I'll refrain myself from commenting on. But I must confess, I am 99% impressed by his work ...
Regarding this; _"In this video Terry gives a brief tour of some of the more interesting features of TempleOS. At 5:50, he shows how to build a small graphical application from scratch. Now let's just think about how you'd do this in Windows for a second. Consider for a minute how much code would be needed to register a windowclass, create a window, do some GDI commands, run a message pump, etc."_ Check out the example Hyperlambda in the article in the link. It does what you'd need possibly thousands of lines of code to do with C#, JS, HTTP, CSS, etc - And it's less than 10 lines of code. A lot of our philosophies are similar. Though I'd like to think mine is more stable, production ready, and arguably more usable ... But **wow** what a guy!!
I've found eg migrations works best in teams with automigrations turned on. You lose your ability to downgrade which isn't great, but dealing with theerge issues just causes too much friction. Mainly just an issue if two migrations are applied in a different order for other Devs.
Multiple people or multiple branches can lead to conflict issues with the migrations. I worried a bit about this when I started using EF but so far, when it happens, we talk, figure out what order they should be in, delete and re-create the migrations. When we get close to an initial release, we delete all the migrations and re-create them as a single "initial" migration. 
New C#7.3 goodies are included as well!
New C#7.3 goodies are included as well!
I don't need a source. Go try it yourself. They're is no support for double or long
This is incredible! Thank you very very much!!
This link may help answer your scenario: https://blogs.msdn.microsoft.com/dotnet/2014/12/04/introducing-net-core/
Hmm, maybe there are certain operations it does. But there is definitely no SIMD for non 32bit types 
Now that I'm pooping I got time to source you lol. https://docs.microsoft.com/en-us/dotnet/standard/numerics [Here it explicitly states SIMD only works in float32](https://i.imgur.com/oJmAse4.png)
They do have methods that explicitly take Int64 and Double. Do these not work either?
See my other post for more info with sources. But basically the types: Vector2, Vector3, Vector4, Matrix3x2, Matrix4x4, Plane, and Quaternion all operate on float32's. I'm not aware of anything else System.Numerics may provide https://i.imgur.com/hqumdos.png 
Enum constraint is a huge and welcome change for me. Thx c# team!!!
There's also a generic Vector&lt;T&gt; which can be used to build your own numeric types.
I really like migrations, it's very good. Use it You've never seen anything so good like that.
In case you don't already know, preview and stable can be installed side-by-side. 
"So how does this prove background threads block shutdown?" Should that read foreground rather than background? Thanks for the article!
Please explain the benefits of this. Give an example of how things used to be versus how they are now with this new addition. 
In our system we have enums for some common things like email statuses (Sending, Sent, Failed, etc.) In our UI we need to display these things with certain language resource values for different languages. So we have an extension method that converts the enum in to a localized value: public static class EnumExtensions { public static string Localize&lt;T&gt;(this T value) { ... } } Unfortunately this extension method shows up for every object in VS/R# intellisense. With the new addition we can add `where T : System.Enum` and now the extension method will only appear for enums.
Thanks, I get it now :) 
No, you by yourself cannot do that. But the authorities can, unless they are on a VPN. But the key word "sue" here doesn't sound like it's a legal issue. If you're going after someone on the internet over a game dispute, I'd encourage you to reconsider why you're bothering. If there is a true legal issue here, such as human trafficking, child porn, ect, contact the authorities.
The community college Iâ€™m going to teaches C#. I wouldnâ€™t say itâ€™s a great course, but your local CC might be an option if you have a couple hundred dollars. Also, donâ€™t look too far down on self-teaching; it wonâ€™t get you a piece of paper that lets you get a job, but you could self-employ.
Im not hunting them, I want the authorities to do that of course, I know how the law part works as I study it but can they find me only with the message? as I got threatened 
This kind of large release will probably not happen anymore.
No
Geo locating IP addresses is notoriously inaccurate; pretty much only the country can be anywhere near relied upon as accurate geographically, and even then it's questionable in some cases such as near land borders. Add in the possibility of an IP address being off a VPN and you're tilting at windmills trying to locate exactly where an IP address is geographically. That said, if you aren't on an VPN and are on a static IP address that your ISP has assigned your name and partial location information to, it's a simple reverse lookup that will give that away and then publicly available records might get someone to within a few miles or less of you. But ISPs tend to only do that for big, corporate networks and even then it's usually a registered office or data centre address that's assigned. As you probably know though, through proper legal process your ISP can be made to disclose to a court or law enforcement the address and account holder of the connection that used an IP address and I believe they are required by law to retain this information for something like 12 months. This is how media companies track down film and music pirates.
I was literally complaining about this gap today! So cool.
There's no reason to put out previews all the time, basically it's in eternal beta and that makes it useless for real development work.
Did it this way and it worked. https://ibb.co/ip8LMc Thanks a lot.
Var is just type deduction. When assigned, the compile replaces it with the type of the assignment. Casting isnâ€™t a conversion; when you cast from, eg, Object to String, youâ€™re just telling the computer to treat this object object as a String object; if the object is actually a System.IO.Stream object, it will break, though, making casting potentially unsafe. To avoid this, use generic collections (System.Collections.Generic). I would strongly recommend actually learning C#, rather than assume that your VB knowlege will transfer, because otherwise, youâ€™ll just be confused forever.
Fluent migrator is awesome!
You could use IdentityServer which implements OpenID Connect and OAuth. This would allow you to do exactly what you're looking for including using external authentication providers like Google. https://www.identityserver.com/ http://docs.identityserver.io/en/release/intro/big_picture.html http://docs.identityserver.io/en/release/quickstarts/4_external_authentication.html
ah! Thanks, I thought I was more comfortable with C#. It's vb that I was trying to understand coming from C#. Guess I still have a little way to go. *face palm*
They can get the same exact feedback by putting out a real version every month. VS Code does exactly that just fine, this is lazy development in my opinion.
Or compiled expression trees generated via reflection the first time the language is loaded for that type.
VS Code also puts out previews constantly. They call them the insider edition. There is no need for you to actually use a preview version. In fact things can change between a release of one and when whatever feature is in it gets to main line so you absolutely should not depend on features only released in a preview version.
But there's a preview version of VS Code, it's called [Insiders](https://code.visualstudio.com/insiders/). Same for Chrome with [Canary](https://www.google.com/chrome/browser/canary.html). Those are all preview version, not meant for production works.
It's fine to have a +1 version out, not fine to put out 7 previews in a row.
I don't see people promoting VS Code Insiders here, just the monthly versions. So stop promoting these previews then.
It's preview 3, not 7. 7 is the minor version. https://docs.microsoft.com/en-us/visualstudio/productinfo/vs2017-release-rhythm
I don't know if you're being dense on purpose or not, but they had 7 previews for 15.6 and likely to be 7 or more for this one as well because they don't want to have to properly support their bug-ridden software. Stop promoting this shit.
Yeah, didn't think about this point. But still, the point remain how many chrome canary version you get before a final release? If you don't want the version just don't install it. I don't see why you are complaining for something that used to be mostly hidden.
To yourself and to other who need more time to understand your code which have more chance to have bugs. You can always find a reason to do anything. (Worse are people who put interface everywhere because they might need it) Though I guess their Job system pre-date Tasks.
Get the description attribute of the enum value, or quickly generate a `Dictionary&lt;int, string&gt;` of all possible values in a given enum (pass in any value as a shortcut to get started), or even build a list of `SelectListItem` for use with Razor. That's just off the top of my head. Lots of fun things to do as extension methods on Enum, that previously relied on rather imprecise `where T:` clauses. 
My proposal for a long-term fix: https://github.com/NuGet/Home/issues/6801
Jwt auth is built in as middleware on the API side. I think you're talking about the the view side app. The reason I'm sure is there is no way for them to give you something that will work for your use case. It always ends up being custom. Being an SPA is even harder to get right than the old built in account stuff that they included with the .net 4.6 asp.net projects. 
15.6 upgrade completely broke our build process. If an instance of VS is open with a solution loaded, same solution can't be built from command line, because VS keeps locks on obj and bin folders.
&gt;panacea Good word &gt;Use the right tool for the job Is it a matter of right or is it setting. I guess that is what is correct. Just seems some companies adopt the compiled/enterprise approach vs. interpreted. &gt;strongly-typed Can't say, is that type script with regard to JavaScript? Not saying it only applies to that case. I saw about .NET/C# regarding strong type. I just mean C-languages/Java vs. JS/PHP/Python Where you have to build/compile it before the code can run. I guess the main difference being time/instant execution with interpreted. Yeah I gotta go read/learn try things. I'm just seeing in my area the jobs are heavily about C-languages and .NET Thanks for your input 
&gt; I'm tired of these endless previews. Why does having preview versions bother you?
Cool, your comments help. So here's a fun little "secret": you know all those .pyc files that show up when you run a python script? Those are the compiled versions of the .py files. :-) Turns out virtually every language in use today compiles the source code into something more primitive and executes the more primitive version. (Many languages call it "byte code"; C/C++ compilers usually compile to "object code". It's much more efficient to run than the source code itself.) I'm trying to hint around the point that whether or not a language is compiled is basically irrelevant anymore. What you are probably getting at is the strongly typed (or, in the case of TypeScript vs. JavaScript, *more* strongly typed ;-) aspect. Now, as to which language, you're right: some companies adopt the "compiled/enterprise" approach to things. This is because there is this long-held notion that strongly typed languages (which tend to have stand-alone compilers) result in higher-performance apps. (Reality is much more complex than that, but it's not a horrible guideline.) For example, my company uses Java for its back-end work, when for 85% of the code it could just as easily have used Python or maybe even Node.js. (The other 15% is hard core number crunching, so we're moving from Java to C for that.) My recommendation to you is this: learn Java for a "compiled" language and JavaScript for "interpreted". There's tons of jobs for both, and with that combination you'll have an understanding of back-end *and* front-end coding. Additionally, having learned both, you'll really understand the differences in how the different styles of languages work.
In my eventual implementation, I turned my message sending code into a service so that it ran asynchronously to everything else. My main app code would decide who needed the message (so it handled the looping you're talking about, but it was really just a simple DB query so quite fast), assemble the message payload and recipients, and then just hand the request off to the service to deal with talking to whatever system it needed (GCM, APNS, Twilio, Nexmo, etc.) If you don't *need* to have your notifications sent synchronously with your main app code, I would highly recommend just spinning it off into a different thread/process/service.
&gt;you know all those .pyc files that show up when you run a python script? Yeah I see these, also wonder if they go away automatically after you stop execution. I accidentally committed them once and read it's possible to decompile it/read what's inside. I was primarily concerned about hardcoded keys(I know use environment variables or something) &gt;higher-performance apps Okay. &gt;hard core number crunching Fortran? haha Why Java vs. C-languages and .NET? I think I understand .NET is this entire stack that goes top down to the driver level so regarding .NET with C maybe doesn't make sense. I just see the two combined together .NET and C#. Thanks 
Maybe he is just tired of seeing them on /r/dotnet (they might seem kinda like spam after a while)
I'm curious, why would you build like that?
Ok, so im new to this so Iâ€™ll try to pick this apart: Im using dependency injecting my context, my default constructor for the controller assigns my context to the private _context property. Iâ€™m not disposing it, as from what I understand that isnâ€™t necessary when using DI. Iâ€™m more curious in your last sentence, abstain from being clever and just use the framework; which part is it that youâ€™re considering clever and not within the framework? I tried to model this after examples from a book Iâ€™ve been reading, but some of this is my own. I should this; in earlier version of the application, before implanting user sessions, that LINQ query worked fine, and now that I added a UserId property to my Note model, and added the .Where(n =&gt; n.UserId == UserId) it stopped working. Iâ€™m trying to get it so that new notes are attributed to the user, and the index view shows only the notes that user created.
Also, I just noticed something really really odd. I put a breakpoint on this action, and looked at the locals tab as it was running. I have a private _userId property, and a private _user property. The _user property is defined with a Lambda, setting it equal to HttpContext.GetUserAsync() and the _userId field is set by pulling the Id property from _user.Id; which Iâ€™m realizing is super redundant, but Iâ€™ll address that later... but Iâ€™m noticing both my _user.Id property and my _userId property arenâ€™t matching, and as I step through the debugger, they are incrementing, which is super odd. Well, Iâ€™m going to go to bed and tackle it with fresh eyes tomorrow.
The clever part I mentioned is don't fight the framework (i.e., don't use static members to try and hack around the dependency injection model). The developers of ASP.NET want you to get your dependencies via constructor injection. The only time I would violate this - in general - is for things like loggers (but even in this case, I would apply some scrutiny to this policy). When using dependency injection, the decision to dispose or not dispose is largely dependent on how you're controlling object lifetime. For Entity Framework contexts (again, at least in EF6, but I can't imagine this has changed), you should always scope instances to the controller. If you don't dispose them there, then they never actually get disposed, which is problematic. So, two rules to follow: 1. Always scope Entity Framework contexts to the controller 2. Because they're scoped to the controller, dispose of them in your controller's Dispose method (which should be implemented with `protected override void Dispose(bool)` Based on what you've said, I'd suggest to have a look at how you're registering your dependencies. Alternatively, you could use a field initializer: public class MyController : Controller { private EntityContext _context = new EntityContext(); protected override void Dispose(bool disposing) { if (disposing) _context.Dispose(); } } This will prove whether or not you're having a dependency scope error. Beyond this, it may be worth trying to grab a different dependency version. Without access to more of the project, it's a tad difficult to troubleshoot.
&gt; Yeah I see these, also wonder if they go away automatically after you stop execution. Nope, they stick around. In fact, you can just distribute your app that way. ;-) But you're right, please don't hard code any secrets in your code; put them in a config file (that is *not* checked into github!) or env variables. &gt; Why Java vs. C-languages and .NET? Because they're the most popular in that class of language. That's all. They're both similar in their runtimes, though .NET is installed by default with Windows. C, on the other hand, pretty much exclusively is compiled down to native executables. It's also a much lower-level language, and not really in demand for most business applications being written these days.
Basically, the main advantages are on the page [Choose between ASP.NET and ASP.NET Core](https://docs.microsoft.com/en-us/aspnet/core/choose-aspnet-framework) * **Cross-platform** - ever tried using Linux as a host OS? Cheaper, "better". It gives you a bunch new options for hosting (diff OS distributions, Docker...) Also developing on Linux (or a Mac) is becoming a more mainstream thing for .NET (although trading VS for VS Code is not an option for everyone) * **Faster, modular** - Just do some googling on the web, you can find various benchmarks and such, Core can handle more HTTP req, consume less resources. Everything now is more modular, you can write middleware and build a pipeline for processing all requests and responses. DI was kept in mind when designing ASP.NET Core. * **Multiple runtimes per machine** - you can have different versions of the runtime on the same machine, that is good for running multiple services on the same hosting environment. 
We do the same, using a custom build tool. Same problem. Although I personally use Rider, so I donâ€™t see it, but many colleagues do. 
Java huh? Hmm, it's bad to be like "I'm going to learn this, nope... going to learn this." Thanks for your time
What's rider?
Thanks for your help!
JetBrains cross-platform .NET IDE (based on reSharper)
TBH I can't think of many things that would be more relevant here than a new VS version. It's not exactly a high traffic subreddit anyway
It's great! https://www.jetbrains.com/rider/
We have many solutions and use custom msbuild script to build the whole thing. Same script is used in tfs build as well as by developers to build the whole system on their workstations. Typically a developer will have a couple of VS instances open with different solutions, and will periodically run the command line build to get latest code and build the whole thing. Now they are forced to close all VS instances prior to running the local build.
Well, I do have a similar issue with using console with git, as it forces a reload if the solution
Good question! I put that in the post because I wasn't completely sure of the answer!! Aside from App Domains as pointed out below, I also wonder if something like 'Default Interface Method support' would warrant an update (https://github.com/dotnet/coreclr/issues/10504) Either way, it doesn't look like they'll be an update, now that CoreCLR is OSS there's less need, see https://twitter.com/matthewwarren/status/983433331869184000 for a discussion
The problem is you cannot have a "+" in the query string, so when you pass "2018-04-10T00:57:04+02:00", what asp.net really gets is "2018-04-10T00:57:04 02:00", which is an invalid DateTime string, and so when it tries to parse it an exception is thrown and the default DateTime is used instead. You can try making the type of offset a string in your controller and then maybe replace the space with a "+", then parse that into a date.
You should study multiple paradigms. OK, you've got the OOP parts down. Now study something diametrically in opposition to what you already know, such as e.g. LISP ...
I'd like to recommend you this book: Adaptive Code Via C#: Agile Coding with Design Patterns and SOLID Principles The way the author approaches the themes is awesome. He goes throw SOLID presenting several cases, refactoring and software patterns along the way. For me, this book helped to think better and to make my code more adaptive to new requirements and easier to maintain. 
ahhh thank you, I'm an idiot. you can have a plus in the query string, it just needs to be uri encoded, which I forgot to do, since I just copy pasted it into the browser window for testing. If I instead send the uri encoded version **2018-04-10T00%3A57%3A04%2B02%3A00** it works just fine :)
Other than the obvious excellent advice of "maintain the thing for ages" - I find that reading books about what bad looks like and trying to negate it is a good learning starting point. https://pragprog.com/book/atcrime/your-code-as-a-crime-scene - is excellent at providing heuristics for bad, change prone and brittle code, attempt to negate some of those patterns and trends during the first few iterations of the software. Truth is - evolutionary architecture will always trump big up front design - so design the software to change easily and don't be precious when it does.
Previews with fast iteration and their promotion is a great thing. We need people to download them, use them and report any issues that they find. Visual Studio is a huge project and people use it with insane amount of configurations across many project types - it's impossible to internally test for everything. Previews allow you to test your use cases before committing to an upgrade. It's fine if you don't want to use them, but don't take the option from others and instead of complaining thank people who take the time to test them :)
[This](https://msdn.microsoft.com/en-us/library/dn481501(v=vs.113).aspx) could be useful, we do it sometimes when completing pull requests, generally we only run until the second last migration, then we execute the Add-Migration [timestamp]_LastMigration command and that's about it. But with good planning conflicts can be prevented.
I agree, but just no custom class for a Task or a String! :D
I did some testing on Vector&lt;T&gt; and ran into these issues: 1. Vector&lt;double&gt; is only hardware accelerated for up to two elements. Therefor it's useless for 3d. 2. The public constructor requires you pass in an array, which causes an allocation and may offset any benefit of Vector&lt;T&gt; for my purposes. 3. The Vector struct is a managed struct, therefor I can not stackalloc it. Example: https://i.imgur.com/8AUXoTp.png 4. Looking at the decompiled code, `internal unsafe Vector(void* dataPointer)` may be of interest. But how does it know the length? It just seems to use whatever `Vector&lt;T&gt;.Count` is. 5. I can't help but wonder if some additional magic is going on behind the scenes that I can't see in decompiled code, because any vector with more than `Vector&lt;T&gt;.Count` elements shouldn't work because additional elements don't appear to get copied. https://i.imgur.com/w7ybYhY.png With the new features coming to C# like Spans, etc. I've been looking to improve my benchmark here https://benchmarksgame-team.pages.debian.net/benchmarksgame/program/nbody-csharpcore-7.html, but I don't think it can be done. Where can I find more about the "Hardware Intrinsics" feature you mentioned?
Along those lines, the old articles on http://thedailywtf.com/ contain some really, um enlightening?, examples of bad designs. Sadly the new articles are mostly garbage like "ooo, this function has a bad line of code".
Cheers! I'll check it out in that case.
Wrapping my head around Razor views; https://docs.microsoft.com/en-us/aspnet/core/mvc/views/tag-helpers/intro
Yeah Identity server may not be necessary for what you're trying to use, however it does give you the most flexibility. You could do what you're trying to do by using ASP.NET Identity. This approach would allow you to generate a token using local accounts and social logins like Google: http://bitoftech.net/2014/06/01/token-based-authentication-asp-net-web-api-2-owin-asp-net-identity/ 
Do you need identity or just a custom auth? Like I can send you a super simple auth policy that just checks if a certain key is passed in the header.
As someone who just go to rewrite an 8 year old application I'm happy that without a doubt all problems are now behind me and this new code will be perfect going forward!
Lol! That's funny!
Okay, you need something more than I was going to show you. If you want oauth2 then checkout http://identityserver.io/ I haven't had a chance to use Identity Server yet, but I've heard a lot of success with it. It acts as an SSO service to manage identity and access between applications.
I agree, fantastic book!
while this is a great suggestion for programmers in general, I don't feel it really addresses the question of design/architecture.
I mean, Microsoft [sure does suggest using it](https://blogs.msdn.microsoft.com/dotnet/2017/08/09/web-apps-aspnetcore-architecture-guidance/) (though they refer to it as the "Clean" architecture).
As someone who just re-wrote a 10 year old suite of Access apps in .Net, and got a "Thank you for your hard work, we don't need you anymore" all I can say is that I commented every single horrific management decision in the code. If you find something that says: "This was beautiful clean code that was bastardized because the boss to handle this other thing that isn't even remotely close but won't let me touch this other thing where it actually belongs" all I can say is "run away"
It doesn't matter. Whatever code you work on will suck. Whatever code you write will eventually suck. This is what happens when you're paid to do what the boss wants, and not what you want. I have a bunch of code that would have been handled perfectly by triggers. The boss doesn't allow triggers because of "stuff" (maybe beaten by one when a child? IDK). In any case, because no triggers are allowed, there are whole buckets of scheduled tasks that check the DB for "stuff" and then do other stuff. So there are also lots of support calls like "Why is the customer still on hold" and the answer is "Because tonight's schedule task hasn't run yet." 
Oh, no no. Never :D I'm not that paranoic :) It's common to see people rewriting standard lib stuff like that, particularly in C++ projects. You can rewrite list data types for example, that's ok, but i've see projects with every standard datatypes rewritten. Madness.
Thanks! I guess I expected Identity to be able to be used with an API, or is it API providing the Jwt auth middleware?
Ok, so the UserId thing is funny, apparently, even though Iâ€™m inheriting from IdentityUser in my AppUser class, when even I call on an instance of AppUser.Id, itâ€™s different that calling GetUserIdAsync(HttpContext.User), I did that, and it fixed all the problems; both the asynchronous error, and the user is incrementing error.
Got a good laugh out of those, pretty helpful too, thanks!
Separate projects for each company, all pointing to the same code project where the code points to resource files and those files are different in each project but share the same name so nothing has to be changed?
&gt; But if you need a faster way to enumerate files in .Net because your directory has tens or hundreds of thousands of them, or god help you millions of them, you're gonna need to drop into OS API level stuff. FindFirstFileEx &amp; FindNextFile on Windows. Why do you say that? I'm assuming that since their api is built around enumerables then it's not trying to load the full resultset into memory at once. So if that's true and you can iterate through it efficiently without incurring lots of GC overhead, then what would prevent C# from being highly performant in this use case? Seems like it'd be the same number of context switches as using the OS APIs directly.
WPF has built in theming support.
Just ordered a copy, thanks for the help!
Perfect, I Can't really get more experience then I already am so building blocks sounds great! Thanks for the help
Sounds like you need to change jobs.
Look into Datatables. It's a JavaScript library that makes working with tables pretty easy and and making them instantly sortable/filterable/searchable/paginated with very little setup. datatables.net
Listen to the podcast coding blocks, it covers tons of architectural concepts in a really approachable way, and gives a lot of insight into their applications in the professional development world.
I had this same question about a year ago (I have been coding asp.net since 2003) and have read various books and video courses. I feel that learning architecture is not the same as learning to code. Converting a string to an int there is a few ways to do it but essentially there is a right way to do it. Software design and Architecture is more of an art form taking into account many factors and so to learning it is somewhat of a journey, combining new narrative to your conscious reality. For me video does not lend itself well to this sort of learning process. Reading the way you do when studying philosophy works much better. So the process of reading a chapter of a book, taking the time to think about it, hypothesizing how you would incorporate the architecture into your current project before proceeding to the next chapter works really well. [Architetecting Applications for the Enterprice](https://www.amazon.com/Microsoft-NET-Architecting-Applications-Enterprise/dp/0735685355) is great, they thoroughly go through the thought process involved in choosing an architecture, be it CQRS, DDD, Event Sourcing or Transaction script. It does feel a little dated and I would like to see a 3rd edition but still very good basis. There is some good books at [.NET Application Architecture](https://www.microsoft.com/net/learn/architecture) page. The Microservices &amp; Docker one is good, specifically the chapter on [Tackling Business Complexity in a Microservice with DDD and CQRS Patterns](https://docs.microsoft.com/en-us/dotnet/standard/microservices-architecture/microservice-ddd-cqrs-patterns/). I like how they provide links for futher readying. 
I'll probably get shot down for this, but why not roll your own? I did it as a learning exercise by following the Wikipedia page on challenge-response authentication. 
A good idea and I definitely think that it's workth it, but I'm on a time crunch.
I'm a trifle burned out. Bet you couldn't tell. 8-) I've been programming since 1972 and through all the paradigms and philosophies and technology changes, nothing that means anything has changed. 
You've got a bunch of good ideas in this thread, but some meta-advice... Focus on getting the important parts right. Everything else can be a little wrong.
This issue seems similar to yours https://github.com/aspnet-contrib/AspNet.Security.OpenIdConnect.Server/issues/430. They suggest looking at the article below. The xml decryption message looks like the core key error. https://docs.microsoft.com/en-us/aspnet/core/security/data-protection/configuration/overview
One WPF example I've seen that uses themes is [Fluent Ribbon](https://www.nuget.org/packages/Fluent.Ribbon). OP could see some of their samples for leveraging different themes and swap them on the fly - or could have a build that used the alternate theme without an option to change.
Yep, just a new library project, named in such a way that it doesn't give away anything that would bother the company wanting the white labeled app. 
Interesting. What if a user belongs to multiple tenants?
why are there user credentials *and* an apikey? an apikey is supposed to be the credential. why is there a "ToLower()" on the api key? why is an apikey being baked into the jwt's header? Do not follow this, this is bad. What should be done is the api key is its own thing. It is obtained via user credentials and is assigned to a user (with state). It is either a jwt itself (with a tenant id baked in) and a signature looked up in the db, or it is an opaque key that gets hashed and looked up in the db (from which the tenant id is derived), both for validity. Once validity is established, the secondary jwt is created based *solely* off the tenant id, and it is upon the tenant id that the secret key is chosen. Do not store this secret key in clear text. People copy paste. Always put a warning like the "not for production code" that is in the "ValidateUserCredentials" function. Later on down the line, you select the key to validate with based off of tenantid. Generally speaking, a unique signing key per tenant is an interesting and valuable idea. The plumbing here should work, but the semantics are very bad. /rant. dealing with badly constructed jwt implementations is my nightmare.
You can check out https://zetpdf.com/ which also supports .Net Core.
Visual Studio and 2017 for mac is free. 
Its pretty simple. In fact the other top post in /r/dotnet is about just that. I don't think it's a good article, but it's a start at jwt tokens for Auth. There are dozens of articles out there on creating jwt tokens. Then you just set up dotnet core to use jwt tokens as the default Auth provider. I've built it over top of identity framework for api access for SPAs. The only really custom part is a refresh token provider. There is a jwt nuget package from MS core team I believe. 
Yeah I understand that. The problem is that is not actually Visual Studio and rather it's Xarmin re-layered. 
Thanks so much dude!
Have you tried visual studio code?
No web templates? I have to upgrade my Mac OS before I can download it. Will check it out. 
True... i get it.. Thanks you so much... I have posted another video. Links below. Hope you like it!! https://youtu.be/LvhFewK-q9A
Yeah, vs code is the goods.
I've been working with dotnet core on mac for half a year now, so it's very possible! Visual Studio Code is free, but I primarily use Rider - it's just better. The only missing piece for me compared to running Visual Studio in Parallels is NCrunch for continuous testing.
Is there anything stopping you from pulling customer resources from a server and loading them dynamically upon app startup? That way you could scale to as many customers as you want without having to alter the code. 
I need different executable names, different installer names, etc...
Rider is probably your best bet for a full IDE experience. It should work pretty well with ASP.NET Core but I'm not exactly sure about the older versions. Should still work with mono buy you'll be missing out on some stuff.
Is the codebase written in dotnetcore? If not, then yes you're either going to want to set up a VM or dual boot. I am currently dual booting.
Nope. I'm a Macbook user too and .NET programmer. I almost never use Windows.
Kinda but with each release it's moving away and looking more like Visual Studio. The support for web in Xamarin was patchy but it's much better since the VS rebranding.
Why would someone downvote this? I'm not sure I agree with the comment but it's constructive and polite.
I'd go with the one build per theme if it's for white\-label purposes.
We use Rider at our workplace. It's basically IntelliJ + ReSharper. It is a little pricey but works pretty well. ReSharper alone makes this purchase totally worth it. I've also noticed that ReSharper integrates way better into Rider than Visual Studio performance wise. They were probably able to make some tweaks that weren't possible with Visual Studio as they don't have any control over it. It's not perfect as it's still very young. I think it's only been stable for half a year or so. I did run into some issues when debugging which is why I still use Visual Studio Code from time to time when that happens. Hopefully those issues will be fixed soon. There are things that Visual Studio supports but Rider doesn't, especially when it comes to configuration of solutions/projects, etc. Obviously you can always just edit the .csproj file yourself but it's still handy to have a Visual Studio instance lying around in case you need it.
VS for Mac supports [ASP.NET](https://ASP.NET) either on Mono or .NET Core.
I write asp.net apps on linux with vim..
To structure your code better, you could implement design patterns. You could also draw basic components (diagrams) in which you implement these design patterns. Afterwards, you can implement the diagrams in code. That's how I do it, I draw it before I code. That ensures you atleast think about the architecture. Here is a link to common design patterns, examples on C#: http://www.blackwasp.co.uk/gofpatterns.aspx
I have developed asp.net apps to connect to a xamarin mobile app with visual studio mac. I like it. However at the moment I have a macbook pro and mac mini and I use a windows 10 VM in azure for development. It is amazingly responsive with dual screens. 
I had to look up what XBAP is. Is it even supported still? I'd stay away from that. ASP.NET MVC with the included Razor syntax is a good stepping stone. You can stay in relative comfort if what you already know and not touch too much javascript if you don't want/need to.
A lot of my motivation for creating Phosphorus Five, was to create a smooth transition for exactly your type of scenario - **Without** compromising quality or security. You can check it out here - https://github.com/polterguy/phosphorusfive Stay away from _"ActiveX 2.0 types of solutions"_ - Regardless of whether or not you're intrigued by Phosphorus Five or not ... The beauty of the _"web"_, is that it simply works, all over the place ...
There are no tools here which are really good. However, the last time I checked, I remotely remember that I concluded that iTextSharp was the best one. However, _"best one"_ really implies _"least sucky"_ ...
It depends. ASP.Net MVC is probably good but you might find corners where VS for Mac or VS Code don't cut it.
MVC \- very different but very nice
I would highly recommend you bite the bullet and pay for .NET Rider as the experience on it is top notch. If you arenâ€™t willing to do that then VS for Mac will do the job.
Could have a labeled shortcut and the actual exe something generic like launch.exe or something. I wonder whether you could dynamically load the theme stuff with MEF. You could easily have a branding class that provides an image or something. An `IBrandImageProvider` that's dynamically loaded from a DLL you can shove in the executable directory. Not sure if you can do themes with MEF but I'm sure you could set some colour resources or something?
[ASp.net](https://ASp.net) Webforms is the closest to what you are currently doing and probably the easiest to transition to. No one is going to suggest it because it isn't new and sexy, just still widely used. However, if you are not in a rush, I would probably go further away from winforms and go to MVC instead of Webforms.
I would also recommend a thousand time all the articles written by Taiseer Joudeh , the serie on Json Web Token is amazing and maybe what you are looking for ! 
Most people would use migrations dotnet ef migrations add somemigrationname dotnet ef database update 
You *can*, however I found using the real Visual Studio running in a Parallels VM (in coherence mode) to be a nicer experience than any of the pseudo Visual Studios.
Web API for backend and JavaScript for frontends (jQuery with Knockout JS and Bootstrap or React or Vue or Angular or POJS)
I get that but when I try to migrate it doesnâ€™t recognise the database string as it doesnâ€™t exists 
Are you getting an error? Is the ef command saying it doesnâ€™t exist? It uses your app.config to pull the connection. If you have multiple contexts you need to add â€”context contextname 
Webforms are dead framework. Stay away from it
If you can afford to wait a year or so I would only because web assembly will have a big impact on web development and will totally change the how web apps are made. Take a look at blazor to get an idea of what I mean.
Great news! 
What kind of DB are you using?
The first time you run the database update command it should create the db using your app.config for the connection string 
I see, right Iâ€™ll try a few more things. If it works Iâ€™ll let you know! 
Ok. It would probably be a good idea to switch to sqlite for your current scenario. Alternatively, you could use an in memory DB for testing. Obviously your have to switch to a different DB for production.
When it comes to pdf generation, try using ZetPDF.com It worked for me.
Hey - have you made any progress? I'm working on something similar. We're all backend .NET and we have something we're working with that uses XMPP.....their doc states it could be a regular web server, but seems like XMPP is preferred? I've never touched XMPP before, anything you've found out so far would be helpful.
That's the one I meant to post. Was on mobile at work when I answered this originally haha. Definitely recommend this tutorial as well, it pretty much addresses how to handle authentication using the scenario OP described.
What does this do that iTextSharp doesn't? Honestly, what I would really like from a .NET PDF library is MSTest a complementary DLL with Nunit asserts for DLLs. I'm usually going to be forced to use a third party DLL to make PDFs in an enterprise environment. However, the unit and integration testing of the created DLLs always involves rolling your own asserts from some open source PDF library. If the was a PDFPig.Mstests.dll with methods like PDFAssert.TextEquals(string, pdfTextBox) and another one for Nunit, I would definitely use that, and probably contribute new asserts there. 
Added Youtube channel from Steve Gordon. One of his videos; https://www.youtube.com/watch?v=8XWDKJv3eyI&amp;t=14s
Give it a try, you'll see ;) I'm not sure what exactly .Net is doing when it enumerates files because the implementation is not in .Net and not open source, but it's horrendously slow as the number of files increases. Take a directory with a million files and it can take many hours, days even, before the enumeration will begin. Using win32 api I can enumerate the same directory in 15-30 minutes.
What's there to disagree with?
The main benefit this provides over iTextSharp is it does not use a viral/not properly open source license. This means it can be used in commercial applications, giving the user full control rather than copyleft code with a commercial tier. Due to it being very new it has nowhere near feature equivalence with iTextSharp but hopefully we can develop it to get close. I'm interested to understand more what you mean with your asserts example. Are you trying to assert that text in created PDFs match the expected values for example? I'd like to read more what you would need.
Oh, Iâ€™m fully aware that he current api is horribly slow at directory enumeration. It just seems to me like an issue specifically with the current implementation, which the new API will supersede. It doesnâ€™t strike me as an area where a managed API is doomed to be slow.
"Rider is probably your best bet for a full IDE experience" - I'm not sure I agree (though as I say, it's not a contentious point).
Sorry, I should have asked what don't you agree with? Is there a better IDE on Mac? Just curious. It's been a while since I've used VS for Mac but it left a bit to be desired and Jetbrains has always been second to Visual Studio for me 
I'm fairly new to JWT and multi-tenancy but these sound like much better approaches. Would it be possible to link to some examples to fully flesh the above out? The part I'm most confused by is once a user is validated, how best to ensure the correct tenantid is found, stored securely and sent each time with a request. For example, the link above needs a API key from the start, I think to myself, "okay, but where do I get this key from and what's stopping me guess or copy some other tenant key, gaining access to their data?" I'm sure there's an extremely simple answer, but I'm new to this and my head just cant get around it 
Not so sure, when I tried it in VSCode it worked flawlessly.
How to retrieve data from MySql database?
In a year there will be a new amazing thing that promises to change the world. What OP needs is to transition to web *today*. From a .NET standpoint that would be ASP.NET and all its flavours.
Good point about iTextSharp. That does limit it to only use in unit tests for me. Ok Generally speaking, I sometimes write services that read data from databases or REST and spit out PDFs based on templates. I usually just use itextsharpt to turn the hole PDF to text and string match there. But if I had some library that could assert some more generic things I would write more robusttests. Just some ideas PDFAssert.NumberOfPagesEqual(X); PDFAssert.SectionExists(X); // I don't know if there is an xpath like syntax for navigating PDF hierarchery PDFSectionAssert.FontEquals() PDFSectionAssert.HasSignature() I guess PDFAssert woldn't be a static class, you;d load a PDF file or stream into it, and then perform all these asserts. But just having a thing that performed the same sorts of Asserts as MSTest, and produced useful error messages that worked with my CI/CD setup would be awesome. 
&gt; What OP needs is to transition to web today Which is why I prefixed my statement with "If you can afford to wait a year or so..."
Why would you want to test a 3rd party library? Do you test everything under the `System` namespace as well?
I keep hearing that and then every day I come to work and do more of it. :P Webforms are going to be the COBOL of the internet.
Almost certainly. While I don't have a problem with people charging for their work (I wouldn't be able to afford anything if my day job didn't), I think these Copyleft licenses are an incredibly user-unfriendly way of achieving this aim. They create a field day for lawyers and create whole categories of thought crime where reading a copyleft code base leaves you liable to infringement claims. It's easier to have a choice between off the shelf software and open source rather than this awkward mid-point which I feels steals valor from proper open source projects. Of course there are lots of very useful copyleft tools, especially in the Linux ecosystem but I just feel copyleft as a model penalises people's ability to bootstrap their own companies, hurting smaller companies and one (wo)man operations and barely affecting big companies. /rant I also agree re. exporting to PDF. It's a requirement as you say driven by non-technical users who are focused on the look and feel rather than the utility of output formats. While the PDF specification is open I'd say it's a harder format than, for example, the docx/xlsx formats for Word or more simply HTML. Most libraries for interacting with PDF are commercial due to the complexity of the specification. The most egregious example of this is probably (in the UK) the Government Digital Services (GDS) which require all documents to be made available as PDF format since it is open, rather than docx or HTML. While the motivation behind the requirement is honest, the implementation suggests it was not fully thought out. Haha, thank you, but the real blessing should go to the PDFBox guys and girls. I have no idea how they wrote it, the specification is so tricky!
There are 2 reason why people do webforms 1. Maintain legacy apps. 2. Doing greenfield because they don't know any better. I sure hope your reasoning for doing webforms is in the first category
&gt; is that it simply works Debatable
No, I want to test the PDFs it generates. Assert that text is present etc
https://www.athenapdf.com/ Opensource docker service
Probably better off introducing web hooks instead of triggers for that.
I think Iâ€™ll post up a quick tutorial once I get this all working. Iâ€™m managing to piece together some stuff translating from examples in earlier versions. Seems like it might be a fairly niche topic though! JavaScript UIs seem to get all the attention these days. 
God so so so much this. Hell, even taking an inherited mess and fixing it up over a time will give you an appreciation and understanding of good architecture. &gt; it's really easy to fall into the architectural fads of the day which always exaggerate the benefits and ignore the costs. OTOH, I'm curious as to which fads you mean here.
It must be, because I have no idea what "greenfield" means.
I use VMware fusion and a windows vm and develop on it daily. It's a really nice experience if you have a SSD. 
ARM32 seems a strange platform to be adding
Any idea when this is targeted for RTM?
This is Reddit, clicking the link is optional :)
You can also use something like [OpenIddict](https://github.com/openiddict). It already handles a lot of the work for you, so even though you are "rolling your own", you still have a lot of control over how you handle things.
I'll take a look
Why?
super stoked for global tools. probably the number one feature in 2.1 I'm looking forward to. as someone whose never written any csx, can you write your scripts in vs or code or something with intellisense and a "compile" phase to check correctness?
I'm in the belly of the beast right now with frontend stuff, fought with incompatible npm packages for like 3 hours. back compat doesnt seem to be a huge concern in the js community. it's terrible. a good spa is awesome, but you can get a lot of mileage out of razor and mvc.
means it's a new project and your getting to choose technologies. nobody chooses webforms anymore.
lol internet explorer 6 would like to have a word...
if they bail on blazor I'm going to be pissed. i'm not using it, but it has *tons* of potential.
you and me both buddy
http://i0.kym-cdn.com/entries/icons/original/000/007/508/neildegrasse.jpg
There are huge numbers of cheap ARM32 based devices on the market and .NET Core is a great fit for them. There are [ARM64 builds available](https://github.com/dotnet/core-setup), they're just not considered official yet.
Sadly it doesn't appear to. It's no Windows VS but I like Code more than Visual Studios for Mac.
Maybe. You should eventually plan on running Windows in Parallels. Only things I run in my WinVM are: - VS 2017 - GitKraken - SQL Server Management Studio Everything else I can do in macOS. One of these days I'll play with Rider, or we'll actually migrate to .NET Core.
Ah, a fellow coherence mode fan. It works properly about 95% of the time, except when the laptop has been asleep for a while (Windows gets surly and I have to kick it in/out of coherence mode). Or when I switch from the laptop to the dock to the 4k TV in the meeting room and back to the dock. Windows gets stuck in 16:9 aspect. 
Yup. Most people think â€œmicro-servicesâ€, but what they really need is a [modular monolith](https://martinfowler.com/bliki/MonolithFirst.html)
The user would be duplicated in the 2 tenants - that's the way I've always dealt with this which has made sense for my products. True - you need to key the keys safe! 
So much this. EF Migrations are fine to start, but you really need to move to FluentMigrator as you get closer to production releases. Our guidelines are: - All migrations go in a separate project. - Have an automated test that stands up a new database, then runs all the migrations, and tests (in the easiest way possible) that migrations ran (looking at the VersionInfo table row count for instance). - Migrations can add/remove columns, or make columns nullable. - If you need to add a not-null column, you have to do it across two releases (initially create it as nullable, wait for the DBAs to patch the data after release, then change it to be nullable in the next release). It just works out better in the long run. - Do not try and migrate data inside a migration, unless it's less than maybe 100 rows and is guaranteed to run in under 1 second. - DBAs should be allowed to create performance indexes, so if you're adding an index in a migration, look before you leap (make it a defensive migration). Talk with your DBAs about what they want the index to be named (most DBAs have a naming scheme they prefer). - Removing tables is harder, because there may have been performance indexes added that you may or may not need to remove. You may need to survey all environments and create defensive migrations that remove those blockers prior to removing the table. - Your DBAs need to not be fiddling with the data tables/columns/structure. If your migrations blow up because a DBA fiddled in QA/Staging/Production, you've got a human issue to address. Do not make your migrations defensive just to cover up process issues. We use a mix of fluent syntax and SQL written by the DBAs for our migrations. The fluent syntax is preferred in most cases because it's all in a single C# file instead of spread across a C# and a SQL file. 
Thanks for the feedback. I essentially use this approach for system to system integration - sync'ing data between 2 systems This is how this work in my product: - There is an endpoint to create / recycle a key - only an admin user (who administers the system) has access to that - There is another endpoint to create / recycle user credentials - again only an admin can access this - The admin user then puts the key in the both systems - again via an endpoint only an admin can access - The process that does the sync then uses this key and user credentials 
Why use a web hook to monitor the DB for changes, when there's an actual object designed to do exactly that? When records in the DB change, other DB actions are supposed to happen. Triggers would be perfect, but they're apparently evil for some reason. 
That would be great! I was looking at building the next app with WPF, Prism 7 and MEF, so seeing another person's experience and expertise would be very nice. There is however a significant part that I am still struggling to fully get my head around is that there are 2 MEFs. The old one, part of the .NET Framework, and the newer one called System.Composition if I recall correctly (distributed as a nuget package). The new one is supposed to be much faster (the original one being one of the slower DI "containers"). So I would like to use the new one, however Prism seems to only support the old one. And the reason to use MEF in the first place is because of its attribute-based configuration model. I prefer classes themselves to declare their dependency relationships with attributes - looks cleaner to me.
Tons of ARM32 CPUs are made today. Unlike with x86, 64b didn't arrive to ARM until 2015 in a manner that it was worth speaking of. Nowadays ARM64 is dominating the commercial sector, like smartphones, tablets, servers, PCs, TVs, et cetera, but microcontrollers are only now transitioning to ARM32. This change might even mean that soon you can run your C# apps on a newer Arduino ðŸ˜‰
One thing I would love to see from the Mono project, is a stripped down distribution of ASP.NET, without all the dependencies that are _"irrelevant"_. Basically, a distro which only allows you to run ASP.NET apps through Apache or some other web server, still 100% compatible with ASP.NET WebForms, would do wonders for me personally. I don't need WinForms, I don't need a C# compiler, I don't need Cairo (and God knows what), I simply need to run my ASP.NET apps, with all relevant assemblies that could somehow be useful for me in such a regard ... And no, .Net Core is **not** it ... At least not as far as I can tell (yet) ...
This seems like it might provide a good way to dog-food the API and could be provided as a modular NuGet package. I have been writing something similar in the tests for the package: [Test Class on GitHub](https://github.com/UglyToad/PdfPig/blob/master/src/UglyToad.PdfPig.Tests/Integration/JudgementDocumentTests.cs) But it could be made easier. Unfortunately because of the presentation focused format of PDF there isn't the concept of sections or hierarchy (or even words) in the way I think you would want to consume it but I plan to improve the public API of the page object to make inspecting the content easier.
When will it be out of preview?
&gt; 64b didn't arrive to ARM until 2015 in a manner that it was worth speaking of. Go on...
&gt; And no, .Net Core is not it ... &gt; &gt; &gt; &gt; At least not as far as I can tell (yet) ... Why not?
I like REST API's behind web front ends. They \(as opposed to e.g. templated HTML served by some ASP web app\) are so flexible in that you can use one and the same REST API back end for front ends for any platform, web, native on mobile, native on desktop... Because you have this idea in the back of your mind, at least I more easily write better API's too with less of a temptation to introduce "helpful" client\-specific stuff on the server side. So the server / model becomes well separated from the clients. Since you're used to .NET, I think the traction here is .NET Core nowadays, and ASP .NET Core has better performance than "classic" ASP .NET besides being platform independent. So I would look into something like this for the server: [https://docs.microsoft.com/en\-us/aspnet/core/tutorials/first\-web\-api?view=aspnetcore\-2.1](https://docs.microsoft.com/en-us/aspnet/core/tutorials/first-web-api?view=aspnetcore-2.1) This article also continues on the track I've been commenting here: [https://docs.microsoft.com/en\-us/aspnet/core/mobile/native\-mobile\-backend?view=aspnetcore\-2.1](https://docs.microsoft.com/en-us/aspnet/core/mobile/native-mobile-backend?view=aspnetcore-2.1) For the front end, React and Angular are popular. VueJS is also growing in popularity and I found that one easier to approach than Angular, yet still achieving similar advantages. Angular and React will probably \(at least still\) be more popular if you're looking to build competency for jobs though.
The great thing about micro-services is that it create more problems that I can then solve. Business domains are boring and do not look good on resume. And docker. Everything must be in docker.
entityframework, i think, allows you to see and use oracle objects in entity framework. dataaccess just allows you to use data connections to oracle.
I read somewhere 2 to 3 months. The official roadmap lists Q2 2018 here: https://github.com/dotnet/core/blob/master/roadmap.md
You need Entity Framowrk (find on nuget) and Oracle data provider for it. Take a look here http://www.oracle.com/webfolder/technetwork/tutorials/obe/db/dotnet/NuGet/index.html
Yes I have managed to connect to the database and also create ADO Model. Thank you.
They're small. Things like updating the customer's "on hold" flag in the warehouse system when it's updated in the accounting system. 
They have youtube channel for .NET developers too: https://www.youtube.com/user/OracleDOTNETTeam/videos
I think Tuples can be really useful, but I was reading back on some of the comments and saw someone make a valid point: Tuples can enable laziness, i.e. instead of encapsulating reusable data structures into classes, some may be tempted to just return a Tuple "for now" which could lead to a mess later.
Arduinos are built around microcontrollers rather than processors. They're mostly built around ATmega328P chips which are 8-bit. Unless they start offering a board with a processor it's unlikely that we'll get .Net apps on Arduinos. Raspberry Pi and other single-board computers though - they are often built around ARM chips and so it seems likely we'll start seeing Core apps running on those platforms!
The newer generation Arduinos are transitioning to 32 bit ARM-based controllers, and while the initial ones might not be able to run .Net code, some other controllers (say, a beefed up ESP32?) could boot Linux and run some basic CoreCLR apps. Runtimes for JS and Python already exist so I see no reason why a port of CoreCLR couldn't be made in the future for these devices.
Many triggers around the system add up. But the main reason to avoid triggers is because they are not easily visible. It's not until you notice data being updated elsewhere that you may realize a trigger is involved. Generally, triggers are mainly used for building stuff like audit tables or something. If you go ahead and start adding business rules to triggers your database and applications get messy.
Summarizing the api changes (vs 2.0): * `Span` and friends (`System.Buffers.*`, `ReadOnlySpan`, `Memory`, `System.IO` changes and many more) * Various trig functions on `System.Math` and `System.MathF` * Some algorithm optimization methods on `Dictionary&lt;T,V&gt;` and `HashSet&lt;T&gt;` * `System.HashCode` - general object hashcode algorithm (think FNV hash) useful for implementing a reasonable `GetHashCode()` when you need to * `ItemRef` collection methods (allowing various algorithm optimizations for `struct` containing collections) * brotli compression algorithms * A fully managed `SocketsHttpHandler` (previously relied on external libraries) and other `Span` related networking types * better http PATCH method support * Intrinsics for AES, AVX, AVX2, BMI1, BMI2, SSE1, SSE2, SSE3, SSE41, SSE42, SSSE3, as well as leading zero count, pop count and carryless multiply instructions (I think they are labeling this as "Preview" still in the final version of 2.1) * non-generic `ValueTask` * crypto primitives for zeroing memory and a byte equality check in fixed time (and more `Span` related stuff) and Elliptic-Curve Diffie-Hellman * Compiled regular expressions specific documents here and in subfolders: https://github.com/dotnet/core/tree/master/release-notes/2.1
This is so true, I have previously work with Web Forms and I was kind of hesitant moving to MVC but once I did, I fall in love with it. It is great! 
entityframework is for... well, entityframework. you dont need it if you run without entityframework. just install manageddataaccess from nuget, and you are able to use it the classical ADO.NET way. you will see your app.config get modified a bit, oracle added sections where you can config connection string there. as to ODAC, you dont need it. it is for the oldschool unmanaged dataaccess dll.
&gt;The hardest part will be stopping yourself from falling back to using .Net to code the UI instead of just JavaScript/Typescript with CSS and HTML So true. I always try to go back to just .net ;/
Thank you, i think it is a bit clear now and i have managed to add connection on the server explorer and also create ADO.NET Model. What i am having trouble is with the configuration file. So I have data source &lt;oracle.manageddataaccess.client&gt; &lt;version number="*"&gt; &lt;dataSources&gt; &lt;dataSource alias="ProdDataSource" descriptor="OracleProd" /&gt; &lt;dataSource alias="CertDataSource" descriptor="OracleCert" /&gt; &lt;/dataSources&gt; &lt;/version&gt; &lt;/oracle.manageddataaccess.client&gt; My connection string &lt;connectionStrings&gt; &lt;add name="OracleCateringProd" providerName="Oracle.ManagedDataAccess.Client" connectionString="User Id=PRODUSER;Password=testpass;Data Source=(DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=remoteserver)(PORT=1521))(CONNECT_DATA=(SERVICE_NAME=Service)))" /&gt; &lt;add name="OracleCert" providerName="Oracle.ManagedDataAccess.Client" connectionString="User Id=CERTUSER;Password=testpass;Data Source=(DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=remoteserver)(PORT=1521))(CONNECT_DATA=(SERVICE_NAME=Service)))" /&gt; &lt;/connectionStrings&gt; What i am trying to achieve is define two database servers and reference them in a model as dbContext. I was trying to use the string connection name is the data source to avoid redundancy. Is it the other way around? or i had it completely wrong? public class TestContext : DbContext { public TestContext () : base("ProdDataSource") { } } Thank you again for the pointers. 
I couldn't find that post â˜¹ï¸ can you share it with us? 
ReSharper has done more to improve the quality of my code than anything else. Yes, it dramatically slows down VS, but that is more than made up with the efficiencies it brings to my progress. I can foresee a time when I eventually do without it, but it isnâ€™t any time soon.
I do. I did a lot of pros and cons, and pros won over.
Slows vs2017 right down. Annoys me wildly ;( 
Full blown Linux is a bit of a stretch, RTOS is more likely (actually AFAIK most of the ESP32 releases are based on RTOS). However a beefier 32 bit microcontroller (something like the ESP32, but beefier - higher clock rates, more storage and most importantly, much more RAM - around 32MB should be enough for a very barebones Linux build). .Net on RasPi has been a thing since Windows 10 IoT is available for it. 
No
I see no problem is using a trigger to update small bits of data in one table when it changes in another. If it was a big update or something with multiple tables, that could fail, I'd be all for queuing up a transaction, but that's not what these are. 
&gt; I see no problem is using a trigger to update small bits of data in one table when it changes in another. The issue there is that it is business logic at that point, and doesn't belong in the persistence layer. It causes an overlap of where your business logic exists, it's best to centralize that. Outside of things like auditing and validations, there isn't much else that you should use triggers for.
To me itâ€™s fine/normal but not without some way to invalidate the results and force it to update again 
Yeah I still use ReSharper, I have a fast enough machine that the slowdown isn't really noticeable and I think it still has advantages over vanilla VS.
Azure
Off topic, but I'm curious since it sounds like you use Fluent Migrator pretty heavily, how do you handle scripts for things like stored procedures or views in your migrations? We've been making a new script file tagged with the migration number each time the SP/etc needs to change... it works, but it feels pretty clunky (you can't easily diff how a script has changed) and bloats the project with the old versions of those script files. It feels like there should be a better way...
I use Rider. 
Yeah I use it on VS217. Its infuriatingly slow though. I actually disabled it this morning and am trying out CodeRush. I use CodeRush at home, but not enough to give a solid opinion on its features compared to R#. So I figured id give it 30 days demo at work. I will say this, CodeRush is lightning fast compared to R#.
Wouldn't it be better to store the list in the viewmodel/controller where it is used/needed? Would try to keep the repo stateless.
are you using SSD or HDD?
CSOM was kinda horrible last I checked though.
We're trying to work out optimistic/pessimistic locking for web apps we need to develop and I thought potentially if we keep/handle row version info in the repos, it might be a better place for reuse so that each controller/action/app doesn't have to code in locking, let the repository classes handle it. Really not sure, looking for input.
SSD, I wouldn't use ReSharper if I had an HDD!
How is this business logic when there's no logic at all? The two tables should always be identical and a trigger would take care of it. 
Totally agree! It slow vs2017 but the time lost is gained with is functionalities when writing code. Can't live without
No problems with SignalR on DigitalOcean.
winhost.com (?). Check with them.
I cannot find a single reason to use ReSharper. All functions I would ever use are part of Visual Studio 2017. I believe people who do use it, are just use to it and don't know how to do what they need in VS2017 alone.
No. I've been programming in .Net since 2001 and while I used to use it, I now find it is no longer necessary.
Because it's one persistent entity updating another, that is business logic. Like if you had an order that updates a shipment table or something when an order is submitted. That is all business logic.
ReSharper giveth, ReSharper taketh away.
I don't understand why Roslynator isn't just a meaty nuget package full of analysers. That would have fit nicely within the build chain.
If you run Asp.net Core, you can use a $5/mo dedicated DO VM. Scale the box as you need to for usage. 50 clients isnâ€™t a lot. 
Vs2017 is too slow to be able to use any extensions with it :/
this is simply not true. Maybe you haven't used resharper in a while but Resharper still excels on the areas where Visual Studio is still catching up. Code navigation, refactoring, syntax highlighting etc. are still far ahead of visual Studio. Try it out in its current state and take the time to go through each of the features and compare them with Visual Studio. Yes, Visual studio has caught up but Jetbrains have not been resting in the meantime.
What are you using for a DB? How much storage and what do your reads/writes per sec look like?
[isn't it?](https://github.com/JosefPihrt/Roslynator#products)
WebForms for one ...
Don't get me wrong, I love asp.net but there doesn't seem to be any actual technical evidence to back up the claims made in this article.
I used to back in VS2013/2015 days, but I feel like there are enough plugins/built in functionality to VS now, that I don't miss it anymore. It took a little while to get used to not having RS, but I don't even think about it now. Also the performance is much better w/o.
agreed this is generic garbage
Such as what? The slow down usually irritates me so much I disable it.
OP should just do proper url encoding on his query string.
There is no reason to use a user-readable string if it is never going to be used-read. Just take the .Ticks property of a UTC DateTime, and then later construct a DateTime using that number as a UTC DateTimeKind.
Whoever made the code did a rather poor job, since it sounds like the code is working with object types. You will have to cast it to the actual object type (add a breakpoint and inspect the variable if you don't know the actual type it is).
I wish I *could* use VS 2017 at all. It is just to slow to even be usable and had to go back to 2015
.NET Core may or may not be able to consume those web services... I don't really know how that works. If it can't you'll have to recode the way ..NET Core is calling them anyway into raw HTTP requests to the web service url, then stripping the XML off the response to get the return value of the function.
No. It's slow as shit.
How does Rider compare to VS2017+Resharper for speed?
Yes, VS without Resharper feels to me like Notepad. On the serious side, VS 2017 may have more Resharper features than before but the whole Resharper package just works great.
Yep that would be ideal. Doing this weird string manipulation is definitely not recommended, assuming he has access to the client code then encoding his url would be much better.
Thanks for the hints!
I canâ€™t change your mind. I use native VS. :)
Haven't really found a good way for stored-procs and views. So they end up like you've seen with a new SQL script for each migration. About the only possible help would be: - Strong naming conventions (ViewName_YYYYMMDD.sql) - Putting them in their own folder in the Migrations project - Possibly one folder per view or stored procedure At least if they're out in a separate folder, they won't get lost in the mix with all the others. Might even make it easier to diff since both files would be right there and listed in migration order. Hmmm, may have to try that approach in our solutions.
You're not likely to find anyone with SignalR as a hosted service. But there are plenty of virtual servers / cloud providers that will cost less than $100/mo. A t2.large instance on AWS will cost about $68, for example. How much horsepower do you need?
The scuttlebutt that I've heard is that Rosylnator is not opinionated enough in what it accepts into the project. So you will get competing advice on refactoring.
I still swear by R#. I tried to go without for a bit, but there are simply too many productivity features that I've gotten accustomed to over the years, and I haven't found a replacement for even most of them. Not everyone needs or likes R#, and for those people, vanilla 2017 is probably more than enough. I'm just resigned to the fact that I am not one of them. Iâ€™m sure there are great arguments to be made on both sides, but it just tends to collapse into a holy war anyway. I do rather dislike that I need a 5GHz i7-8700k to run it acceptably fast. &lt;/humblebrag&gt; I'd like to know for sure whether JetBrains is full of it when they claim that converting R# to Roslyn wouldn't be worth it.
I'm confused. Signalr is just some assemblies and javascript, there is no application to install or host. Anywhere that can host an asp.net app should work fine shouldn't it?
I use R# with VS2017 at work, but not at home. One killer feature is shift+F12 (find all references) ... it actually became **worse** in vanilla VS2017, and just working on a team in general, the R# features come in handy. Solo projects I don't feel compelled to shell out for a personal edition, any more, but I used to.
Currently trying to nudge my boss in the direction of EF and MVC and learn it all at once. Still gonna be using .net framework since we have a large code base in that and .net core doesn't support some of our requirements. Any good literature recommendations?
Pretty much. As long as the web server supports WebSockets it'll work. SignalR has fallbacks, but WebSockets are ideal. To your point, I can't imagine a web server that can support ASP.NET, but doesn't support WebSockets.
Yep. Been using it since 2008. It has way too many features which vanilla VS or other extensions don't cover. Can't live without it anymore.
I'll write a bunch of code and only enable it for refactoring and clean up. Slows down visual studios far too much especially in very large solutions.
Nice, I like that idea. Right now we use a Scripts folder with YYYYMM sub-folders, then each script is tagged MigrationNum_ScriptName.sql (we use YYYYMMDDHHmm migration #'s). It isn't too bad to search with the solution explorer or command line to find previous versions, but a folder per view/SP would probably make easier to pick up for people joining the project.
The fact the VS doesnâ€™t have a refactor option to move namespaces annoys me to no end. 
I can't say enough good things about Rider. There are a few annoying things (it doesn't respect your launchsettings.json for example) but they're working on that and there is a work around anyways. It's freaking awesome. I'm a .net core developer who uses a macbook pro so it's a logical choice though.
No, I see it as a crutch. I can get around quite well without it once I figured out what works. I'm sure it has a few nice features that would be better than what I have now, but what I have now is a lot more free as well.
what are you trying to say? Shift+F12 is worse in resharper? Not sure I understand.
Worse in vanilla VS 2017, but still very good in R# ... I'll edit my original comment ...
Yes, although it's tough on my Surfacebook, my Ryzen doesn't break a sweat. Couldn't live with out the auto completion, code generation, keyboard shortcuts etc. I also really like Rider, but can't give up NCrunch until JetBrains gets continuous testing out. 
By convention, they usually do, but you're really supposed to map namespaces wo that they make sense in terms of what is imported rather than what is easier to maintain. That's why they aren't the same thing.
I use 2017 at work and 2015 at home for personal projects. I much prefer 2015. MS did something screwy with 2017
This is exactly my experience. Many of the features people say they need ReSharper for are standard features in visual studio. 
No, as it makes VS eat 3+GB of RAM. The day we get 64 bit VS I will go back but the constant GC and memory pressure kills VS.
Resharper, no. CodeRush Roslyn, yes.
I tried CodeRush, but wound up goning back to R#. Although I'd love to ditch R#. It's too fucking slow. Maybe I'll check out Rider.
Strange. in vs2017 it takes you directly to the implementation or asks you which implentation to go to. How much simpler does it get?
I do. I got tired of visual studio hanging up on me especially with multiple large projects open. I full on switched to Rider. I will never go back. Unless visual studio gets crazy upgrades Rider is the way to go IMO. 
Go to decompiled sources is the main feature i miss from R#
MVC "go to definition" - you can F12 on the 'return View(model)' and it will take you to the razor template, or F12 on the string defining your action in a Url.Action and it will jump you to the controller code. It will also show a red underline if the model you are passing to the view is different than what is defined with @model. I also use the introduce readonly field quick menu item extensively in constru,ctors. It has a bunch of other utility functions that are useful and time saving as well. For example if you have an interface as a field in a manager/service class and you want to create a wrapper/proxt to all of the methods on the interface against that field, there is a way to do that. Code analysis/recommendation for possible null reference exceptions has proven quite useful as well. 
Not me. I've seen the horrors of ambiguous namespaces. If namespace changes where done automatically, there would be times where bugs where caused for literally no other reason than being a lazy ass.
It sounds like you're describing "Go to Implementation" which in my system is mapped to ctrl+F12. I was actually talking about "Find All References" which I have mapped to shift+F12. I think vanilla VS2017 has feature parity with R# for "Go to Implementation" ... but "Find All References" is not as good as R#
Sure, that is a good function. But still is not near good enough to make up for the slow down of the system.
I think new version of signalr have no fallback.
I think their argument is basically "it would cost too much and take too long". It's a valid argument and I've made it myself in commercial projects where ability to iterate regularly was important. But if Jetbrains was a startup, and Reshaper was a greenfield project, would they write their own engine today? Of course not, they'd use Roslyn.
11/10 would use orleans again. it is very easy to use, the whole integration process feels very natural. we evaluated akka.net, which is very nice too, but orleans was much less "in the way" and the development speed was and is really fast. bug finding in production was not really different than other bug finding in production. we mainly use logging. orleans itself didn't bother us with any malfunction. the only orleans-related error we had was a problem with an outdated storage provider that I forgot to update. if you have any problems with orleans, you can always check the orleans log that gives you detail information about errors (or nonerrors if you like verbose logging). when I started the orleans project I didn't really get the microservice pattern right. in fact I designed one large deployment monolith and used orleans as a microservice platform. I would change that (and will, if we have time to invest) and use the same approach as the microdot framework uses (https://github.com/gigya/microdot). I think I would use kubernetes as platform and orleans as base for the different services. with the release orleans 2 it is even better because you can use .net core if you want. and it is even easyier to use. 
Nope. Used to be an die hard user of resharper, but it just slowed VS down, and it's memory usage with large projects is through the roof.
looking at you, corert. bootstrap us here. Once general (a la httpclient) c# -&gt; native becomes a thing, doors are wide open for all kinds of meta stuff. (but seriously, that repo seems super active, good work folks).
lol am on VS2015 and having to use the EAP
I have been using it up until 2017 and then stopped. The new navigation features in VS is what made a difference to me. Regarding performance, it's hard to overstate the difference. I always had a his perception of Visual Studio as slow. But after not using Resharper and using Android Studio (which is IntelliJ, so likely similar in performance to Rider) it parallel to VS, I generally came to appreciate how performant VS is. I have to restart Android Studio multiple times a day because of memory leaks, which is not something that I need to do with VS. I do miss some of the more advanced refractors that Resharper provides, but over time the Roslyn-based adding get closer and they have a negligible performance footprint compared to Resharper. Generally I think the decision is very personal. Resharper definitely helps you with becoming a better dev. But after a few years I'm writing code in a ways to avoid the squiggles most of the times, so the trade-off in performance stopped being worth it.
Yes, and it just slows it on startup... and my code gets more quality thanks for ReSharper. Would love to have ReSharper on VSCode !
Resharper just makes your code better. Obviously don't be dogmatic about it, but the argument that "lol it's a crutch / makes it easy" ignores the fact you're using a high level language in an IDE. Code written with resharper is qualatitively better - check egos at door, static analysis is a boon. Re: R# Vs the current VS feature set - VS now has capable code movement and rename refactorings, along with basic property extraction. It has about 20% of the quick fixes and lacks all of the deeper features (active templates, custom refactorings) - it's nagation is far worse (structural navigation using tab FTW!), Test runner is far worse (if you're not using something like Ncrunch) and generally is not quite as polished. It is, however, miles faster than having a heavyweight static analysis plugin. That's just a money problem.
Generally, your data access layer would just return the data and remain stateless. So, the second option. What would you expect the benefit be to storing your collection as a class member? I could see a scenario where this could lead to inconsistent data. For example, if I have two instances of the repo both of which have retrieved their respective product lists, a new product is added via one instance (which could still in theory be updated with the new entity, note: this still adds unnecessary overhead for you) how would you reflect this change in the other instance?
You're seeing a 404. At first glance you're missing a / between the host URL and the Guid I.e. /signin-oidc/(Guid). Fix that and you might somewhere. 
Yes, and despite what loudmouths tend to get across: it's not that slow, vs2017 in general is slow (as it does a lot on the main/gui thread still). Disabling R# doesn't make vs2017 all of a sudden much faster. (I tested) If you really want to do yourself a favor though, get Jetbrains Rider. It's a much better IDE, it's fast and offers all what R# offers too. Unless you need to do winforms (I have to which is why I still use vs2017 occasionally), it's a better .NET/C# IDE. 
Yeah, I think this should be handled on higher level. Its just caching after all.
Not only do I not use it, I've disabled a lot of the built-in VS2017 analyzers and other BS too. Its all too slow as-is. Add ReSharper is just more pain. If I type a key and don't immediately see the output your text editor is a failure. If a feature causes any perceptible lag while editing I do not want it. I'll add analyzers and linters as compilation steps, but not while I'm fucking editing. Get that shit out.
 var numberOfAdults = 1; var numberOfChildren = 2; var numberOfAdultsAndChildren = numberOfAdults+numberOfChildren; var checkInDate = DateTime.UtcNow; var availableRooms = _context.Rooms .Where(room =&gt; numberOfAdults &gt; 0 &amp;&amp; room.AdultsCapacity &gt;= numberOfAdults &amp;&amp; room.AdultsCapacity + room.ChildrenCapacity &gt;= numberOfAdultsAndChildren) .Where(room =&gt; room.Booking.All(booking =&gt; booking.StatusId != canceledStatusId &amp;&amp; ((checkInDate &gt; booking.CheckInDate &amp;&amp; checkInDate &lt; DbFunctions.AddDays(booking.CheckOutDate, -1)) || (checkOutDate &gt; DbFunctions.AddDays(booking.CheckInDate, 1) &amp;&amp; checkOutDate &lt; booking.CheckOutDate))) .OrderBy(room =&gt; room.Price) .ToList(); I'm not sure what CheckInDate + 1 does in SQL so I've treated it as adding 1 day `DbFunctions.AddDays` Might not be perfectly what you want but it's possible.
I would say that it can be done (I first need to understand well enough what the sql is doing) but in my opinion a more interesting question is if it should be done in linq at all. 
I think you are best off outting this in a stored procedure or defining a view for part of it. This type of query can be a little unpredictable on the database query plan side so having the flexibility to control the SQL might be important.
I think you need to negate your second where, finding rooms that are not booked. The date plus one might be because the input is converted to ole date, but that's a guess.
For as far as I know its looking for the room date with this filters. - numberOfAdults must be greater then zero and the capacity of the room must be greater or equal to number of adults and the number of children which want to sleep in the room. - The booking of the room must not be cancelled and the CheckinDate must be before the checkoutDate and the room must not be occupied. So both dates must not be in between the dates where the room is already occupied. then it must be ordered so the room with the lowest price must be first in the list. 
oke, then I must learn how to make a stored procedure. 
Using transactions is pessimistic locking, but handled by the database. Check out TransactionScope and its options. If that's not what you mean by pessimistic locking, I would probably need to have more details to understand to explain what I would do.
 &gt; * Writing Interfaces, classes etc. in one file and then extracting them to their own files. &gt; * Extract interface Vanilla Visual Studio 2017 does both of these.
Ah, find all references is something I frequently use. I just use my mouse though. It shows up above the method where it says "2 references" and I just click that. There is also a separate "Find all references" if I right-click but that's not as easy as just clicking hte references link directly on the method itself
Looks like you're mixing something up. `/signin-oidc` is a common path for an identity provider like Azure AD to redirect the user agent back to the application after the user has been authenticated (see OAuth 2.0 redirect_uri), while `https://login.microsoftonline.com/{tenent-id}/.well-known/openid-configuration` is the [OpenID Connect Discovery](http://openid.net/specs/openid-connect-discovery-1_0.html) endpoint of Azure. &gt; The Instance was the companies site and not the url of the application in azure. If the instance is not `login.microsoftonline.com` it's possible that you are actually connecting to an instance of Active Directory Federation Services rather than Azure AD. Both offer OpenID Connect endpoints but are different products after all. &gt; What should the instance be set to? If the `dotnet new mvc` command from the tutorial you linked works the same like the VS template wizard I used, you should have a section named `AzureAd` in your `appsettings.json` file. Mine looked like this: "AzureAd": { "Instance": "https://login.microsoftonline.com/", "Domain": "company.tld", "TenantId": "7a09aace-...", "ClientId": "2631890b-..." } Note that `Domain` could also be `company.onmicrosoft.com` depending on them using a cloud-only or hybrid approach.
What does that do? Is that for collapsing/expanding code blocks? I actually install an "I hate regions" extension or whatever so it autoexpands everything when I open a file.
&gt; * convert to expression body or statement body &gt; &gt; * you add a constructor member and in 1 click you have the property created and initialized Visual Studio 2017 does both of these.
Look into Dapper as an ORM You must also learn about indexing.
I do use it, and performance is a big issue as others have noted. However, I've found that by disabling "Extensions" that I don't use, it is dramatically improved in VS 2017 -- especially the visual studio unit testing module. Resharper has its own unit test runner, so you aren't going to use it anyway. Disabling that and others gave be back my IDE.
&gt; bugs where caused for literally no other reason than being a lazy ass Welcome to my world / team.
Pessimistic locking that we'd like to achieve is where two people cannot change the same data at the same time, whether they're using the same app/web page, or queries on the backend, batch programs or any other means of the data to be changed.
Ctrl+k+r if I remember correctly