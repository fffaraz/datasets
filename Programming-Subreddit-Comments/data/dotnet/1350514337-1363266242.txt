This is a bit misleading since you can bypass the restrictions by changing the GUI directly (.Net reflection or windows automation) or by changing the actual apps code (IL or ASM) And if the .Net profiler is used we can re-write the IL or Regit it
&gt; I chose to use SoftActivate Licensing SDK You made a tutorial which is essentially just a big advertisement for a commercial product. There are lots of .Net licensing components. I have used Intellilock by Eziriz and have been very happy with it. XEHO is supposed to be good as well. There are plenty more.
Nice, installed and using... Beware: it doesn't do the other windows, just the code window
Some colors in 2010 are either baked in or not configurable from the theme editor. As a result setting some backgrounds to black will make the text in that window invisible.
You guys are trying to make vs2010 look like 2012? Id love to have 2012 look like 2010. 
might also want to check into the web matrix websecurity helper class http://www.asp.net/web-pages/tutorials/security/16-adding-security-and-membership
Seems like he's advertising SoftActivate, there's another article submitted on this subreddit also advertising SoftActivate.
If you are working on completely new website - take a look on SimpleMembership http://weblogs.asp.net/jgalloway/archive/2012/08/29/simplemembership-membership-providers-universal-providers-and-the-new-asp-net-4-5-web-forms-and-asp-net-mvc-4-templates.aspx It's a future for asp.net membership framework. To add logins via social network - DotNetOpenAuth is good way to go. 
This is great, unfortunately it doesn't work with WebForms. 
Where does it say that?
Not going to evangelize too much - but as a .net developer who spent most of my career with web-forms I'd say MVC a chance if you haven't already. Going back to webforms seems like a punishment now. 
I think this may just have saved my ass... I had no idea how I was going to implement something like this.. anyone know how I would implement it with Js / ASP like so: &lt;asp:ScriptManager ID="ScriptManager1" runat="server"&gt; &lt;Services&gt; &lt;asp:ServiceReference Path="~/validatethis.svc" /&gt; &lt;asp:ServiceReference Path ="http://localhost:19124/WebSite2/GatewayAjaxService.svc" /&gt; &lt;asp:ServiceReference Path ="~/UploadNow.svc" /&gt; &lt;/Services&gt; &lt;/asp:ScriptManager&gt; and one of my WS methods: function uploading() { var theimage= document.getElementById(currentpatch +'throbber'); var selected = document.getElementById("version"); var theversionselected = selected.options[selected.selectedIndex].text; var PathToPatches = GetFullPath(); var uploadingservice = new UploadNow(); uploadingservice.UploadPatch(PathToPatches, theversionselected, currentpatch,onsuccess,onerror); ReplaceThrobberByID(theimage); } so how would I queue this so it receives postback when complete? for this part: uploadingservice.UploadPatch(PathToPatches, theversionselected, currentpatch,onsucess,onerror); Please help I will be so happy :D
See the [PageRequestManager](http://msdn.microsoft.com/en-us/library/bb311028.aspx) JS object. This event queue depends on initializeRequest and endRequest events. Sounds like you just need the latter.
PageRequestManager is a javascript object auto-loaded in asp.net pages. See [the implementation of AspQ](http://code.google.com/p/aspq/source/browse/AspQ.js) to see how to use it.
Ok thanks, up votes all around sir!
You can't use the browser control to do that. You need to use a webrequest to download the file programmatically, then parse it and display it however you want.
If you control the webserver as well, you can tell it to serve up the page as plain text instead of as a CSV file. But this is a rather brittle solution.
That sounds like what I did once before. Thanks for the reminder.
If you control the webserver its coming from you could program a special view page on the webserver that will read the CSV and display it in a table and then just navigate to that URL. And if this CSV is dynamically created from a table or view or query against a database, we can skip the CSV all together and just drop a datagridview on the page and bind the datasource of the datagrid view as the result of the query. If you don't however, you can use (new WebClient).DownloadString("url"); to get the CSV as a downloaded string and then convert it into a datatable and use a datagrid to display the results on top of the webbrowser control (or in place of if this is the only thing you're using the webbrowser control for) A third option is creating a local page that you can navigate to that uses AJAX to request the CSV and then you parse it in javascript and create the table or populate a table with the data through javascript. personally, I'd go with option 1 if I had control of the webserver, 2 if I did not.
It's good to see Mono making progress. I'm really curious as to how many people use it, and what for. I know for example it's used in Unity 3d but are there any other major projects using it?
Cool, curiously what do you use it for?
I feel mono could be a lot more popular if they had more up to date packages for the popular distros or if they maintained it them self. But I'm psyched to see how well the EF support is like. Having Entity Framework and MariaDB in mono just seems like a 2 hit combo to me.
The backed webservice of my pet project: http://johnluetke.net/911dispatch/app
&gt;Mono is also used for iPhone and Android development. Can be. Not natively or for free. 
Not to creep or anything but while I was checking out your project I saw your full name and it sounded familiar. Likely a coincidence but I googled, found your LinkedIn, and saw we have about 7 connections both being Minnesotans. Small world..
Stalker much? :P
Also it's not Google that uses it (there's no direct Mono support whatsoever), it was the makers of Bastion who built on Mono's (and MonoGame's) "support" for NaCL to make it run within its sandbox. 
Many thanks (and at least one upvote) to all who took the time to reply. The WebRequest solution has been found to be simple and successful.
Couldn't use just use a grid and data bind?
Looking to relocate? We are looking for SharePoint consultants, and it looks like you have have some of the skillset. PM me if Boston sounds interesting at all.
1) Start interviewing 2) Create a project that can demo the stuff you want to do at the interviews. This will also help with your skills. 3) Get out of there!
Are there any user groups in your area? That might be the easiest way to get "plugged in" to a group of people who **care about what they do**. The glib response is "get on github, start contributing to OSS projects", but that can be surprisingly hard to do for someone without unlimited free time. Attending user groups may only take up a few hours a month, but can pay huge dividends in networking, exposure, and plain old motivation. Once you do start looking for a new job, the best advice I could give is *find a place where your coworkers are smarter, more talented, or more experienced than you*. Being a "noob" can be a real hit to your ego, but being the most experienced person on your team can **really** suck, because you're not going to learn anything new unless you teach yourself.
I highly suggest using pluralsight to bring your skill set up to speed. I find their videos very helpful and often they go into areas like unit testing which a lot of developers haven't worked on. Then you can get into github scene and maybe contribute to a few projects. A github profile will almost always get you a job. PSA: I am in no way shape or form affiliated to pluralsight. 
Yes, I have found a couple of user groups and have been attending the meetings and training sessions. There's a local one that meats once per month, and another one an hour away that also meets once per month. I attended two all-day training sessions this month, one for new .NET related technologies and another for Windows 8 development, both having sessions presented by MVPs and well respected developers. It's exciting to be part of that, and there are always at least 2-3 recruiting firms there handing out their cards and swag. I guess they assume that if the devs are spending their Saturday from 8am to 5pm in training, then maybe they care. I've joined the Windows 8 development program and Microsoft provides great guidance to get an app into the store. I got my company to buy many books on the subjects that I mentioned as well as self-paced training for SharePoint and .NET topics. I'm starting to turn things around!
I do use pluralsight and like it. I have access to 25 courses because of my MSDN subscription. I may buy the subscription to get access to other courses though. Right now I'm focusing on Windows 8, MVC 4, and EF.
We're looking for junior and senior devs. Senior devs that can pass a phone screening have been non-existent. I don't think we have a chance there unless we're willing to use headhunters or recruiters which so far my boss has not been. Senior developers are so in demand in this market that they rarely ever make it to the open job market. The only way they move is by poaching more or less. As the economy starts loosening up, I expect that to change though. I think a lot of people have probably been wanting to change jobs but have been apprehensive with economic conditions. People are happy not to be unemployed right now, even if they're unhappy with their jobs. I know quite a few people in that position actually.
Yeah. We poach like crazy for mid - senior devs. There's no shame in it. If the company you are poaching them from didn't value them, then it's that companies fault. On the flip side, you have to make sure you have a good retention program for your devs.
Seriously, just go to another SIG meeting and just mention that you're a .NET developer now and looking to move on to your next opportunity, and you should be set. Just have an idea of what you want to get into and be firm about that and you should be right back on track. That said, if you're going to move on to a new employer who is possibly taking a chance by hiring you even though you may not have all the skills they really need, then be prepared to work extra hard to pick up those new skills. Self motivated learning is important; not sure there ever was a time in IT when it wasn't.
Bah. You don't need to do anything. A C#,SQL and webforms developer with 5+ years experience? Just update your resume and start applying. If you are competent in the slightest you will get a job, most likely doing newer tech. The market is pretty desperate right now. Also, have you tried mobile development? If you can put a hello world on an iPhone you can get a job anywhere. 
&gt; make every Friday a chance to keep your skills up Hands off my Friday evening! It's for relaxing after a hard week's work. But you're right: dedicate one night a week to development of software and yourself. For me it works like a charm and I try to learn something new every week, preferably something I don't have any experience in but that is related to stuff I know. Lately I took a deep dive into WebSockets, SignalR and HTTP/2, for example. Even if it doesn't aid you on the short term, it'll surely help you understand how certain techniques work and how to apply them when needed. I also benefit greatly from writing about things I've learned, be it in blog form or on discussion and Q&amp;A sites. It helps me to do a 'sanity check' whether I truly understand stuff, and perhaps it even helps others. 
I have some buddies in the financial sector that use it. With the continued incorporation of ASP.NET MVC into Mono and the insanity that is the current Microsoft, I can see more people moving their production code across the fence. That said, Mono gets most of its funding through selling copies of MonoTouch and, to a lessor extent, Mono for Android.
http://en.wikipedia.org/wiki/PlayStation_Mobile and https://groups.google.com/forum/#!msg/native-client-discuss/hHYJbE-IL2M/wURhemrkEWIJ
It only occurs in our production environment where I am unable to attach a debugger.
Out of curiosity, if you do something like: var myString = sectionOneDO.SectionOneRow.ACGMEFellowshipProgramName.ToString(); Then use Buffer = Buffer.Replace("ACGMEFellowshipProgramName", myString); Does it still fail?
And what exactly is that supposed to change?
In what way does it fail? The token remains unchanged in the document? As for strings, the Length property is int32 but I doubt you'd get that far before you got an OutOfMemoryException.
Add code that logs the error in the production environment? 
Correct, the token is left in the file after the function returns.
Unfortunately it it's a locked down environment, and we only do deployments every other month. 
If you are receiving no error, then your token is not matching exactly. Although, this 'sectionOneDO.SectionOneRow.ACGMEFellowshipProgramName.ToString()' seems to be a source of many headaches.. Since this is a production environment, it's possible that errors are just suppressed and you are just missing a NullReferenceException.
'Fraid I've only got it as an Outlook OPML file, but [here](https://dl.dropbox.com/u/126005/feeds.opml) you go.
wonderful, thank you :) My reader imported it perfectly. 
Remember System.String is immutable. So, every time you replace a token and concatenate the result a new instance is being allocated in the heap. Try using StringBuilder.Append(buffer.Replace(...)) instead of buffer = buffer.Replace(...) and it should address your issue. 
I'll add this might be a language/culture issue as well. Different cultures requires string comparison to be different. The production machine might be using a different default culture. Op, you might want to specify the culture in the replacement statement or use the string comparison options to ignore case for the invariant culture (can't remember off the top of my head if replace uses them or not). 
String replace is not culture specific. from the [MSDN](http://msdn.microsoft.com/en-us/library/fk49wtc1.aspx#Y0) &gt;This method performs an ordinal (case-sensitive and culture-insensitive) search to find oldValue. It does not take any string comparison options.
Yeah, I cannot wait to get it on Debian testing. 
i prefer just using SignalR for pushing messages to clients and doing queries using Web API.
It seems like with each new iteration of technology, Microsoft is going out of their way to make drawing in C# harder and harder. I hope someday we can see maybe the mono implementation of system.drawing ported over Direct2D instead of Cairo.
I see, thanks for that..
How many sites do you need to run, and how data-intense are they? I've got a few sites running on [AppHarbor](https://appharbor.com/) for free, but they don't get a ton of traffic and don't need much for storage as of yet. I haven't decided what I'll do when it becomes time to need more database storage / bandwidth yet, but if the site is just starting out or doesn't see much traffic, you can host them there in the meantime. I use my clients' servers for other sites, so I'm no help for private VPSes.
Yes Mono has Linq support with Mysql/Postgres. I've done ASP.Net MVC development/testing on Windows/IIS and published to a Linode Linux server using Mono and Nginx for production.
You can get a year free with Amazon Web Services when you sign up for a new account. It comes with a windows ec2 instance you can host your asp app on and a sql server instance. Use elastic beanstalk it's really nice. Their visual studio plugins are also really nice, one click deployment is super easy. Alternatively you can get 3 months free with a new Azure account. Though if I remember you said you have a few sites.. in that case for $20 a month you can get a linode instance and host nginx/mod_mono/xsp with a mySql instance on there. It's a lot more work to setup, and XSP isn't reccomended for production use (even though I use it for some production sites anyways.) There is no linq2sql for mySql without using third party libraries you have to pay for. Linq2sql is unfortunately abandoned by microsoft it seems, even though it's my favorite ORM. Lately I've been using ServiceStack's Ormlite to talk to my sql server and mSql databases. It's not as nice as linq2sql, but it's not raw sql all the time either so you have some static typing benefits. Good luck!
First of all, I promise that I am going to answer your question. However, I need to clear up a misconception first. LINQ is ***not*** a database access technology. It does not, by itself, wrap access to a relational database such as MySQL or SQL Server. LINQ stands for **L**anguage **IN**tegrated **Q**uery, and specifically refers to the ability to write SQL-like code directly in your C# code to perform queries over an instance of the IQueryable interface. LINQ **is** a data access technology, but it's built for performing operations on set-based data sources no matter what the backing store or data provider. It just so happens that the most common use case you find on the web when querying for "LINQ" is providing access to a relational data store using LINQ syntax. I realize that's unrelated to your question, but I've spent many hours breaking this misconception in junior and mid-level developers in order to get them up to speed on other technologies that are leveraging LINQ. The "LINQ is database stuff" mindset will really, seriously impede you in the long term, so please try and be mindful of that. Now, for your actual question. :) Depending on your usage, you can get actual Windows usage free or nearly-free from Windows Azure and AppHarbor. Honestly, if you've never hosted a web app in a Mono environment before, that's your best best. The integration of IIS into the OS and app flow makes setup and management of the sites much less configuration-intensive than trying to put Apache in front of a Mono-based ASP.NET app. However, if you're willing to spend time digging (and if your app doesn't use too much from the WCF libraries), then a Mono-based solution on an el-cheapo linux VPS will be cheaper for higher-usage applications. I hope that helps, and sorry for the lecture on the front end. ;)
Upvote for awesomeness.
Thats pretty cool man! Legendary
As well.
Only if you are using it against a database. Most projects I've worked on did not combine LINQ and SQL, only using LINQ against Lists in the model, or against XML.
sure but the OP wanted to know if there was MySQL support, which is a valid question.
Yes, but my issue is with the fact that 90% of the developers I've hired in the past three years have this erroneous idea that LINQ is a data**base** abstraction layer. It can be used that way, but that's hugely limiting what it's capable of and only thinking of LINQ in this light leads to locked-in patterns of thinking that completely hobble developers from comprehending other uses of LINQ.
Another vote for Facebook SDK. Facebook's API updates frequently enough it's not worth coding directly against it when you have a few well-tested, actively maintained packages for doing the same.
Make it work with 2012! :)
I downloaded it and installed it. Didn't work for me. When I search, the plugin didn't do anything.
I just installed the plugin. This looks interesting. I was just frustrated by the poor functionality of the default search in VS2010 yesterday so this was good timing for a replacement candidate. I'll give it a whirl for a few days and send feedback.
If there is it would be an options file import rather than a plug-in. Your best bet is to do the mappings and export the options. Then import them whenever you re-install. Options don't normally port between versions however.
I would give it a try, but currently am working on a project entirely written in VB.NET Any chance for VB support? 
So I can't test it because I'm on VS2012 and do mostly VB development, but I do have one feature suggestion that I have always thought would be super useful for a search tool. Sometimes, when searching project or solution wide and using find next, it would be nice to have the ability to "step out" of a file. For example, sometimes I'll be searching for something in an MVC project and the query will happen to be used in a javascript library. So I'll have like 30 hits just in JQuery and JQuery.min before I get to whatever is relevant. Anyway, I always thought that would be a convenient search feature. Good luck with your extension.
Didn't work for me either. Definitely had a solution open. I manually opened a file containing the word I was looking for, searched again, no results. It seems that it is not searching at all. VS2010 SP1Rel w/ these extensions: ReSharper, VsVim, VsColorOutput, NuGet, FSharpRefactor, and F# C# MVC 4.
Sorry this didn't work for you! Let's see if I can figure out what is going wrong... What type of file did you open? Was it a C# file? Sando only searches C#, C, C++, and some plaintext files (e.g., xaml). Was there a message just below the search box? It should say either 'No results found' or 'Still indexing the solution...'. What was the search term like? Was it a complete word (e.g., file) or was it a method name (e.g., openFile) or a regex (e.g., open*)?
emailed!
Post it on the internet with a title of "Best Practice for Using XYZ" and wait for people to blow you to pieces.
Best laugh today.
Just based on the fact that you're asking this question, I'm sure your code is better than a **lot** of people's code. From my experience, people that write bad code don't ask this question :) You could always post it here or on TheDailyWTF's [Coding Help forum](http://forums.thedailywtf.com/forums/19.aspx) (to ensure your code doesn't end up on that site :P)
Wow, there are some really scathing comments on there. Made my Friday morning.
Oftentimes when using a new library or api you do things the roundabout/hacky/stupid way because you just don't know better yet. He's a good coder for knowing that he probably did this, but the code probably still sucks.
By the way, I just wanted to point out that I recently switched from a Linq-To-Sql solution (with custom code-gen) to Dapper. The performance improvements have been AMAZING. Memory usage is about a third of what it used to be, too. 
code.google.com supports peer review, but you'd have to have a peer reviewer still. 
Good time to mention that parametrized queries are your friend. 
Dapper has been on here before, it's amazing. I use Dapper and I'm absolutely in love with it. If you do any ASP.NET MVC, be sure to check the mvc mini profiler (written by the same guy that wrote dapper) http://code.google.com/p/mvc-mini-profiler/ It will do a few things, but also spit out the the sql query + time it took to load via dapper. This really helps with trying to debug performance issues. 
By Sam Saffron, [former StackOverflow employee](http://samsaffron.com/archive/2012/06/14/leaving-stack-exchange).
Really!? What sort of hosting options do you provide? I am willing to pay either way
Shared Hosting .Net 4.5 or .Net 4/PHP/Coldfusion Access to MySQL/SQL Server Nightly backups I don't have an official SLA, but I averaged 99.93% uptime over the past year. If you need/want a dedicated server I can spin up a new VM for you.
Man Dapper is great when you want something that a lot more lightweight than the usual suspects.
Are the slides available?
I would also suggest reading the small print. They say it'll be free for 5 or less MSDN users and at the moment you can actually have more users without any charges. Build is also included at the moment. However, they mentioned they will detail fu pricing next year which will then limit users and potentially remove the build options unless you pay!
Do you like TFS source control more than Git? Which version of TFS?
For me the biggest pain point is the inability to link work items in a meaningful fashion. The links are not actually honored by the system for prioritization, stack ranking, or anything else of importance. But since JIRA, Bugzilla, and ClearQuest all have that problem there isn't much I can do about it besides custom plugins.
TIL, thanks for the links.
The team building TFS is tiny in comparison to their goals. Each aspect (version control, task tracking, build, etc.) only has a team of 6 devs, 5 testers, and 1 or 2 PMs. They just don't have time to build everything they want. http://www.infoq.com/news/2012/10/TFS-Release-Cycle
Thanks
You should post the actual code
Hi, this is fantastic, but the site seems to be down at the moment.
What made you choose PetaPoco over the others?
I wanted to work with POCOs, so Massive was out. It was down to PetaPoco and Dapper at the time, and I preferred PetaPoco's style.
throw in a regular expression which would force all non alphanumeric characters to become underscores..
Where are the files downloaded to? I thought they would go to the folder where the script is but I can't find them.... 
just use http://dayngo.com/channel9
Check this for some ideas: http://www.codeproject.com/Articles/473278/Creating-Secure-Trial-Versions-for-NET-Application 
This is as far as I know the only option for cross platform apps. But speed wise it's not great, right?
Why not mono/xamarin? You do have to buy a license if you want to deploy, but for emulator/simulator it works great. With mono/xamarin you won't have to compromise when it comes to userfriendlines of your app. Although you will have to learn how each platform handles it's application lifecycle and how to build interface for each platform. Although you do need to think about your design when developing with xamarin otherwise you may have little of re-usable code. http://xamarin.com/ edit: Oops, I've misread. The op said "...besides C#..." consider this comment void :P
We have developed a few mobile apps with PhoneGap and the Kendo UI framework from Telerik. Performance is WAY better than jq mobile - if done right you'll see almost 95% of native performance (especially on modern devices).
No problem, best of luck. Feel free to drop a message to me if you need advice.
Something as simple as a chat window doesn't work well cross mobile devices as scrolling inside a div set to overflow is handled differently. There are random hacks but nothing that great. There are other things too, like how would implement a FaceTime like app with html/javascript, or make an openGL game.. The kind of application you plan to make is what drives your available choices development langauge and API for each platform.
If I had to write an app for either platform I would want to use the recommended frameworks and tooling available for both. I just don't trust that other solutions (Xamarin, RubyMotion, etc) are going to be supported for the long term. For rapid prototyping and easy requirements PhoneGap/Cordova is a no brainer as it easily allows for native extensions if required. For anything more complicated stick to the native tooling.
Xamarin recently picked up $12 million in VC money and combined with their existing customer base, should be in good shape going forward. 
This is not the case when they're on 0. 
`return Knockout.js + websharper + f# == profit ? false : false;`
We have been using xamarin (novell) monotouch and monodroid for more than 3 years. It has not always been a smooth sail, but the tools today are mature and well supported. You can check out the galery of apps on the xamarin site. Also keep in mind that the unity game engine is based on mono. You will still have to do some 20-30% per platform coding the rest can be shared. I would take the powerful and extensive .net library and the c# language over hacky javascript frameworks any day.
No probs. I've been a .Net web developer for 12 years and I agreed with everything you said. Maybe someone just doesn't like helpful answers.
Keywords are "Right now". And yes, if your bug can be repro'd and enough developers form a reasonable consensus on why it needs to be fixed then you can bet your ass it will be getting fixed asap on a native platform.
I wasn't aware of this. That's definitely a good sign for the community.
&gt;Page Not Found &gt;We're sorry, but the page you requested could not be found. Please check your typing and try again, or use the search options on this page. I tried, but it doesn't work. The "article" you linked to is nothing but fluff with a broken link to the actual article.
Opps, you're right (that was stupid of me, sorry). I just fixed the link (which got mixed up with the one from VisualStudio galery). For reference the linked article is: [Real-time Programming C# WinForms Controls in VisualStudio's IDE (i.e. without using F5)]( http://diniscruz.blogspot.co.uk/2012/11/real-time-programming-c-winforms.html)
&gt;but I can't think of a situation where you'd need dependency injection For plug-ins you do. Well, you don't *have* to but it's not really a plug-in system if you have a switch/case somewhere to do that.
I'll give it a read.
Tried it? (curious)
Is that so? I've never heard anything about a special rule for the first negative point of karma to be counted accurately and the rest to be vote fuzzed. My explicit understanding was all votes were vote fuzzed and you had absolutely no way of discerning what is and isn't a downvote without administrative database access. http://www.reddit.com/r/AskReddit/comments/if7cs/reddit_psa_the_up_and_down_vote_counts_you_see_in/
That's the thing though, it doesn't show the current ratio. It doesn't show the current anything. If you could guess the ways in which the numbers were obfuscated, or they were obfuscated with any kind of consistancy, then there wouldn't be a point in obfuscating them in the first place. I'm certain there is at least a pseudorandom element to it, and while it's entirely possible that the number influencing doesn't take effect until after a downvote is actually cast, it's just as likely if not more that it begins at the first down or up vote cast - or that the obfuscation implementation does not hinge on random users upvoting or downvoting. All I know is that those numbers are meaningless.
Back in 2009 I did, not that I remember anything useful now. Why are you two versions behind?
Thanks man, I wish the others who went to that page also had complained (so that I could had fixed it sonner)
Can't tell if you are being sarcastic or if you accidentally used "embarrassing" instead of "embracing". 
Someone's gotta do it.
I have very limited practical knowledge of serialization, so sorry for asking a perhaps very obvious question here: Why?
The idea is that your model only exposes meta-data about your fields. External APIs using that model should convert the model to the desired output as they are generally closer to the transport (the wire). For example WCF uses reflection to introspect your model and convert it to SOAP XML or even JSON all with configuration, you don't need to write any special code. Meanwhile you could take the same model and stick it into a back-end component and have it consume and work with normal class serialized data (a convoluted XML schema used by .NET or binary) or some any other type of serializer without ever touching the model. This works because of the serialization classes provided by .NET and multiple decorators you can apply to the model to ensure proper serialization (decorators are not required though some advanced patterns are available when you do use them). Using reflection serializers can use the meta data to serialize any type and there is a standard interface through which the serializers populate you model and transform it to a desired output. Extension methods don't work for this as they may be in another library or referenced else where. This would require a sterilizer (like WCF) to take extra steps to figure out where your extension method lives and if it is accessible, it would also require some extra meta data on the model itself that would likely end up being implementation specific. That all said. Like I mentioned in my original post, this pattern is not entirely invalid and I could see some uses for debugging or testing scenarios where you use the extension as part of a shared unit test library rather than a production library. You might also end up doing this kind of thing if you have little control over your models and they are missing key meta-data or do not meet the requirements for serialization (google protobuffers come to mind here) and you don't have a lower level interface you can use to wrap the object. In these cases you may want to use an extension method in production simply because it is just about the only to get what you want and keep the code in a reasonably maintainable location. Finally sometimes you just want to short circuit something, perhaps a framework you are using does something post serialization that creates an erroneous output but also allows you to just dump text on the pipe (WCF and Spring allow this) you can use an extension method or an alternate sterilizer to output directly to the pipe in your desired format. TLDR: The serialization patterns used by .NET (and Java) are designed around keeping the implementation concerns of transforming a model from bleeding into the domain model itself and provide a standard interface to developers for transforming models. For more information : [.NET Serialization](http://msdn.microsoft.com/en-us/library/7ay27kt9.aspx)
This looks amazing, thanks.
Absolutely, yes.
Will take a look - looks amazing!
"Beta has expired download newer version." Which takes me to a web page with a link to download \*`drumroll` the Beta version.
Hi - I think your Windows clock may be Uber fast - the beta times out 2 weeks from now, on the 25th. It looks like the problem is specific to you so I'd recommend adjusting it in control panel. Thanks for trying though!
Nothing a little reflexil can't fix
[Hmmmmmmm](http://daniarnaout.com/sites/default/files/Blog%20pics/new%20PC/hd_computer_guy_meme_by_zapgod16-d4t2jh3.png)
Sure - its the app stack trace so totally internal to the app. It only references schema object names when it is getting size/fragmentation meta data, it never selects any data from a schema object so your data is quite safe.
Regional date/time setting problem? Some unfortunate date to string problem?
Can you download a trial version just to run the graph tool?
You really need to move to a plug-in type architecture. Someone needs to log their continuing ed credits? Ship that DLL with the product, otherwise don't. You can try NDepend to try to sort all of it out in the meantime.
Yes, but with this technique it is possible to script WinDbg/SoS/Cdg in a C# REPL environment. i.e. I can write a C# script to batch execute SoS/Cdb commands and view/filter the returned data
Which do you recommend?
Actually, I really like doxygen for doing this.
I would prefer not to post this kind of empty-feeling comment, but in this case I need to make an exception for the benefit of those who might visit the linked page in an honest search for answers: the linked article is missing so many things in its UI testing, unit testing, and load testing sections that they simply should not be used for reference. It is also missing obvious sections like stub/mock/fake/etc libraries, alternate test runners, etc. Posted two weeks ago, the article was published half-baked and is unlikely to receive improvements to address the above. I would advise the curious to google for better round-ups, of which there are numerous.
NCrunch. That shit is bananas. http://www.ncrunch.net/
Nifty trick that I actually have a good use for. Thanks.
Did they finally upgrade/promote/depricate moles? I only played with early releases, but agree: powerful and a PITA to set up...
Yes, Fakes is, basically, Moles 2.0. 
Thanks, I was looking for a specific proof of concept video that had been posted on this subreddit. 
I use ghostdoc while I'm coding. For a full document after-the-fact, I use doxygen.
My apologies. The extension manager is a nuget based service iirc.
I found this: [Code perspective - video] (http://www.youtube.com/watch?v=s3Y06R4d3F8) [product website](https://www.codeperspective.com/) edit: tired...
ReSharper. It's kind of expensive, but worth every cent. TestDriven.net is also extremely useful for me. Edit: To the guy who said ReSharper is too slow... maybe you're on an old 8086, but my rig runs it flawlessly.
Expensive? The C# version is only £110 (GBP) for a single developer licence. That doesn't feel at all expensive given how much time it saves. It's more expensive for a company (£184), but still totally worth it.
[Productivity Power Tools](http://visualstudiogallery.msdn.microsoft.com/d0d33361-18e2-46c0-8ff2-4adea1e34fef) The scrollbar replacement that displays a zoomed out version of your code is extremely useful. I can't use VS2012 until the same functionality is ported over.
Resharper, Mighty Moose, TestDriven.net, Nuget
Now that I've been using resharper for many years, using VS with it feels like trying to wipe with the opposite hand...
Actually, it's a quad core xeon.
I recommended it, but I do agree. It's even more fun when you name something like PageGetSize() and it returns -&gt; "Pages the Size of the Get". The fuck? Lately I've just been sticking with the standard /// comment VS gives you. 
Find Usages (of any method, variable, property, etc.) Go to Implementation (lists implementations of an interface or abstract class, virtual method) I can hardly live without those two.
VsVim. After multiple failed attempts at learning vim, with VsVim I finally beat the learning curve. I attribute that to being able to rapidly disable VsVim when it got in my way.
This one actually keeps messing with me. I use keyboard shortcuts with my left hand (Ctrl+ C, V, X, A, etc..) and mouse menus/actions with my right hand. I keep accidentally sending myself off to the method/class definitions when I try and copy something in the editor. 
[It's been ported](http://visualstudiogallery.msdn.microsoft.com/3a96a4dc-ba9c-4589-92c5-640e07332afd) over to 2012 :)
Older versions of R# had some pretty bad performance issues, but more recent versions have definitely improved it. I'd recommend giving it another shot if you haven't tried it lately. 
Off the top of my head... note, I haven't used some of these in a while so not sure how effective / current / in vogue they are. mspec nbehave ncrunch mighty moose storevil specflow testdriven.net phantomjs jasmine NCover dotTrace dotCover ANTS Memory Profiler ANTS Performance Profiler
A colleague uses ankh svn. Visualsvn is so much better. I encourage you to check it out, so to speak
I kept disabling features in it trying to get it to stop lurching my Visual Studio until finally I had to just uninstall the whole thing. I was also let down that neither Visual Studio 2012 nor Resharper gets me true code completion in Javascript - but at least 2012 runs well on slower CPUs. Resharper will never be on this dev machine.
Still slow.
I remember back in the day (last month) when it was free.
Stylecop, lovely to have everything in a project multiple devs are working on all formatted the same way.
I have Mighty Moose set up to run only affected tests. It's nice to just right-click on a project with testdriven.net and re-run all tests for that project (or file or whatnot). Mighty Moose's debug test doesn't work for me whereas testdriven.net's test with debugger does. 
Love CodeRush and Refactor Pro!
I had it all through the trial but don't miss it enough.
Yeah, I do find the fact that a personal license is $80 less than R# a bit, uh, aggressive of a price, but it's a super useful tool. Ctrl-U, L isn't that hard to pull off, but seeing things go green or red as I edit code without my doing anything is even easier to pull off.
Hmm didnt know about the personal license, that might just about swing it
Unfortunately yes, it is still very slow. The problem seems to be at it's worst when a project has a single "huge" file. For example, our sass compiles into one hefty css file (~7000 lines). When I get annoyed with the slowness I check and yep, it's stuck processing that file. Removing the css from the project would help, but then I get less autocomplete in html.
I have the same problem and am glad to see it's not just me.
Scumbag boss: Spends thousands of dollars on new software, skimps on machine.
Dude, we don't even get a 2nd monitor (well we gotta scrounge ourselves, the company has no procedures for 2 screens, so it's all about survival of the fittest and stealing someone elses screens when they quit or whatever). 
I feel ya, bro. I feel ya.
I have used it at home and on 2 different work machines. It most definitely slows down all of them. My dev boxes are extremely powerful, as I have to run Biztalk Server on them. 
Yep, vsvim taught me the way of the vim as well. 
[JustCode](http://www.telerik.com/products/justcode.aspx). It's like Resharper, but a lot lighter on my machine, and it doesn't feel sluggish. Also, it doesn't clutter the UI, so it really fits my style.
It is funny trying to first get 2 monitors. You need to get the people with purchasing decisions to try two monitors for a month first, then take it away. Bam approved. I wouldn't have thought my productivity would have gone up with 2 monitors as much as it did until after I tried it. Still miss the 3 monitors plus a 2nd computer from my home setup, but at least with 2 I don't feel like I have one hand behind my back.
Visual Studio Productivity Power Tools and DPack (for incremental search of files in solution and incremental search of members in a class)
I tried it once a year or two ago, I don't remember why, but I didn't like it as much as viemu. What do you prefer about it? I might have to give it another shot. 
I'm using 2012 now so I've just gone back to the basics: Resharper, Productivity Power Tools, and [VSCommands](http://vscommands.squaredinfinity.com/features). VSCommands doesn't seem to be mentioned here but it has some nice features, all minor but very nice to have: Highlighting in the output window makes it easier to read; there is protection against accidentally dragging a source file into another project, which I seem to do far too often; it will list the current branch that you're working on in the 'recent projects' list and the task bar popups. PS: re Ghost Doc. I hate projects that use it. The documentation is worse than having none at all.
I've only used it for a total of about an hour, but it seemed to play better with resharper, &amp; the integration between visual studio's copy/paste &amp; selection seemed a bit more polished. I haven't tried any more advanced features like macros yet, but maybe I'll get a chance this weekend. For now, I'm still using viemu on my main machine.
I tried that out and liked it a lot. Just not enough to buy it when I already had a resharper license. If I didn't have the license though I'd be all over it.
The color-tabs-by-project feature is pretty in 2012 :)
Yeah I use it. It's pretty boss for debugging.
[SonicFileFinder](http://www.jens-schaller.de/sonictools/sonicfilefinder/index.htm) is great for really large solutions.
Even better than Find Usages, the [value tracking](http://www.jetbrains.com/resharper/webhelp/Code_Analysis__Value_Tracking.html) is awesome. Try it on the param to a method.
Convert to LINQ expression is probably one of the best ways to wrap your head around LINQ, as you are learning it.
VSCommands is great. Edit Project/Edit Solution is super awesome.
VisualHG is pretty indispensable, and Configuration Section Designer makes writing your own configuration files _much_ easier.
I haven't quite figured that window out actually :)
Hi! Thanks for giving VSCommands some love! I'm actively working on new features so if you have any feedback or suggestions than do let me know at jarek@squaredinfinity.com. Cheers!
 GC.Collect()
The first thing you should do is find if the memory has any rooted references to it. If it does, you (or the SharpNLP library) has a memory leak that needs to be solved. If it does not, then the memory is eligible for collection and will be discarded at next GC. The GC will be triggered based on heuristics, which does include system low-memory conditions, so in most cases the memory use shouldn't be a problem and will go away on its own. As NonNonHeinous suggests, you could manually call GC.Collect() to force the garbage collector to run immediately, but there's little reason not to allow it to reclaim the memory when needed by itself. David Anderson has a good blog post detailing how to determine if an object is rooted using WinDBG, the SOS debugging extension for managed code, and the !GCRoots command. http://blogs.msdn.com/b/delay/archive/2009/03/11/where-s-your-leak-at-using-windbg-sos-and-gcroot-to-diagnose-a-net-memory-leak.aspx . !DumpHeap will tell you how many of each type of object are in your heap, so with it your leaky objects, if they are there, should stick out.
I'm not familiar with Productivity Power Tools. What does it do, that ReSharper does not? I just tried installing it in VS2010, and only noticed the colored tabs (didn't figure out the color scheme, is it most recent to least used?).
VS 2010? 2012? What extensions? It's almost always a rogue extension for me...or TFS... or database projects... or WF projects. *Sigh*
The biggest question is, did Windows find a solution to the problem?
I get this about 3 or 4 times a day. I figure its resharper doing it. I'm a sucker for extensions.
Lose*
CodeRush caused my 2012 to crash every single time I did ctrl+. to import a namespace until I upgraded it. Drove me absolutely insane!
Are you using ReSharper?
Are you using a poorly written control library that break when you open the form in the designer? Like Infragistics?
Right?! Mine happens all the time! I figured it was cause I had so many files checked out. (Seems to happen when I have a ton of files checked out from Visual Source Safe)
Stop using ReSharper, the productivity increases it provides get conteracted by the slowness and crashes it causes
Funny, I was about to recommend if you're using TFS... REMOVE IT!
Most of my office is using Git, but there's another team that's using TFS still. I had to merge some projects across for interfaces and transport objects, and apparently some latent TFS bindings were causing Nuget to spontaneously combust and take the IDE with it any time I made changes until I removed and re-added the projects to the sln file. That little problem wasted most of yesterday.
We have a rule that if it happens after 2, you get a beer.
Try Code Rush, it tends to be more stable. (but of course you have to relearn all the damn short cuts again.)
Remove it from vs 2010/2012? :/
I hate vs 2012 anyway...let's play hide the buttons, that we also changed the icons for.
Schema compare makes my quad-core, RAID-0 SSD beast of a workstation seem like a crappy old junker.
ReSharper will strain a powerful machine on larger projects. It runs on a great machine but not exactly at lighting speed.
Way better display of the results. That and a ton of other features.
Their server product is super easy to use but I found AnkhSVN overtook them in terms of best SVN too for VS.
Disagree. R# is solid for me
Yeah I already contacted you via twitter :)
You can change the colour scheme settings in the options. I normally have it on by-project colouring.
Done.
Thank you very much for this. I'm currently working on a project where our application will have 2 versions, a standalone and a server version. We're looking into using the embedded version of Firebird for the standalone one and then use server version for the server one. How easy is it to switch between the the two Firebird versions? Is it just a connection string switch or are there other things we should look out for? 
This
Leave. It's a sellers market and you're worth more than that. 
OP will surely deliver!
I have [this](http://cdn.memegenerator.net/instances/400x/23384893.jpg) all queued up and ready to use... so... we just have to wait...
Mono?
Yeah, I was disappointed by the lack of TFS/Codeplex option, particularly for .NET development. When doing Visual Studio development, my preference is TFS, then Git -- strictly because the Git tools on VS aren't as awesome as I would like and I like integrated source control. When doing anything else, however, Git all the way. 
I see TFS gaining more ground with respect to open source in the future, especially after reading about their currently (maybe not later) free service: http://tfs.visualstudio.com/ I will explain why I left it off when OP delivers.
I think small specialized projects are great. When I need a specialized XYZ widget its great to just go grab one, especially with nuget. The problem I think with small projects is that when that widget is missing some feature you need. Ideally you would just add that feature but I think that is a learned behavior most of us don't have, for both the project maintainer and the potential contributor. My experience with software development is that when you find a problem or need a feature you file something in an issue tracker and cross your fingers. I'm trying to change this in myself and feel that others may also need something of a road map. I watch my friend contribute or discuss things on node or ruby projects like its nothing and nobody will mind. I can't imagine just hopping on over to some library X and just contributing out of the blue. I have some kind of mental block against it, like it feels wrong without actually knowing the project owner. For me anyway if that project had a prominently displayed guide laying out how to contribute and explicitly encouraging me to, that block would go away. Most of these small projects (mine included) just have a license file. It may just be me but I don't think the other ecosystems have this problem. Another issue I think is money. I haven't e-mailed many people but so far when trying to collaborate with others on their open source .NET project the issue of money always gets in the way. More power to you, get what you deserve and all that but if you are worried about me contributing to your open source project because it could affect your revenue IF you could someday sell it I won't go through the drama to do so. In some other ecosystems it seems to me that it is a given that any open source project will only have money tied to it through support/services. Because of the money thing I have noticed a trend towards a more go free or don't attitude among developers who participate in these small and specialized .NET open source projects. Myself included, it seems people are getting tired of the whole "this is free software for personal use but I can sell it if I want otherwise" stuff. Hopefully this shift will help with collaboration on these small projects.
I haven't had good luck Telerik's controls, but JustCode is the shizzit.
I think that's very much my issue, too. In "actual" open source land there are a lot of projects with large communities where they can offer mentors and have special tasks cordoned off for people just getting started on the project. In most of the .NET projects I've seen, there isn't as much of a huge community and there aren't necessarily any obvious points of entry. As you say, you just have to kind of jump in and pretend you know what you're doing. Which is what makes me kind of hesitant. Though very often I find a small and kind of neglected library that does almost exactly what I need, so I take that library and build out the enhancements in my own project instead of building it in to the library and giving it back to the community. I think I'll start doing more of the latter from now on.
ServiceStack, OpenRasta and FubuMVC, NuGet, SignalR, NancyFx, Simple.Web IMO are some big, sizable projects if you want to look into. There are also a ton of smaller (but just as active) projects for the various testing frameworks, micro ORMs, etc. 
Actually, we've been running our prototype on the embedded version for quite some time now. What we haven't done is to switch it over to the server version of the database and I was wondering how easy or difficult it will be?
1.Install firebird , start the service 2.modify the connection and add username and password 3.remove ServerType=1 you can use it without password on step2 if you use windows authentication 
The VS plugin ReSharper supports plugins? Yo dawg...
Hmm, installed, restarted but just tried adding nunit to no avail. :-/
Attach to IIS is a god send.
Maybe, but VisualStudio's model for extensions and addins really promotes VS crashes. All you need is an unhanded exception to bring down VisualStudio (and this could happen on a method that was invoked from a VisualStudio callback which would bypass any global error handler that a particular AddIn could have)
API: Application Programming Interface. You'll write these, or consume them within your applications SDK: Software Development Kit. This is a set of tools you'll use to help you write applications IDE: Integrated Development Environment. This is the tool you'll write your application with. Something like Visual Studio or Eclipse
All of this: [What are your visual studio addins you don't know how you've ever lived without?](http://www.reddit.com/r/dotnet/comments/137dbp/what_are_your_visual_studio_addins_you_dont_know/)
I always get that when working with WF designer.
[ASP.NET MVC uses routing](http://www.asp.net/mvc/tutorials/older-versions/controllers-and-routing/asp-net-mvc-routing-overview-cs) which means that the address is really just pointing to a controller (maybe named HomeController?). Check the global.asax file in the root of the project. **Edit:** Meant global.asax, not .ascx
This is why I love Reddit...an honest question is answered forthrightly. Just one more thought: Is there a possibility there once *was* a home.aspx file? As type_checking, Cwiddy and realblackperson all point out: The global.asax file will tell you for sure if this is/was an MVC site; if it isn't, then you may want to check some backup tapes...jest' sayin'...
You may also want to check for a URL rewriter somewhere in the project or inside IIS.
I have a guess... Are you sure it's not using dotnetnuke? DNN isn't MVC, but, it always refers to a "Home.aspx" as your home but only has a default.aspx file in the directory.
It hurts my eyes.
If this is MVC3 Check the Global.asax file for the route.. I have done a similar route in the past to mock a PHP file, it looked something like this: routes.MapRoute("PHPRoute","phpfile.php", new {controller = "File", action = "Action"} ); The important information to look for is a "Controller" and "Action" they will point you to the correct place to look.
Should I be waiting for SP3 again?
Sweet
Unless if you're using silverlight, ria services and entity framework...ef didn't update properly...sl/ria deployment was nightmare in prod machine...end up going back to 2010.
I have had no problems working with EF5 in 2012. Is this only when using EF and RIA together? Silverlight? Who uses silverlight? (j/k) 
Any word on where an update for the VS2012 **express** Windows Desktop edition can be found?
Do you have any examples of the use?
Doubt it, my problem was VS 2012's EF seems to be updating non-nullable field to nullable when I refresh the schema (by refreshing or adding new table). I 'fixed' it by turning off update property facet. Probably would still be using 2012 if not for the deployment problems :)
I think generally its best to put it in a separate class so you could, in theory, change the data storage medium without breaking the controller
What I've done in the past is leave the controller relatively clean and build a "back-end" library to call as a service (using the repository pattern with a data access layer). This makes it relatively easy to unit test all of your logic up to the DataContext, and it keeps your application modular enough for long term maintenance and growth. 
I work on a large enterprise MVC application, we went the Service Oriented Architecture approach. Our app talks to a layer called the "IServices" layer. This layer communicates only to WCF services through dependency injection (Unity, Structure Map, Ninject etc). We create one implementation using Moq and one implementation using the actual service call to facilitate Unit Testing. Typically you unit test the controllers using the Moq implementation, unit test the IServices using the actual implementation and integration test the controllers with the IServices. Depending on the size of your application and how much "business logic" you like in your app, you could place a IRepository pattern in-between the IServices and the Linq2Sql. The IRepository layer would use Linq2Sql, Entity Framework or NHibernate to perform CRUD operations. And the IServices layer would use the IRepositories to perform business operations. In this approach you don't have a WCF layer and have very tight coupling to the db you are working with, however you will probably have a faster time to market. IRepository example: http://www.asp.net/mvc/tutorials/getting-started-with-ef-using-mvc/implementing-the-repository-and-unit-of-work-patterns-in-an-asp-net-mvc-application A really great read is Pro MVC 3, covers most of what I talked about and general good architecture for your MVC apps: http://www.amazon.com/Pro-ASP-NET-MVC-3-Framework/dp/1430234040 
&gt;At the moment I just use LINQ to SQL to add data to my Viewdata Model and using that in the view. Are entities getting passed to the view? If so that would be the first thing to change, create view models. &gt;This results in my controllers getting bloated once I start really needing to perform any logic with the data. What are the getting bloated with? How repetative is the code? Moving common things out to services and/or extension methods, that might be enough. &gt;Right now I'm just displaying data from sql server, but in the future I need to update it as well as perform validation on the data being input. If the complexity warrants it then read up on the command pattern, commands/queries end up being a specific view models.
I've never used the repository pattern, but I've looked into it a little at work today. Can you manipulate and change the data with the repository pattern? The one I saw today only used the repository to display the data.
You know, I wasn't really following what you were talking about, but I looked some things you were talking about up and I think I kinda know what you mean. Everything besides WCF is what I was looking for. I'm not really sure what WCF is, even after just reading about it really quick, but this app is only on an internal network, so I don't believe I'd need WCF? I don't know. I'm looking at the repository pattern example and I'm pretty sure this is what I was looking for. Thanks, I'm still a newer programmer, you really cleared a lot of things up for me. I have a book for pro MVC2, is that decent enough?
you shouldn't really access SQL via the controller, the controller is for handling requests in the UI and controlling the flow of execution. Generally you should apply SOLID principles when designing anything unless it's extremly small. In your case, your question is solved by thinking of the "single responsibility" part of SOLID. basically you should have a sperate set of classes to handle data access and sending any entities to the controllers to display. I saw PRO-ASP.NET MVC mentioned in another comment, it's an excellent book that will teach you how to design an MVC application of medium size to near enterprise standards.
When was the last time you changed data abstraction layers in a project after it had gone live?
[http://imgur.com/UbZVz](http://imgur.com/UbZVz) In the screenshot I have two test files, Test1 and Test2 which are quite similar. First, I'm listing the keys that they share. Then I'm looking for keys which are present in one file but not the other. I find "Test_key_4" in Test2 that is missing in Test1 so I copy it over with --copy-missing-keys. See the --help output on the github page for a list of the other features. I've been using it for finding missing keys or keys which haven't been translated (--identicle-values) between different resx files. I also like keeping my resx files alphabetised with -a. 
Thanks, good catch. I'll fix that over lunch. EDIT: fixed
I haven't read that one, but any reading you do will benefit your growth.
WCF is just a more modern and flexible version of web services. Wrapping your data access in a generalized service could be useful if you had multiple consumers, but if you don't, I'd say code directly to L2S and worry about adding a service front-end when the need arises. As others have pointed out, Linq2SQL already is a repository, and it isn't a clear-cut question as to whether there is benefit to putting another repository on top of it. To me, this comes down to the complexity of the queries. A simple lookup by ID is already fairly abstract. You're describing *what* you want, but not specifying *how* to get it (i.e. create a SqlCommand with this parameter and map the results into this class). To me, this means that it could be included in your controller without breaking the single-responsibility principle. That said, if you start coming up with Linq queries with multiple joins and complex projections, you've stopped specifying *what* and started specifying *how*. Queries of that sort should definitely be put behind a layer of some kind (often times simple extension methods off of IQueryable&lt;Patient&gt; work and are quite testable), since they involve a lot of domain knowledge that you don't necessarily want leaking into your controllers. The inverse problem, of course, is writing aggressive repository layers which end up leaking details of your business logic into your data access code. It is important to watch out for both.
IServices tier is an implementation of command/executor. 
Additionally, if you're writing software to sell to many companies, you might want to support multiple backends. This way you only need (at most) n number of data access layers for n number of backends, which IMO is going to be easier to do than n number of controllers.
It's also a great way to make your code easier to unit test. You can inject mock repositories (or whatever data access pattern you use) into your controllers and other classes needing data when doing unit testing. It's also powerful for fitnesse testing when you want to use a static XML dataset over the built in service or database. Finally I often see stuff that was once a direct DB query getting pushed into service stacks behind the corp firewall allowing easier configuration of network security between the DMZ and the backend data store. Being able to swap out your data access is very powerful esp if you use something like unity where you can change how things are hooking up via mere configuration. 
I highly recommend implementing a repository pattern with MVC. I have used them quite extensively with MVC3+4. It really helps with separation of concerns. In theory you should have a layer of abstraction from your Controller &lt;--&gt; Repository. That way your controller has no knowledge where you get the data from. This is especially helpful when you are pulling data from various places. We also utilize Ninject to inject dependencies. Regardless of how you pull your data (WCF/EF/Etc..) it is considered bad practice to put and data retrieval logic in your controller. If I was code reviewing such work it would be rejected and sent back to be corrected. 
IMO.. if you separate your data logic into two tiers it helps with the complexity. We separate our logic into a service Tier and a Repository tier. We let the repository tier worry about pulling the basic objects from the data tier, and we let the service tier run the business logic on the data. We compile the data into a basic DTO structure, and if that requires additional logic we expand that object model.
Okay, as far as putting data retrieval in the controller that's what I assumed.
Started implementing a repository pattern today. Working great!
Thanks 
Tha looks pretty cool
You scare me.
He did say learn it and apply it, I assumed he meant before interviewing. So he should be able to answer questions about it.
That's cool but doesn't seem geared towards developers as much.
Just a suggestion, you might want to consider moving all of the new/edit/delete actions into a separate controller or decorating them all with the Authorize attribute. For example, you secure the get but not the post for New... Also, if you're liking Sinatra, check out [Nancy](http://nancyfx.org/). It's incredibly lightweight (especially compared to asp.net mvc) and a joy to work with.
If you're worried then review the script before running it.
MVC, Entity Framework, WCF, WPF, LINQ would be the core. 
Not sure how that's different to executing an arbitrary binary installer that you downloaded from somewhere?
Some tutorials: *http://msdn.microsoft.com/en-us/library/aa288436(v=vs.71).aspx *http://www.asp.net/mvc/tutorials/mvc-music-store *http://www.hongkiat.com/blog/responsive-web-tutorials/ Great Book *http://www.amazon.com/Pro-ASP-NET-MVC-3-Framework/dp/1430234040 Word association Table : class Row : object Column : Property Cursor : for, while, do while and foreach Query : Linq If: If Switch : Switch Stored Procedure : Method Now go, and make programs
why is this necessary? It seems like just another thing to manage and tell people they will need to install in order to get your program installed. I feel like it creates more issues than it solves. But hey, cool idea, and I'm sure it'll be great for people who have the need... but EVERY Windows developer?
It's an amazing tool for dev box management. What issues have you run into with it?
Nice word association!
Don't just get a book and read about the topics mentioned in this thread, think of a small project you would like to create (a small web app to list and categorize .NET topics, sites, and materials you come across for example). Basically something to force you to complete SOMETHING tangible. 
ahhh... I didn't know this was mainly for development tool management. I feel like an idiot. I thought it was for end users to manage what's on their windows box, and was trying to convince developers to get their programs to use it to increase the number of programs it was able to manage, so that it could eventually be apt-get for windows, which normal people use on linux just to install everyday programs. I didn't understand it's purpose, but thanks for explaining, it sounds like it would be quite useful actually.
&gt; Chocolatey NuGet is a Machine Package Manager, somewhat like apt-get, but built with Windows in mind. It's kind of on the front page of chocolatey.org. But yeah, it's a stab at moving Windows towards parity with Linux in that regard - "cinst python" and I've got Python all up on my system. It'd be nice if there were more, but it's (hopefully) a start.
right, I at first saw it as. "Hey developers, deploy your packages with this!" instead of "Hey developers, manage you machine with this, and if you develop for developers, also deploy with this." 
That's how your original comment comes off to me.
no, some of the other points are quite valid - for example the guy who mentioned multiple backend support for products, and the one who mentioned testability.
sorry I thought you were referring to changing your data abstraction eg linq to sql, entity framework, nhibernate, raven db etc
This is a key point.
Time bombs in computer software and how you can keep your children safe. Tonight, at 11. Cool example.
Java and especially .net address more needs to an organisation more simply than rails which would involve a more complicated technology stack. Going all Microsoft for many companies saves a lot of money for this reason 
Hi (which training session was that?) ... well it is not a case that the CLR is insecure :) It is just that when .Net C# code runs with Full Trust (99.9% of the cases) it can do whatever normal C/C++/Unmanaged code can do. The key is to remember that the CLR is running in the same process as the 'user code' which means that there is nothing protecting the CLR since there is no security protections inside a process (from code running in that process). Note that on this particular example, I'm using Windows Messages to achieve that environment (with multiple app's windows shown in the same app). The fact that the host app is in C# is just because it was simpler for me to code it using the O2 Platform. All that is needed is to be able to call the User32.dll SetParent call
Do you have any ideas about sample projects I can start with go get hands on?
Thanks. I added the authorize attribute where appropriate. I've been meaning to check out Nancy. I'll definitely take a look.
Thanks for the extra tips!
&gt;When a beginner joins a company or if there is a final round of interviews, known as a machine round, then most of the time the team leader gives the Candidate the first assignment to create an application which allows the end user to upload only Excel files and display it in a grid view and download it. When I joined a company the same task was given to me by my team leader; instead I was expecting him to give me the task of inserting, updating and deleting in a grid view. Does anyone actually use grid views for anything useful? Why would you store a data document in a proprietary format serialized into a data store? Whoever is conducting this interview is doing it wrong.
nice yoda condition
&gt;I have 11 tables each with about 4-25 fields each. Should I have a separate command object for each of those fields? Absolutely not. Commands are simple classes (getters and setters, otherwise known as POCO's) that should model operations, not fields or tables. Commands generally have names like UpdatePassword, CancelOrder, UpdateDeliveryDetails, MarkAsRead, etc. Each of those may end up modifying multiple tables and rows but allow the controller to remain oblivious to this. &gt;but it just seems like a TON of objects I need to write. You do end up with quite a few but because they are POCO's it never really gets too complicated. When you have a lot of classes like this it's perfectly fine to throw out the one class per file policy as well. The other important thing is to separate the execution from the command itself. If your project is fairly simple then you don't need anything to complex. Your controller actions end up looking something along the lines of: &gt; myOrderCommandExecutor.Execute(updateDeliveryDetailsCommand); There are all sorts of fancy things you can do with dependency injection and reflection but they are probably more complicated than you probably need for now.
But, for everyone's sake, do *not* use it as substitute for a cast: var something = other as ISomething; something.Do(); Or: (other as ISomething).Do(); Argh!
Can I ask what your UI looks like? Ie do you have a "Change DEA" page in the application. If this is the case then a ChangeDEA command would make sense. If there is more than one field on the page then a UpdateHospitalDetails command would be better.
Whether or not this is a good idea for the UI is a whole other debate, though I would lean towards it not being a good idea. You are the only one that knows the app and it's users however so your the only one in a position to really say. Does each field have to save instantly or can it all be saved at once? This affects your design choices. Is it all text data that is changing? If so you could have an UpdateHospitalData command with a hospitalId, ChangeTypeId and newValue string. The Execute method would then be a simple switch statement.
If the cast is bad, you won't get an `InvalidCastException`, you'll get a `NullReferenceException`, completely hiding the cause of the problem. It's worse if you're passing it into something: somethingElse.Accept(myObj as ISomething); Since the `somethingElse` class might not use the `ISomething` for quite some time, you'll get insidious null references where they weren't expected. (It should *ideally* check for null, but that's often not done in internal code.)
&gt; worst coders I have worked with never made the first mistake shown Could be that the coder is unfamiliar with .net. With a little patience, you could hire a great programmer who hasn't used .net (and using code review) inform of the idiomatic ways of writing .net code. This could save a ton of time instead limiting your applicants to those with .net experience.
Is it my crappy spelling or excitement over what I hope is a great movie?
I think its a little crazy to be making statements on either end about how not doing code reviews is wrong or doing code reviews is worthless. Software developers don't come out of molds regardless of how closely they follow "best" practices. 
An object's type is data. Sometimes life gives you centaurs and unicorns.
I do not argue with that at all. I am just surprised such a basic thing was actually encountered in a code review and not when hiring.
this. or he could just use the RedGate ANTS memory profiler use it to find the root references that is holding on the the network of objects that most likely exist in the SharpNLP library.
Chris did a talk at DDD North in October on SignalR. A good speaker but was unaware of his blog. Thanks :)
And for those that prefer podcasts: http://thesoundof.net/
Instant favourite
I have been a big fan of Apress lately. O'Reilly is usually decent too.
Code complete 
Agile Principles, Patterns, and Practices in C# http://www.amazon.com/gp/aw/d/0131857258 One of the best books on the subject I've read, ever. 
You get my vote.
 As far as overpriced amazon is my best friend
Have any examples of what you learned?
Best book on C# out there hands down.
&gt;O'Reilly is usually decent too. Agreed. I've been a C# developer for three years. I finally got to the point where I was yearning for a really well written reference/concept book. C# 5.0 In A Nutshell has been absolutely wonderful so far. It really depends on what OP's goal is. Does you want to know more about the framework? Do you want to learn more advanced, new language features? 
Effective C#
While I don't agree with all the opinions in the book, the CLR via C# is my favorite for .NET. Reading that book had as much of an impact on the quality of my work as ReSharper but costs way less. In my opinion it is a must read.
&gt;Also: let go of the db. I've worked at lot with ex-DB-is-the-app people. It's really important they let got of it and start worrying about all the other components. They seem to weep at ORMs and other layers on top of the DB but eventually learn you can make an app that responds just as well as if they had carefully hand-crafted the SQL. It will not be as fast but the end user won't tell the difference. On the other hand they'll learn they can change a ton of things without having to carefully check and correct a ton of hand-written queries.
Well the Richter book had to be mentioned, but I will say its all about language. This isn't a bad thing. But there is a lot more to programming than being familar with the technicals, in as much as knowing music theory will not make you a composer (I should know this :(). Sadly there isn't any book on programming praticies I'd ever recommend, only pratice, reading as much code as possible, playing with everything from AutoFac to nHibernate. A friend of mine despite going to a incredibly expensive US Uni did no compiler theory (Majored in CS thou...) and they really suffered for it. CLR via C# really helped them understand a lot of how C# really runs, so anyone in the same boat should really check it out. **tldr**: A med student knows more about technicalities of love, yet nothing about technique. It's a great starting point, but no substitute for pratice.
What are you seeing that shows you it's not running asynchronously?
I *vaguely* recall there's some sort of short-circuit logic that comes into play when you hit "localhost" - try hitting an actual endpoint instead, like your machine name.
Sorry for the late reply. I posted this at past 1 AM and then fell asleep on my desk. Did you test it out against a REST service built with WCF or just a plain WCF (non-REST) service? Do you mind sending me the log.db3 file? It keeps 24 hours worth of logs in there. Regarding having the install package, there are those who prefer to just have everything zipped up in one folder so that its easier to move the application from one machine to another. Personally, I don't prefer one over the other. It was just easier for me not to prepare the installer. Do you think I should prepare one? 
Not too sure where your level of skill is with Winform apps, but you may just be missing try/catch blocks for proper exception handling? Are you making a lot of Win API calls or doing some more low-level unmanaged code stuff?
I am doing low-level unmanaged stuff. I can use try catch.
Ran it, pointed it to a uber-simple get service (webapi running on localhost) and it immediately crashed. I assume that log.db3 is what you would like to see..??
yup. that's the one. Please send it to erik.araojo@wcfstorm.com. Can I also have the REST service please (if you don't mind)?
Here is some pseudo-code that should do it for you: static void Main() { //This will catch unhandled exceptions throughout the current AppDomain AppDomain.CurrentDomain.UnhandledException += new UnhandledExceptionEventHandler((s, e) =&gt; GlobalExceptionHandler(e.ExceptionObject as Exception)); //This will catch unhandled exceptions in the Main UI thread Application.ThreadException += new System.Threading.ThreadExceptionEventHandler((s, e) =&gt; GlobalExceptionHandler(e.Exception)); //The try catch below is just a safeguard, in case both the above event handlers fail to catch the exception try { Application.Run(new FrmMain()); } catch (Exception ex) { GlobalExceptionHandler(ex); } } private static void GlobalExceptionHandler(Exception ex) { MessageBox.Show("An unhandled exception has occurred in the application.\n\r" + ex.ToString(), "Unhandled Exception", MessageBoxButtons.OK, MessageBoxIcon.Error); //You could add logging, cleanup etc. here } See http://stackoverflow.com/questions/8148156/winforms-global-exception-handling and for a better discussion on this
&gt; You also should make an install package if your going to be charging $50/license. Yes, (s)he does!
Yep, REST (if done properly) should be "standard" across the board no matter what platform you develop it on.
Business will always be behind the 'trends' and it may take 10 years for places with large apps built on WebForms to swap to MVC... if they ever decide to switch. I don't think it is necessary to learn all the latest trends... maybe pick one and just do a side project. If you want to learn MVC, have at it! Ruby is neat but is an alternative not a replacement for other languages... c# is going strong.
First of all - don't sweat it. Conferences and meetings have a way of making you feel really badly about what you are currently doing as a developer. But this is a good thing, it makes you re-think how you develop and what tools you utilize. Just because it feels like everyone is talking about something doesn't necessarily mean that everyone is doing that same thing. Best example is that there are still more Web Forms developers out there than ASP.NET MVC developers. Now, I come from a Web Forms shop. We have a conservative approach to adopting new technologies as we don't want to commit to anything that isn't going to be around in a few years. We are just now beginning to migrate to developing on the HTML5/JS/CSS3 stack (still using Visual Studio). We stick to the big JS libraries (jquery, kendo ui, knockout, twitter bootstrap) and hope that nothing significant happens to any of those. Personally I don't recommend "switching" to ASP.NET MVC as it appears as though MSFT is switching to a model where you can use functionality from both models interchangeably and you'll get more out of learning stuff from jquery and knockout. Just my opinion though.
Get a good MVC book, like Sanderson's. Build some kind of website. If you can't think of anything else, try a reddit clone or blog system. Start with plain HTML. Then add some ajax calls using JQuery. All the MVC books use something like Entity Framework but that's not necessary. Start with whatever data access method you currently use. (At my company we mostly use stored procedures, and I just put all my sproc calls in a "repository" object. I built a simple data layer to abstract out the boilerplate.) When you've got all this down, start looking at some newer javascript libraries, like Knockout (which has a pretty sweet tutorial on its website). MVC is really pretty simple, with a lot less to learn than webforms. You can use the same asp security/membership stuff, sessions, etc. It's a lot easier to build custom components, since there's no viewstate to hassle with. Guthrie's [nerd dinner](http://weblogs.asp.net/scottgu/archive/2009/04/28/free-asp-net-mvc-nerddinner-tutorial-now-in-html.aspx) is a good online tutorial to start with, though I don't think it's been updated for the current version. But it'll get you over the initial hump pretty quickly.
The best way to ramp up is to do a project.
[This](http://www.asp.net/mvc/tutorials/mvc-music-store) is a fantastic tutorial and all tutorials I have done since then have left me wanting more out of them. There are some great MVC books as well, but this music store touches on all of the important elements.' As to some of your other questions, how you learn is really up to you. it seems if you have a lot of books that books aren't the best way to do it. check out some of the free courses from MIT on Youtube. Do the tutorials on the web (Which means you're on the computer, not on the couch reaidng the book. This has been key for me). Then, find something you want to build. Something simple and stupid is fine, but find something. Then decide how you want to build it and start.
A working web site with code on codplex on github is better than any acronym you could put on your resume. We recently hired a recent college grad over a dozen other more "experienced" applicants simply because we could see his work online and got a good feel for what kind of developer he was. 
These tutorials actually are mostly pretty good. http://www.asp.net/mvc The ones that teach you MVC, Razor, Controllers, and Entity Framework are worth learning. If you want a more serious adventure, learning Windsor Castle (IoC Dependency Injection Framework) and NHibernate will definitely keep you busy, and teach you a lot about software design.
If you've been doing any sort of development for 12 years, I'm sure you already have the base knowledge. I'd just find a personal project you want to work on and start hacking away at it. You can hit MVC, Entity Framework, Linq, and WCF in one blow with a personal web site. Maybe build a site (with MVC) and say you want to access your data through Entity Framework (and you'll get familiar LINQ via that). And then expose an API through WCF and then you're caught up on what you mentioned. I'd also strongly suggest [Pluralsight](http://www.pluralsight.com/training). It's an absolutely awesome way to learn for people that are already familiar with basic programming. **edit:** Another way to keep up with the times is to go onto twitter and follow *every-god-damn* MS MVP. They full-on spam twitter with blog posts about new technologies. I'd start with [@shanselman](https://twitter.com/shanselman) recursively follow who he follows (and who those people follow, etc) until your arm gets tired. [here's a list of programmers he follows](https://twitter.com/shanselman/programmers/members) 
Small response, big answer. Definitely [Code Complete, Second Edition](http://www.amazon.com/Code-Complete-Second-Steve-McConnell/dp/0735619670/sr=1-1/qid=1169499581?ie=UTF8&amp;s=books), although it's not *specifically* for .NET.
I also strongly agree with the [Pluralsight](http://pluralsight.com/training) recommendation. I am a .NET developer and started using Pluralsight to get my feet wet with Android development and it has been a godsend. It is really, really worth a look and try!
Here' a different tactic. Go to this site http://careers.stackoverflow.com/ and find three jobs in your area that you think you would like. And then brush up you skills to get those jobs. One thing you should do is learn javascript, css, and html5. Also you should try creating a IOS app. Also you might want to consider trying to get MCSD. That's good way to brush up on the new M$ technologies.
Check out http://channel9.msdn.com/Events/aspConf/aspConf. It's all of the videos from this year's (and last year's?) virtual asp.net conference. All free. Pluralsight http://tekpub.com/ 
This is 100% the truth. It doesn't matter what the project is, just think of something you'd be proud to show someone else, or that you can use in your life somehow, and go make it and figure out the bumps along the way. Maybe it's a program that finds duplicate MP3s in a given subfolder tree, or automatically copies large photos off your computer and onto a network storage drive, or something that plugs into your twitter account to respond with funny comments or a website that keeps track of your grocery list whatever. BTW if you are thinking about doing asp.net, MS Azure lets you host 10 sites for free, with a SQL backend and everything I believe. That would be a great avenue to try.
I've heard a lot of good things about this book. I'll definitely have to get a copy. 
Not sure why C# is getting lumped in there, as it is primarily used for server side processing, not client side.
You most likely use C# to generate markup and scripts that are then served to the client and executed there. Unless you are firing off methods via javascript from a dll that is downloaded to the client machine. Have I mischaracterized your use of C# "on" the client?
I would say WPF / MVVM do take the edge, but HTML/JS development has come a long way. While frameworks like Knockout can be helpful, the development community has come a long way in forming techniques that can create highly organized and efficient web apps. The problem with comparing these two groups is that 1. They have different capabilities. 2. They have different methods of delivery to the user. Regardless of which one is easier to use from a development perspective, it should take a backseat to those two considerations.
While there are strengths in each tech, the overlap is far greater and more ambiguous than those who try to segment the groups would have us believe. From my experience, while the browser has come very far, a process running a native UI on compiled code (JIT or native) is almost always a superior experience, and the only reasons not to choose it are: 1) you already have a lot of tech IP in HTML/JS, 2) your team can't ramp up on client side development in a reasonable time, and 3) the "app" is really just delivering a text-based reading/browsing experience over unstructured data. The two most often cited reason to choose HTML/JS - compatibility over many platforms and ease of distribution - each are weak with today's app marketplaces. "Compatibility" has its own issues (and has had for over a decade and a half now) and you are forced to accept an inferior UI. Mono for one has a great platform which allows you to use native UI and share a lot of base native code. "Distribution" - really, with todays app markets - how different is delivery of HTML/JS vs. a C#/XAML app? 
I believe it is only part 1, so I think a sequel is in the works.
Since when did Microsoft abandon WPF, C# and related technologies for HTML5? People are trying way too hard to see some hidden motives for MS' decision to allow HTML5 W8 apps. It's just a way to get more potential developers...
Type safety really isn't that hard to get past in JS. You get reflection for free so all you need to do is check the capabilities of objects your working with.
Web API
SL was a failure as a Flash competitor, that's certain. But it's still a great tool to build intranet apps, and a lot of WinRT concepts are based on SL, WPF and other .NET technologies, from XAML to WINRT metadata files. Build introduced W8 apps, who can be built in HTML/CSS/JS - that doesn't mean other languages are dead. Anyone with enough technical knowledge can build a WinRT projection, Microsoft decided to do it for languages where it makes sense: C++ because tons of people use it, C# and the rest of .NET because it's the future, and HTML because tons of people use it. If you look at some of Microsoft Research's OS projects (Singularity, Midori, ...) it's obvious that C#, or a dialect of it, is the future. This HTML craze is the same as the C++ "renaissance"; it's a way to tell developers "we haven't forgotten about you" and "you can now develop apps using the language you like, without feeling like a second-class citizen".
True, but you can also use VB.net with Silverlight. Maybe a better title would be to replace C# with .net?
It should be possible and quite horrible. How about using a database table to add/check locks instead? You should be able to reach it even from legacy apps and it will be less of a pain in the ass to access concurrently. Still horrible and something you should be using a Mutex instead (works but in VB and .Net). If your boss doesn't expects the OS to do basic functions, he's a bit pretentious to expect his wonky hack to work better because it's going to be file-lock hell. Edit: I hate programming superstition. Either your boss needs to provide documentation about how Windows can't manage a simple mutex or show you his tests that prove it doesn't works. Hunches are silly things to base software design on specially when the alternative smells really, really bad.
&gt;You didn't explain what exactly is being done It's a variety of things. Usually the processes need to have exclusive write access to some data file or other resource.
I've actually bitched about this legacy code before somwhere else on reddit. My boss's way of doing things really challenges my sanity at times.
Databases are something I've pushed for in the past. It's not really doable at this time since we don't have a central repository for all of our users' data (lots of it is stored locally on their end). I think it could be done with SQLite, though. It's just a matter of getting it to all of our customers and getting tables set up. No no, instead we're using some asinine setup that involves text files. In theory the files are suppose to be regularly structured, so you could use random access to read/write to them. But in practice they aren't because apparently it was a good idea for the files to be human readable and editable, and our users routinely fuck up the structure of each record. If it were up to me I'd gut all of this code and start from scratch.
SQLite would be better but you'd still have concurrency issues when multiple apps try to get a handle on the DB file. In the past I've been stuck with craptastic tech choices I didn't make and wasn't allowed to change, sorry man, I know the pain.
Are these text files stored centrally? Or are they stored locally on each machine? I struggled with an app that I wrote that could be worked on offline, and I settled on using Access. It was a step up from using text files, but it still made sharing data between users a problem. 
Get a new job. Your boss is fucking stupid. 
I don't know about that. I do legitimately think he knows next to nothing about software design/development. Or rather, his knowledge is ~30 years out of date. But at least some of the blame is that he was the programmer, CEO, manager, etc of the company for a long time, so he only had time to write band-aid fixes. Expediency took precedent over design. And I think a lot of his paranoia is simply him not understanding his tools. He can't put in debug statements to see what the OS is doing at any given time, so he can't trust it. He can see a file that he's told the program to output.
Yikes. I hope my doctor doesn't use your software. LOL Maybe the right approach is to paint a doomsday scenario. :-P But I'm not sure I"m really helping any more so I'll shut up.
protip - start looking for other gainful employment now. Part of being a programmer is growing up with people who surround you. If you are surrounded by people who are, let's put it mildly, less perfectionist than you are - you'll develop more slowly.
Like many others have said, the idea is horrible. However, [memory-mapped files](http://msdn.microsoft.com/en-us/library/dd997372.aspx) might help you out.
I think that saying "multiple-user applications can use the file as a lock" and then saying "just don't let them edit it at the same time" sort of creates another instance of the exact same problem he was trying to solve in the first place. You've just abstracted it another level.
Honestly though, it might be time to move on to another job. It doesn't seem like your current job is an environment where you will be able to grow yourself professionally and develop skills that have any value outside of your current arrangement. It's not enough to just have experience, you need to have experience doing the right things.
&gt; I was hoping/assuming SQLite would provide concurrency. It does. I use SQLite to power a website that servers ~8 million pageviews a month. User "ours" is wrong. 
I'll have to do some research into it later to know for sure, I guess. But even if it doesn't, I think I can still make it work. Whenever a process gets ready to call SQLite, I can make it request a mutex lock. The proper kind, not the file-based bullshit kind. ;)
The results map could use some work to make it more visible
It's a shame more people don't use the excellent xUnit for unit testing. So clean and powerful...
As much as I like autofac it should really only take a few hourse to swap out your DI library. I'm more concerned that TFS is the only source control listed.
Is the app reading/writing from a network share or something? Without some sort of server component (service, database, etc) I don't see how a desktop app can be multi user.
It doesn't have to be one central server. You can have a server at each location. Depending on where you want to go with replication between clients/client machines ravendb could also be a good way to go. &gt;The original software is over 20 years old, and I only came on board a couple of years ago. I'm trying to clean up a mess that's been piling up for a long time. Starting from scratch would be better, if it's at all feasible.
Sounds like your fairly new to the industry, if so then 6-12 months working on a complex application makes you look very attractive amongst people with similar experience levels, especially if you want to continue in the medical world. I've been in situations like this before, these companies collapse eventually, sometimes spectacularly. Get as much experience and personal fulfillment as you can on your own time and don't do long hours at work etc. Don't try and "change" them, it's a losing battle.
Might want to consider some kind of message system like MSMQ for communication between two processes.
~~I'm sorry but I believe I'm righ~~t. SQLite is providing concurrency for your single app, albeit high traffic app. OP seems to want to have multiple apps using the same SQLite. In his scenario, it will be first come, first to lock the file. You are just talking of a case where one app does many queries which I never denied it could do. Edit: I'm wrong! Thanks WalterGR
&gt; SQLite is providing concurrency for your single app Actually I meant website*s*. Typo. So multiple websites, each with multiple processes. &gt; In his scenario, it will be first come, first to lock the file. That's not how SQLite works.
I really hate this whole "Metro UI" thing. I hate to sound like some old fogey going "in my day we had rounded corners and things looked pretty" but it seems like a big step backwards for the desktop.
VS2012 looks like something that might happen if you had a graphics driver problem of some sort.
I cannot understand all the people who would rather be looking at the VS UI rather than their code. I also cannot understand how devs don't just hide the menus, use the keyboard shortcuts, or Control-Q and search for commands. Downvote me all you want, but give it a rest! I want to ignore the UI and make VS faster and fix long standing issues like being able to use lambdas in the immediate window.
Metro is god damn beautiful and beats pretty much every other OS design out there.
Lamdas during debugging would make things so much easier!
This says it all: &gt; Speaking off the record, a Microsoft employee with the Windows 8 team confessed that the Metro team was "very surprised" when they saw how the Visual Studio team had interpreted the Metro guidelines. From [Microsoft Visual Studio 2012 Reviewed](http://www.drdobbs.com/tools/microsoft-visual-studio-2012-reviewed/240007128) 
Windows 8 has some Metro apps and some desktop apps. They couldn't get away from it, as much as they'd like to move entirely to Metro. Office 2013 is a Metro app. There are two versions of IE, one is a Metro app. Visual Studio 2012 is a desktop app. Why did they try to make it a 'hybrid' metro app? It's a desktop app, with a Metro theme. They should have just left it as a desktop app, theme and all. If they want it to have a metro theme, make it a metro app. This hybrid app just feels like a kludge like Windows ME. Heck, windows 8 with metro and desktop apps feels like a kludge too. I'm just sad they are mixing my beloved visual studio into the kludge.
I've said this a million times before, so I apologize for repeating myself. I have black floaters in my eyes. Not many, but enough to be a serious nuisance. There are times when I just can't read the screen and I just have to walk away. The black flat UI of VS2012 solves this. It is therapeutic. I am incredibly thankful for it. And I hope that they never go back to the old one.
Office is a desktop app. It also looks great and functions well. The perfect example of Metro principles applied effectively on the desktop.
I'm still waiting for the DB data comparison feature that hasn't been "carried over" from VS 2010.
Unless you're one of the [1000's of people who can't apparently handle the new UI](http://visualstudio.uservoice.com/forums/121579-visual-studio/suggestions/2623017-add-some-color-to-visual-studio-2012)...
I wish they would have fixed the multitude of issues instead of changing something that didn't need changing. 
AND IN ALL CAPS FOR YOUR CONVENIENCE. 
There is an extension for that. 
I still think the outcome would be worse if the metro team were actually involved.
They need to make the dark theme consistent. Dark windows and white windows.. I'M FUCKING BLIND NOW!
Once you go NuGet, you never go back. I'm an expert in nuget packaging creation now.
Windows store apps have a subset of .net available to it. You don't need to go Win32, instead you should look at doing it all in WinRT. 
Checkout stackoverflow.com
According to Stackoverflow/Microsoft WinRT no longer has System.Diagnostics.Process [Relevant Stack Overflow](http://stackoverflow.com/questions/12765699/whats-the-equivalent-of-the-system-diagnostic-process-on-winrt-c)
Most of the threads dealing with this issue pretty much boil down to "Use the Launcher class if possible (not possible in my case)" and "Tough shit, use Windows 7"
If you don't mind, can you try one that does a Kill as well? Maybe it's because I compiled it on a Windows 7 machine (both my machine and the server have the same .Net version though)
Damn, I have no idea what's causing the error then. I'm exceptions whenever I try to access anything from System.Diagnostics.Process.
I usually use NHibernate for database access. I've done a coupple of medium to large projects and I've found out that Models for the views aren't necessary the same as models for the database (which I call Domain classes). I have some projects where one domain class spans across 6 tables in database, but the view model is quite simple. So for consistency I always make domain classes that I map to database and model classes that I use in views even though at least 50% of them are the same (it wouldn't be consistent if sometimes I'd use domain classes in views and sometimes model classes, would it?) Transformation between model and domain classes and vice versa is done using Automapper library. And some other information. I do not write any business logic or database access in controller classes. I always write repository classes for database access and service classess for business logic. Controller classes can use service classes but not repository classes, service classes can call repository classes and other service classes. I try to minimize code in contoller methods to 1 call to sevice class, so that I have the right methods in service classes (if I needed to call 2 sevice methods, that means I did a little of business logic in controller class, which is wrong. Let's say you're also doing an Android client, where you would also need to call 2 methods, so you'd have code repetition). Anyways. Structuring your application the way I described it brings you consistency, less code (you have to trust me on this one, but it's true), portability to web service,... The web service portability can be done in a matter of hours if you programmed your app like I described. You should use WCF, mark your Models as DataContract and make your service classes your OperationContract. Change calls in your controller classes to wcf calls and you're done. You should split your project to 3 assemblies (business with db access and all other things you need, shared assembly to use in business and in mvc; model classes go here, and mvc project). All this was used on at least 20 projects. I still support at least half of the projects and updating\modifying them is easy and fast. I use Autofac for dependecy injection, castle dynamic proxy for aspect oriented programming, NHibernate and Fluent.NHibernate for database access, Automapper for class 'transformations' and a few other libraries that are not so important to mention here in this discussion. I hope I helped.
Right click -&gt; Run as Administrator (either your app, or visual studio if running it in the debugger)
Would an application compiled until .NET 4.0 on a Windows 7 system default to WinRT when run on a Windows 8 system? It's the only explanation I can think of at the moment. 
Access denied errors, despite the program running as administrator. I get the error whenever I try to create a process or kill one. Edit: Just to note, these problems do not occur on our Server 2008 or my Windows 7 machine. 
I've got no clue then, it's really strange how this works on any Win 7 machine I run it on but fails the moment I try using on Win 8. I guess I've got a night of debugging to look forward to. 
Have you made sure that the framework is installed? It just sounds weird...I haven't had a single issue.
Not sure why all the down votes for the OP. He is just asking a question.
you have the full exception details? Access Denied against System.Diagnostics definitely sounds like a caspol issue. How are you launching the app?
Amen brother. The first thing I always did to a new VS2010 was going in with a chainsaw and removing the gazillion useless button bars and menus I would never use. Sadly there was nothing I could do with the contextual solution/project menu of infinite death. Edit: People are just afraid of change. Nothing new here. Bravo to Microsoft for daring to try something different. They could have saved themselves lots of trouble and kept things as they are but that's how products stagnate and die.
Better yet, I can actually give you the full source. [The Dynamic DLL Thing](https://github.com/HarbingTarbl/Derp-Dangerzone/blob/master/Restarter/Controllers/DispatchController.cs) [The System.Diagnostics.Process Bit](https://github.com/HarbingTarbl/Derp-Dangerzone/blob/master/Restarter/Controllers/ProgramController.cs#L43-56) Here is the exact stack trace and exception. [Pastebin](http://pastebin.com/BG2M5wuF) Edit: Might be worth noting that the exact source you see here isn't exactly what is running on both machines, but the parts I linked haven't been changed in the last few commits so they have stayed the same. Edit Edit: Oh, I'm launching the application as a console app, right click-&gt;run as administrator and all that. 
No. But if you and everybody that's interested in my sollution bugs me to make a sample I will. I don't have any personal project to share, it's all company related.
If you're doing desktop .net development, you'll find the ASP.NET web forms model really easy to learn. It's all event-driven like you would expect coming from desktop dev. C# is C# too.
TrikkyMakk, Thanks for this link. Great read. If you scroll down, there is an eye opening comment from Scott Barnes that shows just how fucked up internal politics at MS is.
I didn't see that comment. Great find!
Bump?
Yes great story thank you
No point to please everyone. Might as well just move on and make greater things.
AFAIK, there's no built in POP/IMAP/MAPI client in the framework, so my guess is you'll need to build one of those first, or get a component that does that part for you. Then, you'll need some kind of scheduler to do the checking for you, and parse the message to see if it meets your criteria. Then do whatever you want it to do.
I was under the impression that there is a way to create a service that has a push subscription to an exchange server, like a cell phone, that will allow you to execute code when a notification is received.
Are you wanting this to run on the server or client? And in what capacity? Exchange? Outlook? SMTP?
You can subscribe to receive notifications for many events with Exchange Web Services and SOAP. MS has all kinds of documentation and samples, [start here](http://msdn.microsoft.com/en-us/library/exchange/aa566188%28v=exchg.140%29.aspx).
There are OSS frameworks for reading mail systems (search for "IMAP" or "POP" with .NET), if you are using Exchange then you should have access to SDK tools and libs that have these features. You can also do it brute force style by running a traditional mail client and using FileSystemWatcher to trigger when a new message comes in. Some mail clients also allow for macros and triggers so you could signal your .NET application using a call to a URI or over a socket depending on what your client supports. IMO go with an API first. 
IIS includes an SMTP server that will drop emails into a folder for your FileSystemWatcher to monitor. This might be a bit hackish, but it saves you from dependencies on specific Exchange versions and APIs.
I wouldn't call using a tool for it's intended purpose all that hackish.
When I figure it out I will try and write something up.
Well, it's less than perfectly elegant for your architecture to have to take an in-memory object, write it to a file, then read it right back into memory again.
What's easier to maintain about screwing around with temp files, vs. just getting the data in a function call?
in addition to all these you could check out the [windows workflow foundation](http://msdn.microsoft.com/en-us/library/vstudio/aa349006\(v=vs.90\).aspx)
What happens if your service goes down for a few hours? Would you expect it to pick up the backlog? A mailbox is essentially just a queue, it is best if you treat it as such. Poll every 30s. Keep a HashSet of msgids you have already checked. The easiest way to talk to Exchange is via web services http://msdn.microsoft.com/en-us/library/bb408521%28v=exchg.140%29.aspx 
I don't want to derail the actual question, but the need you're expressing sounds fairly hacky. Are you certain that using the Exchange protocol to deliver the messages is the right way to communicate with your application? That is, why does email have to be the underlying communication mechanism to trigger the event? This sounds reminiscent to me of other hacky legacy systems that do things like parse files that that have been dropped in certain locations on disc via ftp, etc. In most cases (and I'm not trying to imply that I understand your case), messaging patterns are the accepted best-practice for communication across disparate systems: - http://en.wikipedia.org/wiki/Microsoft_Message_Queuing - http://www.eaipatterns.com/ - http://stackoverflow.com/questions/1522861/should-i-use-messaging-instead-of-a-database
Although - this can result in some [yak shaving](http://sethgodin.typepad.com/seths_blog/2005/03/dont_shave_that.html) when Exchange is already there and setup. Setting up MSMQ as a novice who's never done anything with it can be quite the hourly investment. Taking the time to assess all your message queue service options and then picking one and setting that up can be even more... .
That first rule redirects to itself with no kick-out condition. Maybe something like this courtesy of Scott Gu (http://weblogs.asp.net/scottgu/archive/2010/04/20/tip-trick-fix-common-seo-problems-using-the-url-rewrite-extension.aspx) &amp;lt;rule name=&amp;quot;Enforce canonical hostname&amp;quot;&amp;gt; &amp;lt;match url=&amp;quot;(.*)&amp;quot; /&amp;gt; &amp;lt;conditions&amp;gt; &amp;lt;add input=&amp;quot;{HTTP_HOST}&amp;quot; pattern=&amp;quot;\^www\.domain\.com$&amp;quot; negate=&amp;quot;true&amp;quot; /&amp;gt; &amp;lt;/conditions&amp;gt; &amp;lt;action type=&amp;quot;Redirect&amp;quot; url=&amp;quot;http://www.domain.com/{R:1}&amp;quot; /&amp;gt; &amp;lt;/rule&amp;gt; 
This. Client profile is like ".net lite"; the bare minimum required to bootstrap and run basic desktop apps.
Even better: a registry key. HKEY_CURRENT_USER\Software\Microsoft\VisualStudio\11.0\General\SuppressUppercaseConversion=1 (REG_DWORD) http://stackoverflow.com/questions/10859173/how-to-disable-all-caps-menu-titles-in-visual-studio-2012-rc contains a fair bit of UI help. 
We have a kick-out condition, I removed it when I posted it because it had mentioned the domain name in the condition. Is there anything else you see that could be combined? Thanks for your help btw.
Yep. Exceptions aren't mistakes. Number 2 has a similar issue. Exceptions should throw the error as soon as possible. The article's advice goes against this philosophy in some instances. For #3, I would rather have the typecast exception immediately than the null reference exception later on. For #2, sometimes it is expected the query return a single value, and anything else is an exceptional case. In this case, using First() over FirstOrDefault() is preferred. 
This should be titled "8 most common mistakes *new* C# developers make." Even then the "correct" / "incorrect" labels are too strong, since there are good reasons for doing each of these.
Ditto, you don't have to worry about index out of bound exceptions either.
"8 arbitrary things that you can do but probably want to do a little differently some of the time (though definitely not all of the time)." There's the beginnings of some good info in there but the article itself is so sparse on the explanation of why these are things you should pay attention to that's it's mostly worthless. The whole article, especially the title, smacks of fluff piece engineered to draw page views.
Well, I wouldn't go so far as to say StringBuilder is a *very* poor choice - it will still manage good performance and memory usage, but just not optimal. Using StringBuilder exclusively to concatenate strings avoids the worst problems of the '+' operator trading it off for suboptimal performance on the small end - altogether not a bad suggestion, but to declare it "right" is too much.
The longer I work in enterprise development the less I value all these blogs :P Honestly I love my job, and would love to learn tricks that make me better, but most of these blog posts end up being rants and opinions with very circumstantial benchmarks and 2 small novels worth of worthless bickering.
Exactly, I once had a code segment where I had to find the item in the list, and if it wasn't there that was a critical error and I very much wanted an exception to be thrown to stop the proccess from going wrong any further.
The advice in number 3 is terrible to the point of being unprofessional. No professional developer makes a habit, much less a rule, of silently coercing invalid cast exceptions into null values. Null is dangerous enough at the best of times, but even moreso when a double meaning is added to it. 'As' should only be used in specific sections of code where one was specifically testing for types using both an 'is' and an explicit cast, only as a profiling-guided performance optimization, and only when accompanied by the requisite null check. In any other situation, 'as' is simply a means by which to hide (from) bugs in one's code.
Fails to mention that using + to concatenate string literals is more efficient than using StringBuilder; since it's done at compile time.
I've been a .NET dev for 8 months and this article made me very uneasy. Made me afraid my seniors would think this mistakes are common, would not want to work with them either.
&gt; Point 8: In case of a really complex logic, just moving it to the DB layer by building a stored procedure Uh... I'm not sure sql is the best language for "really complex logic", I thought the idea with ORMs is that you can fetch all the objects you currently need in one hit of the database, then run methods on them to do your business logic (you can then unit test these methods without a database), then save them all back to the database in another hit to the database.
&gt; Should use an automapper, why? 1. Because your code runs too fast without it. 2. Because errors are too diagnose without it. 3. Because you just don't have enough dependencies to track. 4. Because encapsulation is for wimps and you need an excuse to make every property public. 5. Because now you can make even more nearly identical classes to map between. 6. Because writing classes that accept an IDictionary and auto-populate themselves using reflection is too convenient. 
&gt; 3 Casting by means of ‘(T)’ instead of ‘as (T)’ when possibly not castable So instead of a type cast exception telling you exactly what went wrong you are going to inject a null reference exception at a later date? That's not an improvement, that's a landmine. The ONLY time an "as T" cast is acceptable is if it is immediately followed by a null check.
&gt; String concatenation instead of StringBuilder You got that one wrong too, but at least you get half-credit. You should be using String.Join so that it can pre-allocate a buffer of the correct size. 
I'll respond in the same manner as the article. Note how I'm not backing up my points or providing information on how to make a decision in varied situations. ---- **1. Reading this article** The author is either somewhat new to c# development, has only worked in one shop or on one product, or phoned this list in to garner page views. In any case, this article is full of poor reasoning and bad advice. The issues are so intertwined with any good advice present that your best bet is to ignore all of it completely. //INCORRECT Reading this article //CORRECT Ignoring it completely. 
&gt; 'As' should only be used in specific sections of code where one was specifically testing for types using both an 'is' and an explicit cast, only as a profiling-guided performance optimization, and only when accompanied by the requisite null check. Not any more. I don't know why, but I've found through benchmarking that using an `as` cast and a null check is actually slower than an `is` test followed by an explicit cast.
You've got two options: 1 Eager Loading: Where you use one massive query that sends down lots and lots of redundant data that you don't actually need. 2. Lazy Loading: Where you make lots and lots of small queries. Either way its sending SELECT * queries by default, making for horrible performance.
I don't disagree with you at all on that one, hence mentioning profiling. ;) Nine times out of ten, perhaps ninety-nine of one hundred even, I find myself removing 'as', not adding it.
In general you should be able to map each rule to a general SEO concept. If you find two rules are mapped to the same concept then you can investigate combining. For example SEO concepts are: * Remove default document * Canonicalization of domain name * Append trailing slash * Lower case url * ... Put them into bins of * Rewrite * redirect * outbound and inbound If you have the same SEO concept in a bin twice, you could probably combine them. EDIT: Formatting
What about the third option: eagerly loading just the data you need?
I just mentioned it because about a year ago I actually went through and ripped out the as-style casts for performance reasons.
Oh sure, you can certainly do that. But I find convincing the ORM to actually give you what you want is significantly harder than just using a DSL designed for that purpose.
Using SQL to get the data into the ORM is quite reasonable: the built in ORM querying features are often a pain to get working efficiently. I just think SQL was designed for reporting, summarising and joining data - not performing really complex logic.
Same. One of the codebases I've been into reasonably frequently during the last couple of years feels like a quarter million lines of 'as'. 'As' was a part of the coding standard for nearly a decade and it has definitely taken its toll. I am cleaning as I go but can only nuke so much cruft so quickly while working to win over the old guard.
stopped reading at #2 because it's just as "incorrect" as what they are trying to correct. because it doesn't matter.
out of interest - in terms of number 1, where does string.concat fit in?
A few thoughts... SQL is designed specifically for data transformations. What looks like complex logic in an ORM is often quite simple in SQL. SQL is actually a powerful set-based programming language. Using temp tables you can perform operations against sets of data. Automatic parallelization, the holly grail of OOP programming, is something you get for free in SQL. SQL moves the processing to the server. This can be really, really good in that it reduces the amount of data that gets shipped to the client. Internal optimizers can even significantly reduce the amount of data read from disc. Of course moving the wrong code to the server can be disastrous. I've seen people do crazy things like parse CSV and XML files on the database server. Did you know that functions in SQL Server have a concept of purity? Similar to what we see in functional programming languages, SQL Server functions are marked as being deterministic or non-deterministic. This allows for things like caching the results so the function doesn't have to be run multiple times with the same input.
Oh god. Even the handful I see in my current code base are a nightmare. For every ten bogus ones there is one that really is supposed to return a null. Telling the difference is difficult to say the least.
It really depends on what you are trying to do, if you code is setup in a way that your cast should never fail then yes let the exception be thrown so that it can be logged. However if you are working with something where a null may be pretty common the the trycast should be better for performance. 
Again, I have to disagree. If you are using linq to search a collection for a single item you should not get an exception if it isn't found. There is a performance hit with exceptions and they should be designed against. And you should always be checking for null
You could have consolidated all of your disagreements to one post. This one I kind of agree with you though, at least for the example, although I think the article just meant concatenation should be a last resort when combining strings. Depending on the use case String.Join or String.Concat may be better options then string builders and in some cases it's not
Using Where then Calling first will result in an exception. If you are trying to avoid exception then FirstOrDefault is the way to go. I have seen this many times as well where the programmer would immediately check for null after call the First method not knowing that an exception will be thrown
What if you don't know if something is going to be there or not and that it isn't really all that exceptional if it isn't? This has to be a lot cheaper way to deal with that than throwing and catching an exception.
Authors Company: http://goyello.com This explains some things.
[Who in their right mind would let Dispose throw?](http://msdn.microsoft.com/en-us/library/ms735103.aspx)
No one accused the WCF designers of being in their right mind.
Chalk that down to people's wonton love for Stringbuilder... Most people understanding of Stringbuilder is that you use it every time or you don't really know c#
I actually think the point-per-post method is nice because it allows the points to be voted on individually.
It's faster than using a StringBuider and the author is stupid for not mentioning it. P.S. Though I have to admit I never use it. I always end up using String.Join, as I need a plus or comma between strings.
For every time I see FirstOrDefault used correctly I see five examples of it being used incorrectly. But null checks are worse. There I generally see a ratio closer to 20 to 1 against, possibly even 30 to 1 if you count properties that shouldn't have public setters but do anyways. After 15 years of remediation work, mostly on .NET code bases, I think I've got a right to make a claim of experience.
What is wrong with null checks exactly? I understand that you should keep branching to a minimum, but how is that worst then exceptions. 
The most common offender is code like this: void Foo(Type value) { if (!value == null) { //do something important } } What does this mean? That `value` can and should be null from time to time? Or `value` is null by mistake and the developer is just suppressing the exception without figuring out why `Foo` is being called with a null. Usually its the latter, but not always. So I have to meticulous study the code paths leading to this method (a process that can take hours or days) in order to figure out if passing a null to Foo is actually a mistake. And if its not a mistake, then I've got to repeat the process with the N-1 other functions just like it until I figure out why the program is silently failing. Here is a variant on the idea: public Type Bar { get... set { if (value == null) return _Bar = value; } } Instead of throwing a Argument Null Exception like they are supposed to for a non-nullable property, the assignment silently fails. This one is less problematic, but still wrong. And then there is the asymmetric property where this expression throws an exception: something.Baz = something.Baz; Here is a closely related fuck-up: private Type _Baz = null; public Type Baz { get... set { if (value == null) throw new ArgumentNullException("value"); _Baz = value; } } This time the property setter is right, but the default value isn't. They either need a constructor to ensure Baz is never null OR they need to allow Baz to be set to null. I would prefer the former, but either is acceptable. Oh that reminds me, here is one I just saw today: Foo value = e.EventData as Foo; if (value != null) //do something important In this case e.EventData should always be a non-null object of type Foo. But out of laziness they didn't use a strongly typed class to store the event data, instead they just used a generic object-based one. The to add insult to injury, they used an `as` cast with a null check to ensure that if the data type of e.EventData was changed the code wouldn't throw an exception. Well e.EventData did change type. So now I have a bunch of no-ops where once there were event handlers. ***** Now I'm not going to say that you should never use a null check. But if the vast majority of null checks are in validation logic, there is probably something wrong with the code.
It will on a value type.
These are at least more entertaining than the CSS ones that are bickering for the sake of bickering. I'll usually stop reading a blog when I see "you should always" or "you should never". There's always an exception to the rule.
I wouldn't worry much, if you've only been a .net dev for 8 months no one is expecting to write anything near perfect code. I'll tell you what I tell the guys under me: * Listen to what people tell you but always find out the why behind what they say. * Google is a great example for how to do something similar to what you want but will never give you the full implementation * Never be afraid to speak your mind, sure 99 out of 100 ideas might be rejected, but everyone's got something to offer and you gotta learn somehow * This one is probably most important : NEVER under any circumstances let me find you copying a pattern or piece of code without being able to fully explain to me what it does and why you did it. If you're only doing it cause someone else told you to, I fully expect you to harass that person until they've explained it to a level that you understand. Edit : One last little bonus tidbit. That piece of code that you're writing right now that you think is really clever is going to really piss you off in 6 months when you're trying to fix something related to it. This industry is full of people who are too smart for their own good.
Yes, I agree there is no difference when using Where and First or just First My post is a little incomplete, this &gt;Using Where then Calling first will result in an exception. If you are trying to avoid exception then FirstOrDefault is the way to go. Should really read &gt;Using Where then Calling first will result in an exception **when the query yields no results**. If you are trying to avoid exception then FirstOrDefault is the way to go. Of course this depends on what you are trying to do. If you want an exception if the query fails First is best, if you want a null if the query fails then use FirstOrDefault. I have no argument for or against using Where then calling First, or Where then FirstOrDefault for that matter.
I've actually had a lot of success with constructors that accept IDictionary.
I don't envy you tracking down a bug related to two properties that happen to have the same name but shouldn't map to each other.
Never happens. It's not like I'm initializing two different classes with the same dictionary. 
Ok. Yes part of that would poor validation and should probably throw exceptions. The other part is just bad design and is another can of worms. &gt;Now I'm not going to say that you should never use a null check. But if the vast majority of null checks are in validation logic, there is probably something wrong with the code. Agreed.
&gt; The other part is just bad design and is another can of worms. That's my problem with most of the "best practices" I see in blogs. At first glance they seem to address a problem, but take two steps back and you see the design is broken to being with.
The author is simply mistaken about foreach/for loops. The CodeProject article is from 2004 - or, in other words, about .NET Framework 1.1. Starting from 2.0 (generic collections and optimizations), foreach loops are as fast as for or even faster according to some tests.
What's qcon?
LMGTFY: http://qconnewyork.com/ Joking aside, I wasn't aware this existed either, grauenwolf - looks interesting tho; wouldn't mind meeting face to face either. Lemme peruse the site a bit, but I'll tentatively say "yes".
I'm not sure whether this helps, but I went to QCon SF - they had a great talk by Ian S. Robinson on Test-Driven Hypermedia APIs that was written with Microsoft's Web API Framework. Really great stuff. Aside from that though, I didn't see very much that was written in .NET. It would have been nice to see more, but I don't necessarily consider it a requirement. Many of the sessions emphasize approaches and techniques rather than nuances of a particular language or framework. That or someone is using their own product.
Even in the example, FirstOrDefault is wrong. What you want is an exception in that example, but what you will get is 0 when nothing is found (not null), which is incorrect.
So the solution to tedious code generation is a code generator? Now you have to maintain the code and your templates. At that point it seems like it would be easier just to program in F#. 
wow, that looks really cool and I am definitely going to try and attend this!
Your template shouldn't be changing much, if at all, so that's a bit of a moot point. It's certainly easier than doing the same without a code generator.
More importantly in 99% of the time it doesn't matter and problems solved/h out weights any minor run time benefits. In those cases where it does matter you need to benchmark your specific case anyway.
Actually it helps a lot. Thanks.
Seems we have an advertising gap. I'll have to talk to the organizers about it.
I like the idea of techniques and approaches vs language particulars. It's more agnostics and transferrable that way. I'd find sessions that didn't require you to be an expert in WCF or node.js or whatever to be more interesting since anyone with a technical background could understand what was going on
Be careful though, a lot of people with 10+ years can be set in their ways thinking the old ways are the best ways. Listen to them but don't let that stop you from learning newer stuff on your own.
I tend to disagree with this methodology. Especially since you can specify failure messages inside your asserts.
&gt; There is a performance hit with exceptions and they should be designed against. People who say this line usually ignore the un-needed 50 SQL queries per second their app is doing.
I am not one of those people, or at least I try not to be. I find that more times then not exceptions are not handled correctly, so when the exception bubbles up the stack connections are left open and objects aren't disposed properly. So you have that in addition to the performance penalties that are inherent to exceptions. With all of that, and of course depending on context, a default value may be what you want.
&gt; That problem can be solved in less than a day. It is easy to write a test framework that allows for multiple asserts to be aggregated. Yep like this one here : http://rauchy.net/oapt/ &gt;And the asserts are wrong anyways. Since you forgot the message parameter it is impossible to tell if documents or documents[0] is null. Ouch, that is a big mistake from my side here, and propably this example is not the best one.
I don't like the syntax. () =&gt; Assert.That(element.Name, Is.EqualTo("single")), The one I wrote just uses Assert.AreEqual("single", element.Name) The so-called "fluent" style is unnecessarily verbose. And I suspect you are going to see performance problems with all of the extraneous memory allocations it needs. EDIT: Their header also requires all the assertions to be grouped. Mine uses this: public void should_parse_single_element() { using (var Assert = new AssertionContext()) { //pre-test assertions //actual code //post-test assertions } } I choose this in part because it is trivial to retro-fit an existing test. 
No, it's completely wrong. You are correct, First vs FirstOrDefault depends on the context, and you only make mistake once before you learn about FirstOrDefault. But that's not what the article states, it says "Where with First instead of FirstOrDefault" which is completely wrong.
Indeed. * Press Alt+Shift+Enter to go fullscreen. * Hide all the toolbars. * Install the "Hide Main Menu" extension. * Go to Tools|Options &gt; Environment &gt; General, and uncheck "Show Status Bar". * Autohide all the useless crap windows that you don't need while coding. (like the output window or error list) * Use ctrl+q for commands you haven't memorized the shortcut to, or use infrequently. You now have a full screen editor window. If you have a nice large monitor, create multiple panes or tab groups. For bonus points, install something like resharper for the ctrl+alt+t / ctrl+shift+t navigation. Enjoy your mouse-free and more pleasant coding experience.
Perhaps a better argument is that if you really NEED immutable objects, stop trying to shoehorn them into a language that doesn't have them, and use a language that does. 
You're probably right. Over the years I have had a handful of occasions where I've needed something to be immutable in C# though. There were other ways to accomplish what I needed but this was for low level framework code where performance was a big factor so being able to assume the data was immutable eliminated a lot of overhead in checking that it hadn't changed over and over again. The few times I had to do this, I made sure to keep the classes simple to avoid the problems discussed in the article. For your normal every day kind of business programming though, I think you're probably doing something wrong if you frequently find yourself needing to construct immutable objects on the fly.
Ctrl-Alt-T / Ctrl-Shift-T, along with Shift-F12 and Alt-End have changed my life. Can I have tool windows open in full screen OH MY GOD I CAN THIS IS AWESOME....
C# heavily relies on immutable objects. You see them in places such as... * Strings * Delegates * Most EventArgs * Most Structs 
For normal business applications in C# I find the number of hard to fix bugs is proportional to the number of public property setters. One of the first things I do when adopting a code base is remove as many public methods and properties as a I can. The way it is at least clear which fields can be externally altered.
&gt; Transformation between model and domain classes and vice versa is done using Automapper library. Why bother? Why not just use stored procs that return data to be loaded directly into your data models? 
P.S. Its "data model" or "business object", not "view model". A view model is a controller-like class for the MVVM pattern. 
You loose the hierarchy of classes (ex. Address class used as a property in Person class) if you use SP. And I like to keep as much code as possible in the C# and not in the DB. When you need to save objects you need to convert Model to Domain class anyways. And it's not like there's a ton of code for Automapper. Pretty complex classes can be 'Automapped' in about 10 lines of code. I sometimes use HQL/CriteriaQuery projections/Linq select new { }/Stored procedures or any other preferable way to get the right model out of the DB. But that's usualy for data that you need to query and not save. When I need CRUD for some object (ex. Person) the Automapper way is the way I choose. No need for writing projections, queries, stored procedures. I just need about 2-4 lines of Automapper code and it's done.
Data model is correct. I'd use business object phrase insted of my domain classes phrase.
My understanding was that concatenation is best done with StringBuilder because it avoids creating a new object each time you append a string. Is that not the case?
I don't lose the ability to populate hierarchies of classes with stored procs. I just return multiple record sets. Which, by the way, requires a lot less network traffic than the "massive join from hell" that ORMs typically employ.
I want projections. I don't want to blindly execute SELECT * queries that perform table scans.
 Can anybody explain why this happens? I thought the finally block always executes.
I'm guessing you posted it before it got answered on SO?
So have them. I don't see any problem with projections. But let me guess. You probably think you can't have projections with ORM. Well you can, you just have to learn to use the ORM you choose to use. Some people prefer stored procedures. I let them write it for me and then call it with my ORM. I actualy prefer it that way, so that I don't need to write queries I don't know how to write.
I do that, too. With ORM. You just have to learn your ORM first.
Most, if not all, ORMs handle projections very poorly. The queries are verbose and you lose support for the things you choose and ORM for like object graph support and change tracking. But yea, I'm fine with Procs+ORMs.
Always check that the advice you get it's actually true/useful. There is a lot of 'wisdom' around that is either outdated or cargo culted from the beginning. Plus what darkpaladin says is correct. Many of your peers may be mentally stuck in 2004 .
Reminds me of a guy I used to work worth "use arrays every where because arrays are faster". He didn't understand what the VB redim statement did.
By the time you do that many concatenations the code is ugly enough to justify stringbuilder anyway.
Perhaps. It might just be a loop. 
String.Format is also good, and looks a lot cleaner.
Or nServicebus for a nice API on top of MSMQ.
Interesting, which version of EF was this?
EF version : 5.0.0.0 XPO version : 12.2.4.0 NHibernate version : 3.3.1.4000 OpenAccess version : 2012.3.1209.1
Yes.
At least you have Eclipse. You could be using Emacs. (If this was in /r/programming I'd be flogged with a cat5 cable.) 
Eclipse??? HAHAHAHAHAAhaaaha heh heh *cry*. ... No, I use IntelliJ IDEA.
I started learning to program in C# a few months back, and just started Java for Android yesterday. This pretty much nails how I felt last night struggling to complete a basic Calculator app. It's rough and ugly, but it works.
I often switch bewteen C# and Perl. It's kind of like a military encampment vs. Burning man. 
I'm feeling the exact same way! I've been doing hard core enterprise java EE for the last year and finally found a new job doing .net in a profitable startup! I'm pretty stoke about it. Starting in two weeks!
Sorry to hear. where i live you can trip and fall on three .net jobs.
I work from home, so that combined with my salary reqs makes it a bit tougher. I do enjoy my job - I generally stick to the frontend with JavaScript. It's just that the backend is all Java, so I have to deal with that occasionally.
Startup? Profitable? .Net? I'm really having a hard time believing this!
Wow, I was sure I kept reading "Script" after "Java". I'm fairly comfortable in all 3, and while C# is head and shoulders above Java in my opinion, both are a world apart from JavaScript, and that's even _after_ all the new fancy intellisense and refactoring tools and nifty JS libraries like jQuery and knockout available. 
Yes, surely in order to be profitable you need to be using node.js
With one attendee.
Ugh I've bad to rewrite perl into c#. I learned more than I ever wanted to.
Nice Freudian :)
I've only used Eclipse and Netbeans for Java development, but only on hobby basis. Now I work in C# and use Visual Studio with ReSharper (from the creator of IntelliJ IDEA). How does IntelliJ compare to VS with ReSharper?
If he has any interest in productivity he would be using vi.
Programmed by JavaScript Rock Star Divas, pivoting into a freemium game-changer by a growth hacker, pre-stealthing into a lean-startup.
Visual Studio, even on its own, completely blows away anything else I've used. To be fair, I've had much more experience with VS so I'm still learning all the tricks and shortcuts and such, but my feeling, and the consensus from other .NET/Java devs I've spoken to, is that VS is pretty much the gold standard of IDEs. Honestly, I've felt more productive using the free/express versions of VS than any other IDE I've tried.
I type with a lisp.
Dallas is much the same.
Heh, I actually don't mind perl that much. Our company has a decent framework that makes it pretty tolerable, and every problem looks like string match to me, so I'm good with regexp. But man, sometimes I have to debug some perl written by someone else. Things get scary then. 
Charlotte
I've been learning Scala using Eclipse... I have no idea how people consider Eclipse to be good. I much prefer Visual Studio, but throw in ReSharper and no other IDE even comes close.
I actually like Eclipse, but VS is pretty damn impressive. My biggest complaint with VS are how it interacts with third party plugins (Vault source control plugin... eeewwwww), while eclipse has some fundamental weirdness (Workspace is odd, code predict is slow, and hot keys are non standard and a pita to config. I use it for perl dev now, and a bit of flex. 
Guava is a poor man's, crappy, not nearly as good replacement for LINQ. But at least it's something. Without Guava, Java would just be hellacious.
"I've been writing server-side Java for the mobile team in Google London - and I can safely claim that few things help you to appreciate new language features than having to code in a language which doesn't have them, but is similar enough to remind you of their absence" Jon Skeet, C# in Depth Sums it up for me ;p
I C what you did there.
VS is awesome, I don't deny that. But if you try to look into extending it, and see all the COM interfaces and crap that's been around for 10 years. You start wishing that MS would throw money and developers at the SharpDevelop team so we could get a clean, fully .NET IDE instead of that monster.
You can still do c# in your spare time on open source projects. We could use some help with [Blade](http://github.com/vannatech/blade) (shameless plug).
Ada thought someone would have put a stop to this by now.
Same here. There are more .NET jobs than people qualified to fill them around here, it seems.
All this smalltalk is a real bore.
Use Scala instead of Java. Then you'll have something even better than C# that works on the JVM. 
Any parttime remote dev help needed cause I'm looking?
Any parttime remote dev work available?
Nah, ed is the best. 
Don't forget coffeescript
This. DC represents.
It makes me want to bash my head.
What do you use to debug javascript, aside from firebug? I've yet to find a decent IDE for it. (I'm a new developer whose only experience is in VS/NB/Notepad++) apologies for the noob question!
&gt; Visual Studio, even on its own, completely blows away anything else I've used. Pretty much sums up Visual Studio right there. I haven't used VS 2012 - but going all the way back to VB6 their IDEs have always been very intuitive. Eclipse et all IDEs all seem to be designed by a sociopath whose killed everyone who came up with a good design idea. Don't get me wrong their IDEs are functionally great - but the design has some things to be desired.
Chrome's developer tools have gotten much better than Firebug. They work pretty much the same, but I've found them to be uh... better somehow.
How can this be?
You will love VS2012. Even if the new UI takes some getting used to. The raw speed improvement alone will please you and MSTest is actually useful now. 
I mostly use Chrome's dev tools, I think they are better than firebug. As for IDEs I just use vim. I've never been too big on IDEs, especially for dynamic languages.
Ah, wisdom from The Great Skeet.
Well when are these jobs coming to SoCal? :/ *grumble*
Brainfuck.
Whoever asked you to do this has two problems. The first problem is a lack of trust in their employees (or a lack of disciplined employees), but that's a little beyond the scope of this subreddit. The larger issue is that you simply can't efficiently do what you're talking about doing. A much simpler way of preventing all users aside from a whitelisted group from running Skype would be to use Windows Group Policy controls. [Have a read.](http://www.catonmat.net/blog/disallow-windows-programs-via-gpo/) Rule #1 of software development: Don't reinvent the wheel. (Unless you have a *really cool* wheel design. ;))
I completely agree with kintar1900 about using group policy...but if you can't use that (which I would understand as in my first job we had it but instead of pushing out the update when DST changed we had to visit every computer) - This sounds like a job for FileSystemWatcher. Also you shouldn't create a console application then install that as a service - you should actually create a service it's VERY easy - http://www.codeproject.com/Articles/3938/Creating-a-C-Service-Step-by-Step-Lesson-I The path you were going down would basically be an infinite while loop - which would suck their CPU.
I do mostly c# right now, but my background is Java. Java is just unnecessarily verbose. I prefer the JVM to the CLR. In Java I don't have to care about x64 vs x86, I can change code and hotswap without context change, and Java 7 brings null safe operators. As to your assertion about IDEs, I use vs2012 and intellij 12 and I find vs2012 irritating to use w/o resharper. Intellij has one of the best javascript and html parsers period. Vs2012 is nearly equivalent but 2010 was missing some of the capabilities that intellij has. I use maven with all my Java projects it does quite a bit more than nuget and I don't enjoy editing solution files and project files. Maven is a better solution on the whole. (Or gradle, whatever you prefer) I hate webforms but I like MVC and webapi. JSF is like webforms and springmvc is the equivalent to MVC. So, no lambdas, auto properties, extension methods, linq, or other such syntactic sugar, but Java tends to have a healthier community/ecosystem which leads to a ton of great ideas that ultimately wind up in .Net under another name anyway. Id be happy to help point you in the right direction if you're just now making the transition to Java. And Lambdas are coming in 2014.
I take it from OP's post that Skype is an allowed process, but restricted to permitted logins? Perhaps suggesting certain Skype accounts are permitted... Like business accounts and not personal. If that's the case, Group Policy won't work, unless there's a specific GPO for Skype Business edition (which actually might be worth investigating). http://www.commodore.ca/windows/skype/skype-business.htm 
If you treat Js more like scheme's big brother than Javas little sister you can see where its strengths lie. You can be extremely expressive in small amounts of code.
I wouldn't know, I'm stuck with IBMs RTC plugin at work and use Git at home. My personal MSDN sub does not get me TFS sadly. 
Group Policy will still work because, as the name suggests, you can apply it to groups of users. You just need a new "Skype Allowed" group that negates the "don't allow skype.exe to run" policy rule.
Not if user A is allowed to run Skype, but only on the Skype account userA@domain.com and not userA@home.com
&gt; You can be extremely expressive in small amounts of code. Exactly. I also like that due to the nature of it being a dynamic language, it is much easier and cleaner to extend when needed. With C# you at least have extension classes. With Java, you end up with endless "Utils" classes.
Use TopShelf to write a console app that can install as a service. You can get TopShelf from NuGet, and look up their project page for examples. After getting that wired up, I believe the service will run as one of the built-in accounts that has administrative rights. Then you'll just need to locate the user app data folders yourself. As long as the directory structures on the machines aren't weird, you should be able to rely on certain patterns. (User profiles are in C:\Users, etc.)
ok thanks for advice, i'll add more info.
FileSystemWatcher has betrayed me too many times. If you use it, you should still have a backup timer.
Personally, after testing the performance... it's only the first time the map is created that makes it slow. After that, it's as fast as any code you write. The same technique is used behind the ASP.NET MVC ModelBinder. We normally use it to map objects from foreign databases into our model. We use it at the edge of our system. Not in the core.
Well that's good to hear. Maybe I'll look at it again. I've never used it myself, but I've been forced to use a service tier that did. The interaction between Automapper and NHibernate made for horrible performance and down right nonsensical error messages. EDIT: But on the other hand, writing my own special purpose mappers is so easy its hard to justify using a general purpose one.
2013 you mean? I would assume Java 8 rolls out during the next JavaOne. 
Well, sort of. You are correct about your compiled code, however, the issue arrives when you are pulling in dependencies. For example, oracle connectors. In .net I have to install the 32 bit connectors for visual studio and the 64 bit connectors for deploy. In Java, its a non-issue. I realize I'm nit-picking over the fact that Microsoft takes the position that an x64 version of VS would not make sense, but it is an annoyance and something that I have to be aware of when developing.
EF 5.0 has some optimizations that only kick in on .Net 4.5. What version of the .Net framework did you test with?
And now... I could technically leverage that when shipping Windows services to our clients or during Windows Service CI for our staging server. The XDT transform was only ever enabled for web projects. Now... I can use it for other projects!
We were bought by a east coast company who bleeds IBM
A lot of mature, open source libs. No need to rely on MS licenses. Many free/open development tools. There are a lot of good reasons to like the java ecosystem, the language itself just doesn't happen to be one of them.
http://xamarin.com/monoforandroid
True, but there are two issues with open source in .net. The first is that there are many developers who won't look at anything that doesn't come out of Microsoft. Many thought that MVC and EF were amazing, not realising that they could have had the same benefits for years with monorail/nhibernate. The ones who think TFS is the ducks nuts because there only previous experience is with source safe. The other problem is MS competing with already established open source projects. IE, they could have added the tooling and anything else they wanted to monorail. They created Unity when there was already half a dozen better IOC containers. Since nuget came about I've seen this changing a bit but it's going to be a long process.
There is only one way, afaik: Monotouch. I have used it a bit and as a c#/.net developer it's a relatively easy way to get into ios programming.
Have you heard anything about either of these? A colleague recommended the following - http://xamarin.com/monotouch http://www.vsnomad.com/how-works.html http://phonegap.com/ EDIT: I'm guessing the 1st link IS monotouch?
Yeah, the first is monotouch. I haven't used the two others, but the major difference is that monotouch builds native ios/android apps using the .net framework, where the two others build html5 and wraps it in a browser in an app.
Definitely only worth checking out Monotouch. I've seen a few other projects porting Mono to iOS and Android, but they're all immature and not in any way commercially suitable. Xamarin (who run the Mono project) do an excellent job of supporting Monotouch commercially, and the framework's top-notch. I've been using it for about 6 months, and I'm *so* pleased my company decided to share code between our Windows Phone, ASP.NET and Android projects, no argument. As for stuff like PhoneGap / Nomad / other mobile webapp wrappers (one man's opinion, mind you), even devices with full HTML5 support can't deliver the level of user experience fussy smartphone owners will expect from an apparently native app. Go Monotouch.
so using native ios I would need a corporate license etc to publish iphone apps internally? 
You may or may not need a corporate license, though. They also offer individual named licenses for far less than the corporate per-seat pricing.
Good points. I also worry about Apple rejecting the apps of html5 apps. Right now they will allow phonegap apps, but jquery mobile, and some of the other frameworks, your app is subject to their rules. Native is the way to go for those picky sobs.
Always a worry, yep - was using Appcelerator Titanium for a while, but between the app approval uncertainty and the bugs (oh, the bugs!) my team switched to Obj-C and Monodroid for everything app-wise.
Xamarin (Monotouch) does **not** yet have a package available that lets you develop iOS apps in Windows (C#). Quote from the Xamarin site: &gt; It is not possible to build iOS or Mac apps on Windows. Yet. :-)
Since you're already using Monodroid, why not just choose MonoTouch as well and get a bit of skill cross-over boost, and perchance a little bit of code reuse?
Practicality, basically - the app's quite UI-heavy, and Android's UI model is well suited to .NET implementation. iOS' view model, on the other hand, is a bit of a kludge when you try to shoehorn it into Mono, and in terms of learning curve for new recruits, we saw it as a false economy. In simple terms, it's just a TCO question - new hires can jump right into Monodroid even if they've never touched it before. Not so much with Monotouch, so it ends up being more cost effective just using Objective-C people from the start.
I would use phonegap or something similar. you can create your own native wrappers.
??????? just use paypal. Its gonna be so much easier.
Paypal could be a way to go, but you will need to set up Paypal account first. I believe they provide an API to implement the module that will allow payment to be handled inside your web page. Try search around in Google. There is also another payment system called Authorize.Net (not necessarily need to implement in .NET despite the name). That one isn't too bad either.
Ok, thanks!
IMO if this is for a non-profit DO NOT USE PAYPAL. PayPal fees are some of the highest in the industry with little to no recourse when things go wrong. If you are a serious business and want to rely on an online stream of revenue use a merchant account acquired though one of the many reputable providers. Many offer a discounted fee structure for registered 501 charities and non-profits. Merchant account providers will provide you with the necessary libraries, endpoint information, account information and any assistance you may need in integrating with their platform. For the most part integrating with a merchant system is extremely easy. Mainly you are concerned with making sure the payment information is secure to your server. After that (for most providers) you have a simple secure service or API with a couple methods. Typically one to check the validity of a card and one to charge the card. The API/service may have additional data that you can pass to set notes on the account statement such as account numbers, transaction location codes, etc. Finally you tend to get better treatment from a merchant account provider. If you are using paypal the folks at paypal know you are either: * too inexperienced to know better * are locked in for some reason outside your control (legacy for example) Paypal knows you need them more than they need you and their customer service is setup accordingly. Meanwhile traditional merchant account providers know its a pain to change (like changing your cell phone plan) but if they piss you off enough, you can and will go elsewhere. It is best practice to provide PayPal as a payment option to expand the userbase for donations however you really want to drive most donations using a CC to a cheaper merchant account if you can. 
please don't use paypal, read my response. 
Can you recommend a few to check out? 
Any kind of payment processing that you're handling yourself is a royal pain in the ass.
Not to mention they may [freeze](http://sourceforge.net/blog/warning-to-open-source-projects-know-your-rights-with-paypal/) [your](http://tortoisesvn.net/howpaypalscrewsopensourceprojects.html) [funds](http://www.escapistmagazine.com/news/view/103385-PayPal-Freezes-750K-in-MineCraft-Devs-Account) [with](http://www.regretsy.com/2011/12/05/cats-1-kids-0/) [no](http://www.somethingawful.com/d/news/paypal-fiasco-summary.php) [reason](http://www.theinquirer.net/inquirer/news/2118235/paypal-blocks-donations-diaspora) [given](http://www.xbmc4xbox.org.uk/2013/01/paypal-guilty-until-proven-innocent-account-freeze/) [other](http://techcrunch.com/2013/01/11/paypal-jay-lake-apology/) than you violated some imaginary rule. Those are only some notable cases but there are many more if you search google. Most if not all of those have since been resolved (and some rather quickly after large social pressure), but the fact is that it happens often and randomly. It's not necessarily donations or commercial selling that causes it either as it can and has happened to personal accounts (including my own). 
[Ed is the standard text editor.](http://www.gnu.org/fun/jokes/ed-msg.html)
I agree. I suggested paypal cause you seemed to be new to .net I dont know what country your in but in Australia getting a metchant account is a pain in the ass and the fees are not that much better than paypal.
This is all conjecture, the author is just ranting about what *he* perceives as code stink, where actually he's mostly just uninformed or opinionated. @1. String concatenation... StringBuilder may be more efficient in cases where large strings are being created over and over. Plain string concatenation is more than performant enough for most cases of small strings being put together. Micro-optimizations are usually a waste of time. Another thing the author doesn't mention is that the outcome of `StringBuilder.ToString()` is not interned, and therefor leads to *some* risk of memory bloat if you tend to get the same outcome from your StringBuilder over and over again. NOTE: Be careful with `StringBuilder.AppendFormat("Test {0} foo", wee)`, it's much slower than `StringBuilder.Append("Test ").Append(wee).Append(" foo")` ... that is if optimization is what you're after. @2. ... Sure .FirstOrDefault()... unless you want your code to fail if the value doesn't exist in the enumerable, in which case First() is just fine. The author here makes it sound like there's no reason for .First() to exist at all. @3. (T) vs as T... lovely, as long as T is a reference or nullable type. Also, classic casting can perform conversions, where "as" cannot. @4. Automappers... fine and dandy, unless performance is a critical pain point for your app. If it's not, then AutoMappers are your friend. If you need to squeeze every drop out of your app, one of the first things you should do is get rid of your AutoMapper, and move to code generation or just hand-made setting of values. @7. The foreach thing vs for... Again people who favor micro-optimizations over readability are just asking for problems. Is a for loop "unreadable"? No. Is it less readable? Yes. Is it an unnecessary optimization? Yes. @8. Code with what you have available, optimize later. It's not a mistake to use multiple DB calls to do something if the calls already existed and you didn't have to write them. If you can combine them quickly into one call, great. If not, don't worry, just code on. If at some point you need to circle back and optimize those calls, then do so. **TL;DR: If it works, is performant enough to pass muster, and is easy to maintain.... it's a winner. Everything else is probably a waste of time.**
In either case I think the price is to high even for individuals, at least to me. If you have a business that will buy the framework, then go for it but if it's a personal project just code it natively. If you aren't familiar with iOS or Android there is still going to be a learning curve with Mono and if you know C# picking up Java should be a breeze. Objective-C may be a little more ramp up but once you get familiar with the syntax it will like be business as usual. Then once you are done not only will you know how to write native Android and iOS apps you will also be a more well rounded developer.
That is a valid point. I am just so used to creating client/server applications where logic is located on the server. 
Love it, but you could of just linked to the [ACTUAL](http://webdevchecklist.com/asp.net/) check list and not some guys blog.
This is pretty cool. Thanks for that.
You should really consider using Oracle's new managed client. This will cure all of your CLOB problems. One thing to remember when switching though is that I think by default Oracle assigns parameters by order not by name (which is the default with MSFT's Oracle provider). [link](http://www.oracle.com/technetwork/database/windows/downloads/odpmbeta-1696432.html) and [info](http://www.oracle.com/technetwork/database/windows/downloads/odpmbetainstall-1696475.html)
I'd find a new job!
Got any openings on The Enterprise? ;) I'm constantly reevaluating my desire to stay here. The coworkers are good people and the pay's OK, but that's always got to be weighted against the terrible code base and our asshole of a boss.
Impossible to say. If the CMS hits a custom database with 40 tables and a bunch of procs that took 14 months to refine, then the ENTIRE management system could simply be in place so that one of the "this is my first job" implementors doesn't assume the database should suffer a "quick fix" for client "X". You may think it is ok to make a rolling refactor on your crappy code base, starting with "client x" and a modified database, but someone else with more experience may be saying, 1. No, we are not going down the nightmare path of having five of our clients launched on differing databases in a few months, because some new developer wants to start a rolling refactor because he found a "better" way to do selectlists. 2. No, we don't have the time, money, or resources to refactor the whole thing right now, we are trying to sign clients and make money, sorry, real world, but on the plus side, we're not actively down-sizing. I'm not saying that's how it is, or anything. I am just saying that management has a way of taking into account the real world, and you have not provided enough information to get much helpful advice on how to get aggressive with refactoring or new code. Sure you want a dream job, but you can't impose that on a company trying to survive. I think that's why your only comment when I got here, was, "find a new job". If you want to fix what you see as a code problem, you will have to define the systemic problem, and then fix the systemic problem, you will have to fix the system of management and deployment. Sorry, that's real world. I wish you great luck. If it was me, I would start defining the paths and costs and benefits of a rolling refactor, and try to sell it to management. However, typically, those are different skills than simply C#, and you typically get those skills from being in the industry a few years or more. On first glance, modifying code-behind instead of libraries and other "source", may be a sign that someone is planning an intelligent refactor and doesn't want to deploy a "significantly" different compilation for each client. So, no, I don't necessarily have a better way to do that without restricting custom client code to code-behind. But it all boils down to what is in the library source, really. And what the costs are to modifying that, per client. It also sounds like there is a strong procedural effort to limit customization, per client. In other words, if it can't be done with code-behind, we ain't doing it. Maybe this is some in-place management gut-feeling that has effectively allowed the company to control the extent of client customizations??
I won't be here forever, you're right about that! I'm fairly newly out of school, having worked there for a little over a year, and it's definitely not somewhere to stick around for a long time, but I'm building some useful experience, such as dealing with a difficult boss, falling into the role of an accidental DBA, working a lot with optimization and other things that will probably come in handy in one way or another down the road. When I quit, I probably won't use my boss as a reference, but rather the senior developers. The official reason will be that he's not an IT person so that he can't properly assess my skills, the real reason will be that he's an utter knob.
Thanks for a long and well-thought out reply. I'll try to answer as well as I can point by point. First a small explanation of the company structure to give some context to the rest of my answer. We're a small company with 7-8 developers/implementers, a small sales team and a boss who recently bought the rest of the shares from the other investors. The CMS used to be developed and maintained by the aforementioned self-taught guy, and when he quit (the same month as I started), the most senior implementer took over his job. The new guy is a very nice person who's given us a lot of insight compared to what the old guy did. As an example, the old developer once threw a tantrum when he found out that the other developers could use a decompiler to view the code he'd written. If I'd worked there when he was lead developer, I probably wouldn't have lasted half a year. The boss/owner has a non-technical background, which doesn't help to bridge the stereotypical gap between management and the programmers. Other than a boss at the top we have a very flat management structure, and all the programmers consider each other peers even though some have larger responsibilities than others. What you express in your first paragraph is a likely assumption, and the CMS does hit a custom database (with an utterly rotten datamodel, I might add), but that's not the problem. Most of our customers require some kind of customization, and the only two ways to do it is either by getting one of the senior developers who took over from the guy who originally made it to implement it, or to make it as I described in the OP. We have a policy that we don't add functionality to the core product until several customers want it, which is a reasonable choice, but even then the senior developers are so swamped with maintaining a poor code base that we often have to do customization on a case-by-case basis nonetheless. From a managerial standpoint, it's definitely point 2 that's the reality, but what's happening here is what we in Norway like to call "pissing your trousers to keep warm". Investing in one or two extra developers and letting the people who actually know how to code make the decisions. Our company is earning money like never before (more than half a million $ for a 12 man operation last year and expected to rise in 2013), so it's not like we couldn't afford to hire more people. Your final three paragraphs are very good, and I've definitely thought along the lines of fixing policy rather than code, and leading by example has helped a lot. For example, I've managed to implement at least some guidelines on proper SQL, indexing, etc., as I'm the only one at work with a background in that area. As you say, we had to change policy rather than just throw code at the problem. &gt;It also sounds like there is a strong procedural effort to limit customization, per client. In other words, if it can't be done with code-behind, we ain't doing it. If only it were that well. Customization will be sold, sometimes without consulting any programmers, and it'll be up to us to make it work. Again, thanks for a thought-out and long reply!
This is probably the most frustrating part of the Oracle .NET drivers. This defaults to false, and there's nothing you can put in an App/Web configuration file to change it, so it must be set to true on every call otherwise it defaults to positional binding (even if you appear to be using named parameter binding).
Why not create a function that accepts your query and parameter list then initializes the connection/command for you while setting this property as well?
iframes, iframes, iframes...
So the graphics design team is leading the entire development effort? Time to start looking for a new job I would think.
Let me be more specific...I'm assuming that your GD team wants basic full control. So they'll say to you "we want your fancy dancy dot net thingie HERE on our page" and they point to it. So you tell them "Fine. Put an iframe there, tell me the width and height, and set the source to MyTeamsApp/MyTeamDoesYourFancyShit.aspx." Then your team writes the page MyTeamDoesYourFancyShit.aspx (making sure the main div of the page is an absolutely sized div). That gives the GDs full control on the overall page but lets you do the fun goodies. There are other ways to go about this, of course, but this is the easiest for the GD team and probably for you as well. The only challenge is that because you're in an iframe the style sheets of the main page won't propagate to you, so you need to either add references to the GD team's styles or maintain a copy of them in your app.
Yea, the CSS was a concern for us as well. We link to them directly instead of having to make sure we always have the latest and greatest version of theirs. 
As others have pointed out, this is the exact opposite of what you should do. The site should be asp.net containing HTML, not HTML containing asp.net. If they need control over content, consider DotNetNuke.
We actually do that now, and we also handle a lot of the tedious work through a custom data access layer. It was problematic and annoying when we first started using Oracle with .NET though. There were a lot of "procedural" console applications that we had to migrate from Java to .NET, so we didn't re-factor a lot of things in the beginning. Almost everything is rewritten now though! :) 
This is a Good Thing(TM) IMO. Your best bet is to use something like [Knockout.js](http://knockoutjs.com/). Get the data via AJAX calls and push them using knockout to the controls your graphics design team wants. You can even have your graphics team be responsible for the bindings. It's amazingly easy. 
I disagree that this is the "exact opposite of what you should do". Assuming the design team knows how to use HTML, which I'll admit is a big assumption, this sort of separation can be a good thing. It's already the sort of thing we already do when we use the MVC, MVP and MVVM patterns -- giving a group sole control over the View can't hurt, provided there is good communication and coordination between groups. 
This. I am .net developer but I ditched asp.net web forms long ago. My rock stars are now jquery ui + knockoutjs + modernizr for presentation and Web API for business layer.
I agree with everything you just said... except jquery UI. I hate that with so much passion. QUIT MESSING WITH MY DOM, JQUERY!!!
Agreed. I get that they do that for all sorts of hack reasons to support IE and whatever else, but holy hell.
.net simply doesn't work like this. However, i can recommend you try Asp.Net MVC framework, it gives you a lot more control over the HTML output instead of wrapping it up in shitty abstractions (ala Asp.Net webforms)
http://blogs.msdn.com/b/bclteam/archive/2013/01/16/immutable-collections-is-on-channel-9.aspx http://blogs.msdn.com/b/bclteam/archive/2012/12/18/preview-of-immutable-collections-released-on-nuget.aspx https://nuget.org/packages/Microsoft.Bcl.Immutable
Why .net 4.5 only? Most corporate developers don't have a 100% win 7 user base yet. Humph
Because it makes use of new functionality in .NET 4.5 (IReadOnlyList and maybe the threadsaftey stuff)? Do you really expect authors to backport functionality to old versions of .NET?
As the GP stated you are not going to fix this easily or quickly and IMO you may just want think of things in terms of damage control initially. When working on a piece of code see how you can isolate it and set it up to minimize its affect on the rest of the codebase, you know standard encapsulation. I would say your best bet to getting the code slowly under control is to stop the misguided practice of not updating binaries. I do understand the desire maintain the "sanctity" of your core code base and that should remain on whatever schedule it is on. HOWEVER nothing is stopping you from making and deploying binaries of your own on a per-client basis. I assume client ASP customization are tracked in source control, custom libraries can be done in the same way. If you can get people to agree to that you might have a chance at making some things better code wise by establishing coding and production library standards (all clients use UI lib X, all clients use helper Y, all code for this pattern follows this template, etc). If you write your libraries well they become natural candidates for upstream integration (hey boss we have 30 of or 50 clients that use the same UI widget that we have now coded into a standard library, might be a candidate to roll into the product proper. Really with this strategy you are not trying to fix the world. Rather you are trying to get things into a position where you and your team can work more effectively by making common operations that the core product does not handle commodities rather than seeing repeated code everywhere. Ideally you do this with a lot of thought and try to take advantage of opportunities. For example: business needs feature X which is pretty big and covers 3 or 4 pages you hate. Estimate a bit high and fix those pages. This won't apply every time but it can apply more often than you realize if you pay attention and know the business. All that said experience tells me you will never really fix this unless you get really lucky but you can damage control and try to make life easier on yourself and honestly if you care so much about the code, be prepared to put in some of your own time to make these improvements happen. Done right its not so much a loss as if you make your job more efficient you can get more time to yourself much more easily. It is situations like these which is why I jumped to new systems development as soon as I had more experience and a company willing to take me on (pay is also better for new systems as opposed to maintenance). I also shoot for internal systems when possible as sales and marketing don't jerk the project around as much when you have a weak product owner (they are almost always too weak). EDIT: FWIW I have contracted and worked as an FTE. In my experience while being on contract means you have to deal with more tax and insurance concerns you are generally treated with more respect, paid better and management tends to listen to you more. Also being versed in the open market helps you learn how to find a job and how not to fear losing a job. If you are any good and you keep your skills up you will always have a job in this industry. Through the last couple major economic bumps the only people in my circle that ended up unemployed for more than a couple months were those that were already fairly weak in their skillset. The folks who write multiple languages, stay ahead of the curve and can fake people skills long enough to seem normal have always had work. When you are an FTE, you get more vacation and less paperwork, but in most companies you become somewhat of a "bitch" to the business side. 
I believe there's some new features/classes in .net 4 to help creating thread safe collections, although an immutable collection probably doesn't need that.
but that is not how development works. The business drives the requirements and graphics and dev are resources. It sounds to me like graphics (or marketing) is driving everything and dev is second fiddle. I personally would look for a new job unless this is just a side thing. If anything they should be saying what they need (requirements doc) and dev comes up with the technical design. 
Typically the depencency goes like this: Controller -&gt; IService -&gt; IRepository The controller knows about the services tier (essentially a command executor pattern) The IServices tier encapsulates the business logic and the IRepository layer from the controller. You can then dependency inject the IServices implementation into the controller and the IRepostiry implemention into the IServices. You can use whatever you like for your IRepository, some may argue that NHibernate IS the repository pattern. In this way, your 'model' is the IService data contract. View Model is the model for the view. NopCommerce does a good job showcasing this in a large app http://nopcommerce.codeplex.com/
Downvoted article for inaccurate title and content. There is no dependency injection here, just service location.
Upvoted comment for the clarifying link. ;)
I feel you, I was angry when I found out jQuery UI removes some elements from form tag. But old browser support(&gt;ie7) is big plus for me; with some hacks I can control the DOM. Of course there are a lot of UI libraries out there,jQuery UI is not the only option.
The timing on this blog post is incredible. I need something to slice up averages from processing data off of a video stream.
I made the opposite switch last spring from Java to C#. Changing jobs was the best thing I ever did. I had forgotten what it was like to be able to properly debug my code in a decent IDE. The Java app that I was supporting was third-party with much customization so I didn't have access to a lot of the source and we couldn't attach to the server to debug because of the way the infrastructure was set up. It was such a god-send to be able to use .NET. I feel your pain having gone the other way!
&gt;Do you really expect authors to backport functionality to old versions of .NET? I don't expect it but it happens. Like how they are taking things from .Net 4.5 and packaging them in NuGet so EF6 on .Net 4.0 can leverage some of the performance enhancements EF5 already has on .Net 4.5. I think it's awesome that more and more functionality is added to libraries instead of being thrown into the core library like before. It allows for a lot of flexibility.
Sure, except that a number of EF5+ features are unavailable without .NET 4.5. Teams are separating out their 'products' into NuGet packages but they're not moving parts that don't belong to them. From what I can tell it's a fairly slow and involved process (meetings)
What about Mass Assignment vulnerabilities, does this API has a better way to handle them? See [OData ASP.NET Web API: An Mass Assignment vulnerability in the making?](http://blog.diniscruz.com/2013/01/odata-aspnet-web-api-mass-assignment.html) for more details and a bunch of references on this topic
Don't accept a database model directly? use a special model that only has the properties on it that should be settable, like you would with any other postback (mvc etc).
The prob is that this type of frameworks encourage the creation of models that expose a LOT of variables that should never be exposed to the outside world. Look for example how this can happen in an application like the [Asp.NET MCV MusicStore](http://www.codeproject.com/Articles/471784/Exploiting-Microsoft-MVC-vulnerabilities-using-OWA)
Yes, exposing your data model directly to modification is often a bad idea. In this example i did it due to simplicity and also because it assumes that users can modify the exposed data model (entities) without any restrictions. Mass assignment is a serious problem especially when model properties affect authorization (or authentication) in some way (eg. the infamous isAdmin flag), which is NOT the case in this example. Nevertheless i understand your point and agree that awareness is important as people may try to apply the exact pattern to systems where authentication is involved. Thanks :)
Note that the two examples that I provide of this vulnerability are in JPetStore and JPetClinic, which are two of the demo apps officially provided by the Spring Framework
the reality is that Mass Assignment is a feature and is not going to go away. For me the interesting discussion is 'how can a framework help static-code/dynamc analysis engines to understand what is going on, and to find vulns' Using Static Analysis, is how I was able to detect (and help developers to fix) this type of Mass-Assignment issue in the past. Mass assignment is also a massive issue when we can change values that shouldn't be changed by the user (like the setTotalPrice). See this video for an automated example in JPetStore: [O2 Script with BlackBox exploits for Spring MVC AutoBinding vulnerabilities in JPetStore](http://o2platform.wordpress.com/2011/07/11/o2-script-with-blackbox-exploits-for-spring-mvc-autobinding-vulnerabilities-in-jpetstore/) 
For curiosity sake. What are the scenarios where F# is more efficient than C#. Genuine question, I'm just not that familiar with the benefits or proper usages of a functional programming language.
I'm just learning .Net and OOP myself (refreshing my job skills as an old procedural programmer), but as I understand it, [functional programming takes the best advantage of multi-threading](http://stackoverflow.com/questions/844536/advantages-of-stateless-programming).
Haha! No! No I won't!
It isn't necessarily more efficient at runtime since it all compiles down to IL and runs on the CLR just like C#. It can be more efficient to develop in if what you're doing is encumbered by type strong typing. It tends to be more useful for high level programming than more "pure" programming tasks. You trade some control for convenience.
What's visual about f# any way? 
Also, does anyone know of any public-facing asp.net sites that show lots of different controls?
What control do you cede?
If you have never tried F# I will recommend spending a little time with it as it might open you up to some concepts you are not used to. I know when I first tried it back when it was still at Microsoft Research (in 2007) I felt it helped me understand lambdas, linq and a whole bunch of other 'new' concepts that were coming out around the same time. Just beware not all of the books available make it so easy to understand. 
This is the usual thing which people say when talking about functional vs. imperative languages. Usually they mean loss of explicit control of memory layout and line-level operation ordering, though I'm somewhat under the impression that it is just repeated from being heard, rather than understanding this. Even then, it's a bit disingenuous, since the CPU and optimizing compilers really remove you from this control, and in C# the GC does even more to remove "control." So, I think it's just a way to draw a line in the sand and make choosing easier.
Processing sets of data. The language is more oriented to "shaping" data via transformations (e.g. functions). Given F# 3.0 type providers, it's even easier to combine, process, filter, aggregate and categorize sets of data via succinct and easily readable language constructs.
The IDE.
That's the implication of "line in the sand" - an arbitrary choice of a distinction often prompted by some very localized or exaggerated conditions. As to "more control" an easy example is using pointers on GC-allocated arrays of structures. I can control memory access to a much finer degree, which may give me more control over performance. You can do this in C# but not in F#. Obviously this example may spur many exceptions to be noted, but my point to begin with was the distinction is often more useful to convince people that there is a real, immediate and necessary advantage to C# (and in the same way to C++) beyond just "it's the language I know better" or "I believe it has more power" rather than being actual advantages.
Yeah but only because you are passing around immutable state everywhere. You can do the same thing in any language with smart design choices, it's just that functional languages tend to enforce this and usually (if at all) make you break it explicitly (like the mutable keyword in f#)
Ive had the same experience, however I HIGHLY recommend "real world functional programming" by Tomas petricek: http://www.amazon.com/gp/aw/d/1933988924 I read this recently and before I knew it I was writing language parsers in F# and workflow computations for mathematical analysis. It's super easy to read and extremely well written. His book will definitely get you to grok functional.
That's [something that F# can do also](http://msdn.microsoft.com/en-us/library/ee340455.aspx), though. I'm not convinced that control is really something that C# offers that F# does not.
I know about this but it appears you can only stackalloc an array and not pin a GC object with it.
not accepted by the dotnet reddit moderators :(
No probs at all, thx for that :) I also fixed the original comment
I've been on the fence about that book since he first announced it. I'll take this under advisement. One other thing I forgot to mention is that the F# team is very active and willing to help their community. Even Don Syme will answer your questions.
Yeah he's really responsive. Easy to tweet at and even left some constructive comments on a few f# blog posts I wrote. The f# twitter community is really active and helpful as well
I didn't mean to imply you give up control completely, more that you give up *convenient* control. Explicitly defined data types used to be a central tenet of C# (inherited from its C syntax) though that principal has eroded with the introduction of `var` and `dynamic`. In much the way you have to exert effort to avoid declaring your data types with C#, you have to do the same with F# to explicitly declare your data type. Or at least that's the way it seemed to me as mere dabbler in F#. It's a cool language though. Seems like it should work well for doing things like building view models that tie your UI to your lower layers with less fuss than C# demands. I haven't tried though, so maybe I'm way off.
While I think C# 5 async methods are cool, I feel like the initial implementation is easier to understand.
The article contains an assertion which is terribly wrong. It suggests that it is better to databind to objects which don't support INotifyPropertyChanged if possible. Databinding to objects that aren't DependencyObjects or INPCs requires WPF to allocate and monitor PropertyDescriptors, which consume quite a lot of memory, and cause memory leaks in many versions. So unless all of your bindings are set to Mode=OneTime, you're honestly better off throwing in an unused implementation of INPC, just so the WPF runtime has a cheap way of determining that no property updates are being fired. I prefer directly using ChannelFactories, but I wouldn't recommend this on a large project with many service interfaces. Service proxies are not an art, they aren't worth even a minor investment of developer time, and you can easily reuse transport classes in shared assemblies when generating proxies.
Or you could run the .NET portion on a separate environment and run it in an iframe.
Build your own webbrowser. Use a textbox, a button, and a webbrowser control from visual studio 2010 express. Put some back and forward buttons on it too. You can have a fun learning time customizing that for quite a while.
sure, i will try it.
If you are already reusing the transport classes, why not take the extra step and reuse the service contracts as well? Why bring a clumsy code generator into play for what amounts to one extra class per service? 
Plus, why bind the model view to the ui anyway? It's MV-VM, the VM is kind of important.
A couple reasons. Again, I choose service contracts personally, but the proxies have their purpose, particularly on mixed teams. * WCF configuration is your real source of runtime error nightmares. The proxy generator does an okay job of giving you a client-side config entry that you can move to your app.config. Anyone with a little experience can do this by hand based on the server's config, but I don't think I've ever seen another developer get this right on the first try. WCF errors aren't terribly descriptive, so when it goes wrong, it is a minor delve to get things working. All avoidable headache. * Letting the proxy generator think a bit about your data contracts can help spot errors at design time. The CLR comprehension of the DataContractSerializer is fairly dumb, as the article says, and it is nice to have it show its work. If your model types are irreparably skewed by the CLR -&gt; WSDL -&gt; CLR translation, then that is a problem that would've only been visible when you're debugging your service, potentially requiring a WCF trace to get to the actual problem. You can always regenerate the proxy using shared types afterwards. * Developers coming from a ASMX background can start being productive in WCF without schooling them for a week in all the stuff they're going to get wrong. You need at least a passing familiar with WCF channels, factories, and configuration sources just to get an interface-only solution working, and you need a far deeper understanding of channel lifecycles, faults, and cleanup patterns in order to make something correct and durable. Or you just tell people to use the code generator. It will almost certainly do a better job in far less time. And re: transport classes, well, the whole article was about how the proxy generator did a bad job on transport classes, and it kind of seems like they are only upset because they didn't notice the "Reuse existing types" checkbox on the configuration screen.
Any reason to do this other than shits and giggles?
Actually I've seen the reuse classes thing fail miserably with Silverlight. In the worst case it won't generate anything when that option is checked. Another problem is DateTimeOffset. WCF doesn't like exposing that type and gives you a weird proxy. But with shared code it doesn't have any problem serializing and deserializing the values. 
I don't use XML configuration for WCF, it's just a big pain in the ass. And the code based configuration is easy, you just need a couple of mostly empty objects. I don't see why you need to know about factories, channels, and configuration sources. Just add one subclass and let the internals take care of all that just like it would for the proxy.
[This might get you started.](http://msdn.microsoft.com/en-us/magazine/ff960707.aspx) Good luck!
Yes. As far as I'm concerned, all of the popular test frameworks are garbage. I shouldn't have to write five different tests just because it can't handle more than one failed assertion.
The M in M-V-VM is also important. The view-model should contain: * References to the models * References to the services * ICommands to glue them together The models themselves contain the data that is bound to the UI. And the models are smart, they include features such as... * Validation * Calculated properties * Change tracking (IEditable and/or IChangeTracking) Models are pure. They can be unit tested without resorting to mocking frameworks and the like. View-models are essentially glue code, messy and better examined with integration tests. ***** Of course you don't have to use the M-V-VM pattern. There are times when it is acceptable or even preferable to cram the model and view-model together. Consistency in an application is far more important than ridged adherence to a design pattern.
Yes, some good points. Regarding the IDE integration and start/cleanup methods, I have considered those. They are listed as potential next steps. Since this post is about learning, I didn't want to make the test framework too complex.
This sounds like you're testing more than one thing in a single unit test. For me, a single test, tests just one thing. If that means you write multiple tests, then so be it
1. An assertion is not a test, it is merely a component of a test. Properly checking the results of a function that returns a complex type may require a dozen assertions. 2. D.R.Y. Don't Repeat Yourself. If you have a dozen tests that are identical except for a single assertion statement, well that's just wasted effort. 3. Who said anything about unit tests? Is that really the only test you are going to write? Of course not, that would be stupid. 4. The amount of time it takes to run all of your test cases is important. If you are wasting CPU cycles repeating the same setup over and over again then you are adding unnecessary delays. 5. The setup for integration tests is very, very expensive compared to the amount of time it takes to execute an assertion. Even if you can get away with one assertion per test with trivial unit tests, you aren't going to be able to with the far more important integration tests. 6. If you tell me that you are writing comprehensive unit tests but still only have one assertion pre test, I'm going to call you a liar. No one is actually willing to take that amount of effort. At best they'll repeat the test two or three times with different assertions, but never the whole thing. 7. What is an assertion? If writing Assert.IsNotNull(a[0]) and Assert.IsNotNull(a[1]) is bad, then why is writing CollectionAssert.HasNoNulls(a) ok? 8. A "test method" is not a test, it is merely a container. Inside it may be dozens of tests, especially if you use the data injection techniques offered by the better frameworks. At this point in the conversation you are expected to offer some sort of lame-ass reasons for one assertion per test. Maybe you'll pretend that you are too retarded to use a debugger to figure out why a test failed. Or maybe you'll feign ignorance of the "message" parameter on the assert functions. But honestly, I've got no patience at all for "best practices" based on blog posts by novices that wrote their first unit test a week ago. So unless you've got something new we can drop this thread.
You are far to angry to ration with, but I'd recommend you pick up xUnit Patterns. Specifically Chapter 5 will be helpful
You can use all the same development patterns in unit tests that you do for actual applications. Most test suites I have seen developed for a full applications end up implementing a number of strategies from inheritance to composition along with various development patterns to decrease repeated code in tests. It sounds to me like you are expecting to have a flat test class with simple asserts and make it work. No test framework has addressed what you are wanting. I think you misunderstand what "framework" means. For a test framework it is a simple execution/reporting harness. It sounds to me like what you might be interested in writing is a unit test SDK that allows developers to setup common test scenarios with minimal code. For example you can do things like leverage nUnit or MSTest and can create a framework that runs a suite of automated constructor tests on all classes. You'll find that most of these frameworks provide hooks at various points to customize things a bit more. Like most API's and frameworks, what you get by default is useful for the most general use case. The power comes in when you start building out the right patterns for your needs. 
Thank you. This, and many other tutorials like it, instructs the developer to create a new Silverlight for Windows Phone application, then add the IronRuby assemblies. HOWEVER, there is no longer a Silverlight for Windows Phone template available in Windows Phone Visual Studio Express 2012. I tried importing IronRuby into a C# Windows Phone application, but I'm getting several build errors and warnings related to IronRuby / DLR. http://stackoverflow.com/questions/14541631/several-errors-and-warnings-for-ironruby-c-sharp-windows-phone-app
Seconded.
Glad you found it useful. I work with multiple platforms but Visual Studio with C# is easily my favorite to work with. The process though can work with any stack you choose. I just decided to start dipping my toe [in the open source arena](http://kerbaldata.codeplex.com/) (this project mainly deals with custom data serialization/de-serialization patterns) if you are looking for any code samples. Everything is under the MIT license. Best of luck and thanks!
Thanks for the kind words! It just so happens I have a project that I am kind of working up to, and it happens to be a data based project. I might just have to make my first ever post on reddit when I get stuck (which could be VERY early on). 
xUnit cannot support multiple assertion failures, so of course they are going to only promote patterns that don't need them. But that's just a work-around.
The book is titled xunit because it applies to Junit, runit, nunit and others. It is five years old and is considered to be the bible for test driven dev frameworks. But surely you already knew that and can't possibly learn anything more on the subject so I apologize for even trying to help
Remember when I said this? &gt; As far as I'm concerned, all of the popular test frameworks are garbage. I shouldn't have to write five different tests just because it can't handle more than one failed assertion. Basically what you just told me is that book is the "bible" of garbage frameworks. Even if it really is the absolute best book every written on the subject of "Junit, runit, nunit and others" that doesn't change the fact that "Junit, runit, nunit and others" are fundamentally flawed.
Oh, very nice! I've been looking forward to something like this. Frankly, I'm surprised it hasn't happened sooner. Also, this needs to be in bold in the article: &gt;But even if you are not using TFS, you can use Visual Studio with Git to work on a completely local repository, or to collaborate using Git hosters such as GitHub and BitBucket. 
Why not Mercurial?
What about VS2010. I hate the 2012 checkin window.
Because Git is orders of magnitude more popular than Mercurial, plain and simple. I am a bit surprised Microsoft has not tried to create their own DVCS, though. Or maybe they are working on it. 
No VS2010 version, read the VS Gallery Q&amp;A 
Yea, it just seems that Mercurial gives you virtually an identical feature set to Git, while being a lot easier to work with, especially on windows. Hopefully I can use this: http://hg-git.github.com/ so I don't have to switch over to Git.
When they were born, each one of Mercurial, Git, Bazaar and darcs offered some unique features. Gradually, they have copied each other and Mercurial and Git are remarkably similar. There is one feature where Mercurial is still clearly superior to Git: large binaries. 
&gt; I am a bit surprised Microsoft has not tried to create their own DVCS, though. Or maybe they are working on it. The Microsoft Dev. division seems to be doing a really good job recently of recognizing when some non-microsoft product is good and embracing it rather than just trying to make their own shittier version of said product. Another good example that comes to mind is the node.js support in Windows Azure.
Same... What were they thinking on that one :S
Good to hear. Looks like GitExtensions is still the route to go for those prior to 2012. I realize there are SCC plug-ins for Visual Studio, but they've been a bit wonky in my experience.
While not exactly new, PdfBox.Net and IKVM are pretty cool, despite some performance trade-offs. I found iText, and plan to play with that next. A short post introducing PdfBox and IKVM to those who may not have used either. Feedback and constructive criticism much appreciated!
It's worth noting that this is a preview and not meant to be installed on production machines.
So a separate PHP can validate that the user is logged in. For example: 1) User logs into .NET site www.main.com - A user/session is automaticaly inserted into a table. 2) User clicks on a dynamic link to php.main.com with their user/session in GET 3) The PHP application checks the SQL table to see if there is an existing user/session matching the GET, then automatically logs them in. 4) After a period of time, the SQL Table with user/session will be cleared. I've also looked into Changing Session State Mode to SQL instead of InProc, but I'm not sure if this will break the existing site. It would be nice though, since PHP could directly read out of the database.
The .NET developer is gone
Pick one than, your solution is WAY too convoluted. Imagine the guy that will come after you, he's not going to understand a bit of what you're doing. In fact, stick to .NET. Are you even using a popular php framework?
www.youtube.com/watch?v=CDeG4S-mJt
Maybe I'm wording this wrong. Simply put: When a user logs into the ASP.NET site I want it to insert the user id and session number into a database.
I'm pretty sure I understand. You want the person to login through the .NET site and then get forwarded to your PHP portion of the site. If I'm correct so far, you're going about this 100% wrong. Please answer, for the PHP portion of the site, are you using a popular framework that supports php 5?
Codeigniter Edit: Forwarding does not have to be automatic.
Switch to a Codeigniter login system than. (although Codeigniter isn't php 5) The way you're thinking about doing this is REALLY hackish. As someone that learned PHP then switched to C#, you should just keep it in C#. In fact, since you're used to an MVC framework, go look at C# MVC.
The .NET login site is linked to numerous other .NET applications and can not be replaced easily. The customers will not want to login twice. I'm not really worried about hackish at this point, because it's taken way too much free time already and just needs to get done. I use CodeIgniter to knock out apps quickly because I'm familiar with it. I've just never had to integrate it with ASP.NET and I didn't think passing sessions would be so hard. I've got this question out on ASP.NET and Stackoverflow, and I've yet to get a solution (hackish or not). And Codeigntier 2.0.0 made the switch to PHP 5.
The call stack code map integration looks pretty baller: http://blogs.msdn.com/cfs-file.ashx/__key/communityserver-blogs-components-weblogfiles/00-00-00-45-92-metablogapi/1856.clip_5F00_image001_5F00_4F984BF0.png
It still isn't fully Php 5 last I checked. Working with your hackish solution, I still don't get how you imagine this working. What is the point in putting the .NET session into a table with the userid? You plan on using what's in the table as your verification that the current user is logged in? Because I don't think you'll be able to match the .NET session via php.
I'll create a dynamic link on an www.main.com with: php.main.com/autologin/{UserID}/{Session#} The PHP app checks the UserID and Session# against the database and automatically creates a PHP session to use the side-app with. The rows will be removed every 8 hours or when the user logs out. Not ideal... I really don't like passing credentials site to site, but I'm an open to alternatives within the stringent scope I'm working within, of course. If I can't get it done this way, I'm going to try changing the Session-State to SQL and reading sessions directly from the database. Thanks for listening, this is driving me nuts!
You got a lot of the technical aspects down. Maybe add some paired programming if you wanna go totally XP. But I think the most important thing is to sell your current employees on these best practices and, in the future, hire/cultivate software engineers that are passionate about doing things the right way. 
You sound pretty solid. I don't put a lot of stock in certifications, especially for things that can be so variable like development (DBAs, server admins, those sorts of things are a little easier to evaluate). Keep on doing what you're doing and boost your soft skills. You're already doing some of that with that last bullet point, but no one can ever really become "perfect" in that regard. Selling people on doing things the right way and putting a **sane** amount of rigor around standards &amp; documentation is always a balancing act.
Honestly, I'm still going to recommend that you just learn C# and code it that way. If you're familiar with OOP principles, C# will be pretty easy. Compared to PHP it's a lot more structured and there are SO many libraries already out there that come packaged with C#. The way your planning on doing it definitely has security vulnerabilities as well, so you'll need to work something out so people can't hijack the sessions. Checking IP/referrer could possibly work, I guess.
&gt; I was in a similar role at a previous job, and we did a monthly "show and tell" where a programmer would present work before the group and it would allow everyone to give feedback and ask questions That sounds great! I've worked in too many places where they just let programmers (and other employees) go down rabbit holes and then months later blamed the programmers for it.
IME certifications are really only useful to employers who are looking to get a certification (e.g. Microsoft Gold Partner), and are otherwise not very useful to the employee unless earning the certification exposes the employee to knowledge that s/he did not previously have.
In my opinion the thing that advances a programmer's rep/career more than anything is an ability to work with non-programmers. A lot of people can write code - the guy/girl that makes the big bucks is the one that can talk to the Accounting Manager in business speak, figure out the debits and credits, THEN take that information back to the dev team and make them understand it from a code stand point. Also, everyone here is saying that they don't put any stock in Certifications - but everyone here is a programmer. We all know that a cert just means that you can read a book and pass a test, but if you're looking to move to a different organization then certifications actually go a pretty long way. Most of the time you're not being interviewed by a programmer, at least at first. You have to look at it from a non-technical point of view, because chances are the person that's deciding who gets a call back is not a technical person. If they see that Joe is a "Microsoft Certified Professional Developer" and you "just" have experience, then Joe is probably going on top of you in the resume pile. Anyway... just my opinion but I come from a consulting background so it may be totally different if you work in other areas.
Put this in your Page_Init: Response.Redirect("http://www.reddit.com"); Problem solved.
Without seeing the actual page, it's hard to be too specific with the suggestions, but the first two things that come to mind are 1) put all the top level tabs in separate pages and 2) ditch the update panels
I'd say nuke it from orbit, but turning off viewstate is probably the best short term win here. People seem to forget that the entire page lifecycle is still executed even though only the update panel is updated.
I would need more context to answer properly. Does all of the information have to appear at the same time? In other words the same request &amp; output? Does all of it have to be editable or actionable? All within the same transaction? I've moved away from trying to build giant pages. The last one I did was way over engineered due to the requirements (full lazy loading, extremely fine grained data sets that allowed pure client side filtering &amp; calculations). The thing was OK in IE8, pretty fast in IE9 and fucking blazing in Chrome (seriously we are talking 0-10ms vs 1500+ms in IE8). However, it took a lot longer to develop and test due to this. It was my fault for not pushing back against the product team and telling them it would be just as effective loading just the filter data set each time. If you can abstract out sections of the page, I would and then at the very least lazy load the different areas/tabs. The method of doing that depends on what this page really needs to do. Honestly, if the functionality can be split into multiple pages (forms) do it. Even in web forms you can have nested master pages to make sections look similar while the actual page only contains the contents of the lowest tab in the hierarchy. That should greatly speed up the performance of any given tab. Also, I would question why do you have so many different levels of tabs within a single 'page'. That smells like a bad UI/UX &amp; workflow design. Remember one of the easiest forms of getting performance is to not do any work that isn't necessary. 
It didn't sound like he was going between sites. I thought he was just trying to add some things to his friend's website, but he only knows PHP so he's trying to add on to the asp site but with php.
From his explanation, to me at least, it sounds like the sites are going to be hosted on separate sub-domains. If the new site is an extension of the old site, then I agree it should just be done in ASP.Net. If it's going to be a completely new site, then some form of session sharing is going to be needed either way.
I thought he was putting the other part of the site on a different sub-domain because he was only really familiar with php. I could be wrong, it's just how I read into it. 
It seems to be mis-billed. My parsing of the AMA announcement is that the discussion is about the Surface Pro (and whatever Win8 specific questions pertain to it).
12 year senior software engineer here with most of that time being in the microsoft space and pretty much focused on .NET since it came out. Too many APIs? The .NET framework is still there and not going anywhere for desktop apps. Make no mistake, traditional WPF apps aren't going anywhere. Every single BCL class is still there and the API's work exactly the same way...in desktop mode. Now yes there are changes in Windows Store (WinRT) mode. RT is not meant to replace the desktop it's simply another mode of applications to run in and more geared toward running on devices similar to the surface (think mobile app vs desktop app). The api's are slightly different, yes, but if you've got enough experience with .NET the transition is easy. I picked it up over a weekend. 
On the technical side of things, maybe some more awareness of various tools/libraries approaches (I don't know if you know any of this or not). This is also on the assumption that team leader is a technical position, some places it is and others it's more of a managerial position. Here are some questions to think about, no need to answer: You mentioned TFS (I have strong opinions about it but this isn't the place for that argument). Have you used alternatives like git/svn/hg? Can you say it is the best choice for that company? Would a git/team city combo be better or more cost effective? Would you use msbuild or nant? Do you know about various unit testing, mocking and IOC frameworks? Enough to make an informed decision? Do you know a broad range of architecture patterns and there pros and cons? Do you know how and why a service bus would be useful to the product for instance. Are you aware of other agile methodologies, kanban etc? SCRUM doesn't suit everyone and you need to be able to analyse if it suits a given company/team/product. You don't have to be an expert on everything (no one is) but being aware of what options are open to you is important. As the saying goes "everything looks like a nail to a man that only has a hammer".
I believe one of the long term plans for TFS is to turn it into a DVCS, can't see it going well myself.
&gt;out of the box That's what the big deal is. The subversion plugin, for example, was extremely buggy and incomplete for a long time. They are both commercial IDE's, it really is an apples to apples comparison.
Exactly this. Desktop development, be it win32 or .Net is as stable in terms of APIs as it gets. Win RT is simply evolutionary step to bring platforms together and if new iterations what many consider as a weakness now (because of segmentation), will basically be its major strength in future (because of single dev stack) - develop once for all form factors. You cannot get there in one big jump, but rather in many focused steps adjusting the strategy as you go.
Looks cool. If it works like they say, that's pretty awesome.
Nothing new in my opinion
Well it's a plug for a commercial library. There's a ton of boilerplate code behind that method call, you could do it *all* in one line if you really wanted to. IMHO it's not 3 lines of code if there's a supporting class.
How is it commercial when it clearly says GPL? 
I've just come across this and I wish something like it existed before I spent weeks trying to learn socket programming. Time I could have spent making a better GUI for my own application. Can you point to another library like this?
It's a commercial product when you want to make money in a product which uses it or if your product isn't licensed under GPL. http://www.networkcomms.net/licensing/ Therefor, a plug for their product *even if there is a free version* means it's a commercial product. 
So is it the fact its GPL you don't like or the fact that you CAN also use it commercially for a price? If I don't plan on selling any software I write how does that affect me?
Fair point. I agree with you there.
WebSockets, SignalR, .net remoting, Griffin.Networking, Indy.Sockets, FastNetworkLibrary, nservicebus, publish/subscribe frameworks, ServiceStack etc all have features that can get a similar job done. Sure some of them are over http and thus aren't as simple as sending a serialized object down the line but I think that service stack and remoting are just as good for a similar outcome. Sure some apps require small slim packets and you can create these with just the system.net classes. Check out remoting and griffin.networking. Edit: https://github.com/jgauffin/griffin.networking, http://supersocket.codeplex.com/, http://www.indyproject.org/SocketsCLR/index.EN.aspx, http://www.servicestack.net/, http://en.wikipedia.org/wiki/.NET_Remoting
I agree. Reflector the code turns out its just using System.Net.Socket .. shock HORROR! Pay me for some wrappers around the BCL!
Is it web-scale?
You use reflector on open source projects - just to be cool
Also WCF which IMO is the granddaddy of them all. You can build contracts and connections via any port, transport and data format as well as support multiple types of connections and contracts for the same functionality. Most people think it's just for Web Services, that is just the more popular usage and the easiest to configure due to the multitude of examples. 
Just wondering, can you build something like an IRC or SMTP server using WCF?
I reflect my own code to see what the CIL looks like and to see what the CIL to C# is "interpreted" as. Sometimes you can find some good refactorings just by looking at your own reflected code.
Hey guys thanks for the XDT love (I'm the Owner of XDT at Microsoft). I love it too :) I'm working to open source XDT as stated in the discussion in the NuGet forums. It's going slowly but the process is still going. If you are looking to do XDT transforms for other projects than web you can install my SlowCheetah extension http://visualstudiogallery.msdn.microsoft.com/69023d00-a4f9-4a34-a6cd-7e854ba318b5. I'm updating SlowCheetah to consume the XDT package we recently released. Let me know if there are any questions on XDT.
The feature page would suggest yes.
Looks like it, is there another free snippet of code out there that does this though? Might be worth while taking this and just adding the methods for 4.5 and 5.0 if you really need it. Might need some updates for Windows 8 as well.
Now that's nice. EntLib eventually improves. Soon^TM //edit: formatting
I dunno, Web Deploy is pretty darn easy. It's also free. I'd also argue that *not* having to use PowerShell is a lot easier than *having* to use PowerShell. Have y'all considered writing a VS extension for it?
WTF? Why would you want to run your unit tests on a device/emulator? If your instantiating your UI it is not a unit test.
Looks interesting. I assume I'm pushing app bundles through your servers though? I'd suspect that's an immediate no-go for PCI compliance. Other than that, I'd be curious how the story compares to something like Octopus Deploy.
Well, you don't need to do any scripting until you are fine with the default deployment flow Appveyor provides (which has built-in provisioning of IIS web sites and SQL databases). It was a VS.NET extension in v1, in fact :) Then we got some initial feedback from customers and decided to focus on command-line support (to be IDE agnostic) and web UI. If there is a real demand to have UI integrated into VS.NET we could think on getting this functionality back. You can use Appveyor NuGet http://nuget.org/packages/Appveyor/ to automate from VS.NET.
We have 60 IIS machines that we have complicated scripts to deploy to. Here are the problems we have that need fixing: 1) The guy who is deploying needs local admin rights on every IIS machine because Web Deploy wants that...especially if you are changing applicationHost.config. The required permissions and setup of WebDeploy and it's components is a complicated, undocumented beast. 2) We can't run the release on all the IIS machines at once or everything will go offline for a minute or two while the IIS worker processes recycle and all that. We do 3-5 IIS servers at a time. Our application takes a minute or two to start-up because we have programmers who don't think about that kind of stuff. 3) We have to write scripts to orchestrate taking X servers out of rotation via the F5 then uploading the code, warming up the server and then re-adding to rotation with the F5. Octopus and Appveyor don't really address those issues. I think you guys have a really, really good start and you could charge a lot more to bigger clients if you made something that was better than WebDeploy and tackled bigger problems in deployment. This looks about 5% better than WebDeploy in terms of ease to use but now I have to worry about all the security vulnerabilities that may go with this and now I would rather just stay with what I have. Keep at it. Also feel free to message me and maybe we can chat on the phone for 5 minutes.
Literally VS.NET? **edit**: You use "VS.NET", which are the [IDE products released in 2002 and 2003](http://en.wikipedia.org/wiki/Microsoft_Visual_Studio#Visual_Studio_.NET_.282002.29) codenamed Rainier and Everett. Subsequent (2005+) versions dropped the .NET moniker.
The App_Code folder in a custom class is usually the best way. Did you add the App_Code folder yourself or right click and have Visual Studio add it automatically. It may be missing a reference or something. 
Also, is the method public and static? If not you'll have to create an instance of the class to use the method. 
Also, a namespace can help promote visibility across the project.
this is nice book and very good price. I like the authorisation examples and also webapi examples. I want to know more client framework with mvc like backbone, jquery ecetra. Can you provide?
Public static ....
As some one who doesn't do much web development, can some one explain why this answer is apparently so unpopular? I can see why it might not be the best answer, but the downvotes would suggest it's patently terrible and I don't understand why.
I WAS excited, until the download page errored out. Though I love what their doing for a cross platform solution unlike PhoneGap.
Where is the ubuntu installer? I see Windows and OSX. Studio is basically monodevelop + more. It would be nice to use what amounts to the pro/commercial version of monodevelop in linux.
It's a product aimed mainly at enterprise developers. What kind of support does MonoGame and Unity give you for free?
You can use the free Starter Edition... and the Indie Edition is $100 cheaper than the previous lowest-cost subscription.
I'm sure the Ubuntu packagers will be rolling Xamarin Studio packages for Ubuntu shortly.
Visual Studio is quite expensive for personal use, which is why Indie doesn't come with VS support. A lot of work has gone into improving Xamarin Studio and we will continue pouring a lot of work into it.
Visual Studio express is free and just because higher versions of Visual Studio are expensive, what makes you think personal developers are willing to pay a high price for Xamarin? infact, my work place pays for my Visual Studio via MSDN. I also got Visual Studio during University for free through Dreamspark. I'm not saying Xamarin is bad. I think it's really great, but it's just not financially viable for personal developers or indies. Businesses, maybe.
I think the download errors should be fixed now.
$1000 per year is for updates. You can pay it once and use that version for building apps after one year.
How can I evaluate the Visual Studio version without spending 999?
Still though. Seems awfully steep, especially when I could develop in Eclipse, using stock ADK/Java, and something like Codename One to get to iOS. Or Unity. Unity is $800 for both platforms, but I see the value, if I'm making games - for that price I get TONS of rendering, networking, AI, IAP, etc., code, plus C# scripting in a standard, open IDE (MonoDevelop). With this, it's not obvious what I'm getting for $1000, beyond a proprietary IDE which is supposedly "way better" than the several already proven environments, with years and years of history and bugfixes behind them... I watched the demo video, which seems to highlight features like autocomplete, and debugging. This is a bit like Ford advertising new 2013 cars that include features like "wheels" and a windshield. Can Xamarin refactor? Does it integrate with SCC? Does it support plugins? Graphical UI editors / RAD prototyping? All of these things are available in free alternatives. I mean, it looks slick, but that's about it... am I missing something?
Thanks for the answer! Wow. I started reading c# books from the library which gave me a good "feel" but you know, you have to gain experience by experiencing. Thanks for the great response!
thanks! So I ended up adding a new file, but declared the same namespace as the "sample" file my buddy set up. Then I created a new class called AdminFunctions, then a public static void LogSave() My problem now, is that I want to set a TextBox from this function, but I can't! Can you help?? I.e. I have at the bottom of each page "This page was last edited by XXX at 12:01pm.", I wrote a function to SAVE into the log, it works fine. But I wanted a function to UPDATE the stuff on the page, and it says the control doesn't exist in the current context. Thanks again!
FWIW, Xamarin Studio is just a rebranded MonoDevelop (we are the core authors / maintainers of MonoDevelop that Unity ships). Does Xamarin Studio have refactoring capabilities? Yes. Better than the refactoring available in MonoDevelop as shipped by Unity (they ship MonoDevelop 2.8.2 which is quite old). I'm not sure what you mean by SCC (I'm horrible when it comes to acronyms), but I suspect you mean source control. Yes, Xamarin Studio supports git and svn. Does it support plugins? Yes. The iOS and Android functionality is all done via plugins, for example. So are the version control, debugger, and refactoring features. It has a graphical UI editor for Android. For iOS, it currently launches Xcode's Interface Builder. More info on the Android UI designer here: http://docs.xamarin.com/guides/android/user_interface/designer_overview/designer_walkthrough 
Does it have full support for async/await?
It is the XXX part you want to update? For that it sounds like you may want a Literal control instead of a TextBox. The thing to keep in mind is that a page ends up being a class and the controls are members. Even if the page passes itself to your data class, the data class won't know what your pages have in common, so you'd have to pass it as "object" which doesn't help you. You could have all the pages inherit from an interface but that'd be kind of a weird way to do it for something like this IMO. I think you could pass the page as Page and use the FindControl method with the id of the control and set it if it exists. You could also do this on a base page you inherit but I don't think either of these ways is the best. If it is something happening on one or two pages, I'd have the data class return a string or whatever other data and have the page set the control on pre_render. For something you need on most pages I'd look into Master Pages since that is really what they are for. This way you can get the data and set the control in the master page and just have all the other pages use it. I definitely think you should invest in an ASP.NET book if you're planning to do more with this. That'll give you a much better idea of the overall approach and how all the parts are intended to work together. Maybe like Pro ASP.NET 4 (4.5 ver is coming out in July it looks like too). Also, as others mentioned take a look at MVC if you have the option. It is newer and has more in common with frameworks on other platforms (making your skills easier to transfer). It also does less to obscure how the web works. Webforms certainly can work but it can be easier to get yourself into weird situations with it if you aren't careful.
I don't think it is terrible necessarily. If it is something that the pages really have in common and you don't put too much of the actual functionality there it can work well. Like say you have a User repository that has security stuff in it you need to use on each page. It might be worth making the repo available in the base class or perhaps wrap the security call you'd want to use. You have to be really careful with this though since it can easily expand and become a "god class". I was on a project with a base page class that was about 10,000 lines long (it also inherited from some other base classes!). Different pages would implement different interfaces and the base class would do things based on what "kind" of page it was. It worked but was pretty difficult to deal with. In general people tend to agree that one should favor composition over inheritance except in specific instances. There's a lot of aspects covered in this thread: http://stackoverflow.com/questions/49002/prefer-composition-over-inheritance Edit: This has a really good overview of everything involved even with the missing diagrams: http://www.javaworld.com/jw-11-1998/jw-11-techniques.html
Is it worth learning xaml for a beginner because html5 and js is what you should be investing in.
Yes, it absolutely worth it. WPF isn't going anywhere. Also Silverlight migh be under a cloud at the moment buy Msft aren't going to bin it completely. People who say that HTML5/CSS4 are replacing Silverlight clearly don't know what Silverlight is. Silverlight is not stateless. HTML is. They are completely different tools for completely different jobs. 
Unfortunately the first part doesn't have anything specifically about monads. I don't blame EL as this is part of a series and a good way of introducing the topic given the parts to follow, but linking to this is kinda useless at this point.
Well that was... not helpful or informative at all.
Monads part 1: Doors and Windows From Classical Era Through the Present
No problem! I'm glad you enoyed it. and to @cheesekun, while I agree that it's important to learn HTML5 and CSS4, I do not think that you will ever convince me to use them over WPF, Silverlight, or WinRT/XAML for rich client applications. 
This is no longer the case.. Xamarin has released v2.0 which includes an free license, a new IDE called Xamarin studio that is made specifically for Android and iOS development with c# .NET, AND the ability to develop iOS applications in Visual Studio!!! now of course there is a small catch.. The visual studio integration works by searching your network for a Mac computer and it will use the Mac to build and deploy the iOS application. Even still you are able to write the application and debug the application in Visual Studio! They've also said that 100% native iOS development in Visual Studio is the next goal. You can read about it here http://blog.xamarin.com/announcing-xamarin-2.0/ Please check out my development blog at http://www.refactorthis.net
Still the wrong abstraction.
&gt; Ok I might of over stated that everything can be written in F# *Twitch* But nice article, never really got around to take a proper look at F#, will have to do that.
Now lets create a LinqToReddit!
Yeah, the original plan for the library included using them, but I didn't manage to add them in time (the library was written for my thesis).
Hmm, the Reddit API doesn't look like it would benefit from LINQ much :-)
I'm interested to see which route he takes to describe them; I've been kicking around the idea of getting back into writing with a "monad for C# devs" article, but can't seem to pull the trigger on it...the scattered notes I've jotted down start with basic SelectMany calls, then expand on that - although truth be told, I'm not sure how many .net folks really understand SelectMany as it is...
A lot of great info in there. Thanks. 
Looks interesting, might play with this some now seeing Roslyn in 2 different contexts (another thread earlier in the week also highlighted Roslyn) The one thing that confuses me is where does the author get that coding in .NET has an IDE requirement? Sure VS or Monotools are nice and help in a lot of ways but neither are required to develop .NET applications. All you need is your favorite text editor and the .NET or Mono framework of your choice. Build systems are included with the framework, the IDE is just window dressing to help organize, analyze and review your code. When I need to make a quick change somewhere I very often will just edit the file in a text editor and fire off my build. When I know I won't need to debug and my unit tests pass ok I'm off. There is nothing that I am aware of that can be done with VS than cannot also be done with a text editor and a properly written targets file. 
I believe it narrows the credential's domain/authority to localhost.
perfect! I'm excited they added this.
Sorry to hear it didn't work out. Could you give a brief overview of the project and maybe add a little insight into why you think it failed? Your experience may help others.
I second this. There is a lot we could glean from your experience. 
For a quick overview, it was because our team of four people (2 programmers, 2 business oriented people) did not have the same vision / direction, and we kept changing it. Therefore, we ended up with a product that didn't satisfy any of our potential clients' need. I'll make a note somewhere to write a blog entry about it.
And… what is the product?
It's possible not even they know. I've seen startups work out like that.
Here is a short write-up of the whole ordeal: http://cdroulers.com/projects/invup/
commented with a link to short write-up. http://cdroulers.com/projects/invup/
Nice. On vit dans un petit monde il faut croire.
Thanks for releasing the code. From the summaries it looks like there's same useful stuff in there. Have you considered making nuget packages for some of this stuff?
While this is great, and shows how far mono has come. It of course begs the question: why? 
My favorite line of code so far : map.Path("**(╯‵Д′)╯彡┻━┻**").To&lt;AccountController&gt;(h =&gt; h.LogOut()); edit: for those who don't know MVC this line of code would cause the user to log out when "(╯‵Д′)╯彡┻━┻" was present in the URL.
We already built external libraries for a bunch of small stuff, named [Awesome.Utilities](https://code.google.com/p/awesome-utilities/) and they are on NuGet. I will add links to the write-up page when I get home tonight. I don't think there's a lot of stuff in the main codebase that can actually be extracted to be useful on its own. Most of it is easily repeated. Feel free to comment on specific parts you think can be extracted, or clone the awesome utilities library and do a pull request.
We put it as a joke at first, but it ended up staying. We also almost kept an Exception like so: public class ಠ_ಠ : Exception {} Which totally works in C#!
For the same reasons you would want cross-platform access on Java or any other platform. Build once, compile once, run where you need it. If I am an ISV, platform choice can be painful to support many types of systems. Mono for the most part (no WPF) can run anywhere now (full core .NET 4 support), this makes it an easier choice for ISVs and other businesses. In some cases it's cheaper to get a Linux server running if you have folks who can use it. (Having someone who can administer is the question)
You're absolutely right. I think this is one of my main reasons to move to RoR for web work. Free &gt; all. 
&gt;In some cases it's cheaper to get a Linux server running if you have folks who can use it. (Having someone who can administer is the question) Definitely agree. 
I was thinking something similar. Entity framework really got in the way sometimes. Perhaps if I used hibernate, or rolled my own data layer (fuck that though...) it would have been better. I'm curious what you found complicated about RoR though.
Webforms is a mess, I have avoided them since they were created (opting instead for my own HTTP handlers). As for MVC, YMMV depending on which framework you go with. ASP.NET MVC is actually quite easy IMO. The issue I often find is that people transitioning from Webforms (which is often coded in a way similar to PHP) to MVC which is far more structured can seem painful and has you doing things that you will feel you should not have to do. In most cases this comes down to not really understanding the pattern involved. Also as in my experiance, even with a framework like MVC you really should not be putting control, data loading or business code into your controllers, views or models. Very often people try to mix all these concerns in the controller and/or model and end up with a mess only slightly more organized than if they had done the work in webforms. Frameworks like MVC give you a starting point, and a logical framework for wiring up your UI and handing user interaction. For other concerns like data loading, rule processing, business processes, etc you should look toward additional patterns like [Action/Executor](http://msdn.microsoft.com/en-us/library/cc984279.aspx) or some other reasonable command pattern. With a properly designed MVC style project, your code should be spread across more files than in webforms however those files should be small (less than 500 lines of code), highly focused to the task they are built for and easy to understand. The advantage is that you should have almost 0 files that are a mess like old ASP.NET pages and code behinds. Everything has a purpose and it is clearly labeled, not buried in a 5000 line code behind. 
&gt;Also as in my experiance, even with a framework like MVC you really should not be putting control, data loading or business code into your controllers, views or models. Are you saying you shouldn't put business logic in your models? That I don't necessarily agree with. If you have a field called ssn in your customer table, and you want to validate that it conforms to certain constraints, you can put a validation method on your model. Are you saying thats a bad idea?
I do not think Windows Server licenses are that very expensive. Windows Server Standard 2012 costs around $730 and if you are going to do any meaningful business thats definitely not a significant cost. From what I understand (although never was involved in purchasing process) 'enterprise' Linux can be expensive as well (Red Hat Enterprise Linux costs $799 for one year subscription if I remember correctly) And don't forget administration - Windows Server and ASP.NET ecosystem provides some tools that can simplify management tasks. Again I am not an admin (neither Linux or Windows), but my impression is that proper production support for Linux requires good admins (which will be expensive) If you are a start-up you are eligible for MS BizSpark subscription which gives you most of MS software (including Server and MSSQL) for 2-3 years for 99 USD. For production use :) The point is I wouldn't say its a matter of price for the license, there are much more factors behind your OS choice, eg. preference for a given OS/environment, existing skillset among tech staff, etc. And most importantly choosing the technology/framework that makes you most productive as developers time is expensive much more than 1k spent on OS 
In general yes it is. You don't want the model to encapsulate something like that as you may have SSN in 10 other models that also should have valid SSNs. A better case for your scenario would be say you have a complex model and in this particular model 3 different value (2 primitives and another object model) all must pass cross checks with each other (say the property must be of the text "HELLO" when the property containing the object model has a description field of "WORLD"). In this case your validation is very case specific and could be preformed within the model. That said, based on the typical behavior of most UI systems embedding validation behaviors into your model can be a mixed bag at minimum and a headache of re-factoring portions in the worst case. Typically I try to keep my models as just that a data model. Code for serilization, INotifyProperty changed and the like is OK but try to keep the model as purely a data dump. Allow your processing classes to apply the correct validation logic and keep your validation logic separate from both your processors and your models (mapping validations to model fields is provided by some frameworks, but a little reflection and a custom attribute for your models is all that is needed). This will allow you to do things like full model validation when a processor is running the model while at the same time wrapping individual validation rules into a shape your UI system can understand allowing you to use one set of validation code for your main display and for internal model validation. The final reason you want to do this is that for most cases these kinds of validations are fluid. If the business wants to change how it validates user data, in a disconnected model you need to update the validation classes and the lib related to validation. If the validation is in the model you need to update your model and possibly any class touching the model directly depending on the validation needed. 
&gt;proper production support for Linux requires good admins (which will be expensive) Proper production support for Windows requires good admins too, and they are similarly expensive.
I don't know. I tend to think keeping the validation of data to be persisted close to the actual persistence engine is the best idea. I don't think I really see a difference in what you pointed out.
Agree :) its just from my personal perspective some administrative tasks seem slightly easier on Windows. But my personal perspective doesn't necessarily reflect reality :)
Your model should also never be tied to your persistence engine (I get antsy when I have to add properties or methods for a custom serializer or transport even) if you think that's what EF or nHibernate do then re-read their docs, they are processors and mappers, if you are putting anything other than decorators in your models to support your persistence framework, you are doing it wrong. I can understand where you are coming from. In a world where you tie things together like you do, you don't see a point. Either you have been really lucky or you end up on code that is written in stone after it is done, has a narrow path and/or little to no re-use outside that case. 
nahh persistence engine is accurate and more encompassing for our general conversation IMO. ORM or not, you should never tie your models to the delivery, storage or data transport methodologies. 
nancyfx and fubumvc. ymmv on if they feel clunky or not.
I am afraid I have lost your context, we have covered a few general ideas at this point, which idea of yours are we talking about now? Please excuse me, coding one thing while discussing another fries my brain from time to time.
The easy things are easy. Doing the less-easy things *appears* easy, but doing them right is not.
no, they're asp.net alternatives not ORMs. NancyFX is similar to Sinatra on the Ruby side. Detangling further, there are also various view engines. I tend to use Spark or SimpleViewEngine primarily. For an ORM that's similarish to ActiveRecord, there's Castle Active Record which sits on top of NHibernate and does all of the wiring and a lot of NHibernate session management for you (can still get down to NHibernate and, by proxy, ado.net) from there of course. I can't speak at all to if they run on Mono or not. 
My two google results: http://www.onbarcode.com/products/net_barcode_reader/barcodes/qrcode.html http://www.codeproject.com/Articles/20574/Open-Source-QRCode-Library If you're still using VS 2008 and the 2.0 Framework, you really should try and get them to update though.
Agreed. Will get to that eventually.
Seems pretty obvious to me: the .NET framework is good and people want to use it on other platforms.
You could use JSON.net and dynamic typing to achieve something like this. Read data from the database and set the properties on a dynamic type according to the results. IE if the row contains a property Foo, you could do item.Foo = reader["Foo"]. The typing is really irrelevant since you are serializing them to JSON, so I wouldn't bother unboxing them. You might consider using rest services instead of asmx web services for this purpose as well. Bit of code: using System.Dynamic; using Newtonsoft.Json; var items = new List&lt;dynamic&gt;(); while (reader.Read()) { dynamic item = new ExpandoObject(); item.Foo = reader["foo"]; item.Bar = reader["bar"]; item.Baz = reader["baz"]; } foreach (var item in items) { yield return JsonConvert.SerializeObject(item); }
I second this approach, I am spending quite a bit of time building a serializer/deserializer for a custom file format and have used JSON.Net both as an inital base as well as a guide for my own implmentation. They have thought of every possible detail when it comes to working with JSON data and the framework is very flexible (though sometimes weakly documented). If you are going to work with JSON data in .NET, just use JSON.Net and save a lot of time and trouble. It's fast, accurate and it works very well. 
There are alternative frameworks to Webforms and MVC and you can always write your own. Although frankly I think the strength of c# for me is static and strong typing, along with plenty of syntactic sugar and useful constructs. I picked up Ruby for work six months ago and I'm struggling to find anything I prefer about it. Edit: also although Visual Studio is a monstruosity under the hood, it's the best IDE I've used. Things like Eclipse and IntelliJ are pathetic in comparison.
The important thing to understand is that you're already paying the cost for the double overhead that you're worried about avoiding. Even though you're manually building a JSON string and that's probably suitable to send back to the client, your string return value will still be serialized a second time on the server-side (that's why you're having to deserialize it the second time on the client-side). If you watch the network traffic in something like Chrome's developer tools or Firebug, you'll see that it's wrapped up in a second level of JSON encoding, and JSON serialized as JSON is a *mess* since all of the double quotes have to be escaped. You end up bloating the size of the response non-trivially. There are a variety of ways to work around that in your case. You could use something like PetaPoco, Dapper, or Massive to map a query to CLR objects instead of using an IDataReader. I believe you might be able to use AutoMapper to map an IDataReader to a collection of CLR objects in one shot. If there aren't too many different queries you're piping through here, you could simply iterate over the reader and build your own List&lt;T&gt; of a ViewModel/DTO object. Ultimately, the key is finding a way to get your data into a collection of CLR objects so that you can work with the framework instead of against. Then, you can just return that IEnumerable&lt;T&gt; and let ASP.NET worry about the serialization for you.
No need to get it upgraded. If the projects do not require anything higher than 2.0 framework then there is no reason to upgrade.
Woah, "require"? Does any project really *require* any abstractions over assembler? The question should hardly be if the project requires a newer version of .NET Framework or Visual Studio, but rather *would the project benefit from such an upgrade?* And would the benefits outweigh the cost? (And it would, in many cases!!)
Is this not the accepted practise? What do you recommend for namespaces / assembly names?
Glad you enjoyed reading it!
I'm not sure I fully understand your question, but this is what I use: using System.Web.Script.Serialization; public string DataTable2JSON(DataTable dt) { List&lt;Object&gt; RowList = new List&lt;Object&gt;(); foreach (DataRow dr in dt.Rows) { Dictionary&lt;Object, Object&gt; ColList = new Dictionary&lt;Object, Object&gt;(); foreach (DataColumn dc in dt.Columns) { string t = (string)((string.Empty == dr[dc].ToString()) ? null : dr[dc].ToString()); ColList.Add(dc.ColumnName, t); } RowList.Add(ColList); } JavaScriptSerializer js = new JavaScriptSerializer(); string JSON = js.Serialize(RowList); return JSON; } So I pass a DataTable into the function. I've never had a problem with it, although I'm not sure whether it's doubling effort. In the function i have: [ScriptMethod(ResponseFormat = ResponseFormat.Json, UseHttpGet = false)] [WebMethod] public string FunctionName(string blah) { ... return DataTable2JSON(DataTable); }
One of the prerequisites is that I have VS 2010. The issue I am running into is being out of date and being able to use the cooler new shit.
There's some [good guidelines for naming](http://msdn.microsoft.com/en-us/library/vstudio/ms229026.aspx) on MSDN. You do a pretty good job on your namespaces, but some "lingo" get's mixed in. Really, namespaces are for the logical organization of things, so it's entirely OK for namespaces to span assemblies. From my general browsing of this code base I see a few main namespaces that stand out: Donations, Opportunities, Teams, Users, and so forth. I would then expect the the namespaces to be Invup.Donations, Invup.Opportunities, etc. Then, all logical types should be a part of those namespaces. For instance, OpportunityRepository would be in Invup.Opportunities along with Opportunity, rather than Invup.Domain.Core.Repositories and then having an using statement for Invup.Domain.Core.Models.Opportunities. Your namespaces should not be tied to the patterns you are using. I generally never have a Models, Views, Controllers, etc namespaces except in the UI projects, and even then they usually don't show up. So in conclusion, I don't really have a problem with your assemblies (ok, I have some problems, but they are very minor and don't matter with the size of this code base, and they are majorly "preference"), but the namespaces are bad because you didn't change the defaults in visual studio (which defaults to the assembly name). So to fix that, when you make a new project, make sure to go into the properties on the project and change the default namespace if it's not appropriate. Also, you can always change the namespace in the file itself, you don't have to stick with what visual studio gives you by default. 
I have this urge to tweak the code for Popeye's...
That works as well, though be aware that using JavaScriptSerializer is not cross platform supported (does not exist in Mono) however you can find examples on how to make calls to JavaScriptSerializer work on another platform. 
OOP covers *a lot* of concepts so I can't imagine there would be any "small" example that covers it properly (it would be like asking for a simple example of how to perform surgery). Probably best finding a better tutorial on it, [maybe this one](http://www.codeproject.com/Articles/22769/Introduction-to-Object-Oriented-Programming-Concep)?
Which four are they?
I was wondering if they added one...
What you are missing is not going to be found in a sample or example, only real applications. Samples are very often to show an API concept or language feature and rarely, if ever discuss best usage patterns. What you want to do is start to google for a read up on "patterns and practices". Get a patterns book to get an idea on what some popular ones are and how they might be used. Read blogs and anything you can get your hands on to help understand best practices around things like encapsulation and testability. [Gang of four is an old popular group for some base patterns.](https://www.google.com/search?q=gangof4+pattterns&amp;rlz=1C1CHFX_enUS475US475&amp;aq=f&amp;oq=gangof4+pattterns&amp;aqs=chrome.0.57.3490&amp;sourceid=chrome&amp;ie=UTF-8#hl=en&amp;safe=off&amp;rlz=1C1CHFX_enUS475US475&amp;q=gang+of+4+patterns&amp;spell=1&amp;sa=X&amp;ei=7rg4Uf_GJOqs0AHE94DIDA&amp;ved=0CDIQBSgA&amp;bav=on.2,or.r_gc.r_pw.r_qf.&amp;bvm=bv.43287494,d.dmQ&amp;fp=1a28eadb0a1e0b9a&amp;biw=848&amp;bih=478) Finally, code, seriously, I get downvoted every time I mention this to someone wanting to learn more. Code, write good code, write bad code, the most important thing is to learn from your code and focus on what you can do to make your code, cleaner, easier to read and easier to maintain. Remember sometimes just because it's done in the least lines possible does not mean its a good idea if it cannot be understood by you a month down the road. 
The way I've always heard it: * Data Abstraction * Encapsulation * Inheritance * Polymorphism 
Thanks, that article is very succinct... Lol, since I work in a med school, maybe I can use your analogy. What I'm looking for is more like a simulation scenario for the [Mazor robot](http://www.smartplanet.com/blog/rethinking-healthcare/israeli-robot-performs-brain-surgery/9107) using the most common brain surgery technique on a broad scope. In simulation, you can leave out details, like bleeding, capillaries, etc... (as well as add them back in layer by layer if you like) as well as most of the science behind it. I just want to open up the scalp with a scalpel, do a [trephine](http://en.wikipedia.org/wiki/Trephine), and poke around a bit.
I highly recommend this series from Lynda.com: http://www.lynda.com/Programming-tutorials/Foundations-of-Programming-Object-Oriented-Design/96949-2.html the instructor has a great ability to explain the core concepts in a language-agnostic way. It's not short, but is very good.
Encapsulation and information hiding go hand-in-hand (and, generally, when people talk about encapsulation they're picturing data hiding) With information hiding, we're exposing public accessors and mutators and hiding the implementation details. Below, I'm exposing a first name and last name but hiding how they're stored (in this case a field is automatically generated, but I'm free to change that without breaking consumers of my class) Another tenant of encapsulation might be to group fields and the methods that act on those fields together. An example of that is the GetDisplayName function in my class below. public class Person { public string FirstName {get; set;} public string LastName {get; set;} public virtual string GetDisplayName() { return FirstName + " " + LastName; } } Abstraction is simply a way to think about your problem space. In the above class, we don't need to carry along other properties of a Person (like blood type, weight, eye color, etc) if they're not germane to our application. Similarly, if we were to mix multiple responsibilities together and had a class called PersonAndCity then that might be a poor abstraction as it might not let us crisply define its boundaries. Or, to quote Booch: &gt; An abstraction denotes the essential characteristics of an object that distinguish it from all other kinds of object and thus provide crisply defined conceptual boundaries, relative to the perspective of the viewer. Inheritance is a way to think about how you might reuse data and behaviors in more a finely-grained fashion. Note, while inheritance is an easy enough concept, it's done differently and with different restrictions in different languages. Extending our example above public class Employee : Person { private decimal salary; public decimal Salary { get { return salary; } } } Now, Employee inherits Person's data (the first and last name properties) and Person's behaviors (like GetDisplayName). So, if we decide that blood type is important and we want to track it across all people, when we add it to Person then Employee will automatically get that property as well. Polymorphism. This is a tougher concept. A very, very basic example might be something like: public class Manager : Employee { public override string GetDisplayName() { return "The Cheez - " + base.GetDisplayName(); } } This is one type of polymorphism. I'm overriding the runtime characteristics of the GetDisplayName() to change behavior. So, a super-basic example... all tied together.. a console app for you: https://gist.github.com/hyrmn/5110108 Another place to read, this seemed decent: http://codebetter.com/raymondlewallen/2005/07/19/4-major-principles-of-object-oriented-programming/ Keep in mind though, these are just four of the popular tenants for OOP. And, arguably, these aren't the only four basic concepts. It would behoove you to also look at SOLID design principals as that might cement some of what OOP strives for.
I don't know if there really is a cheat sheet for application design. There are practices you see over and over (repositories for data access, certain rules on developing models etc) but everyone has varying opinions on what works or does not for your project. Most of what I know I gained from experience and reading overly dry docs over the years. I also look toward other projects for inspiration on what to do. Microsoft publishes ALOT of source code these days and there is a strong and growing ecosystem of OSS code available. I typically use these as places to look for good patterns and ideas when I am trying to put something together. I would say the closest you could maybe get are stack templates. Basically a list of tools and maybe some patterns you would use for a particular type of application. For example, a web application backed by a database: * Separation based UI framework (MVC., or others) * ORM Framework (Entity, nHibernate, etc) * Error management (Elmah) * Caching Framework (Azure, etc if Needed) Even that list above can be hotly debated among developers. Your best bet is to keep reading and coding, its really the only way to build a cheat sheet that works for you. 
I found the book "Guided by Tests" to have a modern/excellent treatment of when/how to use OOP. The core ideas for that are in chapter 2, 6 and 7. I highly recommend it. When OOP was first introduced, people had ideas like "if a cat is an animal than the cat class should inherit from animal", it was kind of naive. "Guided by Tests" goes into approaches like the hollywood principle.
I've never heard data abstraction in with the other three. 
I've heard it, but I've always considered it a "wrong" answer. Abstraction is the *result* of the other three.
In your situation you probably won't need much in terms of OO. Don't go over-engineering your application just to conform to some notion of "should" or "ought". Don't do things just because others do them. Just do the simplest thing that could possibly work.
Just so the OP understands why this is being downvoted... this is .net subreddit and not web development.
I have never had a problem getting IIS Express to work. Also, didn't know Cassini even still existed.
Quite disappointing really. That is not enough for a major version (and thus a license upgrade). I thing it is outrageous that they wait with a huge amount of small bug fixes to the next major. I bought software that didn't work as intended, don't force me to first wait way too long, and then force me to pay. That is not how to treat customers.
I agree. I've been a long time user and huge supporter of all the jetbrains products, but I doubt I can justify upgrading my team to version 8. 
So no F# support then. :/
They have a [plugin](https://github.com/JetBrains/FSharper), not sure how complete it is though.
Yep. We dumped it for the exact same reason. We're not paying to make it work the way it should have in the first place by having to upgrade.
Anyone else really confused when upgrading to VS2012 about how Resharper works? Sometimes i'm not sure it is running at all. 
 using( var c = new HttpClient() ) { var response = await c.GetAsync( url ); // &lt;-- put your url here var bytes = await response.Content.ReadAsByteArrayAsync(); return bytes; }
Now only if there wasn't just 10 assert in the same test.
Oh nice thx. 
Alt+Enter or Ctrl+Shift+R?
Ate you using something else instead? 
If that test is failing, why would it fail? Multiple reasons probably. So when you get to that test, you don't know why it failed. Just that something wasn't an expected value. Then there is the fact that the test name isn't being explicit to what unit it is testing and what we are expecting. Try to rename that test without the word "and" by being as explicit to what it is testing. Read the following if you are interested. http://programmers.stackexchange.com/questions/7823/is-it-ok-to-have-multiple-asserts-in-a-single-unit-test
Unfortunately, no- Still looking.
Been a long time since I answered your question but I came back with another good reason. If the first assert of your test fail, all other asserts are not run. So 10 asserts, first fail, nine other test that weren't run. If you target 1 assert per test, you should have a maximum coverage even when a test is failing. 
You are still learning the iOS API. (Dont think you'll be cruising along with System.Windows.Forms). Not sure why you wouldnt just get XCode (free) and learn Objective-C. If you have an understanding of C#, Objective-C isnt that hard to learn, and it add another thing to a resume. 
&gt; You design a project first then code it. I have no idea about the nature of your projects, but -- believe it or not -- there are many projects that evolve along the way. That is called a healthy project. In such projects, decisions and changes has to be made along the way.
Objective C is near the top of my list of "want to learn"s. However, as a .NET developer with a wife and kids, my time is best spent being as productive as possible. I would like to learn the iOS stack using Xcode and Objective C because I think it's really interesting, but I can use Xamarin.iOS, leverage my current .NET experience, and get access to LINQ, strongly-typed compile-time checking, and every little thing that .NET has that Objective C doesn't (easy string manipulation, better Intellisense, etc.) Here is a good page with side-by-side code comparisons (a little biased, of course, but a good example of how much code needs writing on one platform vs another): http://xamarin.com/how-it-works
I think Xamarin has done a lot of great things, but I would still put an HTML5/PhoneGap app up against any native app in terms of development cost (and yes I realize there are some performance-hungry apps that need to be native).
I think it will depend on the scenarios and how UnitTests are used. I tend to use these tests during development, where I try to cover as many scenarios as possible. After that, I use them to make sure the app is still behaving the way it should, and any refactoring done doesn't break anything. And I don't see a problem in having multiple Asserts in one test, since (like in that example) they can be used to test multiple scenarios with one action (in this case making sure that the Password Reset workflow still works as expected). The password reset workflow is a good example of where multiple Asserts fits quite nicely, since for example that is a way to test that the token used to password reset cannot be used more than once. Breaking that into multiple tests would create a gazillion of tests, make them hard to debug and take a lot more time to write. I also try to make my tests as easy to read as possible (which is why in that example I placed all the data gathering at the top and the assets at the bottom (all lined up so that they are easy to read/scan)
Yes, but in my cases when something fails I will look at it, specially since the master version should always have passing tests. Note that these tests are testing Application Logic actions, which have specific behavior and workflow. In a way, these are more like integration tests, than unit tests (but I like to call all type of programmatic test a UnitTest :) )
Naming is very important. Unit test is testing a unit. System test is testing a system. Unit testing should have one assert per test because they are cheap to run but are not flaky to small changes. System tests may have more than one assert because they are long to run and are complex to setup. Tldr; naming is important
What I really hate about JetBrains is their attitude towards existing customers. Having licensed R#, dotCover, dotPerformance, IntelliJ I would expect a rebate on updates. However, they only offer rebates on full-priced products, selling for the price of an update :(
A couple of the guys on my team love VSCommands. Not a replacement, but I'd be left with a stump for a hand if I tried to take it from them: http://vscommands.squaredinfinity.com/Features2010 
Yeah I used these before I got a copy of ReSharper, quite handy and does some nice formating extras to save time. I've also used CodeRush before (free limited version) if people are looking for other alternatives.
It should be just "abstraction", i.e. the concept of interface. Also, when people talk about inheritance it's important to differentiate between implementation inheritance and interface implementation. More interesting question is, if you had to do away with one, which one would you pick?
Ok, so what I'm doing in there is System Tests :)
Are you saying the form itself is transparent? Forms already support that...
Here's the problem. If you go out marketing yourself as a iOS programmer due to this, you're going to misrepresent yourself and lose your job. If you are in a shop that would use this to solve multiplatform, then that's fine - for that job/company/project *at that point in time*. But you're not helping yourself any - just the company you currently work for. You cant take Xamarin with you. Also consider if you hire someone to take over if someone leaves. Do you hire an iOS developer? A .NET developer? This "in between" makes it difficult to find the right employee. There's no way I would recommend using something like this.
Of all the programming languages that I have used, Objective C is the only one that I have hated. It's like traveling to an alternate universe where programming language design stopped in the mid 90s. So I am a bit biased. However, as with everything, it's all about the problem that you are trying to solve. If the problem is your employment, then learn the language that helps you move to where you want to be. If the problem is creating an Apple only app then ObjC is fine, particularly if you enjoy bondage. If the problem space is wider than Apple only, then Obj-C is a poor choice. The days when iOS was the only game in town are over. Unfortunately cross platform development is still a minefield but starting in ObjC makes it near impossible. As far as hiring people is concerned, it's much easier around here to get a .net developer than an iOS one. Writing my current app in obj c is asking my employer to replace me with 2 people instead of one, one of which will be hard as hell to find.
It's nifty, but it's likely that anyone that wants to use these capabilities is going to go with WPF at this point.
One part of me totally agree with you. But the part of me who has a deep hatred for XAML just keeps doing this awful noise in the background of my mind.
You can use WPF without XAML, the WinForms way, if you want to hand-code all your UI. [See an example.](http://www.tbiro.com/Hello-WPF-Without-XAML.htm)
Interesting. Do I understand the designer is friendly with this approach or is it going to spit and claw my sofa?
There isn't a code-gen designer for WPF, it works only with XAML. But given that XAML ultimately compiles down to the same stuff, you should be able to use hand-made controls within the designer just fine.
So if I want a designer, I use WinForm or I try to swallow XAML, right?
Pretty much. But honestly, it only takes a little bit to start loving XAML. There's nothing you can't do with it that you can with WinForms, and it's a much cleaner way of making UI than designer generated code.
Ah, interop: the fastest and easiest way to crash any application in a completely opaque manner...
I've done many "tries" into WPF and one time came very close to punching my screen. Why some of the things that were so easy to do in WinForms were now so hard? The ideas and concepts behind WPF are sounds. I love the idea of separating rendering from the background logic. I just can't understand why Microsoft took that way for implementing it. They could have extended the Form/Controls to support all the nice concepts they tried to infused in WPF. Everything they did in XAML, they could have done in C#... So why XAML? Some people just explains it way better than me: [Six Years of WPF](http://www.paulstovell.com/six-years-of-wpf)
Actually you **can't** do a lot of stuff in C# that you can in XAML. XAML does not compile down to the same stuff, it goes to BAML. The most obvious example is the FrameworkElementFactory, if you read the comments its virtually deprecated and can't provide all the same functionality that you have in XAML. It is also horrifically verbose. XAML is a bit odd at first, I think readability suffers to begin with because there are so many things which mean the same thing, the use of markup extensions, and the special behaviour of squirlies, for example {Binding Foo}. However, I've still yet to see a more maintable UI framework, the use of DataTemplateing and driving everything as a series of ItemsControls makes for a zen that is un-matched so far.
&gt;Actually you can't do a lot of stuff in C# that you can in XAML. Ok... Now you lost me there. What can't you do in C#? If some Microsoft library are not working or are deprecated, nothing prevent you from rewriting them.
&gt;Honestly, you sound elitist and not really very informed. You sound like a marketer, and not very well in touch with the industry. But that's fine. Im no elitist, but I do have to consider the effect of bringing in these kinds of solutions to problems to a business atmosphere.
I use the Xamarin tools at my place of work. Historically we're a Qt house but developing for mobile using Qt at this time isn't viable. In our business we have to weigh up the pros and cons to each of the tools we use. A massive benefit for Xamarin was being able to write a portable core which was platform agnostic. We have reused this core on both iOS and Android. To our users, they see a native app, to our commercial director, he sees a cut in development time. I understand your point about marketing yourself as an ios dev but I think perhaps you need to reframe your view on this. If I talk to a client about developing an app for them, they will 9/10 times glaze over if I mention technologies. You are selling an end product, not the process of making it. I think with the vast array of technologies available for app development, it's good to know more than one. I have in the past used jQuery mobile, Sencha Touch, Objective-C and now Xamarin. Personally I prefer the Xamarin offering. Horses for courses. 
Well someone nicely blogged a bit more about the FrameworkElementFactory. I don't have time to provide proper examples myself I'm affraid, so I'll just take his example: http://www.ikriv.com/dev/wpf/DataTemplateCreation/ There appears to be the miss-conception here that XAML is just some markup that gets translated to op-codes just like C# does. It does not. It is not. Differen't languages promote differen't pratices, granted C# is a very flexible one, but there are times when it simply isn't right. Thats why people like F# used to love Boo etc. Xaml is Declarative, C# is Procedural. Now these words didn't really mean much to when I was at uni, but after doing WPF in anger they really do. C# has no built in ideas of workflow inherientance, the kind you bring in with Dependency Injection / Resource Resolution. XAML does. C# has no concept of Trees in the language itself. XAML does. I think the problem is that Microsoft didn't really do anything to explain this. They also muddied the water with the notion that you'd have goatee toating designers making the XAML, which was silly. The funny thing is I've, twice, sucsessfully used XAML as a control language for client applications, allowing BAs and the like to layout a technical screen. I completely changed the libaries they were using, but XAML made their life so much simpler, it also added implicit re-use, because screens 'inherreted context' depending where in the application there where defined. So I would say I've definately first hand experiance of XAML been used to solve problems for people who wouldn't be wanting/able to use C#, who with a little training took to it rather well. There is a bit of an addage, if your only tool is a hammer, everything looks like a nail. Microsoft didn't do well to stop this line of thought, in fact they marketed WPF as WinForms++; which really fucked things up, because its not at all similar in paradigm. Someone who has never done winforms will probably have an advantage learning WPF over someone who has been using winforms for years. The simple fact of the matter is that a lot of the people I see who dislike WPF simply don't know it, and its not really their fault, why waste time learning something that feels like the barstard ginger child of Microsoft? Microsoft also screwed the pooch by letting the bunch of utter fucking fuckity tards who made CAL/PRISIM near WPF. Anyone who'd create something called RegionManager that lives in the WPF trees is clearly a complete fucking backbirth who doesn't understand seperation of concern and just wants to bullshit away the fact they use a static as an underlying for DI. I had to use that shit for 8 months thanks to some twat that had never made any stable/useful/resuable code so got promoted out of the way to a company architect, from his ivory tower made the decree. People harp on about MVVM because its simply much better for good pratice than winforms. It lends itself so nicely to your favourite IoC container, it forces nothing on you at all. You do all your assembly at the VM, Vm's use DI/IoC to resolve their children, its just a tree structure after all. Instantly you have integration tests that can run the UI app up without the GUI! CI can now happily run such things with no significant overhead. WPF is kinda like a floppy fabric that drapes over the structure of the VM. This is a good thing, because floppy fabric that molds to the form of POCOs is good. People complain that they can't hold the application up by the GUI, but that's just a bad idea, your inheriently violating SOLID principles, massively on the first one (Single Responsibility) so the ascertion that blog post made that because he sees WPF apps without unit tests they are all wrong is just terrible. 