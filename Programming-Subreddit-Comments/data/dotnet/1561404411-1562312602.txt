yes
The point is the ubiquity of the web ‚Äúlanguages‚Äù (html, css, js). I can hand anyone the UI folder for the app and they‚Äôll be able to read, use, and modify. The same just simply can‚Äôt be said for any of the big natives. GTK, QT, and WPF are all things that need to be learned. Yeah, they basically all boil down to XML, but you can‚Äôt just hand someone those and expect them to use it, never mind it‚Äôs nowhere near cross platform. &gt; ...if you are going to bring in dependencies in multiple JS libraries... And this is why I recommend [webview](https://github.com/zserge/webview). This isn‚Äôt electron. The only JS I use for my desktop apps are transitions (easier than doing them in CSS, in my opinion) and the transfer of data between the server. There are no dependencies there. Totally agree on the repo bit though. A lecturer in college told us that years ago, that you might want to swap out your database. I get the point, but I‚Äôve also never seen it done or even proposed. It‚Äôs one of those things where a complete swap is likely going to kick your ass no matter what.
That seems unnecessary. You shouldn‚Äôt have the compiler block bad code. That‚Äôs the job of a code reviewer.
Such an obscure reason. I would tally a guess that the apppoolidentity used in some environments is an actual account on the server with a profile and settings rather than a service account. However, as you say, wtf MS... I'll save this If I encounter this myself sometime.
&gt; and I have logs written that is accepts the request At what point in the request lifecycle, early? Is it close to 20 seconds after the `client.GetAsync` call? Do you experience delays hitting :53702 from curl or Postman? Do you experience delays if you `client.GetAsync` another url, something not at localhost?
I disagree. Absolutely necessary. All repository interactions should be kept out of the services. Repo calls in services is a clear indication to me that a programmer isn‚Äôt very good at what they do. Separation of concerns. How else are you going to use test databases? You need the separate layer in order to create a comprehensive test suite. I‚Äôm going to assume by ‚ÄúIt has to be separated‚Äù, you mean in an entirely new project. As I do agree, you need it separated, but I‚Äôd keep them in the same project. Again, a decent programmer can easily keep UI separate from logic, along with data access. It just creates more hassle to have separate projects anyways. My standard API is split into controllers, domain, services, and repositories. Very simple, yet very effective. All the UI is a few html files if you need it, with the controller infecting models it gets back from a service, though I‚Äôve recently moved to SPAs entirely, so I don‚Äôt deal with that at all.
Good guess, but no, all of our security is AppPoolIdentity for security purposes to prevent cross application security concerns. We are very tight on security.
The first request has the 20 second spin up time. Subsequent requests do not. However, if we let the app idle for 30 seconds so the configured Timeout is hit, then we see the 20 second wrath again. The first log entry on the endpoint :53702 logs 20 seconds after the client.GetAsync is called. There are no delays with Postman or the browser when hitting that URL. We have also configured the URL to be the FQN and IP. Both still have 20 second delay. *note* I added a 'SOLVED' comment. If you are interested in the problem solution you can view it there.
I have to admit webview is something I have no experience with, I'll give it a look. I can see your point with wpf, qt but surely everyone can understand winforms? At the place I work at winforms is the go to method to develop applications we work with internally because it's rapid and simple. I know this is also the case for a couple of other companies I am familiar with. There are a lot of developers still unfamiliar with web development or have out of date knowledge, do you just assume they can learn because you prefer web technologies? I'd go as far as to suggest that it's more likely that any desktop developer is more likely to be familiar with desktop technologies, but I take your point about the transferability of html, css and cross platform is definitely a consideration you have to make. I guess its generally going to depend on who is employing you and what they use, if it's for your own projects then use whatever you like I guess.
If I'm understanding correctly, you want to be accessing the HTTP Request url: http://msdn.microsoft.com/en-us/library/system.web.httprequest.querystring.aspx var returnUrl = Request.QueryString["returnUrl"];
I get an error: CS0021 Cannot apply indexing with [] to an expression of type 'QueryString'
Ignore the original comment - Try fixing the casing on your OnGetAsync method. It should be ReturnUrl instead of returnUrl from the looks of your provided url. So: public async Task OnGetAsync(String returnUrl) Should bind correctly
Looks like [this site](http://csharphelper.com/blog/2015/06/zoom-and-crop-a-picture-in-c/) Has some basic code you could use for that
Nice, I was going to mention that auto-detecting proxy settings can cause a delay like that, but I wasn't sure off hand how to turn it off.
I actually started doing just this two years into my career, after having pleasure of working on some legacy VB applications that were horrendous. &amp;#x200B; When I go back to early applications I wrote I feel naughty. I also agree that once you get a hang of layered architecture and dependency injection it is pretty straight forward.
That's... odd. I mean I'm guessing it's not that it can't identify there's not a proxy otherwise it'd be broken in a lot of places I'd imagine. It's like it thinks there is a proxy but it takes ages to connect with it or something. Anything strange in the way the dev environment is set up? I realise that's a rather open ended question.
Wow, that looks extremely promising. I will let you know how it goes. Thank you!
I think he worked where I'm at before I arrived. All the existing code here is riddled with Klopblocks!
And your test projects right?
I can't answer that question. We have network security, information security, application security, architects and application teams all tweaking/adjusting/manipulating our servers to optimize and secure them. I know what settings I've configured but I can't say what all the other teams have done. Not to mention our network layer is a fucking mountain.
Sorry, by my observation, you are wrong. However each situation and org is different. If doing X works for your org or domain, that's fine. But you seem to be over-extrapolating. The K.I.S.S. principle should be a top influence of designs. If a problem pattern emerges over time, then adjust abstractions to fit that pattern.
Are the first three front end and then the last 4 backend, basically?
Make a javascript based web UI and bundle it into a standalone desktop application using electron.
&gt;The point is the ubiquity of the web ‚Äúlanguages‚Äù (html, css, js). I can hand anyone the UI folder for the app and they‚Äôll be able to read, use, and modify. The same just simply can‚Äôt be said for any of the big natives. GTK, QT, and WPF are all things that need to be learned. Yeah, they basically all boil down to XML, but you can‚Äôt just hand someone those and expect them to use it, never mind it‚Äôs nowhere near cross platform. That's a pretty questionable reason to base the technology of your project on. If you do a mini frontend, maybe. But for something big you better chose whatever technology fits your needs best. A good web dev can learn any of the mentioned front end frameworks in a few hours enough to start working anyway.
Remember that WinForms is incredibly niche. In order to have exposure to WinForms, you need to be using .Net, on/for Windows (mostly, I do know and have used Mono to make it work on Linux), and developing/maintaining old applications. Winforms isn't exactly modern. While .Net is neat and all, it has a usage base of like 4%. You're excluding every Java, C/++, PHP, Node, SQL admin, etc. And while people can probably read WinForms, I'd put the bar of understanding higher than that. They likely won't be able to do much with it without learning more about it. But I think you're really overestimating the complexity of a GUI built with the web trio. First off, Flask and other "lightweight" server frameworks are dead simple. I enjoy Flask, but it's common to use Golang among a few others. To render a template in Flask, it's like 4 lines of code? Import the framework, start the server, route for the controller, and return the html. From there, I don't do much else. Html is easy enough, and while I'm not a designer, inline CSS isn't much hassle. Another benefit of using the web, there's thousands of free templates out there. Knick one. And because this doesn't need to be a fully functional website, you can skip most, if not all, JS. Whats the functionality of the app? Post/Get requests? Maybe save some data to a file? I actually do not prefer web development, if you can believe it. I'm not the artsy type, and I think JS is a bit nonsense right now. That is why I've looked quite hard for better solutions. Native desktop apps are near dead, and a pain right now. Development became stale a decade ago. Electron was a neat idea, but runs like hot garbage, as everyone knows, so that wasn't the way either. That's how I ended up here. I like desktop apps, I use my own all the damn time. But they're a pain to develop, quite bloated, or not cross platform. Just my two cents.
What would you use?
If you're not married to ASP.NET, you may want to take a peek at Active Directory Federation Services. I had to do something similar a while back for some of our applications at work, and it worked nicely.
Yes
.net has serious epidemic of over engineering, especially new developers trying to learn. These are all good patterns, but you refactor to them when the need arises. I've also moved away from services and repositories. And moved to feature folders + request handlers, and single method query/write objects. Everything required to implement that feature goes in that folder. You don't end up with large repositories or services
yep, agree with this :)
Looks like we agree on the current state of JS at least. I quite like wpf personally but the last app I built (the one I previously referred too) used cefsharp (chromium). This was because I wanted to use d3 for some visualisation and honestly it was incredibly painful but you've given me some stuff to look into for sure, maybe I'll come around to your way of thinking after a bit of investigation.
Well you can have two DB contexts. One for Postgres the other for SQLite. Copy entities from one context to another
He said the CLI
I disagree with almost everything you've said and have found the opposite true in almost all cases. Either that or we are simply using different terminology somehow.
Yes, but I can't think of a slower way to do it.
I also think KISS should be top influence but I happen to think KISS is different than what you think it is. Depenednecy injection is not complicated. It actually simplifies code a lot. I'd love to discuss this in more detail over an actual code base but I'm not sure there is one available that falls under your description.
Its going to be slow. EF is not designed for ETL. Not an answer to your question, but related: [AdaptiveClient](https://github.com/leaderanalytics/AdaptiveClient) is a library that makes it easy to use an app on multiple DB platforms. Perhaps you can borrow from it to suit your need.
I would love to have a project where we implement it two different ways to compare the pros and cons.
No reason for the dev to learn it. They‚Äôre all dying fast.
There's a bulk insert library out there that'll make it faster, otherwise each copy is going to be inserting individually
&gt; Dependency injection is not complicated. But it can marry your code to an inflexible interface, and take up code space without benefit if you don't actually end up swapping service sources/implementation in the future. Most humans are lousy at predicting the future. I sometimes make bets with developers and win, because their ego makes them over-estimate their forecasting ability. &gt; I'd love to discuss this in more detail over an actual code base Yes, the devil's in the details. Often there are multiple ways to solve the same issue, dependency injection being one of them. It may help better than average, but still may not be the optimal solution/design.
Let me get this straight. So if there is a process with a fairly complicated algorithm that also does validation; you believe one should copy the algorithm in *both* places (biz logic service, and validation service) in order to provide "separation of concerns" (SOC)? A practical example may be parsing something non-trivial. Let's say the parsing splits a user-given text string up into chunks that are (eventually) stored in a database in different rows. During this parsing and chunk-ification process, it may detect errors. I believe most will agree it's best not to duplicate the algorithm in two different spots just to make SOC "happy".
Text editors only
A lot of language constructs are designed specifically to do that. Public, private, internal, readonly...
What? Why would you need to duplicate it to validate it? Just chunk it out and if it fails, throw an exception back to the user. You don't need to chunk it AGAIN, just pass along the chunkified data.
Not using an interface at all can also marry your code to an inflexible interface. If you write unit tests, your interfaces are immediately useful and provide value. You don't have to predict very far to know that you are going to write a unit test.
That‚Äôs my point. Use them, rather than separate projects.
&gt;Services What does "services" mean here?
Well, that's nice and all, but you know, I'm maintaining a legacy application that has a lot of its business logic in stored procedures, in javascript, in HTML, or whatever the developers 10 years ago thought was a good idea and it's written in Visual Basic with WebForms. Of course, it doesn't have unit tests. Just today, I finally found some logic in a stored procedure that I've been searching for 3 days. A stored procedure that was nested within 4 calls of stored procedures. Refactoring this thing would definitely break it, and it's a lot of work.
Listen to this person, build for open/closed focused functionality as much as possible. Classes that scale horizontally as an application grows is a smell.
They service the app.
Seriously though... Say you have a controller that works with a user model, and then stores it in a SQL data store. If you tried to handle all this in a controller method, you would mingle Http related validation, regular model validation, business logic, and then anything related to the specific data store you use. What you should do instead is add in a user service. Using a DI library like Autofac or even just Microsoft's standard DI service, you can inject in a DBContext or a Data Access Service into to a UserService, which then has methods for interacting with that model. Say, for example, you have a CreateUserAsync method on the UserService that receives a data transfer object(dto) or a request model that encapsulates everything that is needed to create a user. The service can validate the request, utilize business rules to create the domain model, which can then have further business rules on just the domain model for state validation, and then it can be passed to the context or DA service for storage. You've now broken apart Http/Net related validation to just the controllers, request related validation and business rules to the service, model state validation to the actual domain model, and then persistence to a persistence service, which could be SQL or something like Mongo. All of this leads to small, easily testable methods, where you don't need to do major refactoring to change storage mediums, and business logic is highly contained and focused. If you use something like AutoMapper, you can even setup Data Transfer Objects so you don't work with raw domain models between services and your front end. Sure, you could do all this in larger chunks, but applications are always evolving and business requirements change, so why make you or the next dev's life hard when they inevitably want to switch from Azure to AWS or put in a whole new set of requirements for how user's need to be maintained in your system?
Nice looking modern responsive website. Bad grammar and incoherent sentences. Written entirely in javascript. Oh yeah you‚Äôre revolutionizing the internet for sure...
\&gt; If your data access interface doesn't care how the info gets to and from the database, then you might was well communicate directly to it rather than go through JSON etc. If you later need it to go through JSON, then in theory you could switch the implementation as needed. But **in practice, "just swapping implementation" is easier said than done** because there are usually enough nuances to muck up straight 1-to-1 conversion. If your infrastructure is set up well to handle a JSON-centric way of communicating with the database, that's fine. But have that in place *first* rather than force it per project. I'm confused. I never said anything about JSON. You should only ever be working with domain models (concrete s) when working between domain services and your persistence store. If I have a user service (I'll keep using this example), it should work with an interface that represents a persistence store (IPersistenceService for example). At this layer, it can perform validation around the request to create a user (does the supplied request object meet the criteria to allow a user to be created), while the domain model can perform validation on its own state (say if we're updating a user model) before being provided to the persistence service that just handles basic CRUD and Query operations. \&gt; That generally should be avoided in my experience, and be in an RDBMS unless there are special needs, such as communicating with outside systems that use FTP. Where did I ever say anything about not using SQL or some other system? Nothing I said precluded using SQL, and in fact is entirely about not only using SQL, but non-relational systems as well. The point is the flexibility. My examples were about using, for example, a CSVService if you wanted to read some test data out of a CSV for unit tests. I think you're over thinking what I'm saying here. Services are just about handling one responsibility for the application. Managing business logic around a specific domain model, writing to a specific file type, raising an event if the network status changed on your mobile app, etc. \&gt; Most of these **inherently interweave in practice**. If you over-force them apart, then you can end up with lots of "interface spaghetti" code to make them talk back in forth to each other. Validation often ***is*** business logic, for example. "Customer cannot use 2 coupons at the same time" is both validation and business logic. Sometimes complex processing discovers errors along the way that are essentially validation. If you split validation from processing, then you'd have to code and process such *twice*. (D.R.Y. violation). Some data entry problems are easy to discover up-front, some are not. Should we split based on what validation is "easy to process/detect"? That's a poor splitting rule to me. Why would you want that? The XML Web Service fad of the early 2000's **already tested this idea**, so it's not new. Using Json instead of XML won't solve the practical bottlenecks/limits discovered. (It worked well in certain limited situations.) Those who don't learn from history are doomed to repeat it. There's different kinds of validation, and all have their place. \- Your controller needs to handle whether or not the request object is in a valid format and that it has valid headers. That's not business logic. \- Your service should ensure that the user providing the request (probably information pulled from a token service populated via middleware as to not pass the HttpContext into the method) has the proper rights and permissions that wouldn't normally be handled by scope authorization, as well as validating that the request model (a dto or specific request object) is in the proper state. It should then transform this request object into a domain model. \- Your domain model should handle validation of its own state. The user model should raise a flag if the service tries to make the phone number contact field "dsfjsdfijsdf." I could think of better examples, but the point is the same. \- Your persistence layer should finally validate if the model can be stored. Is the primary key field not a duplicate of another model? Are fields we marked as unique indexes not unique? I could provide other examples for days. All of this should be managed through IoC. Simple DI managed by Autofac or Microsoft's service container. The interfaces are clear, the concrete implementations are light, and the unit tests are easily handled in conjunction with Moq. You do it right, your classes are light, your methods are lighter, and you can literally change out key pieces of infrastructure with rapid turnaround time. I literally switched a production application from using CosmosDB to SQL in two weeks following this pattern, without anyone noticing a thing. I don't really feel like we're speaking the same language though. You keep going on about XML/JSON and mixing around the terms "validation" and "business logic."
&gt;DRY is one of the least useful principles in my opinion. lolwut?
Maybe look into symmetricds
Business logic should be all handled with the service and domain layer. If you're mingling data input and persistence with your business logic, you've fucked up. Your service layer should know that it received some data, and that a model was persisted, and that's it. The service layer should never know that it received data via an http request and it is being stored in a SQL database.
So you agree that module is then doing *both* processing and validation?
I mentioned databases only as a side issue to flesh out the example. I don't know what you are "correcting" here.
A service would handle receiving the data ([ASP.NET](https://ASP.NET) Controller, FileStream client service, HttpClient, a serial port service), and would probably ensure the message structure is valid. This could be a check sum, ensuring proper json format, etc. A "UserInputRequest" should be generated here and passed onto the next service. The next service should be responsible for validating the data and transforming it into some sort of model. It should look at the UserInputRequest and ensure its data is proper, valid permissions have been granted, etc. It should then parse this request into a domain model for storage. The domain model should then be requested to validate its state to ensure all of its fields are in the proper state. If not, an exception should be raised or some sort of error code should be provided. Finally, the service should then pass this model to a persistence service. The persistence service should check to see if the model can be stored in the database. Is primary key valid? Are the fields that need to be unique actually unique? It should then persist the record(s) and move on. Is this making sense?
Completely irrelevant, but when you name a variable with an underscore, it is actually a convention to not write "this" before it, as the naming convention already suggests it is a class variable. You do it right in your method, but not in the constructor, consistency is key !
Very nice and interesting. Did not ever think about app config I have only ever needed to transform web config!
But you still have an interval vulnerability, the way they do it is by storing all valide tokens on a shared database, So when a user opens the app it will check if he has a valide token in the database, if so it will use that token, otherwise it will redirect the user to the login page, and after the authentication is done the user will be redirected back to the app and continue from there.
I'd check the code on GitHub but I think cookie is the default
As someone who typically works on applications that have a request handler -&gt; service -&gt; domain -&gt; persistence kind of structure, I'd be keen to see an example of the structure you mentioned, if you are aware of any?
So in your case the services are just viewModels/dtos to domain entity mappers?
Validation is domain logic.
Really cool and thorough explanation!
Thanks! Appreciate the feedback üëç
Thanks üëç
As powerful and useful as config transforms can be, I'm really glad that they aren't needed in .NET Core for appsettings.json. IME config transforms usually end up being a mess because few people bother to really understand how they work.
When people start using transformations for environment stuff, it usually turns out a mess, yes. Azure DevOps, Octopus Deploy, and similar are created to improve the deployment process. For differences between debug and release configurations, transformations are (when kept on a minimum) a good choice IMO. When looking through my transformations, they look a lot like the "transformations" I create for [ASP.NET](https://ASP.NET) Core projects. \`appsettings.release.json\` is indeed also a transform file, but in a much simpler and clean format than XDT.
I know you chose not to use the "different environments" example but maybe you can answer a question I have anyway. Is everyone really creating different builds for different environments? I've inherited a few legacy .NET apps -- not my area of expertise -- and they are all set up this way. I've always been taught (and believed) that you should create a single artifact and promote that same artifact from dev through to QA and on to production. If you're rebuilding between environments you risk accidentally including a different dependency or other change in prod that wasn't tested in lower environments. I stuck with my gut and changed them to use deploy-time transformations via MSDeploy but I have no one but my rubber duck to advise me.
I've worked on systems created years ago that did indeed use this approach. I can understand why, since Microsoft and others all used this approach to illustrate how config transformations work. I'm not saying it was a bad thing to do 10 years ago. I mean, modern choices like Azure DevOps and Octopus Deploy didn't exist at the time, so config transformations were still a step up. I wouldn't use config transformations for different environments today though. You are absolutely right, that you should indeed build a single version and deploy this on your staging environment, test it, then either switch staging with production or deploy the same version on production. Both Octopus Deploy and Azure DevOps supports replacing configuration variables on deploy time. I'm not sure about DevOps, but Octopus can actually run config transformations as part of the deploy too. You probably always have something that differs between even staging and production, why you want some kind of software or script to replace configuration. I hope it makes sense. And the above is just my personal opinion based on my experience with transformations.
Great, thanks for the quick response!
Great, thanks for the quick response!
IMO they are really controllers in the original sense of the word before MVC bastardized the pattern. Often called interactors as well. They take and return plain transfer objects and primitives, and call injected dependencies and interact directly with your domain models. They depend only on your domain model directly. If your domains models contain your application independent logic, your services/controllers/interactors contain your application-specific logic in a framework independent manner. Service is a really overloaded term though. Enough to be as meaningless as the word manager. This pattern is usually called 'clean architecture', popularized by Uncle Bob.
Windows 7 is fine, but is it worth developing for?
Is there a book or something that goes into how to architect an entire app properly this way?
IPFS comes up on Hacker News quite a bit. Check the comment sections of the article posts, they are quite engaged. https://hn.algolia.com/?query=ipfs&amp;sort=byPopularity&amp;prefix&amp;page=0&amp;dateRange=all&amp;type=story
This is very interesting, but I don't think I understand the reason for this post. Is it to share the library or just the vision of the library.
lol, I didn't even notice that. Don't worry we follow the convention. This code was just hacked n slashed from a few different place.
If I have an endpoint that requires you to send me JSON of something, I have to make sure you sent me something that was allowed. I do this immediately after receiving the request. Yes, this is where the "sanity check" validation occurs. I don't expect to fully process the object here but I do need to translate it from JSON. If you consider that "business logic" then yes, business logic goes here. It's specific to the endpoint. Endpoint would then translate this raw JSON into an actual object that can be used or mapped to a business level object where further processing can occur, using business level classes. I don't think this is controversial at all.
Great response.
And where the majority of your business logic is contained.
Yeah thought so when I saw the second one, my inner alter developer autism had to say it haha :)
But business logic = domain so it should be in the Domain layer that you specified in your comment above. So your services look like they just do dto-to-entity mapping.
That is also a great idea!
You can generate you entity framework context from an existing database.
Parsing and validation are often part of the same process (for well-written algorithms). For example, a language interpreter, say JavaScript, would be less efficient and more code if it validated the JavaScript first, and converted it machine-oriented instruction-code later. If you personally disagree, so be it. I'm confident most readers will agree with me on this one.
Well, to be honest, your MVC application doesn't need to know about your database. You say that you are migrating your WebForms app to MVC, it depends on how your webforms application was built. Give us more information about your existing webforms architecture. Is it tightly coupled with your business logic layer? Does your webforms has lots of UI logic written in it ? Unfortunately a lot of webforms applications tend to have lots of logic in code-behind of aspx pages. If you are lucky and your webforms is loosley coupled with business layer and data layer then technically you can use MVC on top of your business layer. You don't need to use EntityFramewotk with MVC. If you already have data access layer that is working then you can build on top of that. If you have data access layer then you can build service layer on top of that and then your MVC controllers can call the service layer. Also, see if you can code against interfaces and include DI. I am assuming you have WCF also because it's exposing some functionality to other apps in your company? If yes then you have to make sure the client who is consuming your WCF should be able to change to HTTP based API. That's additional work for them. If you wanna build Web API the ideally web api should call your service layer, and your web api controllers should be as thin as possible, &amp;#x200B; You could have DataAccessLayer --&gt; ServiceLayer--&gt; then both MVC and Web API can call service layer.
You are talking about just JSON validation, I'm not. I don't think this is controversial at all. It is because it's unrealistic idealism for things apart that belong together in the name an obsession with a single principle above all other principles.
The issue is not what word one uses to verbally label things, the issue is whether to duplicate the check-and-parse logic in two different spots or keep it together.
"We don't need no stinkin' DRY! We don't need no stinkin' DRY! We don't need no stinkin' DRY! ..."
The app is broken into 3 projects: the main app, a web service and a proxy. The main app does have a lot of code behind. Every aspx file has a large code behind .vb file with it. My plan is to completely rebuild it in C# and not rely on any of the old code.
Ok, so correct me if I am wrong, from my understanding your WebForms calls WCF that calls some other service? As you said if webforms have lots of big code-behind logic then it better to spend a bit of time re-writing. Also if you are in charge of your database then you can use EF code-first even for an existing database or you can use Database first approach and generate EDMX file. If your database is good, and you already have StoreProcs, Views etc...then I would probably use Dapper for it. Even though MVC 5 is still good, May I ask have you considered using ASP.NET Core if you are re-writing everything?
The webforms calls the proxy and the proxy calls the web service that calls the Oracle database. I had planned on doing EF code first for an existing DB. Dapper is not an option but there are no SPs. Believe me, I wanted to use Core but my management said no. So, as far as build-out goes, to me it makes sense to create the MVC app but focus upon wiring up the EF and WebApi first and using Postman to test before messing the the UI.
What are the better options to access a database in .net?
 I don't really feel like we're speaking the same language though That's why I gave a more specific scenario, per complex parsing. Talking in generalities is often not enough.
If I had to do that I‚Äôd probably use syncfusion. https://help.syncfusion.com/xamarin/sflistview/item-drag-and-drop
Hi Thank you for answer. Unfortuntely, I cant use third party control.
So many people said that Microsoft open sourcing WPF wouldn't lead to XAML implementations for other platforms. Well look here, XAML in the browser. What a time to be alive.
&gt; Well look here, XAML in the browser \*Silverlight tries to signal from its grave\*
Share the vision; I don't have approval to share any code for this yet (decent chance for at least a typescript or js implementation to let clients use the api easier; probably a reference C# impl that works with Nodatime as well but we would be talking in the next few years about it). I guess I was looking for feedback on it and if anyone might point me at something that already exists. Supposing you were to write an application that worked against an api with a range parameter accepting one of these strings, would you want something else instead? You can always pass standard 8601 dates in this field like `theEndpoint?range=q2019-01-01--2019-06-25`, but with this you also have the ability to maintain something like a dropdown of common expressions and let the user do things like bookmark a url to the "last fiscal year" table data. Since this post I now have working state machines in TypeScript and C# for this syntax. I'm not really happy with the handling of nonspecific ISO dates where my logic is basically: 1. serialize the current relative date to $local 2. consider the 'x' positions in the operand that form an unbroken set from the left as "open", and the ones after to be "closed" 3. based on the operator, set the closed set to be the max (for subtract) or min (for add) possible digit in that position 4. produce an integer from the open set using digits from $local and the first digit from the operand 5. deserialize $local into a new date $next 6. if it is valid and moves in the correct direction (based on the operator) then update the current relative date and proceed to next parse point 7. parse the open digits from $local as an integer 8. increment/decrement this integer based on the operator 9. serialize the integer and update the positions in $local, failing out to the next operator if I've gone negative or gained a power of 10. 10. deserialize $local into a new date $next 11. if it is valid and moves in the correct direction (based on the operator) then update the current relative date and proceed to next parse point 12. goto 8 (every case I've come up with for this is because the open set is 5 or 7 digits and incrementing/decrementing causes the tens position for the month or date to be invalid, which resolves itself after a carry operation; I can probably improve the open date move logic some) There is also a bit of validation on the nonspecific string to ensure I could enumerate the 'x' positions and generate valid dates before doing this.
My comments: For 2, when testing a dictionary you can use .TryGetValue to test and get a value in one step instead of two. Slightly more efficient I believe. Won't matter in most cases of course but if you're writing some new code no reason not to use it. The tips are top notch. #1 was one I didn't realize I needed to do for some time since I didn't realize `throw ex` blows away an existing stack trace. Whoops. Also I forgot catch when exists. I should use that. Right now I do: } catch (SystemException ex) { if (!(ex is NullReferenceException) &amp;&amp; !(ex is MissingReferenceException)) { throw; } // handle null dereference in Unity } I could use catch where. Also the example in 5 won't actually throw an exception. It needs t o use `.Single` to throw the exception, not `.SingleOrDefault`. The latter form is what you SHOULD use instead of trying to catch the exception, then you check for the default value (assuming it's not a valid value you'd except to see) to see if you need to clean up duplicates. Lastly the DOs and DON'Ts list has two #1s. Good article! Thanks for posting.
&gt; - don't swallow things - better to leave them unhandled!! I would say sometimes you just want to abort something on error instead of crashing the whole app which is fine. BUT you should ALWAYS log or display the error somehow instead of quietly ignoring it.
Silverlight would've been great if it was a couple of years early... A shame really
I agree, it's a balancing act. In my \*actual experience\* the very worst software by miles and miles is spaghetti code -- meaning a change in one part of the system trickles across the system to unrelated things. Your example is only so useful because you don't describe what type of validation it needs, the very thing we're discussing. There is no reason to ensure it is proper English grammar twice. You can simply do it later in the business logic (service), and if it fails validation there, the error bubbles up to the endpoint and it returns an error to the user. There is no need to validate the same thing twice in this example. Maybe it's not a good example?
&gt; and monolith architectures are slowly fading into obscurity. I don't believe that's true. I suspect many larger-scale applications are using more microservices, reducing average the number of "monolith" applications, but that's not the same as fading. It's comparable to when commercial jets came out. Propeller planes did start shrinking in market share, but propellers are still used for smaller planes because they are the best tool for the job. When new technologies come out, it often takes a while to figure out when to use them and when *not* to. (Microservices are not really new. XML web services were the "in thing" around 2000. Changing from XML to JSON as the default format is a minor change.) In my experience, Conway's Law should be your primary guide to whether you use microservices. If you don't have dedicated teams for each service, microservices are probably a waste of code and time.
Flutter/iOS(SwiftUI)/Android(Compose) doesn't need that kind of resource file anymore
&gt;You can simply do it later in the business logic (service), and if it fails validation there, the error bubbles up to the endpoint and it returns an error to the user. That's pretty much what I suggested, isn't it? It thus happens in the "business logic service" *instead of* the "validation service". &gt;There is no reason to ensure it is proper English grammar twice. To be clear, my example includes processing of info, not just "checking". I'll make the scenario more explicit: the user is entering Wiki markup text, and a parser splits it out into multiple paragraphs and titles. These sub-elements will eventually be saved in the database as one row per element (single paragraph, single title, etc.) This, we are validating the Wiki markup and processing (chunk-ifying) it at the same time.
What did you end up doing? I‚Äôm currently pretty comfortable in Laravel (2 years exp) and recently picked up Vue. But the job market here in Belgium is mostly Java (spring) and C#. So I‚Äôm thinking of shifting my focus to Angular and dotnet. Any advice? Did you enjoy the switch? I don‚Äôt see much reviews about former Laravel users shifting to dornet, but the ones I see are positive.
Web 3.0 baby :)
I don't think I have ever read an article on microservices where the false dilemma between microservices and monoliths was not presented in the first or second paragraph. Monolithic architectures faded away years ago. Those of us who are writing n-tier apps are not writing monoliths and we won't be converting our apps to microservices anytime soon. Speaking of fading into obscurity, I haven't seen a REST article in a couple weeks and this is the only microservices article in a while.
I think we agree so there's probably not much point in going further with this but the example is a little unique because in this case your business logic overlaps so much with validation. I don't think that's a normal scenario in most apps. It's like saying "Let's say I write an app that validates stuff". Well yeah, there's going to be weird overlaps and SOC is going to be really unique in that situation.
Yes but this is truly in the browser. You don't need any plug-ins and it works cross platform.
Perhaps we are using different definitions of "monolith".
Absolutely, Microservices is a practice for change within the organization; not a change in the technology.
For the record, Uno predates open sourcing of WPF.
Is it running really sluggishly for the rest of you as well?
Running smoothly on Android.
In what scenario?
Perhaps a "validation" service is not a common enough need to be necessary. Trivial validation should be done with various canned model attributes/markers: is-required, max-length, is-integer, phone, email, url, etc. What's left over could be put into biz-logic because it is arguably as much "business logic" as anything.
In a scenario of accessing a relational database
:)
&gt; Just wondering where to place my career bets People are now beyond trying keeping up with the Jonses/Kardashians, now they are trying to keep up with the Jetsons. My past predictions about IT have been worse than random. I hope your crystal ball is better than mine.
Thanks for sharing!
I can't speak to exactly how u/UK-sHaDoW is accomplishing their work but I did a small class at my work over this topic in the vein of teaching 'vertical architecture' a la Jimmy Boggard. You can see the compare contrast between what I've typically seen where a service acts as the orchestration/application code and when you use individual handlers to act as the orchestration/application code. [Mediator Implementation](https://github.com/bgk0018/vertical-slices/tree/mediator-implementation) [Service Implementation](https://github.com/bgk0018/vertical-slices/tree/services-implementation) I've changed my approach a little bit since writing the above, but if you're in a OOP language, I've favored the mediator approach overall. Let me know if you have any questions!
it uses identity framework and will use cookies.
Did not know that .NET supported xml sigs and verification. That's awesome.
The answer is ‚Äúyes‚Äù because they must. Webassembly is the future, unless you want to deal with JavaScript forever (I certainly don‚Äôt). I expect you‚Äôll see it come together in .NET 5 (2020).
Tell that to my iPhone
This is part of why client-side blazor isn't coming with dotnet core 3.0 - the Mono team is busting ass on linking/tree-shaking/AOT. &gt; As part of the effort we have been pursuing two strategies; one that uses the new Mono IL interpreter to run managed code at runtime, and one that uses full static (AOT) compilation to create one .wasm file that can be executed natively by the browser. &gt; We intend the former to be used for quickly reloading C# code and prototyping and the latter for publishing your final application, with all the optimizations enabled. The interpreter work has now been integrated into Mono‚Äôs source code and we are using it to develop, port and tune the managed libraries to work on WebAssembly. So, what we have now is the "generic mono.wasm interprets your existing .dlls" approach, end goal of course being "mono does magic and spits out relevant .wasm"
https://caniuse.com/#search=wasm Must be a bug to report
I should be more clear. I‚Äôm not saying there is an be-all and end-all better option for db access compared to EF. What I‚Äôm saying is that there are other options, and some options will be better than others. Writing really complex joins in your application? Going to be hard to do this in EF in a performant manner. In this case, I‚Äôd probably use dapper. There‚Äôs also different types of databases. Maybe you are using some Oracle/IBM database that doesn‚Äôt have an EF provider. In that case it‚Äôs not even an option for you. My point is simply: EF is not the ONLY option, and thus EF is not ALWAYS the best option.
The best possibility would be in addition from AOTing the whole app would be able to JIT things to wasm on demand. Kinda like the R2R format .net core just recently announced. This would probably be quite helpful for emitting stuff dynamically on the client side while achieving acceptable speeds and avoid the pitfalls of `Expression.Compile` and the likes being interpreted on AOT environments which is slow, JSON.NET had this problem for `Xamarin.IOS` as it dynamically compiles delegates and caches them to deserialize objects quite quickly. Though I'm quite positive it's gonna be possible in the future as the mono runtime can now read both AOT wasm and IL together on a current POC shown by Steve Sanderson on a past aspnet community standup.
 [This code](https://github.com/leaderanalytics/AdaptiveClient.EntityFramework.Zamagon/blob/master/Zamagon.UI/Zamagon.WPF/DragDropListBox.cs) works to drag a listbox item to a different position on the same listbox. Maybe you can tweak to work for two different listboxes?
Anything more advanced? I mod on /r/CryptoTechnology which as the ne implies for CryptoCurrencies uses alot of cryptography. Is it possible to implement say shnorr signitures, hommorphic encryption or zksnarks (zero proofs) in c# without having to write the algo? Perhaps there r nuget packages? Implementing a custom diffie hellman where there is no key negotiation to establish a secure assymetic connection would be nice too. For app to app communication, I imagine this already exits with using custom certs?
This is not WPF based, it's UWP lol
That's fair, but it's a sink or swim world out there and technology churn will probably only grow faster. I'm lucky the .NET world has made such strides recently, though. C# is a really nice language and Core is the future.
Microservices aren't based upon any radically new technology. They're just a different way of organizing different parts of your code. Jets largely replaced propeller planes because they go faster and use less fuel, at least for longer flights. Those are clear benefits for everyone involved. The benefit of switching to microservices is debatable. It's probably a good decision for big tech companies, but smaller shops are doing it as well and honestly, I don't really see a clear benefit to it.
&gt; Why ‚Äì well that‚Äôs what we at Uno Platform do üòä ‚Äì enable the same C# and XAML code to run on the Web, Mobile and Desktop.
Karoly is that you?
Have you approach them with ‚Äúbusiness oriented‚Äù mindset? If you lay on them how old is MVC5 and the expected support lifetime and then compare it to .NET Core, as well as show some costs in infrastructure and arguing that core is Multiplatform? Another question is, if you have your entire logic behind the webapi and DB why not use a JS framework for UI? Even if integrated within your MVC :)
why do you loop over `MccDaq.MccService.ScaledWinBufToArray` and don't just immediately put it after `DAQ.AInScan` ? Also why name the Stopwatch instance "timer1"? (btw. there is a `Stopwatch.StartNew()` static-method) &amp;#x200B; Somehow this code looks like it shouldn't even work the way you expect it. While timer1.ElapsedMilliseconds &lt; 500 '... Threading.Thread.Sleep(1) errorStatus = MccDaq.MccService.ScaledWinBufToArray(data, dataArr, 0, numPoints - 1) previousArr = dataArr Voltages.AddRange(dataArr) Voltages.Add(5) VoltageArrs.Add(dataArr) 'writeDebugLine("sent to list: ", timer1) End While Arrays aren't really value types, you always loop over the exact same array, but at a minimal later time. I'd imagine the `DAQ.AInScan(...)` to immediatly load all data into the `dataArr`, but this code makes it look like it is streaming data in (maybe because of `MccDaq.ScanOptions.Background`) it might be an much simpler approach to just do it synchronously but inside another Thread to not lock up the Main-Thread/Form while loading in the data. &amp;#x200B; nitpick: `Voltages = New List(Of Double) 'clears voltage list` does not clear the list, but replaces the old list with a new one. (might want to use `Voltages.Clear()` here) &amp;#x200B; Also there is so much unne
It will work with ASP.NET Web API (to what the term Web API usually refers), but it will not work with ASP.NET Core when running with .NET Core, which you use. A short term solution is to run your application in the .NET Framework, instead of .NET Core. ASP.NET Core 2.x still supports the full .NET Framework, but this support will be dropped with version 3.0.
Android with Chrome and I get the same blank screen
Thanks. I spent a good part of last night trying to do just that --- trying to get it to run under .NET Framework -- and it was also having problems. It turns out the special camera support DLL was causing problems with IIS Startup until I force all builds and IIS running to 32-bitness (despite running on a 64 bit setup).
Then the DLL is likely native code, which does not support AnyCPU. You need to set up your project to use 32bit only. Your system being 64bit does not matter, as 64bit systems support running 32bit applications.
WASM version takes like 20s to load. Pretty unacceptable.
Same here. Also, no hover transitions on the buttons like in the Windows version.
It's not WPF or UWP, it's Uno, which uses XAML and C# but isn't the same thing.
Yes, running "UWP XAML", not WPF. It just support UWP Code. There's no relation with WPF, like, at all.
I'm in the same boat as OP, and unfortunately this is a hallmark of answers online. I, too, have a legacy webforms site that I've already re-written to be as decoupled as possible but want to move to MVC. But all the tutorials I've paid for and gone through are about creating new databases. That's not practical for most people because unless you're a startup, you're going to work with existing data. And you're not changing that database structure. I work for a university that has multiple campuses all connecting to this application and that has to work with several Oracle databases. No amount of persuasion is going to make a university system discard their existing Oracle databases for SQL Server or whatever else. So we must find solutions for the requirements and constraints that we have. It seems like nobody else in the world has ever had to connect to an existing database, much less an Oracle one, based on exhaustive research online. There's generic "Oh just download Oracle's crap and put it on your machine, problem solved :DDD" but that doesn't work. And it's not that simple. Nothing with Oracle is that simple. I know how to connect to Oracle in webforms. I do not know how to get MVC to do it and use it for models. Everyone at best says to use the ADO.NET model builder wizard, but I find it simply doesn't work. After fighting Oracle's stupid TNS crap, once you enter credentials, the wizard just vanishes and no further dialogues are created. I'd bypass the wizard and construct things manually, but there is still no information on how to connect to an existing Oracle database.
Just want to say I'm in your exact situation, and have yet to find good answers. Been trying to do this for years...usually getting frustrated and abandoning the effort, then coming back later as I gain new skill with .NET and trying again. Online instruction is worthless. Everyone is all about creating a new customer order application with a new database, which I highly doubt anyone taking the tutorials is *ever going to do*, certainly not anytime soon in their careers. There's nothing about reaching existing databases that has any particular value.
Ya, the code is really messy cuz it was a debug script and I just kept changing things. I guess I should have taken the time to clean it up as to not trigger other programmers, lol. &gt;why do you loop over MccDaq.MccService.ScaledWinBufToArray and don't just immediately put it after DAQ.AInScan ? Because I'm trying to take data more than once. I need many smaller queries in order to implement feedbacks. There's no need to call AInScan more than once. &gt;this code makes it look like it is streaming data in Yes, that's the continuous mode setting, actually. AInScan in continuous background mode just starts constantly filling and overwriting the buffer. So to actually get data, you query the buffer. Trust me, that part of the code works just fine. &gt; just do it synchronously but inside another Thread... Yes, that's how I always implement it. But for debugging, it's useful to take multithreading out of the equation. In the multithreaded version we couldn't query faster than about one per 30 ms, which we realized was because the function which tells you where you are in the buffer is crazy slow. &gt;Also why name the Stopwatch instance "timer1"? LOL. Because I usually name the stopwatch "timer" despite there being a timer class. It's a bad habit. At one point I managed to break it and thought maybe the compiler was confusing the stopwatch with the timer class, so I renamed it and didn't change it back after. &gt;might want to use Voltages.Clear() here I usually do, but I actually, but this made me curious. What's the advantage there? New releases the old list's objects, too and resets the capacity. Clear doesn't reset the capacity, but otherwise the methods amount to the same thing don't they? Is clear faster? Sorry my code is poorly cobbled together, but did you have any insight on the actual question?
I hope you get some good feedback because this sure does seem like an interesting project. I myself wrote a fuzzy time textbox for a project tracking. You type in 830 and when you tab out, it interprets it as 8:30 AM. If you are in the textbox and press P, it will parse and switch to PM. If you type 130, it assumes 1:30 PM. There are a number of little things that make it complete. It's nothing monumental, but it's one of my favorite controls of all times, just because it reveals itself to be the only correct way to have a time box...
I'm not sure exactly what vue is like since I use angular, but if the concepts are at all similar, then you should be able to. They're both libraries that facilitate a Single Page Application structure, but they don't HAVE to be that. Each page can be its own "application," and that's actually how I use angular in the project I work on, since it's a multi-page application. We still get great use out of the data binding that keeps the app responsive and easy to work with, I imagine it'd be no different with using vue to accomplish something similar.
I thought I had mentioned this in the article but it looks like i nix'd it for the sake of brevity. Yes I absolutely agree with you that the decision to refactor here would be best if it was based on a true need. This article is more the \_how\_, but not the \_why i decided to\_. For example in this case, there are plans to move away from Google Sheets as the logging mechanism, so this is what dictated the decision to move that piece into a service and behind an interface. On top of that, this is an azure function, so you wouldn't have feature folders, DDD, layers, or any of the complex architectures you are mentioning.
I feel your pain :)
Always great to hear from these two. .Net Core is shaping up to be everything I hoped Mono would be back in the day.
Yeah if you are pulling in the cdn then you should be ok. But you're going to have a bad time if you start writing javascript that needs to be transpiled via babel or webpack. Webforms is a nightmare to put it simply.
CLR via C#, Windows via C/C++, Windows Internals, Pro .NET Memory Management, Concurrent Programming on Windows, .NET Internals Cookbook.
I bought [Writing High Performance .Net Code](https://www.writinghighperf.net) by Ben Watson as a thank you for his [RecyclableMemoryStream](https://github.com/Microsoft/Microsoft.IO.RecyclableMemoryStream) package, and it's full of interesting behind-the-scenes stuff.
IPFS is just a distributed content addressable storage and is not necessarily anything to do with "blockchain." The purpose of IPFS is to enable data to be stored, referenced and accessed possibly far into the future even if any servers or registerd names go down or change owners. Consider for example, the number of Wikipedia references that go 404 because most web pages from the 90s and early 00s no longer exist. Simply put: IPFS separates file content from *where* it is stored, whereas the web is based on looking for data at specific locations (URIs). The underlying technology is a DHT. It has more in common with Bittorrent, freenet etc than blockchains. There are several other projects with similar goals to this which are also not "blockchain" related. Use of IPFS in "blockchain" projects was an obvious choice where the amount of data you can put onto a blockchain is limited. Instead, you can put your content on IPFS, then you only need to put its content id (the hash of its contents) onto your blockchain. IPFS developers have certainly tried to ride that hype, and in 2017 they publised a whitepaper on "Filecoin", which raised a few hundred million dollars before any prototype existed (and AFAIK, no prototype exists to date). I'd personally stay well away from Filecoin, but IPFS is valuable technology.
I just got a copy of the second edition yesterday and it's great so far. Definitely second the book.
I sure wish people would simply post articles instead of videos... Some of us don't have an hour to go through a video for three things that might be interesting.
The camera support code provides both 32 and 64 bit versions. When I initially developed test code to validate the camera stuff, I was able to create a Framework Console app that used the 64 bit managed library. In fact, it didn't work until I explicitly set the built to x64 -- it was referencing the 64-bit version of the camera's managed library. HOWEVER, I can't get it to work with IIS Express/Web API Framework app in x64 mode. I can get it to work in 32 bit -- At least for development. &amp;#x200B; Sadly, I can't seem to get it to publish: https://imgur.com/7wE1R0G &amp;#x200B; I realize that I'm a relative newbie to VS and dotNET, and probably being overwhelmed by my not understanding all the pieces -- I want to thank you for taking time with the help you've already given me!
Did you enable x64 mode of iis express? By default it runs in 32bit.
I did try that. It would cause IIS to exit at startup with an error code, but with no apparent explanation that I could tease out. I'd like to keep most of this public for the benefit of others; but I'm going to send you a separate PM as well. Thanks!
Just to be clear, I set the project option to indicate running 64 bit -- but I don't know if IIS Express actually RUNS 64 bit mode, or do I need to do something more explicit to ensure it is running in 64 bit mode?
&gt; it's a sink or swim world out there and technology churn will probably only grow faster. Software development is indeed a crazy career. You can make pretty good money but you can also get hit by a proverbial sportscar rushing past you. It's driven more by fad than vetted logic and analysis. For example, is why is core throwing out XML config files for JSON as the default? They are fixing things that ain't broke to be hip and cool. In 5 years some other data syntax may also replace JSON as the "in" format. Stop chasing the Kardashians and their fat asses.
There is no project option for IIS Express 64bit mode. It's a global flag in Visual Studio. Google it.
Ah. Thanks. (https://social.msdn.microsoft.com/Forums/vstudio/en-US/e206cebd-28fe-4c38-a4fb-a214f65ce56f/64-bit-version-of-iis-express?forum=visualstudiogeneral) I was going down the wrong path -- and didn't realize that there was in fact a separate option for the IIS Express invocation. (I've been thrashing on several fronts, and I thought the setting in the project was sufficient.) It was a case of prematurely pruning my search!
Whats the difference between "Assembly Linking" and "Tree Shaking". Like in [WebPack](https://webpack.js.org/guides/tree-shaking/).
There is no BasketTicket dbset in your MyDbContext class.
That shouldn't matter. Adding it makes no difference. If I generate migrations it creates a BasketTicket table.
Ok, [so there's success on that front!](https://imgur.com/Vf6af0J) I now have it running in 64 bit mode. Thanks! (BTW, blurry image is from a test camera at my desk which is a proxy for the real thing.) Still having troubles with the publishing process, though... Still working on that...
This is what threw me off, btw -- it seems as if the server's running bitness can be set from here [https://imgur.com/r8NgSNM](https://imgur.com/r8NgSNM)
This is coming in Core 3 finally!
I feel like I'm losing out on the coolness train by doing C# and enterprise work, and feel like I should sell my affordable house, move to Silicon Valley, and write full stack Javascript in an office that contains a ball pit. Thing is, I like C#, I don't like Javascript, and I actually love how opinionated the MS world is. More choices just risks more procrastination. I need a few solid, well supported technical solutions, and I get it.
Your `Basket.Ticket` property only has a public getter, not a public setter. This means Entity Framework can't set it to a collection that tracks the `Tickets` associated with a `Basket`. Replace it with this: public class Basket { //... public ICollection&lt;BasketTicket&gt; Tickets { get; set; } public Basket() { Tickets = new List&lt;BasketTicket&gt;(); Id = Guid.NewGuid(); } public AddTicket(decimal price, int quantity) { Tickets.Add(new BasketTicket(price, quantity)); } } That should do what you need. In addition, in your `TestController.cs`, you don't need to call `_db.Baskets.Update()` on line 33. EF automatically monitors property changes on tracked entities, so all you have to do is call `_db.SaveChanges();`.
Ok. I only want the object itself to be able to mutate the collection though, how would I achieve that?
... and now I've got that sorted out, too, sort of. My publish settings was not quite right - in creating a new publish profile, I: 1. Set a publish target of a folder 2. Under Advanced... set the Configuration to Debug-x64 3. Published Then I could actually manually start is from the shell with: &gt; cd \Program Files\IIS Express &gt; iisexpress /path:c:/path/to/publish/target Thanks /u/AngularBeginner for the pointers and the resulting morale!
You can't. This is why it's generally inadvisable to use Domain models with EF. Instead, you'd use Data models.
Winner winner chicken dinner.
I tried the example you provided, but it still doesn't work.
The example doesn't work though?
One more thing I just noticed: in your `TestController.cs` on line 22 (where you pull in the first Basket from the database), you need to inform EF that you also want all of the Tickets belonging to the Basket. Do this like so: var basket = await _db.Baskets.Include(b =&gt; b.Tickets).FirstOrDefaultAsync(); Otherwise EF will just get the base properties of Basket, without attempting to set its Tickets collection property.
Hmmm, I just assumed that his thing would work without looking at the code. Let me take a peek. It‚Äôs a common error so I just assumed it was it.
That's it! Works now! Even with the original code, there was no need to provide a public setter as per your first suggestion.
I assume assembly linking is rolling all dlls into a single exe (for example). This is great but would generate some huge executables without tree shaking, which is the process of removing code that is never going to be called.
Use a string with the name of the private or protected property when mapping the relationship. Or you can set the model metadata to use a field. https://stackoverflow.com/a/44285643/224087
I asked because [this slide from the video](https://i.imgur.com/Gwhm57E.png) specificall mentions that it "trims unused code from your code and dependencies" which sounds identical to tree shaking. So I guess its safe to say Assembling Linking is NOT Tree Shaking but its doing Tree Shaking conceptually under the hood?
Good stuff. üëçüèæ
Looks like /u/unndunn got to it before I did. In EF 6 and lazy loading you didn't need to explicitly call Include but it appears with your app it is needed.
I don't think use vue with webform is possible. Rewrite all the app using asp.net mvc instead and use vue
See this blog post by Scott Hanselman, https://www.hanselman.com/blog/MakingATinyNETCore30EntirelySelfcontainedSingleExecutable.aspx
Use private setter: https://docs.microsoft.com/en-us/ef/core/modeling/constructors#read-only-properties
I can confirm that I'm logging out as I can't access things that require specific authorization. I also saw one cookie named ``.AspNetCore.Identity.Application`` getting deleted on logout. My issue was that I was using the userManager instead of the ClaimsPrincipal to add my claim. The manager was creating the claim in the DB so even on logout, they were persisting. Now, my new issue is that the claim isn't getting added to the cookie so on new request, it's lost. I should be close to figure this thing out.
It is hard to go back to jquery I would start to use vue in the webforms posting data to WebAPI/MVC controllers instead of webform postback You can then start to move all new pages/major rewrites to MVC as you can Note you can actually use webpack and vue to compile multiple pages but it might get a little unwieldy on large projects [https://cli.vuejs.org/config/#pages](https://cli.vuejs.org/config/#pages)
Can you look into Rx and sample?
ReactiveX framework? That might be a good long term solution, but I need to learn a lot first. Thanks for bringing that to my attention though.
Follow Microsofts 'getting started' guides for newbies. They'll have you install free development tools and work through sample applications. If that seems interesting and fun to you, there you have it.
I implemented this exact scenario a few months back using Mixed-Auth (https://github.com/MohammadYounes/OWIN-MixedAuth) as an external AD provider. It was for .NET framework but may so work with core. As for if you are using Identity correctly, remember that you just building an identity with a set of user claims, and using a sign-in manager to then persist this set of claims to a cookie, etc. Identity doesn't care where your user comes from, e.g. in memory/database. As long as you implement the back services to correctly authenticate based on either flow (credentials or AD username and password) and build the correct set of claims it will work fine.
I'm currently on a team writing a Blazor server side app for the company we work for. The app is being rewritten from Vue. We've had our ups and downs with it so far. It's a pleasure to work with C#, and we do much prefer it to Typescript, however it has a steep curve. With it being so new, it's hard to find documentation on how to do certain things. If you're comfortable reading aspnetcore source files to find out how certain things operate, then you should be just fine. Once it's fully out in September, I have no doubt that it'll take off quickly.
Speaking as a .net developer, it can be very fun, as long as you like creating and solving problems. It doesn't necessarily mean you have to go for .net however. A programmer is a programmer. The language and framework is simply a tool to get the job done.
https://speakerdeck.com/davidfowl/hidden-gems-in-asp-dot-core-and-net-core-3-dot-0 On the flipside, it's easy to multitask and listen to a video for the interesting parts while doing other things.
There is no such thing as a dotnet file. For a front end page using .net, you can use (depending on your template) : - .aspx web form with code behind - .html file with a back end ASP.NET WebAPI - .cshtml file which uses ASP.NET MVC with Razor (optional code behind if you prefer to not use MVC)
Dotnet (.NET) is a framework, not a language or file. We would need more details on what you are trying to accomplish go offer you a valid response. .NET applications are hosted on a server. You would create the application and have JavaScript respect your user, or offer them a hyperlink.
One simple solution is to deploy the same code base on two separate sites in IIS.
okay so I created a .Net web app for Stripe API... it has a View with a form ... how do I create a hyperlink to that View? what would be the destination of the hyperlink?
It would entirely depend on what you setup on the server... I would recommend you take a course on Udemy or watch some YouTube videos at the very least to understand basic HTML syntax, before you dive into .NET. Without knowing how your .net app is setup, if you're using asp or razor pages, etc, there's not much that we can do to help you. Im sorry if this is coming off a bit rough, but you would be doing yourself a favor of you took the time to learn the basics first.
&gt;okay so I created a .Net web app for the Stripe payment gateway API... it has a View with a form ... how do I create a hyperlink to that View? what would be the destination of the hyperlink? I probably sound insane right now because I cant even use the right terminology lol ... but I used the MVC template to create a controller and view... the view has a form that sends payment details to Stripe that sends the form back a token that is checked in the controller... Now I want to redirect the customer from my HTML page to this form... but I have no idea what the file structure is of .net or how to hyperlink to this View/form
bro I am a game designer and have been coding in C# and C++ for 9 years and assembly and machine language for 4 years and CG/HLSL for 3 years now... html syntax is pretty simple and creating a
&gt;bro I am a game designer and have been coding in C# and C++ for 9 years and assembly and machine language for 4 years and CG/HLSL for 3 years now... html syntax is pretty simple and creating a Almost none of those things have anything to do with creating a payment processor page that is handling financial transactions.
If you have that much experience under your belt, then you should know that Reddit is not a forum for you to be taught how to program. You should be doing some research and instead ask focused questions that are not nearly as broad as "how do I link an html file to a dotnet file" Further, if you have 9 years in C#, there's no way you got this far and call it a dotnet file... I wish you the best in your search.
to do that research I need some keywords that are .net specific that I was hoping to get from reddit users that would be willing to help a brother out
its like if a web developer like yourself would be building a vertex/fragment shader and not knowing the file structure or what to call anything
Sounds like you‚Äôre trying to do something pretty basic. Strip out anything you think might be confidential and throw it on GitHub. I‚Äôd be happy to take a look and help you out. Sounds like you‚Äôre not talking about much more than an entry form that submits data into a third party API for processing so probably not massive amounts of code involved.
Ma Man! appreciate it...yea Ill just do that and hit you up
Just bought this, definitely a good read
&gt; so what is the dotnet equivalent to an index.html file? If you are using the Web Forms framework, then there are two files that are roughly equivalent: Default.aspx and Default.aspx.cs (or .vb).
the form submission works fine... the 3rd party (stripe) is processing the data fine... I just want an index.html file to point to the form
ah okay...I think I did create a Default.aspx thinkin that Visual Studio would do it for me
This is what I wish existed in 2001 when I was still in college and learning to hate web development....Blazor would have eliminated all of that hate.
Nice list didn't know hanslemen and a podcast. Any interesting podcats that is good for architecting systems?
it was a rebuttal to the suggestion of taking a course in html
Interesting and super cool that your team adopted the idea to use it. Is the backend .net? Thanks for sharing!
Non .NET centric podcast, but has some good content: [https://softwareengineeringdaily.com/](https://softwareengineeringdaily.com/)
Look up routing in .NET :)
Since we are using Blazor Server Side, it's technically all backend. The backend generates the HTML and transfers it to the browser via SignalR. The actual .razor files have direct access to the database, therefore there isn't an API.
thanks man! really appreciate it
&gt;routing in .NET that was it!!! you a legend brah!
Feature folders &gt; layering. I don't think I've ever seen a layered architecture that has properly followed open/closed principle. I'm sure it can be done, I just haven't seen it.
Can you give me an example or link to what you mean? Or explain the benefits?
The No Dogma Podcast had Mads Torgerson this week. https://nodogmapodcast.bryanhogan.net/
I have experience working with: * Blazor server side * AngularJS (\~4 years, one mid to large sized B2B ecomm system) * Angular (\~1.5 years, 3 internal LOB web apps and one small PWA ) * VueJS (\~6 months, an ecomm integration portal) &amp;#x200B; Angular is probably the most similar framework that I feel I have enough experience with to compare to Blazor server side. **Advantages for Angular** * It is production ready today, Blazor's model is still being changed and hasn't officially released yet. * It has support for PWA's (though honestly, use Workbox, its so much better). Blazor server side categorically can't work as a PWA. * TypeScript. You'll still need JS to interop with the browser no matter what you are coding your components in, and writing that code in TypeScript is nice. You can technically use TypeScript to compile JS to use through JS interop in Blazor, but I don't imagine that approach will be possible. * More scalable. Blazor requires an active connection per client, and storing component state server side for each client. * Angular Material. There are some equivalents being worked on for Blazor, but they aren't ready yet, and Blazor doesn't have an animation library that is as sophisticated. * Scoped styles for components. This can be really nice and Blazor doesn't have it. * Tooling is more mature for Angular today. Razor support was only recently added to VSCode's language server, for example. &amp;#x200B; **Advantages for Blazor** * Server side rendering (called pre-rendering in Blazor to avoid confusion) is basically free and much easier to use than the Angular equivalent. The initial page rendering can often be much faster because of this * The initial page download is much smaller compared to a similar Angular app, since the Blazor js library is basically just a websocket connection and a way to render graph differences to the DOM. * Async and threading paradigms. While RSJX is a decent paradigm for handling asynchronous operations, the C# approach feels more natural and is much nicer for the 'happy path' (i.e. when you don't need event debouncing). * Websocket based connection. Compared on an HTTP2 server this advantage might not matter as much, but the message framing over a websocket through signalR doesn't have to establish a connection or send or parse headers. The latency can be very good when it matters, and the websocket can be used with services to do server side push of events to components. * The language. TypeScript is good, but the only advantage it has over C# is that its output runs in a browser...C# is better in most other ways. * Build / iteration time for Blazor is MUCH faster. Blazor build and debug time is usually an order of magnitude faster than an Angular serve rebuild for a single file change. CI/CD builds compared to Angular production builds can be 10-20 times faster. &amp;#x200B; **Things that are similar or mixed** * Routing - Angular's routing is more powerful, but also requires a lot more boilerplate and is harder to understand and use. Blazor's routing is strongly typed (for example, if you want to to have an integer route parameter), which is more valuable than it sounds. * Parameter passing is very similar for both * Making calls to web services. Both have decent HTTP Client libraries. * Templates. The Angular and Razor templates have similar levels of expression and power.
I would try a couple of things. Try [using the dotnet tool to add a secret](https://docs.microsoft.com/en-us/aspnet/core/security/app-secrets?view=aspnetcore-2.2&amp;tabs=windows#set-a-secret) and see if it ends up in the file that you expect. Try adding a fake setting for "FOO" to your appsettings.json because in the examples there is always a default setting that the user secret overrides.
 My dev group was using blazor server side components for building an application up until about a few months ago. Nice to work with but not enough documentation. Also kept running into issues getting auth to work with it so we decided to go with razor pages and js instead because of time constraints. We'll likely wait until net core 3 is out of preview before trying to use it for production. It shows a lot of promise and most of the devs would rather use c# for everything. I used angularjs for about a year before angular was a thing, and react for over a year. They all feel pretty similar in the component based apps arena. Hard to say which I like more. They all have pros and cons.
Thanks for your insights. &gt; Blazor requires an active connection per client, and storing component state server side for each client. Can't decide if this is good or bad.
I had a similar reaction, but then I started leaning towards good. For the apps I build, if the client loses the connection to server-side, I want them to know anyway, and no be left mistakenly thinking they still have live data. Maybe with some apps that's less important, but if their network is down or they get cut off, I don't want them still working in the app and then only realize when they try to 'save' the work. You can customize the error messages they get, from what I understand, so rather than the webpage just getting broken like Facebook does now and then on my mobile when it isn't getting any response when it polls the server, you can give a clean network down notice. Should anyway, I suppose. When client-side Blazor is available, I'm sure it'll have the ability to work offline and then update on reconnect, and that'll be nice, but in the meantime, I'm content to start developing with server-side. YMMV
This is super insightful thank you!!!
Dropping the `I` prefix will just cause confusion, e..g `class Fubar : First, Second, Third {}` - Is this class inheriting from any other class?
Cool idea. Perhaps you can cache the result of the reflection call in \`AliasModelBinder\`. E.g. A static concurrent dictionary with for containerType and AliasValueProvider. \`private static readonly ConcurrentDictionary&lt;Type, AliasValueProvider&gt; typeValueProviders = new ConcurrentDictionary&lt;Type, AliasValueProvider&gt;()\` Also how does this library the precedence of binding aliases when dealing with derived classes?
The author who argues against Hungarian notation clearly doesn't understand [how Hungarian notation is supposed to work](https://www.joelonsoftware.com/2005/05/11/making-wrong-code-look-wrong/), as is tradition. The idea that prefixing interface names with `I` is a form of that misunderstood version of Hungarian notation is, of course, also wrong. And not everyone reads code in a fancy IDE. In a world where people read code on GitHub instead of Visual Studio, it still pays to make the code readable on its own.
Why downvote him? He is right. Without intellisense or looking through the class/interface definitions you wouldn't know if there is a class or not.
I always disable code lens right away, the performance hit of that feature alone drives me crazy.
I disliked it at first, but after you see how many idle connections a server can handle it becomes less important. I think the RAM usage to store component state is actually more concerning. I would expect a Blazor server would require more RAM than a stateless one, but I haven't seen anyone run tests yet to see exactly how much more.
I'm holding off VS2019 for now. Main issue? Projects (.Net4.5- 4.7) that compile successfully in VS 2017 are giving dozens of errors in VS2019. Mostly in the Test projects
Well... when Microsoft abandons it like it has everything else, I'm sure we'll all learn to hate Blazor as well :D
Oh...no....I learned to shower development because it was a nightmare realm of duplication and hacks.
VS2019 performance are better than VS2017, but performance with resharper are awfull and worst than ever.
it is a separate process than does not block the main process ?
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/csharp] [Hosting a .net core application as docker container on windows](https://www.reddit.com/r/csharp/comments/c64xd6/hosting_a_net_core_application_as_docker/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
Rename stopped working in 2019 on me just yesterday. First time I‚Äôve ever seen that in 18 years.
Not really, GC Gen 2 collect blocks the UI.
Then I might question if the project is portable. We had a lot of problems upgrading, turns out the projects were just setup wrong a long time ago, or had old imports that we should have never used, or were just using NUnit 2 (we should have upgraded a long time ago). Just for context, our projects target everything from net35 to netcore2.2.
Hey, I've only had a brief play, can you expand on the difference between server and client side Blazor? &amp;#x200B; Thanks
That sounds more like an issue with your environment and/or projects. The Roslyn compiler between 2017 and 2019 didn‚Äôt change much aside from fixes and feature editions. You should try testing on a complete clean environment (always best to use VMs for development) with a fresh install of VS2019 only.
Docker for Windows is only for dev, not for production. Also Docker for Windows only provides a interface, the docker container itself will run in a VM f. e. on HyperV and will be - yeah u guested it - Linux! First of all, you should think about, if using Docker brings advantages. Do you need Scalability? Are your services stateless, so they can be easily scaled? Then yes, Docker is the right path. But don't use docker, because it's a fancy buzzword these days. I also like to use docker as kind of a sandbox for customers, with only one virtual server and many different services to separate them and provide additional security. &amp;#x200B; However, if you only have it as a stateful Windows Service on your Windows Server, there is no really need to use Docker. I already used the Windows Service integration for a [ASP.NET](https://ASP.NET) Core application, so there should be no problem to use it for your scenario, especially as your are already using generic hosts.
I'm just a *bit* biased, but "Coding Blocks" did a big series on clean architecture a while back, and we're currently working through a "Pragmatic Programmer" series that looks at things from a high level perspective.
I moved from VS2019 to Rider last month for the same speed issues. For me the editor typing became painfully slow; it doesn't seem to be related to code lens (i disabled it).
Ooh, I hadn't heard of this show before. Subscribed now!
That's a feasible approach. Not sure what you're buying yourself other than the ability to `docker run myFileWatchingService` but maybe that's good enough. If you look at how some of the other containers are built for windows, such as sql server, you can see that basically you have a command that's run inside the container that is the application that stays alive - look here at the bottom - you can see that the command being called is "start" - that's the powershell file in the same directory... https://github.com/microsoft/mssql-docker/blob/master/windows/mssql-server-windows-developer/dockerfile And here are the contents of that file that basically keeps the service alive: https://github.com/microsoft/mssql-docker/blob/master/windows/mssql-server-windows-developer/start.ps1 So, you can totally do what you want. I'm assuming the primary reason you'd want to put this in a container is portability? For example, if you do convert your application to .NET Core, then technically you could run the same container in any environment - Windows, Linux, Mac, etc. The other thing to consider is you don't necessarily have to port it to .NET Core. You could likely just keep it as a .NET Framework application and use the Microsoft .NET which is a Windows only container... https://hub.docker.com/_/microsoft-dotnet-framework-runtime
&gt; Docker for Windows is only for dev, not for production That's not true, There are plenty of places using Windows Dockers Containers on Windows servers in production. Though maybe you are just arguing that you don't think its suitable for production, even though it's being used that way. &gt;Docker for Windows only provides a interface, the docker container itself will run in a VM f. e. on HyperV and will be - yeah u guested it - Linux! Also not true. Docker for Windows provides allows you to pick between windows containers or Linux containers. The Windows Containers are windows all the way down. (see "Switch to Windows Containers" [here](https://docs.microsoft.com/en-us/virtualization/windowscontainers/quick-start/quick-start-windows-10#switch-to-windows-containers) &gt;Do you need Scalability? Are your services stateless, so they can be easily scaled? Then yes, Docker is the right path. But don't use docker, because it's a fancy buzzword these days. I absolutely 100% agree with all of this.
Okay, i I didn't know, that there are real windows docker containers. Even the thought about that gives me goosebumps... Then yes: this might me a possible production scenario. I'm kind of suprised because the official .NET core containers are also based on Linux. I only used Docker for Windows during Development of a .NET Core application with Visual Studio and it was the second biggest mess, right after npm with node_modules. I personally would never use it for production, especially as you can run .NET Core on Linux.
Join the Project Rider user community, we have cookies!
Well, It defaults to linux, so I can understand that. I typically see it being used for .net framework apps, since they can't be Linux. Most .net core apps (that I've seen) do end up on linux containers, just because it's cheaper (no Windows licensing costs), and faster to deploy. And if you are going to deploy on Linux, it makes sense to do you docker dev on the Linux containers, even if you are using a Windows machine.
My biggest issue is with Intellisense being non-existent for a whole day sometimes. I agree with the other comments here, I use Rider when I get too frustrated.
Another clarifying point here. I think the assumption was Docker on Windows 10 or similar. Docker for Windows Server actually runs Windows containers by default - there are configuration files to change which can be run. But yes, totally, there are containerized applications that are production ready that run in both Windows and Linux containers, on Windows servers. For that matter, Microsoft heavily uses both types of containers in Azure, their public cloud. Also, back to my original reply - I too agree that the use case needs to make sense. There is ONE HUGE benefit to running in the container vs just installing the service on the OS - other than portability, the main draw to running in containers is they have all their dependencies bundled in - so the version of the .NET Framework, any other dependencies, etc. - that's all baked in so running it on any server that can host the container should just work as expected. So, don't use it just because it's a buzzword for sure...bu there are real, tangible benefits to using a container.
Thank you very much, that was very useful! I didn't realize querying for local users was as simple as changing ContextType, that alone will save me a lot of time.
Blazor Client runs via wasm in the browser. Web Assembly is responsible for loading mono which in turn loads .net into the browser and gives you full capabilities of the .net core framework from within the browser. This comes with the nice benefit of having near-native performance. Blazor Server runs .net on the server and transforms your templates to HTML and transfers it to the browser over SignalR. The browser simply loads a small .JS file to communicate via SignalR with the server. This has the nice benefit of having absolute full access to .net core and .net standard such as having direct access to your database without the need to go through an API. &amp;#x200B; Blazor Client is not yet slated to be supported until after the release of .net core 3.0. I would assume sometime next year. Blazor Server is slated to be supported in September with the release of .net core 3.0
Yes.
I actually used that process to create the secrets file originally. I decided to add another secret to the file, which it did, but it changed the file's syntax to: { "ConnectionStrings:FOO": "Server=X;Database=FOO;Trusted_Connection=False;User Id=XXX;Password=XXX" } Weird.
This was one of the major blunders for UWP, tying it to the OS was a really bad idea. Most large companies update windows on a really slow cycle. My company is in the middle of rolling out Windows 10 1709, which is almost 2 years old now. Many companies us LTSC, which is 3 years old. There is no point for me to even think about upgrading my WPF app to UWP. I'm working on pool membership management software on the side, I'm still targeting WPF since I have no idea what version of Windows pools will have, if it will be the latest.
Pretty sure xamarin is not under unity
&gt; Use events on singleton backend services and allow Blazor components to bind to those events when they are created. This gives you server side notifications to the client for free. This one's really nice when I ported our existing internal LOB app's news feed. I just hooked a notification request on with Mediatr and let it fire the event to update the feed instead of all the plumbing I did with Angular + SignalR. You essentially get data synchronization for free with SSB. Also plus points is that our server was already .net core so adding it and reusing all our existing `Request / Command` POCOs made rewriting everything quite quickly enough for a POC that I presented to the team. We definitely have plans on going live with SSB for a lot of our future internal apps here. I do agree styling and animation does need a bit of polish as today you'd be hard pressed on implementing transitions on events that may happen (e.g. when deleting a DOM element via next repaint, you don't have an easy way to know when to do a fade transition). I hope that get's solved as that's one of the biggest pluses of Angular right now and is cleaner than React's way of animations in my opinion which involves wrapping the target with a wrapper component `&lt;ReactCSSTransitionGroup component='div' transitionName='css-trigger-here' /&gt;` vs Angular's `&lt;div [@definedAnimationTrigger]='animation states' /&gt;`.
I get excellent performance on the current preview version; something that's helped me is [solution filters](https://docs.microsoft.com/en-us/visualstudio/ide/filtered-solutions?view=vs-2019). This lets you specify only a subset of projects active within a solution, and speeds up most actions.
Literally the first link to show up when searching for ".net core 3 uwp". &amp;#x200B; [https://devblogs.microsoft.com/dotnet/net-core-3-and-support-for-windows-desktop-applications/](https://devblogs.microsoft.com/dotnet/net-core-3-and-support-for-windows-desktop-applications/)
You can throw those commands into a scripts. I would write both .bat and .sh that way the company can run it on whatever platform they want.
I don't have any issues, using 2019 on 2 different computers. I dont have a huge amount of plugins, no resharper, but AWS, azure and git. I'm on enterprise version and it's on 2 desktops.
If that happens just think that there are also people out there using Xcode that never saw it in 18 years.
Everything seems fine for me. I don't use any competing programs though, like Resharper or Coderush, and I do have code lens on and rename works as same as it ever did. To be honest there are always posts like this within the first 3 months, with proclamations of the latest version been worse and with the usual replies from people using competing products. I haven't seen any messages from microsoft saying codelens is broken or any problems with the rollout. They had it in public beta for over 8 months so you cant really say that they didn't have any QA.
Interesting... I don't have that issue on any of my dev machines. Our day to day is a 64 project solution (not counting test projects). The only hangs or slow downs I've ever encountered were on old projects that use WinForms when opening designers.
&gt; I haven't seen any messages from microsoft saying codelens is broken https://developercommunity.visualstudio.com/comments/598696/view.html
Can it support service fabric application? If yes, I may consider giving it a try
I haven't used VS in well over a year, and commit daily to several open-source projects. I use Rider on Mac exclusively.
FYI, with .net framework 4, GC gen 2 collections happen in the background: https://docs.microsoft.com/en-us/dotnet/standard/garbage-collection/fundamentals &gt; Starting with the .NET Framework 4, background garbage collection replaces concurrent garbage collection. One thing maybe you can try is changing the setting to use 3D graphics acceleration? It's in general I think and I've seen it cause huge lag on laptops with embedded gfx.
How does this even happen? Multiple Whitespaces? Curious, because I check my strings for such things.
Way to spawn a religious war, where the only people who show up are Microsoft developers. Because nobody else cares.
perfect explanation, thank you for taking the time to write all that :)
dotnet publish &amp;#x200B; Then a bat file to do donet AppName.dll
This really seems to be the wrong place for data sanitation.
I switched over to vs2019 with no issues. Everything is much faster. This is on a 180+ project solution. Have you tried turning off some extensions? Maybe there's the culprit. E.g. Resharper is no longer needed and it's slow as fuck anyway. Edit: my machine is pretty beefy though. 32mb ram, m.2 ssd, ryzen 2800 (if i remember correctly)
Unity is under mono twice. [.](https://Asp.Net)net framework also has razor pages, but it is only listed under .net core 3. WebAPI doesn't exist in .net core, it has been merged into MVC. gRPC is not a .net core only feature, it can be used with .net framework 4.5+ as well. As for the rest of it I haven't used those parts so I don't know.
Quote from MS reply https://developercommunity.visualstudio.com/comments/624451/view.html *GCManager can freeze VS due to Gen 2 collections but its not the one who allocating but one that cleans it up. so it is not the root cause*
Rename a property, class or project? Because they all work fine for me.
I also completely switched over to Rider, I like the intelligence of Resharper without the slowness. The ability to precisely control which projects get to run is incredibly useful. When dealing with projects with multiple executables that interact with each other, being able to stop just one without restarting the others is a godsend.
It says under investigation not confirm issue. I am on mobile though can't find the post of the microsoft employee
That's a comment on a blog, by tech support. Its referring to an issue in a edge situation with Live Code Analysis, specific to that issue on large solutions. With a match for an existing issue, that will be in the next release, but can be mitigated until then. It is not a statement from microsoft that codelens is broken for everyone.
Quote: *just make sure to turn off code lens since that known bug will overtake everything.*
Not an edge situation, any mid side project breaks it that is causes 100% cpu usage almost permanently.
Not straight away yet. Is there something hindering you from using a normal UWP app? .Net Core 3.0 *currently* supports WPF and WinForms as UI frameworks. There might be 3rd party UI frameworks as well. What you might be able to do *now* is using a technology called XAML Islands to host ‚ÄúUWP UI‚Äù parts in WPF / WinForms applications. Microsoft is working on several things in this field which were presented at Build 2019 however: - WinUI 3.0 will give ‚ÄúUWP UI‚Äù support to non-UWP apps (preview probably *later this year*). WinUI is a nuget package, see https://github.com/microsoft/microsoft-ui-xaml/blob/master/docs/roadmap.md for a roadmap with relevant background - .net 5 will merge the various flavors of .net (even further in the future), see https://devblogs.microsoft.com/dotnet/introducing-net-5/
And its iterations constantly introduce breaking changes. It will be a great framework but yes overall lack of maturity and stability make it a tough pick right now for production code.
&gt; I'm kind of suprised because the official .NET core containers are also based on Linux. That's not entirely correct. Microsoft [lets you choose](https://hub.docker.com/_/microsoft-dotnet-core-runtime/) between Windows Server, Windows Server 2019, Debian, Alpine, and Ubuntu.
No, this chart is not correct. There are numerous ways in which it shows the creator doesn't understand the relationship between .NET Framework, .NET Core and Mono. For example, APS.NET Core and ML.NET runs just fine on .NET Framework. There is a confusion between .NET editions and runtime compatibility, something that is orthogonal.
[removed]
We started the conversion with preview 4, and we have upgraded to preview 6. Each change isn't that bad and Microsoft has provided upgrade guides with each release. I wouldn't be too concerned in this area. &amp;#x200B; This would be the same if you were supporting an Angular app and needed to upgrade to each major Angular revision. Of course there will be breaking changes, and are certainly more frequently than a standard release cycle, but it's pretty easy to deal with. &amp;#x200B; As far as stability goes, can you site sources with the recent previews that make you believe it's unstable? My team hasn't come across any issues thus far and everything has been running consistently fast and smooth. &amp;#x200B; With it's fully supported release for production in about 2 months, I would say it's a pretty solid pick if you're in the dotnet stack and looking for an SPA. It competes quite well with other JS SPA frameworks and libraries. &amp;#x200B; One thing to note: There are not nearly as many packages as you would find on npm, however Microsoft has done a very good job at getting you what you need to get the job done, and where it lacks, there is always JS Interop until Microsoft finishes building its complete browser wrapper that will take care of everything JS can do currently.
Stability as in lack of breaking changes. I know that it‚Äôs in preview still and I‚Äôm cool with the breaking changes, but I don‚Äôt think you‚Äôd get that from Angular unless you went from Angular 1 to 2+. There‚Äôs also stuff like, you can‚Äôt have a debug and release directory, it‚Äôll throw an exception to the browser telling you to remove one of them. That‚Äôs what I‚Äôm talking about. I‚Äôve already built a simple app with it but even if I look up documentation or sample code on it now, it‚Äôs likely to be outdated. This is also just me fucking around in my spare time, not me working 40 hours a week paid to do it, so maybe you guys don‚Äôt see these things as big issues or you‚Äôve learned how to get around them already. It‚Äôs certainly cool tech and I don‚Äôt want you to feel like I‚Äôm criticizing your choice to use it in prod code, but for me it just isn‚Äôt mature enough yet IMO.
Did anyone else notice that the diagnostics window no longer shows outgoing web requests as events? I really miss that feature.
I understand where you're coming from. We haven't released this to everyone in our organization at this time, it's just a pilot group while we finish the conversion. We don't intend for a full deployment until around Sept. or Oct. which at that time should be in it's stable form. I appreciate your feedback, and I don't feel like your criticizing, I was actually just genuinely interested in the stability aspect of your comment as I thought it just might be something we haven't encountered. I 100% understand what you're talking about with looking up code snippets for understanding. My team has encountered that frequently, and I think we have just gotten in the habbit of reading Microsoft's github repo for aspnetcore and looking at their actual source to see how they do it. It can definitely be tedious at times, and trying to use their solution in your own project can be challenging. Thankfully that has been few and far between for us, however I can say without a doubt there has been several days where we were stuck on a single issue before we could move forward because of the lack of documentation. I can only assume it will keep getting better though :)
Seconded. No performance problems here.
Oh of course! I‚Äôm looking forward to the day when I don‚Äôt have to use the deep and vast forest that is the front-end ecosystem when I‚Äôm doing something simple, like creating a small SPA. With my knowledge of it now, if I had to recreate my app from scratch it would take me maybe a half hour. That‚Äôs awesome that you guys are early adopters, you‚Äôre already ahead of the curve.
whenever I attempt to rename a class VS throws following COMException: System.Runtime.InteropServices.COMException (0x80004005): Error HRESULT E_FAIL has been returned from a call to a COM component.&amp;#x000D;&amp;#x000A; at System.Runtime.InteropServices.Marshal.ThrowExceptionForHRInternal(Int32 errorCode, IntPtr errorInfo)&amp;#x000D;&amp;#x000A; at Microsoft.VisualStudio.LanguageServices.Implementation.ProjectSystem.InvisibleEditor..ctor(IServiceProvider serviceProvider, String filePath, IVsHierarchy hierarchyOpt, Boolean needsSave, Boolean needsUndoDisabled)&amp;#x000D;&amp;#x000A; at Microsoft.VisualStudio.LanguageServices.RoslynVisualStudioWorkspace.OpenInvisibleEditor(DocumentId documentId)&amp;#x000D;&amp;#x000A; at Microsoft.VisualStudio.LanguageServices.Implementation.ProjectSystem.VisualStudioWorkspaceImpl.ApplyTextDocumentChange(DocumentId documentId, SourceText newText)&amp;#x000D;&amp;#x000A; at Microsoft.VisualStudio.LanguageServices.Implementation.ProjectSystem.VisualStudioWorkspaceImpl.ApplyDocumentTextChanged(DocumentId documentId, SourceText newText)&amp;#x000D;&amp;#x000A; at Microsoft.CodeAnalysis.Workspace.ApplyChangedDocument(ProjectChanges projectChanges, DocumentId documentId)&amp;#x000D;&amp;#x000A; at Microsoft.CodeAnalysis.Workspace.ApplyProjectChanges(ProjectChanges projectChanges)&amp;#x000D;&amp;#x000A; at Microsoft.CodeAnalysis.Workspace.TryApplyChanges(Solution newSolution, IProgressTracker progressTracker)&amp;#x000D;&amp;#x000A; at Microsoft.VisualStudio.LanguageServices.Implementation.ProjectSystem.VisualStudioWorkspaceImpl.TryApplyChanges(Solution newSolution, IProgressTracker progressTracker)&amp;#x000D;&amp;#x000A; at Microsoft.CodeAnalysis.Workspace.TryApplyChanges(Solution newSolution)&amp;#x000D;&amp;#x000A; at Microsoft.CodeAnalysis.Editor.Implementation.InlineRename.InlineRenameSession.ApplyRename(Solution newSolution, IWaitContext waitContext)&amp;#x000D;&amp;#x000A; at Microsoft.CodeAnalysis.Editor.Implementation.InlineRename.InlineRenameSession.CommitCore(IWaitContext waitContext, Boolean previewChanges)&amp;#x000D;&amp;#x000A; at Microsoft.CodeAnalysis.Editor.Implementation.InlineRename.InlineRenameSession.&amp;lt;&amp;gt;c__DisplayClass73_0.&amp;lt;Commit&amp;gt;b__0(IWaitContext waitContext)&amp;#x000D;&amp;#x000A; at Microsoft.VisualStudio.LanguageServices.Implementation.Utilities.VisualStudioWaitIndicator.Wait(String title, String message, Boolean allowCancel, Boolean showProgress, Action`1 action)&amp;#x000D;&amp;#x000A; at Microsoft.CodeAnalysis.Editor.Implementation.InlineRename.InlineRenameSession.Commit(Boolean previewChanges)&amp;#x000D;&amp;#x000A; at Microsoft.CodeAnalysis.Editor.Implementation.InlineRename.RenameCommandHandler.ExecuteCommand(ReturnKeyCommandArgs args, CommandExecutionContext context)&amp;#x000D;&amp;#x000A; at Microsoft.VisualStudio.Commanding.CommandHandlerExtensions.ExecuteCommand[T](ICommandHandler commandHandler, T args, Action nextCommandHandler, CommandExecutionContext executionContext)&amp;#x000D;&amp;#x000A; at Microsoft.VisualStudio.UI.Text.Commanding.Implementation.EditorCommandHandlerService.&amp;lt;&amp;gt;c__DisplayClass13_1`1.&amp;lt;Execute&amp;gt;b__1()&amp;#x000D;&amp;#x000A; at Microsoft.VisualStudio.Text.Utilities.GuardedOperations.CallExtensionPoint(Object errorSource, Action call, Predicate`1 exceptionFilter)&amp;#x000D;&amp;#x000A; --- End of stack trace
I've seen plenty worse in Xcode than failure to rename. Remember the good ole - "SourceKit has stopped working". Those were horrid times.
Have y'all figured out a middleware story with blazor? I've seen a lot of demos, played with it myself, but I don't understand how to use it with middleware.
I use vs1019 with R# and performance is awesome.
To add, the client-side Blazor release isn't officially coming till next year with .Net 5. There is a preview though, and the transition should be simple from server to client (I'm not sure if it's supposed to be entirely seamless or not?).
you should tell to jetbrain how you did, they will be very interested. https://resharper-support.jetbrains.com/hc/en-us/articles/206546919-Visual-Studio-with-ReSharper-is-slow
I was under the impression that APS.NET Core was dropping support for .NET Framework
LOL I used to make a lot of money from people like you. InfoQ paid me to watch and summarize MS Build videos so you could get the info you need in 5 minutes instead of 60.
Thank you for the slide deck, disagree that there is something called "multitasking."
Please, if I am going to spend an hour watching a video it will be something with known ROI like a course on Pluralsight, not some random talk that may or may not be good, with topics that may or may not be relevant to me.
It was exactly the same when going from 2015 to 2017. I remember how slow and buggy 2017 was at the beginnig, compared to the efficient machine it has become. Visual studio is a big complex thing. Either you want to try the new features and you have to be prepared for bugs and severe performance issues. Or you wait for 6-12 months waiting for MS to tackle the pb and enjoy a (not so new anymore) excellent ide.
I work on a massive solution with vs2019 and code lense works fine for me. I do have to disable r# though as it destroys performance to the point it's no longer usable.
It's gotten worse and worse to me. I disabled Resharper entirely in VS2019, and VS is now snappier than ever.
eh? simply install the "dotnet-sdk" package with pacman or Discover or w/ever
VS2019 + R# and works great.
and if that doesn‚Äôt do what you want, try with Flatpak or even Snap.
Rider is the only choice for me. Visual Studio is just a joke.
I have noticed that vs2019 debugger optimizes out many variables so I can't check them, even if optimisation is turned off in project file. Never had this issue in vs2017 so I still use it sometimes for this one reason
Ooh, thanks for the share. I just filed a ticket against the repo there a couple days ago and was surprised when they immediately addressed it. (exposing some of the ssl configs for the schema registry) Glad to see they are putting so much effort into it!
Podcast listeners everywhere disagree. (Or, we don't define multitasking the same way ?) If one listens to something potentially educational while browsing reddit or driving or some other mundane task, they haven't really dedicated time to that listening, have they ? On the other hand, reading an article while browsing reddit or driving or doing dishes etc isn't possible/advisable. Preference is more of a factor than possible/impossible. Talks by David Fowler &amp; Damian Edwards are typically **very** dense, and would make for a hefty article. This one in particular is great IMO.
My performance is decent. However, on several occasions I have to restart visual studio because typing slows down to a crawl. I will type a letter and it will take 1-2 seconds for it to appear on the screen, super annoying and never had this issues in 2017. However, it is a rare occurrence and I just deal with it.
Go 32 gb ram or go home.
rebuilding takes around 15-30s on a m.2 ssd in debug mode. Release mode takes around 2mins.
Is "Blazor Server" also Razor?
On the beta version I had real performance issues, my pc would freeze for up to 5 minutes. I'm now using the full release with no performance issues. Maybe try updating?
It used to be known as Razor Components a few releases ago, however they changed it purely to Blazor to avoid confusion since Razor is simply the templating language that can be used with Blazor or MVC.
Hah well that's over at least. Compile times gotten tolerable. At least it's a vertically integrated vendor stack, that softens the pain.
Package without any unit tests ü§î Not a package I would use.
So is each project a single class?
Didn't once upon a time intelli-sense worked in the immediate window? Seems that got dropped somewhere along the way.
average amount of classes per project is around 40.
Did you read the link you posted? It contradicts your first post: "code lens" and "simplify typename" issue cause 100% CPU making machine to slow down, but it doesnt' block UI thread. so that can't be the reason. none of work happing on OOP can cause GC issue since allocations is happening in different process and that process has its own GC.‚Äù
Sorry for asking but, any podcast is beginner friendly?
Thanks. I did search Google before posting this, but somehow I could not find the answer. I think the page is saying that UWP UI can be used with .NET Core 3, which is good.
&gt; "hindering you from using a normal UWP app?" There have been so many new things, so it is confusing. As I have read, WinForms/WPF are sort of a legacy (maintenance mode) and UWP is the future, and also it seemed that everyone is talking about .NET Core, so I wondered what if I use the UWP UI + .NET Core instead of just regular UWP, for creating a new application.
Yes I understand. Things are moving fast indeed. For the moment I would recommend the following (and might of course change with new developments): I would stick to ‚Äúregular UWP‚Äù, unless you need something that it does not support. The Windows Template Studio is a great way to get started with it. For non-UI apps (like CLI programs or backend services) or modernization of legacy apps I would recommend .Net Core. For libraries I would recommend .Net Standard, which can be referenced from both .Net Core and UWP. If you start with UWP now, I would recommend to use the WinUI library I mentioned in any case since it helps to make controls available on older Windows 10 versions and it makes your code future proof because you‚Äôll then use the correct namespaces that Microsoft is moving towards.
‚Ä¶And you were expecting‚Ä¶ what? Unless you are using a boilerplate template to pre-populate a crapload of stuff, a project is empty by default. That means you‚Äôll have to build everything yourself, from bringing in things like Bootstrap to constructing your login Auth. Not trying to be an ass, but what were you really expecting? The IDE has no clue what you want, so unless you explicitly specify a boilerplate as a template to run with, it just gives you the bare essentials.
I guess I should have eleborated; by empty project, I mean a completely blank project with nothing inside, as far as Visual Studio is concerned. This happens even if I choose a template like 'Web Application (MVC)'. [Here is a picture to kinda show what my problem is](https://drive.google.com/open?id=16FZJIf4m9VIVJLr4JJ51mrsabwj0INgR)
I have always disabled Code Lens since VS 2015. It is always slow and I don't even see the point of that feature. That said, I have seen much better performance in VS 2019 compare to VS 2017. And VS 2017 was already way faster than VS 2015. So I'm not sure what your current issue is. I have a big solution with 450+ projects and more than 1.5 million LoC. I even have Resharper enabled. There a few things that you need to do to get better performance: * use an SSD * **disable** some debugging features that are known to slow down execution: * Enable UI Debugging Tools for XAML * Enable Diagnostic Tools while debugging * Enable Edit and Continue * if you use Resharper * Go to Environment/Performance Guide and fix any issues * Go to Products &amp; features and disable stuff you don't need * But always keep Debugger integration or you will have serious performance issues when debugging * Use Resharper Build * Configure the cache to be on a custom folder that is on your SSD * At work, the user profile is synchronized on the network and by default Resharper cache was going there O_o
Did that fix the issue?
Uh... yeah. Something isn‚Äôt right. Are you sure you are creating your project properly? Give us the steps you use to arrive at a new project, starting with clicking on ‚ÄúNew Project‚Äù in the splash screen.
Probably not neccessary. Check the edit to my original post; updating VS fixed it for me.
Winforms, WPF, and UWP are all being brought to .net core. I'm not sure if they already are on .net core or if they are in some type of pre-release situation or what. However, they will not be crossplatform, just windows only. In addition winforms and WPF are also currently being open sourced (they are open sourcing it piece by piece to github). They are open sourcing it because they don't have plans to continue adding features to either WPF or Winforms. If you're trying to decide on a .net platform for a desktop app then I would definitely choose either WPF or UWP. When you think UWP basically think windows store app. The biggest use case for UWP was that you could build one app and build it for all the windows platforms: windows 10, windows phone, xbox, hololens, etc. However since windows phone was axed the support for UWP has been meh imo. The only way to install a UWP app is either through the windows store or side-loading. WPF apps build to an executable that you can just run. To run a UWP app you need to "deploy" it first. UWP out of the box comes with some animations and pretty things like that, and requires a little less styling. It will also surprise you with things that don't come out of the box like built in validation. You can get WPF to look and behave like UWP ones for the most part but it requires more styling work up front. I havn't yet encountered anything I could do in UWP that I couldn't do in WPF. By contrast it takes a little more work to get UWP app to function like a traditional desktop app as UWP is focused on making one app that can run on touchscreen or a desktop. Hope this helps
Not going to lie.. I thought I understood interfaces until I read this article. Dropping the I actually did give me a better understanding.
Scott Hannon commented this in the article ‚ÄúIt also makes sense that if we're depending on an abstraction, we don't need to know whether it's a class or an interface. If we need to know that when we use it, or think we do, then we're not quite getting the concept.‚Äù
We use resharper at work and my VS there takes nearly a minute to start with a much more powerful computer than my home machine. Home machine is seconds.
.NET Core Podcast had an early "history of .NET" episode that I would think is really great for beginners. Most of the episodes are also high-level enough that I think that they would be good for just about any. .NET Bytes is also news focused, so I'd think that is good for beginners as well.
I thought it was Progmatic Pragrammer
Oh man, introduction of 1.0 was such a hassle at first but there are some real performance gains I am seeing right now. Great job people at Confluent!
UWP apps don't run on .NET Core or Framework. They use a flavor of Core in debug mode, and are AOT compiled using .NET Native for release builds.
yes, WPF works fine with Core, I tried. But Windows only :)
&gt;I'm not sure if they already are on .net core or if they are in some type of pre-release situation or what WPF works.
The error list is also completely broken, showing old error that aren't errors. Confirmed by another user https://developercommunity.visualstudio.com/comments/626602/view.html For now, the only option is to go back to VS 2017.
Linkers have done this classically for decades, long before webpack. Don't know why it's called "tree shaking" all of a sudden.
yea.. not really, atleast with preview6. embedded resources (resx) for icons, media and other stuff does not work yet. (didn't when i tested around last week)
ah, OK, I tested just simple form with drawing on it
Parmgagic Poorgamer
Framework is dead, there will never be another major release and there are already features that core has that Framework simply doesn't. .NET 5 is going to be the next major release of core. It will bring Framework, Mono, and Core together into one product, but it will be Core and not Framework. ASP.NET core doesn't run on framework just fine at all, and while ML.NET does at the moment, that's not going to continue. Framework and Runtime compatibility are not orthogonal.
UWP is a sandboxed framework for Windows 10 with restricted access to system resources like Android and iOS apps. It uses the same XAML markup that WPF developers are familiar with. Microsoft introduced XAML Island which brings some of UWP features to WPF. &gt; I am not sure Microsoft will continue to support WinForms/WPF for the next decade or will replace them with UWP. That was the plan. To focus on UWP and Windows 10 S, but it failed and also Microsoft killed its mobile OS. So now Microsoft wants to make its Store available for legacy Win32 apps and unifies all these frameworks (.NET Framework, .NET Core, UWP, Mono) to .NET 5. We have to wait and see. So now if you go with UWP your app only runs on Windows 10 with restricted authority and you can put it on Microsoft Store. But if you go with .NET Framework or .NET Core 3 your app runs on Windows 7 and higher with full access to system resources, and you can use XAML Island for some of new UWP features.
yup.
thanks. seems to be the only solution other than Rider.
Layered architecture for me always went well for a while at the beginning of a project. But, the bigger the project got it ALWAYS ended up being a compromise here, a compromise there, in order to get the features working without treading on too much of the code you've already written. Before you know it, your project is now a big ball of mud which is a complete bitch to maintain or evolve. Fuck that. Moving over to feature folders and CQ(R)S was a revelation to me and I'm disappointed it's not more well know/implemented because I can tell you people will have to step over my cold dead body before I go back to classic layered architecture.
My two solutions both have over 75 projects each. I'm definitely waiting to upgrade.
I have upwards of 75 projects and release mode build takes a loooot longer.
Not really, SSD is vital though especially with Resharper
To be compliant with European law by default and so they don't have liability for it. I imagine you can remove that somehow.
This isn‚Äôt right, the basic login cookie for Identity has (or should have) `IsRequired` set to true, which means it is saved regardless of whether the user has accepted the cookie policy or not. It‚Äôs not the default value, but the boilerplate contains the code that sets it. Make sure you didn‚Äôt remove it by accident.
I couldn't find the IsRequired You were talking about in the code or online while searching, I found if I just turned the CheckConsentNeeded property to false (was set to true by default) it fixed the issue by getting rid of the cookies pop up! Thanks!
Ahh is it a bad idea to get rid of it since it's European law (even thought i'm not based in Europe)?
If you have any end users in Europe it still applies.
http://docs.identityserver.io/
Look into Azure B2C, that's what we are using to support this exact scenario. Our users can login using their Facebook or Microsoft accounts or by creating a new account specifically for our services.
Functional cookies are always allowed!
I can't speak to exactly how to architect this in workflow foundation, but in a general sense: You've got three separate processes going on here: process 1 does steps 1 and 2 (persist id and 'incomplete' status to a database). Process 2 gets incomplete jobs from the db does step 3, creating a new worker process to handle each incomplete job callback. When the callback completes, a message goes back to process 2 to update the id to complete in the db. Then, in the event of a power outage, just ensure that the first thing process 2 does is gather all incomplete jobs from the db and start the callbacks again. Also either regularly have process 2 poll the db or better yet have it receive messages from process 1 that there is a new incomplete job in the db.
I'm looking at a similar situation at work and the best I've come up with is a locked down machine with the key stored as an environment variable (for portability). However, at the last place I worked, a coworker mentioned the idea of keeping the key on an encrypted thumb drive and setting up a mechanism for the system to read it on startup. That way, the key is only out in the open on system startup, as you can pull the thumb drive once the system is spun up. There are limitations to that approach as well but it is an option(although he may have been wrong about how good of an idea it actually was, idk).
Some kind of vault. Azure has one, hashicorp has another common one that is used.
One thing I fail to understand is how the key store is helping. Wouldn't it require you to store the credentials for the key store similarly to storing the key? Or would you use integrated aithentication so that OS handles fetching the key?
If you are hosting on windows, the windows credential manager api is fine: https://stackoverflow.com/questions/19410186/c-sharp-using-credwrite-to-access-c I think that code should still work in .net core... I wonder why there are no .net core or .net standard nuget packages that I can find that interact with this win32 api.
Great to see more Git libraries in .NET. Thanks!
Sounds cool. Why not even a single test, thou? I'm going to give my repo in your tool's complete control: it would be really nice to know the tool has been thoroughly tested, wouldn't it?
I enjoyed reading this. Very informative. &gt;Next time we'll run through some tools which helped us identify the remaining bottlenecks in our code. Is part 3 not done yet?
The best way is to set it as an environment variable and inject it with CI/CD. I've deployed several .NET Core APIs, both microservices and large scale, and this has been the way we've done it.
No it's not, I just finished part 2 last night. Will probably be a week or so with my current schedule.
If your user is from Europe, you shouldn't be setting *any* cookies until they have accepted your cookie policy.
You can probably speed that up at least 45% by neglecting your other duties.
Interesting implementation but I have to agree with u/jeenajeena. This is something that should be making heavy use of unit tests given the nature of the tool and what it is touching.
Ha! That's how I got this one done :P
There's multiple libraries choice for commandline parsing, why write your own?
Blah, figured it out. Had to include the [Microsoft.EntityFrameworkCore.Tools](https://Microsoft.EntityFrameworkCore.Tools) dependency and now it works.
Cheers. I've implemented your ConcurrentDictionary idea. I test it latter, but that may have been a fairly critical over-site on my behalf. I also added some tests for model inheritance. I'm not sure the inheritance behavior is ideal, but now I know. Thanks for taking the time to make suggestions. I appreciate it. &amp;#x200B; ([https://github.com/NathanLBCooper/aspnet-core-model-binding/pull/1](https://github.com/NathanLBCooper/aspnet-core-model-binding/pull/1))
Agree. Sounds cool. I'd expect integration tests as well. The OP said they conducted tests already, but I assume they meant they didn't automate them.
Yeah I had some tests, but after starting with the pack files I basically had to throw them away. My integration tests run against a private repository, so I didn't publish them yet, but will when I changed it so that they are reproducible
The motivation was a repository with about 10 years of history which had some trees with duplicates (something that really is not supposed to happen). This started to be a problem with our hosting environment, so it had to be fixed. Turns out it is not easy to fix this and there is no tooling available for this kind of issue. After that the rest of the features were easy, and I wanted to see how fast it can get, compared to other tools. Turns out very fast, still getting faster every day
So, about command line parsing?
Ah sorry, about that üòÇ I added the most popular one a few revisions earlier but then noticed in the profiler that it was significantly slowing down the startup, which made about 20% of the time for removing empty commits (which only takes like two seconds of you don't have any, but still). Then it did not work the way I expected it to, so it really took less time to just throw the library out and do it myself compared to understanding how the lib works and why it seems so slow (obviously there was some reflection involved)
Sorry, it is \`IsEssential\`. &amp;#x200B; If explicitly adding cookie-based authentication: \`\`\` services.AddAuthentication(CookieAuthenticationDefaults.AuthenticationScheme) .AddCookie(options =&gt; options.Cookie.IsEssential = true); \`\`\`\`
Thanks I'll give that a shot!
Following up here, PKCE is actually an entire new flow that is an upgrade to "authorization code" flow and uses a dynamically generated 1-time secret. This now works for both frontend JS and backend server-side with the same security and is what everything will eventually move to. You can use PKCE authorization code flow but you need a JS framework or library that supports it. IdentityServer has support for this and a JS library. Here's a video just released this week that explains everything: [https://www.youtube.com/watch?v=zOy3-\_Cdhn4](https://www.youtube.com/watch?v=zOy3-_Cdhn4)
Easiest and most efficient would probably be to cache the list in a SQL Server table, with the location stored in a SqlGeography column. Then you could just query that, ordering by \`STDistance\` from the user's location.
Simplest option is to just use a file (like appsettings.json) but have it encrypted first. All the major clouds have KMS (key management service) that lets you encrypt and decrypt content easily with an API call. We store our encrypted file in a cloud storage bucket (with its own access settings for an extra layer of security) but you can also just keep it in source control since it can only be read after the decryption call. We have an internal library to do this with GCP storage and KMS, let me know if you're interested and I can opensource it later. Here's the GCP guide on this: [https://cloud.google.com/kms/docs/secret-management](https://cloud.google.com/kms/docs/secret-management)
There is a formula called the haversine formula that you can use that will tell you the distance between two coordinates. There are many implementations of this formula. I‚Äôve used a few different ones in C# as well as JavaScript and even even the latest PowerShell has a built in one The google bot shows this as a first result although I can‚Äôt vouch for it https://megocode3.wordpress.com/2008/02/05/haversine-formula-in-c/
k-d trees are very fast for this type of thing, I've used them for 3D data point matching. All of my data is stored locally in an XML file so this might not be the best approach depending on your specific circumstances. https://github.com/codeandcats/KdTree
That's only for server-side Blazor, not client-side which would run completely within the browser.
What in the [ASP.NET](https://ASP.NET) stack has MS ever abandoned? No other company matches Microsoft in terms of backwards compatibility across their products.
Depends on your dev ops. Azure or AWS, even if you are using appsettings.json, you can replace the test key or blank key during a deploy. Most dev ops programs have this
I think what you're looking for here is OAuth. There's some good docs on Google you can find that quickly get you up to speed with it
In my experience of MS SQL Server the performance varies significantly from version to version, 2008 was the first version with spatial functions and its not great, but it gets better with the newer versions, so try a few different things and see which one preforms best. As several other people have mentioned you can create a geography column and use STDistance, possibly with a spatial index, and this would be proper, but it may not be quickest and if your looking to display these on a Web page quick is important. You may also want to consider trying it with straight math, take the coordinates (assuming that's what the API returns) and calculate the distance with an in line function, there are examples for this on most Coordinate systems or there some where, it's unlikely to be quicker than the built in function, but it may be quicker than loading the data, converting it to geography and then using STDistance. Most programming is the art of the lazy, so it's worth considering getting someone else to do it, you could, for example make a second API call to Google's distance matrix and have that do the heavy lifting. Finally what ever method you do is worth remembering that the number of transactions should be a low a possible, so if there's any data you can use to exclude stores before you start checking the distance that'd be a good way to go, maybe it's a max range or the county, country or some other Meta data, be aware of the edge cases, but you can probably forget about stores in Scotland if your query originates in Cornwall. Read Mexico / Canada if your not from my part of the planet. Just one more thing, one question to ask, is SQL the right tool for the job? If your updating your store list once a month then it probably is, but if your calling the store API from a button push on your website, posting the data back to the database, doing your comparisons and posting the results back to you website you may want to consider doing the lot client side, or via a third party api Hope this helps, I've done a little bit of work fairly similar to this over the years but it's quite hard to give a good answer without knowing the use case. Good luck
Yes, I was explained that for this flow to work you're expected to expose your identification server (or at least it's login page), which is what I didn't get. However I've been put on a different project for now but I'll probably try to implement that on personal stuff and I hope I'll be able to get it to work :)
This link might help you. [https://docs.microsoft.com/en-us/sql/t-sql/spatial-geography/stdistance-geography-data-type?view=sql-server-2017](https://docs.microsoft.com/en-us/sql/t-sql/spatial-geography/stdistance-geography-data-type?view=sql-server-2017) If you like i can provide you mi MSSQL function
-At this time, I would not bet on Java for anything -the meaning of ‚ÄùEnterprise application‚Äù is different for each person and each context. (for me today it means an overengineered smoking and spluttering behemoth monstrosity) -While .net core is a separate implementation of .net, any skills and most investments are usable on other implementations as well (like .net Framework), which makes it attractive -.net core is cross platform which is nice -.net core is lacking in the desktop UI department but that will get remedied at least for Windows in the near future -even enterprise applications should be comprised of separate parts focused on one thing and .net core can do that easily -if the UI is web-based, you‚Äôre good to go with .net core So IMO .net core has either some minor disadvantages for enterprise applications or none at all, depending on your usecase, but looking at what Microsoft is doing, it is the way to go for now.
most of the things are available as libraries. also mvc development is faster than spring or java based frameworks. also the amount of boiler plate code written in java is too much. c#sharp has so many features that you end up writting less code eventually. for enterprise or lob apps .net is the best. &amp;#x200B; also if you are paying for ui frameworks they reduce the time drastically.
I believe there is a huge overreaction to this. For example i recall that you don't need to inform about cookies where they serve a necessary function, such as keeping you logged in. Though I don't know whether this cookie does more than that.
I'm guessing this is used for a feature similar to "find my nearest ATM"? You don't strictly need to get exactly the 10 closest match; and in some cases, the nearest match may include locations that are too far to be practical. It helps to bound the return from your API to fit inside a box around your search center. Use the sum of squares of the delta-X and delta-Y to get distnace squared, and then get a sorted order from closest to farthest. Just be aware that these are closest as the crow flies. Sometimes, that's not the closest effort. (If I have to drive a few miles to take a toll bridge and double back on the other shore to a point 2,000 feet away, I'm better off going to the location on my shore a mile away.)
I'm kind of a newbie when it comes to web dev but I'm in the process of converting existing applications in PHP to .NET Core in an enterprise environment and I've just about finished the first one. EF seems to speed up the process significantly as all our our data (and there's a lot of it) is using MS SQL. Oddly the stuff I thought would be the easiest are taking the most time and vice versa but so far, it's been relatively smooth sailing.
In addition to Basson, the users can try Alvas Audio library. The library has a rich set of components that allow transfer of files to another format. [**Alvas Audio library**](https://www.filerepairtools.com/alavas-audio-library.html) records and play compressed/ uncompressed audios. Mixing of sounds, split and merge two audio files, change the speed of data, convert VOX to MP3 stream, WAV to mp3 and it is compatible with .NET 2.0 to above. So, try out the [Alvas.Audio](https://Alvas.Audio) library and include in your project to build an awesome full control media player.
Why you don't like Java?
AFAIK dotnetcore is compatible with standard dotnet which allows you to use any library originally developped for dotnet. You can also call nodejs libraries from dotnet or a binary command that would to the trick (a tool like IECapt)
The limitations will totally depend on what you need to do. Might be.Net core isn't the best language for developing cross-platform UI applications - even then it can be solved with Electron.Net + Blazor. In terms of web development, it‚Äôs a quite good cross-platform solution with a growing community and good infrastructure.
I don't think .net core has limits compare to other platforms in ' **enterprise applications** ', and if you find a library to solve a special problem, you can call or embed other languages in .net core, for example, you can use JavascriptService to call a node.js project.
It‚Äôs not. They‚Äôre different frameworks. That‚Äôs why .NET Standard came to be. But soon there will be only one.
We are not doing MVC apps anymore, React frontend + PHP/NodeJS or .NET backend is usually what we do nowadays.
There an SDK license issue, from my experiences Java heavy and slower compared to dotnet and the dotnet core is way faster and smaller than dotnet as it is very close to Nodejs. If you are building new web based solutions then I would recommend dotnet core. I have ditched Java 10 years ago after 5 years of enterprise development in favor of PHP and dotnet, depending on hosting options windows vs Linux. Now I maintain PHP but develop in dotnet core. Golang is also an interesting option for micro services.
Oracle
.NET Core is still fairly new, it really got good for web apps / microservices in version 2.1. And it will hopefully get good for Desktop apps in version 3.0. it's making good, steady progress. It is the future of .NET. The people in your company who use .NET should be looking at it already (and if not, why not?) It's a fairly easy transition, if you know .NET, you can quickly adjust to .NET Core. Because it's new but fast-moving, if the required packages aren't there yet, they might be soon, as existing packages are migrated from .NET to .NET core.
I'm surprised cause I used this library a long time from dotnetcore [https://www.nuget.org/packages/SimpleCrypto](https://www.nuget.org/packages/SimpleCrypto) &amp;#x200B; And it was last published in 2013 so way before dotnet standard and it worked like a charm in my dotnet core apps. The only thing was a warning during compilation notifying me I was using some dotnet code and that I can eventually have problems with it.
Our .NET team will switch to Core eventually but we are maintaining a lot of legacy .NET apps / code which cannot be rewritten at this point but new services and apps will be written with Core when the desktop "part" of Core is stable because our .NET team develops desktop apps for clients as well so that is pretty important.
so what are you expecting to find in .net that you see in java community. rest api's are quick and consistent. support of various db's also included in core. also dapper can help.
Something like the example I wrote about in my original post. Java and NodeJS both have considerably more packages which can be both a good and a bad thing but at least there are options for pretty much everything if you need something. I am not saying I want to use a package for everything instead of writing it myself, not by any means, I would write everything myself if I could but tight deadlines usually do not allow us to do that and reinventing the wheel isn't a good idea either so if there is something that already works and is maintained properly then I would pick a package instead of writing it myself.
You are fairly correct: .NET full framework _can be_ compatible with Net Standard 2. If you only use supported theings. From the release notes: &gt; Reference .NET Framework libraries from .NET Standard &gt; You can now reference .NET Framework libraries from .NET Standard libraries using Visual Studio 2017 15.3. This feature helps you migrate .NET Framework code to .NET Standard or .NET Core over time (start with binaries and then move to source). It is also useful in the case that the source code is no longer accessible or is lost for a .NET Framework library, enabling it to be still be used in new scenarios. &gt; We expect that this feature will be used most commonly from .NET Standard libraries. It also works for .NET Core apps and libraries. They can depend on .NET Framework libraries, too. The supported scenario is referencing a .NET Framework library that happens to only use types within the .NET Standard API set. Also, it is only supported for libraries that target .NET Framework 4.6.1 or earlier (even .NET Framework 1.0 is fine). If the .NET Framework library you reference relies on WPF, the library will not work (or at least not in all cases). You can use libraries that depend on additional APIs,but not for the codepaths you use. In that case, you will need to invest singificantly in testing. https://devblogs.microsoft.com/dotnet/announcing-net-core-2-0/
For distance searches that don't need accuracy of less than say 1000 meters and that need to be as fast as possible, particularly if the list of locations to search doesn't change often, I use GeoHash with some precomputed details on the locations to search. Beats the pants off geo features built into RDBMS's or Redis.
&gt; we need to create a preview image for every document that gets uploaded to our document library (Word, Excel, TXT, Images, CSV, PDF etc.) which is a trivial ask I think That is not trivial at all.
prob performance
Their licensing, security issues in the past and how they were handled, bundling malware with downloads. Other stuff as well but I don‚Äôt want to start ranting.
There' a massive point for .net core that you need to think about if you come from node: you can use node in dotnet core. This means you can re-use all your existing stuff. That seems important to me
Java (the language) is okay, but C# is basically Java-done-right. Java (the ecosystem) is mostly big heavyweight overengineered monstrosities. .NET Core feels the opposite in this regard, lots of small pieces that do one thing and do it well. Java (the SDK) is mired in legal issues because of Oracle. .NET is mostly open source and not a legal quagmire now.
To provide an example of what /u/crazy4l is talking about (whether or not its a good idea), the SPA templates for new projects for Angular and React both use a middleware that can call out to nodejs to support server side rendering of pages where Angular or React are used as the front end framework.
I would not expect to find a ready to use library for any platform that can do this reliably, unless it is a commercial library. Maybe on desktop where the OS can provide a thumbnail, but on the web world this is a really difficult task due to versioning of documents and differences in implementations from vendors.
then .net is best. i don't think i have reinvented the wheel. easiest way to compare is check if all you requirments in an existing project can be completed in .net ecosystem. linq is also your friend, ado.net is equally. check this for more info https://github.com/thangchung/awesome-dotnet-core
killer feature for me in .net are generics. the java implementation is horrendous. and then there is LINQ which java has a terrible answer with streams.
I‚Äôve worked in both Java and .NET shops. The platforms can both do whatever you need them to for the vast, vast majority of use cases you‚Äôre ever going to really care about. I, personally would always choose C# for a solo project, between those two. But, I‚Äôd rather work with advanced Java devs over middling C# devs (even better is advanced C# devs, though). Why? C# has a more ‚Äúmodern‚Äù syntax and more advanced language features. It‚Äôs a subtle thing, in some cases, but the simile I‚Äôve used is that it‚Äôs like if I want to build a table, Java makes me go cut down the tree while C# gives me the boards. That means that Java developers are often forced to understand things that a C# developer can safely ignore, but the C# is faster to work with. One example that might be relevant to building REST services is that Java doesn‚Äôt have properties. Instead, it uses beans to serialize. That means fully typing out the ‚Äúpublic string getThing() { return thing;} public void setThing(string value) {thing = value;} private String thing = new String();‚Äù which ends up being a lot of cruft to read through for what is, essentially, a simple DTO. C#, on the other hand, does the same thing with ‚Äúpublic string Thing { get; set; }‚Äù. Done. I think the latest version shortens that even further. Regardless, it‚Äôs really easy to read and understand the model objects for your contracts. C# also has much, much more mature functional programming capabilities. It could almost be used for straight-up FP, but that wouldn‚Äôt be my recommendation. Instead, I like that I can use OOP concepts as the backbone of my app, but pull in FP where it makes sense ‚Äî which is fairly common, actually. Plus, .NET Core actually runs significantly faster than Java. Overall, C# has continued to modernize much better than Java. C# has managed to ‚Äúfeel‚Äù more like a Node or similarly newer language than Java. It‚Äôll be more comfortable to a progressive shop than Java. On the other hand, Java has a staggering amount of legacy code and ecosystem (Jenkins is written in Java, for example, IIRC), so there‚Äôs a case for it being the ‚Äúmost common denominator‚Äù for hiring. I‚Äôm not particularly sympathetic to that, but it‚Äôs there. There‚Äôs an old adage about IBM that I think applies well to Java, in the current day (substitutions made): No one was every fired for choosing Java (but they should have been).
Protip: if you're trying to describe your software, describe what it does, in addition to listing other software it's like.
One of our dept's uses Java and the code was all in XML config files. I'd burn that crap to the ground. I think it was all Spring, but I've only every done a bit of Java sans frameworks.
What about Oracle? I mean, I also hate them, but using OpenJDK with Spring Boot has nothing to do with them
Google docs viewer is pretty much the only way to do this reliably. However, that uploads the file to google‚Äôs servers and that might not be in the organizations best interest.
If you are willing to look at commercial solutions, DevExpress have a DocumentServer Library that can be used to "print" a lot of formats to images. I recently used it to create a Document preview service.
Successful enterprise applications are more about architecture and design than specifics of languages and frameworks . You might use several different languages in parts. I've deployed Java, .Net Core and Standard, Javascript, and Go this year, though a vast majority of what my team writes is C#. If there's any downfall, C# isn't necessarily the fastest or most memory efficient language (at least in the way it is used most of the time), but that usually doesn't matter for enterprise applications when you use horizontal scaling. Productivity of your developers is far more profitable for the business as a whole than trying to roll everything from scratch in C/C++ to save pennies on compute.
There's lots of libraries and they don't need to be perfect as no one going to complaint about slightly wrong render in a thumbnail.
Have a look at orchard core on GitHub. It's a pretty awesome framework / CMS
What‚Äôs the condition on the client that hides the field? Use that same condition on the server. Is it a checkbox? Post the value to the server. Is it based on the value of a drop down? Check that value on the server.
Trust oracle to play in your pool, eventually they are going to pee in it so much the whole thing is yellow. I would never trust Oracle. Source: Engineer that has been in companies acquired not once but twice by Oracle.
No. Neither syntax appears to work. I'm going to create a new, 2.2 project and follow the instructions to create the `secrets.json` file.
Pure Spring is shit (that's the ine with XML), but Spring Boot is good. I use Spring Boot on my job and I've done some hobby projects with .NET Core, they are very similar.
The biggest weakness I've seen so far is in 3rd-party support. As an example, my employer uses an oracle database. Oracle has an entity framework driver for .net framework but is 6 months beyond when they said they'd be releasing an EF core driver. So we're stuck with a managed ODP.NET driver until they sort that out. That being said, oracle has no reason to want to support their competitor's product so I can understand them dragging their feet.
They're different frameworks, yes, and .net core is the only part that's cross-platform. But if you're targeting Windows, you can build ASP.NET Core applications on top of the full framework runtime (you just change the project runtime form netcore2.2 to dotnet472). We have a production application running on 200+ nodes that's using Kestrel as the webserver (which is part of asp.net core 2.2) but executing on top of dotnet 472, because it interacts with Point of Sale hardware that only has a full framework .net 4.5 DLL for the SDK. Note that this is not a .net standard 2.0 DLL so the reason this works is because it's executing with full dotnet 472 interop.
Yes, ASP.NET Core is a completely separate thing to .NET Core. It runs on both.
My point was that the .net core runtime is not what most people are referring to when they're talking about .net core. They're talking about new ASP.NET, new EF, the new project system, Kestrel, etc. Things that are new and improved. All of this can execute on the full framework runtime too and then you also get access to windows-specific stuff. A lot of people think that if their application has a dependency (for example on MSMQ) that is windows-only, they can't migrate that to .net core. But you can, you just have to execute it on top of the full framework runtime instead of the .net core runtime.
My favorite answer : it depends. Yet, dotnet framework is pretty mature than core but eventually its on Windows platform. If it's about just a service for document thumbnails dotnet core would be adequate. Unles you aren't recreate the document management service, the problem turns into a thumbnail service. A simple conversion service in dotnet core would satisfy the requirements. But going on full dotnet core is not so trivial, like any rewrite project it has so many downsides. It's mostly about a risk assessment now.
I don't know if this a viable alternative for OP but if the documents were hosted in SharePoint...
Re: document preview, it's definitely not an easy task unless you have a pretty small set of file types to handle. My last job was on a product dedicated to browser-based document review and we used Aspose (https://products.aspose.com/total/net). I never worked with it directly so I can't give you too much insight beyond the link. It's not free so if you don't have a budget for tools I guess that's out the window, though in my opinion you'll spend 10x rolling your own
Can confirm. Was working on exactly this recently. Ended up using imagemagick, but only was supporting pdf and images. Imagemagick uses ghostscript to work with pdfs. I don't remember the steps required to expand support to other document types, never got to that point. But even for what I put together, took me a good bit of time to implement.
Re: document preview, it's definitely not an easy task unless you have a pretty small set of file types to handle. My last job was on a product dedicated to browser-based document review and we used Aspose (https://products.aspose.com/total/net). I never worked with it directly so I can't give too much insight beyond the link. It's not free so if you don't have a budget for tools I guess that's out the window, though in my opinion you'll spend 10x rolling your own
Generally true, but to answer your question, WebForms will not make it in .NET 5. Not that this is a bad thing for once.
&gt; Edit: I should also say we used several other libraries too because some files are always going to throw you for a loop Exactly. Not trivial at all. Even a format as ubiquitous as PDF is fraught with gotchya's - regardless of the language or library you're using. Previewing Office docs is no cake walk, either.
&gt; There's lots of libraries and they don't need to be perfect Yes, I've used many of them. Saying "they don't need to be perfect" makes me think you haven't actually done much with this. If only they were just "not perfect."
Oh lord, another of those "We don't hire .Net devs" people. Of course a senior Java dev is going to be better than a journeyman .Net developer. Any senior dev is going to be better than a journeyman, no matter the language. But, you learned Java first and understand it more, so anyone who learned .Net first is shit right?
Keep in mind, Spring and Java are old. .Net is much newer, especially with Core.
Yep, Spring Boot is great. It focuses on ease of use and does that very well.
Project Lombok is an option for making constructors/getters/setters via annotations, though some people have issues with it.
I disagree, ASP Core is going to be much slower to develop on than Spring Boot, as that‚Äôs the project‚Äôs target, ease of use.
Old dotnet code can work with Core, but there‚Äôs no guarantee.
Use the fluent validation package and add a validator for the incoming model. You can easily add conditional validation and even return helpful messages for the client.
Oh completely, this is the thing I hated trying to review their code. Who in 2019 wants everything in untestable XML files? It's an insane way of doing things. One of the first things I changed at current work was moving Unity type registrations out of the config files into code. It solved so many deployment issues.
Interesting, I might have a poke at it just to see how it works. Thanks :)
We have a handful of WebForms apps that will be damn near impossible to migrate. We're thinking of just lightening up our .aspx.cs code-behind files as much as possible and moving all logic to separate .netstandard class library projects. Eventually just swapping the UI from WebForms to either (SPA+WebAPI) or (Razor+MVC)
That‚Äôs why people don‚Äôt use plain Spring for new projects in 2019. Spring Boot changes all of that.
I'm aware of it, though we didn't use it. My understanding is that it's more like library assisted code snippets that expand to save you typing, but still result in the same, verbose code that's harder to read. At this point, I assume my IDE or similar tool will handle menial tasks for me (say, the way the Angular CLI simplifies components), so Lombock is more about patching a deficiency in the tools for dealing with a deficiency in the language. If I was going to spend much time on the JVM, I'd really consider Kotlin, which actually fixes done of these things at the language level.
Have you considered a proper Digital Asset Management system. This functionality comes out of the box.
Dependency hell. Likely easier to implement on Linux and run in a Docker container under Windows.
Nice. I might pass this on. The stuff I looked at was not old, so I'll ask about why they're doing it this way. It's not my team, but they are friendly and it's helpful to get a handle on why technically disparate teams do stuff.
Spring Boot is basically your opinion in framework form. ‚ÄúWhy are we still using XML and Maven? No, Gradle and in-code configuration is the way to go. Get rid of that nonsense‚Äù. It still is Java, so there‚Äôs language limitations there, but it is so much more modern.
Is .NET limited by the amount of processors a server has, even if CPU is relatively low. Someone said that it‚Äôs limited to 32 threads per processor at my company, and that didn‚Äôt sound right to me. I am not a .NET developer, just a systems engineer but unless I did a deep dive somewhere I wasn‚Äôt finding the results I was looking for by quick internet searches
Well yes, but does it matter what ‚Äú{ get; }‚Äù or ‚Äú@getters‚Äù compile to? Nope. It‚Äôs just better syntax. But how is that a deficiency in the tools? You can just as easily generate code in any IntelliJ platform IDE for sure, and I bet many other IDEs have the same feature. Lombok is just a plug-in that cleans out the classes and removes the need for getters, setters, and constructors to actually be there. They can instead be generated. I‚Äôm not saying it‚Äôs a magic bullet, as people have found issue with it, but I‚Äôm not sure you have any idea what you‚Äôre talking about here. Kotlin is neat, but I personally disagree with too much of what it does, like the null safety. I just don‚Äôt think that‚Äôs something that warrants that much hand holding.
:) This sort of post really helps me when I work with teams that work outside of .NET. Thank you.
&gt; C# isn't necessarily the fastest or most memory efficient language But almost no one write web applications in C++ or assembler :-)
Exactly! You could, but the productivity of your developers would be poor. Certain performance sensitive web apps could be C++ (i.e. Chrome browser, that runs in a very performance sensitive context), but for the most part for enterprise applications you don't care. HAProxy is also C++ same sort of deal. It's a critical path. Your business rules engine is almost certainly not. OS kernel might be straight C, network stack might be, etc. But that's not enterprise software. For the enterprise if your code is 2x the CPU power and 2x the memory it won't matter if it took you 4x the time to develop.
Haven't looked back since moving to Core/Standard. For *enterprise* software there's not much reason to use Framework. In rare cases a fat client may still have a case, but browsers are awfully good and capable. PWAs now may be a viable alternative even with spotty network, thinking back to when I worked on a Windows Universal/Windows Mobile Enterprise app that had an offline requirement.
"Enterprise" to me means scalable business operations. Storage and use of hundreds of gigabytes or more of data, hundreds to millions of of concurrent users, and ability handle hundreds of thousands to many millions of business transactions per day. I've spent pretty much my entire career in this space in several industries. It's not just CRUD apps and webpages and has different concerns. Significant M2M data transfers, data transformations, business rules, data cleaning, business transaction exception handling, etc. .Net Core and Standard covers these sorts of requirements extremely well, but that's not to say you may have critical paths or integrations that are better suited to other languages, or they get dragged in due to availability of third party libraries, etc.
How so? Net Core middleware and SDK is pretty robust, as is the availability of packages to handle common concerns for enterprise software.
Emmm. ASP.NET Core MVC + Entity Framework Core + Chart.JS
Like I said, Spring Boot is aimed at ease of use to setup and use. You simply don‚Äôt have manually setup DI or long setup files. It does that all for you. Dependency injection isn‚Äôt something you need to setup with Spring Boot. Don‚Äôt get me wrong, it isn‚Äôt a magic bullet. But there simply isn‚Äôt a more beginner friendly, yet robust, framework out there. I do prefer ASP, as it‚Äôs less opinionated in the way you should go about things, but some things are a pain in the ass.
I have been experiencing performance issues with Visual Studio 2019 + Resharper. Without Resharper, the performance is not too bad. I found the project load time to be significantly improved as compared to Visual Studio 2017. On a couple of occasions though Visual Studio became completely responsive and I had to restart the IDE.
There are DI packages that do similar in .Net, they use reflection and register Impls for you. Or you could write the one line of code copied and pasted from Stackoverflow to do that one time. That sounds like the same fuctionality as @Autowired for the most part, though you would still have a constructor to pass the interface in. https://stormpath.com/blog/spring-boot-dependency-injection This shows a @Configuration decorated class for multiple impls (english vs french in their example), which looks like the equivalent of container.Register but in a class instead of a method. *shrugs* Not a Sprint Boot expert, but at least from a quick look I think there are already similar solutions to what you're pointing out.
Inherit from RequiredAtribute, override the validate method and call super when your condition is valid. https://docs.microsoft.com/en-us/aspnet/core/mvc/models/validation?view=aspnetcore-2.2#custom-attributes
To be frank this is one of those things where you should be able to pretty much just do it with the tools you're thinking of. Maybe add Signalr in place of some auto-refresh thing.
Frank, I‚Äôve never written a web app, just winforms. Are you saying I could display it in a form, or no, gotta go with a server page?
That‚Äôs not remotely similar, no. Copy/pasting code to register all service and repositories (interfaces and implementations included) is no where near as nice as just putting ‚Äú@service‚Äù above the class declaration.
You are faster with whatever you are more proficient with.
We're logging stats with Azure AppInsights and building dashboards with Grafana.
Is there any reason you wouldn't just leverage the OS though? Toss all the files in folders in a way that makes sense for your business needs, then grab the Thumbs.db(or equivalent) generated thumbnails. Problem solved for most filetypes.
I'm curious since I do exactly this, what WebForms functionality can you not migrate to Razor Pages? Not saying it wouldn't be a better idea to move towards a SPA or MVC.
This is a pretty moot question but I'll answer it anyway because I've got experience writing both .NET Core and Nodejs production code. It really depends on *what* you're building. Do you want to prototype a small MVP before dedicating a load of time to building it? Nodejs. Do you want something that will naturally scale well in a production environment, but requires some more time to build? .NET Core. Node.js was great for throwing something together to prove a point, but .NET Core always wins when it comes to something that will continue to be used in a production environment.
I second using graffana. there's even a built-in connector for MSSQL to run queries against your database to display values in charts.
Third. We have a grafana dash that pulls data, displays counters and charts, and does alerts if certain numbers are outside a range. Way better than building!
I am not going to rewrite anything I am just learning .NET Core for myself and perhaps future projects and this issue came up in a PHP project which made me think what would I do if it was .NET Core project.
Just checked out Grafana‚Äôs site. Looks pretty cool, plus, the price is right. I‚Äôll download it Monday and play around with it. Thanks for the recommendation.
Any time the term `render` comes into play, you know you're in for fun and pain
Fluent validation is the easiest way to do conditional validation, bar none.
Take WebForms and you'll see the productivity!:) Most of the things you can just drag and drop, no one line of the code! That's if you need the speed of development...
Actually, the MSIL for C# properties end up looking pretty much like Java getters and setters. I don't really care (much) about the way it compiles. My understanding of Lombock is that, at some point (build?), it actually expand the "properties" into the full getters and setters, so they aren't permanently shortened. That's why I say it's more like pasting a code snippet. It doesn't help at all with the long term readability, just saves some keystrokes. It's easy to dismiss syntactic sugar, but it's a real and beneficial thing.
lol... frank.
This honestly sounds like a post with a serious lack of software development experience... Which means grossly over and underestimating the complexities of different features... The premise of the questions is even wrong, everything you can do in PHP you can do in C#. The difference being .net provides a hell of a lot more than PHP standard libs, and has much more consistency.
This is similar in some ways to my Disposal project https://github.com/NickStrupat/Disposal I'm curious what you think of my approach?
AppDynamics can do this out of the box for a few different layers
Yeah, Stephen Cleary has a Disposable library as well. The 1.2.1 version of Open.Disposable had a "DisposeHelper" similar to your DisposableTracker&lt;T&gt;. I used that approach because it could be implemented by any class. IMO, this is an anti-pattern where you are allocating more memory for each instance just in order to handle disposal. I have with 2.x simplified DisposableBase in order to avoid that pattern. I can't even remember a time where I actually used the DisposeHelper elsewhere.
This.
Fuck imagemagick, even though it is pretty cool for what it does.
Webforms is also deprecated and a big old yikes too, definitely not the best advice.
Just to expand on what Frank is saying, it'd probably need to be a server page, it's pretty simple to connect back to the database and you could set the page to auto refresh every few seconds to update, but that would be, well, janky. Something like signalr will make the updating much cleaner. Basic graphs are included past .Net 4.5 and if your comfortable in VB.net you can use that for any code behind if you need any or if you want to go with something that more people are familiar with the jump to c# isn't that big of your familiar with the principles from vb
Please indulge me
Its a joke, not advice
SSRS Report Viewer
So it's like... Hey this company is buying 5 million dollars worth of our products... We should buy them since they have such an awesome product / service. ?
You win the cookie.
Thanks, this is what I was looking for.
Speed of Development will slightly slower in .NET Core. However you get the benefits of the .NET which is static typing, sane updates (for the most part) and lots of very mature libraries to build your software with.
Clean Code by Robert C. Martin
&gt;You might use several different languages in parts. Sometimes we had to use multiple languages but honestly, I really do not like to use multiple languages/frameworks, if I can avoid it I will do my best to do so. This is not because I do not like to learn or use new tools but managing multiple languages can make a project hard to maintain. That is my opinion at least so I may be wrong on this but this is what I believe.
I agree the language itself is way better at least so far what I have seen makes C# a lot more appealing.
we are doing it similiar. we have a lot of backends in .Net Core and use react for the frontend. the communication between the react frontend and the backend happens with graphql from HotChocolate ( [https://github.com/ChilliCream/hotchocolate/](https://github.com/ChilliCream/hotchocolate/) )
It was my mistake of not properly wording what I wanted to say (my English is not that amazing). When I said it is trivial I meant the feature request itself is a common ask not the development of such a feature. Having the ability to get a preview of a document by hovering over the document's name is a common feature request at least for the kind of apps we create. However, such a feature requires a lot of work especially if you want to support a lot of file types. Again I apologize for not clarifying what I meant.
We do have O365 and Sharepoint but this module is part of an independent application we are deloping, my employer wants us to develop our own solutions.
This is why we are developing our app without using any online services, we manage sensitive data for our clients (as most companies do) and my employer does not trust any online service except AWS and Azure still we have our own server farm... Data security is pretty much the most important concern for us.
NodeJS has a package for this, Python also has one and probably there are other languages which have a package for this for free, are they reliable? Well I have no idea, we did try the NPM one, that seems fine but we only did a limited test so we cannot say for sure.
We have plans to switch the frontend for our MVC apps to use React or Angular on the frontend but the backend will not be rewritten ever, at least not completely, that would be a couple of years of work and none will finance that.
What is your experience with this process I am intrigued? Which PHP framework was used for the PHP apps? What are the downsides and upsides you can see so far with this change?
No, there is no such limit.
My PHP experience is limited to say the least, but the existing applications were really old hosted on a Windows platform using Zen Framework 2 with Zend Server. The reason behind it is to try and standardise the technology we use, so that it's easier to maintain and we only ever have to worry about a single set of tools. As our server estate changed and evolved the PHP apps started to fail and become buggy because they were so old and not maintained at all. The only downsides I've experienced so far is I don't have the PHP experience and I'm having to refer to vague class diagrams with completely undocumented code so it's been challenging. I'm hoping to incorporate CI/CD processes and maybe even Docker later down the line to streamline processes further. In terms of the applications themselves, I've not seen any downsides so far and I've been able to integrate and improve functionality as I work through the application which I guess in turn is actually an upside too. There has been a few occasions where a certain set of functionality isn't available for .NET Core as it's something that's coming later down the line but there's been workarounds for that. Also, Active Directory integration is a breeze, requiring much less code than the previous applications.
For our VMs on AWS we store configuration variables in Systems Manager &gt; Parameter Store and fetch them at runtime.
Environment variables are the way to go (if you can) as they provide the most flexibility for development, CI/CD pipelines, and when running in a container. This approach is also cloud-agnostic, if you're the type that likes to avoid lock-in.
Your post has been removed. Self promotion posts are not allowed.
How can I get that job
What type of stuff are you guys disposing?
Both times they were bought to crush out competition. Some really great software at the enterprise level was shelved so that Oracle would not need to deal with superior products from a company with a smaller market cap.
Right, anything outside of C# and React.js I'll actively try to avoid just to lower the ramp we have on our wider staff. I can't expect everyone to be an expert on every language. We got backed into a corner on Go and did a very small fork on an open source repo because there were no other alternatives, and we used some services from vendor that were Java, etc.
Yeah that is annoying. I've ended up just using the URL api for embedding.
# If you're in MSSQL you could use SSRS with or without Mobile Report Publisher
No no, you don't get it. You need to encrypt the key store key. Then keep the key for that in appsettings.json.
But couldn't you then also encryot whichever key you are storing im the vault instead?
If you're on Windows the DPAPI is better than the credential manager and its natively supported in Core.
Why the need to shout?
I think that this is mainly useful for low level native code, where you have unmanaged memory/pointers.
It's useful for releasing references to any large managed object as well, to lower memory usage.
Wow not even sure how I did that..
Good luck, man. That‚Äôs a daunting task.
 any suggestions what i can do better?
Send me an email at Jonathan@infoQ.com and I'll make the introductions. There is some training on news writing involved, but nothing too onerous.
caching
Caching
Since you're asking for suggestions: &amp;#x200B; I checked various parts of your source code and noticed that caching is not implemented anywhere? I would assume that a site like this, would contains lots of caching in order to serve heavy traffic. &amp;#x200B; Since you're using the English language, I spotted you misspelled Profile a lot (you use: Profil) &amp;#x200B; Other that that, I guess the way you build it fits in purpose. If you want to continue working on it, I would drop all referenced to Insta and their look-a-like logos and come up with a smart related name, that does not contain any Instagram references.
thanks you for the suggestions. &amp;#x200B; sry for the misspelled word my native language is german not english and do you believe instagram can sue me for the name it is not a serious project?
Honestly I believe some of them could‚Äòve been built into the language. `abstract class Exception` is one of them. Unfortunately to late for that. Forwarding of inner exceptions should have been made as well automatically toggable by some compile-time flag. I don‚Äòt get 2) though. You don‚Äòt think it‚Äòs reasonable to use `throw new NotSupportedException("You tried to access session related info in a session independent context.‚Äú)` or `throw new ArgumentException("Only direct method expressions are supported as factory for caching.", nameof(factory))`
Very unlikely they will do anything. No problem about misspelled words, my native Language is not English either (it's Dutch)
I‚Äôm confused by the results of his first test. Shouldn‚Äôt the example the uses caching have about the same response time for the first request, and subsequent requests would be faster? Yet in his test even the first request is much faster.
I don't think this test is really useful. All 3000 database records are queried the same way and all of them are cached. What if you have different queries with a million rows? How would it work with multiple tables? Is the cache stored in memory?
According to 2) - \`NotSupportedException\` just like \`NotImplementedException\` seems to be a special case and I should probably exclude it from the analyzer. \`ArgumentException\` is very vague so you should use a more specific type depends on the situation for example \`ArgumentOutOfRange\`, which in my opinion should accept as constructor parameters the following information: current value, range definition (min and max), argument name. The message should be constructed inside the exception constructor - not in the \`throw new\` expression. Otherwise, it's hard to manage error messages (duplication, localization, etc.). &amp;#x200B; According to 5) I'm not sure if \` Calculate \` should directly throw \` CalculationException \`. Why not throw immediately \`ArgumentException\` and avoid this additional step of \`catch-and-rethrow\`?
Really wish people would put a little more effort into posting these articles instead of just putting it up. For those who want a little more than the headline, here is the TLDR from the author.... TL;DR: Versioning is inherently hard, but the way that .NET infrastructure is set up makes it harder than it needs to be, I suspect.
I assume disposablebase has a finalizer? If so, it has to be made very clear that this alone will put pressure on the GC. It has to be very clear that this class cannot be used for syntactic sugar. If I'd get a dime for every time I've seen IO operating types be idisposable just to avoid exposing and using the close() or disconnect() in exchange for a sleek bracketed using-statement solution I'd be filthy rich. Having a finalizer means moving the cleanup from a fast gen0 gc to a slower gen1 GC run. If there's nothing meaningful to clean up using a finalizer for the love of God please no.
I don't understand how to persist keys between different IIS IUSR accounts running on different machines for this. Once you have encryption keys, DPAPI is great, but how do you get the keys to the correct user and use them after?
&gt; the result needs to be multiple assemblies present at execution time Shared Resource contention is a problem with this approach. Think device capturing.
1. Set a break-point and step through the code to see if you are actually hitting the lines you think you are. 2. Attach a profiler to your database to see if your code is actually calling the DB. My first guess is that ModelState.IsValid is returning false.
By this way, this is what is referred to as "eating the exception" or "silently discarding errors". If the model state is no valid, you need to return an error so that the caller knows the function failed.
I read the blog post and it contained a lot of details. The author of the post is Jon Skeet. https://stackoverflow.com/users/22656/jon-skeet Yes, he is one of the most high-profile people on SO. He even has shown people how to implement LINQ from scratch in multi-post blog series. https://codeblog.jonskeet.uk/2010/09/03/reimplementing-linq-to-objects-part-2-quot-where-quot/ In short, I don‚Äôt think of Jon Skeet as posting a blog post just for the hell of it like many others in the programming community where you see 10 different *‚ÄùHow to use Hooks in React‚Äù* Medium.com blog posts everyday.
Plus, a lot of data is per user so you couldn't really cache that well.
They may want to change it from CLI Tour...
Are you saying dr_dimaka = Jon skeet? I know of Jon skeet and the work he has done on SO as well as numerous other projects. Highly respected and no issues there. My comment was regarding the post that was just a link with nothing more. Would prefer we get a little something like the TLDR to help evaluate before going to the page.
Oh I thought you were criticizing the blog post. That is why I was defending that the blog post is a legitimate topic that concerns the .NET development. I didn‚Äôt know you were referring to the Reddit poster. My bad ü§ó.
Cool! Why not Blazor?
Welcome.
Probably! Though I‚Äôd try to do things with VS Code as much as possible. It‚Äôd probably cause less headache.
I would assume it is. It won't be the fastest experience. But a small solution should work. You don't need a lot to code. When you are working with a local dB and web server the ram might get a bit tight. I suggest trying it out with the community version of VS 2019.
He definitely addresses how his proposals have very big issues to overcome that even he doesn't have all the answers to.
I can just use Azure if I need a database. But most of the stuff I'm working on is read only so I keep the data as XML files. Just toy projects, I have my desktop for real work.
I wan‚Äòt to wait for the release
Did you take someone else's video, uploaded it on your channel and linked that video to your website?
4gb of ram are enough. i'd be more worried about the processor. I have a cheap laptop with a weak processor (2ghz dual i think) + 4gb ram and VS runs so mhe to the point were it's unusable. on my desktop pc on the other hand with 4gb and a 3,2ghz quadcore, VS runs smooth with a few hiccups here and there.
Not totally unexpected. Startup and networking latency can vary by all sorts of variables
If you can afford to travel for work, you can afford a laptop w 32G.
VSCode takes much more memory than VS2019 as it is electron-based. Even simple electron-based apps like Slack and Teams take a similar amount of memory (300MB each) as VS2019 (about the same, depending on project size).
I would say no. Nothing less than 8, but hopefully 16. Reason is that one VS instance takes about 1 GB to just run. Then you add inn Chrome or some other browser, skype/slack/teams, outlook, etc... and just the baseline requirements to run Windows, and you'll probably end up using more than 4 GB. Not that it won't run, it just will start to page memory to disk (and if you don't have a SSD, memory speed will slow down to old HDD access speeds).
Thanks - I've had it working for a while roughly as you describe above - the idea behind using WF was to allow the end user to customise the workflow so unfortunately it's specifically the WF part that's causing issues. I'm making some headway with it - I think I've got the required workflow figured out, the problem now is getting the workflow to resume after a reboot (easy if one is using AppFabric, not so much if one just wants a simple, self-contained service).
Really good post, I think the only reason people haven't noticed this as much until recently is that * The standard library for C# and the other Microsoft frameworks really limit how many packages you need to pull in. * Most packages, in my experience, don't tend to rely on other packages that aren't part of System.*. I've only recently encountered this rather annoying problem when using Azure Functions which are pinned to a specific version of Newtonsoft. If I try to pull in another package (such as Flurl) that has a higher version then I'm screwed. It's not the end of the world though. I really like Skeet's idea for the public / private dependencies, even if it's not fully thought through.
I agree, this was unclear. I didn't see anything in the comment that would clarify the criticism, and the fact that it included a summary of the article suggested to me that it was being critical of the article. One could almost say they wished people would take a little more time and effort and make it clear what they're criticizing.
Don't look yourself blind on your dislike for electron. It is true that vscode uses more memory than vs2019, but only if you dont open any projects. My same project initially (before running debuggers) takes up nearly 2GB memory on VS2017, 850MB on VS2019 (only microsofts required extensions) , and a measely 360MB in vscode (and thats with a bunch of custom extensions). VS2019 is also slower and uses more cpu than vscode.
I just made the comparison of ram used for the same solution opened : * Jetbrains rider : 850mo * VSCode : 615mo * Visual studio 2019 (32 bits) : 330mo After some coding, the memory used is pretty stable for rider and vscode but explodes for visual studio (sometime more than 2GB used !)
I also notified the debug process is more RAM consuming and slower in visual studio than in rider/vscode
You can use transactional operations on NTFS volumes, and they can be part of distributed transactions for example part of your database call, but Microsoft encourages you not to. https://docs.microsoft.com/en-us/windows/desktop/fileio/about-transactional-ntfs
Roll back the transaction if there is an issue saving to disk. It's not more complicated than that.
&gt;that Yeah, I saw it is deprecated
If any european user can access your website, you need to either completely block their access (e.g. geoIP) or have cookie consent in any practical way that is not hidden or hard to locate for the user. e.g. no "cookies" url in the footer, but rather a popup in the middle of the screen (or visibly at the bottom or wherever)
4GB is enough until you turn the computer on. After that the experience will be absolutely miserable.
That is doable, but I need to take care of the order of operations. It is something I actually implemented in the solution I am working on, but I was thinking on a bit more elegant solution, that is why I jumped in here to see if someone has a different view on the problem.
What kind of projects? You may be able to get by with just dotnet core command line tools for creating and building projects. Then maybe a lightweight text editor. Also maybe compare visual studio to visual studio code with the C# plugin as that might be faster than a full IDE.
You could probably turn off a lot of features in VS to get that down a bit. I know, in particular, that the debugging features (breakpoint with rewind, RAM / CPU analysis, IIS spin-up) are greedy little goblins.
And CodeLens. This thing eats a lot of RAM and makes VS unstable IMHO.
I occasionally run VS 2019 on a Surface Pro m3 with 4 GB. It works and is stable, but it is far from an enjoyable experience. It is my super lightweight travel device and I only use VS on it as a last resort. For any real work, get at least 8 GB of ram and preferably an i5.
My favorite way to do this recently has been to use my VS subscriber credits and get a 2VCPU / 4GB Linux VM on Azure (Standard B2 with dev discount) and use VSCode with the remote dev extension. The laptop barely gets any load and I can seamlessly switch between devices without a headache.
I love Scott Allen. He's honest, straightforward, and an excellent instructor on Pluralsight. Would definitely recommend a read-through of his blog posts.
I would try to make a breakpoint as well, since it could be a problem with your form post. It's important that the primary-key is present in the form. I've had problems with that before.
&gt; It‚Äôs possible that there are lots of people who are worried, and they‚Äôre just being quiet about it. I feel like I've been called out. I'm extremely worried about it, and the most I've done to raise awareness is [a GitHub Issue comment](https://github.com/NuGet/Home/issues/6434#issuecomment-468421972) about one specific aspect of the problem. Maybe a really long Reddit comment can help compensate... I'm a maintainer of NetTopologySuite (NTS). We have a v2 coming up with lots of breaking changes to try to address some major long-standing design flaws. One of them, for example, removes an interface used ubiquitously throughout the library, replacing uses with an abstract class that has already existed for even longer and has all the same functionality. This experience has gotten me to do a ton of research about this topic, and yeah, this is a huge problem that's just waiting to blow up. # Lots of existing software NTS has releases I can trace back to 2006. That's potentially a **lot** of old intermediate libraries that are perhaps not maintained anymore, and so cannot be updated to use v2, and so I'm fully expecting that some people will be stuck on v1 for a while after v2 is released. The team supporting NTS is very small. The other team members choose to hide their affiliation on GitHub, so out of respect for their privacy I won't say how many there are or how active they are in private channels, but it's fair to say that we're primarily working on this in our free time, and so unless the community steps up, 1.x is very unlikely to have significant new releases. I'm sure that this all means that somebody's going to try to use both v1 and v2 at the same time. We do strong-name our assemblies, so I have a shred of hope that this won't be the end of the world, but I still worry that it's going to cause headaches for everyone involved, and our ecosystem just won't be able to do what's needed to make it right. # Disappointing tooling story This is something Jon Skeet's blog post started to touch on, but it didn't quite get into the tooling story (perhaps because it's comparatively easy to fix, and fixing the tooling won't fix the underlying issues). I'm going to use the same names from his blog post, because then my story can be traced back to the pictures he posted, but this is definitely a problem I've thought of in the context of NTS, and it's a non-trivial reason why I wanted to remove what's called "GeoAPI.NET" as a standalone package starting in v2. Let's say the developer of `Lib1`, wants to start depending on `NodaTime`, which is at `1.0.0` at the time, and so they use the tooling to add this dependency in whatever way is easiest through their tooling. Let's say `App` wants to use features from `Lib1` and `NodaTime`, so it adds explicit references to both, again in whatever way is easiest through their tooling. **By default**, when `Lib1` is published to NuGet, users who depend on it will see something that says "`Lib1` is compatible with any version of `NodaTime`that's at version `1.0.0` or higher". So if `NodaTime` publishes a `2.0.0` release to NuGet, then the developer of `App` will see that there's an update available. We all know that we should strive to be on the latest versions of everything, so they go ahead and update. Of course, `2.0.0` might break things that `Lib1` depends on, which might not even affect `App` until much later when `App` starts using some feature of `Lib1` that it never used before. The problem here is that **there are no warnings or errors when the user does this**. [`NU1608`](https://docs.microsoft.com/en-us/nuget/reference/errors-and-warnings/nu1608) exists, but `Lib1` was published without an upper-bound. OK, so the developer of `Lib1` gets the memo. They go to the [docs](https://docs.microsoft.com/en-us/nuget/reference/package-versioning#version-ranges-and-wildcards) and see examples of setting upper-bounds, so they replace their referenced version "`1.0.0`" with "`[1.0.0, 2.0.0)`". - Actually, let's pretend like the developer of `Lib1` saw [this GitHub issue](https://github.com/NuGet/Home/issues/6434), and so they actually specified it as "`[1.0.0, 2.0.0-0)`" to work around that. - Actually, let's also pretend like they also saw [this GitHub issue](https://github.com/NuGet/NuGetGallery/issues/6948), and so they actually wrote "`[1.0.0, 2.0.0-A)`" to work around that one too. The developer of `App` sees the `Lib1` update, pulls it in, and then [`NU1608`](https://docs.microsoft.com/en-us/nuget/reference/errors-and-warnings/nu1608) starts showing up in future builds (which is the only way that the system currently informs the user that something's wrong). - Since all applications build without a single warning, the developer will see the new warning immediately and then proceed to reverse the `NodaTime` version update. - And it's a good thing that this happened while the `NodaTime` version update was still fresh, so there wasn't much v2-specific stuff to revert. - And after this failed attempt to update `NodaTime`, nobody else on the `App` development team is going to try it again, because the team has perfect communication and memory, so everybody's either definitely going to remember to ignore the version update notification that the tooling flashes in their face, and/or they're going to catch the `NU1608` warning if they try it out anyway. ## Solutions? Even without solving the underlying issues that Jon Skeet's blog post identifies, I think our tooling can do a better job of at least making the user aware when there is a potential problem. Perhaps this will even raise awareness of the underlying issues and get people to start clamoring for a fix :-D NTS has an unfortunate history of making intentional breaking changes without a corresponding major version increment, and I suspect that it's not alone, so this won't be perfect, but I think it's **much** better than what we have now: ### Scenario 1 1. The developer of `Lib1` says "I want to depend on `NodaTime`" and adds it using whatever sequence of buttons / command-line options the tooling makes the easiest. 1. The system sees that `1.0.0` is the latest version of `NodaTime`, and it knows about the convention for packages to use SemVer, so it adds `NodaTime` with a version range of "`[1.0.0, 2.0.0-A)`". 1. The developer of `App` adds dependencies on `Lib1` and `NodaTime`. 1. `NodaTime` releases `2.0.0`. 1. The developer of `App` sees the update, but the tooling makes it abundantly clear, before they even try the update, that this might cause an incompatibility with `Lib1`, and so they should be careful. ### Scenario 2 1. The developer of `Lib1` says "I want to depend on `NodaTime`" and adds it using whatever sequence of buttons / command-line options the tooling makes the easiest. 1. The system sees that `1.0.0` is the latest version of `NodaTime`, and it knows about the convention for packages to use SemVer, so it adds `NodaTime` with a version range of "`[1.0.0, 2.0.0-A)`". 1. `NodaTime` release `2.0.0`. 1. The developer of `App` adds a dependency on `NodaTime` using whatever sequence of buttons / command-line options the tooling makes the easiest. 1. Later, the developer of `App` goes to add a dependency on `Lib1`, which is still at `1.0.0`. When they try to do this, the tooling makes it abundantly clear that this might not be compatible with the version of `NodaTime` that they're using, which is currently at `2.0.0`.
A lot of our users have problems with XDT transformations. To try and help, I was in the need of an online tool able to show a diff (like the Preview view from SlowCheetah), why I created this service. Enjoy.
&gt; I don't know why i get downvoted here. Probably pissed someone off and now you've got some down-voting bots trailing you.
What is stoping you from inheriting from ITransaction and saving your file to a MemoryStrem then when commit is called, write it to the file system?
Sounds interesting. I could even try to have a context and save all my changes in memory, file content and file names for example and on save i can flush them to disk and then add a transaction on top of it. Thanks for the idea
That is pretty much what I was getting at.. let us know how that goes :)
Kind of OP to make this, and I'm 99% sure it's not malicious. That said, any developer should think twice about posting their project's web.config into a website. The config file could be chocked full of api keys, machine keys, connection strings, etc and you're essentially handing it over to a 3rd party. Also Visual Studio lets you preview web.config transformations out of the box (right click on one of the transform files).
It does seem like there are tons of .NET jobs here in Toronto. I have my LinkedIn set to not looking for jobs but I constantly get recruiters with .NET positions contacting me. I'm curious, do you work mostly with .NET Framework or the newer .NET Core stuff? And do they always use .NET or do they mix in other tech if the situation warrants it?
I‚Äôve made something like this and I can only figure out in this way: - write the files maintaining the list - in case of commit is done - in case of rollback manual cleanups of all files The idea is the rollback is an exception and having a bit more work to do is mandatory. Hope this helps
Totally agree. Never publish your connection strings etc. online. I don't hope anyone has production API keys, connection strings, passwords, etc. in transform files. That is what Azure Key Vault, Octopus Deploy, Azure DevOps, etc. are for. But good point!
Basically yes, this individual is taking free courses / videos off of other sites and trying to peddle his developer social media / network app in the process.
never used it so YMMV: https://docs.microsoft.com/en-us/sql/relational-databases/blob/filestream-sql-server?view=sql-server-2017
Awesome!!
I have no idea what I'm reading. Who uses their platform? This is specifically tied to their platform right? It's sort of interesting, I've just never heard of them. &amp;#x200B; Blockchain in my head is a linked list where each subsequent node is signed with the hash of the previous node. What value are they offering above that?
Actually, an unofficial statement is that client-side Blazor will come out after .NET 3.0, but before .NET 5. Probably as out of the band release in the first half of next year.
[removed]
And microsoft owns all the code on github. No thanks.
Have you read the [reaction of Linux Foundation](https://www.linuxfoundation.org/blog/2018/06/microsoft-buys-github-the-linux-foundations-reaction/) regarding this acquisition? It was written by Jim Zemlin himself, the Executive Director at LF.
Bullshit.
Interesting, I know they weren't talking exact dates at Build, but mostly said by .Net 5.
VS captures a ton of info by default. Turning off that feature (Intellitrace IIRC) should calm it down.
Your results are really surprising. In a previous job, we had 4gb ram workstations with standard drives : More than 5 minutes to compile a WPF LOB app on a windows 10 only running VS ! After an upgrade to to computers with SSD and 16gb of ram : less than 30 seconds.
Ease of implementation while preventing bloat, according to the article.
No, compiling of course isn‚Äòt that fast, but that is not a ram problem, thats a harddrive problem, at least on my side. Maybe i could squeeze out a couple of seconds with more and faster ram, but there‚Äòs already a huge difference to my dev laptop with a new hdd with idk 7000rpm? Still 4gb ram. (Plus, after the first compile, when i only need to compile 1-2 maybe 3 object files, it‚Äôs really not that big of a deal anymore) And i think for op it‚Äòs more important that he can run multiple programs and VS smoothly than how fast it compiles if he wants a cheap solution. If compilingtime is important, of course, take a little bit more money and buy a 8gb ddr4 laptop with an ssd.
spam
First guess: ModelState.IsValid is false. Second guess: no [Bind] or [FromBody] attribute on the document argument.
Lol. Gotta love dumb logic.
Totally agree. I especially like his high-level assessments like this one on MVC 5, or [Azure Functions](https://odetocode.com/blogs/scott/archive/2017/07/10/thoughts-on-azure-functions-and-serverless-computing.aspx). He finds just the right perspective to give an overview of a technical area with enough detail to bring the terrain into focus.
Jesus christ this will be a cancerous place if we let recruiters post instead of from the hiring manager directly.
Hey are you on the market Jeremy?
Not to mention that '**no job postings**' is an explicit rule, visible on the right of the page.
Intellitrace is only in Enterprise isn't it?
There are two hard problems in computer science; cache invalidation, naming things, and off-by-one errors.
Not any more. Though you don't get important stuff like database tracing.
Assuming recruiter are able to read and understand these rules.
Ah ok, I'm probably thinking of the DB tracing... that was pretty cool when I was giving the Enterprise edition a trial.
Yea, I really miss that feature.
Are they all just Hello World? Seriously how do you manage that.
I love Resharper but on any medium sized project and up the performance is terrible. I tolerate it only because I can move faster with Resharper than how much it slows me down. I regularly have to restart Visual Studio or toggle R# off/on to stop my CPU maxing out for no particular reason.
I love this. A very long read but also riddled with resources that can be used by lots of folks as well!
You can do the same in C#. Add an attribute or inherit an interface and then register all the classes with the right scope from all your assemblies on startup, with 1 line of code.
I did not have fun working with it, that's for sure.
Somebody who knows my pain I'm guessing. Ghostscript is certainly a dependency from hell. Eh, at the end of the day it worked.
That‚Äôs still not quite as good though is my point. And I believe you mean in ASP. C# is just a language.
Same for me, always getting sent messages from recruiters, but I guess that‚Äôs a good thing? I‚Äôve usually found that if a business says they‚Äôre using the Microsoft stack, they rarely stray away from using .NET, SQL and the newer Azure tech. It‚Äôs just easier to replace developers if everything is built using the same language and database. I‚Äôve done a bit of both to be honest, maintaining legacy systems built in the older .NET frameworks and I‚Äôve been gradually using more .NET Core to use Azure for scaling, etc.
There are also two hard problems in distributed systems: 2. Exactly once delivery. 1. Guaranteed ordering of messages. 2. Exactly once delivery.
Use events in the worker class, or a callback method on the method you execute on it to report status change messages. Handle the event/callback in the control to dispatch the change for updating the UI on the UI thread. In either case the signature for the method could be something like Action&lt;string, double&gt; to report the message text and pct complete. Keep the dispatcher out of the worker and push that responsibility to the calling UI to manage. Maybe you want to use this in a console app one day where there is no dispatcher or maybe you want to have multiple UI subscribers that update at the same time. If you use the callback method it's nice because you can just pass a lambda to it, but having multiple subscribers will be a bit harder. If you use the event method then you can both have multiple listeners and use lambdas.
&gt; Maybe you want to use this in a console app one day where there is no dispatcher or maybe you want to have multiple UI subscribers that update at the same time. That's one consideration, there's a good possibility that (if this works well, besides the GUI) it may be integrated into another program - so I don't want the underlying worker code to even have to know about anything WPF related, potentially. So I have a code path like: Main Window -&gt; UserControl -&gt; Thread/Task (UserControl Button Method) -&gt; USB Library I want the 'lambda' or callback function ultimately to be executed within the UserControl so that I can confine any UI logic to it, meaning the messages have to go in some generic form from the USB library to the user control, presumably in a different method than the one synchronously executing it. I started working on something where the UserControl would instantiate an instance of another class, which would be instantiated with a reference to a callback function on the UserControl. This class contains a ConcurrentQueue and a method to add a dictionary to the queue, as well as a separate looping method to dequeue the next method and then execute the callback against the newly dequeued dictionary. Does that sound reasonable?
Welcome, and Happy Canada Day!
SlowCheetah lets you do this right in VS and has a nuget package to integrate transforms into your build pipeline (for all the project and file types that aren't natively supported, which is quite helpful if you're transitioning .Net full framework stuff to Core).
\&gt; The startup logic for an ASP.NET MVC application is difficult to follow. There is code in global.asax and three or four other files in the App\_Start folder. I haven‚Äôt been a big fan of how ASP.NET Core applications organize startup logic (see opinion [7](https://odetocode.com/blogs/scott/archive/2019/02/14/net-core-opinion-7-startup-responsibilities.aspx) and [10](https://odetocode.com/blogs/scott/archive/2019/03/07/net-core-opinion-10-move-more-code-out-of.aspx)), but even the worst examples are far better than the MVC approach. &amp;#x200B; \&gt; The scaffolding tools in MVC 5 are **far ahead** of the scaffolding tools for ASP.NET Core. Not only are the older tools *considerably faster*, but they tend not to throw exceptions as often as the ASP.NET Core tooling. Hopefully, ASP.NET Core will catch up. &amp;#x200B; agreed,especially the first,I've gotten a lot of surprises in terms of application entry points when I get a new MVC app, at least with ASP Net core its not as bad.. &amp;#x200B; One thing that I think should've been mentioned is how much simpler [Asp.net](https://Asp.net) Core's middleware pipeline is;I mean MVC's request pipeline has [this beast of a document](https://opdhsblobprod04.blob.core.windows.net/contents/ed5efb1947c04bb29402a0c08d68958e/d0ed2e012c44fea6a368d4591ea14088?sv=2015-04-05&amp;sr=b&amp;sig=AnSrPxG0N3JN3RQECi%2FmvEilfO%2B1CM24lkG8UySvQcg%3D&amp;st=2019-07-02T02%3A39%3A52Z&amp;se=2019-07-03T02%3A49%3A52Z&amp;sp=r) describing it (although I appreciate the detail)
I've typed this three times and the reddit editor keeps eating my text. Here's the short: You're over-thinking it, and fighting the framework. &amp;#x200B; Just use an event on the worker class. The callback pattern is not really suited to this use case (callback provides no functionality to the worker that isn't served by using an event). You can use any async mechanism you want to kick off the worker's method - won't matter to us. ThreadPool, [Task.Run](https://Task.Run), etc. await/async with [Task.Run](https://Task.Run) is probably the recommended method these days, but ThreadPool.QueueUserWorkItem() works just fine for a fire-and-forget method. &amp;#x200B; In the handler for the worker's status changed event, just wrap all your functionality in a call to whatever the method is for Dispatcher.InvokeOnUIThread. This should just call another method in the UI class that updates the user controls. &amp;#x200B; This way of doing it handles any number of attached listeners, makes no assumptions about the environment it runs in, has no requirements of external classes except that they know how to provide a handler for ProgressChanged. &amp;#x200B; It also does not ask the UI class for context it has no need for, doesn't involve any extra queueing of anything. It uses the available tools more less for their explicit purposes and is very little code to do what you want. &amp;#x200B; //start bad pseudo-code that won't compile //this attaches a lambda which just calls the dispatchers method to invoke on UI thread with the method that actually updates the UI controls &amp;#x200B; //somewhere in the UI class attach your handler to the event (in the constructor, initialization method, wherever is appropriate) \_myWorker.ProgressChanged += (msg, pct) =&gt; Dispatcher.InvokeOnUIThread(() =&gt; UpdateUIStatus(msg, pct)); &amp;#x200B; //also in your UI class a method to update the UI with the new status text. This will be called on the UI thread UpdateUIStatus(msg, pct) { \_statusText.Text = msg; //.... } &amp;#x200B; and the event definition on your worker &amp;#x200B; class MyWorker { public event Action&lt;string, double&gt; ProgressChanged; &amp;#x200B; MethodThatRunsForALongTime() { //notify all listeners that this method has officially started its process and is 1% complete ProgressChanged.?Invoke("Starting",1.0); }
Don't know if it upgradable, but I'll certainly ask.
&gt; You're over-thinking it, and fighting the framework. I had a feeling I was - I basically got overwhelmed trying to figure out a bunch of things novel to .net (i.e., the whole dispatcher/event thing, which I thought was something like a callback) and tried to just do what I've done in other languages that have less structure around it. Basically, it turns out, .net does a whole bunch of things for me that I wasn't expecting! Your pseudocode seems to make sense, so I'll take a stab at it tomorrow morning. Thanks!
This is awesome!
Preview in Visual Studio is awesome. The Transformation Tester is very much inspired by this feature. I don't always have Visual Studio open though, why an online tool is great. Visual Studio also provides XML and JSON formatting, but I find myself googling "json formatter" all the time :D
Maybe it's a JetBrains-ploy to get you hooked on it, then degrade the performace to the point where you decide to dump VS in favor of Rider :)
Link? I'm getting multiple results Thx in advance
This is a good point. Primarily DisposableBase is trying to follow the classic pattern as best as possible. Disposal isn't a magic wand to everything, but it can be a magic wand for specific things. As I mention in the 'Avoid Anti-pattern' section, let the GC do it's job where it does it best. The classic pattern with a path from the finalizer does provide a catch all for when the GC should cause a clean exit from managed resources. I thought about this quite a bit, that it might simply be best to not implement the finalizer. It would simplify the class structure for sure. Was the classic pattern a mistake?
It's more about providing a thread-safe base class for allowing a single dispose call. I have one example of attaching to the `BeforeDispose` event to 'unravel' dependent classes which isn't a very common case, but is a really nice addition when it's needed.
I'd also like to add, that if you don't need the finalizer, then the base class has much less value as simply implementing \`IDisposalbe.Dispose()\` is then all that is needed.
There are many ways to solve the problem. Typically what we would do is have a [ViewModel](https://www.markwithall.com/programming/2013/03/01/worlds-simplest-csharp-wpf-mvvm-example.html) that implements [INotifyPropertryChanged](https://docs.microsoft.com/en-us/dotnet/api/system.componentmodel.inotifypropertychanged?view=netframework-4.8) and then use a binding from some property to something in the view. The viewmodel would invoke the actual work in a new task or thread and be responsible for collecting the updates from that task. The binding there will take care of all the threading concerns such that when the property is updated from any thread the binding will enqueue the change to update on the dispatchers [SynchronizationContext](https://docs.microsoft.com/en-us/dotnet/api/system.threading.synchronizationcontext?view=netframework-4.8). For the background task doing the work, either you can use events as /u/rhino-x mentioned, or my personal preference would be to use [IObservable](https://docs.microsoft.com/en-us/dotnet/api/system.iobservable-1?view=netframework-4.8) from [ReactiveExtensions](https://github.com/dotnet/reactive) (RX). They are pretty similar to events, but allow you to use Linq-like operations on the event stream. For example, you might want to ensure that each message is displayed for a minimum time before moving onto the next one which would be tricky to do with events but relatively easy with RX
Also if you need that extra bit of dev speed - use the `dynamic` type to avoid creating dtos and other data-only classes, always use `new { Value = "", ... }` and create a helper function like `Helper.IsBoolean(dynamic d)` and `Helper.IsAnyValue(dynamic d)` for every possible type, like one would in Javascript `if (myObj) { ... }` **/s /s /s** &amp;#x200B; please don't. Someone might have to maintain that...
Same for this 4 year old issue https://github.com/NuGet/Home/issues/1192
&gt; Seriously how do you manage that. With patience
But what about dropping Exception from the end of those? InvalidOperation is expressive enough
As a programmer I get really annoyed at the use of the wrong slash... &amp;#x200B; Watching syntax all day makes me very picky about those things.
Great article. Any idea how the speeds compare to the ML.net implementation?
 [https://dotnet.microsoft.com/learn/web/aspnet-hello-world-tutorial/intro](https://dotnet.microsoft.com/learn/web/aspnet-hello-world-tutorial/intro) is one example. There's tons of similar documentation from Microsoft.
Honestly I would be afraid to use this API. I would not trust Google would yank this out from under us....
I know this sounds stupid, but did you try restarting VS?
[removed]
Tyvm m8
What are salaries like there compared to the USA?
I also wrote and often use this pattern: async Task Main() { var (result1, result2, result3) = await WhenAll( Task.FromResult(1), Task.FromResult(2), Task.FromResult(3)); } async static Task&lt;(T1, T2)&gt; WhenAll&lt;T1, T2&gt;(Task&lt;T1&gt; t1, Task&lt;T2&gt; t2) { await Task.WhenAll(t1, t2); return (t1.Result, t2.Result); } async static Task&lt;(T1, T2, T3)&gt; WhenAll&lt;T1, T2, T3&gt;(Task&lt;T1&gt; t1, Task&lt;T2&gt; t2, Task&lt;T3&gt; t3) { await Task.WhenAll(t1, t2, t3); return (t1.Result, t2.Result, t3.Result); } async static Task&lt;(T1, T2, T3, T4)&gt; WhenAll&lt;T1, T2, T3, T4&gt;(Task&lt;T1&gt; t1, Task&lt;T2&gt; t2, Task&lt;T3&gt; t3, Task&lt;T4&gt; t4) { await Task.WhenAll(t1, t2, t3, t4); return (t1.Result, t2.Result, t3.Result, t4.Result); }
You may consider using [Power BI](https://powerbi.microsoft.com/en-us/). Additional functionality would be: * Interactive dashboard. So you can change filters/scale/etc to understand data better * Out of the box support for mobile devices. A big screen is good, but the ability to check the data during commute or a meeting can be useful * Notifications
Why is it not quite as good? The attributed definition and extension method would be a few lines of code in 1 file that you can use in your entire solution and it does exactly the same thing. If you want that as part of library then you can wrap it in one, or choose from dozens already available, which is exactly what Spring Boot is anyway (prepackaged code in a library).
Automatic DI vs janky ways of stringing it together. Really? You need to ask?
Could you explain why you are using task.WhenAll and .Result? .Result will still block the thread even if the task is already completed and can possible create a deadlock. Task.WhenAll is completely useless because you are waiting for the tasks in the next line anyway. everything it does in this case is wrapping exceptions within the tasks to an aggregat exception. I would suggest to just await the tasks within the tuple or outside and then pass the result to the tuple like return (await t1, await t2) var t1 = await t1; var t2 = await t2; return (t1, t2) ; The task will still execute in parallel and it should do exactly the same or am i missing something here?
&gt; .Result will still block the thread even if the task is already completed and can possible create a deadlock. When the task is finished, then accessing `.Result` is an instant operation that returns the result that is stored in a field. [See the source code for Task&lt;T&gt;.Result](https://referencesource.microsoft.com/#mscorlib/system/threading/Tasks/Future.cs,4fbfc7c2f98c9636) &gt; I would suggest to just await the tasks within the tuple or outside and then pass the result to the tuple like Your suggestions will create a **vastly more complex** state-machine, for absolutely no gain (again, accessing `.Result` of a finished `Task&lt;T&gt;` is safe). https://sharplab.io/#v2:CYLg1APgAgTAjAWAFBQAwAIpwKwG5nKwDM6A3gUulZgByZwBsmDAPABQAqcANOhzAEoAfOgDqACwCmAOwCCAG3kB9AMLzJAQ2ksuvfkLZRWXEQBcezHTDODk1MnfvUoATmYA6CTIXy253qaC+JROVFAA7Oh+cO4ASpIAzgCu8qYBMHGJKaYCwfYAvo5URbT0TEbsunyCIl5yikoAchoJpgCeOhb6hsZwZhYV+uiBAiXkIaEAbhoATugzcOgAvJhu5nmh6NNzMzDLq8MwG6ERUQu8u7klhUj5QA==
I don't think you understand what "automatic" means. There's no magical feature. DI is just code, and Spring Boot is just a library that contains some helpers for registrations while you can get the same libraries (or write the few lines yourself) for .NET.
DI is just code, but in modern frameworks, I don‚Äôt have to set it up myself. Not inbuilt into ASP means it‚Äôs definitely not as good in that regard, seeing as how there‚Äôs no reason for it to not be.
Yes
You use the wrong tool for the job, a DB like ravrndb can atore attachments which are in a transaction
It's necessary because your property is named differently than your column (property starts with uppercase "S" and column starts with lowercase "s").
This is so great to see. I, and I'm assuming many others, have taken a go at making a quick cross-plat video player app over the years. libVlcSharp is really an amazing contribution to the .NET community. Thank you for your hard work!
Strange. When you publish the app (remove the code that produces the error first), does it include the ClosedXML DLL in the output folder where you published it? Also, try using a class from ClosedXml but don't put in any usings at the top. If you hover your mouse over the class name, does it suggest to add the correct usings for you?
Just to add to this comment, if you want it to go away, just name your columns and properties the same.
Try using the Dispatcher to delegate work back to your UI thread, in this case the invocation of the Window. If you're in a window at the point of the call you can just grab it from the Dispatcher property, otherwise it can be found in Application.Current.Dispatcher.
I can't think of a good reason not to use React, other than maybe Vue is easier to learn (IMO), and much easier to work with. I'd not use Razor pages, but that's just because I don't care for the design paradigm. React or Vue would be much more marketable than just Razor pages. I'd stay away from templates, but I am a control freak so I like to build my stuff from the ground up. I'd be curious to know things like, where is the app hosted, where's the data hosted, what kind of auth/authentication scheme will be used, stuff like that, and that's very basic.
Or check out this blog post where they talk about applying conventions (like snake-casing identifier names in postgres) to EF models: https://andrewlock.net/customising-asp-net-core-identity-ef-core-naming-conventions-for-postgresql/ I did this for my work identity model so that the identity tables would follow postgresql semantics and not stand out like a sore thumb.
React + redux along with azure is great. For db use postgresql &amp; apis can be in python or c#
Not in the media business anymore but was in the exact situation you described and gave up. I'm considering to try again just for fun thanks to this.
You can get a VPS for like 2$ a month on services like vultr.
Azure has a free tier for webapps https://azure.microsoft.com/en-ca/pricing/details/app-service/windows/
It's not free, but it's close to it. I use DigitalOcean for everything I do. Their VPS starts at $5 a month and I've never had a problem with them. You'll need so basic Linux knowledge to get going, but their services are great. I believe referrals are allowed here, so [here](https://m.do.co/c/fb74caed153d) is my referral link. You get $50 and I get $25 on their services. [Here](https://photos.app.goo.gl/WZxgPbh6NrSRVHNV6)'s what their control panel looks like. You can SSH into the Linux server and you have a dedicated IP. I use Apache2 reverse proxy to serve multiple APIs
Digital Ocean has gone down hill so much in the past few years. Their performance is noticeably worse than vultr, linode, and Upcloud (has the best performance out of all 4).
Huh, TIL. I'll look into the other services. Thanks
It has target frameworks "netstandard2.0;net40;net46". Check your runtime for incompatibility.
Check out vpsbenchmarks.com. They track performance of most cloud providers. Digital ocean definitely used to shine a while back, and I was a happy paying customer/supporter. I guess they got too popular and heir stuff is overloaded? Who knows?
Aws and aws lightsail has instances for 3,5$ / month. To many people want everything free these days.
https://www.aspone.cz/cz/Webhosting/Freehosting/
I can't afford a monthly service for what it normally costs, or even a steeply reduced rate.
This is worth considering, do you know if I can create more than one web application under this? Or is it one shot and done?
I think they're talking about [Cleary's blog post](https://msdn.microsoft.com/en-us/magazine/jj991977.aspx) and also [Cleary's blog post](https://blog.stephencleary.com/2012/07/dont-block-on-async-code.html) .Result being bad has become a bit of a meme.
Some more info would really help folks determine what you need to get going. What version of .Net - Framework or Core, and which version? Is your database going to be a SQL Server instance, something local (Sqlite) or No-Sql (MongoDB, etc...)? Is this a web-app, or desktop? I'd imagine you'd make your database/tables first in something like SQL Management Studio or whatever interface for your DB. Then you''d either use Entity Framework or Linq-to-SQL in your code in Visual Studio (C#?) to read or modify the data in your DB? &amp;#x200B; Does any of that sound familiar, or are you coming to this from a no-knowledge perspective?
I'm not sure you are asking the right question here. The editor or IDE you are using shouldn't dictate how you make a database. You should look for guides to ORMs like Entity Framework or the likes. Here's a getting started guide for EF Core https://docs.microsoft.com/en-us/ef/core/get-started/index
As a SQL Server user, I generally create a SQL Server Database Project in Visual Studio where I create the database schema. From there, it's trivial to publish it to an actual SQL Server instance. Plus, when changes are needed, after you update the project, you can publish again or do a schema comparison between the project and the database and just push the changes that way without losing data (depending on the changes). What database are you wanting to use? If you are just learning, I'd suggest downloading a free copy of [SQL Server 2017 Developer Edition](https://www.microsoft.com/en-us/sql-server/sql-server-downloads) and [SQL Server Management Studio 18.1](https://docs.microsoft.com/en-us/sql/ssms/download-sql-server-management-studio-ssms?view=sql-server-2017).
Hi and thanks for answer, here are my answers: Version of .net? Im not pretty sure, i think 4.5 or 4.6 what is my database going to be like? I need to use entity framework as my database layer Web-app or dekstop-app? Web-app! Yes, I will use SQL management studio to make the DB and tables, thats correct :) Answer to last question: I will use Entity framework yes. I must admit that I am pretty new to visual studio and C#
You have such a good heart :)
Yes I am using SQL server management studio 18 :)
If you register for a Visual Studio account you get a monthly Azure credit (VM, hosting, db, whatever). [https://visualstudio.microsoft.com/free-developer-offers/](https://visualstudio.microsoft.com/free-developer-offers/) &amp;#x200B; It's all I've ever needed for POC and "interview / learning" projects.
Not even 3,5$ ? O_o
There are free options listed in this thread. What's wrong with looking for free options? That should be the first thing you do every single time, imo.
&gt; Digital Ocean has gone down hill so much in the past few years. Their performance is noticeably worse than vultr, linode, and Upcloud (has the best performance out of all 4 and it‚Äôs not even close). Could you elaborate on that? I have been using Digital Ocean pretty much since they became available and I have always been very happy with them. Never noticed any performance degradation.
Cash is really tight at the moment. I can only afford to do certain things. Hopefully soon things will change.
Thank you, I think this is the solution I will use.
I don't know what your situation is, but if you can qualify for student benefits, you can also get a ton of free hosting credits that way.
OP need a way to display his skills. Seems understandable not wanting to pay for something that is not used in prod.
I always prefer using migrations scripts [https://docs.microsoft.com/en-us/ef/core/managing-schemas/migrations/](https://docs.microsoft.com/en-us/ef/core/managing-schemas/migrations/) If your using an older .net framework or other ORM (dapper, npoco etc) you can use fluentmigrator [https://fluentmigrator.github.io/](https://fluentmigrator.github.io/)
It would be nice to have a switch to ignore case. Most RDBMS don't care about case in column names such that one might as well echo that convention in the framework.
This is the best solution if you are unable to rename. Used it for same situation with postgres.
Sure. Outside of vpsbenchmarks.com‚Äôs tests (and others like this: https://joshtronic.com/2019/07/01/vps-showdown-digitalocean-lightsail-linode-upcloud-vultr/), my anecdotal experience consists of the following: I build SSR JS node apps with .net core api backends and tried my stack on all the providers (I didn‚Äôt try on Vultr‚Äôs big frequency stack yet, which might be the new winner) and there was a noticeable slowdown on DO vs all the other providers. Upcloud and Vultr were the two best, in my experience.
&gt; The task will still execute in parallel and it should do exactly the same or am i missing something here? Well, first, async/await in no way determines what actually runs in parallel or not. Second, no, you're wrong. In your code, with `await` both inside and prior to the tuple, `t2` cannot start until `t1` has completed. In the poster above's code, `t2` is free to start before `t1` has completed. Again, nothing about this code tells you if `t1` and `t2` will run in parallel.
https://www.reddit.com/r/juststart/comments/ah81m3/hosting_what_you_should_do_if_you_are_not_a_pro/ Goto that post and use the $50 free credit affiliate link for vultr. That‚Äôs 10 months for free server time.
&gt; In your code, with await both inside and prior to the tuple, t2 cannot start until t1 has completed. This is not true. Tasks are started hot, means both tasks are already running, and both tasks can finish - independently of any `await` statement.
Free tier cloudflare with a 1year Amazon ec2 free trial behind it. Churn aws accounts annually and you are good to go. 0 cost except for your effort to set it up and cloudflare helps a lot with ddos protection (it caches your content in a cdn so your web tier doesn't work so hard).
There is a free level of usage in AWS, so if you use virtually no compute you can prob run it for free, at least for the first year. Or you could deploy it to lambda in AWS and it will cost at most a few cents to run
Is Npgsql + Dapper an option? https://dotnetcorecentral.com/blog/postgresql-and-dapper-in-net-core-part-2/
Yes, but how can I return a JSON response directly from a Dapper query? Without having to remap everything?
A jsonb column maps to a plain string by default, no need to map: https://www.npgsql.org/doc/types/basic.html#read-mappings
Following - I‚Äôd like to know this as well.
Use the Vue cli. 2 separate projects. The .net js templates are dogshit. Thank me later.
Use two separate projects and it won‚Äôt matter what your frontend framework is.
&gt; Having a finalizer means moving the cleanup from a fast gen0 gc to a slower gen1 GC run. I'm going to really consider this adjustment. As I do find it VERY rare to actually need the finalize step.
Maybe this is what you need? &amp;#x200B; Model binding to a list: [https://haacked.com/archive/2008/10/23/model-binding-to-a-list.aspx/](https://haacked.com/archive/2008/10/23/model-binding-to-a-list.aspx/)
@/u/MeikTranel Ok this was a huge help. Thank you for commenting. I was really struggling with retaining the old pattern, and now that I've let that go, everything seems so much simpler and easier. I'm still able to implement the features I was intending, but now there's so much less convolution about how to implement the abstract classes.
One million times this. And no we haven‚Äôt decided on angular
Hah yea definitely. Use all three of you want, at the same time. Your api will not care... because it‚Äôs in a separate project!
I saw that! The problem I ran into using this was dynamically creating the input names with unique index values - I'm not sure how to go about this when the sub-form fields are created dynamically. If you have any suggestions in regards to this, do share. Thanks!
[https://www.nuget.org/packages/Open.Disposable/2.1.0](https://www.nuget.org/packages/Open.Disposable/2.1.0) Latest version has finalization removed. If the consumer/implementer has reasoning to cleanup during finalization, they can implement the finalizer themselves and use the \`WasDisposed\` property to decide if something still needs to be done or not.
No idea, I‚Äôll check that out. Thanks for pointing that out. I‚Äôll add a benchmark for that at the top of the next post.
Two separate projects for sure. I develop the web API in VS 2019, and the front end in VSCode. Works perfectly.
I‚Äôm not entirely sure as I‚Äôve never worked in the USA, only Scotland and Canada
Try Azure Functions consumption plan
&gt; Always pass caught exception as an `innerException` parameter when throwing from catch clause. Looking at the analyzer code, it looks like it won't give any warning on this: catch(Exception ex) { throw ex; } When that's easily the single most unambiguously wrong catch-and-rethrow pattern (it should be `throw;`, which will bubble up the exception without smashing the original stack trace)
You get it ;) (I figured you did from your first comment lol) I hope we converted OP
Free tier for Azure Functions is a decent choice too depending on Framework.
Do you ever take a step back and think WTF? Why, should we as developers, need an IDE and Text Editor / Lightweight IDE and a full front end framework in one language and totally different backend language and framework to make an application? Our job is to solve problems and it‚Äôs Microsoft‚Äôs job to make that as easy as possible. Seems like making an application should be easier.
Functions are generally garbage for traditional "backends". At least in my experience you end up with a lot of calls randomly taking way too much time due to startup. Not to mention lack of swagger, less than ideal DI, garbage logging/monitoring, etc.
Take a look at the Vue Middleware project on GitHub. It's easy and clean, and works just fine from my experience. Otherwise yeah, separate stacks, separate runtimes, so feel free to run then separately.
If you can do without SSL certificates and a custom domain Azure App Service free plan is probably the way to go. You can even put up 10 apps in that same app plan. There are several ways to get some free Azure credits, use those to offload any additional costs your projects might have such as bandwidth, storage, databases etc... because I assume your API's actually show off something skillful :)
I just wrote my first .net core api and have it hosted on heroku. I had to put it in a docker container, but that‚Äôs pretty simple.
Marten is designed for this task: [https://jasperfx.github.io/marten/documentation/documents/](https://jasperfx.github.io/marten/documentation/documents/)
Is there anything similar that results in much better response times? I considered using Functions for a proof of concept a while back and might be getting back to it later this year. Thought it might be a good alternative to building out and publishing a Web API project.
Heroku.
App service is fine for most use-cases.
Welcome to web development in 2019 &lt;/snark&gt; If you don't need a SPA, go Razor pages and use Vue just for data binding. Then you can just use Vs2019.
Dependency Injection is built into .NET Core (and used by [ASP.NET](https://ASP.NET) Core). The only thing not included is registering a class using an attribute - but it just takes a few lines of code to enable it, and DI isn't as simple as you make it seem either unless you've never had a need for advanced scopes. It seems your entire argument is that these 5 lines of functionality are included in Spring Boot, a library that upgrades Spring, so it's somehow better than [ASP.NET](https://ASP.NET) without any libraries. That doesn't make sense and it sounds like you're not familiar with either, or DI in general.
1) Use a \`string\` property. EF with Npgsql with automatically handle this. 2) EFCore has Value Conversions so you can wire up a function that will be called for a property on both saving and loading, to convert between your object representation and database value. EF already uses these to implement lots of new types like the geospatial stuff. [https://docs.microsoft.com/en-us/ef/core/modeling/value-conversions](https://docs.microsoft.com/en-us/ef/core/modeling/value-conversions)
that's why you usually implement a keep-warm function ;)
That‚Äôs the argument you honed in on. You wanted an example, and I gave you one. Ease and speed of use. Requiring a user to figure out how to register their classes manually is simply bad design. That‚Äôs not ‚Äúless effective‚Äù or ‚Äúslower‚Äù, that‚Äôs just simply an oversight. Not saying Spring Boot is better in general, as that‚Äôs largely opinion, but it is designed with the purpose of being easy to setup an get started. ASP falls way behind in that regard.
Functions are not intended for "traditional backend". They are used for serveless compute tasks... Background jobs. For example, sending emails to a customer, why would you want to do that within your website? Get your website to place a message on the service bus/event queue and the function sends the email.
&gt; And no we haven‚Äôt decided on angular That was a good decision.
It's about to get a lot easier for .NET developers. Check out Blazor if you haven't already. I wasn't keen on it at first glance, but I'm sold now. [https://dotnet.microsoft.com/apps/aspnet/web-apps/client](https://dotnet.microsoft.com/apps/aspnet/web-apps/client)
Off topic question but why did you build the web API in VS and not VSCode? I've found if I am doing a web API with .NET Core then VSCode (with extensions and the dotnet cli) is plenty. Was there some feature you could not do without?
Azure has a free tier for its App Service. I use it to host a simple .NET Core REST API
Yes, you can consider them. If you only host simple site without database, then you can go ahead with them. But if you want to host database, then **make sure** you check their calculator pricing, so you don't get shocked. Other recommendation for you is [asphostportal.com](https://asphostportal.com). They offer shared hosting, not free, but they offer reliable and low budget hosting. Just consider them on your list. Good luck!
[removed]
Can you be more clear? The design tools never worked properly from the get go. but if you are using xaml. you will be good. also please note that xamarin android is just a wrapper for the android SDK. so maybe the problems you started facing are not only caused of the xamarin part but also the android sdk part.
How long does it usually take for the app to start? I am asking because my experience with Heroku so far is that it puts the apps into "sleep" after some time and then they take some time before they start up again. This behaviour is perhaps not optimal for a dedicated API.
This looks good, worth checking out.
Might give this a go, been using Insomnia recently
try this one https://aspnetboilerplate.com/Templates
Looks like a poor mans Insomnia
Have you try asphostportal? I use their service too. Azure offer easy deployment, but beware with their cost.
how does having one project make any difference? you can still do dotnet run npm start from the command line
Same here, looks less rich than Insomnia so I wouldn't bother.
I agree 100% with this. But I see a lot of people trying to use them as a traditional backend or as a full REST API. It can be used for that, but it is absolutely the wrong choice.
That just kicks the can down the road. As soon as a second function is spun up, you have some users randomly waiting for 5-10 seconds. And that's if you just have a single layer. I have seen multiple people who have 2-3 chained http calls in Functions that I guarantee will cause random ridiculously long (we're talking \~30 seconds) waits. Turns out choosing the right technology matters. Although these are often the same people you find storing graph data in a relational database, using nosql when they need strong consistency, putting verbs in their REST endpoints, etc.
For us the design tools worked well in past iterations. They use the designer, and the properties, which this year just fail to work. The actual C# in the back end works as usual. No problens. But unless you code the xml by hand it's just a pile of crap. Exercises that take a couple of hours to complete in the past took an entire day.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/technologyaddicted] [\[ \] Nightingale, a fast and efficient rest api client for Windows 10, was recently updated to add syntax highlighting, text searching, and json collapsing. Nice Postman alternative](https://www.reddit.com/r/TechnologyAddicted/comments/c8m73b/nightingale_a_fast_and_efficient_rest_api_client/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
Ok, you've mentioned you are new to VS and C#. Have you worked with other programming languages in the past? If this is your first language, congrats - having a project in mind can give some direction and focus when learning. You don't actually need SQL Server Management Studio installed - with Visual Studio, you can use the VS installer to install a lightweight version of SQL Server for development purposes, and connect to it inside VS 2019. **Database-First or Code-First** Read the [Entity Framework docs](https://docs.microsoft.com/en-us/ef/core/). It sounds like you are planning to build the tables first in SSMS and then build the app to use them. That's "database first" design in Entity Framework. Nothing wrong with it at all, but let me suggest looking at Code First development. If you aren't having to support an existing database, I think its the better option. As you write your code, you push the updates to the database. With database first, Entity Framework has to generate classes for you based on the database, which I don't like. With Code First, you have full control over the code, and if you want something specific on the database side, you can always add it. * [https://docs.microsoft.com/en-us/ef/core/get-started/aspnetcore/new-db?tabs=visual-studio](https://docs.microsoft.com/en-us/ef/core/get-started/aspnetcore/new-db?tabs=visual-studio) \- this part of the docs does a quick walkthrough of setting up EF Core in an app using code-first development. As you edit the classes over time, you'll use [migrations](https://docs.microsoft.com/en-us/ef/core/managing-schemas/migrations/) to update the database schema. * [https://www.c-sharpcorner.com/article/code-first-approach-in-asp-net-core-mvc-with-ef-core-migration/](https://www.c-sharpcorner.com/article/code-first-approach-in-asp-net-core-mvc-with-ef-core-migration/) \- Another quick tutorial that shows some of how this all works **Search tips** I understand the challenge of finding good resources out there. Keep in mind that you can narrow your google searches by date, and that can help filter out material tied to earlier versions of VS, EF, and so on. On google, look under the "tools" menu item to see the date range options. You can also add a "+" sign to a keyword to make it required, like " NET +Core mvc tutorial ". If you put "core" in the search, that alone will keep it from pulling really old material. if you put in "core 2.2" that can narrow it down to the latest version. That said, keep in mind that tutorials for anything in the 2.x series will probably still have useful information. Just have to keep an eye out for any changes from 2.0 to 2.1 to 2.2 if you are working through a tutorial for one of those earlier ones. **.NET Framework vs .NET Core** Some quick suggestions. It sounds like you said you were using .NET Framework, not .NET Core. I strongly recommend using the Core version of everything. A few years ago, MS began rewriting a lot of their projects. ASP.NET Core is much faster than old ASP.NET, thanks to this. No new development on .NET Framework is happening after the current version, so the future of all things .NET is going to be in the Core family. If you are building a new app, build it on .NET Core, EF Core, ASP.NET Core. So, in Visual Studio 2019, when you create your project, make sure to select .NET Core and ASP.NET Core 2.2 or higher. .NET Core 3.0 is coming out later this summer, but I would expect upgrading a project won't be difficult. **Docs and Tutorials** As far as good docs go, the best place to start is actually MS's own documentation. It's actually very good. * [https://docs.microsoft.com/en-us/](https://docs.microsoft.com/en-us/) \- The top level page * [https://docs.microsoft.com/en-us/aspnet/#pivot=core&amp;panel=core\_tutorials](https://docs.microsoft.com/en-us/aspnet/#pivot=core&amp;panel=core_tutorials) \- a few tutorials. * [https://docs.microsoft.com/en-us/aspnet/core/data/ef-mvc/?view=aspnetcore-2.2](https://docs.microsoft.com/en-us/aspnet/core/data/ef-mvc/?view=aspnetcore-2.2) \- this one looks like it would be really relevant * [https://docs.microsoft.com/en-us/aspnet/#pivot=core&amp;panel=core\_overview](https://docs.microsoft.com/en-us/aspnet/#pivot=core&amp;panel=core_overview) \- tons of good stuff here, and look at that free courses link! Also, look at getting an account on Azure so you can publish the app to the cloud. Consider also using PostgreSQL for the database. It's a cheaper alternative to SQL Server that's available with most cloud services (Azure, AWS, etc.) and it's just as good for anything but the most demanding applications. Could be better, even. [You can install it locally for free](https://www.postgresql.org/download/windows/), it's open-source. You'll have to add the EF Core provider for it to your project, but that's easy enough to do. **SPA or MVC?** If you are completely new to this, MVC is probably the easiest type to work with. It's been around for a while, there are lots of good tutorials and docs for it, etc. That said, if you are comfortable with Javascript, single page applications (SPA) are going to be increasing in popularity, and there are several project templates for Angular and React in VS 2019. You could also look at building a Blazor app, which uses C# on the front-end instead of javascript. It's still new and won't support authentication very well until .NET Core 3.0 is released, but it lets you build a SPA using all C# and .NET Core libraries, which is kinda amazing. [https://dotnet.microsoft.com/apps/aspnet/web-apps/client](https://dotnet.microsoft.com/apps/aspnet/web-apps/client) I hope this all helps. This is a great time to be learning development with .NET.
I can also recommend the RestClient extension for VS Code: https://marketplace.visualstudio.com/items?itemName=humao.rest-client
I was actually reading an article this morning on different styles of Vue/.NET combinations in place of a "default" template. [Quite an interesting read](https://www.dotnetcurry.com/aspnet-core/1500/aspnet-core-vuejs-template)
Would use chrome headless for doing this.
Windows Store? I'll stick to Insomnia/Postman.
Oh, I know it. I really like razor pages.
I really hope this catches on.
If it only works on Windows 10 then it is not a Postman alternative, unfortunately.
That is a really good question. Considering I love how VSCode is setup and works, and constantly am thinking how I wish VS was more like it, I continue to use VS for the backend. But it's the little things that keep me there. Code snippets and navigation I think are just way better. I'll pay closer attention today at work and update this with some better examples. It might be time for me to try VSCode for backend again though.
I haven‚Äôt had any issue with availability. Every time I send a request, I get a response ü§∑‚Äç‚ôÇÔ∏è
I started it with my front end spa app inside my .net project, and that does work perfectly fine. Over time I found that having them as separate projects for source control and general management was much more convenient. They are separate components and treated as such.
Actually I take a step back and think "wow! This is fantastic!" The capabilities of VS and VSCode are amazing. I'm able to build an application much faster than ever before because of these tools. Web applications have always required using multiple frameworks. That might seem like a pain, but we don't have to suffer the pain of pushing out an updated desktop application to thousands of users. We only have to push to the web servers. The browser takes care of the rest. Speaking of which, we are able to create one application that will run on any device, anywhere, no matter what hardware form factor or operating system. THAT is an incredible feat. Considering that, this is the easiest software development had ever been.
As long as you don't need SSL.
FaaS can actually be a good choice for a low traffic API Annette long start up times aren't an issue. And some languages have less startup time than others. Node.js starts up almost immediately on AWS Lambda for example.
If your requirement is that it must run on any device, things have improved. I agree with that. But I still think modern web development should be easier. I like Razor pages a lot, they are very simple.
angular, while *technically* being a great framework for large applications, is just *waaay* to bothersome for smaller ones (i'd say, less than about 20 components) most of the time Vue, Vuex and VueRouter are plenty for an application.
Why even use xamarin for just Android? It makes little to no sense. The way I see it, C# is similar enough to Java so students don't have to learn anything extremely new, they can get used to a language in a day. Xamarin Android is just a wrapper for native android sdk, which means it adds another layer of problems on top of existing stuff and doesn't bring any noticeable benefits.
Why use Insomnia vs Postman? This is the first I have ever heard of Insomnia.
Buy a used ThinkPad with 8GB RAM instead of a cheap laptop. Cheap may be useable, but buying a new laptop for cheap will definitely not be useable. /r/thinkpad
I like the simpler UI of Insomnia. I find Postman too cluttered and it has annoying modal dialogs to get you to use premium features.
Finally... thanks for sharing !
I used insomnia regularly before trying Nightingale out. The speed improvements alone have made Nightingale my go to client, with insomnia my second.
Curious, poor in what way?
Ubuntu is in the store. The new Windows Terminal is in the store. Hell, even python is somehow in the store. What's wrong with an app being in the store? It's just a distribution system isn't it?
Sorry, I meant postman alternative on Windows 10. Not across all OSes. Thanks for helping me clarify.
Same reason I tried Nightingale. Simpler ui than postman
Nice! I tried this app a while ago, but stopped using it because it didn't have syntax highlighting. I'll give it another try now!
Can you please provide an example?
The Store doesn't work on my corporate machine. I never really looked into why nor have I needed to as all the software I usually use can be installed without it and/or there are alternatives to Windows Store apps I can use instead. Additionally, even on my personal Windows machine I've avoided using the Store as I don't want to give my payment details.
The [documentation](https://docs.microsoft.com/en-us/dotnet/api/system.windows.threading.dispatcher?view=netframework-4.8) is pretty clear, and also explains *why* you need to do this when manipulating the UI in WPF. I'd suggest reading up on the WPF threading model since you're not already familiar with it as it's pretty fundamental to using the technology correctly.
Better than Skype.
Don't. Create a (observable if needed) list of objects that hold those 4 values (as can be dependency properties), then bind an ItemsControl to that list.
ah okay, good to know :) No idea why my node.js app "wakes up" after a long period of inactivity. Guess I just try again with a .net core app
Why not just teach the class using Kotlin and Android Studio. Kotlin is awesome and you can pick it up quickly!
I didn't mean to sound like I have a lot of experience, so YMMV. I've only had my app up for a few days, and have been testing it fairly regularly. It may be that it just hasn't spun down since I started it. &amp;#x200B; Did you host your node app through a container? I wonder if that makes a difference? Also, my api is SUPER light. One model, one controller, one page, \~6 js functions, in-memory database...
Great!
On your corporate machine, I understand that it's out of your control. On your personal machine, you know that you don't even need to login to download a free app, right? I can boot up a brand new PC, refuse to login to my MS account in the OS, refuse to login to my MS account in the Store, and I can still download a free app.
Yeah I didn't like the app as well before because of the lack of syntax highlighting and code folding. Hence why I wanted to share the latest update which added them :)
Never had any speed problems even on a pretty low end workstation, but happy it works for you.
I don't think that was the case when I last used my Windows machine - which admittedly was 2 years ago now; my PC has been in storage since I moved house and I've been using my Macbook exclusively at home since then. I'll have to look into it again when I eventually have my home office renovated and my PC is reinstated.
I'm not sure what it was like 2 years ago, but today you can absolutely install free apps without logging in.
curious, what are the specs on your workstation?
That's good to know. At the end of the day though apps like this are more useful to me at work as I don't have much time for leisure coding so if it can't be installed without the Store it's useless to me.
Yes, it has done for a while now. Very welcome improvement.
I'm glad I was able to share new info about the Store with you, especially since you've been using a Mac at home for the last 2 years, so you might not be aware of all improvements in Windows 10. Also, good to hear from your perspective that your corporate environment doesn't have store apps enabled. I agree that's unfortunate since store apps are useless to you. Thanks for providing more context behind your original statement of "Windows Store? I'll stick to Insomnia/Postman" Thanks for the discussion
Not at work atm but off the top of my head 3rd/4th gen i5, 8gb ddr3 ram
Oh man that's awesome. My machine is 4gb so RAM is a precious commodity üòÇ Nightingale's memory efficiency has helped a lot. (Yes, I know I should get more RAM, but hey we can't afford it so ü§∑üèΩ‚Äç‚ôÇÔ∏è)
&gt; Really wish people would put a little more effort into posting these articles instead of just putting it up. One issue here is that Reddit encourages this behavior, by not allowing link posts to have a body.
Any reason to use postgres over sql server?
Postgresql is advanced version of sql &amp; supports cross platform. It also has good csv &amp; regex support.
At least for C# I don‚Äôt see any advantages of FaaS over a .NET Core API. The DI options are better, swagger support is better, performance is predictable, doing things like loading files is easier, etc. Not to mention you lose a ton of docker benefits by going with FaaS. It‚Äôs also a nearly identical amount of work to get a function app vs an app service out to Azure.
I used the "Deploy to heroku" - button ;) so I think it is a rocket container but I am not quite sure. In this case I deployed the "juice shop" project to my Heroku account (github project dedicated to the gamification of pentesting). The app is fairly large since it emulates a full-stack webshop for pentesting purposes.
üòÅüëç
[removed]
&gt; to download a free app "+ Offers in-app purchases" *"free"*
Free to download app as opposed to a paid app. The reason I said "free app" is because a "free" or "free+" app does not require you to be logged in for downloading. Meanwhile, a "paid" app does require you to be logged in because you have to pay. I'm not saying the entire app is free (and that wasn't the point of my comment). I'm talking about the login requirements for downloading. Sorry if that confused you!
Just check in each setter method if the other is not null.
You could do some validation inside an explicit set. So if you set the Customer and the Behandler is null throw an exception. But a much more elegant way, assuming you need one or the other and having both null doesn't make sense and it's an immutable value object, is to create two constructors. One taking a Customer, the other a Behandler. Inside the constructor you of course add a guard clause checking if the passed reference is not null. That way you'll always end up with an object in a valid state. The set methods of the property should of course be private in that model.
Thanks, will consider this.
Your second recommendation sounds good! and straight forward lol.
&gt;throw new ArgumentNullException(nameof(behandler)); `public class ApplicationUser : IdentityUser` `{` `public ApplicationUser(Behandler _behandler)` `{` `this.Behandler = this.Customer == null ? _behandler : throw new ArgumentNullException(nameof(_behandler));` &amp;#x200B; `}` &amp;#x200B; `public ApplicationUser(Customer _customer)` `{` `this.Customer = this.Behandler == null ? _customer : throw new ArgumentNullException(nameof(_customer));` `}` &amp;#x200B; `public virtual Customer Customer { get; private set; }` `public virtual Behandler Behandler { get; private set; }` `}`
Wait, is it redundant for me to check for null on the other property, since it MUST be null as the setter is private and the only way to set it is by its respective constructor?
Using Azure SignalR\*
There is no reason to check if the other is null since you're making the only place they are set via the constructor. /u/kowgli 's suggestion of an interface and then only a single property still probably makes more sense unless these are distinctly different objects. The logic would imply they have something in common though.
All they have in common are the ApplicationUser properties.. Now EF has issue determining the principal of Behandler and ApplicationUser since I have: public class Behandler { .... [Key] public virtual ApplicationUser UserProfile { get; set; } } How do I fix this with fluent API? Behandler.UserProfile can be null and ApplicationUser.Behandler can also be null, so none are a required field..
How would this approach not give you headaches throughout your code? If there are different use cases that only work correct when the applicationuser has it's customer set or it's behandler set then how would this approach not give you exact the same problems? You should seriously consider that the other parts of your code are the main cause of your headaches.
I don't think so. I have separate controllers for them and a Role defined for each of the entities. So only a Customer ApplicationUser can ever be referenced in a \[Authorize(Roles("Customer"))\] controller/action.
Don't know if this will lead to spaghetti code long-term though. But that's my issue, I can't find any documentation on best practices even though the issue seems trivial.
The rules around ValueTask are stricter than I expected. For example, I didn't realize that you can't have multiple things await them.
This? https://github.com/danijelh/aspnetcore-vue-typescript-template
Although I do consider building an application fully OO a mistake applying the OO rules (inheritance and encapsulation) for what you describe are almost always the right choice. Having those two properties on the AU and having a rule that only one of them may be set with a value effectively states that a certain instance of the AU is a customer or a behandler. This is similar to having two inherited classes. The main difference is that you now depend on the correctness of your code on how it runs because the compiler cannot help you anymore. Case in point: you now need coded rules that enforce the one or the other property to be null. Even more hidious is the fact that your AU can be neither a customer nor a behandler. There is no explicit part in your code that knows about this. The upside of what you describe is that you can change the implicit type of the instance of the AU from unknown to customer or behandler without loading a new instance. But if you don't use that then still you should look into the inherited approach again Good luck with that! Hth
This is a solved problem by using inheritance and a user type enumeration. When your user is hydrated from the identity db it checks the user type and casts to the appropriate subclass. holding a one or the other field is going to result in so many null checks, and what happens when you need a third or fourth or fifth kind of user?
Totalmace is correct. This is a solved problem by using inheritance and a user type enumeration. When your user is hydrated from the identity db it checks the user type and casts to the appropriate subclass. holding a one or the other field is going to result in so many null checks, and what happens when you need a third or fourth or fifth kind of user?
Thanks Totalmace and Joepetrakovich, it makes so much sense. Inheritance was also my first instinct, but I had problems with Entity Framework recognizing the structure of my entities. When I fixed those issues, the code broke wherever I user `UserManager.GetUserId()` or similar, because UserManager was declared as UserManager&lt;ApplicationUser&gt;. What I then tried was explicitly declaring a UserManager&lt;TUser&gt; for each TUser (AU, Customer, Behandler), but that seemed clumsy..
Btw. What do you mean with "Although I do consider building an application fully OO a mistake[...]" ? Cab you ellaborate on this? Seems interesting.
Honestly, this is the question you should have posted (including relevant code) - how to solve your issue with UserManager.GetUser when you have different concrete user types. This may have led the discussion to either some simple fix or maybe a clear and correct design change. The design that was recommended to you is very poor; hopefully that has become clear from the other discussions you've had in your post. Maybe the person that recommended this to you didn't fully grasp what you needed to achieve and what these objects represented, but if they did, I would be wary of their advice in the future.
From an OOP perspective, this design implies a brittle, unsafe contract. I would argue that you should not be looking for an opportunity to throw, but instead be trying to abstract the qualities of Customer and Behandler to something that is safe for both types. You could do that with either an abstract base class or even a simple interface (if, for example, the relevant interface fields exist for both types: name, id, whatever). This would allow you to then instantiate your ApplicationUser class via the constructor: public ApplicationUser(IAppUser userInstance) &amp;#x200B; And then expose the IAppUser via a single readonly property. This would allow the consumer of your type make their own decisions about what to do if or when a more concrete type is needed (they could just use 'is' / 'as').
I still have VS installed for older legacy non-.NET Core apps that I occasionally need to support or update. I got so used to using cli tools with node/frontend frameworks and backend technologies like rails and laravel for the last several years that the dotnet cli was a breath of fresh air. I find I can manage the creation and deployment of an entire .NET Core web API efficiently from the command line- so much so that the VS UI just seems to get in my way. Quite a different story from when I was primarily working on .NET (SharePoint, MVC, WPF) nearly a decade ago.
Can call `.AsTask()` to get a Task that you can then have multiple things `await` (and the Task is then the one thing awaiting the ValueTask)
Good point, I missed that one.
The environment switching and variables are a little more intuitive in insomnia I honk. It‚Äôs also more privacy conscious and nothing is ever sent or stored from insomnia I believe. Interface is also super clean.
Your best bet is likely StackOverflow. I think most of us have long left deprecated tech behind.
Wow, that is the exact post I was mentioning! Thanks for going out of your way finding it, just so you could explain this to me :) \- How would you go about the UserManager issue? Is it possible to declare an abstract UserManager that can be used for all types if you use it like UserManger&lt;Type&gt;.GetUser() ? And btw. what is the difference between using a usermanager and just using the dbset (context.UserType.Where(...)...) ? I imagine UserManager is faster for some reason? Thanks for the guide, I will look into it. I think I have to re-study the .NET basics in general, since I have gathered a few misconceptions over time about what it can/can't do and what the intended use of certain features are..
Hoped you wouldn't ask that question because the answer will take a lot of writing :-P &amp;#x200B; The origins of OO programming date back to the 1950's - 1960's . Back then someone could not design a language without also designing the hardware it would run on. So the choices made in the design of the language were influenced by what was possible on the hardware. OO was a good fit between having a good programming experience and running the application. &amp;#x200B; But the OO model has a lot of issues (see the criticism part in this wikipedia article [https://en.wikipedia.org/wiki/Object-oriented\_programming](https://en.wikipedia.org/wiki/Object-oriented_programming) ) &amp;#x200B; These days the available resources and compute power of hardware are such that the performance is not such an issue anymore. So now other aspects are getting more important. &amp;#x200B; To design an object model of a non trivial size you need a lot of experience. Basically when you do that for the first time you will fail. The chances that you will fail on the next 10 attempts are also high. Most beginners end up making models that are overly abstracted. Only when you start learning Domain Driven Design and also teach all other people involved including non technical people like domain experts then you might be able to do it well. (actually applying DDD the first time will also fail ;-) ) &amp;#x200B; This is not to say that you cannot use OO principles like encapsulation and polymorphism in your system's design but to attempt a full OO design just makes things much too difficult. &amp;#x200B; I could go on in detail where things will get difficult but I guess that this post will explain a bit why my opionion on OO is the way it is. &amp;#x200B; Greetz! &amp;#x200B; B.t.w. do you know that you can Inherit from UserManager? Also for just getting an instance of a customer or a behandler you do not need to go through the UserManager. You can also just use your ORM for that.
**Object-oriented programming** Object-oriented programming (OOP) is a programming paradigm based on the concept of "objects", which can contain data, in the form of fields (often known as attributes), and code, in the form of procedures (often known as methods). A feature of objects is an object's procedures that can access and often modify the data fields of the object with which they are associated (objects have a notion of "this" or "self"). In OOP, computer programs are designed by making them out of objects that interact with one another. OOP languages are diverse, but the most popular ones are class-based, meaning that objects are instances of classes, which also determine their types. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/dotnet/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
It's just annoying that shareware always gets called free... instead of shareware.
Ah I see what you mean, and I how my statement was annoying to you. Thanks for that perspective, I'll be more mindful of using the term shareware instead of free for freemium software. Cheers
What is the pattern where you have many awaits for one task?
At Signature Code, we use Constrained Semantic Versionning [CSemVer](https://csemver.org) It provides a coherent subset of SemVer. We have implemented CSemVer for dotnet core shipped as a library, SGV.Net (Simple Git Version). We use SGV.Net to add versioning tag to our codebase and this simply ensures proper versioning, nuget compatible, semver compatible, and Continuus Integration build support. This helped us a lot to manage hundreds of libraries. We are also developing a tool to manage a coherent set of libraries together, but this will je the subject of a dedicated thread I guess !
Extremely powerful tool when leveraged correctly. Avoided alot of pain through rewrite rules.
haha, thanks for explaining anyway! I've heard people increasingly mentioning DDD, so maybe I should have a closer look at the concepts. What would your DDD solution to this problem be then? Ps. if you feel like you've already spent too much time teaching my sorry ass, you don't have to answer this. I completely understand :P Just generally curious about these technical details.
Actually, DDD does not solve your current issue. Better still - using OO techniques will solve this issue. DDD is more about managing the object model in such a way that you can create one of a non-trivial size without running into the typical problems when you only apply OOD. The book Domain Driven Design is written by Eric Evans and is a long, but good read. But also it helps looking into functional programming languages and see what you can learn from that. It's entirely possible to apply some of the functional approaches inside your OO language. Using the ORM is probably the best way to go. Only when you want to extend the dependencies of the UserManager (like the validator dependency) then you will probably have to extend the UserManager. Greetz!
https://www.reddit.com/r/dotnet/comments/c8szcf/understanding_how_to_use_task_and_valuetask/esqbyca/
Yeah I saw that, and actually now realized that you need this when you store the Task objects in data structures.
Thanks for everything! I will read the book, thanks for that too :)
Hi again. I've read the articles now; they provided great knowledge, thanks! Which strategy would you use for this problem? I'm leaning towards TPT, but I feel like the author would have chosen TPC. What is your take?
Too much self promo. If you want to make blog post. Highlight the blog post. Don't start out with your company. It's okay to end a blog post with few lines of promo. Downvote from here.
This is my company and main reasons to share is spread knowledge not promotion... Read the blog and still if you find it is promotional let me know
It is quite spammy. I assume English isn't your first language, so the text has lots of grammatical and spelling errors. Each section contains no real information about the technologies, or why an enterprise would want to actually use any of it. I think the biggest problem you'll have is it driving people away from your company because they will look at this.
If (a == null ^ b == null) A = null b = null // false A = null b = something // true A = something b = something // false It checks whether or not ONE of the conditions evaluates to true, and the other must evaluate to false in order to return true
Custom attributes https://docs.microsoft.com/en-us/dotnet/standard/attributes/writing-custom-attributes https://stackoverflow.com/questions/41900485/custom-validation-attributes-comparing-two-properties-in-the-same-model/41900684
Mike James here (former Xamarin employee and now working at Microsoft). Sorry to hear you‚Äôre having issues with the latest release. If you want help getting the issues resolved or have any specific feedback then please feel free to reach out to me at mike@xamarin.com Obviously would love to see Xamarin remain part of the students studies and happy to help anyway I can.
I'm really sorry that this is the experience you are having, and I'd love to help out - or at the very least collect some information for the product teams to help fix these issues. When you get a crash in the designer or an app failing to run can you report it via the Help-&gt;Report a Problem option so we can gather the crash reports and logs to investigate. &amp;#x200B; Can you also email me - jim dot Bennett at Microsoft dot com and I'll see how I can help.
It's all about exception handling. If you are given multiple tasks to await, *never* await them one by one, because if earlier Tasks fault, any faults in later Tasks will be lost. For example: if `t1` and `t2` both throw exceptions, only the exception `t1` will get returned to the calling code. The exception from `t2` will be lost, and eventually raise the `Task.UnhandledTaskException` event when the Task is finalised. Another issue is that the later Tasks may still be executing when your WhenAll wrapper returns as faulted. If you're depending on it being finished, you now have a bug. If you use `Task.WhenAll`, the exceptions will both be captured and turned into an `AggregateException`, and your WhenAll method will only return once all the passed Tasks have completed.
Thanks very much I will look into this. I think my problem is I don‚Äôt fully understand binding.
WPF can be a handful, but once you get it it's quite nice imho.
[This site](https://wpf.2000things.com) has quite a few useful tidbits.
Do you have any xp running it through IIS by any chance?
Oh nvm I get it now, and it's working. Thanks.
Glad to hear it! üòÄ
&gt; It‚Äôs reliable and does work well. Unless it doesn‚Äôt. And then a fix gets promptly released (a nightly build could be available within 24 hours after reporting the issue). And it works well again. This is a non-starter for a version 4.x product. I don't understand why you would subject yourself to this type of shenanigan for your core infrastructure.
so, you want to charge for your commercial software, but not pay for an opensource library?
Congratulations on the job.
Oracle definitely beats MS in backwards compatibility.
iTextSharp is actually iText 5. iText 7 is the newer version, basically.
For the size of team they have, those results seem pretty reasonable. I would say upgrading every minor release from a mid / smaller vendor is pretty risky. They don't offer LTS releases?
I've only ever published to IIS, so yes. üòÅ
Have you got any conflicting dependencies? I had a similar issue with some libraries recently and it turned out they both depended on different versions of the same package that were incompatible with one another, and the error was essentially the same as what you're seeing.
We moved our e-commerce website's data cache from RavenDB to SQL Server and then to Redis. The purpose of this cache is not for page content, but to store data-intensive intermediate results that pull from various data sources, and need to be calculated nightly, rather than on-demand on page loads. I will admit that we didn't know much about RavenDB and moved off of it due to the team's unfamiliarity with how to run it reliably. The SQL solution was much worse performance than RavenDB. However, the migration to storing all the data in Redis was very pleasant and we've been on that architecture for a couple years now. Redis is really stable and trouble-free as well.
Spent some time using version 2.x, it seemed to have promise back then, but the pain wasn't worth the benefit. Lots of things "almost worked". Issues raised were greeted with a "prove it" mentality. To be fair, we put a ton of data in there, not sure it was ready for that volume of records at that phase in its evolution.
And toolbars
The RavenDB 3.5 -&gt; 4.0 change was definitely a massive undertaking, invalidating a lot of the old documentation so now there are some gaps here and there. I think the article has good points and was generally fair but I would say I don't think they gave enough credit for how much better the .NET API for RavenDB is compared to some of the other NoSQL client libraries. Maybe he's deducting a lot of points for the lacking breadth of LINQ coverage but even still, the Client API is comprehensive, easy to understand and reason about, and downright fun to use.
I know this doesn't translate to deployed size. But it still bothers me. I don't know why. ... Maybe because it took 10 minutes to delete those folders.
Your Anguler and React projects have the node_modules already installed, right? So you should also copy the restored NuGet packages to your Blazor project.
Are you talking about client generators or server stub generators? They pretty much do the same thing and they're easy to swap out.
My main goal is to have typescript endpoint calls, enums and interfaces easily generated from the API controllers.
You can manage NuGet packages for the entire solution in one place pretty easily
Not the point. The point was to delete the downloaded packages, but only those used by the project.
The NuGet packages are supposed to be user session wide. They don‚Äôt get downloaded for each dotnet solution. Windows: %userprofile%\.nuget\packages Mac/Linux: ~/.nuget/packages
Also, if you're comparing client side angular and react, how big is the blazor runtime?
For this to be a fair comparison, you need to include the size of the entire dotnet core runtime and aspnet.
Did you include the fact Blazor needs Visual Studio (multiple GB's) and the others only need VSCode (&lt; 1GB).
You're still missing the point. Well done avoiding it.
The Blazor template doesn't include any NuGet packages. But even a typical MVC or Razor Pages project with numerous NuGet packages wouldn't see numbers like that. I edited my comment above. It's the number of files that's bothersome. Most of them are node modules and include things like "is-number". For me, the number of files is irritating. And that's all I wanted to share.
Not really. I'm just saying I don't like 53k files in my project folder. That's all.
Visual Studio and Core SDK are shared across all projects. I'm just saying I don't like having 53k files in my project folder. That's all.
What matters is the boilerplate payload for the client.
52.7k files that you don‚Äôt really need to manage and can clean out at any time. you should be checking those into source. maybe a better comparison is looking at the size of your repos, number of files, etc.
&gt; I edited my comment above. It's the number of files that's bothersome. Most of them are node modules and include things like "is-number". Well, in JavaScript you don't have such a thing like a standard library. If you want a real comparison, you need to add the source code of the .NET Core framework.
Most of those files won't be added to the repository. They're build artifacts.
Can't I just not like it? It's cool if you're fine with it. But I just wanted to share that it bothers my OCD.
it‚Äôs just the way things are moving. you allowed to not like it, sure, but to me it‚Äôs an odd thing to be concerned about. when I want to clean my node_modules, I shift delete the top level folder (node_modules) and it‚Äôs literally gone in no time.
Swagger codegen can do that from a swagger endpoint or you can use nswag. I'd try them both and pick the one you like better.
you can download them FOR EACH solution. just add a .nuget folder to your solution ;)
When I was looking around for a NOSQL to build on I rejected RavenDB primarily because AFAIK It sits ontop (for the most part) an old version of Lucene.NET. This is why its a bit "black boxy", this is why it corrupts and has the sort of horror stories you get from MongoDB too. It seems to have a very nice client but this reliance on a hideous piece of old tech kills its viability as a tech choice IMO. To be honest when I looked around I didn't really find any real "winners". Mongo has a suspiciously effective marketing team against some old horror stories but is likely the best bet due to its market capture. Couch seems "better" in that its less "sales-driven" than Mongo but large consumers have also moved away to other platforms implying it sucks in given use-cases. Cosmos IMO is likely a solid choice due to the way it multi-models its APIs and is backed by Microsoft but is useless for those that can't cloud. ArangoDB ultimately looked like a very interesting proposition purely because it has a model for dealing with the downside of document databases (linked data) by multi-modelling with a graph db as well. I think I'd still piss my pants though once I move past the single-node usecase with any of those platforms. Do you even ever want to do that with a "single-source-of-truth" (i.e. the typical "starting point").
&gt; Visual Studio and Core SDK are shared across all projects. If you don't want external modules in your project file, install them globally with -g
I know I can but why would I like to? I like how it behaves by default.
:)
Looks cool!, will try.. :)
Been using htmlagility for years. But will give this a try. Looks interesting.
Running the components on the client-side is seamless but your app might not work if you're directly accessing services and databases in the components. WASM is still in the browser and can only really make HTTP calls so you'll have to make sure you get all of your data over HTTP or SignalR if you switch to client-side.
That's an awesome, unbiased, detailed, write up and very helpful. thanks so much !
Green = Winner, Red = Loser
It pissed me off these were all video content
Why? Haven‚Äôt they (this series) always been video?
Because I can't watch videos at work and it's way more efficient to read an article compared to watching a bunch of short vids by those annoying sycophant Microsoft "evangelists"
Looks like you can exclude classes / assemblies via a runsettings file. From https://docs.microsoft.com/en-us/visualstudio/test/using-code-coverage-to-determine-how-much-code-is-being-tested?view=vs-2019 You can exercise more control over which assemblies and elements are selected for code coverage analysis by writing a .runsettings file. For example, you can exclude assemblies of particular kinds without having to add attributes to their classes. For more information, see Customize code coverage analysis.
I agree. I do like the videos to a certain extent, but having an article paired would be way better.
Why not just use PostgreSQL with a jsonb column as a document column?
You know... you can put any video into a website where it‚Äôll give you subtitles, and most of the time at the video link there‚Äôs also a github link... but by all means become outraged at MS instead.
same reason I wouldn't buy a pizza from McDonalds.
[https://devblogs.microsoft.com/dotnet/understanding-the-whys-whats-and-whens-of-valuetask/?WT.mc\_id=ondotnet-c9-cxa](https://devblogs.microsoft.com/dotnet/understanding-the-whys-whats-and-whens-of-valuetask/?WT.mc_id=ondotnet-c9-cxa) &amp;#x200B; In this case, there's a decent blog post linked (but I agree, it's not always there).
Most of the problem I've experienced were on v3.5. Back then, the outlook was so gloomy that I even started migrating the project to another NoSQL DB (it's another long story). At this moment v4 was released and I gave RavenDB a second chance. v4.0 had abetter reliability and new fixes were coming out quickly. I expected that by the time we completely migrate to another DB, RavenDB will become very reliable, so we stayed with Raven. RavenDB has a dark past, but seems its future is going to be bright.
Just started offering LTS. [The latest version (v4.2) is LTS](https://ravendb.net/support). I agree with you risk assessment and I upgraded only out of necessity.
In the article, I rated the .NET integration and Client API above other NoSQL DBs: &gt;Comparing to other NoSQL databases (though, I have modest experience), it seems that Raven‚Äôs .NET client API trumps MongoDB .NET Driver, CosmosDB + Cosmonaut bundle and leaves smaller players like Cassandra (with DataStax C# Driver), CouchDB (with MyCouch) completely out of the competition. Nothing is ideal and our life is full of compromises, and I believe RavenDB is a good compromise. I just tried to stay unbiased and along with all the pros I disclosed cons.
Forget cross platform. They're all messes. About the only legit solution is Flutter with Dart but it's adoption is slow right now. Just go straight native with iOS/Swift and Android/Kotlin. It's not really that much of an effort to learn them both.
There's a linked blog post on the bottom of the video. So I guess your employer doesn't have a pluralsight or degreed account? What your company do for continuous learning?
Check out [Marten](http://jasperfx.github.io/marten/), .NET interface to work with `JSON` fields of `PostgreSQL` database. I mentioned it in [the article](https://alex-klaus.com/ravendb-pain-and-joy/). It's a very interesting project . I implemented a small project with it a year ago and the main downsides are \- A very slow pace of development. See [this feature request](https://github.com/JasperFx/marten/issues/1027) and how long it took to implement it. \- Lack of .NET integration. It's not an ORM and they [don't want to go down that road](https://github.com/JasperFx/marten/issues/1017#issuecomment-395404033). Which at the end leaves the devs with hand crafted query strings and custom solutions for wiring Dapper.
This is one of these questions for which there is no right answer, The important thing is that *you're asking the question*. By so doing, you will arrive at an answer that is right for your project and your coding style.
That is true. I have learned a lot going down the rabbit hole with all these design patterns
I will say this: I don't use Repository pattern anymore. I did for a while, but I've come to the belief that 9 times out of 10, a well-designed Service layer will make Repository pattern do more harm than good, especially since EF already implements Repository pattern.
You're good man. EF already implements the repository pattern. DbContext is your unit of work and each DbSet is a repository. To answer your question as to why it's "bad practice" to use DbContext in controllers though, it comes down to properly disposing the context and unit testing. If you're using dependency injection then you're good on the dispose front as the context gets disposed after every request. Can't help you with the unit testing as I don't do it myself. Bring on the shame lol
Those are all very different data stores. If you needed caching then Redis should've been the first choice all along.
The Javascript issue is because all document-stores (MongoDB, CosmosDB, RavenDB, CouchDB, etc) are based on JSON documents for the most flexibility, with various extensions to support things like date/time formats, 64-bit/big integers, geospatial, binary data, etc. Just because the database is written in C#/.NET doesn't mean it can magically interface with C# code perfectly. It's no different than expecting a database in Go to work with all Go code because there's still an official interface to the data, and in this case it's RQL/Javascript over HTTP. The docs show that the entire query operates over the full JSON document and the projections at the end require Javascript code to format and transform the exact data you requested: [https://ravendb.net/docs/article-page/4.2/csharp/server/kb/javascript-engine](https://ravendb.net/docs/article-page/4.2/csharp/server/kb/javascript-engine) There's really no other way to go from Linq expression trees other than compiling to JS with their current setup. They could probably upgrade their RQL syntax to a more full featured SQL syntax and build the Linq provider around that but it's probably not worth the trade off in effort for such a small team.
RavenDB has a custom storage engine (called Voron) that's very fast. Only the indexes are built on Lucene, and that's solid tech that's used in several search engines like Elasticsearch and Solr. RavenDB also supports graph queries in the latest versions. MongoDB is also a solid choice today after fixing many of their problems over the years, as long as it's primarily an OLTP scenario.
Not sure about your second point there, how is there a lack of .NET integration when the entire thing is a .NET document-store interface to postgres? \] Also you asked for it to store certain properties as relational table columns - something it supports as duplicated data - from a product that is a document-store built on a single JSONB data column so it's understandable that they wouldn't add it. If you had such a shallow data model with just a few JSON properties, why didn't EF work for you?
Swashbuckle is a more modern suite than NSwag. The Swagger/OpenAPI spec can be hosted by either but for generating client code, I still recommend using OpenAPI or Swagger generator tools instead of these packages as they have more development and generate better output. There's also the Autorest generator from the Azure team: [https://github.com/Azure/autorest](https://github.com/Azure/autorest)
I like RavenDB. I seriously want to see it succeed, but it‚Äôs too hard compared to CosmosDB. Stop worrying about replication, and rebuilding indexes or if Voron can handle more than 30 requests a session.
It depends on what you're doing. Are you doing this for yourself? Are you doing this in an enterprise settings? Are you doing this for a POC? Are you putting this to support many concurrent users in a high traffic production setting? Patterns are meant to solve problems. Sometimes those problems aren't really problems depending on your project scope.
you've found yourself in a never-ending architectural hell spiral. I hate when that happens. try this: stop reading about what other folks say you SHOULD do. just make your feature work. after it works, tidy it up JUST A TINY BIT. then move on to the next feature. repeat. it's easy to get lost trying to perfect your design amidst all the contradictions. the problem is that each peace of advice is usually correct in one specific context, but usually not YOUR context. It's called premature optimization when you're playing with designs before an actual pain is anticipated that the design would aid. just get it working, take some basic care with low coupling, high cohesion, and readability, then only get fancy when something has to change.
Sounds like your apps never have gotten to the size and age that you start to notice the benefits. The abstractions you talk about are meant for maintainability, extensionability and testability. If you don't really see the future of your apps to grow to a size where you need it then applying all these patterns are a case of YAGNI. https://en.m.wikipedia.org/wiki/You_aren%27t_gonna_need_it With future I actually mean a concrete point in time when you are going to need it. You have to be able to say 'next year' or 'in three months'. If you find yourself saying something more vague like 'if in three years time my application has grown in size a certain way then I might need the repositories and specifications' then this again is another case of YAGNI. But on the other hand you must understand that when your applications do grow to a certain size that then these kinds of architectural patterns become a necessity in stead of an option. Still you can choose to refactor towards those patterns at some point of time. You don't have to start with them from day one. HTH
My rule of thumb is to use as few levels of abstractions as necessary, and really only add some when you find that it‚Äôs either incredibly obvious that you need some abstraction there or you realize that any test you write for that piece will be very awkward, like you‚Äôll have varying levels of abstraction you‚Äôll have to mock out for instance. Personally, I have no problem using your DbContext in the controller, since your EF stuff already implements the repository pattern. If you find that you also need to make service calls or do some transformations, you‚Äôll probably want to add small abstractions for each of them, like just a service or something. At the end of the day just add abstractions when they make sense and make your life easier. Don‚Äôt listen to other people who say there‚Äôs a ‚Äúright‚Äù or ‚Äúwrong‚Äù way to do it (like the people telling you to use the repository pattern over your EF abstraction) because design is so contextual that it‚Äôs unlikely that anyone who says something like that is actually correct.
These projects are personal projects and will probably never have more than a couple users per day. They are providing research and learning I hope to bring to the table at work though. We use PHP at work and I have been pushing .net hard and I have been researching all these architectural patterns to better hone my arguments as to why .net will scale much easier than the PHP framework and practices we use.
&gt;how is there a lack of .NET integration when the entire thing is a .NET document-store interface to postgres? \] I meant to point to Jeremy Miller's comment that Marten is not ORM and will never be. Saying about "*lack of .NET integration*", I was comparing to the Raven's level of integration. In Marten all DB queries are strings (or at least they were a year ago). &gt;Also you asked for it to store certain properties as relational table columns The subject of the referred GitHub discussion wasn't relevant to my comment, but I'm happy to explain. I liked other features of Marten (that's why didn't use EF) and that thing I asked looked to be a minor extension of its functionality.
Then I wouldn't worry as much about all these patterns. A lot of these patterns are ultimately for maintainability, unit testing, future refactoring, etc. Get what you need done, and if you need to scale things down the road, then you can break things out. If you find yourself in a position where you have to do a bunch of refactoring because you've scaled, then that's a good problem to have. It means your first implementation was a success, and more is wanted. You're more or less in the POC stage, which means rapid delivery is the most important thing.
When I started rewriting the first part of the monolith into a separate app at my company, I started with "as few abstractions as possible". I literally called EF dbcontext and manipulated entities in controller actions. I did a few IQueryable extensions as helpers and few common methods in "base controller" but that's it. Because it was a fairly isolated service with less than 10 controllers it worked pretty well.
same dilemmas here. I've ended up with unit of work... i know ef is a unit of work too etc, but Im ok with it. I inject unit of work into controller and use that... I then bundle any specific trickier queries into the specific repo class that needs it so in my controllers can do _unitOfwork.Products.GetSpecificBasedonX(param1) etc...
Perhaps I should have clarified in the article * Storing data in JSON doesn't require to use JavaScript to use it. .NET has JSON libraries, which can map data types (DateTime, etc.). * I understand that Raven is targeting a wider audience, not just .NET devs. And JavaScript engine is intended as a common ground well known for all devs.
Oooo sweet! I've been pulling my hair out trying to put my vue app on IIS.. my app shows blank when hitting browse and from what I understand, npm run build creates a dist folder that you place as the path in IIS but I don't see a index.html generated when building it :/ only build, build.js and an image file.. am I going crazy to think it should be there? This project doesn't use a vue router since it's a really simple front end to one of our endpoints but nothing seems to work on IIS and everything works fine with npm run dev
awesome, can we see the repo? üò±
That's not quite how it works. The data model and interface is JSON. The on-disk representation is part of their Voron storage engine and they have their own proprietary JSON library to handle the parsing but thats all internal. Querying is an extension of the data model so you have to be able to serialize the query into something that understands that model. They have RQL for simpler stuff but projections use Javascript because that's what naturally works with JSON and, like I said, it's probably not worth the effort to extend RQL with all the typical relational logic. There's no other way to transfer serialize and transfer expression trees with all the edge cases unless they serialize the actual LINQ syntax as C# and then run a C# engine inside, but that's probably even more work. ComosDB has recently gotten much more SQL coverage but it even took them several years and they're a much bigger team. Query syntax and data model is just a very hard problem to deal with.
Honestly, as much as I love C#, PHP has improved a lot! You need to use the right frameworks and libraries, OOP and a rigorous approach. If the project is large, it might not be worth it to switch. Switching to .NET will not solve your architectural or other problems. You can write crap in any language. You might be experiencing a lack of functional or structural quality at work, tackle that instead! Test at varying scopes, refactor, analyze complexity and code smells and work out a plan for quality control. Composer, symfony, phpunit, infection, behat, phpmd, psalm, stan can help with that. Lastly, if you are the only one using .NET, it could be an expensive decision to switch: educating existing developers, hiring new ones, migrating systems...
You're not going to measure any real difference using localhost because it has pretty much unlimited bandwidth and no network latency/jitter.
This kind of post really motivates my inner self. Thanks for sharing!
I bet it's web scale.
Is this open source?