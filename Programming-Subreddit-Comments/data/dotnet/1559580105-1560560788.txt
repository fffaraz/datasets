You seem to be basing your answer solely from consumer product software. Xamarin, for example, is very popular in domain-specific business software, and is extremely successful. So much so that they've expanded their development with the upcoming .net 5. Also, Java swing is incredibly popular for business applications, especially internal. JavaFX isn't as nice as WPF, but it's surprisingly close. By the way, Discord is built in React native for their mobile targets, and it's probably one of the most well-made mobile/desktop/web apps I've ever used, from UI to UX to features.
AvaloniaUI has an extreme lack of documentation and support, which is why it really can't be used in big apps. I've used it before. It's a pain in the ass. It will work perfectly fine for small apps that just need some basic controls, as long as you don't need it to look exceptionally pretty.
I tried enabling all "Common Language Runtime Exceptions" in the Exception settings before posting, VS is not catching the exception.
Yes and yes. Search for job activator and hangfire inmemory storage.
Lol I think you're arguing with yourself mate. I didn't dispute any of that.
&gt;See Xamarin/React Native/Qt. Why aren't they more popular? &amp;#x200B; Actually React Native is one of if not the most popular tool for creating mobile apps lmao
[learnrazorpages.com](https://www.learnrazorpages.com/) Nothing stops you from using using Babel to transpile your scripts. Just add a [post-build event](https://docs.microsoft.com/en-us/visualstudio/ide/how-to-specify-build-events-csharp?view=vs-2019) to run any of your npm scripts and you should be OK.
There is a Thread being used for the core program not a background/ThreadPool thread to keep the program alive. It is good to know async Task Main in C# 7.x will generate code to wait.
Interesting...would this provide similar functionality to the Diagnostic features found in VS Ent but missing in Pro?
I am mixing async/sync code and don't see why that is bad, aside from when an Async method is available. I'd like to understand you. Why is using async and sync bad? I skimmed the link you provided, that bad mojo the author discusses is blocking threads which I agree would be bad practice in async nor synchronous code. I'm not doing that. BTW, using OpenAsync() had the same exiting issue and I was calling Open() just to get the program further along and just left it as is in the OP.
Elmah on steroids with proper tooling? Yes pls! I'll be taking a poke at this.
Pretty much, yeah. :-) Especially time travelling is our favourite.
&gt;Thank you! The solution is not perfect, but it is a way to learn.
Bit of a "how long is a bit of string" question, but how much data does it collect over time and where does it put it? ANTS creates a lot of data in a relatively short period of time for example. How detailed is the data? Final one, what is the performance overhead when collecting data? I might have a poke. We have security policies which will probably exclude our use, but I'm always happy to know a new tool I can recommend to people :)
You said the sync version should be fine, I'm saying it's not...
Does the Sql Server on Azure have any particular firewall settings? Under Sql server -&gt; firewalls and virtual networks. Are there particular Ip addresses which need to be added there?
Until you understand why experts recommend a practice, it's better to follow it until you can explain why you're OK to ignore it in a certain context. Blocking is especially bad when you mix sync and async because you can cause a deadlocked situation where the continuation of the async method where you are blocking could only proceed if you await and return control up the stack. You end up blocking on something that's waiting for you. So it's not bad in the "could cause choppy UI sense," it's bad in the "take down your app" sense. &amp;#x200B; Is this a web app, console, or what? Any way you can share the whole project on github or somewhere? It does sound like you have the "async void" problem others are describing. There's no exception anywhere, just the first time you await you're returning control all the way up to a main method that isn't being awaited.
Can you stick a breakpoint where this top call happens, and then share a capture of the callstack? Let's see what's at the bottom. Basically, what code is awaiting this code: &amp;#x200B; &gt;var companyList = await Company.GetSavedCompanies(connStr);
Yeah
There's no HostedService support in .NET Framework :'(
I'm gonna plop a +1 here because: With Framework i can copy/paste a WinForms app over to Linux for the last decade and it just works, thanks to Mono. With .NET Core 3.0 we get WinForms back... on Windows. Howbout .NET 5, "bringing it all together" or what have you. Hmm... I'm thinking more like bringing most of it together, and sweeping that cross platform UI option under the rug. (As shat on as winforms may be, it's had that going for it.) /minirant
Interesting suggestion since reading about what that call does was a good learning path for me, but unfortunately the additional call didn't solve the problem. It is a Console app. Maybe the console app threading model in .net core changed from .Net Framework? As you may know, Npgsql is nulling the SynchronizationContext just so we don't have to make that call. But I'm not confident that code is working as expected. Having the issue caught under a debugger would be helpful.
Thank you all guys! I will gonna use Quartz or Hangfire after some tests. If someone knows more solutions, please comment to keep documented here.
The DbDataReader method you are calling returns a task - it is your responsibility to catch any exceptions thrown by the DbDataReader.
It's not more popular than native Android/iOS and most probably never will be. Even though it costs more to develop on both platforms they're still more popular.
Oh cool I didn't realize it as simple as that. Thank you.
Be aware of Hangfire license being either LGPL v3 or commercial - the latter requires a yearly subscription.
Hmm OK mate. You're still arguing with yourself. You strike me as one of these types who likes to have the last word so please show me where OP's code throws an error or deadlocks. Which was *my point*...
Lets get back on track. As the OP states, it is a dotnet core console app and async void is not being used.
Understood.
So this is what the material design devs have been working on for the past 6 months.
Ah, my bad I missed that this wasn't Core.
This site renders so badly on mobile.
Why do you create new account to repost the same repository every month and delete/ignore all criticism? Are you just fishing for github stars to look good in your portfolio? https://old.reddit.com/r/csharp/comments/bvzjyw/architecture_net_core_22_c_aspnet_core_entity/ https://old.reddit.com/r/aspnetcore/comments/arae5h/architecture_with_net_core_22_c_aspnet_core/ https://old.reddit.com/r/programming/comments/aypkek/dotnetcorearchitecture_ddd_example_with_new/
This is pretty cool, definitely some good principles at work here. Is there a particular reason you went with the repository/UoW pattern on top of EF Core? I know the court of public opinion is still in session on this, but I fall into the pool of not including either strategy in my projects due to the nature of DbContext and DbSet effectively already implementing both.
Irrelevant
The purpose of the repository pattern on the Entity Framework is to facilitate very common methods, such as GetById, List, Add, Update, etc. In this way, it is possible to maintain a standard of names and implementations by everyone who is working on the project. The biggest problem of the Entity Framework are queries made in an unoptimal way, and with repository pattern, the problem is almost reduced. It also avoids duplicate code and facilitates possible improvements in a unique way.
Why would you take something blissfully not Google... and plaster Google onto it? Case in point, this website took like 40 seconds to load on a desktop with a 300 Mbps connection.
No, the Azure one is completely open due to the ongoing tests (I can connect to it from anywhere). We also ruled out any profile level weirdness since it works for the same user on a different computer. It seems to be device related but we cannot find out what is special about these machines.
Thats really strange. 1-2 sec to load.
You don't know if it would deadlock because you don't know the context it's used in.
Can you show your main method?
What exactly is a type class, please explain?
How ?
If it's not prohibitively heavy, then it might at least be good to go in your testing environments. ? Just a thought. I have the same questions though: how is this magic achieved and what are the implied costs of the overhead?
It's a site for documentation, how programs on their phone?
Loaded basically instantly for me...
The overhead for snapshot/crash-recording is consistently sub 10%, and for constant recording varies depending of how much data is being processed and stored - we do record and inspect lots of data - changes to variables values, all of the non-deterministic stuff, method calls, etc; after post-processing what you get is basically line-by-line recording of what your application have done under the hood. There are also ways to configure what is being recorded and what's not so you can quite easily make it as fast or as lean as you need to. The recording does not leave premises/cloud you control - it is not being sent to us and we do not have access to them - hope this is at least a good start of addressing your security policies. Would gladly learn about your environment on a remote call if that's possible - you can reach me on the private message.
instant for me and I've only got 200 Mbps.
It seems comprehensive, but I am so over Material Design. Delineate and put more than one colour in (not you specifically, just the general UI community who have lapped this crap up).
Ok, I'll have a poke around then :) Yes, if I found out it was sending anything to you I'd be extremely pissed off. we do have monitoring of that sort of thing. Let me have a play first, and later we might chat. I'm only with the company a few more months, so if it has value I'll hand it over.
People read reddit on their phone. Why not take a few minutes and test responsiveness before publishing it to a forum?
I'd give it a go locally first, and then see from there. I know it's remote, but I should be able to get some idea on my work laptop. Damn, I forgot to ask if it works in Linux Docker containers. That would exclude it immediately if it doesn't.
Try making TrustServerCertificate=True. Had the same thing today connecting using ssms.
Ok, I will begin with Eric evans book. I found some resource with .net core but not for a beginner with DDD...
&gt; The biggest problem of the Entity Framework are queries made in an unoptimal way, and with repository pattern, the problem is almost reduced. Care to elaborate?
0.6s with no cached resources.
To roughly explain, it's like interface for type parameters that happen at compile-time. That means, you could enforce a type argument (of your generic types) to satisfy like ‚Äúit should have a constructor that takes something or other‚Äù or ‚Äúit should have a static method that returns an instance of it.‚Äù As like interfaces describe shape of instances, type classes describe shape of types. FYI the term ‚Äútype classes‚Äù are coined by Haskell, and the mostly same thing is called ‚Äútraits‚Äù by Rust and ‚Äúconcepts‚Äù by C++ (I'm not sure if the ‚Äúconcepts‚Äù proposal is already accepted by C++ standard though).
MVC was the in thing before SPA frameworks like Angular and React came along. Now it is outdated. Frontend is going to communicate with a .net core API or graphql project. Apart from "hello world" you are not going to need to study MVC if your focus is on SPA apps.
Solutions are never perfect, development is like chasing the horizon.
It depends on what that query should return but I have also ran into these issues with very complex actions. Sometimes you just need to crack into SQL and write it yourself, this provides some flexibility and control to achieve that.
&gt;You are welcome!
Is the backslash in Trusted\_Connection intentional?
I do understand how repository pattern can be useful. I'm just trying to see if OP can explain their reasoning. It's not enough to know about patterns, you also need to know when to apply them and when it's just overengineering. Many parts of this repo were discussed already but instead of engaging into discussion, OP discarded all criticism and acted like it didn't happen by deleting reddit account. A month passes and this repo is reposted again, each time new account pretending it's something new. It simply looks like someone farming github starts to make it look cool on their resume. There is little value and it's mostly a salad of buzzwords and bunch of overkill patterns to prove that you can execute all the right things for the wrong reasons. https://old.reddit.com/r/aspnetcore/comments/arae5h/architecture_with_net_core_22_c_aspnet_core/ https://old.reddit.com/r/csharp/comments/bvzjyw/architecture_net_core_22_c_aspnet_core_entity/epuiqdd/ https://old.reddit.com/r/programming/comments/aypkek/dotnetcorearchitecture_ddd_example_with_new/
Yes, but we must always consider all the people of the team, and it is possible to have juniors. So if you can direct the code to follow a pattern, it is best. But it is just a matter of approach, one way or another will work out.
You are right!
You are completely wrong. The goal is to help and collaborate with the community. And what are you doing to help? Causing hatred and discord? I believe you have something good to do. Or am I mistaken? If it does not help you or you know everything, just ignore and be happy.
Alright, I'm spreading hatred, discord and being an idiot just because I pointed out that you don't respond to anything but praise. If you want to learn and share your adventure with others - show them HOW you learned. It's easier for other to learn and see how the project improved if you didn't pretend to be a new person with a rewrite of the commit history every month. &gt; collaborate with the community Best way to collaborate is to have an open issue tracker and improve together with PRs. It's a great tool to see what is the reasoning behind the changes.
Thanks I have done that and the correct items are selected. I can see the data begin passed correctly but what I did, the deduction is correct. The for each loop is deducting the sum of the quantity purchased from each quantity bought I did this &amp;#x200B; var productIds = sales.Select(t =&gt; t.productId).ToList(); var result = _context.Products.Where(t =&gt; productIds.Contains(t.ProductId)).ToList(); var quantityPurchased = sales.Where(c =&gt; c.QuantityPurchased == c.QuantityPurchased).ToList(); foreach(var items in result) { foreach(var quantity in quantityPurchased) { items.Quantity -= quantity.QuantityPurchased; } } &amp;#x200B; I am still leaning C#
 var quantityPurchased = sales.Where(c =&gt; c.QuantityPurchased == c.QuantityPurchased).ToList(); This line has the same issue the previous one did. what this line is currently doing is going through each sale item and saying if ( "my current quantity purchased" equals "my current quantity purchased") then pick it and put it into this list. I'm guessing Products contains an inventory level and thats what you want to deduct right? If so you'd want to do something more like this var productIds = sales .Select(t =&gt; t.productId) .ToList(); var products = _context.Products .Where(t =&gt; productIds.Contains(t.ProductId)) .ToList(); var quantityPurchasedByProductId = sales .GroupBy(t =&gt; t.ProductId) .ToDictionary(t =&gt; t.Key, t =&gt; t.Sum(t.QuantityPurchased)); foreach(var product in products) { if (quantityPurchasedByProductId.ContainsKey(product.Id) { product.Quantity -= quantityPurchasedByProductId[product.Id]; } }
Avalonia.UI is used successfully in the Bitcoin community for a wallet software. (https://wasabiwallet.io) Maybe the devs, /u/nopara73 or /u/lontivero can tell about his experience at it.
When in mobile, the top bar overlaps with the top right icons. Also, when opening the side bar it's almost impossible to read anything on the right bar and yet it still displays the right bar?
Better than deploying self-contained, just log in to the Azure portal and go to the App Service and enable the Extension for .NET Core 3 support.
There's nothing about Material that mandates usage of a single colour. It actually actively promotes the use of a primary and secondary colour, on top of any variants. See https://material.io/design/color/#color-usage-palettes Seeing what most developers manage to do with UI and UX when left to do their own thing, I'm very happy to have a standardized approach available.
Pretty excited for this. I‚Äôve been working on a greenfield Angular application at work where we leverage MD and flex layout heavily. This is pretty huge!
Besides the literal html, a single file is technically possible. Just because you can though doesn‚Äôt mean you should. Separation of concerns is important not only for functionality, but for scalability and the ability to work on the project as both a creator and contributor. I‚Äôd look into Microsoft workshop ASP.Net Core MVC development from scratch videos, they really emphasize all of these points.
Perhaps you should actually investigate why instead of just complaining. Also, the site loaded instantly for me on a mobile phone.
That's right. Next time I will do better for mobile.
Is that your final answer? :) &amp;#x200B; "Hangfire is **completely free** even for commercial use. Subscriptions below allow you to use additional options while ensuring the project will stay here for years to come. "
Nahh, jokes. Its free even for commercial use.
This is only really useful/needed for previews that have not been released yet (i.e, by the time Preview 5 is publicly announced, the repo is working on preview 7 already), aka the nightly builds. For publicly announced previews, the ASP.NET Core 3.0 extension for App Service is always updated within minutes or hours of the public announcement. FDD reduces the deployment and publish times, and when working with an app in development I think the shorter deploy times probably help. Anyway
Your post has been removed. Self promotion posts are not allowed.
Azure App Service supports Linux and Docker both, including multi container apps and what not. https://docs.microsoft.com/en-us/visualstudio/containers/deploy-app-service?view=vs-2019
The hamburger menu on the app bar has 1-2secs delay before opening and closing.
This is one of the biggest reason I'm hoping Blazor gains traction as it eliminates a lot of duplication like validation. It compliments MediatR quite nicely as well, you setup a validation pipeline for the request classes (using FluentValidation in my case). And use MediatR on both Client and Server and let the DI container resolve the appropriate handler (when on Client-side it'll call the handler that calls the appropriate endpoint via `HttpClient` and if on server-side it'll resolve the handler and services to complete the request). Both share the validator classes on a separate assembly and both runs through the same validation pipeline registered on both ends to make sure validation is done both sides without much effort. It feels pretty great.
&gt;as long as you don't need it to look exceptionally pretty are WPF apps ugly?
I just checked out Heroku, it looks great, i might go with them thanks
You can get away with two files: [https://pastebin.com/WeriG7Nn](https://pastebin.com/WeriG7Nn) More realistically, there is an "Empty" template in VS. It's not entirely empty, but it's very thin.
I do. My gov dev machine is pretty locked down. Instead of logging between two machines, it's sometimes easier to pull up to docs on my phone. So there's your use case. Now stop being a shitty dev.
It does! Let me know if you need any help. :)
I love that comparison. ;) But we have a huge deal of respect for Elmah as well.
***mobile first dev docs***
Yeah, but their advice is to use a primary colour and a secondary sparingly. I get what you're saying about a common approach to UX. I just wish it wasn't material.
I think to make the translation to the real world you should give a weight to each step. If you do that in seconds you can have a real world estimate in seconds. The .net benchmark isn't really applicable to the real world.
Let's not [store passwords in plain text](https://github.com/rafaelfgx/DotNetCoreArchitecture/blob/master/source/Database/User/UserEntityConfiguration.cs#L34), even in examples and such.
I totally missed that the extensions existed. You are correct they are a great option to handle official previews.
That is something that Reddit's editor inserted, the connection string has no backslashes.
Thanks for helping me out This code var productIds = sales.Select(t =&gt; t.productId).ToList(); var products = _context.Products.Where(t =&gt; productIds.Contains(t.ProductId)).ToList(); var quantityPurchasedByProductId = sales.GroupBy(t =&gt; t.productId).ToDictionary(t =&gt; t.Key, t =&gt; t.Sum(t.QuantityPurchased)); foreach (var product in products) { if (quantityPurchasedByProductId.ContainsKey(product.ProductId) { product.Quantity -= quantityPurchasedByProductId[product.ProductId]; } } This work, there is an error here t.Sum(t.QuantityPurchased)) I am getting an error saying : IGrouping&lt;int, Sale&gt; does not contain a definition for QuantityPurchased and no accessible extension method method QuantityPurchased accepting a first argument of type IGrouping&lt;int, Sale could not be found Intellisense is not giving anything pertaining to sales. I have tried everything I couldn't go further
Tried that but no luck. Thanks.
Thank you for pointing out the other options we have available. I need to learn to not use words like "no option" in blog posts.
Oops my bad I wrote that on my phone. It should be t =&gt; t.Sum(u =&gt; u.QuantityPurchased)
How is HTML not graphical?
Vanilla ones are. But WPF has a much much more robust styling mechanism than Avalonia.
Thanks Its working now Can you please explain this line in plain word sales.GroupBy(t =&gt; t.productId).ToDictionary(t =&gt; t.Key, t =&gt; t.Sum(t.QuantityPurchased)); Thanks
They're expecting him to build a desktop GUI application. That's what you do when someone asks for a C# visual application. It's probably a visual programming class.
&gt; who programs on their phone? dO yOu guYs nOt hAVe pHonEs?!?!
If you run from a console with \`dotnet run\`, if there are any exceptions they will be written to the console. I still think there aren't any exceptions and your program is just exiting early because you aren't actually awaiting all the way at the top of things.
Could have used Linq to reduce the amount and increased the readibility of the code. The SplitBySomething() methods can be oneliners.
Yes, it's completely free for commercial use under LGPL v3 ... https://github.com/HangfireIO/Hangfire/blob/master/LICENSE.md &gt; Commercial License: Subject to the **purchase** of a corresponding subscription, you may distribute Hangfire under the terms of commercial license, that allows you to distribute private forks and modifications. Emphasis mine.
I have been working with .Net MVC 5 for just over 2 years and my last project is on .Net CORE MVC because I'm pushing my company forward and can pick tech stack. &amp;#x200B; Anyone that has dabbled with code is ready to get a job. Just go interview be honest about your capabilities. Many employers respect people that may lack knowledge but are just honest about what they know and what they struggle with. It shows you won't be a pain in the ass, and won't sit quietly for months then say "Hey, I have been stuck on this for months". Just go interview and don't get too defeated if you don't get a position. Just try to get feedback and always follow up. &amp;#x200B; I can say that interest in me really spiked up after I edited my resume, and added things like use of dependency injection, unit testing, layered architecture, separation of concerns and working on mission critical applications. I would send resume out and get invited to interview the next day. So, you should want to get familiar with these concepts, once you pretty familiar with the framework.
I got it! "Loading Related Data".
Thank you sir. Your comments give me a lot of confidences.
Make sure you are using the latest version of Rider. Also the WinForms designer only works on Windows. If you are using Mac or Linux you are out of luck.
Yea I am on windows and have the latest version. It is just no where to be found.
In Rider when you create a WinForms project when you first open Form1.cs if you look at the bottom of the editor you will see 2 Tabs Design and Code. It defaults to code. If you click Design it will switch to the Form designer.
So when I start a new project I don‚Äôt see an option for winforms project. I only see ASP.NET Web Application.
This is what I see https://i.imgur.com/y6JIreN.png
&gt;You said the sync version should be fine, I'm saying it's not... Exactly. One minute it's not fine the next you don't know. So you're contradicting yourself. &gt;You don't know if it would deadlock because you don't know the context it's used in. Actually I do. To put this to bed, `GetAwaiter().GetResult()` could deadlock when it's used in a one thread at a time context. **There's no `SynchronizationContext` in .NET Core**... hence me saying it should work. In hindsight, it *will* work. &gt;The first and most obvious consequence is that there‚Äôs no context captured by await. This means that blocking on asynchronous code won‚Äôt cause a deadlock. You can use Task.GetAwaiter().GetResult() (or Task.Wait or Task&lt;T&gt;.Result) without fear of deadlock. https://blog.stephencleary.com/2017/03/aspnetcore-synchronization-context.html
Most of the bigger companies tend to use job recruiters. Usually I just put my resume on the bigger sites like Indeed and Monster and let them find me. If you have some place specific that you want to get into finding the correct recruiter helps or applying directly with on their site also works. Where are you located at?
Start at the beginning. Get a book on WPF. Pro WPF 4.5 in C# looks good. WPF hasn't changed that much so the book will still be relevant today.
Linkedin is best because they can see your real work experience directly, and it's only that what matters really.
Pluralsight if you can afford it. It has great resources.
make sure you also look into the MVVM pattern.
First of all. XAML programming and especially WPF programming is very different than Web programming. And not to offend you but probably the best UI programming stack at this moment is the HTML/CSS/JavaScript stack. If you want to get started with WPF then you should familiarize yourself with the MVVM pattern. If your UI grows just a little bit beyond the most simple apps then this pattern will help you very much. A good starting point is the use of the MahApps library. (HTTPS://MahApps.com) This way you can quickly get started. It has nicely styled controls, an icon library and great documentation. And it is an open source project. A big difference between winforms and wpf is the way you get your data in your UI components and get the UI events into your code. This is done using data binding and the INotifyPropertyChanged and INotifyCollectionChanged interfaces. If at all possible find a MVVM framework that you can use in conjunction with MahApps that has a good implementation for ICommand and syncing the property changed events on the UI thread so that you can easily do work on background threads. You can probably use the MVVM light framework. Starting this way reduces your need to become a WPF expert before you can start building your first app. And please do not try to use the visual designer to layout your controls. This works for winforms based development but it really sucks for wpf development. Good luck!
Group by is a method that will reduce a list of items down to a list of groups where the key is product id and the value is a list of sales objects that have that key. Then ToDictionary lets us make a fast look up by key to get the value. The value in this case is the sum of the quantities sold for the current grouping we're dealing with. If you want some plain English examples go-to Google and search "dotnet perls (dotnet method name)" and you should get what you need.
Typical recruiter logic though: "I need to fill a principal engineer position for a financial company with their codebase written in Java... Hmm this person has 10 years experience writing embedded C and designing schematics. Perfect match!"
Linkedin, the ladders, I‚Äôm in Austin so a really good one is BuiltInAustin which is a bunch of direct ads from companies(mostly startups). Stack overflow also has a job board.
Hey, really nice app. One question though, if I'm replaying something to find what caused an exception and I have a List&lt;string&gt; it will show in the replayer as "List`1" Is there a way serializing or exploring the object in more detail?
No exceptions being thrown does makes sense. Even with the trusty Windbg, nothing is being caught except unrelated first chance exceptions. Running from the console does not show an exception nor does running the same code in a .Net Framework console app.
Hey man, I haven‚Äôt forgotten about you. Tutorial is coming in the next day or so.
Hey man, I haven‚Äôt forgotten about you. Tutorial is coming in the next day or so.
I do a mixture of LinkedIn, Monster, and Glassdoor. They all are filled with terrible options, and Monster especially has a slew of recruiters gunning for you, but the thing is that they are all trying to get your attention. You get to pick, instead of you going to them asking for a job. The best jobs you'll have to wade through a lot of garbage to see. You might also just check companies' websites. They often have their own jobs posted. If you know of a company in your area, or just one your interested, take a look.
Just wondering, does this work with F#? Google doesn't seem to turn up anything.
[stackoverflow.com/jobs](https://stackoverflow.com/jobs) [weworkremotely.com](https://weworkremotely.com) [www.keyvalues.com](https://www.keyvalues.com/)
Have you found a solution? I can‚Äôt believe the lack of documentation around SSR with Angular and .net core
Not a fan of putting the angular app inside the api
A WPF application without MVVM can turn into a real mess and very quickly.
Shit mod.
Oh wow, I'm in Austin too and had never heard of BuiltInAustin. Thanks!
I prefer dapper to using the efcore fromsql, much faster, tho depends on your needs
there are a lot of online courses, but for paid, not free. But I met sometimes (rarely) online teach sessions in YouTube. Also sometimes it's possible to ask some YouTube blogger to make such online session. But you can always ask questions on stackoverflow, here, on Quora, Microsoft forums, etc.
Check out Exercism (https://exercism.io). I haven‚Äôt done the C#/F# tracks (VB isn‚Äôt offered), but the tracks I am working on have been wonderful.
I haven't used Rider before but it sounds like you are missing some project templates. Are you sure you are using the latest version? It seems that they added WinForms [only recently](https://blog.jetbrains.com/dotnet/2019/04/26/developing-windows-forms-applications-rider-2019-1/), on the release 2019.1.
Do you have .net framework 4.x installed or .net core 3.0?
https://docs.microsoft.com/en-us/learn/
awesome thank you!
DebugView uses a very specific mechanism to collect the logs. It is based on global wait events which control the behavior of the OutputDebugString - have a look at [this excellent article](https://www.codeproject.com/articles/23776/mechanism-of-outputdebugstring) to learn more. The code is in C++ but you should be able to port it to C# (or check available code on GitHub: [https://github.com/search?l=C%23&amp;q=DBWIN\_BUFFER\_READY&amp;type=Code](https://github.com/search?l=C%23&amp;q=DBWIN_BUFFER_READY&amp;type=Code)). The reason why your Trace logs appear in the DebugView output is that the DefaultTraceListener uses OutputDebugString internally. I spent some time learning how it is implemented so if you find it interesting, please check also [my post](https://lowleveldesign.org/2018/01/08/few-facts-about-outputdebugstring-and-default-settings-of-the-system-diagnostics-trace/). As you will see in the post, the DefaultTraceListener is not really an optimal way to collect the traces and I would highly recommend using something more efficient, such as Event Tracing for Windows. It is fairly simple to create a trace session with the help of the [Microsoft.Diagnostics.Tracing.TraceEvent](https://www.nuget.org/packages/Microsoft.Diagnostics.Tracing.TraceEvent/) package. Check the [Vance Morrison blog](https://blogs.msdn.microsoft.com/vancem/) to find lots of examples how to use it.
This project is an example. Angular app is inside the api to facilitate for beginners. In the documentation is explained about this and other practices for a real project: Some features and practices were made to facilitate learning and make the architecture as small as possible. For a real project, consider the following: Do not use technologies and features that are not necessary. Use DDD concepts, such as ubiquitous language, to express the domain. Use Identity Server for authentication and authorization. Separate ASP.NET Core API and Angular in different projects. Apply CQRS with two databases (reading and writing) if the main purpose is performance. Apply SignalR for real-time communication, avoid calls every x time. Apply a message broker, such as RabbitMQ, for asynchronous and parallel processing.
Your post has been removed. Self promotion posts are not allowed.
Not yet. :)
You will be able to see elements when iterating through them.There is also mechanism that allows you to choose serialising method for any type you wish. in "C:\Users\{USERNAME}\AppData\Local\RevDeBug\default.rdbdisplay" file you can add line with: FullyQualifiedName-PublicMethodOrPropertyName e.g. ConsoleApp1.Foo-GetBar Unfortunately this option is not available for generic and indexer types right now
Thank you for the answer. Amazing tool.
Thanks for the answer. Amazing tool
You, sir, just have put a smile on my face. Thank you!
Another stolen video. The original is from Bob Tabor.
As /u/NicolasDorier [noted](https://old.reddit.com/r/dotnet/comments/bw97yk/what_are_the_drawbacks_of_using_avaloniaui_for_a/epy3nyp/) we built our cross platform software with Avalonia and we may have the largest userbase with that platform ([~10,000 users](https://www.somsubhra.com/github-release-stats/?username=zksnacks&amp;repository=WalletWasabi)) so we have a fair amount of user feedback on a variety of environments, but first I start with your questions. &gt; It probably wont have any problems with a very basic app that i need to make but i wonder, what are the disadvantages of using it for big apps? Is it not ready-yet? Will it ever be "ready"? I don't think there are many things needed to fix up in order to make it non-beta and stable, but I Avalonia devs concentrate on adding new things, not on not breaking API. However as you can see with our software, it's not that hard to achieve a stable app with Avalonia, it's just you have to deeply test everything on every platform every time you decide to upgrade to a new release. &gt; Also if some people can in their spare time make this in their garage why cant Microsoft add their own version of multiplatform gui for .net-core? I've been waiting for this since .NET Core 1.0, but Microsoft is alarmingly silent about desktop development and .NET Core. I guess they don't see desktop apps to be the future. However .NET Core 3.0 will have some really good things in it, so let's hope for the best. Generally I found .NET Core to be more lacking than Avalonia. Packaging, having icons, hiding console, assembly info and and similar convenience accessability and vanity features are non-obvious to get right on different platforms and these are the areas where I needed to do the most hacking. &gt; And last question, is it better(less RAM Hungry hopefully) than Electron? Hell yeah. I've used Electrum in the first iteration of my software. It was a huge pain. At least in Avalonia if you have an issue, you can fix it, because it's C#, when I had an issue in my Electrum app, I learned how to live with it, but of course it depends on your JS skills I think. One other interesting thing I noticed is that my Electron app was attracting a host of low quality contributors to my GitHub ("yes, it looks great what you did, but no, you can't just add these 500 npm packages to a security critical application") and generally I had spent a lot of time to review these contributions, I think it's because in the web stack patterns come and go. In general, I'd say use Electron if you love the web-stack and if you want to pay cheap web-devs to hack together something for you quickly. If you want something performant, stay inside C#, familiar with WPF and Reactive Programming and build your app for the future, then you may want to choose Avalonia.
Codecademy has recently introduced a [C# course](https://www.codecademy.com/learn/learn-c-sharp). Check them out but don't let your expectations get too high: the JS/React course I took with them recently was riddled with inaccuracies. On the upside, they let you into their Slack channels where you can interact with other students, and get help from moderators.
Exercism is great as a concept (I love that their exercises come with tests that you need to make pass) but implementation is kind of doomed. They rely on volunteer mentors that are not very reliable and are in hard demand. I went through most of the C# track late last year, and while waiting time for mentor review on obligatory exercises was usually a few days (me being in Europe and my main mentor being in New Zealand didn't help), I think I'm still waiting for review on some of the side exercises that are most challenging. They may have reinforced the C# track with more mentors but if they haven't, just don't expect to get mentor feedback too soon.
"Standing on the shoulders of giants" is cool when you add something, if you are not adding and just parroting the information to get it more exposure that should be ok.. I get your point though, that if there is channels where it is just parroting and not additional add in then we should filter it, and make it for the people who work hard to write and review new content.
First, completely agree on what most people have told you about MVVM. Second. About learning WPF, at the time, my approach was the Charles Petzold book "Applications = Code + Markup". I really love the book. However, a caveat. It's focused on explaining the guts of WPF, and thus it's not a really good tutorial on how to get working fast with it. But I believe it's awesome.
I will look into that, thank you very much !
Very much obliged man!
Firebase
perhaps some auth as a service provider such as auth0
If you take the default options and just let .net scaffold every thing, it's pretty much plug and play. You could always set it up to use 3rd party authenticating then you only have to worry about roles.
I guess you meant Electron, not Electrum(typo)
I'm using Firebase for auth in a webapi and it works good. Very simple to implement.
Useful article! Thank you!
Just have the auth done by EF and identity and do the rest with Dapper
Yes, thanks.
I have to say that I'm pleasantly surprised by the changes. This actually does address most of my non-fundamental concerns about EF Core. Still, I feel sorry for the people who have to deal with the fallout from all of the changes.
&gt; WCF has made a much better showing this time around using the more representative network binding. gRPC is still a tiny bit faster, but we‚Äôre only talking 20Œºs (that‚Äôs microseconds, or millionths of a second) difference now. The memory allocations are much closer as well; WCF is only allocating about three times as much memory as gRPC instead of nearly 20 times as much from the previous test. Interestingly, gRPC actually causes twice as many heap allocations as WCF, but again, the actual numbers are tiny. Both are better than their counterparts from the previous test.
I really enjoy [exercism.io](https://exercism.io) for challenges, but that's not really like a classroom type environment. Also, I'm more interested in learning real world work usages. Reading/writing to databases, and creating web apps, etc. And yes, as mentioned, I an get all of that through videos but I simply don't learn well that way. I also have a very hard time retaining that information. Thank you for the suggestion :)
Happy to pay for the type of environment I'm looking for. What I would really love is to find a college had a .NET path. I have yet to find one though. They are all general CS paths, which I don't need. I already practice solid, am familiar with most design patterns, and have done Java/C++ applications for many years. What I'm not familiar with is things like web applications &amp; database interactions &amp; really all the other stuff that happens in the workplace.
Thanks, I'll give it a look.
It could be worse. Experience has taught us to not rely directly on a context, so hopefully it will be isolated to a specific "layer".
I agree that recruiters are not always the smartest bunch but I can guarantee you that I live and work in a top world financial center city and that the recruiters calling me for Finance sector jobs offering well into 6 figures know what they are looking for and the above won't really happen.
I love me some Dataflow. The setup is a bit non-intuitive, but the end results are so much better than manually screwing around with buffers and queues.
Splitting your code up into modules is just good design sense. I don't feel sorry for experienced developers having to change their entire code base because a database concern is affecting their business logic. The internet can't wait for them.
No more than any traditional WinForms application. While it is very rare, occasionally I skip the data binding and use the old-school MVC style.
&gt; And not to offend you but probably the best UI programming stack at this moment is the HTML/CSS/JavaScript stack. I would strongly disagree with that. While far from perfect, I find that XAML-based frameworks are far more internally consistent than the mishmash of libraries we typically see in a web app. Simply put, HTML/CSS wasn't designed to handle what we use it for and it shows.
Splitting your code up into modules doesn't magically decouple your code. Once you hit run, all of those modules are linked together and problems in any will cascade up the tree.
Article author here - let me know if you have any questions. I'm not an expert by any means, but I got this to work in a way that made sense to me.
Here you go - https://www.reddit.com/r/dotnet/comments/bx6vka/host_nuxtjs_net_core_and_postgres_with_docker/
Here you go - https://www.reddit.com/r/dotnet/comments/bx6vka/host_nuxtjs_net_core_and_postgres_with_docker/
That makes it easier to find where the changes need to be made, but they still need to be made. And EF is infectious. Unless you copy all of your data into DTOs instead of returning the models directly, there is always the chance of picking up weird side-effects that you don't see until later. Especially if lazy-loading is enabled or you forget to use AsNoTracking.
Interesting. I have a program that uses WCF and needs to have pretty good performance so nice to see this about gRPC. Haven't looked much into converting but is it the recommended/accepted way to really define your message and classes in proto files? Is there a more programmatic way or method to define these in C# instead?
I don't know yet, but I'm interested in seeing how this WPF-&gt;gRPC converter tool he's talking about shapes up. He said the first release may be later this month.
Then why is there so much more software development done in the web stack then on wpf? For some line of business apps wpf might be a good choice but when it comes to applications used by the masses then you encounter a lot of difficulties with a wpf app. Deployability is troublesome. If you need to White label the application then the XAML styles are just not good enough. The speed of application development is much slower. Innovation is low. Ever tried to support meshing 3rd party content into a wpf app? I can go on with examples in which the web stack excels over wpf. Of course there are some areas that wpf might be better but in total the web stack is simply better. I've been developing wpf apps of large and small size since the beginning of wpf and also web applications for 20 years and I will only use wpf if it has a clear advantage over web. Mostly this is when the sandboxed environment of the browser prevents me from achieving my goals.
&gt; Then why is there so much more software development done in the web stack then on wpf? Because it generally takes 3 to 4 times more effort to accomplish the same feature set. Which means we need 3 to 4 times more web developers than desktop developers for a given project size. *** There is also visibility bias. For every web app that you can see, there may be a dozen internal desktop applications keeping it running. But you'll never see them. *** Finally, yes, deployment is an issue. But look at the iPhone and Android ecosystems where they solved deployment. People generally prefer installed applications over web sites (though to be fair, many of those apps are just thin wrappers around a browser).
Not if interfaces are used to decoupled the modules. For example, if a module accepts an object that "saves a record in the database" it won't be affected if EF Core makes a change where you need to call SaveChanges and then also call YesImSureSaveChanges. That would be encapsulated.
And with the introduction of electron.js the same goes for installed applications on a desktop computer üòÅ
If you DAL module is broken, then its broken. And if a broken DAL module causes your UI to not work, then your UI is coupled at runtime to the DAL. *** When you talk about interfaces you are confusing 'abstraction' with 'decoupling'. Think of it like a train, with each car coupled to the next. Abstraction is sticking a car in the middle. train ==&gt; UI ==&gt; IDAL ==&gt; DAL Decoupling is using a second train train1 ==&gt; UI train2 ==&gt; DAL *** Encapsulation makes it easier to ding the place where the flaw it, but it doesn't eliminate the flaw.
electron.js just makes HTML on desktop possible. It doesn't actually make it work better.
Totally with you. I killed 90% of the DB access in our app, so that mapping phase wasn't too painful, but the whole process of getting there was so painful :/
I don't know what Plesk is but permissions for IIS AppPools can be adjusted through Windows Explorer, no other software needed.
Yeah, if only we all started with 10 years experience it would all be fine ;)
No, this is still coupling. You decouple the specific implementations but the intention of the modules remains coupled through the interfaces. What happens when you change the interface? Messaging offers a partial solution and is preferable to an abuse of DI.
I did have public static async Task Main(string[] args) signature and launched a Thread() from Main. Starting that Thread() was preventing the code C# generates to wait for the Task to finish from working. Removing the Thread() and awaiting from main resolved the problem. Thanks for responding.
40 changes? I only counted 9 ...
Thanks, appreciate that. Dataflow's documentation is a little bit too terse so I actually spend a lot of time making sure I had all the scenarios right. Hopefully it will help a few people.
The article tries to cover the highlights, the ones that I think are going to cause problems for the widest number of people. As mentioned in the introduction, the full list is here: https://docs.microsoft.com/en-us/ef/core/what-is-new/ef-core-3.0/breaking-changes
You were right, I wasn't awaiting all the way to the top of the stack. I had a Thread() in use that was preventing compiler generated code in Main() from working to wait for the Tasks to finish.
See all of them here : https://docs.microsoft.com/en-us/ef/core/what-is-new/ef-core-3.0/breaking-changes#query-types-are-consolidated-with-entity-types
I remember the good old days when they didn't break stuff between versions all the time.
Wait to you hear the horror stories around just trying to add ObservableCollection.AddRange. I want to do a report on it, but every time I sit down to start I get another email about something else that broke.
TBH I've just been using Dapper now and written my own Identity Framework implementation in it and use it as a Git sub module.
cool! thanks for coming back to confirm.
Yep. In cases where I don't use my own ORM, Dapper is the way I go. That said, EF Core 3 does address the "Hell no" aspects. I just don't think treating relational data as an NoSQL style object graph is a good idea.
I might be underestimating how much one could limit the blast radius of changes like this then. In my admittedly exaggerated example, the interface wouldn't change. The DAL module would just call one more method on the DbContext object to finish the save. My point was that you can protect yourself from having to update every module in your code base by using interfaces.
True, I think the term I was looking for here was abstraction, not decoupling. And I agree that you can't prevent the need to update code in this situation, just that you can limit the blast radius. You'll narrow down what needs to change.
Step 1) Interview for entry level jobs. Step 2) If you get turned down, ask for feedback. Step 3) Address feedback. Repeat.
Maybe I'm a bit out of touch, but used to be I'd throw my resume on Monster or Dice and watch the recruiters ambush my phone like a pack of piranhas attacking fresh meat.
Yeah, Proto files is definitely were you put your contracts. You can use grpc's tools to convert the proto contract into service and client codes in a number of different languages. [https://www.nuget.org/packages/Grpc.Tools/](https://www.nuget.org/packages/Grpc.Tools/)
You're correct of course, I could have been more clear. Interfaces allow for substitution, which decouples the consumer from the implementation of its dependencies. The bit that I was describing is how a dependency graph forms, where an implementation becomes dependent on an abstract contract. It's not necessarily a bad thing, but comes with caveats.
Auth0.com has a free tier and is pretty easy to set up.
&gt; https://docs.microsoft.com/en-us/dotnet/api/system.runtime.caching.memorycache?view=netframework-4.7.2 Go back here and read more carefully. &gt; **The following example declares a reference to the default memory cache instance.** The cache entry uses a CacheItemPolicy object to provide eviction and expiration details for the cache entry. It also uses a ChangeMonitor object to monitor the state of the source data (which is a file) on the file system. private void btnGet_Click(object sender, EventArgs e) { ObjectCache cache = MemoryCache.Default; string fileContents = cache["filecontents"] as string; if (fileContents == null) { CacheItemPolicy policy = new CacheItemPolicy(); List&lt;string&gt; filePaths = new List&lt;string&gt;(); filePaths.Add("c:\\cache\\example.txt"); policy.ChangeMonitors.Add(new HostFileChangeMonitor(filePaths)); // Fetch the file contents. fileContents = File.ReadAllText("c:\\cache\\example.txt"); cache.Set("filecontents", fileContents, policy); } Label1.Text = fileContents; } &gt; The following example declares a reference to the default memory cache instance. `ObjectCache cache = MemoryCache.Default;` https://docs.microsoft.com/en-us/dotnet/api/system.runtime.caching.memorycache.default?view=netframework-4.7.2 &gt; This property always returns a reference to the default cache instance. For typical application scenarios, only one instance of MemoryCache is required. &gt; Because the default cache instance is not created by the constructor, you must use configuration to explicitly set the memory and polling values for the default cache instance. For more information, see &lt;memoryCache&gt; Element (Cache Settings).
In the example above, it is calling MemoryCache.Default which will return the shared cache.
My pleasure. I appreciate your help.
Thanks for the input. I think I'm picking up what you're laying down, but... What's still confusing me is how I would--in a different button click event, for example--read that memory cache data. Would I have to declare "ObjectCache cache = MemoryCache.Default;" all over again? Something just seems wrong with that. Maybe I'm overthinking things.
&gt; ObjectCache cache = MemoryCache.Default; All that does is make `cache` be a reference to `MemoryCache.Default`. You could remove that line and then replace every use of `cache` with `MemoryCache.Default`. The documentation for `MemoryCache.Default` tells you that it's implementation will always return a reference to the default cache instance - it will always be the same instance. You could declare a class-level property in your code-behind - `private ObjectCache Cache =&gt; MemoryCache.Default` - and then use `Cache` instead of `cache` along with the aforementioned line or instead of `MemoryCache.Default`. If you're using a dependency injection framework, you might register `MemoryCache.Default` as a Singleton to fulfill requests for `ObjectCache`.
Oooh, I get it now. Thanks!
Check out https://natemcmaster.github.io/CommandLineUtils/ and https://github.com/dotnet/command-line-api
Do you use dapper for updates and inserts?
MicroORMs aside, do you have a recommendation for an ORM besides EF6? NHibernate and LLBLGen pro come to mind, but they are ancient so might not be worth their weight.
&gt; I just don't think treating relational data as an NoSQL style object graph is a good idea. CosmosDB has some interesting data projections.
Well of course I'm going to recommend the one I created. https://github.com/docevaad/Chain/wiki/A-Chain-comparison-to-Dapper But if you have certain features in mind, I might suggest something else.
I'll have to look into that. I want to extend my ORM to talk to CosmosDB anyways.
Also https://github.com/fclp/fluent-command-line-parser
I maybe getting old but there is a lot of changes in .net core letely that is not compatible with previous versions. Not a fan of that aspect, although good changes are good obviously.
I come from a VB background, so I was once used to major breaking changes every 3rd version. But yea, as I get older it gets less fun.
[removed]
I'd use the command line parser built into Core's Configuration system. You can then access the parsed values like any other IConfiguration object. See [CommandLineConfigurationExtensions.AddCommandLine](https://docs.microsoft.com/en-us/dotnet/api/microsoft.extensions.configuration.commandlineconfigurationextensions.addcommandline?view=aspnetcore-2.2).
**Pardon the interruption.**
We use ServiceStack.OrmLite where I'm at, and we love it.
still waiting for ef core to catch up to nhibernate before switching
Definitely go with [https://github.com/dotnet/command-line-api](https://github.com/dotnet/command-line-api) if you can, it has its origins in Nate's code but is being actively worked on.
But that just caused barely any advancements. What did .NET Framework add that was significant in the past 5 years? Now compare that to .NET Core over the past few years. They do can a lot more a lot faster now that they don't need to worry about breaking changes.
System.CommandLine
You would map to a VM if you want to have properies that are releated to the view that you do not need or want on your models. You could and probably should move the mapping from model to viewmodel into another class. That isn't really the responsibility of the control and mappings can change over time. You can look into Automapper or write your own mapping function to clean up code in the controller.
Hey, I'm a dev on Avalonia. We know out documentation is very lacking at the moment :( I recently added a basic tutorial at http://avaloniaui.net/docs/tutorial/ Is there any particular area that you really struggled with without documentation that we should focus on?
Where did you find Avalonia's styling to be inferior to WPF's? In theory our styling system should be more powerful. I know we're missing Triggers but there are usually other/better ways to achieve what triggers do in WPF using Avalonia's CSS-style styling system.
I thought they killed this one off very recently as well? (this is like their 5th semi-official library for this) Hopefully its still alive then!
I love VS! But for front end development I choose VS Code. It's really great and the most popular IDE of the world. &amp;#x200B; As I wrote: Consider testing out [https://aspnetboilerplate.com/](https://aspnetboilerplate.com/) just to see how they do it. It's a great tool to learn, too.
Another Dapper, thanks. I‚Äôd better stay with [linq2db](https://github.com/linq2db/linq2db) and continue writing complex linq queries.
Thanks, I appreciate the time
Of course not. Who even are these people?
?
Come on, it‚Äôs 2019.
Doesn‚Äôt seem too bad. My first impression was that they‚Äôre forcing people to stop bad habits.
The awful layer you always get on medium.
Oh yea, lol. FWIW, I turned off the paywall and made this post free to all viewers.
Blogpost.Replace("So, ", "").Replace("Now, ","");
I actually made a library that uses Attributes. You decorate methods, properties, or fields and those get called/set with your command line arguments. So I can do: [CommandLine("test")] public bool Test{ get; set; } "--test" or "/test" will set this to true, otherwise false. [CommandLine("install")\ public void Install(string arg) { /*... */ } This function gets called for "--install=something" or "/install something". [CommandLine("foo")] public int Bar { get; set; } --foo=12 Finally, it's invoked by calling CommandLine.Parse(obj), then any attributes on obj's members will be processed. Since Program is a static class and it may make sense to use that class I also have CommandLine.ParseStatic&lt;T&gt;(). I made it for my personal use for an internal command the user never actually runs directly, so it lacks some of the niceties for a complete system like a help system, short flag support, of support for command line arguments not tied to switches/flags (eg like notepad.exe filename) If anyone is interested I can throw it up on github under the MIT license.
&gt; you can protect yourself from having to update every module in your code base by using interfaces and encapsulation At some point you have to have an implementation. In the case of the changes described here, that implementation is going to break. One way to isolate - but not avoid - such changes is to use something like [AdaptiveClient](https://github.com/leaderanalytics/AdaptiveClient) where you can easily abstract your DAL and swap between implementations by flipping a bit in a config file. You can easily code for different versions of EF or different platforms (MSSQL vs MySQL), etc.
Thank you for taking the time to make the long in depth tutorial mate ! Will check it out more thoroughly during the weekend. Cheers!
How are you deploying your app? You might make use of a secret store that can be coupled with your deployment. Docker containers are pretty good at this.
So the app is a desktop app, that will be hosted on a domain for download. So the user visits the website and then downloads the files and installs the desktop application to login and use it. That sounds interesting but would it work in my scenario?
Without running the app in a cloud environment, it's probably not the best idea. In an effort to not restructure everything, I would suggest decoupling your db from your app by having a web service act as a data pipeline. You can develop a Java web signature key or cookie to authenticate your users to allow access to clal the service, then have your web service have access to your data bases. You could in turn deploy this new service via docker and have secure scalable gateway to your sensisitve dbs.
Without running the app in a cloud environment, it's probably not the best idea. In an effort to not restructure everything, I would suggest decoupling your db from your app by having a web service act as a data pipeline. You can develop a Java web signature key or cookie to authenticate your users to allow access to clal the service, then have your web service have access to your data bases. You could in turn deploy this new service via docker and have secure scalable gateway to your sensisitve dbs
Oh they are still worried about breaking changes. Much digital blood is currently being spilled about `ObservableCollection.AddRange`. Also, EF was never exactly shy about breaking changes. To the best of my knowledge, every major version of EF and EF Core intentionally broke stuff.
Chain is at a much higher level that Dapper because it actively reads your database schema at runtime in order to generate more efficient queries. But if you want LINQ, then no, it's not the right one for you.
That was an interesting look at the machine code the CLR produces. Technically it violates the intent of the code, which is to reevaluate the value length of the array each iteration. Which means if you had something else swap out the array from underneath you, the length could be wrong. I'm sure you are thinking, "no one is going to do that because it opens the door to all kinds of race conditions". Which is true, but it does mean if you see `for (int i = 0; i &lt; array.Length; i++) {` throw an index out of range exception you know to look for concurrency issues.
As a follow up, what would this do? int[] arrayA = ... int[] arrayB = ... array = arrayA; int sum = 0; for (int i = 0; i &lt; array.Length; i++) { sum += array[i]; if (sum % 2 == 0) array = arrayA; else array = arrayB; } return sum; } I would hope it would go back to evaluating the length with every iteration.
This might keep you up at night :) real time debugging on a decompiled .net exe: [https://github.com/0xd4d/dnSpy](https://github.com/0xd4d/dnSpy)
If your desktop application can read and write any user's data, then so can any attacker who comes into possession of your application. There is no magic way around this, the only way to prevent that is individual credentials for each user, stored on and validated by a server outside of the users' control. Encrypting the database credentials is meaningless since your application has to contain the decryption key. Obfuscation is not a security measure, it will at best slightly annoy the attacker.
Thank you, if it simply is a case of it cannot happen that way, it is what it is, so thank you. So would this work by when the user logs in or creates a login, you'd create a new user account on the database server, with absolutely no permissions, other than to execute a stored procedure, where the parameters aren't passed by the application, but are hard coded into the stored procedure? So they can only execute the procedure and not view it or amend it or pass parameters to it, and the hard coded parameters would only return data for that user?
That is horrifying..
You shouldn't have to worry about closing the modal if you're redirecting on success. What you do need to do is pass back the URL you're trying to redirect to. Something like this: return Json(new {url = Url.Action("Index", "Home")}); Then in your success handler (not entirely sure this works as I don't use Ajax.BeginForm): OnSuccess = "window.location.href = result.url;"
&gt; IDE0058 C# Expression value is never used
Isnt this enough to make it redirect? return RedirectToAction("Index", "Home"); Or does have to be a Json response?
It's in F# but you can try https://github.com/fsprojects/Argu
RedirectToAction and redirection through javascript are both doing the same thing, sending you to the HomeController's Index action. Are you sure your Index action is querying whatever it needs to to present the updated data?
Both have been active- I notice they're working on adding this new Try.NET [tutorial/documentation](https://user-images.githubusercontent.com/547415/58752436-905aa880-8463-11e9-9ab7-c2a8136b0a93.gif) stuff into the System.CommandLine repo. Hopefully this in particular is some indication of an intent to make this an official/non-alpha thing. --- As for `McMaster.CommandLineUtils` (the still-active spinoff of discontinued `Microsoft.Extensions.CommandLineUtils`) - &gt; natemcmaster commented **20 days ago** [...] For more context on this issue (and why I missed your question), I had my first child a few months ago. As you can imagine, I don't have as much free time anymore. [...] Allow me to clarify - the primary goal of this announcement was meant to communicate that the pace of development here is going to slow down. It was not my intent to say that 2.3 is the last version of this library ever. I will still take contributions and make improvements [...] &gt; I don't see this library as dead and I will occasionally make improvements. For instance, I was actually just thinking last night that I should try updating this library to C# 8 and incorporate nullable reference types. https://github.com/natemcmaster/CommandLineUtils/issues/206#issuecomment-493507500 &gt; Update this project to use C# 8 and nullable reference types. This should help anyone else using this library who also wants to use this feature. @natemcmaster *natemcmaster self-assigned this* ***7 days ago*** https://github.com/natemcmaster/CommandLineUtils/issues/240
The general rule I follow is if the data is just being displayed on the page then use the Model. If the data is being manipulated and posted back, use a ViewModel to prevent overposting attacks. There are other ways to prevent overposting attacks, but ViewModels can also be used for other purposes so there are additional benefits to using them.
Put an ASP.NET API between the database and the application. Access it securely over SSL and use whatever login mechanism you like to negotiate the connection. You can't allow your application to communicate directly with the database over the internet without exposing every detail of what it is doing.
Why? Just why would you want this? If you want to build a string, create a new method.
Have you ever considered that it was at the stage where it was mature, stable and doesn't necessarily need many advancements? I've got code now that is over 15 years old that is still quite happily chugging along.
I ended up using the CommandLineParser one. It took a bit of fiddling as the examples weren't entirely clear but it's working great now. Thank you everyone.
It's nice that lazy-loading hasn't been the default for ef core since the beginning, but `.AsNoTracking()` is a big one for sure. I have no idea how many times I've had to point this out to people in code reviews... they just get lazy and add `.ToList()` on their queries to make things "work".
Yes, i prefer to write linq queries, because it gives powerful mechanism for query decomposition. And another benefit is compilation time query check, it works in 90+% cases. And do not forget about SQL optimization out of the box (removing unnecessary joins, subqueries, dead predicates, simplifying projection, etc.) It is why i‚Äôm active linq2db contributor for several years - it gives me real flexibility in writing queries and almost every SQL can be translated to linq and reused in constructing other queries. Just my thoughts about EF Core - it is still good for ‚ÄúHello world‚Äù projects even it become very powerful from release to release. After year of usage in performance critical application, it becomes a pain and people switch to Dapper and write RAW queries. I‚Äôm missing in EF bulk operations: bulk insert, bulk update several fields in 1000+ records. I do not need to select record for just update one field. Wen inserting record, usually i do not need fetching back information. Every additional roundtrip to database breaks performance, thats why ChangeTracker along with simplifying work with database introduces additional performance penalty. BTW, EF Core is a real piece of art, and i hope is not overdesigned. When it will allow more control of queries that are sent, introduce more optimizations - it will be unbeatable data access technology.
Stacking Retrace perhaps?
Have you looked at Application Insights already? It is not perfect but it gives you quite some insights (pun intended) out of the box.
EF Core still does not have first class support for basic functionality such as stored procedures and table valued functions. Nor can you perform updates with non-Entity objects. So for me it's still a highly advanced toy not suitable for production work. But what's really frustrating is that it doesn't have to be that way. Unless there is something truly heinous in their design, fixing these gaps is a simple matter. Consider this: my ORM only has two part time developers and we manage to support tricky stuff like PostgreSQL functions with multiple resultsets. EF Core has a whole team and they still haven't figured out a basic SQL Server proc. It doesn't make any sense.
Not yet, to be honest, I am pretty new in the .NET world, I did a bit of searching but did not really find what would compare to those two tools.
&gt; Wen inserting record, usually i do not need fetching back information. This is where the EF core team could really use some SQL experts. In my ORM, I use OUTPUT clauses so the read back happens in the same statement as the insert or update. EF makes a separate trip. And I agree about bulk and batch operations. I don't think my ORM quite has it nailed down yet, but it at least handles the basics. An ORM that can only modify data one row at a time does not actually understand databases.
\+1 for api between app and database.
If you need to use only the browser and you can't access the server, you can convert the objects you're populating with data into JSON strings and stick it all in LocalStorage under some sort of key. Then, when you click 'sync', it reads in all the keys and values, converts them to a collection of JSON strings, and sends it off to the server to be inserted into the database. If you do have access to the server side app, you can either store it in MemoryCache until the database is available to be synced to, or you could go as far as to convert it to JSON and save it to the disk. I'm not really experienced in this, so those are only a few ideas I had, and they probably aren't that good.
Done this a bit, we use indexeddb/dixiejs ([https://dexie.org/](https://dexie.org/)) in a webworker (to prevent UI lock) On save we generate a changelog entry and save that to indexeddb Then sync the changelog back to the server on connection and pull the new dataset after updates None of this is .net dependent its all front end javascript we use vue On the .net side we use webapi controllers and from there its regular backend
For local I‚Äôve used Stackify Prefix. For APM in prod Application Insights or New Relic. Both have their pros and cons. Try em out!
Thanks for your suggestions, even if you aren't experienced. What you described is similar to what I'm thinking it will have to do. LocalStorage and IndexedDb are similar in that they are basically just key value pairs. Still leaves me with a lot of problems to work through on querying that datastore, ensuring relationships tables stay in sync between that and SQL Server, detecting if data was modified offline, conflicts, etc. Was hoping to find some client database, wrapper library, or even just example projects to help with some of that stuff.
I think if the original plan is to have data that is disconnected from the database, and remains disconnected for a long period of time, conflicts are inevitable. If you're going to be validating the locally stored data against the SQL Server data, you'd need to be connecting to the server anyway, wouldn't you? In terms of detecting if data has been modified offline, I'm not sure I understand what you mean by that? Are you saying that the server-side app should be able to detect changes in data that exists on a machine that it doesn't have access to? Or, are you talking about a flag that gets attached to the locally stored data to say "Hey, this data was modified offline on 06/06/2019" so the server will know which data is the newest?
OUTPUT... I have to find time to finish [that insert part](https://github.com/linq2db/linq2db/pull/1703) )) It is really helpful functionality when you are doing ETL stuff. A lot of work here for other DML operations but it is possible and really handy. Pity that not all databases support this as MSSQL does.
Yea. I had to spend a lot of time simulating it in some databases. Thankfully PostgreSQL does support it, just under another name.
Let me make an analogy for you. Think of the PC as a worker doing some work, and an attacker as someone looking over their shoulder at everything they do. Let's say the worker sometimes needs to open a safe with a combination (SQL Server) and place documents into it but nothing else. Now he wants to keep this combination from the attacker. So maybe he memorizes it instead of writing it down, maybe if he writes it down he writes it down backwards to confuse the attacker. But it doesn't matter. All the attacker has to do is wait for him to open the safe and read the combination as the worker enters it! It doesn't matter what steps the worker takes to safeguard it. And there is no way around that. Now the attacker can open the safe and do whatever he wants. Now let's say we introduce a new worker, Worker #2 (A web service). He is responsible for all safe access and nobody else is allowed to touch the safe. Everyone has to go through him. We see that worker #1 no longer needs to know the safe combination since he never opens the safe himself. So he doesn't. The attacker now lacks the piece of paper he wrote the combination on backwards or whatever. When worker #1 needs to access the safe, he now goes to worker #2 (and of course the attacker is still over his shoulder). Now worker #2 has a conversation with worker #1 about what he needs to do with the safe, which is add documents. The documents are handed over from worker #1 to worker #2 and worker #1 leaves. The attacker however can't look over anyone else's shoulder and is forced to leave as well! He doesn't even get to find out where the safe is located. The attacker can come back alone and hand over documents himself that he made. But that's all he can do. And let's say the documents require a seal stamped by worker #2 at some other time and place (let's say worker #1 got his documents from worker #2) he will get rejected anyway. Of course for anything sensitive you can go further. Let's say worker #1 is talking to worker #2 again. Worker #2 says "OK, I can file these documents, who's asking?" Worker #1 now turns around and asks the attacker for his username and password. A legitimate user of the program can supply them to worker #1 who can turn around and give them back to worker #2. Worker #2 knows who is allowed to supply documents for the safe and can accept or reject them. The attacker won't know and won't get past this defense. Now, you could just do the same thing with just worker #1 and have worker #1 ask the attacker for the safe combination. However like the analogy of a safe combination, it's not practical to have multiple combinations for each user of a system for the same safe. And if you only have one combination it's trivial for someone to abuse it without fear of being identified, and if they need to be denied access you have to change the combination and give everyone the new one. And there's no way to restrict individual users of the safe from doing different things inside of it (SQL server is a bit more flexible than a safe but it is still not designed to be exposed over the internet!)
Have you looked into hosting in Azure? I really recommend using API app services, setting the connection string in the environment variables then, and then explore Azure SQL Always Encrypted leveraging Azure Key Vault. Sounds like a lot, but it‚Äôs not. Plus there‚Äôs a LOT of PaaS going on there so way less maintenance for you to have to fuss with
If QueryProvider can't determine how to convert an expression into a SQL query, it will instead pull down the data client side and evaluate the remaining expressions there. This can be very slow depending on the query and the developer may not realize it's happening. Thankfully EF Core 3.0 changes this to an exception so you can be more easily aware it's happening (you can force it to evaluate client side if you really want to), So that's why you would want to do it. That, and interpolated strings look nice and tidy. We like nice and tidy source code (well, I do).
Angular is good for line of business apps i.e. data entry. Also it is easy to make reusable controls. Not that React/Vue are not good in those areas....it is just functionality Angular provides.
I had been reading a bit about Dexie. In your "onsave" example would that be done with [Dexie.Syncable](https://dexie.org/docs/Syncable/Dexie.Syncable.js.html#tutorial) or a custom method you wrote that calls your rest api? Did you find it solid to work with / good enough to put in production? I always have a fear of JS projects going dead a year down the road but I guess that's a risk with all of them...
Herd mentality is a big part of it I'm sure. In this industry people want to chase things as to not be left behind.
Because there are a lot of jobs. I think Vue is the best, followed by React and then a close third is Angular. But all I've done for the last 3 years is Angular, C# for APIs and mostly SQL backend.
Angular requires TypeScript and is incredibly opinionated as a ‚Äúbatteries included‚Äù framework. Both of which really appeal to a certain portion of the asp.net crowd.
It's been a while for me, but I would avoid localstorage for anything other than very small data (kilobyte order of magnitude) &amp;#x200B; IndexedDb was a much better choice when I was doing client-side data storage - more storage, less overhead &amp;#x200B; The only drawback is the API for IndexedDb is more difficult to use. But you don't want your client's tabs to die because you had a bug that put too much in localstorage...
Basically my thought was if a user downloads 5,000 objects I would need to track which ones they modified to be pushed to server when they regain connection. Creating either a timestamp or a bool hasUnsynedOfflineChange property for each object in the browser datastore would probably work. I'm just trying to think through all the edge cases like users trying to work on multiple devices at the same time or other users changing the same records, but I guess I would need to write validation logic somewhere to handle it.
I'm looking at 5-10MB so LocalStorage is definitely out.
Personally I think this is a big factor. The React ecosystem gives you a *lot* of choice. There are of course best practices and so on, but there are many places in the React world where you find yourself weighing 3+ ways of doing something (libraries, recommended practices, or whatever) where they're all viable choices, they're all reasonably popular, and there's no clear "best" choice. A lot of people don't like that especially in the corporate world (IME).
React is very good at stateful single page applications. Forms are a nightmare however. Asp also delivers a familiarity of controllers and reusable components. Also, in my opinion, react can be a nightmare to debug and read.
I have no idea, I don‚Äôt get it. Just use Razor and JS / JQ. Especially if you are building a asp.net app
For me the reason is typescript.
AngularJs was the popular framework being chased originally. Then it was React. Now it appears to be Vue. I'm not sure Angular (2+) has every been the trendy/popular framework.
In what way are forms a nightmare? Store things in an object then submit that object. It's probably the easiest it's ever been for me.
Create React App supports Typescript now that it's in Babel 7, if you want to give it a shot. I've been using it for the past 8mo or so and in love. React + Typescript just makes so much sense.
Thanks for the heads up, I'll look into it.
I personally think its because Angular/Typescript approach appeals to the over-engineered OO mentality that so many c# developers have. Never really bought into all of that myself so I much prefer the simplicity of something of Vue.
Recommending jquery in 2019 is like recommending Somebody a CRT screen.
jQuery has its place when the user interactions are simple. Once it starts getting even a little complex though then yeah Vue/react/angular become a better choice
I hope that persons is joking.
So if you use it on your web server, your peachy.
Yeah, agreed. React and TypeScript is awesome. All the components and their properties get type verified.
This is big for me, especially when it comes to projects at work. It's really nice to not have to deal with opinions on what router or styling conventions to use. Because there are so many ways of doing things, I've run into compatibility issues with using libraries. Maybe it's just because of my limited experience with React, but I would find myself fighting with the libraries and tooling to get things to work together. It's nice to be able to just pull in a library for Angular and have it just work
It provides a shit ton of architectural guidance. If you're using Angular on a greenfield application most of the tough choices will be made for you. If ten people join the project later they'll be funneled through the same path so it will be easy to work together with them. Not every choice will be your favorite choice but at least the project will be consistent. This way of thinking is common in the enterprise world and .NET is, at its core, an enterprise framework. This conversation reminds me of ES6 when it first came out. Many JavaScript developers hated it because they were making JavaScript more Java-like ignoring its beautiful flexibility and prototypal inheritance and this and that and the other thing. I was just happy to have a version of JavaScript that didn't require a philosophical discussion before choosing a module system.
I think that C# developers have had more exposure to two way property binding and are used to it. The chances are C# developers have exposure to communication using events I don't think it is the go to solution for communication between components either. \+ Typescript.
I don‚Äôt get that. Can‚Äôt you use TypeScript with Vue, React or even JQuery?
not for long, Blazor will take over as early as next-year
Yeah, I cant wait! Though, using anything 1.0 from Microsoft is a huge gamble. 2.0 would be better, or at least 1.1...
This is really big actually. React's flexibility is both a boon and a bane depending on what the problem is. On a very big team with a lot of new developers going in and out, having an enforced opinionated way of doing things really helps out the team as there's a common ground even for new developers. The batteries included also helps lessen too much dependencies to work and maintain especially on certain enterprise webapps where it's pretty hard to drop a library without another team reviewing it.
Because I am old and I prefer my html in html files, and my CSS in (s)css files. Jsx gives me a rash. Also, TypeScript.
I hear this argument a lot and I strongly disagree with it. It‚Äôs not that the argument is incorrect. It just sort of brushes off Angular as an easier path. It justifies React without real comparisons. Angular dependency injection is great. It‚Äôs lifecycle hooks, content projection, and dynamic component rendering is super easy, barely an inconvenience. Grabbing DOM items from your component is easy with Angular. Having built in routing is great. Especially with lazy loading and child routes. Working on teams where the code almost always looks the same is a huge plus. Typescript and tree shaking helps in bundle sizes. Of course you can use React with Typescript. But if you want good tooling, Angular has that built in. With Bazel as a build system and Ivy (the new renderer not out yet) it just keeps improving while react is just what it always was.
Right.. With formik and Yup, forms are drastically simplified.
I don‚Äôt disagree. Lid for every pot.
Switching to Angular, forms were the one thing that was much harder. I miss Formik
I just switched after 3 years of React. I love how organized and modular it is and the built in routing. Especially the relative path routing
So by this logic, React is good at firms, because two other libraries are? That‚Äôs like saying C# is good at JSON serialization because of Newtonsoft.
I've never used React or Vue, but I found Angular extremely easy to use. I hated web development before, I found it a very frustrating experience, but using Angular feels like building a native app.
To add to this, perhaps c# devs are also more familiar with larger code bases, purely because c# has been around for quite a long time now. Because of this, they see the value in opinionated frameworks and understand the importance of having a good clean architecture for easier long term maintenance. In short, the reason why many c# devs choose angular is because of the same reasons they chose c#.
It is probably correct, but I still like React best.
I learned Angular first and then Vue. Vue is awesome so you can guess my preference.
An excellent article, thank you very much for spending the time to put this together.
I went to an all day workshop on Blazor, and it was pretty darn cool
formik and yup look great thanks
Up vote for vue. Used to work a lot with angular but once I switched to vue much prefer it.
I would like to know more people‚Äôs opinions on this.
Have you looked at Vue by chance? It keeps separation of concerns without having 3+ files for a single component.
Same. Not sure why Vue is never mentioned in this sub.
Vue is a tiny player compared to Anglar and React. Plus, it has no huge corp behind it like Google or Facebook. I love Vue and use it whenever I can, from my experience it was the most seamless front end framework.
I switched to react after a year of angular and I love it. Angular feels a bit verbose and clunky to me and I like the declarative thinking behind react. It's highly subjective though.
I do generally agree with your positive comments on angular and detailing its benefits as opposed to the brush off However, your last lines brushes off react. It is not "what it always was". It now has great lifecycle hooks, the new ref hooks make grabbing DOM items easy. Using `create-react-app` gives you great tooling preconfigured, including using typescript if you want. Admittedly you still have to get a router yourself, and Suspense isn't ready for data fetching yet. But it is constantly improving and based on your comments I'd say they're very comparable, and its mostly personal preference.
Yeah I should read up on changes to React. I started in React. I got heavily into Redux. It was fun. I resisted using Angular because of it. I was forced to try Angular at work. Then I realized that it was my own bias that created a rift. I also felt like the community was dumping on Angular back then. The main argument I read was an emotional plea to having control over libraries vs using a single monolithic framework. I don't miss having to play with webpack configs. But I guess now we're stuck profiling some Angular code and it's miserable to do so.
Indeed this, there's alot of interest on our team once SSB goes live on .net core 3 release for some of our up coming internal apps. We'll migrate to CSB after that goes live for those that needs more scaling.
Because Vue is the PHP to React's C#. Popular for it's low barrier to entry but kinda shitty.
Angulars use of TypeScript is incredible poor and lacking.
&gt; Thankfully EF Core 3.0 changes this to an exception so you can be more easily aware it's happening You could do this with earlier EF Core versions as well. 3.0 just changes the default value, because too many people don't bother learning the frameworks properly anymore.
Over-engineered only if you work on small to medium sized projects. Most of us (.NET devs) work on large enterprise projects where you can't have 8 different devs do things their own way over a course of 20 years. An opinionated framework is good for big projects. Hence why .NET itself is popular in the enterprise software industry.
Angular is more backend-styled. OOP, DI... etc. That‚Äôs why .net developers like it.
When you say localStorage I hope you mean IndexedDB. It's what it was designed for.
Why?
Not sure what .NET itself has to do with how you sync your front-end data with your back-end. Regardless of back-end you'll have to work out a front-end solution for the storage and syncing process. The way I do it is I store the data in IndexedDB (using [idb](https://github.com/jakearchibald/idb) because the original IndexedDB API is shite) and then when you want to sync you just send those objects to your back-end to be saved. I'm not sure how .NET itself or the back-end in general is relevant to this offline and sync problematic. Offline mode for web apps is in theory really simple but in practice it's hell. Which is why I'm very careful about choosing whether an application can even handle offline mode. I have some applications where different users share ownership of resources so syncing can cause a loss of data if you're not careful.
I'd never heard of it until now, so no. I meant the browser's HTML5 storage.
Yeah `localStorage` has a limit of 10MB, and even that amount is shared with `sessionStorage`. IndexedDB can hold up to 50MB IIRC and also supports transactions and running arbitrary queries like you would in a real DB. The only problem with it is it's terrible API but this is mended by JS libraries like `idb`.
Honestly, I do not know what Retrace is at this point since I am new to .NET Core but I am going to look into it, thank you.
Mini profiler might do some of what you are looking for
- The default project template is not making use of any `strict` flag. - Using `strictPropertyInitialization` is conceptually near impossible to use with Angular (except via hacks), due to the way the binding works. - You can't use TypeScript in the templates. - Libraries like Angular Forms will completely drop type safety and you're reduce to `any` all the time. - Usage of a lot of magic strings. To name a few quick of my head.
Since iam a fresher i like to learn Angular js ,since there are many reasons .many opening for this course .and after 1 year experience you can get good package .
This is why I use LLBLGen. Things just work and got better.
already using it right now for an upcoming big production service
Don\`t start with AngularJS, look at the newer versions of Angular. Angular 8 was just released
Azure active directory has a free tier that should suffice for a simple application or Auth0 is also pretty decent and easy to setup.
Angular uses typescript, and also shares alot of similarities to the mvc framework so you don‚Äôt have to manage two different structures at once.
In Angular you not forced to create 3 files, you can put template and styles inside component.
React is good at forms, though. Forms follow the same unidirectional data flow paradigm which is predictable and flexible. However, it can be verbose due to the nature of forms - hence my suggestion to use formik. You can still easily build forms with regular controlled components.
I like it because it‚Äôs a full UI replacement, including most of the scaffolding ‚Äî deployable without a .net host. I have nothing against Vue, though, and tend to recommend Angular for greenfield and Vue for refactoring an existing app. I sure wouldn‚Äôt fault anyone who just ran with Vue as a consistent choice, though. I‚Äôm one of those folks who think the JSX structure is an abomination, though, which is the main reason I don‚Äôt use React.
I would agree with this mostly, I don‚Äôt consider it a negative more of a who cares. Almost like putting their 3.2 GPA from undergrad. Makes no difference to me. I would suggest to the OP, why spend all the time becoming book smart when you could be spending that time building what ever application is in your head. When I started out as a developer, seems like every weekend I had some new project I wanted to build and test out different technologies or implementations. Hands on experience is by far way more valuable than studying for a cert. Over my 20 years in this field, mostly dot net, you come to realize who the people are that have read about something and those who have tried to build something. Night and day difference in approach and success.
I'm the one who made the original statement about forms being easy and I've never heard of either of these libraries. The only one I've ever used was "Redux Forms", which was probably the most complicated over-engineered library I've ever dealt with. I don't use any libraries when dealing with forms. I just store all their values into a local form state object (no Redux) and submit that.
If default is bad it is not a fault of users. Look what nightamre default settings in MySQL are and noone should blame users for this.
Please elaborate how Vue is kinda shitty? What exactly is wrong with how it functions?
I like vue for personal projects or micro apps, but for a big desktop app replacement with 50 screens and 1000 controls, I don't know if it can manage the scale. To be fair, I haven't tried it.
I'd say the number one reason angular should be the preferred front end framework is the stability and opinionated nature of the framework. I can very quickly get up to speed on any angular project without having to inspect/learn which libraries the developer used for routing, di, forms, http, etc.. This consistency also leads to increased speed in development. Every time I build a react app I have to ask myself is the library I used last time for 'x' still the best at doing 'y'. This doesn't happen with angular nearly as often.
You can, but he was talking about specifically not doing that
Stick to iFrame. It works.
It is more or less a singleton you have made. Here are some other ways https://medium.com/@sinethneranjana/5-ways-to-write-a-singleton-and-why-you-shouldnt-1cf078562376 And information why you shouldn't. (Mainly multi threaded apps)
ApplicationInsights is the closest popular .NET tool to Laravel Telescope. I'm only recommending it because it's one of the few free services you can get on Azure.
Just to give another point of view, I think some points are omitted. A lot of these things are personal preference which I won't debate (things being easy) but there are some downsides. Compared to something like Vue, Angular is rather large, verbose, and hard to migrate from. Some of these can be said for React as well, but those aren;t the only 2 players in the game, just currently the most popular. Also saying React is just what it always was is quite misleading.
I haven't tried it either, but looking at it's build pipeline and how components are constructed, hard to see any red flags there.
The issues you cite are mostly due to limitations with Javascript. Either which way the benefits provided by Typescript FAR outweigh problems.
All issues I cited are directly related to how Angular works and uses TypeScript.
Exactly. As a C# person who was moving into web to get things more dynamic and sick of windows forms apps... angular2 instantly appealed to me. It looked like a real application instead of javascript garbage all over the place. Yeah it has a bit more architectural overhead, but anyone who has managed a medium scale application should tell you that is a massively good thing for future maintainability.
What do you think of Svelte?
So does Angular
Haven't heard of it. Tell us about it?
Yes, basically. LGPL v3 means you have to disclose source code when distributing.
Ah, I'm not sure what the best free options are. If you ever end up with some cash to blow on your production environment, it is a very nice tool for keeping an eye on performance and errors. Its also on the cheaper end of similar (paid) tools I've seen.
Does .NET 4.6 have service worker support?
I would love to hear from people doing desktop development these days: where do you think the field is moving to? Do you keep getting desktop green dev or is it mostly maintenance?
It's basically Vue with even less boilerplate. It's a compiler instead of a framework so it has the smallest package size as well. https://svelte.dev/ https://github.com/sveltejs/svelte
A Singleton? What are you smoking
An issue with using the the next greatest framework for me is usually libraries and tooling support.
Why write an UWP app when PWA and Electron is available? Soon also React native
Honestly, if I forget to instantiate my list I would prefer a nullreferenceexception so that I can fix my bug. Not write extra code every time I use a list so I can allow myself to skip instatiating the list.
You're confusing things. https://www.reddit.com/r/Windows10/comments/bmxa2f/rudy_huyn_and_ginny_caughey_respond_to_the_lies/en3czq0/
I haven't seen anyone mention unit testing yet, and while I can't really speak to React and Vue, the tools for testing your services/components/directives/etc. are all there and the Angular test bed makes life a lot easier when writing unit tests. I work on a huge enterprise Angular application with multiple developers, and the ease of unit testing and not having to solely rely on automated/integration tests for QA'ing bug fixes and new features has sped up our development cycle by a sizable amount. You'd be surprised by the amount of people that develop frontend applications and just throw them into the wild praying to god they work as expected with little to no unit test code coverage.
Because Electron is a bloated piece of shit.
Angular can, but that puts your HTML and CSS inside the TypeScript, which is explicitly what /u/anonymousLurker2080 said he doesn't like doing. Vue has [Single-File Components](https://vuejs.org/v2/guide/single-file-components.html) that allow you to put all your code into one file while also keeping the different languages separated.
Yep, decision fatigue.
You're right, it's not exactly .NET dependent. But I was hoping someone knew of an open source C# project or tutorial I could learn from to see then entire flow. The codebase I inherited was creating using [this tech stack](https://www.telerik.com/blogs/introducing-jaydata-and-kendo-ui) but that javascript library was deprecated years ago, majority of documentation 404's, and has been a general pain in the ass to work with. I don't fully understand the backend OData api, which also seems to have fallen out of favor... I've been thinking about totally refactoring those technologies out along with building this offline feature but feeling overwhelmed with the scope of it.
People always complaining about chrome eating up memory but seem to have no issues with electron
First of All, i wnat to thanks everyone for the answer, i decide that when i'll start to learn [ASP.NET](https://ASP.NET) to create web application i'll learn Angular, people made me curious about this framework and how it's work, I'already work with React, React + Redux, so try to learn new thing it's always a good thing
Internal applications. We don't touch UWP, everything new is WPF. We're not rewriting WinForms apps ;) I think you'll still find shops creating WinForms apps, because they have a huge ecosystem of those, probably with third party and paid components. I guess most stuff nowadays is done in WPF.
Show me anyone who complains about Chrome's memory usage but is okay with Electron. I have seen complaints about Electron for this very reason, but I've never seen anyone defend it while attacking Chrome.
Right now my single Discord instance is sitting at 634MB of RAM. That's fucking *insane*. There is *no* reason a chat program should consume anywhere near that much RAM. But it does because Electron. And most other Electron apps are like this. They all consume hundreds of megabytes of RAM doing trivial shit.
So you can only use ApplicationInsights if your project is hosted on Azure? I am looking for a self-hosted solution which I could use with apps hosted on closed intranets or on our own self hosted virtual servers.
The most important features for us when we are developing an app/api are the ability to see each and every request and what happened during those request (sql queries per request, incoming request details, outgoing response info, exceptions if something happened, be able to see whatever we log during those requests) and to be able to see what queries we run, what exceptions we had. We usually enhance performance after we have the basics down so in the first iteration the before mentioned features are way more important.
Thank you! Mini profiler seems to have most of what I need, I certainly will check it out, thank you once again!
I know there was another thread discussing this but, honestly, unless UWP somehow becomes cross-platform, I don't see much of a future for it. WPF, for all its flaws, at least works on all modern (supported) versions of Windows.
Windows 10 has a windows component 'Bash for Windows' aka WSL. There is also 'Ubuntu 18.04' as a UWP installation from windows store. The 'Bash for Windows' component is Ubuntu 14.04, pretty old these days. I tried installing 18.04 from the store. The problem with 18.04 is there is NO WAY to launch that version of bash.exe from the command line. If you right click the icon in start menu, there is no 'open file location'. It doesn't have a location anywhere. It's buried inside a 'WindowsApps' folder which has permissions set to TRUSTED_INSTALLER. Even windows administrators cannot go into that folder. You have to boot into safe-mode to see what's in it. The only way to get your 'Bash for Windows' (14.04) upgraded is to upgrade from inside the bash prompt using ubuntu 'do-release-upgrade' command. It's that experience that has led me to swear off all UWP apps. UWP is dead to me. I'll never install anything from the windows store if that's how they are installed.
&gt; hat‚Äôs like saying C# is good at JSON serialization because of Newtonsoft. Yes? Same way, "python is good at ML because of the libraries and tools ML people have built using python". A language and an ecosystem go hand in hand, when talking about suitability for a purpose. There are countless Domain Specific Languages out there that are shit at the domain they are intended for because the ecosystem around them never developed.
I have the same experience as you do. I also find Xamarin interesting for cross platform development (Mac, WPF) but never tried it (outside of mobile dev).
Under the metro "Add or remove programs" there is a link titled "App execution aliases" that can be used to manage mappings for exe names to UWP apps.
Jesus. And here I'm thinking "huh, 75mb on my wpf, I must've done something wrong, that seems bloated."
uwp is more than just the user interface. It's an entire API to access OS features.
The extension method is in a static class that "manages" the activation/lifetime of \`List\` entities.
UWP is more than just a UI framework.
I don't disagree, but the limitations of it are what holds it back.
Your post is informative, but also maddening. Even more reason I will avoid UWP apps. Burying crap in AppData isn't an improvement over the old model. AppData is new the HKEY_LOCAL_MACHINE
&gt; The 'Bash for Windows' component is Ubuntu 14.04, pretty old these days. I believe it's more complicated than that: if you install the "Ubuntu" app, it should install the most recent LTS version. But it will then be stuck at that version, unless you install manually. So if you installed it a long time ago and used `do-release-upgrade` it can be 14.04. &gt; The problem with 18.04 is there is NO WAY to launch that version of bash.exe from the command line. That is not true, you can always launch it with `ubuntu1804`. And if you configure it as default using `wslconfig`, then `bash` will start 18.04. &gt; It's that experience that has led me to swear off all UWP apps. WSL distros are not UWP apps, so I don't see how anything you said is relevant here.
Building a large enterprise application in UWP, and at this point it's perfectly safe to pursue it for new projects. It's ahead of most of the curves people we're hung up on.
I thought service workers are completely client side. Are there specific webapi features only in .net core you need to work with them?
I agree. That's why I'm an Angular/React developer. But it's something to look into.
So I don't any book or site or what have you for this to recommend (which is why it was such a bear for me to learn enough to put something together), but learning how ASP .NET and .NET Core handle authentication and authorization for anything that isn't 100% trivial is something I would highly advise taking the time to learn.
It's probably the images and videos linked in the chat that make the majority of that.
Sorry I've got a side question for you. I'm trying to get into .net web dev field coming from front end developer. But I feel like theres so much to learn. Any resources youd recommend?
hey mate, im just going the tutorial, its really great, the mention of using UpCloud was a good suggestion, i think ill go with them. much cheaper than other providers. As for using UpCloud what kind of plan do you go with? just a single linux vm that you deploy your containers to? People said not to containerize the db. when i putting my sql server in the docker container, i thought to myself, this seems like a bad idea as the containers are supposed to be "transient" for lack of a better word i.e. you spin them up, run them, maybe throw it away spin another one up with different config. But that wont work with sql since its data you want to keep. However as i said in my other comments, my DB is very light in what it does, my site is a video aggregator https://www.mmavideosearch.com the only mutation to hte db is when someone clicks a link, i like to keep a view count on the videos people watch. other than that its read only, so i can dockerise my sql instance. though im running sql server so it might be a bit heavy on the vms from UpCloud, or do you think not? Otherwise i can just use sql lite, would this be worth putting in another container? or should i just put it in the same container as the api? Part of me doing this is to learn docker, and later on kubeneties, so perhaps i should go with best practice and use container for each component. so 3 all up.
I made an internal WPF app. We were considering making kiosks (which might have used Windows??), but decided we didn't want to sell kiosks.
one more q, i tried to use your referral code but i couldnt see where to add it. ive already signed up so perhaps its too late :/
Well even so making an UWP app just doesn't make much business sense. Just look at the Windows Store. All the popular apps is not UWP. And thanks to electron I can use discord, vsc and slack etc on linux just as I would on windows. That shit was juat not happening before.
Yea, you enter it on sign-up here: https://upcloud.com/signup/
For toggle to work the way BS4 implements it, bootstrap.js expects the outer div element of the the modal to have class="modal" and the attribute role="dialog". You're better off defining the modal structure separately and then declaring or loading in your form via a partial. Alternately you could add both via jquery with .addClass and .attr.
Thankfully's it's changing so that the UWP APIs aren't mostly restricted to Store apps. Now if you don't use them, you're an idiot.
I know in .Net core there's some code you need to include in your startup class that will register the service worker. It is a client side thing, but .Net still handles the initial page render, which is probably where the service worker would be initialized from if you aren't letting a frontend framework handle it.
Anything worth doing is worth doing right, which means don't reinvent the wheel. I'd search for a third party tool or library instead of hack it up yourself. Datadog is what I'm used to. https://www.datadoghq.com/
Pluralsight has a lot of material for all levels, I'd say take a look there.
The field is certainly getting smaller due the ubiquity of web technologies, and what‚Äôs left seems to be moving towards Electron and things like it, but I still do WPF for all new dev that‚Äôs Windows-only. I maintain some WinForms and VB6 stuff still, because ‚Äúif it ain‚Äôt broke...‚Äù
Ohh that's nice. I've recreated a big module on our production internal app quite quickly as a proof of concept when I suggested Blazor to the team. They we're amazed I actually finished the prototype quite quickly since all I did was reuse all the Request and Command Models and validation classes (FluentValidation) our backend had XD. Basically all I did was wire it up and reproduce the UI. That was the part that conviced the team that this was gonna be big and convinced management to use them for prod on .net core 3 for new apps.
few questions regarding the tutorial There is only one docker compose file, for production i.e. docker-compose.production.yml if i want to run this in dev, do i need another compose file? Also, i already have certificates from my exisitng domain so there is no need to create them in the init-letsencrypt.sh file. I guess it would be nice if the tutorial gave you an option. But the tutorial is quite long and it presumes prior knowledge on various things. I can get around the above with just adding my own certs to reference when setting up nginx targetting prod, which is fine. I guess i was hoping for something that would work dev, with the option composing this for production purposes, i think most people running in prod would get a cert from a trusted CA and not generate them (i could be wrong as generating it would be cheaper and perhaps you can just get a CA to authorise it) Perhaps the article should be more geared towards setting up a docker compose purely for development purposes i.e. composing the vue, postgres and .net core api into 3 containers and have them work nicely with apache. Adding the production steps perhaps should be relegated to a "next" article. This might be more useful since ive read that its better to use docker machines to deploy to remote hosting environments (correct me if im wrong) Perhaps my feedback is just based on ignorance as im new to using docker compose and then using it to target a production build. Still doing lots of reading etc. but other htan that the article is quite good i have learned a lot. i still have to finish it and get something working, but i wont use the production compose yml file. it wont work locally unless its in prod, as my domain is already live, unless i can use an equivelent of a hostfile in apache to route traffic from www.mmavideosearch.com to my local docker instance. ill stop ranting now, heh and i thought docker setup would be a weekend job. nope.
We have a few internal apps in UWP but they mostly talk to a .net core API backend, I'd say the team was pretty satisfied with how UWP as a framework works provided they didn't require anything that UWP didn't provide or only WPF provided. Overall I feel pure one platform desktop development isn't that popular anymore especially with all the hype with Electron XPlatform alternatives. Hopefully after WinUI 3.0 finishes with it's decoupled `XAML.Composition` and renderer is done being open sourced, we might find an Xplatform alternative as well, but that's a year off from now from the looks of it.
I wonder if they'll incorporate the new perf improvements .Net core provides after they finish porting it to production ready, `Span&lt;T&gt;` and the likes. Overall looks like great news for those who have legacy WFC code-bases to support but want to run on .Net core (we also have a number of WCF services as well, we might try to port if this goes well).
This is fantastic for the platform. We shouldn't willy nilly just abandon people's investment in a tech.
I definitely agree this is great news. At least with this tons of those apps built in WCF (there are tons even in our company, and a rewrite doesn't always pay off) aren't left in the dust, and can now host on Linux for a cheaper alternative hosting OS as well. Will definitely look closely on this on how this grows after they make it production ready. I'm curious what new features or improvements it will take now that it's open source. I definitely expect `Span&lt;T&gt;` improvements there.
I guess you refer to id attributes being unique in your HTML. Yes, that's how it should be. Your browser does not show an error if you violate this, but it's against the original intent. If you have two views, I assume you have two separate documents, so there is no problem. I'm not aware that it's problematic to use the same view for the add and the edit mode. Whether you really want two views probably depends more on your requirements than technical limitations.
I hope this becomes available as a trigger type for azure functions.
I've been using IOptions. so his argument for not using it is that you simply dont need it as you can just create poco's using his extension method which is quite nice. What extra bloat does IOptions add?
IOptions will be more efficient. It will allow you to get the "current" value (e.g. if the appsettings.json changes during runtime). You can achieve that with his approach as well, if you make it transient instead of singleton, but it will be a lot less efficient as it now always reads from the iconfiguration.
Participate in ASPNET Core development on GH, you'll learn a lot about how it works and good practice. You can just read PR from the team, it's really interesting
There are a million different kinds of search tree, each one faster than the last on some specific problem. But they're all an order of magnitude slower than a decent hash table for all common problems. My advice is: pick any good all-rounder tree for the general case but make sure your hash table is tip-top because that's what 99% of the developers will be using 99% of the time.
I hoped we could just forget WCF let it die out slowly and move on with WebAPIs, but I guess not.
There's nothing wrong with having separate views for create and edit and that has nothing to do with unique IDs in a single HTML document. Can you elaborate on what you mean?
I like this one: [https://miniprofiler.com/](https://miniprofiler.com/)
Look into design patterns. There are a few courses online (Udemy, pluralsight) where the instructor is implementing design patterns from the ‚Äúgang of four‚Äù book in C#. Clean architecture, unit testing, and ORMs like Entity Framework or Dapper.
I don't think "Business Process Management" is a good name for what you talk about in your article. And saying you should give away your source code for a commercial product is ludicrous. If you want to go open source then fine, but there are plenty of reasons for safe-guarding your source code when your software is a product you create to make money.
I am using dexie and it is very easy to work with. I can definitely recommend using it.
Yeah spend at least one or two weeks learning C#. Don't jump directly to ASP.NET MVC/Core. Make some console applications, etc. Once you are comfortable with C#, then * https://docs.microsoft.com/en-us/aspnet/core/?view=aspnetcore-2.2 * https://github.com/dodyg/practical-aspnetcore
Pay attention to ASP.NET Core 3. There's a major change coming up with endpoint routing (https://github.com/dodyg/practical-aspnetcore/tree/master/projects/3-0), blazor, etc.
&gt;C# is good at JSON serialization because of Newtonsoft. this, but unironic
If only electron wasn‚Äôt such a pig
‚ÄúStuck‚Äù like Most Linux users are until the run ‚Äúsudo apt-get upgrade‚Äù
thanks for advice, i guess i continue on Pluralsight, it's good and have path for MVC and Core and Web Api core, so i can learn different things, then Angular
Would you start building a house without learning how to use a hammer first?
It makes little sense to study Angular once you know ReactJS. It's better to invest your time on Blazor.
&gt;uilding a house w i asked some day ago why Angular it's so loved, i curious about this framework and why some many people that work with [ASP.NET](https://ASP.NET) used Angular, then most important things in my Country the majority ask [ASP.NET](https://ASP.NET) and Angular, so i need to know how work with both
i don't start building a chair without know how use a hammer :D
LLBLGen is modern and fantastic. They also really care about backward compatibility.
In my opinion when it will be time for you to start learning ASP.NET just go directly to ASP.NET Core. You can skip ASP.NET MVC as this is the old version of the framework
I think you misunderstood me. It's a free service on Azure, but it's not bound to Azure. ApplicationInsights doesn't care where you use it, it's only an API that your application communicates with to send telemetry. So for example I use in on my ASP.NET Core apps hosted on DigitalOcean VMs just fine.
Hash tables don't do in-order traversal, upper- or lower-bounds, etc.
[removed]
MVC is a design pattern and applies to core as well
I know that but when we talk about ASP.NET MVC we are talking about the Framework itself. OP is going to discover by himself the MVC design pattern through ASP.NET Core that's why I was advising him to skip the previous Framework.
Please don't say you "know PostgresSQL, MongoDB": they're simple data persistence tools, you "use" them you don't "know" them. If I caught that on a resume it'd be an immediate red flag.
I am still a bit confused, do you need to use Azure for it or does it have a locally hostable "admin" where you can check the telemetry data? Thank you for answering me, I really appreciate it!
It's all good, for dinner reason I was thinking the HTML figure was the whole application.
I would pull down the gRPC GitHub repo and take a look at the 2.2 version of their host, play with the proto3 (protobuf) schema, change it, and look at how their services register (it's easy) and how yo make a client. Then pull down the Microsoft dotnet core 3.0 preview version of the asp.net core kestrel host for it to get a feel for how it's different and registers with the pipeline. There is a lot of hype right now with protobuf and gRPC and although I'd like to see better tooling support before using for production I feel like it's a worthy investment if time.
Guess I'm in the minority but I actually rejected all JS frameworks as it added too much complexity, especially on the deployment end. Pure vanilla JS with razor views seems to be working super well and easy. Now Blazor is interesting but something comes off like it will be another Silverlight.
I think you'll have to elaborate a bit. Do you aim to stream video from a server to one or more clients? Or do you try to stream from your computer to a remote service? (e.g twitch, youtube etc)
I aim to stream from a personal computer, out through a hosted site
www.liveswitch.io
Most solutions out in there are RTMP server or similar. There are plenty of server implementations done in various languages however most of the servers are paid for service which aren't that cheap. They are geared for customers that are broadcasters. There are open source implementations but these aren't in .NET. This seems to be a decent implementation of a client library in C# on the face of it [https://github.com/hinaria/rtmpsharp](https://github.com/hinaria/rtmpsharp).
You could try https://github.com/ZeBobo5/Vlc.DotNet/blob/develop/README.md to receive the videostream, a collegue did this for a HikVision camera and this worked very well. Other solutions had problems of some minutes of delay after a day of streaming. But I don't know if you can also broadcast with it
Alright, then it comes down to what the receiving end wants. Is it rtmp or similar? Anyhow, what I've done earlier when there is no existing SDK or framework (which fits my needs), I've turned to ffmpeg. What you can do is start a process with C# with arguments to ffmpeg, an example can be found [here](https://stackoverflow.com/questions/26583828/use-ffmpeg-executable-inside-c-net-project/26589410#26589410).
You log into Azure to see the ApplicationInsights data. I'm not aware of any locally hostable AppInsights dashboard. So AppInsights is indeed on Azure but your application that uses it doesn't need to be hosted there.
Yes in some of our applications we do use Dapper. Our main application uses NHibernate but this has advantages and disadvantages. IMO it is quite easy to separate database access for identity and database access for the other data access. EF or NHibernate or something similar works great for small to medium sized applications. If they grow in size or the amount of concurrent users grow then a combination of caching and simple data access frameworks are a good way to go. Look at the architecture of stack overflow for a nice example
Thank you very much for the detailed answers.
What are the missing features you're waiting on?
There are so, so many ways to stream without .net . Whats your reasoning for needing the .net stack!? There are countless other solutions for this.
I landed my first job as a junior Dev this year (3 months ago). Previously I did 10+ years in hotel work and coded in my spare time, mainly in python. I had never touched C\# or .Net before starting. Someone on my team set me a few tasks to learn the basics and then I moved onto a project using asp.net, razor etc. You should do the same. Plural sight is great - but nothing beats actually doing something. The brief I had, maybe you could try was this: Create a console app that takes a user's input, their name, dob, company name and how long they've worked at that company. Generate an insurance quote that gets returned with a base cost of ¬£200. If their second name begins with an S, they receive a ¬£20 discount. If they have been with their company more than 10 years they receive a ¬£20 discount. If their company name begins with an F they receive a 50% discount post all deductions. It was great to learn syntax, flow and a general hands on feel. Once I completed the console app. I had to make it a web app. Was great!
Thanks, i tried to find the github of stackoverflow. is this it? there are so many projects, not sure what to look at, besides its stackexchange, perhaps it doesnt have the repo? tried a few other google keywords, no dice. unless the project is in this url https://github.com/StackExchange As for using nhibernate over ef core, is there a reason? A few things bother me in efcore that are not problems in regular ef like the n+1 problem and you can't do a lot of simple operations like unions, they are executed client side. doing left joins is a nightmare and groupbys are tricky to do without them ending being executed on the client. so for a lot of read operations im just starting to use dapper if the query is say mainly used for reads like a report. is it possible to do the reads with dapper then do mutation on the returned data mapped to an efcore poco entity class and commit it with efcore? to add to that, would it even be worth using efcore, the benefit with efcore is that you dont have to write the sql. As for using dapper to read to an entity poco, i presume you just attach and efcore will play nice. does that sound about right?
Done üòÇ
Hey man, finally have time to answer you! &gt;As for using UpCloud what kind of plan do you go with? I just use a single $5 or $10 server. For full production stuff with legit traffic, go with the $20 servers. &gt;People said not to containerize the db. when i putting my sql server in the docker container, i thought to myself, this seems like a bad idea as the containers are supposed to be "transient" for lack of a better word A data volume is not transient. Your db service might be spun up or spun down, but your data won't be. &gt;though im running sql server so it might be a bit heavy on the vms from UpCloud, or do you think not? SQL Servier might be? I'm not sure, just test it out. You might need a server with more memory, perhaps? I use Postgres because it's free and just as good with asp.net core. &gt;would this be worth putting in another container? or should i just put it in the same container as the api? Each service should be in it's own container, like the setup in the tutorial. When you look at a docker=-compose file, each service is a "soon-to-be" container when you user docker-compose up. Hope this helps!
&gt; There is only one docker compose file, for production i.e. docker-compose.production.yml &gt; &gt; if i want to run this in dev, do i need another compose file? Yes, create a docker-compose.development.yml file (or staging, whatever you want, really). &gt;Also, i already have certificates from my exisitng domain so there is no need to create them in the init-letsencrypt.sh file. I guess it would be nice if the tutorial gave you an option. But the tutorial is quite long and it presumes prior knowledge on various things. Just put your existing certs in the cert directory and call it a day. Just know that if they're not lets-encrypt certs, they may not be renewed. Or just create new certs. It really doesn't matter. &gt;I guess i was hoping for something that would work dev, with the option composing this for production purposes, i think most people running in prod would get a cert from a trusted CA and not generate them (i could be wrong as generating it would be cheaper and perhaps you can just get a CA to authorise it) The script doesn't generate them. It connects with Let's Encrypt (by way of Certbot) and creates legit ones. &gt;Perhaps the article should be more geared towards setting up a docker compose purely for development purposes i.e. composing the vue, postgres and .net core api into 3 containers and have them work nicely with nginx. Adding the production steps perhaps should be relegated to a "next" article. This might be more useful since ive read that its better to use docker machines to deploy to remote hosting environments (correct me if im wrong) I don't know. Setting up dev is quite easy, in my opinion. It's the production stuff that's more challenging - which why I did the article lol. Like the article says, it's not a beginner's guide by any means. &gt;i thought docker setup would be a weekend job. nope. Lol, no, it is not. I spent about 2 months studying docker on and off to get a good feel for it. Out of everything that I learned, this tutorial by Stephen Grider helped me the most: https://www.udemy.com/docker-and-kubernetes-the-complete-guide/ Good luck!
Because he‚Äôs a .net developer?
thanks i appreciate you answering my questions, like i said i was probably going to be wrong on a lot of it as im still a newbie. i decided to go back to scratch and slowly build up, ive got .net core working in docker, now its angular. so i got angular working now im trying to get it working with nginx. the tutorials online i follow, i delete everythinig in the default apache folder and copy my angular stuff in going to the url on my browser still shows the apache default hellow world site :/ not asking for help, just airing my frustration haha all that info was good stuff, and i guess i should probably go back to your guide once i get my head around things more just from a basic dev setup. ive heard good things about www.udemy.com a couple people mentioned it being the best for getting your head around docker. you reckon its worth the money? i had a pluralsight subscription but i cancelled it, i found most of the videos either too basic or the advanced ones to tackle a problem i had were bad solutions for any number of reasons. for udemy.com, is it good for other topics like .net core and angular? ill get a subscription if its quality stuff. usually to get really good guides, its a book or a blogger whjo knows his stuff. googling problems often leads you to SO posts with people posting answers that often will work but are not best practice or will bite you in the end or are just flat out wrong.
yep thanks again, your answers are great!
This is a nice read: https://nickcraver.com/blog/2016/02/17/stack-overflow-the-architecture-2016-edition/ No ORM is used. Mainly because of performance concerns. When we started building our main application (an ERP application) we used EF (5 I think, could be 4). This became troublesome quickly. Moving to NHibernate solved the issues we had with EF. It is a fair bit less abstract in the sense that it allows you to better control how the actual database querying will be done. One of the requirements of our application used to be that it could be installed on premise at our customer's network but also in a cloud based SAAS offering. Having just one database system makes installing our application a lot more easy on the customer's network. But this approach of having 1 database as a back end system for all types of functionality is architecturally not a good choice. A few examples: - Reporting has very different requirements on the way the data is stored in a database. - Searching functionality and especially text based Searching is hard to do - Recursive querying over data (like in social data where people have friends that have friends that have friends) requires yet another way of storing and reading data To solve these issues we had to make some compromises. Mainly in being memory efficient and we do have some performance issues. But NHibernate allows us to cache data at different levels and also to delegate the cache storage to an external server like Redis. This supports our cloud scenario quite well. We also have the challenge that we need to support m Made to Measure functionality. We support 3rd party plugins that can extend the existing data schemas. This basically means that the set of data returned from a query is extend at the result set column level and that the query has additional joins and where clauses. Here is where NHibernate really excels over the other ORMS. This scenario is very difficult without an ORM. But generating reports using NHibernate is slow so for that we bypass the ORM and fall back to plain SQL. As far as attaching disconnected entities this might work for you as long as you can keep the time short between reading the data and updating it in the database. Preferably within the same transaction As far as not having to write sql. The time spent on writing the SQL is just a small bit compared to total amount of time you spend on building some kind of functionality. It is tedious but that should not be the reason not to do it. The benefits of an ORM are found mainly in other aspects like reduction of complexity and improved maintainability. By the way it seems that the new version of EF core that ships with .net core 3 will solve a lot of the current EF core issues.
Oh I couldn't find it so I started learning c#. Tbh, its really good lol
&gt; This basically means that the set of data returned from a query is extend at the result set column level and that the query has additional joins and where clauses. Here is where NHibernate really excels over the other ORMS. This scenario is very difficult without an ORM. Thanks for that answer, very interesting. regarding what you wrote here. I take it that you can further refine the query from a result set and perform more joins on it? or am i not understanding this correctly as this kinda flies in the face of what i know about ef core orm now. basically once you have your data thats it, if you want to do another query its not attached to that same data set i.e. to perform additional joins unless you use explicit loading on navigational properties. e.g. you might want to load a sub table given business logic
What is the source video?
I think the guys point is there are so many ways to stream without having to program anything at all.
Maybe not quite what you're looking for, but have you looked into something like Azure Media Services? I think you can get streaming up and running pretty quick. Probabyl has good .net integrations /api as well.
In ef core terms its called lazy loading. I prefer fluent configuration of my entities and lambda expressions for the queries. I can then use .AsNoTracking() and .Include() as needed.
There is a native folder structure build into nuget so you could try that. In any case if that doesn't work you would just need to make sure that the following is correctly configured: - targets file is loaded (test this with a test target that prints a message and initialtargets set) - items are included in the content items ``` &lt;itemgroup&gt;&lt;Content include="$(MSBuildThisFileDirectory)nativebins/**/*"&gt;&lt;/itemgroup&gt; ```
You could probably just wrap a ffmpeg process. [vMix](https://vmix.com), which is written in .NET, does that for streaming.
Not the answer the OP was looking for. He specifically asked for a solution in the scopes of the .net stack, what relevance does you answer has to this question?
but who are we to decide what ops requirrments are lol
Care to put your pen where your mouth is? If you, or someone you know, is interested in writing about LLBLGen I would be happy to publish it on http://InfoQ.com . We've interviewed LLBLGen founder Frans Bouma before, but I'd love to hear some an unbaised source about their expereinces. Maybe a critical review of its good and bad points or a getting started guide. It would be a good way to spread the word about the product, which I think is necessary for it to survive given how much competition there is for ORMs these days. If you're interested drop me an email at jonathan@infoq.com.
Your post has been removed. Self promotion posts are not allowed.
No once the query is done that's it. But try to imagine the following scenario. You have a CRM application. This application has a view that shows the names of all the customers and the user can filter these customers on properties like their name or address. This is not a hard thing to develop using plain SQL. But now you want this application to support plugins so that afterward someone can add additional data to the existing data scheme. Let's say that this plugin allows the users to store and show the pets that the customers own. To do this you will have to add a pets table to the DB, add additional column names to the select add a join to the query and add a restriction to the where part. Remember this is done through a plugin that you do not develop yourself. How would you support that using plain SQL? If you think you have found the answer then try to imagine how you would solve the situation that yet someone else will build a plugin that adds the capability to store which types of food those pets like... If you have made some kind of way to dynamically build SQL you will quickly run into complex code to support this but it's quite easy with an ORM.
1) You are using a Timer to handle scheduling? Come on. 2) No mention of TopShelf which would save you an entire post 3) No mention of .NET Core 3's hosted background service worker that changes all of this dramatically. I don't see what this tutorial brings over other older ones. Sorry.
You shouldn't be able to reference the SignalR .NET Core package from your .NET Standard library. But the SignalR package depends on .NET Standard 2.0, not on .NET Core.
&gt; You shouldn't be able to reference the SignalR .NET Core package from your .NET Standard library. Do you mind elaborating on this? I have installed the nuget package for AspNetCore.SignalR.Core into my .net standard class library and I seem to be able to use it. Thanks again and I appreciate you taking the time to walk me through this.
1. I can't see why I should use quartz for just simply implementation of scheduling. Timer works just fine. 2. I used TopShelf and will never recommend to anybody to use it. KISS (keep it simple stupid). I can even write a post why you should never use ut. But probably later :-) 3. that one sounds cool, will investigate this one. Thank's for you comment!
The `Microsoft.AspNetCore.SignalR` NuGet package has a dependency on .NET Standard 2.0, not on .NET Core. That's why you can use it in a .NET Standard library.
If this is the case, can I still use my .NET standard Library in a .Net Framework app?
I think what they're saying is that .NET Standard is the base, and either .NET Core or .NET Framework can depend on a .NET Standard library/package, but Standard can't depend on either of those higher levels and neither can they depend on each other. Since AspNetCore.SignalR.Core is at the base level (.NET Standard), both Core and Framework can use it.
ahhh! Thanks for clearing it up! :D
Yes. You can safely use .NET Standard libraries in projects targeting .NET 4.7.0 or higher. For the most part you can use them in .NET 4.6.2 as well, but there are known issues (that won't be solved anymore).
Thanks! I understand now.
Don't... If you're a web d√©velopper, develop websites. If you want to develop an app, use the proper native way of doing it
Also take a look at NSSM to help with hosting. I prefer it over TopShelf myself.
yes, have used this one but now prefer to use powershell, simply because we are using it for our CI/CD
You dislike electron huh?
Of course, it's the worst thing that happened to development with node.js (in my opinion obviously)
Fyi, I've written a wrapper lib over the windows API calls to manage windows services to create/update/delete service registrations - [https://github.com/dasMulli/dotnet-win32-service](https://github.com/dasMulli/dotnet-win32-service) Also contains an alternative to ServiceBase which is conceptually simpler for simple services but maybe no longer as useful since ServiceBase was added to .NET Core 2.0 (and before that, it was not part of the MIT reference source so I couldn't port the original one or its API without getting into legal grey area).
Has anybody ever used an electron app and NOT wanted to burn their phone afterwards?
Sure. The product does a lot of thing but I primarily uses its LLBLGen Pro Runtime Framework.
Isn‚Äôt discord electron? Visual studio code too. Twitch‚Äôs desktop client might also be electron...
You recommend handling two code bases for any application that needs to exist on mobile? What if it needs to exist on mobile and desktop? 3 code bases. Maybe an API layer that adds a fourth? I'm not saying electron is great or anything, but use the right tool for the job. Sometimes electron is that tool.
Each platform have different constraint in term of design (for those who still cares...) So you will end up having a lot of platform-specific code in your giant mess of "one project for every platform"
I'm not saying it's a one size fits all solution. I'm saying to completely exclude it is wrong.
I‚Äôm very interested to hear your recommendation against using TopShelf. What‚Äôs the TLDR?
Use an electron app on your phone? I didn't know that was possible. I thought electron only targeted desktop.
Who wants to pay for the overhead of a server to run a scheduled job? Why even bother with windows service? Just make a lambda function on AWS that is triggered by a step function or seeing as your'e using Azure logging, use Azure Function with Azure Logic Apps. IMHO this is how you make this blog post relevant.
The last time I tried this it didn‚Äôt work but I‚Äôll give it another go if this guy got it working.
Electron is for desktop. Are you thinking of Cordova?
Right... It‚Äôs not like one of the most popular source code editors right now is electron.
He is right though. Web technologies mostly suck. Their only advantage is that they suck in a standardized way, and therefore will run on all platforms with (theoretically) no changes, so it is cheaper. If you want to take advantage of the platform you are running on, or simply follow its UI and UX guidelines *like you should*, you have to add platform-specific code, so you lose most of this advantage.
Yeah, I'm interested in your answer as well. I've gotten a lot of miles out of topshelf. I'm curious what you find bad about it.
&gt; If you are putting user first and not money first, you should have multiple code bases Businesses will _always_ put money first. However, if you're a small team (maybe one-man?) then anywhere you can save money can be the difference between surviving another month or going bankrupt. I say this as a mainly backend developer who hates frontend.
Maybe react native?
I'm on the fence about it. On one hand Microsoft made vscode in electron which is awesome and performs nearly at native speeds, on the other hand Microsoft made teams...
AWS Lambda has a Cron timer that can trigger scheduled events. The only limitation we experienced is the smallest interval you can choose is 5 minutes.
My app used Quartz and I ended up removing it in favor of a handful of Timers. It was way overboard for what I was doing. Just because you can dump in a fully kitted out tool doesn't mean you should when a primitive will do.
Out of curiosity, what are modern use cases for gRPC, and WCF that it supposedly replaces? When would I want this over WebApi?
gRPC is a newer API tool, a way to build cross platform / cross code APIs. WCF as far as I know is limited to .Net Framework. https://grpc.io/docs/guides/concepts/
Streaming items to/from the server, among other things (similar to what you can do with SignalR in ASP.NET Core 2.2+). I'm not knowledgeable enough to know all the benefits of the fact that gRPC uses HTTP/2, but I imagine that you get a lot for free because of that, too.
Performance. gRPC uses the binary Protocol Buffers by default. REST uses text-based JSON. Yes, I know that neither PB nor JSON are required by the respective standards. But they are what's used the vast majority of the time.
I suspect given his replies and NIH syndrome that there isn't a legitimate reason for avoiding it.
"gRPC may or may not have been developed as a replacement for WCF" this is a silly statement. gRPC was developed by Google. There is no "may" about it, it was not developed as a replacement for WCF. They developed it for their internal services then later open sourced it.
I generally agree though there's also the case of cost which can affect decision making or how complex your app would be. If it's very basic I'd guess you can get away with an Xplat solution (most apps I'd say which is why a web-codebase works most of the time), but you'll always end up with the lowest denominator platform features only with the one codebase approach, features that work on both sides without platform conditionals which can be limiting. The very concept of Xplat has always been compromises honestly it's impossible to create an xplat solution that fits all due to the fact that platform specific code will always be needed or may not even exist on other platforms so abstractions doesn't always save you and you'd need to create wrappers for native stuff in the end. I'd say how `Xamarin.IOS/Android` approach is much more preferred imo, one language and "business logic" code but the interaction model and UI is tailored fit for each platform. That way you don't need to reimplement your business logic on each platform but still get to use all the native capabilities of the platform without compromises (some niche feature, platform specific extras etc...).
&gt; WCF as far as I know is limited to .Net Framework. [Not anymore](https://github.com/CoreWCF/CoreWCF). It was [announced](https://devblogs.microsoft.com/dotnet/supporting-the-community-with-wf-and-wcf-oss-projects/) just a few days ago with MS giving WCF to .Net foundation and open source it and make it .Net core compatible. It's still quite early but that's the goal from what I can tell.
Gprc is fantastic for internal apis between different microservices. Rest or Graphql is great for your public facing apis.
Yea Teams is horrible
Visual Studio Code is electron and it runs fine. It is not about electron, it is how you write the application for it. Write an application with shit optimization and you will get shit performance.
A comparison of gRPC and HTTP APIs: https://docs.microsoft.com/aspnet/core/grpc/comparison At some point I'll probably add one comparing gRPC to WCF.
.Net Standard is an specification rather than a runtime. As long as the version of the framework you want to use adheres to .net standard it should work.
discord is great
Yo dawg, I heard you like native so I put native into web into native.
I think it's a bit more nuanced than what OC proposed. I probably wouldn't want a game built of electron, but I can think of more than a few cases where electron is a good choice. Simple apps, small dev shops, lack of knowledge in certain tech. I'm not saying your second point is wrong, I just think there is room for interpretation and OC doesn't seem to. Also, web tech doesn't suck. It's good at what it does and enables a huge amount of people to contribute.
This! There are levels and electron is one of those. Not everything needs to be native.
I am a developer who loves front end and I agree. Not everything needs to be native or should it be. Electron fits a lot of use cases and small teams is one. Simplicity is another.
That doesn't sound like anything I've seen before. Try starting over with a new project. Maybe your csproj is corrupted.
What's wrong with Teams?
What's NOT wrong is easier to answer: Often, when you send a message to a channel or contact, the message is delivered.
gRPC was a child born in google to take case of scenarios for communicate across services behind load balancer. It‚Äôs crazy fast and efficient. Search Istio and respective tutorials around it, it will be helpful to understand and build the gRPC concept.
Compare VS Code with Sublime and I think you will reconsider what 'fine running" is
Startup time is unacceptable. Compared to Slack it is getting a little bit better but it feels clunky
Startup time is unacceptable. Compared to Slack it is getting a little bit better but it feels clunky
That sounds like desired behaviour to me
I've used both and I haven't really been able to tell a difference?
‚ÄúOften‚Äù. And that‚Äôs the only thing that somewhat works.
There‚Äôs not many decent ways to make desktop apps anymore.
If it‚Äôs a mess, you don‚Äôt know how to properly refactor and structure.
When it comes to the programming languages team and dev tools, Microsoft has really talented people with very good direction. Look at how C# and the Roslyn team have come in the past years. And VS (Code and full) are some of the most powerful and polished IDEs around.
I do agree. Sadly, it‚Äôs the problem of an easy solution that fills a void. Prior to Electron what were your options for making a cross platform GUI application? Java Swing? Qt? GTK and the headache of running it on non-Linux? Adobe AIR? Everything sucked and a lot of them limited what backend language you could use. I wish WPF would have gone cross platform with .NET Core and an OpenGL renderer.
My experience with Teams seems wildly different. The only problem I can recall is once when my internet connection dropped and reconnected, Teams didn't want to connect back to the server.
I use a dozen extensions that are not available for sublime. Extensions for sublime are a pain.
But the "W" stands for "Windows" /s
Have you looked into QML.NET? https://github.com/qmlnet/qmlnet
Nope but thanks for that, I‚Äôll check it out!
WCF can utilize REST too, am I right?
Yes, though without something to generate proxies from Swagger files you very rarely see it done.
Generally speaking you would use WCF or gRPC for application to application communication. Especially when both sides are using strongly typed languages. WebAPI only makes sense when your client is a web browser. For anything else its a clumsy hack as HTTP wasn't really intended for this purpose.
What I'd like to see is a gRPC binding for WCF. I would gladly trade the (probably tiny) performance hit for a consistent API.
I don't think an overhead of dozens of megabytes on disk and in memory of very complicated code just so that your app can start is a good choice for about anything.
It's on my personal list of things to do with CoreWCF once I've got the current code into good shape for the existing main scenarios.
Could be easily done with castle Windsor wcf facility
I do a lot of react-native projects and besides setting up native modules for each platform, which are basicly plugins for different services like firebase, we use relatively little platform specific code. And when we do it, it usually a small component that is seemlessly overridden with a .ios or .android file which contains the platform specific feature.
Upgrading to Core 2.2 fixed the problem. Strange.
When you are working with a list as a property of a class , and the class is already instantiated , what is the point of the null reference exception when you explicitly want to add an item to it ?
Never had similar issues even with version of net core prior to 2.2. This was probably just your local issue.
Link please. I haven't seen that one yet.
Did I ever tell you you're my hero?
It means there's a dependency that is incompatible with your project, or conflicts with another package installed. It makes sense that EF would fail, but start working once you update to 2.2. If you look at the requirements of the package it will probably say it requires Core 2.2. If you had to use it with a previous version of Core, you could probably install a slightly older version of EF.
[removed]
A LOT of successful apps on electron is out there. Your snobbish attitude is your mistake, the tech is good, and it is here to stay.
I've been using Teams for almost a year now and I'm definitely experiencing a different product to you seem to be.
A successful technology doesn't mean it's good. It just mean that people want to use it because it's easier than learning something else. Bringing websites into standalone windows is neither HTML, CSS or even JS goal. It's just a hack that someone created because it didn't wanted to learn a desktop language. And by the way, JS is an horrible and incoherent language.
Being successful means it works. It accomplishes the goal that is set in a reasonable timeframe. Not a lot of frameworks out therr that allows you to build as fast and on as many platforms as electron. It's not some theoretical battle of what is good and what is bad. It's a tool that help make things happen, today.
You also visit our facebook page for daily updates ([Click Here](https://www.facebook.com/YasirMFazal/)) Join our whatsapp group ([Click Here](https://chat.whatsapp.com/invite/FeqdahBLTKTIAtDNPJhmAr))
time to close out of your shareware and give vs code another try, can't tell the difference anymore in speed
&gt;Their only advantage is that they suck in a standardized way, and free, they are mostly free
The REST support in WCF is **very** limited. Basically all you realistically can do is make endpoints available via HTTP.
Here are Stanford NLP libraries [https://nlp.stanford.edu/software/](https://nlp.stanford.edu/software/) As they say there, some of the libraries are translated for .NET too, you can check what they have and what is available for .NET
&gt; REST uses text-based JSON. This is very often the case, but the statement in itself is wrong. REST services should perform content negotiation. It's just that most people don't give a shit about REST and just use JSON.
Your post has been removed. Self promotion posts are not allowed.
Thanks. I did stumble across the Stanford libraries, but the licensing is restrictive -- no commercial use.
If you don‚Äôt find anything suitable consider using IronPython.
Very shilly sounding comment.. What you said has very little to do with the comment you're replying to. He said MS Teams is crapola and you're saying Microsoft makes great dev tooling. No one's arguing that Microsoft isn't great at making dev tooling, it's just that the difference in usability between Visual Studio/VS Code and MS Teams is staggering. Obviously even at Microsoft there can be a huge difference in quality between teams.
&gt;Isn‚Äôt discord electron? Think Discord is React Native. Discord is basically a complete counter to your argument since they had a long discussion over choosing the right stack because JavaScript execution on mobile devices was so slow that it made the application completely non-viable if it was written in pure web tech without any native parts.
This is probably what you want: [https://www.luis.ai/home](https://www.luis.ai/home)
MS Teams is woefully slow but if you're on $1500+ hardware you probably won't notice. Either way it's incomparably slower than VS Code.
You can roll your own with ML.net as well.
I'd never heard of that before. Thanks.
Interesting.
I don't think anyone's arguing that you can make both a shit and a normally performing Electron app. It's just that some technologies are slower by default so it takes a lot more effort to optimize them. Even the shittiest native (WPF, UWP, or even WinForms) application will outperform the fastest Electron app. But we can't do cross-platform with those .NET frameworks so we use Electron. There's no arguing why Electron is popular. It's better for cross-platform dev than what we currently have and I will agree with you day and night. But don't even start to argue that Electron apps "run fine". They run fine only on expensive hardware.
A second Microsoft offering, different to Luis. Thanks.
Compared to other cross-platform UI solutions like Qt or GTK, yes it is worse. But I am betting that Microsoft did their research before putting in resources to make VS Code and they still choose Electron over Qt or GTK. I can only deduce that the performance drop was not that high.
Compared to other cross-platform UI solutions like Qt or GTK, yes it is worse. But I am betting that Microsoft did their research before putting in resources to make VS Code and they still choose Electron over Qt or GTK. I can only deduce that the performance drop was not that high.
I did try topshelf but am not using it anymore. Mainly because the command line parsing really sucks. A coworker if mine managed to install a service with the service name "ervicename" and display name "isplayname"...
Try .NET is a great tool to create interactive markdown-based documentation. You mix markdown with code blocks linking to a project behind the scenes, and you get interactive code that you can run from inside the browser. &amp;#x200B; The links are to small parts of the code, so your interactive code doesn't need to contain everything - just the code you want the reader to see and edit.
https://github.com/sergey-tihon/OpenNLP.NET
This type of thing makes me feel like a neanderthal of coding lol
This makes me uncomfortable. This is to avoid lock()?
No, it is to avoid ThreadAbortException from interrupting code in critical sections.
According to the article there is no Thread.Abort in .Net Core, according to the article ThreadAbort was the one exception to breaking the "uninterruptability" of finally blocks.
[These people](https://social.msdn.microsoft.com/Forums/en-US/2299aaa9-ffea-40aa-83b5-b9649d9c8508/can-a-finally-block-be-interruptedsuspended?forum=csharplanguage) seem to think finally _can_ be interrupted. Who is right?
So how does this work? Does it need server support, sending the code back to be compiled and ran there, or is this using something like WebAssembly to do everything in the browser? Or is it perhaps running everything on an external hosted service somewhere like with the [Go playground](https://play.golang.org/) (which can also be embedded, but will still run the code on Google's infrastructure^(1))? That seems to be a rather important distinction: if it needs server support that somewhat limits its applicability, but if it's all client-side then you could just plop it onto any static web server (AIUI) and it should work. ^(1): Though IIRC that one still uses a bit of server configuration to forward stuff to the hosted server.
No, ThreadAbortException cannot be raised in a finally block. That is why it is used in really critical sections to avoid any chance of ThreadAbortExceptions interrupting things. Much of the code in CoreCLR comes from the .NET Framework which does have Thread.Abort, so it is likely most of the empty-try-with-finallys came from the .NET Framework.
[Apparently](https://github.com/dotnet/coreclr/pull/8949) these are optimised away in .NET Core now. As /u/ylyn [stated](https://www.reddit.com/r/dotnet/comments/byvwpr/empty_try_with_finally/eqms1vi/) they are merely an artifact of attempting to avoid Thread.Aborts in non-Core environments.
\^ This. I have had to edit the project file manually to update correctly because it can get stuck with downgrade errors which rollsback the whole transaction.
It can use client side Blazor, so WebAssembly.
There are a few different ways to go about this. First, you can redirect the user to a specific 'Product not found' page. If you would rather not redirect the user, but keep them on the same page, from your Controller you can add something to the ViewData which indicates an error (the product was not found). In your view, you'll add logic to check the ViewData for an error, and if one is found, display the message to the user.
It uses WebAssembly
I can heavily recommend any training by Brent Ozar for the SQL Stuff. They tend to have deals on Black Friday for dirt cheap 'everything pass'. &amp;#x200B; Learned a lot from his courses. How statistics work, query performance, clustering etc.
And that‚Äôs precisely why I said to look at the track record of the IDE and languages teams. MS is obviously a large ship and doesn‚Äôt always hit the mark in all their products. But every iteration of VS from 2003 to now has been constant improvement and feature addition, while streamlining as much as possible. Anyone who used TFS shouldn‚Äôt be surprised.
It depends. Its easier to kick off the project if they live together, and its not too much effort to cut the SPA part out if you feel the need later on. Some pro to separate them: - you can scale the api and static hosting separately - easier to maintain separate code base if you have dedicated frontend/backend team. Not just the skillset, but different build pipeline, different tooling, etc - deploys can go separately if you respect backwards compatibility. This will be visible if you can do frequent deploys for low hanging fruits - you can choose different hosting solution for them, which can both cut expenses and increase performance some con: - more initial effort including setup of CORS and configs, setting up different rules - slightly larger release window if your frontend/backend components share versioning - your vertical stories will be split to components, can make the code review process slower and merge orders forced. Unless you guys will focus on the same project for years in a big team, or you already have the templates set up for different parts, i would recommend to put them to the same place.
If he wants a job in development he should not learn Blazor but reactJS instead. I see react jobs all the time and I have not seen a single job with blazor.
Yup - it all runs client side using Web Assembly. It runs locally which is great for offline learning. In theory you could totally drop it into any static web server and it would work. There is an open issue in GitHub about providing a simple way to publish to a static site.
It's really nice to have this syntax even if it's optional. It makes so much more sense. Coming back from languages like Kotlin or Swift the Java-style optional references really look dated.
well obviously that was the missing dependency ;-)
Cheers for the tips. I'll have a go at building both perhaps to see the differences.
Blazor is not out yet until later this year.
Since these are community driven, I'm sure only companies that badly need WCF will consider these options. While I currently work on a project that is heavily leaning on WCF, we did move the UI from Silverlight to Angular, so I really don't know if we'll get to work on the heavier lift of going to Core ever. I've worked on a lot of other projects--some with Core, and some Go as well--so I don't think I'll be heartbroken if this project never leaves Framework.
Or you can just use OpenNLP and IKVM.
Why Apple? Why isn't it a standardized login method such as Google, Microsoft, Facebook, GitHub, Auth0, etc etc etc
it removes try but not the finally block I think?
 It's not, he doesn't know what he's talking about. Heard hype about hating on electron then just spews out.
Log in with Apple is the new gold standard for third party authentication services as far as user privacy is concerned.
The point is, someone starting out should not invest time in something that is not even out yet. New comers should be learning existing stuff that has been out long enough for tutorials, stackoverflow discussions/questions/asnwers to exist.
Does anyone have any experience with this? Text-based run-time configuration of libraries always makes me nervous and I wonder how easy it is to shoot yourself in the foot with this thing.
Could you elaborate? The article states that Apple uses OpenID Connect with a JWT-esque token. Auth0 on Sign In with Apple: https://auth0.com/blog/what-is-sign-in-with-apple-a-new-identity-provider/
Doesn't matter. Windows tablets are a joke, the only one doing well is the surface and that's because it's basically a laptop. Having had my share of all the platforms I can definitely confirm that windows tablets offer a remarkably poor experience.
&gt; (I already know HTML, JS, CSS, ReactJS, PostgresSQL and MongoDB This is what Op wrote. They already knows ReactJs.
We'll be watching this one's career with great interest. /palpatine
Oof, sorry! Only if I could read.
There's always `git filter-branch --subdirectory-filter` to help you split out directories to new repositories later while preserving commit history. GitHub has [a nice tutorial](https://help.github.com/en/articles/splitting-a-subfolder-out-into-a-new-repository)
Assuming username variable is string type, C# equivalent would be: var q = (int)username\[i\];
The Chancellor's right, Senator. /padm√©
Cool, a migration path for WCF is a showstopper for us ever moving to .Net Core
If I never see a NullReferenceException again ü§ì
Hmmmm ü§î nope üëé
Oh come on. Don't you want to spend another decade hiding your loops and function calls in WF-XAML files?
Sigh, I really wish my boss would allow me to write headlines like that.
I'll miss them. I could knock out 3 or 4 in a good morning before settling down to fix a hard bug. Like coasting down a hill before having to climb the next one.
Unfortunately they don't have the option for API projects made from templates. I just usually create an MVC app template and then delete all the MVC stuff. It's faster for me. Alternatively you're stuck using the extension methods.
Link to Microsoft article: https://devblogs.microsoft.com/dotnet/supporting-the-community-with-wf-and-wcf-oss-projects/
That is one of the repos I stumble upon, read a readme and still don't know where I could use that and how :(
You irk my life by not making the C uppercase
What's wrong with leaving WCF on .NET? It's not like there is a gun to our heads to move everything to .NET Core.
Sounds like you should look into the Telerik components (especially their Grid). They‚Äôre paid, but well worth it.
Short term? Nothing. Medium/Long term all of the new development, libraries, etc are going to go to .Core leaving classic further and further behind. Plus the communications layer backing our WCF comm stack would most directly benefit from the recent performance work they've done in core.
Amazing
The standard response to this in the past has been to keep them separate, run angular in visual studio code and the API in visual studio.
jQuery datatables can do this
Can you recommend some jQuery packages for this?
This is what I‚Äôve struggled with. I need some flashy way to demonstrate use cases. As it stands, you can interrogate an sql dB for its schema, then write out say, class files that represent the tables. I know it‚Äôs not a new concept. This is a different approach from what I‚Äôve seen. Could be a controller, could be a view mode... maybe a repository. Boilerplate mundane typing be gone.
It‚Äôs included with jQuery UI
This is the setup my uni team is running at the moment. I might just stick with it
how would you have finally without try?
Casbin.NET (C# version) is fairly new. But Casbin in other languages (Go, Java, Node.js) have already been used in many real-world cases and companies: [https://casbin.org/docs/en/adopters](https://casbin.org/docs/en/adopters) . The text-based configuration (model, policy) is supported mostly because of easier demonstration of examples and maximized flexibility in expressing the authorization scenario. For advanced usage, Casbin users can always choose to use APIs and DBs for loading &amp; saving these configurations.
This doesn‚Äôt seem like a very clean option. I found a .net Core extension of jQuery DataTables that attaches to the model attributes but still feels messy.
Make your own extension? I'm sure one exists in Nuget.
If you could provide some cookie cutter starter templates that would be useful for everyone. That would be very helpful. You said you were scratching your head to find an example. If you could produce a script that turns sql server tables, relationships, column mappings and constraints into a dbcontex with fluent and attribute mappings, that would be awesome. If you could do this for postgressql you would have a new best friend :) Efcore power tools already does this for sql server but it's buggy, it does pull all fk relationships for example and I can't get it to work with postgressql. On that note, if anyone has a reverse engineering tool to create c# pocos for efcore with relationships, I would really appreciate it. Efcore power tools works pretty well and gives you the option of mixed fluent api and data annotations on columns, which is what I'm after. So yeah OP if you could build that as a demo in ur github that works well, you will make a lot of devs happy. No one wants to map out ef core mappings and pocos by hand from an existing db
For the docker containers for the dBs, is the data volume inside the container? I may be butchering what I'm asking; but essentially if the docker container is destroyed is the data in the dB gone? That said this is very cool, I'll have a play with this repo
Apple shill go fuck yourself.
This question is so broad as to be impossible for anyone to satisfactorily answer here. There is however a plethora of information about these topics just a search engine away. If nothing else a discussion of why JIT is used at all is well covered in the Wikipedia article: https://en.m.wikipedia.org/wiki/Just-in-time_compilation
I second this. https://datatables.net/ is a simple library that has a ton of useful features. It handles everything for you from sorting to pagination to truly responsive tables etc.
Lol. I still have a project I maintain that uses .aspx pages and UpdatePanels. It's rock solid and still going strong to this day.
One of your points of confusion is about how C++ is optimised for different CPUs. C++ code has to be compiled multiple times, once for each different architecture it will be run on. Each of those compilers makes whatever different decisions it needs to to produce the best equivalent machine code for its own architecture. (So the *code* doesn't know in advance what processors it will run on - but the *developer* has to, to compile a binary for each of them.) That's why a compiled .Net program can be passed around from a Windows machine to a Mac or a Linux system, and the same file will run on Mono on all of them; but each needs a differently compiled binary produced from the same C++ code to run.
IMO I can't find a single scenario where raw SQL queries inside strings is superior to LINQ queries, specially in read queries, in 99.99% of the time. In that other 0.01% of the time you can usually write an adapter to the SQL feature you need
You can mount a volume and add additional parameters to store the data somewhere else. Pretty common use case, have fun.
You're not wrong...
LOL. I write reports for a living. There is no way LINQ can even get remotely close to the expressiveness I need for most of my reports, let alone offer me the control needed to make the performance of those reports not suck. Hell, most flavors of LINQ don't even properly support joins. Instead they have a bastardized version mostly geared to populating object graphs.
This comes up often and as mentioned in another post, separate them. The hacks in the Web api to serve angular have only bitten me later on. it leads to an ugly startup file. Finally imo it breaks separation of concerns
OMG this company bad, other companies good!
We could also stick with it. Net 3.5 if we wanted to, but I wouldn't recommend it.
It's an excellent idea. I'd love to see small wiki or examples section covering what you think would be common use cases that can't easily be done with other tools. Pocos from Db is easy to do with the EF reverse poco generator for ex. so maybe something else.
Nope, you‚Äôd need to write your own.
WCF, WPF and... WWF... You know there's a guy out there who still regrets calling it Workflow Foundation.
I believe there's a light weight windows version available for the raspberry pi. You might want to do a Google query on that
If I remember correctly it's called windows IoT
Put it this way, there‚Äôs absolutely no way the pi is gonna have windows iot installed, the client is using raspbian btw
 struct ILoveNRE { public string Mwahaha { get; } } public static void Main(string[] args) { new ILoveNRE().Mwahaha.ToString(); } this will not cause a warning/error, right?
Have you considered migrating the project to .NET Core?
For the moment, there is no way to do cross platform UI with the standard components of .net framework. You could try converting to .net core and using [Avalonia](https://github.com/AvaloniaUI/Avalonia) for the front end. If you are lucky, you could continue to try using the .net framework code on top of Mono for the Rpi, using the partial implementation of WinForms that works, but it means you must test every single component and interaction of UI on the Pi.
jquery datatables is what you need! handles pagination, sorting, Ajax calls, export to excel, pdf, print etc
use jwt authentication for core web api
This. I'm a dotnet developer and we exclusively use dot net core if we are doing anything with linux
At this point, any new projects should be started in Core regardless of what you're targeting.
Which Pi? Also, Mono is your best bet if you don't want to upgrade to Core.
&gt; .Net Core SignalR
Containerisation makes deployment and, well, pretty much everything, better. Linux containers are not necessarily better, but are cheaper than Windows containers. .Net classic only runs on Windows, Core will run on Linux. Just because there's no gun to your head doesn't mean there's no carrot. (mixing my metaphors :) )
&gt; .Net Core SignalR `Microsoft.AspNetCore.SignalR.*` packages are a part of ASP.NET Core SignalR. [ASP.NET Core (version 2.x) runs on .NET Framework, not just .NET Core](https://docs.microsoft.com/en-us/aspnet/core/?view=aspnetcore-2.2#aspnet-core-targeting-net-framework), because the NuGet packages are .NET Standard 2.0 based, so you can reference them from .NET Standard 2.0 class libraries. ASP.NET Core 3.0 only runs on .NET Core and does not have .NET Standard packages (only works with .NET Core class library), however the ASP.NET Core 3.0 SignalR packages are still .NET Standard 2.0, so I'm assuming they are planning to maintain compatability for some packages. &gt; AspNet SignalR ASP.NET SignalR and ASP.NET Core SignalR are [two different libraries](https://docs.microsoft.com/en-us/aspnet/core/signalr/version-differences?view=aspnetcore-2.2#how-to-identify-the-signalr-version) and they are incompatible with each other. ASP.NET Core SignalR is .NET Standard 2.0 while ASP.NET SignalR is .NET Framework 4.5. You can use ASP.NET Core SignalR from both .NET Core and .NET Framework, ASP.NET SignalR is deprecated.
Thank you for the detailed explanation!
Yeah.. No. Blockchain is rarely the right tool for the job. And nearly everyone forgets that you **need** to be able to delete data / make it inaccessible.
You directly posted your SO question here as well? Why not have at least some patience and give SO a chance?
Linux nodes on AWS EC2 are half the price of Windows nodes, i.e. you get double the machine specs for the same price. WITHOUT virus scanners. It has nothing to do with containers.
[removed]
Roll your own, its pretty simple and you will do it once. If / when your requirements change you can adapt your code... I know someone will say why reinvent the wheel?! This stuff is about as simple as crud gets, why bind yourself to a library?
Amen!
Visual C++ is a development environment. C++ is a language. You can use Visual C++ to develop "plain" c++ apps. You can also use other IDE. I would advise concentrate on one thing only. If you want to learn C++, dont bother with .net, and concentrate on that. Even better, dont focus on language or technology, choose a field, is it gaming, web development, embedded development or mobile, and select the language / technology based on the field of your interest. C++ is actively used in some fields, while in others languages like java, python or .net are used.
I‚Äôm working on this tonight ;) totally appreciate the input and feedback. About pocos for EFCore, that‚Äôs entirely the type of situation that Genesis could accomodate with the right template etc. More examples, got it!
MvcControllers, Repository classes, xamarin view models etc are there now, templates need tweaked a bit though. The thing that I like most about it is that you don‚Äôt have to ‚Äúgenerate‚Äù anything. You can simply ‚Äúact‚Äù on data , like call a service, or email something, or tweet etc. I‚Äôll get some use cases posted. Thank you!
yes it works. Thank you.
HiLo for one. Once you add that lovely NHibernate feature your database will be so screwed up that you can never remove it.
I think every full stack .net engineer should know: * Writing stored procedures * working with stored procedures on the .Net side * be comfortable with SQL * Entity Framework db first/code first and how to use migrations properly * Layered architecture (data access layer, webUI, service, core) Use something different and try to see negatives and positives between different approaches * Unit Testing/mocking db access * Dependency Injection &amp;#x200B; I generally improved on most of these things by working on large projects, basically by getting burned and trying to figure out a better approach. I recommend reading discussions on different topics. Also, don't be too concerned about "doing it the right way" at least the first time. Once, something clicks in your head it will be much easier to work with but you probably know that by now.
It has everything to do with containers if you use containers.
Try debugging on windows using mono. I assume you are using the official .net framework when testing on windows.
Patterns and practices are your next goal. remember than an architect is often also a team lead/pusedo dev manager so do not ignore soft skill as you need a good bump in both to hold the role in many companies. I would suggest learning scale, if you have a home lab running some VMs to setup some kind of enterprise data store that you can simulate scaled loads on. This is very similar to the work you might do as an architect when evaluating solutions. Once setup you can concoct scripts to load the system in different ways and play with tuning. Finally don't forget that once you are doing arch the dev team is as much your customer as the end customer. Keep this in mind when constructing an architecture. Very rarely does the design you create make it to production. If you don't want the dev team ignoring you then make sure to work with the team and do not over-complicate the design. A big thing to remember here is that YOU are an over-achiever even wanting to go here. The vast majority of people in the industry are competent but it is just a job to them.
Do people use Windows containers in production?
I don‚Äôt know if many online resources, to be honest. I‚Äôd suggest watching The Zen of Architecture on YouTube to get a great insight into the goals of architecture. I‚Äôd also suggest reading books by Robert Martin to get an understanding of the SOLID principles. I think Martin Fowler also blogs on architecture occasionally too. My final suggestion: look at, analyze, and question other people‚Äôs code structure. Think about how they adhere to or break the SOLID principles. Think through their long-term strengths and weaknesses.
If you can draw pseudo-UML on a white board - congratulations, you're an architect! But seriously, I'd just spend time working on application stacks and you'll pick up a lot as you go.
_Designing Distributed Systems_ from O'Reilly is available as a free eBook [from Microsoft right now](https://azure.microsoft.com/en-us/resources/designing-distributed-systems/). It may not cover all the topics you're interested in, but it is sufficiently broad and up-to-date. Also, _Clean Architecture_ by "Uncle Bob" Martin is a classic on this topic.
I can't speak for everyone, but my organisation had to adopt them to deal with legacy stuff that just would not work under Core, no matter how many hammers we hit it with :)
Ok, I was assuming most windows servers are run 'directly' on vm
&gt;rendering the Gridview part Is this an [ASP.NET](https://ASP.NET) project, or Windows exe? Because the answers will be different. (You're not going to like the answer in either case...) If it's [ASP.NET](https://ASP.NET), Mono only has limited support for WebForms (which GridView is part of) and is several versions behind Framework 4.6.1. So features that were present in earlier versions - that Mono *does* support - should work, but new features will cause issues. [ASP.NET](https://ASP.NET) Core does not support WebForms, so that's not a viable upgrade path. Both .NET Framework and .NET Core support MVC. If we're talking about a WinForms (Windows exe) application, Mono again has limited support. They should support anything that was present in .NET Framework 2.0, but again - that's quite far behind. .NET Core does not support WinForms at all.
codingblocks.net
&gt; If you could produce a script that turns sql server tables, relationships, column mappings and constraints into a dbcontex with fluent and attribute mappings, that would be awesome. &gt; If you could do this for postgressql you would have a new best friend :) As someone who's had to rewrite such templates across multiple templating tools and languages, I would strongly recommend against basing your data access code on some Joe Blow's toy project that almost certainly will find itself abandoned and defunct in a short time. Bonus points if op isn't even using a stable language like razor or T4 but decided to invent their own.
The ebook here has a great amount of helpful information. https://dotnet.microsoft.com/learn/web/aspnet-architecture
Find out how your organization does it and do it the same way. Fitting in with organizational standards is very important.
Review Microsoft's eShopsOnWeb architecture and its associated guide.
This one? https://youtu.be/Jxm2rgeuC6s
How is attention defined?
I partially read both and remember liking "In Action" more. However, I can't recall why, therefore, this comment may be of very little value to you.
&gt; Review Microsoft's eShops OnWeb architecture Do you mean [Microsoft eShopOnWeb ASP.NET Core Reference Application](https://github.com/dotnet-architecture/eShopOnWeb) on github?
That's the one!
I'm not an architect, but I've worked on systems that have had a range of architectures - desktop, microservices, monoliths, ASP.Net web gardens, data warehousing, shared-host wordpress (:-D) and I can tell you something I've learned. No matter the architecture, you'll face a problem at some point that will leave you wanting to curse the person who made these decisions, and throw it all out and start again. All architectures suck, they just suck at some things less than others. Under normal conditions when you're writing code and making steady progress, you don't often take a step back and appreciate an architecture's good parts. So... the point is - expect the people working on the systems you architect to be indifferent at best, and anything else is a bonus :-) It's important to try and balance your experience - broad vs deep (are you aware of the term Architecure astronaut?). Anyway, here's a rough overview of what Microsoft are saying at the moment (there's a pdf link on there too): https://docs.microsoft.com/en-us/dotnet/standard/modern-web-apps-azure-architecture/
Idea for noob is to abandon ship. I did mono kiosk project on raspberry pi, it was total crap. Pi was crashing because of external factors (electrical 10KV electric motors around) so sd cards were dying like flies, mono runtime was quite ok to display kiosk (but if you need Gridview, mine was couple of pictures and couple of buttons). Mono had memory leaks. It was not the application mind you, but mono runtime. Maybe now that bug is fixed, but I would bet quite a lot of money that there are tons of other like that. &amp;#x200B; In my opinion that project is doomed to fail. Better to get some windows kiosk with normal framework, those NUCs from intel are small and have small power needs but run full windows.
I came here to post this. Yeah, read this one
lol
I'd argue if you're using the DI context built into Asp.net core then don't bother with using static and just register an instance as Singleton. Maybe that's what you're saying at the end but I just don't think the class really needs to know it's going to be used as a singleton.
Sorry I probably didn't explain it well. I find that projects that introduce DI at a later date (Gonna be rare these days but just saying), and they still "new up" things in code still, then there is nothing stopping a developer new-ing up your "singleton" class.
I've been reading the Pro ASP.NET MVC series since the 1st book with Steven Sanderson (and ASP.NET MVC 1.0) up through Pro ASP.NET Core MVC2 with Adam Freeman. It's a really good series. Not only does the book teach you everything you need to know about ASP.NET MVC, it also goes into good length about important software engineering techniques, like Unit Testing, Test Driven Design, Dependency Injection, Object Relational Mappers, etc. I've read some of the "In Action" books before, and they're very good (LINQ in Action, WPF in Action, etc.) -- Can't comment on ASP.NET MVC in Action, though.
I think it‚Äôs impossible. You either port the app to .net core or you don‚Äôt run the code on a Raspberry Pi.
Raspberry pi 3, the latest version.
I read that author as Brandon Sanderson and about had a nerdgasm. I need a life.
This is correct.
You should check out orchard core. https://orchardcore.readthedocs.io/en/dev/
Converting an existing project to use true dependency injection and not just controller dependencies is so much fun! I just tag teamed a large app continually maintained by 10-15 developers since 2007 to use DI across 11 different csprojs. We started at controller level and just moved project at a time. Facade, DAL, BLL, Common, ServiceProxies, etc, really cool way to rehash a layered app actually. And also good insight into future refactorings. And easier future refactoring.
Outside of knowing how to build a regular onion architecture api that can handle load, and I mean load where the rdbms can handle a lot of requests that mutate the data with some complex table mutations. e.g. a put request that will update parent table plus potentially +n dependent entities where the data modified is from a disconnected scenario, say a get request is made the data is modified and persisted. This is assuming the usual monolith stack spa + api + rdbms. Building the above that scales and is enterprise quality, takes on the job experience plus reading, lots of reading. I've picked the brains of all the architects and tech leads I've worked with, what's a good book, video etc to learn good architecture. They always say the same, on the job and building new projects. Each time I make a new project, solution. It gets better, it's just all the tid bits I pick up along the way. A real important take away when implementing good architecture is be pragmatic, dont over engineer when you don't have to, but don't cut corners either as this will byte you when trying to improve scalability. Basically, it's a balance and it's something you pick up. Every architect I've worked with has their own style.
Agreed, if the t4 templates or whatever is used is well documented then you can always fork and keep it up to date but ideally you want a solid product that is maintained
What sort of stuff needs to be done on the API side to makenit work. At present in a uni project I only had to enable CORS
I am learning .net core as well and I have been reading the Asp .net Core in Action and I am having a really difficult time enjoying it. It feels like there is almost no code in the book, there are abstract diagrams/flow charts on every page but no code.
If you are ever interested in architecture in an enterprise environment, take data and how systems integrate with each other as the highest priority. Even if you don't go the microservices route, you can learn a lot about the considerations and tradeoffs from reading the following books: [Building Microservices](https://www.amazon.com/Building-Microservices-Designing-Fine-Grained-Systems-dp-1491950358/dp/1491950358/ref=mt_paperback?_encoding=UTF8&amp;me=&amp;qid=) [Designing Data-Intensive Applications](https://www.amazon.com/Designing-Data-Intensive-Applications-Reliable-Maintainable-ebook/dp/B06XPJML5D/ref=sr_1_1?crid=23RPF7BH8O81U&amp;keywords=designing+data+intensive+applications&amp;qid=1560310185&amp;s=digital-text&amp;sprefix=designing+data+%2Cdigital-text%2C204&amp;sr=1-1)
I personally choose jwtoken implementation. It's easy to setup and it's included in the framework.
Look After identityserver4. That's what I used, it's pretty efficient and easy to setup once you've got your head around it.
Lets not talk about threading...
Yea it's tough to find info on sometimes. the best documentation I found was Microsofts. They have some sample projects for a Todo list app that shows you how to do a web app and we API using JWTs and Azure AD.
out of curiosity, what do you store in the Facade layer?
Maybe you can try to look into this repo https://github.com/dotnet-architecture/eShopOnContainers It comes with identity server implementation and there is also a book which explains all the concepts. If that's bit too much look into official identity server 4 documentation. They also have nice quick start examples on github.
api expects api calls, not calls to get say index.html, there are a bunch of spa related middlewear that you need to add into the startup class. create the .net core + angular project and you will see for yourself
should i read both?
......facades :D
Ms has some documentation although it‚Äôs not great https://docs.microsoft.com/en-us/aspnet/core/security/authentication/scaffold-identity?view=aspnetcore-2.2
I asked this same question a couple of days ago. Didn't get many replies but somebody suggested setting up an mvc app and then taking all the mvc stuff out. Haven't tried that yet, not sure how well it would work
ofc the webapp-demo is already broken..
I did something similar, as i didn't like the scaffolded razor pages rubbish they give now. Something to get going: https://github.com/tjoudeh/AspNetIdentity.WebApi/blob/master/AspNetIdentity.WebApi/Controllers/AccountsController.cs
To bad, the implementation in that article is actually incorrect: it is missing the empty static constructor. That can cause some initialization issues when dependencies are involved. Sources: * [C# in depth - Singleton](https://csharpindepth.com/Articles/Singleton#cctor) * [C# in depth - BeforeFieldInit](https://csharpindepth.com/Articles/BeforeFieldInit)
Honestly, 6 months is nowhere near enough to get into architecture, can you build you build an application from the ground up and deploy it while developing all stacks? If no, you should not be getting into architecture, master all the tech your company uses and more, when you understand why its there and its advantages and disadvantages then you can start playing and seeing it as a whole. Like you on my first job i thought i grasped everything easily and i should make the next step, but i advise you to take it slow, dont use the tech, understand why its there. The only thing i would advise you study a little bit is onion architecture or 3 layer architecture, other than that i think you should focus your time on learning as much as possible with the current project and or get a new one.
Connect your own IUserStore implementation. https://docs.microsoft.com/en-us/aspnet/core/security/authentication/identity-custom-storage-providers?view=aspnetcore-2.2
i made a Middleware that validate every request. in startup.cs `app.UseMiddleware&lt;MyAuthMiddleware&gt;();` &amp;#x200B; in middleware class i use something like this: private readonly RequestDelegate next; public MyAuthMiddleware(RequestDelegate next) { this.next = next; } public async Task Invoke(HttpContext contex) { //your code validation //i use data in query string or cookie string token = context.Request.Query["token"]; if (string.IsNullOrEmpty(token)) { token = context.Request.Cookies["token"]; } //validate if (ok){ await next.Invoke(context); } else { //redirect to login context.Response.Redirect(loginurl, false); } }
There's existing UseAuthentication middleware and custom auth implementations are something to be extremely wary and cautious about because if things go south it's a full blown disaster
Adding auth to webapi is fairly straightforward, you need to define what kind of auth will be used, how it will be used and hook up the auth middleware. For APIs the OpenID Connect in conjuction with jwt tokens is a de facto standard, if you were to go that way your api would only validate the tokens it's been provided, but would not issue them. For an issuer you'll need an identity provider service, it'll manage your users' accounts and provide auth tokens. Identity Server is a very popular identity provider in .NET but there are other options: [Community OSS authentication options for ASP.NET Core](https://docs.microsoft.com/en-gb/aspnet/core/security/authentication/community?view=aspnetcore-2.2) That is if you want to implement it yourself, because there are auth-as-a-service providers available as well: auth0, okta, authrocket, azure b2c and others. And there's a talk about it: [Implementing Authentication and Authorization with ASP.NET Core 2 - Chris Klug]( https://youtu.be/-50ntzz18XU)
There's existing UseAuthentication middleware already provided. Custom auth implementations are something to be extremely wary and cautious about because if things go south it's a full blown disaster
Is there documentation for this on the ms site?
Good question, really this is mostly a pass through to hide BLL and DAL calls. Most of the time it's just a 1:1 pass through for BLL and DAL but sometimes it orchestrates both, like passing the DataSet from a Stored Proc (DAL) into the BLL to merge with other Data and denormalize into a POCO model. We're technically using Model-View-Presenter (MVP) from an old framework called WCSF (Web Client Software Factory) part of the Component Application Blocks (CAB) put out by Microsoft before MVC and went out of support in 2008/2009. Our spin on WCSF was the idea was that all of the presenter classes should call into Facade rather than directly into BLL or DAL. Long term this was not a good practice and has annoyed and confused developers since we put it in.
It doesn't support database projects.
Here is a nice tutorial. https://jasonwatmore.com/post/2018/08/14/aspnet-core-21-jwt-authentication-tutorial-with-example-api
Great, thanks! I will be sure to check it out.
I just looked at the Table of Contents for the ASP.NET MVC Core "In Action" book, and it looks comparable. The In Action book has a free preview here: https://livebook.manning.com/#!/book/asp-net-core-in-action/chapter-1/1 I'd give it a look and see if it resonates with you. Looking at the lengths, it appears that the "Pro ASP.NET MVC" series goes into more depth and detail. It's 1000 pages (vs the In Action at 700 pages.) EDIT: Come to think of it, the point of the "In Action" book is to show you "how" to do something and less of the "why". The Pro ASP.NET book has always shown how, but also goes into great detail on the "why". If that's something you'll want to know, then I'd favor the Pro ASP.NET book. If not, then stick with the "In Action" book.
A blog entry that basically rephrases docs.microsoft.com really isn‚Äôt worth it, for anybody.
&gt;there is nothing stopping a developer new-ing up your "singleton" class I wonder if it's possible to build a safety for this into C# itself
Another low quality shit post...
You can't, duh. Backbone is javascript and doesn't have anything to do with the backend. So go read a c# book or something.
i personally use this https://marketplace.visualstudio.com/items?itemName=AdamRDriscoll.PowerShellToolsforVisualStudio2017-18561
[removed]
Yes you can. You should have a controller that gives back the value from your appsettings.json file. Something like this: &amp;#x200B; public ConfigurationController(IConfiguration config) { _config = config; } public bool GetProceduralGenerationEnabled() { var enabled = _config["ProceduralGeneration:Enable"]; return enabled != null ? enabled : false; } &amp;#x200B; Now I don't know anything about Backbone.js but a quick search turned up [this post](https://stackoverflow.com/questions/27315447/ajax-call-from-backbonejs). Basically, combining these two should give you a viable solution.
the nuget console is actually also a powershell terminal (albeit not fantastic but it does the trick for git and stuff)
You know you can deploy Aws lambda from visual studio? You don't need to use their bad UX website. Further more Aws lambda supports native dotnet core projects like webapi and websites. So you can host entire API in one lambda instead of single functions.
whack whack terminal is an actual proper terminal emulator. It's available on the VS Marketplace. Even better, the new Windows Terminal will have a UI control usable from WPF and UWP, and someone will surely use it to create a VS plugin.
Thanks
I'M SORRY, I CAN'T HEAR YOU OVER THE TITLE!
lol exactly
Yeah well we used that today for Paket and the package manager console didn‚Äôt attach to stdin/out/err of that process. That was bad because Paket was asking for something in the background and we couldn‚Äôt enter it. VS didn‚Äôt close anymore after that because the Paket process was still waiting for input until we killed it. So I‚Äôm not happy with that thing.
I did learn that ASP.NET Core has exclusive support for WebSockets...
Which is not true. It's not exclusive.
[ASP.NET Core and Blazor updates in .NET Core 3.0 Preview 6](https://devblogs.microsoft.com/aspnet/asp-net-core-and-blazor-updates-in-net-core-3-0-preview-6/)
Ready to Run seems cool. &gt; IL-only Application: &gt; Startup time: 1.9 seconds &gt; Memory usage: 69.1 MB &gt; Application size: 150 MB &gt; With ReadyToRun images: &gt; Startup time: 1.3 seconds. &gt; Memory usage: 55.7 MB &gt; Application size: 156 MB
Have you seen F# Interactive?
This guy was working on bringing web forms to .net core, i think could not be a lot of trouble to take his work and make it work with your project https://forums.dotnetfoundation.org/t/bringing-refsrc-asp-net-webforms-to-mono-and-beyond/3309/6 https://github.com/steveisok/kaliko-webforms-demo
Except soap services
An explanation of what sort of software you intend to build would probably be pretty helpful.
You need to configure cors on the webapi. See https://docs.microsoft.com/en-us/aspnet/core/security/cors?view=aspnetcore-2.2
Yes, but I'm not sure what does that has to do with my question.
Not that I know of. If your singleton has no dependencies then you could make it a "traditional" singleton with a private constructor and a static `Instance` property. If it does have dependencies I guess you could still make the ctor private, then register a factory function with CI that invokes it via reflection.
I seem to be seeing a lot of responses suggesting this. Any good resources / tutorials?
I'm not a fan of the in action books. Efcore in action was OK but had the problems you described. I did learn a lot from it so it's worth a read esp if you lack understanding of more advanced features of efcore
Azure Key Vault
For clarity, I'm not subscribing to Azure.
You should
This is the correct answer
If I recall, the Key Vault is initialized in the program class of ASP.NET Core during the configuration builder customization. You can still host it elsewhere and just leverage the Key Vault. Edit: you‚Äôd have to look into provisioning an account and setting connection credentials to the Key Vault somewhere, though. Unless your app needs a lot of horsepower, I would say app services are worth at least a test drive.,,
So I looked at that article prior to this but haven't had luck implementing it. Could tell me what I'm doing incorrectly? public void ConfigureServices(IServiceCollection services) { services.AddCors(options =&gt; { options.AddPolicy("AllowSubDomain", builder =&gt; { builder.SetIsOriginAllowedToAllowWildcardSubdomains(); }); }); services.AddMvc() .AddMvcOptions(o =&gt; o.OutputFormatters.Add( new XmlDataContractSerializerOutputFormatter())); string dbconn = _config["DBConnectionString"]; services.AddDbContext&lt;HouseInfoContext&gt;(x =&gt; x.UseSqlServer(dbconn)); services.AddScoped&lt;IHouseInfoRepository, HouseInfoRepository&gt;(); services.AddScoped&lt;IFurnitureInfoRepository, FurnitureInfoRepository&gt;(); services.AddScoped&lt;IImageInfoRepository, ImageInfoRepository&gt;(); } And configure public void Configure(IApplicationBuilder app, IHostingEnvironment env) { if (env.IsDevelopment()) { app.UseDeveloperExceptionPage(); } AppSetting = new ConfigurationBuilder() .SetBasePath(Directory.GetCurrentDirectory()) .AddJsonFile("AppSettings.json") .Build(); // Allowing for cross-origin browsers to access the API endpoints. app.UseCors(); app.UseStatusCodePages(); app.UseMvc(); } I still get the same 'wildcard' error tho.
You create the policy called `"AllowSubDomain"`, but don't reference it in `app.UserCors()`. Also `SetIsOriginAllowedToAllowWildcardSubdomains` is to allow the usage of wilcard in`.WithOrigins("https://*.mydomain.com")`. It will not do anything by itself.
ok cool, I got working for my localhost:8080 sub domain but say I want this API to be pinged by any domain and make it open to the public? What would that look like?
https://docs.microsoft.com/en-us/aspnet/core/security/cors?view=aspnetcore-2.2#set-the-allowed-origins On the same page I already linked.
Didn't they say in the Build talk that the VS team themselves showed interest of building it into VS directly?
I really want that powershell tab-completion that the nuget console has for the actual powershell console as well, I use PSReadline for bash style completion, but it's nice to have an actual dropdown to appear as I type and explore a cmdlet through keyboard up / down. Though It's probably due to it being powered by VS that it works like that, hopefully the new terminal since it's done on UWP will support plugins like that.
I don't know, I didn't see the talk.
Exactly :)
For what it's worth, I'm biased because I've been using Key Vault recently to solve exactly this problem (I can't abide storing sensitive data on disk nor via injected environments), and I love it. I have a useful and working [implementation](https://dev.azure.com/electric-sheep/_git/Roentgenium?path=%2FGeneral%2FAzureKeyVault.cs&amp;version=GBmaster) that requires [minimal setup](https://dev.azure.com/electric-sheep/_git/Roentgenium?path=%2FProgram.cs&amp;version=GBmaster&amp;line=40&amp;lineStyle=plain&amp;lineEnd=44&amp;lineStartColumn=1&amp;lineEndColumn=1) &amp; is [easy to configure](https://dev.azure.com/electric-sheep/_git/Roentgenium?path=%2FStartup.cs&amp;version=GBmaster&amp;line=32&amp;lineStyle=plain&amp;lineEnd=33&amp;lineStartColumn=1&amp;lineEndColumn=1) (once you've added a bit of [connection string handling](https://dev.azure.com/electric-sheep/_git/Roentgenium?path=%2FGeneral%2FConfig.cs&amp;version=GBmaster&amp;line=82&amp;lineStyle=plain&amp;lineEnd=120&amp;lineStartColumn=1&amp;lineEndColumn=1)) in both [code](https://dev.azure.com/electric-sheep/_git/Roentgenium?path=%2FGeneral%2FConfig.cs&amp;version=GBmaster&amp;line=122&amp;lineStyle=plain&amp;lineEnd=154&amp;lineStartColumn=1&amp;lineEndColumn=1) and [configuration](https://dev.azure.com/electric-sheep/_git/Roentgenium?path=%2Fappsettings.Production.WithAzure.json&amp;version=GBmaster&amp;line=25&amp;lineStyle=plain&amp;lineEnd=37&amp;lineStartColumn=1&amp;lineEndColumn=1). I'm working now on pulling this all into a library for ease-of-use as I realize it's a bit scattered as-is, I'll try to update here when that's ready if anyone finds these snippets of use.
You should user asp.net core identity and JWT for net core. It is easy for setup and use. I am using both in my project
On nuget, download times of preview 6 is still 0. I'll try this version until Npgsql.EntityFrameworkCore.PostgreSQL has released corresponding version
To avoid leaving KeyVault confi strings/secrets in code, do you use MSIs?
Even the Microsoft Program Managers get confused with all this versioning... He mentioned .NET Core 5.0.
[removed]
love it, congrats!
It's been a while since I mess with razor pages in a real way. I think dropping Model and just calling Fields directly in your markup is what you need. The view should already be in the data context of its backing model.
Remove the model? I dont really understand "dropping Model and just calling Fields directly", do you mean *@model* is not needed on the page code?
I dont believe so, depends on how your controller is wired IIRC but if you have been following the examples I don't think you need to call model explicitly. Like I said its been a long time, but its something you can easily try out. I assume you have debugged already and confirmed the model is as you expect it to be at the latest controller line before you render your view.
&gt;Yeah, went into more depth, and apparently before OnPost is called, a new model is being created, and even with \[BindProperty(SupportsGet = true)\] for DesiredType it still cant access the OnGet passed in value.
hmmm, sounds like something in the controller or maybe routing options. When i have a potentially more complex project I don't want to fuss with to figure out as simple issue I will create a smaller project with smallest amount of code needed to just do the basic thing that is not work. take defaults and let templates do what they do. If you can get it to work in that project then you can compare and see what you missed.
Does anyone know if this is the last preview before GA? I couldn't find a roadmap.
More shitty spam..
You can host WebAPI inside an Azure function if you want, just need to not use the default builder from the template.
Got any suggested resources or tutorials?
r/fellowprogrammers
They seem to keep the [ASP.NET](https://ASP.NET) Core GitHub issue milestones up-to-date, and they have conventionally always released at the same time with .NET Core previews: [https://github.com/aspnet/AspNetCore/milestones](https://github.com/aspnet/AspNetCore/milestones) It looks like they have previews 7, 8, and 9 already planned. Both 7 and 8 have features and enhancements in them...9 looks really small and just has a couple housekeeping items. I would guess its just a place to put bugs and tasks and a buffer for enhancements that have to be pushed out of previews 7 or 8. Take that with a grain of salt though, they have increased the planned preview milestones a handful of times this year already; at one point preview 7, 8, and 9 weren't on the list and many of the items in them were in previous milestones. Half the items in preview 7 have already been dealt with. They seem to keep a pretty good pace and the work in the previews is overlapped.
[https://github.com/dotnet/core/blob/master/roadmap.md](https://github.com/dotnet/core/blob/master/roadmap.md) RC in July, GA in Spetember.
Are you sure? Last time I tried to use azure functions it wasn't supported. But again it was a long time ago
I've seen it done, not sure if "supported" is the right word though! https://blog.wille-zone.de/post/serverless-webapi-hosting-aspnetcore-webapi-in-azure-functions/ Probably not as nice as Lamda but doable.
Cool. Would be nice to see Microsoft make a template for it
Thank you!
Good to know, thank you!
Yep my dev team got hooked up with Azure key vault. I am now also bias towards it after using it.
Ctrl+Space will open a "drop down" in PSReadline
How come the use of AutoMapper?
I am usually annoyed by the self promoted blogs because they end up being needlessly opinionated, but this one was a good read for someone trying to understand a default clean approach. Well done!
There are no secrets in code or configuration when using Key Vault, instead it goes through a tiered process to obtain a secure token to access Key Vault. Fortunately enough, someone else just asked a question about exactly how this process work and a [great answer was given](https://www.reddit.com/r/csharp/comments/bzy23x/explanation_of_some_code/eqyks22?utm_source=share&amp;utm_medium=web2x) that both explains the details and provides a link to the code itself. In short, this is one of the great reasons to use Key Vault: nothing secret is put into any source or config file (look how clean [this is](https://dev.azure.com/electric-sheep/_git/Roentgenium?path=%2Fappsettings.Production.WithAzure.json&amp;version=GBmaster&amp;line=25&amp;lineStyle=plain&amp;lineEnd=37&amp;lineStartColumn=1&amp;lineEndColumn=1): no secrets at all!)
This all goes to one of my main reasons to use Key Vault: I prefer to let people much smarter than I figure out the hard parts: the Azure team has done a very good job ensuring communication with KV is secure &amp; damn sure a much better job than I'd do securing that sensitive data on own.
A lot of things mentioned here but with wonderfully simple explanations of core concepts of effective and efficient design. I'll definitely take some ideas from here for my own projects.
A note about your "generic repository": &gt; Without this, I would need a repository for each entity/table I intend to utilize ‚Äì the benefits scale! This is extremely powerful stuff. Entity Framework already implements the Repository pattern; this is redundant and a pet peeve of many programmers. public async Task Create(TEntity entity) { await _dbContext.Set&lt;TEntity&gt;().AddAsync(entity); await _dbContext.SaveChangesAsync(); } Calling `SaveChangesAsync()` on every operation completely misses the point of the Unit of Work pattern. This is another pitfall of the "generic repository" implementation. Many people cite the desire to decouple their code from Entity Framework as the motivation for putting repositories on top of it, and while this may be true for trivial apps, there's just no version of reality in which you can swap out Entity Framework for anything else just by tweaking your "generic repository" class. It works on paper, but in a scaled application EF implementation details will leak into every nook and cranny. It is true that a generic repository helps to mitigate this, but then you're limiting your ability to use EF efficiently by restricting the API surface area. Again, for trivial apps this is fine, maybe even microservices in a production environment if they are low volume and performance isn't of great concern. The tradeoffs need to be understood before someone heads down this path though.
If you're doing everything on-prem, why don't you run your own key vault? I found this after a quick search: https://www.vaultproject.io/docs/what-is-vault/index.html
Regarding your comment about the UoW pattern and `SaveChangesAsync()`: I've seen people overriding EF Core's `DbContext` `SaveChanges` method and intercepting the actual call if a transaction is in progress. That way you can still use this kind of abstraction.
100x this. Developers shouldn't confuse setting up EF with using the underlying provider framework (SQL, DocumentDB, Mongo, et al). EF provides you with the repository pattern already, abstracting the availability of CRUD operations from the infrastructure layer. Adding an `IGenericRepository` on top does nothing for you other than add an unnecessary layer.
I think the main argument for IRepository is for mocking it in unit tests, InMemory EF provider still isn't that smooth for me.
Doing the same just for the tests :(.
What about when you need to issue custom queries?
EF also has breaking changes in 3.0, so there‚Äôs that.
That's the problem with hiding EF behind a repository pattern - you're unnecessarily narrowing the feature set for literally no gain other than not having to call SaveChanges. For custom queries, you end up adding Expression or Func support to the repository interface and it expands from there. You soon realize that it'd just be easier to expose the EF API.
[https://www.google.com/search?q=dotnet+send+email](https://www.google.com/search?q=dotnet+send+email)
thanks brother
u/[JoeyXie](https://www.reddit.com/user/JoeyXie/) We've been having various issues with Postgresql and .net core 3.0 which I believe are version related (or Identity). I'd really appreciate if you posted what has worked for you. (privately if more appropriate). For full disclosure this is the first time we have concertedly tried to get Postgres as our database with .net core so may be doing other things wrong besides versions. We are presently having most issues with utilizing identity core with postgres (possible not feasible?)
Just simple libraries for math and advanced string manipulation. This is what I would do to start off and get comfortable in the language. Start simple and build up.
Mocking in unit tests usually ends up mostly testing you have setup the mocks correctly. I now use mostly integration tests which hit the database as it is an essential part of the solution. Unit testing my domain classes is valid, but if my code hits the database I might as well test it works correctly in my tests.
Nearly always a terrible idea.
I would offer a few criticisms: * Your custom logging abstraction is basically a clone of `Microsoft.Extensions.Logging` minus a few features. Why not use it? It is fantastic for letting you do *all* of your logging using a common pattern, and the only piece of your app that's tied to any specific logging library is a bit of configuration code in the MVC app. * Personally I don't think I've ever seen an app where the generic repository pattern really added value. TBH I'm in favor of abandoning repositories entirely if you're using EF. Make an interface for your DbContext then use that directly. * I can't speak to the architecture of Razor pages, but in the world of MVC and WebApi I'm a big fan of CQRS with MediatR. IME trying to make a services layer that handles everything just tends to turn into a mess, as each service is a collection of loosely related methods that are grouped together and often coupled together. The CQRS approach works well to break your logic up into loosely couple and testable chunks, as well as the other benefits that come from its pipeline (easy logging, validation, etc.).
Why not create multiple models that inherit from some common class? This way you can abstract away the fields and validation that are common to your Create and Edit models, and customize the properties and validation for the Create and Edit models as needed.
So, the edit grids would use like a sub-class (or, sub-viewModel)? Is that what you mean?
Yes. Or both the Create model and Edit model will inherit from some common ancestor.
You can use it as a programmable terminal, keep your scripts in files in projects in solutions and so on. I find it very useful.
Disclaimer: I'm no Vue expert. So I believe somewhere under the hood your Vue request might be submitting as part of the fetch request credentials, i.e. this: [https://developer.mozilla.org/en-US/docs/Web/API/XMLHttpRequest/withCredentials](https://developer.mozilla.org/en-US/docs/Web/API/XMLHttpRequest/withCredentials) And when that's the case, then you can't allow via CORS *every* domain, only a specific list of domains. So you might want to look into how you can disable sending along credentials in your Javascript (which, unless this is an intranet application of some sorts, might not be very useful). Then it will allow adding CORS for every website via *. Again, I could be wrong about Vue using withCredentials under the hood.
The performance improvements for `System.Text.JSON` over `Newtonsoft.Json` are pretty impressive: https://github.com/dotnet/performance/pull/456
I love that this is all being done in the BCL. As a Xamarin dev, it means that we‚Äôll get all of this for free in .NET 5 [when Mono and .NET Core use a shared BCL](https://www.andrewhoefling.com/Blog/Post/net-5-and-the-future-of-net-framework-and-net-core).
I'm not sure this was covered in your article but the fROC hosting implementations in the GitHub gRPC repo that uses dotnet core 2.2 is different from the implementation in Microsoft's MVC core 3.0 preview examples (coming in September). Microsoft rewrite the host to use Kestrel, and provide access to the full MVC dependency injection and middleware stack, and is overall faster and more extensible than Google's implementation. Both use the gRPC.Tools nuget package to add the protobuf includes in the csproj file so that protoc.exe code generator will generate the protobuf classes and the abstract class for the service itself. The generated code for the POCO classes and service base classes are put into your projects obj folder for the target framework, so you should not modify that generated code (or even consider extending with partial classes). That's a big gap people may not realize with protobuf: it does not play nice with your POCO objects, it creates its own for you to use. The challenge I had with both was that when running on my local machine I couldn't for the life of me get it to invoke with Bloom RPC (linked on this sub last week). However I was able to get it working with a C# client, so I'm not sure if that's an issue with BloomRPC or with my companies endpoint protection software (firewall). Ultimately I decided using Proto to define my DTO's is freatz however for now I think tooling support is better for REST services with MVC returning JSON. I will hold out on gRPC for now until the MVC 3.0 release **and better tooling** support for testing.
Thank fuck. James Newton-King worked on it, the guy who did JSON.NET , That lib caused me so many comparability issues because of the legacy. This makes me so very happy.
And here's the associated Blog Post: [https://devblogs.microsoft.com/dotnet/try-the-new-system-text-json-apis](https://devblogs.microsoft.com/dotnet/try-the-new-system-text-json-apis?WT.mc_id=dotnet-reddit-bramin)
They should compare it to the old .NET JSON libraries. They'll probably beat it by an order of magnitude.
Why is it that JSON.NET has so many compatibility problems? I've never run into comparable issues with other libraries.
Everything uses it. So you import a library that uses something like version 6. Another library that uses like version 9. And then your program which uses latest. Now shit don't work.
Was easy to have library x require version 6.2 and then another library y require version 11.2 or greater. Go to add library y and and have JSON.NET updated to 11.2 and then break everything in X.
Yep, the two responses below are spot on. I've had to work with libraries that rely on version x, but others require version y. There are breaking changes between versions so it means I can't use certain libraries. It's a legacy thing and not JNK's fault at all. It's just a problem with being the de-facto JSON library, and history.
is there a easy way to configure it to always use snake case?
I wanted to see the comments to see if this article was any good. First comment is about the generic repository. It's exactly what you said. You don't need it. People may argue using it for unit testing but imo using in memory sql with fake data built from real queries is much better to test your service layer. It's less hassle setting up mocked data, you get real data and tweek the result set to mimic any scenario which is often a copy paste job and you change a few values
I share your pain in that. We had so many issues with the mixed version he‚Äôll that ecosystem created we ended up moving to protobuf and limiting any external library that used json.net
Do you have a good article or github implenting CQRS. Some examples I've seen were way over engineered
Imo this stuff is too basic
Brilliant solution :)
It actually ended up being extremely beneficial when it came to pushing down millions of domain objects. JSON.NET was just getting so bogged down. Though I‚Äôve been eyeing https://github.com/neuecc/MessagePack-CSharp as a possible replacement.
The thing is, breaking changes should be incredibly rare to begin with, moreso for this because JSON hasn't changed, ever.
Never mind trying to use it in a custom script task in SSIS... go ahead and pick a version to stick in the GAC lol
Newtonsoft was never particularly fast. I'd be curious to see how it compares to Utf8Json.
You can enable support for preview versions of .net core under Tools &gt; Options &gt; Projects and Solutions &gt; .NET Core
&gt; https://github.com/neuecc/MessagePack-CSharp That and Utf8Json by the same author are solid and performant. His method of copying bytes around handily beats every other method I've seen.
Yes! Include is what I found. Thank you! Now I'm trying to work on Identity......
Yeah that‚Äôs been what I‚Äôve noticed, I‚Äôm just waiting to have some capacity in my time to prototype something against it to see if I can squeeze it into a feature sprint.
Totally agree, but some of the crap we've been lumbered with is aeons old :/
Something for me to do tomorrow :)
Mocks enable testing specific areas of code by reducing the number of moving parts. Integration tests are great too, but mocks aren't useless.
I saw that online but my vs does have the option and it's up to date
Eh? Wonder if they removed it in a previous patch. I‚Äôll check in the morning when i have VS in-front of me and get back to you.
I'm a fan of this video: https://www.youtube.com/watch?v=_lwCVE_XgqI Besides the video he has a github repo with a demo project.
Thanks appreciate it
It was moved to Tools &gt; Options &gt; Environment &gt; Preview Features
we are using dotnetcore, efcore 3 preview 5 with postgresql 11.3, techologes we used include: 1. \`uuid-ossp\` extension to generate uuid primary key 2. use \`jsonb\` to store json 3. use trigger to auto generate \`updated\_at\` timestamp 4. foreign key constraint these features work fine, we use \`dotnet ef dbcontext scaffold\` to generate model code.
[https://github.com/npgsql/Npgsql.EntityFrameworkCore.PostgreSQL/issues/903#issuecomment-501600036](https://github.com/npgsql/Npgsql.EntityFrameworkCore.PostgreSQL/issues/903#issuecomment-501600036) Too bad, the Npgsql team may skip preview6 and go direct to preview7, I will keep up with Npgsql team.
If you read the link you would know.
You can create query objects that extend IQueryable for custom queries. There really isn't a need for a repository on top of EF in most cases
There's nothing to read, it's a 20-minute video that not everyone will want to sit through.
Ah, you're right. I just scanned the tables which only showed a comparison against Newtonsoft. Utf8Json is still faster.
Yes, we know *how* that works (broken backwards compatibility). Nobody so far offered an actual example of a broken feature, which is what grauenwolf asked about. At this point, I suspect that "shit broke" is about people merely not knowing how to build or deploy in face of differing versions.
Why PBF instead of qRPC?
What I don't understand is all the downvotes I got for saying breaking backwards compatibility is a bad thing.
If I see it correctly it can only (de-)serialize POCOs with an empty constructor and can‚Äôt be used for immutable classes/structs, or?
Excellent tutorial! I know nothing about GA or AI and stuff, but was able to easily follow your example from the beginning to the end. Now all I'll need is a use case for this ;-)
Yep on small ones it looks like. From my understanding.
Your post has been removed. Self promotion posts are not allowed.
Your post has been removed. Self promotion posts are not allowed.
Please let me know how this has anything to do with me, or promotion of myself. This is about dot net core and writing clean code. I even had comments saying they liked that it wasn‚Äôt the typical self promotion, so I please ask you to re-consider.
 *We don‚Äôt want to compromise on the Json.NET support customers are getting today. For example, the ability to configure the JSON serialization in ASP.NET Core via the* AddJsonOptions *extension method. Thus, we want to provide the Json.NET integration for ASP.NET Core as a NuGet package that developers can optionally install, so they get all the bells and whistles they get from Json.NET today.*
Thank fuck JNK was not responsible for design decision. Some of his design decisions are really questionable, e.g. https://github.com/JamesNK/Newtonsoft.Json/issues/862
It is recommended to use with VS2019 preview but you can enable it with older versions also [https://dotnet.microsoft.com/download/dotnet-core/3.0](https://dotnet.microsoft.com/download/dotnet-core/3.0)
Hah, that's nasty. I think he is doing design too. From memory its syntax is very similar, it's supposed to be a drop in replacement almost. Don't quote me on that. We had a great bug. We're forced to use an old version because of "horror". We had a portable class library which shared some code and then various standard class libraries. Randomly I'd get odd de-serialization errors, but only on my local machine. It would expect a "Type" to be in the serialized message. Anyway, lots of hunting, checked everything was using the same version, turns out in some cases it would use the portable version and sometimes the .NET version (and for the .NET version it might use a version targetting a different framework version). The de-serialisation behaviour differed if it got the portable version during the build :/
All serializers need an empty ctor. It doesnt mean you cant have other ctors, just make sure you declare an empty one.
I'm still on preview5, I tried System.Text.Json and found some incompatible with Newtonsoft.Json 1. for json string with a trailling "\\n", when using JsonSerializer.Parse I got an exception says '**The provided data of length 108 has remaining bytes 1.'** 2. I have a json with field 'id' but JsonSerializer.Parse doesn't automatically map this id field into a class attribute 'Id' I can't upgrade my dotnet core version to preview6 now, so I don't know if these 2 bug get solved in preview6, anyway, thank you for the nice work.
i just got home, yep its there, i created a .net core console app and then changed its runtime to .net core 3. thanks!
Use FluentValidation ([https://github.com/JeremySkinner/FluentValidation](https://github.com/JeremySkinner/FluentValidation)) &amp;#x200B; It allows you to create custom `RuleSets` ([https://fluentvalidation.net/start#rulesets](https://fluentvalidation.net/start#rulesets)). For example for a `Create` Ruleset. Then, in your Action, add `[CustomizeValidator(RuleSet = "Create")]`
I'd be very surprised if the devs at my workplace knows about [bindingRedirect](https://docs.microsoft.com/en-us/dotnet/framework/configure-apps/redirect-assembly-versions) If there are useful features available in the basic toolkit then you can be sure it's being ignored. I get their view though; how would they justify all those hours spent if it's actually just a knob in the standard environment that needed to be turned? Can't be that simple, the problem its solution clearly needs its own cost center.
&gt;I have a json with field 'id' but JsonSerializer.Parse doesn't automatically map this id field into a class attribute 'Id' The following works. Using 4.6.0-preview6.19303.8. Notice the trailing newlines var itm = JsonSerializer.Parse&lt;Item&gt;(@"{ ""id"": 1563 } ", new JsonSerializerOptions { PropertyNameCaseInsensitive = true }); public class Item { public int Id { get; set; } }
Wasn‚Äôt aware of it at the time
Awesome, thank you
Thanks! If you know Unity3D, I think you would like to try this one [TSP with GeneticSharp and Unity3D](http://diegogiacomelli.com.br/tsp-with-GeneticSharp-and-Unity3d/). &amp;#x200B; In this video you can see some samples using it with Unity3D: [https://www.youtube.com/watch?v=xXqNcgeOU\_g](https://www.youtube.com/watch?v=xXqNcgeOU_g&amp;t=6s)
Feels like spam. I looked at some of the linked tutorials and they were equally insipid/anaemic.
So as usual, the wonderful folks at Microsoft made an obsecure UI change. The option still exists, but has been moved: [https://i.imgur.com/s6Xp669.png](https://i.imgur.com/s6Xp669.png)
Must have been prior to coffee o'clock, I sympathise.
Json.net uses constructor parameters when there‚Äôs no public empty constructor, and you can explicitly set the [JsonConstructorAttribute](https://www.newtonsoft.com/json/help/html/JsonConstructorAttribute.htm).
Could you use visual studio refactorings to split files by class?
This article could be applied to any platform/language, not just .NET. So I would suggest you either add more pertinent information or change the title.
Yes, not knowing what binding redirects are for grinds my gears too. WTF people, basic stuff...
You mean the serializer that was converting to XML before converting to JSON? ü§£
Very cool, hope to see the high quality level of documentation we are used to on the msdn docs. Even better would be life dotnet try docs for this.
People in that thread seem to be making little to no effort at understanding the decision, though. I mean this kind of thing really pisses me off: &gt; I don't care about the reasoning that went into this - it's wrong, and should be fixed. If you don't care about the reasoning that went into it, then you can't possibly say it's wrong. A lot of things in programming appear to be wrong at first glance, until you understand that "right" is much harder than you thought it was. I guess JNK's terse replies didn't help much, or at all.
I wonder how the Newtonsoft folks feel about this. Will they continue with [Json.NET](https://Json.NET) as a competing solution?
I said one order of magnitude, not 3.
WTF? Yea, that makes no bloody sense.
He works for Microsoft now.
I hate to be "that guy," but really, the thing you should consider when moving to functions is not the starting difficulty, but the long-term architectural viability of it. I say this because I've been burned by microservices in the past. Microservices are trendy, and they're used by big companies for a good reason. But smaller companies should think twice unless they really, really think they have a compelling use case. The main benefit of microservices when you have a large organization and you have an entire team working on that specialized microservice. In that case, the boundary between the microservice and the rest of the architecture mirrors the human boundaries, and it is very nice for a team to have its own universe they have full control over. If you've got a few tens of developers on your team and a monolith, your "microservice" should instead just be a well designed class wrapped in a simple interface that you can test and inject. You've got all the information hiding that a microservice offers, but you can actually debug. And if it ever happens that you need to change the interface, it's much easier to do so. But deploying Azure Functions is dead simple, and extremely cheap. They're useful for periodically executing tasks, too.
Anyone know how to utilize this in a controller route the way you could use JObject and then operate on the json itself with Json.NET? JsonDocument is null when I attempt a [FromBody] JsonDocument query and then post a json document to the endpoint, so that doesn't work.
thanks. Very much appreciated.
Been effectively using Azure Functions for months now. I can't say what the difference is with AWS Lambdas, but the obvious ease of use with C#/.NET and integration with Azure. Azure Functions + Consumption Plan + Serverless SQL (new) = WOW costs are low!
[removed]
I love using this for immutable objects. The deserializer passes everything into a constructor and every value is assigned to read-only properties.
You can look for some open source projects on github. Just search for trending repos tagged with C# and look for something that you would like to invest your time to. Then take some task and start working on it. There are lots of articles focusing on how to start with open source projects if you don't know how to begin. Or start your own project on github.
Yup, this, 100%. Learn By Doing: it's the only real way. (P.S. I've been doing _exactly this_ lately to learn more about C#'s amazing reflective capabilities, and just posted the project I've been building to do so [on Github](https://github.com/rpj/rg))
You need to use Xamarin to write .net apps for Android.
Some outcomes are so bad that there are no justifications for it. If you were test driving a new car and discovered that the brakes were automatically disabled whenever your speed was between 60 and 60 MPH, would you really care why they think that's a 'feature'? Or would you just demand that the fix the obvious flaw?
Xamarin is for GUI applications, dotnet core has it's own runtime for Android
Yeah, but this isn't that.
iirc it was said that supporting Span wasn't possible without extensive rewriting which is the motivating factor for this solution. At any rate, competition is good for software. There will be reasons to use both
Interesting, would you share a link for information about the Android dotnet core runtime from Microsoft?
The date/time/offset '2016-03-31T07:02:00+07:00' is not the same value as 'and 2016-03-31T02:02:00+02:00'. It is incorrect to change the time and time zone components because they have semantic meanings which may be important to the application. If they were not import, we would have used UTC instead.
I've found some website which said you can publish with the \`android\`, \`android-arm\`, and \`android-amd64\` runtimes but can't find it, the website said this feature was added in NET 2.2. Looks like MS removed all mentions of android in dotnet core but the RIDs still remain.
Just setting the published/myapp binary to executable won't work because dotnet needs to be launched as a host for the app. I've been using dotnet console apps on Debian Linux as well as Windows and the command to launch looks like: dotnet run myapp. So getting dotnet to launch on Android would be the first step, if you haven't already done that.
from what i understand, json.net is more feature rich and can do more. the new apis are supposed to be faster, but are a more "plain jane" serializer/deserializer. so use the new stuff if you wany speed, use json.net if it has features you need. sort of orthogonal use cases.
Publishing with a provided RID outputs an executable with the runtime included into it, you don't need to use `dotnet run`
Then you should probably deserialize to a DateTimeOffset. I'm not trying to say this is correct or that it shouldn't be fixed, but it's probably a bigger fix than it appears to be, and it's an edge case with a known workaround.
&gt; If you want to produce something that is human readable, you can pass in an instance of JsonSerializerOptions to the serializer. This is also the way you configure other settings, such as **handling of comments**, trailing commas, and naming policies. It would be great if this is used for parsing appsettings.json during configuration build. Having the ability to add comments with the flexibility of JSON would come in handy.
He read it as a string. There's never an excuse for changing the value of a string. This isn't an 'edge case', it's an example of a library trying to be too clever for it's own good.
Seriously. I still default to XML for config files because of the lack of comments in JSON.
Good to know. That sounds like a much better way to launch it.
Thanks!
Ye, this is it, json.net is absolutely packed with features and lets you do pretty much whatever you need and that comes at a performance cost.
Assuming Provider really does need to be a singleton, which seems unusual but might be correct in your case, your code is fine. For an explanation of why you don't want to dispose of the client, you can read the famous blog post [You're using HttpClient wrong and it's destabilizing your software](https://aspnetmonsters.com/2016/08/2016-08-27-httpclientwrong/)
Does this allow custom serialisation/deserialization of custom types? In Json.Net it was done through 'converters'. Hoping to use this with NodaTime typed properties but not sure how / if I can make it work.
Given that even the Twitter account is deleted, I'd say that Calvin A. Allen gave up on it.
Cool, ya it does have to be for our situation. This is a dramatically simplified version. Thanks for the heads up, I'll read through that.
He replied in a GitHub issue that Json.NET isn't going anywhere.
Blazor is awesome.
Podcasts are tough and when you‚Äôre not bringing in much $$$ from sponsors, there‚Äôs little motivation to continue.
Maybe I‚Äôm just dumb, but what all can you do with Json.net outside of basic api responses?