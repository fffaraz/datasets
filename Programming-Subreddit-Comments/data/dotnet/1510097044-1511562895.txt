This is probably not *that* useful for your own services on your own hardware. I can see its use for debugging any installation where you don't directly have access to the hardware or underlying system, basically those where the customer installs anything on his own hardware (be it a service or a regular application)
Of the top of my head: Session expiration and invalidation, multi device handling, session re-authentication when switching ip addresses. I'm sure the list is at least 5 times as large, depending on the security requirements. You still use a cookie, but all the cookie has is a unique id that ties it to the session saved in the database, not the actual session info. 
Sometimes recycling the Sites application pool will help
Update: opened an issue asking about support in Mac/Linux in ReportGenerator https://github.com/danielpalme/ReportGenerator/issues/112 And managed to generate the report in Mac for OpenCover sample file. It is using Mono, not sure how easy it is to port it to dotnet core. 
CSRF isn't particular to SPA. My question would be, to whoever called you out would be this: What about being an SPA makes JWT a better choice? OR are you suggesting all sites use JWT? ... because cookies work. They are the correct why to do authentication unless you have a *specific use case* that requires a different auth method. OAuth even has support in identity server 4 to establish cookie auth instead of JWT for SSO. Yes, you have to deal with CSFR... but you have to do that *anyway* with every web app. The JWT hype far outweighs the number of people who understand what its good for. For example, sticking a JWT in local storage is a SLO disaster waiting to happen. You logged out of the IDP, so you expect SLO has logged you out of the SPA? nope. surprise. when the next person comes along on the same shared computer they get a restored token that may not have expired yet, off goes silent token renewal and woops, two different identities on the IDP and SP. (cookies, by comparison can have their session revoked, meaning even if the browser session isn't cleared the webapi will never accept the requests) /me shakes head. JWT isn't best practice. Its just a different practice, with different trade offs, and a lot more complexity people don't seem to understand well 
Check out Dapper if you haven't yet, it's a really slick way to write repositories, and it uses hand written SQL queries, so you know exactly what you're asking the database to do. It's amazing.
I did some more research, and I think I'm going to use Selenium for this project. Thanks for the input!
Getting a 500. Is there a mirror? 
Yeah exactly; and i dont know of any app that would be written with .net and docker that way :) For a scenario you described - sure, this is very useful
While this is pretty neato and satisfying to get a bunch of system info reported on, much of it seems pretty extraneous to me.
I would NEVER log my environment variables coz they contain my app's secrets; the version in my assemblies (which corresponds to the ci build number, btw) is freely output by the status controller and known in the ECS. And no, i dont use command line arguments in the actual app - they belong to the tools, and a few tools we wrote ourselves the ci invokes those with args.
Careful when logging environment variables which can often contain sensitive information like api keys and credentials. 
Thank you, I'll definitely take a look.
This is very neat and I am definitely adding this to some of my products. However, the beginning of the article lists some common problems as reasons to use this and don't see how a few of them are ameliorated by this. Specifically, the OutOfMemory exception. How would one use this diagnostic output to track down such a problem?
Why you say that ?
Why you say that ?
lol where do I start. Your project will stop building for no reason at all, maybe visual studio hung for some reason and you had to quit it via task manager, so now your project won't build. This sends you down a rabbit hole trying out a handful of suggested fixes on the xamarin forums site and SO, most likely with none of the suggestion actually working. You'll 'clean' and rebuild your solution god knows how many times, but then you remember that cleaning your solution doesn't actually clean the solution like you think it will, leaving you having to remember that you need to manually delete the bin and obj folders from every project in your solution. Oh now your project runs again? GREAT. Now try and fix that random null reference exception that has shit for a stack trace and doesn't even give you a file name or a line number to start looking around. XAML is a joke when it comes to doing your UI, and if you have to fine-tune your UI, you have to rebuild and run your project for every. single. tiny. change. Sure there's the new Xamarin Live player, but it only works if the device you're deploying the app to is on the same network as the instance of visual studio that will be used for debugging. I'm just gonna stop there because I feel those are enough reasons. I've been working with xamarin forms professionally, and react native at home for fun. React native is just so so so so much better.
Storing confidential information in environment variables is only slightly less insecure than storing them straight in configuration. 
Configuration gets committed to source control, and it's pretty much universally agreed upon that storing passwords and API keys in source control is a really bad idea. Particularly in public repositories. Environment variables, on the other hand, only exist on the servers themselves. If your servers are compromised, then the environment variables are likely the least of your concerns. Additionally, the tooling used to set those environment variables (during an automated deployment), should be behind some secured login mechanism too. 
Are there any better alternatives?
Composition &gt; inheritance
Database config where the user running the application has shared credentials with the DB so you don't need to store the config in DB. Encrypted config stored on disk and decrypted by a cert in a properly secured key store. Not using stored credentials in the first place because you're authenticating via certificates (again stored securely) or some sort of oath mechanism. Hell if you're not using a public repo straight up configuration is not a lot worse and a lot easier to manage. 
Sure, committing keys to a public repo is stupid, but if you've configured it properly a private repo is as secure as your server, probably more so. My build and source server is more locked down than my environment variables would be. Config is also not the only other option either. 
Or this 
Haven't tried it yet, but I hope the .net core secret manager turns out well for just this reason https://docs.microsoft.com/en-us/aspnet/core/security/app-secrets?tabs=visual-studio 
There's a default timeout for out of process servers, 3min, I think. The process does not go away even if all clients are gone. This is done to avoid trashing the OS by incessant process startup/shutdown when clients come and go. Did you try just waiting after releasing your interface pointers?
Sure, but even a private repo can be accessed by every single developer assigned to it. And perhaps not all of them should have the keys to production.
There are solutions for that too. I'm not suggesting that config is ideal, but in some cases (all developers have prod, but not everyone else should), which is fairly common with smallish teams it's not too bad. Environment variables are just horrible though and only a tiny bit more secure. 
"The Secret Manager tool does not encrypt the stored secrets and **should not be treated as a trusted store**. It is for development purposes only. The keys and values are stored in a JSON configuration file in the user profile directory."
And if you run on the client computer and you're a company located in the EU, you should definitely NOT log this. There is just no way to know what you might log that way, it could contain sensitive information. And with the upcoming changes in the privacy law and the draconian penalties this is not a risk anyone should take.
I remember once we were getting OutOfMemory exceptions after one of our releases it took us a week to figure out that the LargeAddressAware flag added to the 32-bit executable which was part of our deployment process was removed by one of the devs limiting the app to 2GB of addressable memory.
A lot of comments seem to be concerned about logging env variables. Whether you should be storing sensitive data in your env variables is subject to another post but don't forget you can use the library to generate partial reports therefore excluding the env variables.
&gt; Note: Using these adapters comes with a performance cost. Applications using only ASP.NET Core components should not use the Owin package or adapters. https://docs.microsoft.com/en-us/aspnet/core/fundamentals/owin
As the author of both of Owin.Hosting and AspNetCore.Hosting I strongly recommend going all in on AspNetCore. All of the Microsoft.Owin components moved to Microsoft.AspNetCore and have had several years worth of additional investment there. See https://blogs.msdn.microsoft.com/webdev/2014/11/14/katana-asp-net-5-and-bridging-the-gap/
This seems what I'm looking for, but I thought repos should only return domain models?
This seems what I'm looking for, but I thought repos should only return domain models?
[removed]
Also good to log GDI rendering mode (Directx vs CPU)
As someone who doesn't touch web with a 10 feet pole and solely develops native apps, from win32 MFC to UWP, let me just chime in on what you DON'T want to spend your time on. - F# 10 years in the industry, never saw this in the wild. Not even academia is aware this exists. Why do you want to introduce F# again? Skip this. - Microservices: every 10 years the industry makes up a new word for a requests server, no a web-service, no a rest-api, no a micro-service... You get the point, just any consuming a internet based service will do, you don't have to showcase fancy new tech that your students probably won't ever see in the wild. 
Excellent choice. It's along the lines I was suggesting, but better than the built-in browser object. Good luck with your project.
What would you change about it? We are totally open to changing it.
Headless CMS is cool - Orchard Core currently has GraphQL and JsonAPI in the works to enable these types of scenarios. 
In addition to this, I have found it usefull to log the reason for shutdowns. Usually they are not interesting, but occasionally they are.
Great to hear you like it, thanks!
- There is no way to filter already created contents. Everything is listed together. - There is no way to root the default folder within asset folder for specific content types. So if you are blogging extensively, every time you upload an image, you have to navigate from the root folder again. - There is no way to edit the content from the output, e.g. edit this page functionality. Even the most basic functionality that will bring the user from the output to the editor will help a lot. - Most of the editors do not have save and continue features. - There are way too many concepts that are not explained well from zones, shape, widget, stereotype, layers, etc. - When you are editing the template, there is no way to navigate what's properties are available except using the display tag. I can go on.
Don't forget value types and unsigned integers. Pretty much the only thing Java does better IMHO is lambda classes.
&gt; If your servers are compromised, then the environment variables are likely the least of your concerns. Someone in another thread mentioned that you should always code your app so that if it's compromised (including the server), nothing sensitive gets leaked. This would include doing things like encrypting your database. I am unsure of how to start going about this. Perhaps someone else will chime in.
Thanks! I'll look into this to make sure it requires a password. Currently I have the connection string using a password, but I'll be sure to check to see if it still works without the password.
Everything makes sense now. Thanks!
thanks, I'll look into that.
I'm interested in know this as well.
i've met two of the three Scotts at Microsoft, he's my last one left. 
Me too (no hashtag...)
The previous company I worked at have some products out built on ABP that have a couple of thousand active users. Lots of trouble though, like 50 seconds loading times - but not because of the framework itself. They just never updated it, and several development had done solo work and made some real spaghetti of the whole thing. I think the framework seems decent enough though. Good standards, lots of updates, easily expandable and it looks good!
For long running tasks on Windows server, best to look at creating a Windows service. For your web front end, you can create a asp.net core app and host in IIS or Kesterel. I'd personally wrap your db in a web API and have the web app and Windows service consume from the same API layer. I've had bad luck doing AD work in the IIS thread pool, hence my recommendation on federation. That plus IIS is a terrible place to do long running work.
I figured I'd probably go the route of creating a service - would also probably make authentication to AD easier. I have created ASP apps on IIS in the past and always had difficulty making deployment easy. I'm not familiar with Kestrel, but after a bit of googling it looks like I could embed that into my service fairly easily. I agree on creating a web API. Any recommendations on lightweight DB? 
I use FxCop and StyleCop. StyleCop for .NET Core is still beta though.
do you have any recommendations for replacing OAuthAuthorizationServer for issuing JWT since it seems to be deprecated?
Gonna have to keep this one in the back pocket I think, actually looks really good!
Why do you need a framework already on top an MVC framework? You can quickly assemble facilities out of: - Autofac - Serilog - Mediatr - ORM of your choice - FluentValidation - Mapper of your choice And you can adjust the infrastructure depending on your application size.
dotnet watch is slow, even on SSD. The thing I like about ASP.NET Core is that it's gonna be fast even if I don't optimize as long as I don't do stupid stuff.
I always use SQL server. I think you can launch it in a docker container for testing. Other than that, I think people here are fans of sqllite. Really depends on how much reliability you need. 
Very nice, but the attribute should have been "asp-authenticated". Authorize and Authenticate are not the same thing.
I get what you mean but I was trying to match the way Authorization at the Controller and Action method level works in MVC today. I think it's better to follow the existing pattern in the framework rather than introduce something new. 
That's is my problem too. Maybe it's not ready yet for serious projects.
It is ready for serious project - just don't count on dotnet watch.
I think you may want to rethink your fixed width's EDI is not a fixed with format. The ISA segment is the only segment that is fixed width. Every other segment that I am aware of can have varying lengths. To clarify my knowledge I have been working with EDI for 15 years and run my own Third Party EDI company. I have dealt with several hundred trading partners and X12 Standards from 4010 to 4060. My clients transmitting business, transportation and financial documents. I process about 10-15,000 inbound and outbound documents a day. I scrolled down a ways and saw what it is your are trying to do. I have been working on just such an answer for a LONG time and there are so many pitfalls. To read EDI you read in the fixed width ISA segment which is the first segment (line) at the end in position 104 is the element separator, 105 is the component separator and 106 is the line separator. Then you have the GS and ST segment which ALWAYS has the same elements. They are closed using the GE and SE segments and the ISA gets closed with the IEA. Where the difficulty comes in the rest of the segments. There is definition for VALID segments within a document those Segments may not have the same number of elements. For instance the SDQ segment supports 15 elements but if the trading partner only wants to use 5 elements that is acceptable EDI practice. The best way to write the program to read edi that I have found is to use a SCHEMA either an XML, other format or hard coded in the program. To make it useful you would have to define a schema for each EDI release 4010, 4020, 4030 etc etc. The rules change from release to release. EDI is almost a black art.
I am going to ask another question. You github does not appear to show an example where headers are not user. How can I read in a CSV file without headers or is it even possible?
I really like the functionality regardless.
IdentityServer4 and OpenIddict are the two I'm aware of. https://github.com/IdentityServer/IdentityServer4 https://github.com/openiddict/openiddict-core
Most of the schemas I work with are old, i.e., one is from 1994, another is from the 1980s, etc.. They don't change :) There are "modern" XML-based equivalents (from 2007), but they aren't as heavily used in the industry. We support both the modern XML and the ancient EDI formats at my job because of various customer and partner integrations
EDI is an OLD OLD format and you are correct XML never really caught on. There are changes from Version to Version they sometimes are minor and sometimes not so much. Like 4010 to 4030 they changed the composite qualifier.
Please stop spamming the sub.
The specific EDI format I use are called DARE (used to accept electronic insertion orders from advertising agencies and ingest into a "Rep" system) and R100 (used to take data from a "Rep" system and send that to a "Traffic" system at the TV station), not anything specifically called "EDI".. they are Electronic Data Interchange formats.
Well I think I accidentally stumbled on the company you work for. I am not familiar with DARE as an EDI format but there were several off shoots of X12. Like VICS and The medical one which I cant remember.
Play with it and figure it out like anyone else would do. Geez!
Maybe not what you are looking for, but most professional C# developers I know use Resharper like a linter if they want one. The tools /u/TheHexWrench mentioned are good too, and I think they can be used during CI builds too, which might be nice.
This is great! But the output is really difficult to work with. Is there any way you could output everything to JSON? FYI, my interest in this is related to PowerShell Core development (PowerShell Core is the .Net 2.0 App that can run on almost any OS, as opposed to Windows PowerShell, which is the .Net Framework App that comes installed on Windows by default). Right now, there are a lot of basic cmdlets missing from PowerShell Core (like Get-NetIPAddress for network info), and this report can provide a lot of info until the PowerShell community gets around to filling the PowerShell Core capability gaps. Also, I just filed an issue on GitHub related to using the netstandard2.0 assembly in PowerShell Core Beta 9. Thanks so much for creating this!
Is this WPF or Winforms? Basically, this behavior is dependent on the properties of the controls themselves relative to their container (the window). For WPF, I imagine you can set a min and max height/width for each control (or the container they are in) and the window should be able to resize freely without resizing the controls. For winforms, I believe this behavior is controlled by anchoring or not anchoring a control's top/bottom/left/right edges to the edges of the window
Am I the only person who's kind of sick of articles and presentations which present themselves as informative but really boil down to **To solve your problem, buy my product**? 
If the number of concurrent users is small, just deploying a windows service that also self hosts the front end is a good simple option and can be buttoned up fully self contained in a wix installer for very simple deployments manually or automated
I used parts of it for a job I’m working on right now, namely the DI, dynamic APIs for application services and background services with Quartz. Honestly, the ABP Framework has really helped me bridge the gap between developing enterprise Windows apps and fully featured Web apps. I have learned a lot picking through the source code. I will be using the full framework on a side project coming up here as it offers many of the features we are looking for, in addition to it being extensible with its module system. I’m a big fan.
Thanks for posting. I was just working on something where this will fit the bill quite nicely. Cheers!
Since I was on my phone, here is a better explanation: Both tools are Roslyn Analyzers and are added as NuGet packages. The errors/warnings are displayed in VS and/or command line. What is an error/warning/information can be configured. FxCop is more of a "code guidelines" checker, e.g. something like "do not expose generic lists", "Implement IDisposable Correctly". Many things about coding quality and performance. StyleCop is more of linter. You can add rules about braces and so on. Important: If you plan to use FxCop/StyleCop in a .NET Core project, you have to add &lt;Features&gt;IOperation&lt;/Features&gt; to a *&lt;PropertyGroup&gt;* element in your csproj. This information is unfortunately hard to find but extremely important.
We use a combination of FxCop, StyleCop and Resharper. Resharper also has a StyleCop plugin too with quickfixes for StyleCop violations. The nice thing is, that having FxCop and StyleCop works for people on the team without Resharper too. You can also add an [.editorconfig](http://editorconfig.org/) to the project root (VS 2017 and VS Code as most editor support it). Here you can define some low-level guildes like indentation style. 
Characters aren't expensive :) better too much than too little.
I didn't know about .editorconfig. Cool.
[removed]
I've wondered the same thing. As long as it's been around I have yet to see one presentation on it online or at a code camp or conference. It'd be nice to see a good presentation/discussion from a passionate user.
To use performance counters with .Net Core, don't use .Net Core? Marvelous tip. 
IdentityServer doesn’t include user management functionally such as registration &amp; password reset. You have to implement these yourself using a library such as ASP. NET Core Identity.
I tired and couldn't. That's why I posted here.
It's UWP. I hoped there would be some kind of resize property on the whole grid. Guess not.
[removed]
Ok, thanks for your reply.
Also ReSharper Command Line analyzer is free to use (good for CI scenarios). https://www.jetbrains.com/resharper/features/command-line.html
I think the main question is: Do you want to deploy your web app to other hosting than windows? If yes - then the only solution would be .NET Core, but if you play to deploy your app only to standard windows hosting, then there is not need to migrate to .NET Core, because you wouldn't get any new big features. Standard ASP.NET would be enough.
You can use .NET Core, you just can't use the Core CLR and deploy to Linux.
I would encourage you to learn .NET Core 2.0 and ignore .net core 1. Also, ASP.NET core 2.1 is expected to come out early next year. Look into the following terms ".NET Framework", ".NET Core", ".Net Standard" &gt;The .NET Standard is a formal specification of .NET APIs that are intended to be available on all .NET implementations. The motivation behind the .NET Standard is establishing greater uniformity in the .NET ecosystem. So if you code up your stuff in one and follow .NET Standard, it might work as a dependency for the other.
Yes!
https://www.youtube.com/watch?v=HeDjv3blBjQ&amp;list=PL1rZQsJPBU2StolNg0aqvQswETPcYnNKL&amp;index=1
head over to Stack Overflow. you'll get better responses or even find someone else's answer.
Do they go over Boilerplate in this one?
&gt; You can use .NET Core, you just can't use the Core CLR and deploy to Linux. Titling this post "How to Use Performance Counters with .NET Core: Current Solution [...]", and then going on to describe the process of building an application using the .NET Core SDK tooling that targets the full .NET Framework, is grossly misleading. You're not "using performance counters with .NET Core" this way... by the time performance counters come into play, you're "using them with" the full .NET Framework... the only part about it that can even be called ".NET Core" is that you built the full .NET Framework application using tools that can also be used to build .NET Core applications.
I dunno, man. Reading up on the [documentation](https://aspnetboilerplate.com/Pages/Documents), it supports way more than just frameworks out of the box. 
Could you help me name the thing I'm looking for? I'm not sure what the exact term is.
Check how the module system works using OrchardCore Modules.
Nothing is free. All these pre-arranged infrastructure is nice but only if your applications demands it. Once you start with ```using Abp.Domain.Entities;```, you are committed to the framework. It might or might not be a good thing depending on your requirements.
Not sure about xsd 1.1, but Saxon supports XSLT (2.0, 3.0), XQuery (1.0, 3.0, 3.1), and XPath (2.0, 3.0, 3.1) https://www.nuget.org/packages/Saxon-HE/
I could see them stopping support for their MVC as they migrate more and more if the functionality of MVC into core. Another Project Manger had to drill this distant fact into my skull. This conclusion is very far in the future tho, so if you’re quicker using the MVC model I’d say stick to it for now, while keep an ear out on future core versions. 
That's what I'm talking about returning. A domain model. There are no rules saying domain models are one to one with a table. That's something a lot of people fall into with things like Entity Framework and such because it makes sense in most cases. But there is nothing wrong with projecting a single table into multiple entities if that makes sense from a performance stand point, etc. Some of the "generic repository" pattern stuff is built around that "should", but that's just one reason its fallen out of favor for half of the community. The "entity" approach vs the "query" approach is something that you see a divide on. Entity approaches are simpler for people who don't know or care about SQL, but on a lot more complicated apps, you need the full power of SQL to achieve what you want (thus smaller direct object mappers like Dapper are more common for those). You can also pull the full entity and then project your DATA model into your DOMAIN model. It's not uncommon to have three layers of entities (data which is a direct map to table, domain for internal representation, and view models or API contracts for what actually goes out to the clients). It's just less efficient, and non-viable in really big cases where you want to limit what you bring back at a lower level (SQL).
Thanks. I did checkout our Stylecop but it wasn’t obvious how to make it work so thank you for a more detailed explanation. Someone else recommended resharper and I tried out the free trail yesterday. It’s absolutely awesome but has a big price tag so I might take another look at these two options. 
Definitely have to check this one out. The resharper plugin is amazing. This could work nice on our deployment server
24 hours later, tons of build agents cried out in anguish. 
Your login and registration pages are hosted in your identity server project, and you redirect to that from your apps. It's really clunky from mobile apps because you have to use a webview or a browser instance, and there's just strange behavior and it's somewhat difficult to get it to work smoothly. I have no idea what would be a good alternative though since I was kind of forced into making identity server 'just work'.
While it's not as straight forward, you can still use ViewModel validation at the backend and send validation errors via the webapi to display on your frontend (some processing is required but should be easy enough to generalise for all your views/forms). I normally just set up validation for required inputs on the frontend and everything else I get from the backend, but it can also be feasible to duplicate the whole validation on the frontend for a smoother user experience. http://www.jerriepelser.com/blog/validation-response-aspnet-core-webapi/ Personally I also use FluentValidation because it makes configuring the validation a bit easier in my opinion https://github.com/JeremySkinner/FluentValidation/wiki/i.-ASP.NET-Core-integration (Note: both articles are for ASP.NET Core but should also work with minor adaptions for pre-core projects)
The article is a good start, but is lacking some key details like refreshing tokens and token revocation. (I just glanced at the article so I may have missed it if you mentioned it) With regards to OPs question, I am not sure the specifics of your application but its important to note that frameworks like IdentityServer are an implementation of the OAuth2/OIDC frameworks and OAuth2 is designed for authorizing 3rd party applications access to user protected resources.
I seem to remember from skimming the release notes that the "classic" MVC or MVVM approaches are still possible in .NET core 2.0. Is that not the case (anymore)?
I found learning Perfview VERY useful. The video tutorial, done by the creator himself, is good: https://channel9.msdn.com/Series/PerfView-Tutorial
Yes of course they are still possible and also a bit less complicated then they where before. But for everything that's not a simple internal web application I prefer using a Web API with SPA frameworks like Angular or React because I think they deliver a better user experience and better modularity if you want to switch to a different frontend in the future.
Thanks!
Yes. Quite honestly working with ASP.NET pre Core is such a chore. I've used Core to make both API projects and MVC projects, and the difference between doing those with Core and with pre Core is like night and day. Pre-core feels like a relic to use (maybe the wrong word here) but everything feels like its one giant [kludge](https://en.wikipedia.org/wiki/Kludge#Computer_science) to achieve anything interesting. I find working on ASP.NET pre core to be an all round frustrating, at times poorly documented, and it certainly invokes a few "Oh yeah, I forgot, I have to do it this convoluted way which is a one liner in Core". For example, the bipolar personality disorder that ASP.NET MVC and ASP.NET Web API has: exactly the same named classes in both but with wildly different implementations. It's far to easy to accidentally add in some ancient crap from `System.Web` when you meant something from the newer namespaces... *and the damn thing will still compile*. You don't know something has gone terribly terribly wrong until runtime... *if you are lucky*. Some of those overlapped types sometimes work the same as each other... *until they don't*, leaving you puzzled and then realising the fix is to fix the `using`. Another one is the shitty JSON serializer that is used in ASP.NET pre Core: There is no way to apply the proper and correct naming conventions for JSON/Javascript like you can with JSON.NET. Anyone who works with TS/JS and ASP.NET knows the frequent pain of having to have pointless violations of JS naming conventions because the damn API is returning data that looks like this: { "CustomerName": "Test" } instead of the correct: { "customerName": "Test" } Core now has JSON.NET as the default, I don't even know if the older shitty serializer is available to be used in Core. Another point is Core's promotion of dependency injection which is a whole topic on it's own and what you should always be aiming for, but yeah, it has that built in too. Core is a much much cleaner in every way possible. I detest working on ASP.NET pre Core.
But you do get a lot of big new features. MVC Core is a complete rewrite and is stuffed with new features and quality of life improvements. Even if not targeting the. Net Core runtime, there are huge benefits to moving to MVC Core.
Thanks for replying, I figured that may be the case. Where I'm more stuck is where does that live in the chain, On the IdentityServer or the API? My ideal use case would be not having to use a webview or browser as a login dialog on the native mobile app as per [/u/CptAmerica85](https://www.reddit.com/user/CptAmerica85) comment. I would rather the app's be able to POST for login / registration if its a possibility. Do you have any suggestions as to how I would structure such a setup?
We totally agree with all of these!!! So I uploaded them all as issues so we can address them, - There is no way to filter already created contents. Everything is listed together. - https://github.com/OrchardCMS/OrchardCore/issues/1189 - There is no way to root the default folder within asset folder for specific content types. So if you are blogging extensively, every time you upload an image, you have to navigate from the root folder again. - https://github.com/OrchardCMS/OrchardCore/issues/1199 - There is no way to edit the content from the output, e.g. edit this page functionality. Even the most basic functionality that will bring the user from the output to the editor will help a lot. - https://github.com/OrchardCMS/OrchardCore/issues/1200 - Most of the editors do not have save and continue features. - https://github.com/OrchardCMS/OrchardCore/issues/1201 - There are way too many concepts that are not explained well from zones, shape, widget, stereotype, layers, etc. - https://github.com/OrchardCMS/OrchardCore/issues/1197 - When you are editing the template, there is no way to navigate what's properties are available except using the display tag. - https://github.com/OrchardCMS/OrchardCore/issues/1202 Got any more?! :)
I've absent mindedly thought about someway to expose the validation rules for a model on post to the client app. Someway to say "hey, for this http method to this uri what are the the validation rules for the message body?" Not sure how it would look or if that would be insane. But I could see it being useful.
I guess you could always expose your validation rules in this way GET /api/employees/validations { "firstName": [ { rule: "required" }, { rule: "minLength", params: [4] } ], "birthDate": [ { rule: "between", params: ["1900-01-01", "1999-12-31"] } ] "employeeNumber": [ { rule: "required" }, { rule: "regex", params: "^[0-9]{5,5}$" ] ] } and then retrieve your validation from a fixed rule set via something like this: for (let prop in entity) { for (let validation of validations[prop]) { let validationResult = RuleSet[validation.rule](validation.param)(entity[prop]); } } I haven't put to much thought into it, but it's probably more complex if you need to validate against another field (like x &lt; y). Also I see a few drawbacks if you want to use this with none dynamic languages as an api consumer. For JS this would probably work fine, but I would probably sanity check this with other people before I would think about implementing this.
Registration can live anywhere, as long as it ultimately creates a user account somewhere, that IdentityServer can use. Browser based authentication for native apps is a must: https://tools.ietf.org/html/rfc8252 What you hinted at can be achieved using the resource owner password credentials grant type. Please don’t use this. I beg of you: https://www.scottbrady91.com/OAuth/Why-the-Resource-Owner-Password-Credentials-Grant-Type-is-not-Authentication-nor-Suitable-for-Modern-Applications
I second this. As someone who learned programming using .NET Core and eventually ended up in an internship using full .NET Framework (although we are *slowly* transitioning), everything just feels heavy and clunky.
I would search around "responsive UWP apps" and read up: https://docs.microsoft.com/en-us/windows/uwp/design/layout/screen-sizes-and-breakpoints-for-responsive-design
Except it's not weird at all. Microsoft has decided to focus on xquery which is a better fit for where they want to take dot net. This is perfectly rational since it's functional and strongly typed rather than a steaming pile of shit like xpath. Given this, why would they implement xsd 1.1 which is essentially xsd 1 plus xpath. Even if adding xpath to anything was a good idea, if they're not going to going to support xpath enhancements xsd 1.1 would just be crippled. 
What components are you using that aren't otherwise included with Bootstrap or freely available as independent JS?
Thanks again, you have convinced me to not go with the ROPC form and to do things correctly.
I think for now it's ok to continue use "old" asp.net mvc, but it will be more and more projects using dotnet core and new ecosystem so you will need to learn it anyway. 
I think the [`HorizontalAlignment`](https://msdn.microsoft.com/en-us/library/system.windows.horizontalalignment.aspx) and [`VerticalAlignment`](https://msdn.microsoft.com/en-us/library/system.windows.verticalalignment.aspx) properties are what you're looking for.
Use FluentValidation
However if you follow the relatively new ".NET Standard" specification that Microsoft puts out, then you can write libraries that work with both framework and core.
Yea, for a website, there is usually no reason to stick with .net framework.
You can run MVC Core on the .NET Framework (not .NET Core) as well though - we do for compatibility reasons. 
Second this. Depending on your front end framework, there are tons of options and documentation. To get you started, I've used [Datatables](https://datatables.net/) in many projects.
FxCop and StyleCop are easy to use - you just have to install the NuGet packages. Unfortunately configuring the rules is a bit awkward, but once the rules are set it works just fine. We use FxCop, StyleCop and ReSharper (it is worth every penny!) as they work very good together. The analyzers are good for finding flaws, and ReSharper for correcting them. ReSharper has a plugin for StyleCop too which adds quickfixes for StyleCop violations.
And after digging through the source git repo for auth, finally found it, was so simple. context.AuthenticateAsync() apparently will replicate it.
Because Microsoft marketed .net as an enterprise platform. Turns out that in the enterprise sector, you are sometimes mandated to validate XSD 1.1 schemas or use XSLT 2.0 transforms. So sometimes I'm stuck either switching platforms for specific projects (Java), or seeing if the files can be re-written in XSD 1.0 or XSLT 1.0 and hoping they don't change too often. 
I've never had to do a whole lot of pre core mvc or webapi, so i'm always shocked when people hate on asp.net. it doesn't make sense, asp.net is super slick, and it's one of the fastest frameworks out there. what can they mean? oh wait, they aren't talking about asp .net *core*. global.asax? lol. nope. iis? nope. web.config? nope. app domains? nope. silent failures? nope. closed source magic? nope. console app. on linux. in a container. load configuration however the hell you want. configure the server programmatically. logging to stdout. runtime perf that makes me blush. and when something is wrong, i can look at the code to see if I'm just doing something stupid. and the .net core community is extremely active, and momentum is only getting stronger. /happy rant. life is very good in asp.net core these days.
As you said, there are libraries for that, but xpath is truly shit. 
If you are looking into web components ( no MVC wrappers ) I successfully used prime ng ( primefaces) , it is not up to par with kendo or dev expess or even ignite but has most of the components you might need and it’s free. Hope this helps 
The entirety of Tess Ferrandez's amazing blog is worth reading, but starting from the `Debugging` tag might keep the time commitment down to less than... erm, a year or so: https://blogs.msdn.microsoft.com/tess/
It's a bit domain-specific (but then, that's half the joy of Roslyn analyzers!) - check out Serilog Analyzer if you are doing any work with Serilog: https://github.com/suchiman/seriloganalyzer
why do you need to use something other than the attributes? actually asking.
A bunch of different, and simplier, ways to handle web requests now outside of controllers that are actually kind of elegant with core 2. Check out web delegates. 
I'm not here to tell you what you want... but what I realized I wanted was not a Resharper-clone, but a set of extensions that made me as *productive* as Resharper, without the horrendous slowdown it causes. With that in mind, I currently use: Codemaid NUnit Test Adapter Roslynator Stylecop.Analyzers as part of my builds
In Visual Studio you can change the auth method to organizational when you create the app and it will register the app in Azure AD for you. You can also set it up after it's been created from the connected services panel. https://docs.microsoft.com/en-us/azure/vs-azure-tools-connected-services-add-active-directory Even if you don't have visual studio that link should be enough to get you headed in the right direction.
&gt; Stylecop.Analyzers Great extensions yet with emphasis on the Marker Bar and the Smarter Intellisense i hardly can find any convenient alternatives. And yea i am here because Resharper makes everything horrendously slow..
I had good experiences with Coderush from DevExpress. It's more performant and it has some features you don't find in Resharper. However Resharper has more features.
The only two features i use in resharper are those described above so if there is something out there which provides similar experience i will gladly switch.
Hey, I have the same problem. I can't find an example anywhere. The microsoft doc has an angularjs sample :(
 I would say that changing the IDE might seem a good alternative cuz VS is really bloated and Rider comes with Resharper shipped with it... and yeah, super fast and small! (I'm still using VS 2017 cuz Rider miss scaffolding views feature in asp core).
Really ? i thought rider is same crap as WebStorm and other Jetbrains Java IDEs, I tried WebStorm and it was a disaster.
Yup confirmed, it's the same crap as the others, my eyes still hurt. 
Showing errors in the scrollbar has been a built-in feature since Visual Studio 2013; so for that specific feature you don't need Resharper, however it does not show warnings. Visual Studio's intellisense has come a long way, I'd recommend you trying Visual Studio 2017 without Resharper, i think you might be surprised how comprehensive the intellisense is. if you are still want to supplement VS features, i recommend Productivity Power Tools, not only is it free, but to ensure your VS is as light as possible every piece of Power Tools can be turned on/off individually.
Syncfusion has good a licencing model (flat fee). Its free if your revenue is below 1 million, if its higher it costs you abt 4000$ a year. No hidden costs, unlimited developers, projects, installations
If you enter a search query at the input box at the top right and press Enter the url in your browser will change to what you need for adding it as a search engine. e.g. Search for 'csp' https://docs.microsoft.com/en-us/search/index?search=csp Usually you just exchange search (here csp) with %s , so the url for the search engine may be https://docs.microsoft.com/en-us/search/index?search=%s It may depend on your browser.... 
Another alternative is to just use your search engine but for a site specific search. e.g. both DuckDuckGo and Google support "site:" queries [DDG - Azure](https://duckduckgo.com/?q=site%3Adocs.microsoft.com+azure) [Google - Azure](https://www.google.co.uk/search?q=site%3Adocs.microsoft.com+azure) 
I looked in to this in the past and was frustrated by the fact this is no longer an active or supported project. It's very strange that something like this isn't a basic feature of .NET/VS as, coming from Java, it seems like such a fundamental thing.
Thank you.
Thank you.
Oh, good to know! I thought that MVC Core is meant to use only .Net Core, and not .NET Standard or just .NET Framework. 
So a while ago, as a hobby and then later as an attempt to start a business, I made an Excel plugin for using SQL in Excel. I've now added the capability to use C# in Excel, using Roslyn. Sort of like Linqpad in Excel. This lets it work with Excel tables, fiddle with formatting, and automate stuff. Some of the practical applications: - processing data in Excel (LINQ) - getting data from various sources into Excel (REST, databases, files, active directory, whatever) - building interactive dashboards - building prototypes applications (you write logic in C# and use Excel as the UI and data storage) Here's the [introduction](http://querystorm.com/documentation.html). There's also a [short video](https://vimeo.com/242216594) for a brief intro. I charge for the plugin but it's freemium. If you don't want intellisense, error squigglies and so on, you don't need a license. So... what do you think?
Are you looking at using Visual Studio or Visual Studio Code?
Yes, it's the same IDE. Curious what your issues are with it?
Is there an upgrade guide for 3.9 -&gt; 4.0?
I think it's brilliant. If I were still working in an office, I'd probably find a million uses for something like this. As an aspiring game developer, I could definitely see using this for managing game data without building my own tools completely from scratch. 
https://github.com/nopSolutions/nopCommerce/releases/download/release-4.00/nopCommerce_4.00_upgrade_guide.pdf
Hey, thanks! Yeah, I think it's pretty nice for prototyping if i do say so myself. No preparing databases, and very little UI work required. Just get data, and dump it somewhere into the excel file. Excel's formulas and charts update automatically as the data is updated, so you're also getting data binding for free. Anyway, thanks for the kind words, I do hope you use it and get a kick out of it!
You could basically create simple Access-ish databases this way. Put your "interfaces" on separate pages from your data.
Wow very nice, congratz nopCommerce teams and all .net devs. Is it possible to run this on a linux docker container ?
Great! Thanks!
Yeah, exactly, put the data into a separate sheet from the UI sheet. It's even possible to hide sheets to keep the raw data safe from those pesky users:)
Congrats guys
I've been working with 4.0, it's fantastic. One of the major downsides to NopCommerce the past few years was needing to switch gears back to MVC 5 when all of my other projects are in Core. The only downside I see right now, is that there are very few themes and plugins available for 4.0. I'd imagine they require some significant rework to be compatible with 4.0 and ASP.NET Core. Just something to keep in mind if you are planning on giving it a go. 
Also curious. JetBrains' IDE's are all great. DataGrip is amazing and I love webstorm too.
I don't know what's the crappy part you saw there... it's very stable and just 260mb ! VS is about 10 gb to get up and running with a simple .Net core project!! And do not forget the XUnit shi**y adapter... sooo slow :~ Not mentioning opening project which takes years to load.
Can anybody with experience in both this and Shopify share which they think is better?
This looks awesome. I'm going to give it a try soon.
"Past few years" of being on Core? do you have time machine?
Hey, happy to hear it! Let me know in case of any suggestions, comments, questions and all that
Your setup looks fine. I would use your browser's dev tools to verify the cookie(s) are being set.
Well I guess I was referring to MVC 6 and Core, essentially when the disaster which was the MVC 5 web.config was moved to Startup.cs configuration (among other improvements). I've been working with 6 &amp; the Core RC's. MVC 6 was in 2014-2015, so yeah, a few years now. Times flies.
NopCommerce is an open source project, so complete customization is possible. 
The out dated look of the IDE itself is kinda distracting. even with themes it's still have some weird borders and unpleasing fonts. not to mention the utterly mediocre performance compared to how lite the installation is. So moving from this [Imgur](https://i.imgur.com/U30KjSf.png) is kinda hard.
i replied to @heji above about what i find wrong with Jetbrains products.
But if you want to take ecommerce seriously check www.carismar.com 
Yeah i am already on VS 2017 just as i suspend resharper Intellisense becomes way less `intelli` the difference is still huge. also showing code style warnings in the scrollbar is so handy.
Do they have a plattform för developers/partners?
The pic is Visual Studio 2017, not vscode. (that theme is a custom one i made)
Great idea! I just added a .NET Core search shortcut to my Chrome. * Chrome Settings -&gt; Manage Search Engines, then click ADD. * Enter a name for the search engine. * Enter a keyword (I used **net**). * Enter a search query (I used https://docs.microsoft.com/en-us/search/index?search=%s&amp;scope=.NET). * Click ADD and you're good to go!
Excel fills me with rage every time I use it. This looks like it would help my anger management.
We used to have it but now we are focusing on middle size e-commerce clients. Maybe in the future? 
If it's an ASP.NET Core 2.0 project, it should run on `microsoft/aspnet:2`. I'm running my own project on this, works great. I had some issues on an older version of Docker, where the container wouldn't shut down (only the aspnet based ones for some reason), but upgrading Docker solved that.
Rider is great for some people Pros: - fast - resharper built in Cons: - not all project types are supported - somewhat expensive - does not integrate well with desktop scaling
Maybe install [SonarLint](https://www.sonarlint.org/visualstudio/)? This is from the same team that do [SonarQube](https://www.sonarqube.org/).
Vscode is great and free
Thanks for the article. I definitely ended up using it to implement my JWT token. One thing that ended up tripping me up was in the article you aren't using Asp.net core 2 Identity. One thing that is important in Identity is setting the Claim sub to be the user id and NOT the username or email address. new Claim(JwtRegisteredClaimNames.Sub, userId) This allows you to retrieve the user using the UserManager's GetUserAsync with the ClaimsPrincipal that is present when calling an endpoint with the [Authorize] attribute. I'm not sure if you are planning on doing an article on Identity or not but it might just be a helpful tip for the article.
this comment really rubs me the wrong way. Care to expand on why your company's solution is more "serious" than the ones presented?
I think it just might:) I'd love to know if it does
I've got a payment plugin that I'm upgrading to 4.0. Its the most amount of work to upgrade yet but I should be done this weekend. 4.0 is noticeably faster.
The reason rider is less bloated than VS, aside from missing a lot of features is that it only has to compile the code once to deliver its feature set. If you install resharper into VS it compiles twice, but this is resharper's fault not VS. 
I think webrequest has a default number if maximum redirects. Maybe try it after explicitly setting maximum redirects to a high number?
Just curious, how many business subscriptions have you gotten at that price? I'm aware what you've built holds huge business value, but I'm wondering if anyone's been willing to pay $300/seat for it.
This is my understanding: others can open the Excel files without the plugin, but automations and scripting will not work - they're basically dumb Excel docs without it. With that in mind, /u/anakic might want to consider introducing a free "runtime" license/binary for commercial users. This would be "read only" and include the ability to execute csx via automation/VBscript. No IDE, no editing scripts or modifying triggers. Maybe some advanced features would continue to be locked behind a paying license, but for the most part it would allow non-developers to consume Excel docs with this technology without paying for a developer license.
&gt; There is no way to apply the proper and correct naming conventions This is not at all true. In global.asax you can set the JSON formatter/resolver to `CamelCasePropertyNamesContractResolver` and it automatically camel cases property names. It's existed for years. Also, I'm pretty sure it's been the default behavior for non-Core MVC/WebAPI since last year so if it's a choice between one or the other today they both act the same.
[**The Authorization header is cleared on auto-redirects** and HttpWebRequest automatically tries to re-authenticate to the redirected location. In practice, this means that an application can't put custom authentication information into the Authorization header if it is possible to encounter redirection. Instead, **the application must implement and register a custom authentication module**.](https://msdn.microsoft.com/en-fr/library/system.net.httpwebrequest.allowautoredirect.aspx)
* Template needs to accommodate `mobile only template`. That will requires better mobile sniffing support. Responsive design is not the answer to mobile site. More and more people are complaining about the state of websites on mobile. * There is no reason why the themes cannot be managed and edited from the browser. They are just a bunch of files. * Fluid template supports include. It's not very clear how it can be used inside OrchardCore or if it is supported. * Fluid needs to support inline partial. There are so many cases where you have to repeat Fluid templates. * It needs activity log so if you are working with a team on your site/blog, you know who does what and when. 
Cool... what about F#? 
I don't know of any out of the box solutions, but I run a pretty basic solution and it works. I just run the database and two instances of the application with a systemd unit, which keeps them running. The two app instances run on different ports behind an nginx instance. Whenever I need to run an update, I have scripts to pull down a new build, install it, and then restart each instance, staggered by about 30 seconds. Monitoring can be done with nagios, including emails and sms messaging. 
This is actually one of the reasons I'm a fan of azure, especially if you are already doing .net code. Assuming you do not choose a VM specifically and opt for a service resource, it will all be handled and abstracted away for you. When you buy into a platform as a service these are exactly the things you are paying not to care about. When they need to apply a patch to all their VMs they would transfer everything out of a shared VM/OS upgrade it then put it back in the pool. Yeah, it's complicated and hard to transfer and entire OS bit for bit while running in real time, but it's possible and that's what you pay to not deal with. If you roll your own VM(probably docker too?) then that's a different story.
This is assuming you are using WebAPI and not stuck on a setup with MVC controllers and doing: return Content(jsonString, "application/json"); or return Json() Which also adds another point about the bipolar personality disorder: there's about 20 ways of doing anything.
You might find the link below helpful too. The first one contains a ton of good info. I think it is all being updated for .net core 2 right now but it should still be relevant. The first two "books" will probably be the most helpful. There are sample apps too. https://www.microsoft.com/net/learn/architecture
Kubernetes? Service fabric?
You use something like kubernetes or docker swarm to host everything in containers that have some redundancy. That way the containers can always be updated to the latest patches without interruption. There are other ways like using VMs but containers are the way these days. Once everything is in the swarm you can take a physical node down and update it without affecting the services on the swarm.
As I was reading OP's part I was imagining a setup like the one you just described. I never though to do the database replicated on each VM too. Clever. I always thought Docker would work well for this too. I'm going to look into Kubernetes and Terraform looks neat too. I wonder if Terraform has built in features for this.
Would love to. Unfortunately, Roslyn doesn't support F# so I can't support it with a few hours of work, I'd have to invest a month or two of development, but other tasks are a priority now. It's quite possible I'll add support for it in the near future, though.
Were you logged on to your subscription when you were doing these tests?
Logged in, like into the web portal with my browser? Yes. I see what you're getting at, I tried on another machine that was not logged in (and never had been) and still the same result.
If you indeed found a bug, I'd tweet to Azure or Azure_Support. They respond pretty quickly. Nice find. 
Did you run the test in the portal or with the PowerShell cmdlets? I cannot replicate this, but if you can with more tests, it is something that should be brought to the attention of the Azure people.
I actually got a pretty good answer [here](https://www.reddit.com/r/AZURE/comments/7c78le/im_able_to_login_to_storage_account_with_invalid/dpo1spq/). It appears this has to do with the way the keys are Base64 encoded.
Cool :-) I thought that had to do with the padding required in base-64 encoding but did not want to potentially mislead you with confusing explanation. Good someone was able to do that.
Exception.ToString() still output stack traces for C#1 so all the new features from C#2 -&gt; C#7.2 come out as a garbled mess. This library converts stack traces from the exceptions back into the source code signatures - rather than the compiler intermediary functions
Personally I just have a $10 instance on Digital ocean running Ubuntu
Check out eShopOnContainers: https://github.com/dotnet-architecture/eShopOnContainers/blob/dev/README.md
I know this does not solve your problem, but you should be using ASP.NET Identity instead of ASP.NET Membership nowadays.
Will it output line numbers (assuming .PDB is available)?
A post on stackoverflow says you have to set the cache option https://stackoverflow.com/a/9088541
&gt; Will it output line numbers (assuming .PDB is available)? Yes, so it will change System.Exception: Collection was modified; enumeration operation may not execute. ---&gt; System.InvalidOperationException: Collection was modified; enumeration operation may not execute. at System.ThrowHelper.ThrowInvalidOperationException_InvalidOperation_EnumFailedVersion() at System.Collections.Generic.List`1.Enumerator.MoveNextRare() at Program.&lt;Iterator&gt;d__7.MoveNext() in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 65 at System.Linq.Enumerable.SelectEnumerableIterator`2.MoveNext() at System.String.Join(String separator, IEnumerable`1 values) at Program.GenericClass`1.GenericMethod[TSubType](TSubType&amp; value) in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 172 --- End of inner exception stack trace --- at Program.GenericClass`1.GenericMethod[TSubType](TSubType&amp; value) in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 176 at Program.&lt;MethodAsync&gt;d__8.MoveNext() in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 78 --- End of stack trace from previous location where exception was thrown --- at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) at System.Runtime.CompilerServices.TaskAwaiter`1.GetResult() at Program.&lt;MethodAsync&gt;d__9`1.MoveNext() in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 84 --- End of stack trace from previous location where exception was thrown --- at System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() at System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) at System.Runtime.CompilerServices.TaskAwaiter`1.GetResult() at Program.&lt;&gt;c__DisplayClass12_0.&lt;Method&gt;b__0() in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 103 at Program.&lt;&gt;c__DisplayClass12_0.&lt;Method&gt;b__1() in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 105 at Program.RunLambda(Func`1 lambda) in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 97 at Program.Method(String value) in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 105 at Program.&lt;RefMethod&gt;g__LocalFuncRefReturn|14_1(&lt;&gt;c__DisplayClass14_0&amp; ) in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 127 at Program.&lt;RefMethod&gt;g__LocalFuncParam|14_0(String val, &lt;&gt;c__DisplayClass14_0&amp; ) in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 121 at Program.RefMethod(String value) in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 117 at Program.&lt;&gt;c.&lt;.cctor&gt;b__19_1(String s, Boolean b) in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 43 at Program.&lt;&gt;c.&lt;.cctor&gt;b__19_0(String s, Boolean b) in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 42 at Program.Start(ValueTuple`2 param) in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 158 at Program.&lt;Start&gt;g__LocalFunc1|15_0(Int64 l) in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 139 at Program.&lt;Start&gt;g__LocalFunc2|15_1(Boolean b1, Boolean b2) in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 144 at Program.Start() in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 135 at Program.&lt;&gt;c.&lt;.ctor&gt;b__5_0() in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 50 at Program.&lt;&gt;c__DisplayClass6_0.&lt;.ctor&gt;b__1(Object s) in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 58 at Program.&lt;&gt;c.&lt;.ctor&gt;b__6_2(Action`1 lambda, Object state) in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 45 at Program.&lt;&gt;c__DisplayClass6_0.&lt;.ctor&gt;b__0(Object state) in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 58 at Program.RunAction(Action`1 lambda, Object state) in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 90 at Program..ctor(Action action) in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 58 at Program..ctor() in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 50 at Program.Main(String[] args) in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 15 Into System.Exception: Collection was modified; enumeration operation may not execute. ---&gt; System.InvalidOperationException: Collection was modified; enumeration operation may not execute. at bool System.Collections.Generic.List&lt;T&gt;+Enumerator.MoveNextRare() at IEnumerable&lt;string&gt; Program.Iterator(int startAt)+MoveNext() in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 65 at bool System.Linq.Enumerable+SelectEnumerableIterator&lt;TSource, TResult&gt;.MoveNext() at string string.Join(string separator, IEnumerable&lt;string&gt; values) at string Program+GenericClass&lt;TSuperType&gt;.GenericMethod&lt;TSubType&gt;(ref TSubType value) in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 172 --- End of inner exception stack trace --- at string Program+GenericClass&lt;TSuperType&gt;.GenericMethod&lt;TSubType&gt;(ref TSubType value) in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 176 at async Task&lt;string&gt; Program.MethodAsync(int value) in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 78 at async Task&lt;string&gt; Program.MethodAsync&lt;TValue&gt;(TValue value) in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 84 at (string val, bool) Program.Method(string value)+()=&gt;{} [0] in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 103 at (string val, bool) Program.Method(string value)+()=&gt;{} [1] in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 105 at string Program.RunLambda(Func&lt;string&gt; lambda) in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 97 at (string val, bool) Program.Method(string value) in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 105 at string Program.RefMethod(string value)+LocalFuncRefReturn() in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 127 at string Program.RefMethod(string value)+LocalFuncParam(string val) in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 121 at string Program.RefMethod(string value) in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 117 at (string val, bool) Program.s_func(string s, bool b) in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 43 at void Program.s_action(string s, bool b) in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 42 at void Program.Start((string val, bool) param) in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 158 at void Program.Start((string val, bool) param)+LocalFunc1(long l) in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 139 at void Program.Start((string val, bool) param)+LocalFunc2(bool b1, bool b2) in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 144 at string Program.Start() in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 135 at Program(Action action)+()=&gt;{} in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 50 at Program(Action action)+(object s)=&gt;{} [1] in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 58 at Program(Action action)+(Action&lt;object&gt; lambda, object state)=&gt;{} in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 45 at Program(Action action)+(object state)=&gt;{} [0] in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 58 at void Program.RunAction(Action&lt;object&gt; lambda, object state) in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 90 at new Program(Action action) in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 58 at new Program() in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 50 at void Program.Main(string[] args) in C:\GitHub\Ben.Demystifier\sample\StackTrace\Program.cs:line 15
I host two ways. On a Linux server I write a service for systemd with nginx as the reverse proxy. https://docs.microsoft.com/en-us/aspnet/core/publishing/linuxproduction?tabs=aspnetcore2x I also deploy to an azure app service plan. https://docs.microsoft.com/en-us/azure/app-service/app-service-web-get-started-dotnet Both are simple to setup, but the app service deployments require zero admin outside of setup, autoscale instances, multiple deployment slots, etc. - it's by far my new preferred method. TL;DR: If you have a small app get a cheap Linux deployment - digital ocean, linode, lightsail and manage it. If you need enterprise level service get an azure app service plan.
It uses system events to detect changes, so my assumption is no as nothing will be listening to the events. If you want to emulate this behavior, you could maintain the filesystem state (like file list and their hashes) while the watcher is running. You would then serialize the list to json when you serialize your watcher. On wake up do a directory scan and look for differences and "replay" the differences through your processing logic. 
No, there's nothing built in to do that. The FSW receives notifications from the Windows OS about the basic file events happening. If it is not running, it will not receive notifications and therefore will do nothing. What you could do (I'm not advocating this) is to manually trigger the Created event handler for each file in the directory on startup. In real-time, since the FSW receives notifications directly from the OS, the event handlers will fire after anything happens on disk. By calling the Created event handler for every file in the directory, the FSW assumes that they are newly created and your code will run. The downside to this is that you can *quickly* overload things with large directory structures and lots of files. The real question is: what metadata do you need that's not already part of the [System.IO.FileInfo](https://msdn.microsoft.com/en-us/library/system.io.fileinfo.aspx) class, and if nothing, why not just iterate the folder on startup using this class to refresh your data? 
You can embed a FSW object into a service either using a bus/long running process framework like NServiceBus to automate the error handling if the directory becomes unavailable through either the FSW level or the bus feature level. This is sort of the canned approach since you don't then need to specifically scaffold out error handling for things like the watched server being down. I did it last year on some project, the only instability issues came from NSB itself so there is that. 
nopcommerce
If your file system is NTFS you can use [Change Journal](https://msdn.microsoft.com/en-us/library/aa363798.aspx). Since this is a journal entry outside your app, you can store the last processed information in your app and resume from that entry to process the changes that happened when your app was offline. 
Even FileWatcher that is running won't always catch all changes. There is a hard buffer limit to the amount of information it will catch. Large changes (think directory renames, etc.) will overflow this buffer and you'll only get updates for whatever fit in the buffer. The wisdom on this when I had to do this last time was FileWatcher running at all times to catch what it can, but a full scan on some interval to catch what it didn't, as the best of both worlds. Another tip, for full scan, if you have a ton of stuff to watch, do NOT use the .NET FileInfo objects, etc. Look around, and you'll find some examples of direct FS access from .NET without those abstractions. The speed difference is significant when you have to watch a lot of stuff. I had to watch a directory structure with upwards of 100k files, and the difference was from hours to seconds. I don't remember where I found an example of this, and I don't have the code anymore, but I know example sare out there. You can use LastChanged dates between runs this way to identify what to check, and do MD5 hashes as necessary for identifying beyond that. When I did this last, I found an easy way to do this was to use SQLite databases that I dumped the lastChange dates into on each scan. This made it easy to use JOINs to find changed, deleted, and new files very quickly.
Thanks, the solution I've implemented basically iterates the folder on startup and refreshes the database. The application is an ASP.NET Core WebAPI. Where can I shove the FileSystemWatchers such that they will persist beyond IWebHost.Run()?
Is there an event that I can subscribe to that will notify me of a buffer overflow so that I can run a manual refresh?
Don't believe there was, but there was a way to make the buffer BIGGER... but that doesn't systematically solve the issue, just allows you to adjust if you can make it work within your personal limits. Basically, everything I saw was you HAD to do a full scan to stay in sync at SOME point. FileWatcher used the native OS hooks for this, where the OS itself has that buffer limit, and there was just no way to guarentee that you got everything that way without a full scan (unless you could limit the things you were watching artificially, like watching a single file, or a directory you could control the file count in).
Same here. Every FSW service I wrote had a backup scanner running on a timer to catch stuff that was missed.
&gt; How would you go about this? You don't. Websites can be recycled at any time, killing your file watcher. So put your FSW in a separate Windows service. 
The intention is to have this be as portable as possible, so I'll probably wrap FileSystemWatcher on Windows and inotify on Linux so that I can use them with the same interface. Using the Windows service framework isn't good for portability in that sense. I tried a singleton after reading [this](https://stackoverflow.com/questions/6600093/do-static-members-ever-get-garbage-collected) but it seems that it's getting garbage collected anyway.
https://stackoverflow.com/questions/637948/how-to-migrate-a-net-windows-service-application-to-linux-using-mono
https://docs.microsoft.com/en-us/aspnet/identity/overview/getting-started/introduction-to-aspnet-identity
If you need to use the service during startup, you can use `app.ApplicationServices.GetService&lt;ChessContext&gt;()` to retrieve the service in the Startup.Configure method. Have a look at an example [here](https://github.com/hugo-vrijswijk/GiraffeChess/blob/master/GiraffeChess.WebAPI/Startup.cs)
There is an event called OnError I believe it throws an InternalBufferOverflowException in that case. Look at the answers in [this stack overflow thread](https://stackoverflow.com/questions/11667041/whats-the-best-practice-to-recover-from-a-filesystemwatcher-error)
Thanks! I came up with my own solution after posting this (see original post), but I might modify it to use this instead.
A small note to your solution: the ConfigureServices method really is only meant to, well, configure what your services look like. Starting your application config in there means that things could go wrong when you might add some needed dependencies in your config class.
If you just want simple login and roles, Membership is fine., and a lot simpler to set up than identity and claims.
Thank you. I already know these ebooks. What I want to do is apply some of these techniques to a non-releated project. 
Thank you! I appreciate your comment, but like I mentioned in my other reply, I am already aware of this Microsoft project and I'm now looking for a non-related project to apply these techniques.
Thank you, I will consider this one.
No need for all of that... just understand how the DI works in the ASP .NET Core. Perfect summary for that: https://odetocode.com/blogs/scott/archive/2016/02/18/avoiding-the-service-locator-pattern-in-asp-net-core.aspx To answer your specific question, I had a similar issue when I was making an Uploader service which needs to get the path from the IHostingEnvironment, and there were two options: 1) Register the Uploader service in the DI in the startup class (and it will magically put the needed IHostingEnvironment dependency). 2) If I didn't go with the first solution, then when I instantiate it from any place (controller, view, or whatsoever), I have to pass the dependency by myself from the place it got instantiated. * For seeding data, I added my seeder in the DI like this: services.AddTransient&lt;EntryAgentsSeedData&gt;(); *For repository, I add my repository like this: services.AddScoped&lt;IEntryAgentRepository, EntryAgentRepository&gt;(); And it depends on my DbContext and UserManager, so the constructor looks like this: public EntryAgentRepository(EntryAgentsDbContext context, UserManager&lt;Agent&gt; userManager) { _userManager = userManager; Context = context; } Best of luck!
Are you trying to implement AJAX support in your WebForms page? That is what ICallbackEventHandler is for, and the lifecycle for processing AJAX calls is different from the normal lifecycle which involves serialising/deserialising the View State.
Yeah, I just read [this](https://joonasw.net/view/aspnet-core-di-deep-dive) and found it very helpful. Now I'm having a different problem though. I have a singleton service that has been properly registered in ConfigureServices, but it runs a job every so often (via Tasks.Timer) that needs access to DbContexts (which are scoped services iirc). No idea how to get a fresh instance of a DbContext to the singleton every time it needs to run that method.
I think here you need separation of concerns cuz what you're doing is putting a two different kind of services in one place (singleton and scoped) which seems odd... Just separate the services which you need to do **long** life-time things and **short** life-time things ;) I prefer to put the logic of accessing the DbContext in one place (repository) and **NOT** allow any other way to access the DbContext. * As far as I see is that you are struggling with the architecture of your project, so this course might help you: https://www.udemy.com/design-patterns-csharp-dotnet/
Yeah I really have to up my DI game, this is the first time I've used any sort of structured dependency injection. I'm having a hard time trying to figure out where I can stash the Timer object. I don't think it can be a member of Startup because it'll get cleaned up by the GC after the web host starts, but it can't be a member of the singleton class because it needs those transient dependencies. My amateur hour code is [here](https://github.com/judilsteve/fastmusic/), if you dare. The current hack where I pass in a lambda does *not* work, as the lambda's scope is destroyed before the timer executes its callback the second time.
So far the best potential solution I can come up with is a singleton metaservice that holds a reference to the service provider and can dole out scoped DbContexts at will. Then I just have my LibraryWatcher hold a reference to the metaservice.
I cloned the repo and I tried to figure out what you're doing... as I understood, you wanna watch the file changes and update the database accordingly, right? Won't this cause too much load to the server, why not changing the library monitor into a scheduled task (library updater) as in here: https://blog.maartenballiauw.be/post/2017/08/01/building-a-scheduled-cache-updater-in-aspnet-core-2.html And use the factory pattern to get a fresh copy of the **transient** DbContext *or preferably* Repository! As you know, &gt; Transients are newed up fresh each time they are injected so nothing else can interfere with it. * src: https://stackoverflow.com/questions/33081103/in-simple-injector-why-is-it-an-error-for-a-singleton-or-scoped-service-to-depen 
That blog post looks like exactly what I need. Thanks a ton.
For what it's worth, you should consider supporting your CRUD logic in the library watcher with batch operations cuz you're adding/updating/ deleting one single item then saving the changes every single time.
Yeah, performance profiling and optimisation (and method signature documentation) is something that will happen once I've got the basic feature set working. I started writing this yesterday.
If you are a student like me, you can get all JetBrains products for free!
pretty sure this is the service locator antipattern
It is exactly that. But in this instance it's acceptable, since your container isn't actually off the ground and injecting dependencies until Startup is finished.
As a general rule you shouldn't "grab" a DBContext. Create it when you need it and destroy it immediately afterwards. If you hold onto a context for the lifetime of a request then you aren't efficiently using your connection pool under high loads. Also it makes your service classes and repositories stateful/single-threaded. If using EF, you also have to deal with context pollution. (The more you use a single context, the slower it gets, unless you are very careful about using AsNoTracking and friends.) You can use DI to push down connection strings/options or factory methods. 
I am a working class hero :/
Plug in for Serilog: https://github.com/nblumhardt/serilog-enrichers-demystify :-)
I just started using resharper and it’s great but I haven’t seen the slowdown you talk about? Is this something that happens over time? Using visual studio 2017 machine is ok spec i7, 16gb ram, SATA ssd drive. Just interested to know your experience. 
People underestimate how good design matters even if the tool underneath is amazing. 
I just want to call a function from code behind and then display the result. I tried with Page Methods and now ICallbackEventHandler. This seemed good but the page variables are not saved. So I have to find another way to save variables. And View State seems to be an option. I now also tried it with an serialized class. But I also could not save it. Do you have an example how it works?
Not sure whether that's the best approach, but one option could be introducing an extra service layer, which converts models to different DTOs, on top of the repository. For example, if you have a repository `Users`, you could have `UsersService`, with methods, such as `GetUserName`, `GetUserBasicProfile`, `GetUserFullProfile` that return DTOs, such as `UserBasicProfile` or `UserFullProfile` derived from the `User` model. You can probably use some mapper, e.g. `Automapper`, to make the objects transformation easier.
&gt;When I try to get the values, they are always the values from Page_Load. Just checking. Are you doing a Postback? If you are then you need to wrap your Page_Load in an "if(!IsPostback)" when you set the initial state of your page, otherwise they will be set everytime. 
We really need some kind of sidebar information or blog post to literally point this out every single times, I'm actually getting tired of having to explain to people they shouldn't be putting long running processes inside ASP.NET. Cue much resistance and moaning and complaining that they don't see why even though you explain it about 10 times.
Do not know if it is postback, I am using ICallbackEventHandler. But I just tried it, still not working.
Look into the [System.IO.FileSystem.Watcher.Polling](https://github.com/dotnet/corefxlab/tree/master/src/System.IO.FileSystem.Watcher.Polling) library in [CoreFX Labs](https://github.com/dotnet/corefxlab), [downloadable from MyGet](https://dotnet.myget.org/feed/dotnet-corefxlab/package/nuget/System.IO.FileSystem.Watcher.Polling).
I recommend not running timer tasks on your web application. It will be very unreliable and could get unexpectedly shut down. Instead built a separate console app in the project. It will run on its own on the same server. The timer is in the main thread. On each tick it will reinstantiate all the objects needed for the next run. 
If I were to entirely decouple the LibraryMonitor from the Web API, it would still need to access the db somehow. I'm using an SQLite database, so having the dependency injector automatically handleo concurrent access to the db is useful to me. I'm guessing I'd have to do something like [this](https://andrewlock.net/using-dependency-injection-in-a-net-core-console-application/), and even then I'd end up with two different DI instances handing out dbContexts with no knowledge of each other, which sounds like it could cause concurrency issues. If my Singleton service is a true Singleton (as in, private constructor, instance as a private static member, and a static member to create/return the instance) rather than just added to the service list as a Singleton, then the instance should be able to persist across recycles of the web app, right?
IMO - converting an existing projects is rarely to be worth the effort unless you want to deploy on Linux servers, run in docker, or developer on a MacBook. There are dozens of small, infuriating ways the runtimes changed between the versions. Although some of the API is similar, it would be complete rewrite of your app. That said, I would definitely recommend ASP.NET Core for all *new* projects. MVC 5 is stable, but isn't likely to get some of the new features that ASP.NET Core has. Regardless of whether you switch to ASP.NET Core or stick with MVC 5, bower is a deprecated feature. They removed bower from ASP.NET Core templates recently in favor of using npm and webpack to build the JavaScript assets. 
C#, SQL, HTML and JavaScript. Optionally Powershell for automated deployment. 
Where can I find some good examples for asp.net MVC websites
u need to know the basic structure like there are 3 parts of a website the client side the html coding the code part which is the .cs class in asp.net and then the part which holds the informstion the database. i am a .net dev. Can you please tell me which version of visual studio are you using 
and CSS ;-)
You'll need c#, HTML, javascript, css, and razor. Also, English for countless hours of troubleshooting in Stack Overflow.
[Microsoft](https://docs.microsoft.com/en-us/aspnet/mvc/overview/getting-started/mvc-learning-sequence)
LINQ if you consider that a separate language
Is JavaScript used in front end?
Yes. You'll be using a lot of JQuery (a javascript library).
Bare minimum: C#, html and css. There is Javascript aswell, but I would say it's optional. One could do post-scenarios instead if one wants to limit the initial effort. What's the context of your question? Why do you ask?
I am starting with asp.net so
I count that as HTML... A website with pure HTML and no CSS is a very sad website :P
That's true, but originally CSS was part of JavaScript ;-)
What the fuck did you just say? http://motherfuckingwebsite.com/
:-D back to the roots... love it
We have: C# HTML JavaScript -&gt; TypeScript KendoScript / Kendo / Telerik (For Controls like Charts) CSS / CSS3, most likly Less / Sass SQL with EF6 and LINQ to make my life easier with hanlding the database-querys in my C# Code Knowing SSMS (SQL Server Managment Studio) to analyse the database and create tables (Database first) is a huge benefit We have a Poco Class designer to automate these things a bit
SQL?
yes telerik controls are very useful. i am also using them in my current project 
All right, good luck and welcome to the profitable world of webdev :).
while most database communication will be done in Linq, I agree that knowledge of SQL is required to understand what's really going on
You could do it with just HTML and C# if you hate yourself enough.
I'm working with .Net Core right now on a SPA and its great in terms of allowing a front end dev to work on their Mac in their node.js world since you can install the back end APIs on their machine without them having to rely on some server somewhere. I'm hoping I can pretty much just copy their file structure into the project and I will be able to run webpack etc in VS using all the node.js integration you now have.
Check out pluralsite.com
Yeah, pluralsight is amazing but unfortunately I can't afford $30 bucks per month. I have vs enterprise from university tho, and i've seen 6 month trial somewhere but I can't find it now
There are some free puralsight courses offered through msdn, but in the end, paying gives you far for to choose from. So you’re basically looking for something similar, but free? 
Are you doing a wpf desktop application? Or UWP? If you're using wpf/winforms: https://blogs.windows.com/buildingapps/2017/01/25/calling-windows-10-apis-desktop-application/#j7bgqaU4DRx34Tlb.97 If you're using APIs that came with the fall creator's update, you may need to add the winmd file from 10.16299.0 folder in Union metadata folder again. I just did this to access gatt central/gap roles the last couple weeks for awpf app we have.
Not really free, I can pay but that pluralsight subscription is too much. One time payment for a course would be great. 
Microsoft Virtual Academy or Pluralsight, you can get a few months free of Pluralsight access when you sign up via Visual Studio Dev Essentials: https://www.visualstudio.com/dev-essentials/
SQL, and Typescript is probably a better option if approaching JavaScript for the first time.
Yeah, you should try to build it in a way that does not need a persistent class. The example you provided is pretty good. There are a couple things you can do if you are concerned with concurrent db access. First would be to use transactions. Second would be to have an api on your web app that your console service hits per tick. That way the work is still being done on the site but the process is managed externally. Either way, each tick should be using new instances of all your services and contexts just as good practice. Everything gets lost during a web app recycle. I setup services as transient so they are created on each injection. Dbcontext are scoped by default so one single instance is shared between all services per web request. I use the same concept for console apps, where each tick refreshes the Dbcontext and services. 
Do all projects require linq
I wouldn't call it a requirement, but you'll be severely hamstringing yourself by avoiding it and it'll be replaced by requiring a direct knowledge of SQL.
Fantastic. Create plugins for your apps on the fly.
&gt; if you hate JavaScript enough. FTFY
Abandon the idea of using `ICallbackEventHandler`. It seems completely irrelevant to what you are trying to do. All you should be doing in your `Page_Load` event handler method is set the View State if `!IsPostBack`. (It would be interesting to know why you think you need to use `ICallbackEventHandler`.)
google "pluralsight site:my-university's-website.edu" without the quotes and replace the website's url with yours. Thats how I found mine.
I need the ICallbackEventHandler to call a c# function from the code behind. Without reloading the page. But I just thought about changing to SignalR.
Create a console app that monitors the CSV file for changes (FileSystemWatcher), parse the file on change and put the data (the diff?) in a database (sqlite?). Then your website simply gets the latest 100 from the SQL and outputs them. Cache if needed.
Viewstate will only persist when you do post-backs.
No, but its so awesome I don't see why you wouldn't want to use. The time invested into understanding linq pays off huge. As a side note if your are going to learn it, I'd recommend method syntax over query syntax.
maybe 10 years ago
I write my apps in F#/C#/Elm - I use SQL, HTML, CSS - maybe a bit JS for the glue ... to be honest: you an use whatever you like - don't like JS? No problem find a transpiler - don't like C#? No problem use whatever language you want there will be a MVCish framework ... for HTML/CSS ... well it's a website right?
dotnet watch needs this interpreter. 
Yes it's a website.
Forgot to mention. I cannot use a database. I thought about saving it to a variable. Is this a good idea? Not all the data, but the ones that are needed.
Sure. If you don't need to manage too many rows you can just use a normal list and save it to memory. I'd still have a separate console app to monitor the CSV file an be responsible for updating the list, tho.
(so you probably have to deal with HTML/CSS at least for now)
The pluralsight trial was inside visual studio enterprise itself, but seems to be gone now. 
And is it bad if it has too many rows? Because I do not exactly know how many rows but probably a lot more than 100. I do not have a separate console app. But an own class that is managing the FileSystemWatcher.
Yeah, I'd say having a good understanding of how that works, and what ORMs in general do, is probably a good thing. This was back when I used to use PHP, and Laravel, but I've known some guys who don't really understand the concepts of ORM or how they work. They just followed some basic guides for the Laravel Eloquent ORM. They really abused it. One example (there was several): their goal was to pull some user data and display a few fields from that data, for each user in the DB. Logically you would pull once, then send the fields up via a model collection, and iterate over the collection printing out fields. What they actually did was query and loop right in the view. It was something like: foreach (user in Users-&gt;GetWhatever()) print Users-&gt;GetWhatever()-&gt;FirstName(); // This did a query print Users-&gt;GetWhatever()-&gt;LastName(); // This did a query etc It made the site *really* slow.
Which course do you recommend? The one tried is frustrating. Shawn Wildermuth doesn't explain most things that need an explanation and he makes changes between lessons and doesn't talk about or even show them. I got to the 13th chapter and had to quit as I ran out of patience for his terrible course.
Well you have two options. One is to parse the file on web request, and that will most likely cause terrible execution time. Your other is to have a separate process that deals with parsing the file, and then having the web just spit out whatever the result of the last parsing was. That will be fast. As for what a "lot" of rows is, that depends on how much data you want to put in there and also how you process it. A few thousand lines shouldn't do much harm.
Thanks for that. Yes I was thinking of covering Identity. There are so many moving parts to authentication/authorization that it's difficult to know where to start. But sooner or later you're going to need somewhere to store your usernames/passwords etc. and Identity is a good starting point for that.
One strategy you can use is setup your watcher (or a job) to periodically parse your data into a .json file and store that on the file system (this acts as your "database"). Then in your web app (or directly in your server config) serve that json file up, for example: "/api/data.json". Then you write your web page to display data from only that file. You could use whatever you want to display it. If you need a starting point, jQuery DataTables displays data nicely and has AJAX built-in so all you would do is feed it the URL to that json file and you're set. I use this basic method at work all of the time to give users visibility into data that's only available via command-line. You can keep everything in one place and you get an "API" to your data in case you need to use it elsewhere. 
Well I just checked how much it approximatly will have. About 700.000 Lines of Data. (That is probably around the max lines) And I just got an OutOfMemoryException. (Ok, Exception only happended because I put the code in Page_Load) I do not understand what the second option is. How will the web request read the parsing of the file. Where will the separate process save it? It is just some work I have to do. I also only got a rough specification. The only thing I cannot use is a database. It has to read some data of a large CSV File. I have to be able to sort and filter the data. I want to find the most efficient way to implement this.
&gt; &gt; So, you have a file with 700k lines of data, and you need to be able to sort and filter that on demand quickly? Unless you can use a DB of some sort you are shit out of luck, me thinks.
Ok now I noticed, that that does not make any sense. I forgot to filter the data that I needed. So it is just about 1000. So this should work with only that?
Awesome stuff, wish this was in dotnet.. one of my biggest grips is the full rebuild. 
Well you have to do the 700-&gt;1k filtering at some point, so I still think you should consider doing that outside the web application.
&gt;In 2001 when the Mono project started, we wrote an interpreter for the .NET instruction set and we used this to bootstrap a self-hosted .NET development environment on Linux. Reading statements like this makes me realize how little I know about how things really work under the hood. I'll stick to developing apps :-)
I agree. Split this process up mentally in your head. Step 1: Write the code necessary to cut your data up, filter it, and then output that somewhere (database, or file). Step 2: serve that processed data via a webpage. Step 1 and 2 will be entirely separate things. You only have to worry about performance if you're combining Step 1+2 together. 
I've seen that recently in a .net/EF website. Performance was terrible.
I was thinking about parsing the data from the file when I start the application. Anything new will be detected by FileSystemWatcher and appended to the data. Everything will be saved in a variable. The webpage just requests the data that are already processed on startup and in the background.
What year is it?!
Anybody here ever use c# scripts (.csx)?
Yeah. You can run SQL Server 2017 in a docker container 
Hate to burst your bubble but VS for Mac has no support for Razor views (.cshtml) so using it for ASP.Net is pretty difficult. I’m currently using Rider because of this. Oh, VS Code doesn’t have Razor support either. 
jquery works fine for simple stuff.
if you're approaching it for the first time, you'll have an easier time learning js than setting up a build environment for ts to work. start simple.
Can you use SQLite? It's a database, but it can be embedded. 
You dont need to use Razor, you can just use something like Angular or React for your frontend instead.
Rider or Vs code. Steer clear of asp.net in vs mac.
I don't know of any .NET core tutorials in this area, but you can still use sprocs with EF.
Out of curiosity, how many here are still using traditional ASP.NET, WebControls that is ...?
Right, so how does that help with the issue with IDE support that he brings up with Razor?
It's a long read, but it should cover everything you mentioned. It's pretty in-depth and the full source is available on GitHub. https://blogs.msdn.microsoft.com/cesardelatorre/2017/05/10/free-ebookguide-on-net-microservices-architecture-for-containerized-net-applications/
Microsoft is giving away a book on Docker containers and microservices and has several code examples. I don't have the link on me but I'm sure it's easily accessible.
This might also be helpful: https://helpercode.com/2017/09/26/develop-and-test-a-dockerized-postgresql-backed-asp-net-core-microservice-in-less-than-an-hour/
jquery works fine for lot's of stuff - but if the problem is simple enough jquery is overkill and if it get's more complicated you'll usually look for something like React, Angular, ... things moved on and I would not recommend learning jQuery any more - rather pick one of the modern libs/frameworks or look for smaller packages for your need instead
[removed]
[removed]
If you are relatively new to .NET, I suggest stick to the basic until you get a handle more of the framework. Adding containers and service fabric, etc are just distractions.
I've been developing ASP.NET on a Mac for about 3 years (I was using Xamarin Studio and Mono prior to ASP.NET Core) and I've certainly hit pain points but the lack of Razor support wasn't at the top of the list. What is it that you're missing, code completion?
I'm sorry, but how jquery could be overkill and react/angular not?
I'm not a senior Dev, I'm a tester that works with both senior and junior Devs. And let me tell you, the title doesn't really matter when comparing the quality of work people produce. Technologies shift on a regular basis, and ten years of knowing Adobe Flex will not help you in writing quality code in Angular when your company decides to update its web app. Both the Junior and the Senior Devs will have to learn how to use the new technology. Go sit down with some of your senior devs, and with your manager and ask them the following questions. "What makes a senior dev a senior dev at this company? Of those qualifications, what am I missing to become a senior dev?" "What technologies will a senior dev need to know in order to be considered a senior dev?" "What soft skills do i need to work on to become a senior dev?" "What am i doing well? What should I be doing more of?" "Keeping the company's needs in mind, what would you recommend I work on in the following year to both improve professionally, and respond to the company's needs?" "As someone who works with me, can you give me some feedback on both my technical skillset and my soft skills on a regular basis?" Additionally, grab a bunch of senior dev job ads and look for commonalities across them. What are they all asking for? is it just years of experience? The type of experience (such as some team lead experience, or specific technologies)? At the end of the end of the day, what matters is that you have a skillset that other people value and are willing to pay good money for. 
I use autofac for years. I haven't tried the others.
Here's an video, posted yesterday, about the basics of DI in general, they used Autofac, so that might be okay to look into it. https://www.youtube.com/watch?v=QtDTfn8YxXg
I tried all of them, autofac by far the best, has huge number of extensions, fast and easy to use
I tend to use Unity in my projects, mainly because I find the initial setup to be very straight forward. There may be better options out there though as I've only used Unity and Ninject.
Autofac is nice, Castle Windsor is ok. .NET core also comes with its own limited built in DI if that is also an option for you.
If it's a .Net Core project, just use their built-in DI. Otherwise, I've grown to like AutoFac quite a bit, pretty simple to integrate.
Aside from university degrees (super time consuming would not reccomend) the MCSD are the only 'official' qualifications I'm aware of. However, as an employer I'm generally looking for evidence, ability and passion rather than bits of paper. My personal reccomdation would be to learn what you can, and then build some things that you can show to employers. Projects for your hobbys, or for charities/community projects (that are unlikely to say no to a free website) are a great idea, and give you evidence of your skills and experience to draw on. 
Thanks for replying. Apart from c# what would I need to learn to end up at that point? There is a lot more to it than just c# and I don't know what I need to know. From what I've read I'd need at least c# and HTML5. How does Javascript feature in this? And is it worth it to subscribe to Azure as part of the learning curve?
You might want to take a look at simpleinjector 
To build a full Web app from end to end? You'll need some basic html + css + javascript on the front (or razor + css + javascript if you're going MVC). Mid is just C#, and a database. The most commonly used is Microsoft SQL with .NET. The progression of the MCSD certificate is (if I recall): Html5 + CSS3 C# Web apps Azure It's alot to learn so I would personally start with just that before moving onto azure or aws. If you can afford it, I really recommend pluralsight, which have great developer tutorials. Otherwise Microsoft have free tutorials: https://docs.microsoft.com/en-us/aspnet/mvc/overview/getting-started/introduction/getting-started
You can sign up for MS's "Dev essentials" and get some free credits for Azure: https://www.visualstudio.com/dev-essentials/ However, I'd save the credits and not "start" them until you've had a chance to get more learning under your belt first. You'll get more out of them later on. You can also get a free code to 3 months at Pluralsight there, and they have plenty of courses. /u/Alyraelle is spot-on about certifications and how your best bet is to learn and put up sample projects for people to see and for you to talk about.
I find it’s not so much of understanding a language. The important thing I find is architecture. Pick a project idea and make it. Msdn has a lot of resources in order to get started. A piece of paper is unless if you can show your value. 
The pluralsight courses seem impressive. I see they have an ASP.NET MVC course, would that be the best one to do? Also liking the tutorial on the Microsoft website.
What kind of project idea would involve all of the tools of .net? A website that accesses a database and I assume some other stuff?
https://www.microsoft.com/net/download/thank-you/net35-sp1
A few project ideas off the top of my head: A CMS for news/blogs/or events An equipment/game score information or calculator for a video game you like (most of them have open APIs) A text based adventure game
I used to be a big fan of Castle Windsor, however it did not seem to be compatible with ASP Core (yet) So far we've been using Autofac, which is compatible with ASP Core and also compatible with Castle Dynamic Proxies (interception) which is nice.
Oh, that's a bummer. They must have removed it. however, pluralsight usually offers a trial anyways if you sign up directly with them. it might only be a month, though. There's a C# pathway on pluralsight that might be beneficial before you go to the mvc stuff itself.
WintellectNOW still is part of the benefits and they have [quite a few courses](https://www.wintellectnow.com/Home/Series) for .NET developers.
This is runtime, not SDK
What version of Windows?
You can use the .net core di and configuration in asp.net http://scottdorman.github.io/2016/03/17/integrating-asp.net-core-dependency-injection-in-mvc-4 Honestly this is what I did and what you should do. If you ever convert to .net core or .net standard this makes it less work. Why can't you use net core? I would make a netstandard 2 library to hold all your services and code. Then make the full framework web API dumb and just wrap the services in a web API controller. Doing this will make doing to asp.net core so much easier
This has just managed to remind me how much work is needed to get my current dev department up to speed. *sigh*
Hi u/Flibberdy! Thanks for your feedback. Appreciate it :) Would you like to share with me more about your development process more?
if you don't need much ("is simple enough") you should IMO look for smaller libs that do only what you need - if you have the need for a bigger solution frameworks like react and angular are just more powerful and better thought out
Hasn't it been out of support for years now?
3.5 will be supported until 2020 and die with the platforms it was designed for.
OP here, that’s some really good ideas. Thanks! 
 What? Almost all tooling automatically installs typescript, just install .net core 2.0 and do dotnet new angular, you have a full working environment ready to go.
OP here. I play World of Warcraft and I’d like to make something for that. I also am involved in a national NGO. How should I approach this now? Should I do the HTML5, CSS and c# courses on wintellect and go from there? Or try to just start with it and browse through tutorials as I need them? I think a challenge I would have is knowing how all of the technologies link with each other. I know HTML and CSS is for the website layout and look. And I have a rough idea of javascript’s role, but where does C# enter the picture? Is C# how I use the API for warcraft for example?
You will use C# on the backend/server. Fetching open WoW data, process and store it, retrieve and deliver it to the client/front-end. Your C# server will either create custom HTML (using Razor) in response to a page request or send data (as JSON) in response to a request from client javascript code. Maybe both.
It depends. You could build an ASP.NET MVC project and send a request to the Warcraft api and return the data to the client or store it in a database etc This tutorial goes through building a small api and a console based client but highlights what classes you should be using: https://docs.microsoft.com/en-us/aspnet/web-api/overview/advanced/calling-a-web-api-from-a-net-client Alternatively, you could send a request to an api using JavaScript and have the client handle the response, but that’s a different story.
Oh, thanks. Weird that it isn't on the list.
I think it's important to define what experience is and how it translates into 'senior' jobs. From what I've seen (and senior dev means different things to different people), senior devs have far more experience than a junior (duh). But in particular they hare : * Domain knowledge : They've been in a role (or multiple roles) for a long time. They know the problem domain well and can see issues coming. * Industry knowledge : They've seen technologies come and go. They can foresee whether a new technology actually solves a problem that may not be resolved before. * Technical knowledge : They know a single (or ideally multiple) languages well. Essentially technical knowledge juniors can acquire quickly (they how) but may not know what domain problem it solved or whether its truly a new industry technology. TLDR : You will gain knowledge organically through experience. However be careful to ensure you get a rounded knowledge base. You may feel like you've become a senior but in reality you just know the domain well and not have much industry for example.
Here's a few tips I think are great for junior .NET developers: - Get a good grasp on [LINQ](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/concepts/linq/getting-started-with-linq) right away. It's amazing. - Learn to write your code so it's testable. I think practicing with [TDD](https://en.wikipedia.org/wiki/Test-driven_development) works pretty well since it gives you a good idea of how to achieve testable code. - Have your code reviewed by more senior developers. Seriously, having someone who thoroughly reviews your code for mistakes and points out flaws or things you could improve is the single most important factor in order for you to learn. ^^^^also ^^^^please ^^^^place ^^^^opening ^^^^brackets ^^^^on ^^^^the ^^^^same ^^^^line
We use Ninject at work, it does the job.
Oh this looks amazing
I am more of a mid level and have been working in CS for 6 years after college with 0 programming ability coming out of school. (Math degree) Ive come to realize its less about what you know in terms of memorizing c# code and more about being able to recognize good and bad solutions and being able to find good solutions from whatever source you can. Also, good debugging skills are extremely valuable and being able to walk through problems with non-technical people (stay away from IT buzz words). In the end ive seen senior developers who were very smart but awful to work with and terrible at maintaining code. Ive seen others that dont have the vision to start new projects but are great at fixing problems and talking to and explaining things to others and showing leadership. If i had to pick one thing I think what junior level developers need to learn most is how to communicate effectively to other developers and non developers as seniors will need to teach others and help along the way and not everyone has your knowledge of CS, the product, or the industry.
Learn concepts not libraries.
 Thanks! it was really helpful. Unfortunately curretly there are no senior developers here. this enviroment is totally against inovation, in matter of fact before I get in this job nobody here knew of the existance of tools for versioning code like git or tfs. There is no one who I can count on doing these questions wich just amplifies these feeling that i'm getting behind or not envolving at all.
 Thanks that was great! yeah I need to get better on LINQ. I've being studing some patterns like DDD, I'm going to get my hands dirty on TDD right after. This was all very helpful, thanks again for your time.
Yeah, the lack of code formatting, intelisense, etc. 
A few weeks ago I was trying to reduce dependencies like this, thanks for great post.
Got started but bailed after: &gt; For the following statements, kindly select one answer for each statement. &gt; To what extent did the software development team actually incorporate requirement changes in each of the following categories? The answer matrix makes no sense to the question involved. Further it is a type of question that is extremely difficult for any one person of an org to answer unless they are already at such a high level of maturity that those reports are available right out of their ticket systems. People even able to respond to this question would very likely rate their networks and systems all as highly adaptable and scale-able as well; making the survey very self-selecting. This will likely skew your results and not give you a good idea of the state of Dev ops in the industry. It might be better to stick to the following categories for your questions: 1. Determine the survey takers personal idea about Dev ops and related concepts 2. Determine the takers thoughts on organizational culture with regards to dev ops (IE do you feel your org is heading in that direction strongly or not, etc) 3. Finally determine what the survey taker thinks of organizational readiness for dev ops and related. Try to avoid anything too specific like your feature list on software dev and stick to more general use of the concepts and practices. If you are interested in how people are actually doing/using these concepts today then you might want to re-work the survey around the use of tools and techniques rather than readiness.
He does have a doctorate in CSE though. 
Can I ask why MVC Core isn't an option?
Test induced damage.
Some advice for your senior situation: Companies define senior differently, so it will be up to your manager on what it takes to get there (and sometimes this is political as well). If your manager is unsure how to answer "how do I get to senior" then just start taking ownership of things. Act like a senior dev, and your manager should take notice (and if not, then find a company who will appreciate you). Another non-obvious piece of advice is that it could be possible that you don't deserve or really want to be promoted depending on how those titles are defined at your company. Promotions should be based on merit and responsibility, not "seniority." Some people get stuck at the level they're at, and are perfectly good/happy where they are. To get to the next level, you must perform next level and want those responsibilities. You need to make that happen. Some general advice: * Keep learning. If you feel you're approaching expert in a technology/language, learn a new one. Read tech blogs. Watch tech conference videos. Do side projects. Technologies change. Teams change. Job opportunities change. Be able to adapt. Learning is a skill you need to keep fresh. Don't get comfortable in one stack assuming you'll always use that. You won't. * Learning doesn't have to be scoped to technology either. It's always good to know your particular business domain and the trends in your industry as well. Domain experts are the ones keeping the ship on course during development and are a huge part of a project's success. * In the end, it's all about keeping your boss happy (fortunately or unfortunately). If you regularly show your competence and ownership of important things, they should acknowledge your contributions and/or promote you. If not, find out why or get out. * If possible, join meetups and network with other developers in the area. Being able to share ideas, learn of new technologies, bounce ideas off of someone else from an outsiders point of view was a huge eye opener for me. * The best developers I know write concise code. I can read their code and understand exactly what they're trying to accomplish and they usually do it in less lines of code than most. In C#, this is where groking Linq, lambdas, and other language features are really helpful. If you really understand these features, it will lead to less code, which leads to less bugs. * Every company has issues (architectural, procedural, tech debt, personalities) to deal with. Working for a company that realizes that Agile is not a process but a state-of-mind is a huge advantage and will allow you to grow as a developer/team. Being open/honest in retrospectives and adopting meaningful change should be embraced. 
Uow! This gives me a lot to think about! I have one more question, you spoked about writing less code, I'm really paranoid with the quality of my code, and I try to refactor aways but i've noticed that my code speed is dramatically damaged because of my perfectionism. Ia there any trick to find a good balance between code speed and code quality?
This is a pretty common question, you could learn quite a bit with a quick Google search and save yourself some time. If you've already done some work on your own and are still stuck, then post exactly what's giving you trouble.
Or... someone could point him in the right direction. If he’s asking here then he probably wants some advice as well. 
I think pretty much everyone runs into this. Don't worry, you're not alone. The best advice I can give is: 1. Code it to work. 3. Refactor as necessary. As necessary can mean different things: * During a code review, you identify a good reason to refactor (someone else could reuse code, etc.) * Anticipating where change is highly likely/guaranteed (a handy skill) * To be able to unit test properly If you do unit testing, it usually forces you to write better in the first place, which will lead to less refactoring later on. You also shouldn't be refactoring without unit tests, to make sure you're not introducing regressions. There's no such thing as coming up with the perfect design. Your job involves finding the balance of producing product value and creating maintainable code. You will have to make trade-offs. You will look at some code again in a year and say "Why did I do that?" It's just part of the repertoire, it never changes, even for senior devs (although hopefully it should happen less). A good manager will allow time to address tech debt over time, which I recommend you keep track of when you find things you'd like to refactor but don't provide immediate value. I could tell you so many stories of preemptive refactoring of code that never gets reused. To reuse code, it needs to be in an obvious place and easily discoverable. We usually discuss as a team or during code reviews on what makes sense to change, and it has to have some immediate/short term impact. Just keep in mind the impact to timelines and the value to the product when making these decisions. 
there are a few techniques, one of which would be to create a session token that's stored in a cookie. Once a user is authenticated, a cookie (that is NOT the username and password, but a random hash) is sent to the user. Cookies are sent with every HTTP request for a particular domain (as defined by the server) When the user makes a request, the cookie (holding the string value) will be sent to the server. The server will then look in its database of "session" and see if the cookie is valid AND if the session has not expired. Then the user is "Authenticated" and often a profile is generated for the user with their roles and permissions (to be left up to the developer). This user's profile (it could just be a bunch of DB checks) is pushed through an "authorization" pipeline (did .net core get rid of pipelines?) and if the user is authorized to use the service it will continue to the controller. If through any of these steps the user is not authenticated, the server will send back a 401: Unauthorized or can redirect the user to a login page. If the user is not authorized to use a particular service, then the server will just say 401 (no redirect, because it means the user is already authenticed) there are different implementations of this scheme. 1. you can use a database and default identity https://docs.microsoft.com/en-us/aspnet/core/security/authentication/identity?tabs=visual-studio%2Caspnetcore2x 2. use windows authentication (dont do this for extranet sites) 3. basic authentication (dont do this ether unless using SSL) 4. oauth 5. federated services 6. ldap and so on. Oauth, Ldap and AD are just for the authentication step for your application, and it is up to you to configure the authorization for the user. 
Sounds like it time to move to an environment that supports innovation.
This was so helpful and great that I can't thank you enough! I'll certainly apply this next time I would have to deal with those decisions 
Wow! Thanks for doing this!
This is a broad question, I assume you are interested in the overall architecture of the application as well as authenticating the user. I suggest you first read up on n-tier architecture. "Microservices" is the hot buzzword right now but from a practical standpoint almost all properly architected apps regress to some implementation of n-tier. Now, to answer you question "how do you connect your frontend with your backend": I wrote a very small client called AdaptiveClient that wraps your service layer. You inject an instance of AdaptiveClient into your controller and from there you can access any of your services: public partial class MyController : Controller { private IAdaptiveClient&lt;IUsersService&gt; client; public MyController(IAdaptiveClient&lt;IUsersService&gt; client) { this.client = client; } public async Task&lt;IActionResult&gt; Login(int userID) { // AdaptiveClient will use the best server available at the time the request is made. // Server may be SQL, WCF, REST, etc. - your application does not need to know or care. // If the request fails AdaptiveClient will begin an orderly fall back to other // servers that can handle the request regardless of platform or protocol: User user = await client.CallAsync(x =&gt; x.GetUser(userID)); } } You can access your services in-process (load an instance of a .dll) or you can make REST or WCF calls - from the perspective of your application it makes no difference because AdaptiveClient abstracts that busy work away. The key to being successful with AdaptiveClient is to structure your app correctly using n-tier. But you should be doing that anyway. Source with plenty of examples: https://github.com/leaderanalytics/AdaptiveClient nuget: https://www.nuget.org/packages/AdaptiveClient/ 
Fair enough, I find that pretty minor. I suppose if you're used to it then you miss it. You should be able to format the files though? FWIW I've started using VS Code a bit more, I find it easier if I'm doing a lot of Razor page stuff.
That was a pretty useful video. I'll probably be giving Autofac a try. Thanks.
I'm using a library that doesn't seem to work with Core. (I guess there might be a way to get it to work, but I haven't really looked into it beyond trying once &amp; failing.)
I love SimpleInjector. Truly lives up to its name.
Sounds like good advice, I'll disregard for now, how easy it to switch a project to using service fabric later on?
Thanks I think this is the[link](https://blogs.msdn.microsoft.com/cesardelatorre/2017/05/10/free-ebookguide-on-net-microservices-architecture-for-containerized-net-applications/) 
Use the bundle.config file to setup bundles. They will be combined and minified. 
That's the thing though: the people asked this question so many times already and have been directed that having yet another half-assed post produces noise, not answers.
Cool. Would be very useful to those who use pure C# for game development. But how does this stack up against SharpDX?
ASP.NET Core has out-of-the-box support for JWT authentication which is the way to go with modern SPAs (in my opinion). To simplify, when user logs in, post request with username/password is sent to an API endpoint that returns a token. Token is then stored in either a local storage or cookies and is then used for every subsequent API request. You can then decorate controllers with familiar decorators such as Authorize and filter by roles...
It doesn't replicate or try to replicate SharpDX. It just provides helpers to automate SharpDX boilerplate so you can get right down to your application logic. https://www.prasannavl.com/2016/10/introducing-winapi-graphics-with-direct3d-d2d1-gdi-opengl-and-skia
Try it again. NET Core 2 is much better at integration.
Hi u/Manitcor, thanks for your feedback. Appreciate it! I will include your feedback as part of my discussion and it will also be part of my consideration when a new set of survey questions is built. Thanks :)
Any idea how to run a custom function? E.g. private static int AddNumbers (int x, int y) { int z = x + y; return y; } Then in templating do something like: {{ Addnumbers 4 6 }}
https://visualstudiogallery.msdn.microsoft.com/9ec27da7-e24b-4d56-8064-fd7e88ac1c40;
If you're using Dependency Injection (DI) then you could easily invert control (IoC) of the executing controller and method to a constructor injected member of an interface and eliminate the cross cutting concern upon the save... not sure I'm getting the question fully though. hth.
Your entity should have the id set once it gets inserted by EF, is that not happening? Are you passing your mid layer an object or just individual fields?
It gets id, but to the mid layer Im passing a command with some values from front-end part, then midlayers create new object depending on the command and saves it. I got the ID but top layer has no idea about that and this makes me wonder, how. How can I pass it up there ._ .
Isn't this covered in the post? See http://xoofx.com/blog/2017/11/13/implementing-a-text-templating-language-and-engine-for-dotnet/#custom-functions
Should the mid layer return the new object to the front end?
No, only location of the created thing in the header response. That means I need the id to be at the top somehow o_ o 
Information can change, techniques can change. Why not at least give a link or some high level info. Replies that basically say go google hat are not conducive to a helpful subreddit. 
This is currently just on the first iteration so if you have suggestions please let me know. I am planning on adding in more features soon for better support for parameters and error handling. 
With a piece of middle end. 
Dear God that sounds like a "could v. should" argument that went horribly wrong.
I just feel like this would trigger me. I write such shit code the first round, I can't have people seeing that lmao!
This looks pretty cool. Sadly I'm a solo Dev so I won't have a solid reason to try it any time soon
Suggestion 1 through 1000000: Documentation. Examples. The NuGet gallery entry says almost nothing about what it actually does. "Enhancements"? Enhancements on what? How do I actually use it in the first place? I followed the link to your github site and see a vague readme.md about attributes and controllers. I could dig through your code to figure out what things do and how to use them, but at a glance, there's nothing on either your nuget package or your github that would convince me that using your package would be faster than me handling my own CLI arguments. Documentation and Examples of how this library makes out lives easier would go incredibly far in getting people to use it.
The documentation it lacking absolutely. And I plan on fixing that. At the end of that readme there is a link to template that uses the package. It is setup to be an example of use. 
Man, I have to imagine this raises lots of security concerns. I wonder what sort of security mechanisms are in place to keep this from getting hacked. Could you imagine, you're coding and all the sudden you are seeing someone else in your code and you have no idea who the hell they are? I'm sure that MS has gone to great lengths to make this secure, but still...
Looks very interesting. Could reduce a lot of the overhead we currently have with UI automation tests and deployment.
Innovation is about what you do with the language, not which language it is. Language is trend, ideas are innovation. And you can get the same done in both.
I completely agree, it's difficult trying to stand my ground on this as I'm a junior and haven't got as much real world experience!
I don't really see how that would happen since it has to be initiated by the host and others have to be invited via sharing the link. Unless you're just for some reason leaving a sharing session open indefinitely and the link gets out to others, there doesn't seem to be much risk.
When it gets into things like this, with anyone, you're usually not going to change opinions. If he's your supervisor, make your case or your point once and let it lie.
Yeah he's potentially the new supervisor, thank you for the response 
If your concern is employability, as always, go look at what jobs are available locally to you and make a decision about how many are available that look like things you'd be interested in. As for the innovation line, I'm gonna call bullshit. There's a lot of churn and noise, yes, and they ARE improving tools and JS in general as they go, but I don't see anything that Node gives you over other platforms at all except for a preference for the ecosystem. I mean, I'd probably push Node.js over PHP, Perl, Ruby and MAYBE Python at this point, but for corp work or business line stuff, I don't think there's much of a chance of it supplanting Java, .NET, C++ and the old standards. Frankly, VisualStudio alone is enough of an argument for me to not want to move over. Be wary of the "we must always change" people, and of the "we must never change people". As in most things, the best answers usually lie somewhere on the middle road. I have my own preferences and such that lie completely in the .NET camp, so of course, take my own views with a grain of salt.
Few years ago i wanted to build something like this to help me mentor people that are learning to code. I'm so happy this exists!
Thanks for this, great advice!
I recommend saving yourself some time and energy and trying Octopus Deploy, it's magical. :) 
Searching https://www.nuget.org/ for 'html to pdf' yields several possibilities including PdfSharp, ExpertPdfHtmlToPdf, and HtmlToPdf (and a couple of thousand others).
Could you imagine what sort of security concerns a door has? Could you imagine, you're sleeping and all of a sudden someone is in your house and you have no idea who the hell they are? What's a lock?
If you're doing webdev, go node. Doing things in the Js ecosystem is much more a recipe (which complicates things dependencys and such .. good luck..) but if you want to use shiney new fast things **there**.. nearly everything plays nicer with node.. PS I really like dotnet core. 
I have never had any interest in node, but I don't think its going away soon and .Net is definitely not going away soon. The thing that could really hurt you in future job hunts is to become infected by by this person's way of thinking ;) 
Yeah I'll definitely not let them influence me! 
I've been using DevExpress XPO for 11 years now, and this October it supported .NET Standard 2.0. Even though this is a commercial product, its first .NET beta with .NET Core support (v17.2.2) is going to be free for everyone. Further updates are paid, but they include the visual designer and technical support. While this ORM is different from EF and is older (unless I am mistaken, its first version was released for .NET 1.1), it basically has everything we needed for apps of very different scale. Check https://github.com/DevExpress/XpoNetCoreDemos for demos and tutorials.
Go ahead, shit all over me just being curious about what they did security wise. I hope you enjoy being a sarcastic fucking asshole.
If you behave this way when someone disagrees with you on the internet, I'd hate to be around you when anything actually bad happens.
There are going to be some pissed off people who think these changes make the code less readable or just hate changes to a language. However, while I think that there's no perfect way for them to fix it at this point, this approach will still allow us to reduce the cognitive load of finding and tracking all the ways our data can suddenly be null.
What problem is this feature trying to solve? Remote pair programming? Google Wave died because not even non-programming folks liked to work on a document while someone else was working on it. That said, I was helping my brother in another state with his resume, and being able to edit live together was a big help. I still think this is very situational.
I want this is javascript or typescript!
Thanks to being able to override a non nullable reference type and set it to null with = null! implies to me that I still need to null check things and so the whole thing is pointless 
Hey there PM on Live Share here. We are considering how sessions should be closed including inactivity and timeouts. Thoughts?
Being able to rm -rf / means the whole thing is pointless and we shouldn't even bother with computers. The point being, if you write garbage like that, then it's on you.
Fair, fair
Just tell him change for the sake of change is a good way to shoot yourself in the foot. I'm a senior .NET programmer who has recently released 2 production apps in nodeJS with Express. It works, but so does .NET. In our case, .NET has better server side performance (request/sec) than nodeJS. One of our Node JS apps runs on Azure Web Apps in IIS, and one runs in a docker container on linux. Neither is capable of more than ~100 requests/sec on minimal hardware. That same hardware will gladly serve up ~500 requests/sec on .NET. Anecdotal evidence is not real evidence either, but in our case, it's compelling enough.
Ask him this: When it comes to enterprise level support and sustainability, who wins? Node JS with its fractured upper leadership and a platform built on open source community trust and contributions alone or Microsoft?
Sweet, they listened toy year old suggestion (or I simply want to believe they did).
A few things for me; IMO this would be a good way to code review another devs work, better than checking in and having me pull it down. Screensharing without the ability to control the host is really painfull. "can you inspect varx? No varx!" "Add a breakpoint here" "what's the current value of x?" "What happens if you change a to b?". Those are some pretty common things which come up when screensharing and collaborating on code or helping someone with a problem and not having direct control is a waste of time and frustrating. Similar to above, I like the fact the other guy won't have to checking their work for me to help him out. 
Typescript got strictNullChecks as a very similar solution to the same problem.
While there is a lot of innovation in node there is still a lot of existing infrastructure built on older tech, and that tech also needs smart people. There will be .Net jobs for a long time to come. There are still coldfusion jobs out there ffs.
Well, this is meant for situations where they would already look at your code anyways.
Oh god if this starts getting used in interviews...
I wonder if this uses SignalR at all ... ?
First things first is to ask if the build in Service Collection DI suits your needs. All of those other containers will no doubt be more full featured, but it may be features you don't need at the expense of added dependencies and bloat. If you do decide to go with one of the libraries in your list, you'll find very little to distinguish them in terms of core features. (Ninject and Unity have been lower performance containers)[https://github.com/danielpalme/IocPerformance]. Having used Ninject, Autofac, and StructureMap, I recall liking the latter two a bit better. All that being said, (LightInject)[http://www.lightinject.net] is my personal favorite. It's as fast as they come, yet still supports some pretty impressive features, supports both .NET Framework and .NET Core, and the option to install the package as source makes it slightly more flexible.
Assuming the job market in South African is similar to the US (which I have no idea if it is), I'd look to building demonstrable web applications or contributing to some open source projects as a way to prove that you're able to do the job and show the quality of your work. Certifications aren't a bad idea, but in 14 or so years in the industry I've met one person I know of that actually had one.
I'm sure you can come up with better ideas than me, I'm certainly no expert. Two ideas thought of are: 1. Might be good to have separate time out for allowing people to join and for the actual session. So maybe, unless you 'renew' the link, people can only join via it for first 10 mins or 10 mins after first person joins or something (just picking random time). That way people can't join indefinitely if link gets out but session could stay active. 2. Maybe add a way that the host has to accept anybody trying to join via the link rather than just letting anybody join who has it. This way even if a session link got out there it wouldn't be the end of the world. I'd think this or even something more would be required for any company to allow it's use. 3. I think it needs to very obvious to the host that a session is still live. I haven't tried it personally, only going off the video, but there doesn't seem to be anything screaming on screen that you've got somebody else connected and watching you with access to everything. I see in the status bar the bottom it shows your name and a 1 beside a people icon but it's very non-obtrusive. Non-obtrusive normally is nice but I think I'd prefer it to be very obvious when hosting something like this. Definitely a neat project though. Could see something like it being very useful in my work often helping people working in remote locations in field.
I'd tell junior developer hejj to spend more time digging into open source projects of interest to develop better practices and learn higher level concepts. 
Well, it's better than Google Docs. xD
Great. Now I just need to get the devs to use Typescript... 90% of our run-time errors are js null exceptions.
I think .NET's future is looking pretty good right now. Microsoft has put a ton of effort behind it in the past couple years.
Telerik has one https://www.telerik.com/products/wpf/calendar.aspx There are most likely several other controls from other vendors. The controls market is fairly saturated. I would do an exhaustive search before implementing your own.
.net (core) perf vs node perf isn't anecdotal. it's just the way it is. not hating on node, it works fine. but the new asp net core stuff is faster. same can be said for stuff like vert.x on java.
i agree, people who only want the new hotness are going to spend a lot of their time chasing their tail. and people who don't realize that new ways can offer benefits are doomed to be left behind.
is it only about node vs .net or is it about the Windows ecosystem vs the *nix ecosystems? there has never been a better time to be a .net dev if you can use .net core. Linux, mac, windows, containers, you name it, it all works great. if it is about the ecosystem, that issue has largely been addressed. vscode works pretty good for c# on every os, vs is great on windows of course, and vs for mac is ok. with the windows subsystem for linux stuff, we all use the same tooling and scripting no matter your os. pretty good.
i chose .net core because it is xplat. we have devs on different systems, so without xplat .net would have been a no go. came for the async/await, stayed for the xplat.
Right there with ya! I'd like to have a reason to use it but no reason too 
[removed]
I can't wait for all of the "I clicked next next finish on WordPress install! I'm a web developer!" types to start asking .NET questions. /s
Running shell commands for simple tasks is a very Linux / PHP way to handle things. In .NET, try to avoid unmanaged code at all costs, especially when you're learning. Check out https://msdn.microsoft.com/en-us/library/system.net.http.httpclient(v=vs.118).aspx . Chances are it'll do whatever you wanted to do with wget but with advantages like async.
Vscode + WSL improved my workflow so much. It really is a different platform
If the business layer needs to pass the generated ID to the view or response layer, then it should simply return it. I would guess you are calling the business layer from the view layer, so why not return the ID?
I’m actually pumped about this. Learning the mathematics of ML is no easy task, and for me it’s helpful to code things in C# for learning. For example, in the beginners tensorflow MNIST tutorial they gloss over softmax pretty quick. Softmax didn’t really click for me until I wrote it in C# and played around with it. For more advanced learnings it will be useful to have Tensors as a native type. 
I'll still choose screen share and a phone call over this any day. It looks pretty slick but I can't come up with one good reason why I would use it.
I'm so happy Mads convinced them to fix the billion dollar mistake instead of creating the new mistake of `string!`
For the front-end he's not wrong. Compare Razor to Angular, React, Vue, Aurelia etc. Nodes got an enormous ecosytem as well. 
Thing is, can't we create an API using .Net that hooks straight in to any front end framework as a JSON feed? Another argument was that using Node would mean being able to render React server side which is better for SEO, but I've read that Google insists that well-constructed, semantic JavaScript front ends won't be a problem for crawlers anymore. Either way I do agree that Node has a great ecosystem 
Yeah, .net core back-end and Angular(typescript) front-end (SPA) would be my preference. Yeah goggle should be able to crawl some javascript. They will have this documented somewhere. Tell him SEO is dead, social is where it's at! :) If you're a med/large B2B you probably don't get business from your website but through your sales channel.
Thanks for the reply! :)
Escape values are necessary. Just try to not use them too much.
Escape value as in how to deal with `return null`? 
You can use the TypeScript transpiler to check your existing JavaScript without changing any of your code.
He'll likely reply "VB6"
Please show what your deployed web.config looks like?
Where is that file? It does not exists in my local directory. Is it generated on AWS when I publish a project? But then, I do not know how to download files from AWS.
I saw this yesterday in a post showing off VS new Live Share. How does that work? Does it just guess what types things are?
It should work. We've also deployed our application ASP.NET Core 2 to AWS (Elastic Beanstalk) You can go to the AWS console website: https://console.aws.amazon.com/elasticbeanstalk/ and check if everything is ok. If that's not ok, you probably have some configuration problems.
Well. I can tell you it is possible :) But dont know why you are using a Windows Server 2016 to deploy a dotnet core project :) My team are using AWS for all our deployments and have been using dotnet core for the last year. That said we are using CD / CI with Teamcity and Octopus deploy. Our new Dotnet core microservices are deployed as Docker Images on linux machines and currently working on moving it all to kubernetes for scalability. But Dotnet core can run on ISS, but haven't tried it. So happy to be gone with that beast ! :D
As u/phuber said, there's tons of options for controls out there. Many of them are free. However, as far as paid ones go, I would strongly recommend Dev Express' scheduler. Their Winforms scheduler is awesome and they're set to release a revamp of their WPF scheduler, which looks extremely promising. I hate to come off as biased, but if you can't afford to make your own custom controls, then Dev Express is worth EVERY penny. In the end though, you should probably evaluate Dev Express, Telerik or Infragistics stuff before you buy. Each one has its own api conventions, strengths and weaknesses.
The Health is Green, and I have not done any weird things. I just used all defaults. If it works for you, this is weird...
Typescript has had this for a while now, and it's something I never knew I needed in my life. Can't live without it now. Every time I go back to C# now I find myself annoyed that everything can be null! Sooooo happy it's coming to C# too! Yayyyy!
I know that ASP.NET Core can run on Windows, but the Amazon extension does not seem to think so. In its Publish dialogue, the Container type lists only Windows Server types. Since this is a free period, I did not try to investigate how to deploy on Linux, but since Windows is more expensive, I will look into Docker or other Linux methods...
This is like punching yourself in the face and then telling yourself to stop punching yourself in the face. You're being your own bully.
There is often (almost always I'd say) more than one person working on code and we all know that there are people out there that do silly things and are surprised when the library or other bit of code they use suddenly doesn't work. Yes you can go back to them and tell them it's their fault, it's still a pain in the ass to deal with 
I have one running with nginx proxy. No issues. 
Change log enabled to true and restart the app. Fire the app to generate logs and go to log location. Might have an answer for you.
I often work on code that we inherit from other companies. I fix things when I can, but sometimes a nasty hack is the only thing that gets it working in the time available.
I usually like the changes to C# but this is probably the worst proposal ever. - It adds new syntax - It adds complexity to the compiler - **And it doesn't solve anything at all!**. It relies on a lot of arbitrary and unreliable control flow analysis rules and works no better than just some attributes and few VS plugins (resharper?) What happened to Lipperts "-100 points" rule for new features?
Isn't that what code reviews are for? I don't want my junior guys to be junior forever. Any language will give you enough rope to hang yourself with if you try.
You can edit the security group of the instance to allow RDP (In the ec2 options) Then you can RDP to the instance that your application is deployed to, and browse it through localhost, which might give you more details for why it's not working
I appreciate the guide (even though it doesn't affect me), but realistically this bit is worrying: &gt; We don’t currently have bandwidth to update it anytime soon The "easy" fix is to update to a version of TFS that can build these projects out of the box, saying "but we don't have time" suggests to me that priorities are all wrong. I get it, not every company is big enough to warrant someone owning something like TFS - it's usually one of the devs who gets to look after it and they're busy, but time really does need to be allocated to keeping these systems up to date.
 Looking at my code base, it will catch every null reference exception I've seen recently. Is it perfect? No, but neither is the type system. But I'm not going to drop types in favor of JavaScript either.
Awful website. Websites that are hijacking scrolling behavior are just horrible. Think about the UX!
It does real time analysis of the code, and tries to infer what types are assigned to each variable.
Which website do you refer to?
The one you linked...
Ah, ok. It is a presentation realized by [Office Sway](https://sway.com/). You can change this behavior by click on top right *Settings* -&gt; *Layout*.
Which requires me to do it every time, or allow the website to store data on my local system. I'd rather opt for the option to simply avoid websites that perform these shitty practices.
We actually spun off a dedicated platform team to do this and keep other platforms up. I 100% agree, you have to prioritize. We have enough backlog work for 2 years of platform work alone. In the end, the developers are our customers and they are more productive because we handle the platforms. For a large Enterprise I would also look to vsts. They have vsts certified for HIPPA and other government certifications which should eliminate any compliance issues.
This is a different topic but, I thought the EC2 feature is some kind of managed hosting, like Azure's web application; you just use the exposed service, not caring about the underlying OS. But if I can connect to my t2.micro server using RDP, is it just a Windows virtual machine? In that case, who takes care of installing OS updates and those inevitable server reboots? The reason I am testing AWS was that I have to install updates and restart my cheaper VPS on my own, which makes my web site down for a while.
So many times I've moved my classes to structs for this very reason. This will be a wonderful addition that avoids passing around large value types that really are just nonnullable references. 
Beanstalk is just like a control panel for automated creation of EC2/RDS/ELB/etc as far as I'm aware. Behind the scenes all its doing is spinning all those instances up on your account and just obscuring them in the beanstalk interface. You can still connect directly to them.
I don't understand "private protected ..." Isn't that instead saying "internal protected ..."? If it's only available to the same assembly that's what the internal modifier is for. 
No, EC2 is just a Windows Virtual machine, and you're responsible for OS updates, patches, and creating a highly available architecture with autoscaling, load balancing etc. Like u/Apk07 mentioned, Elastic Beanstalk would give you a more "managed" App experience where you just upload your code and let Amazon handle all that stuff for you
Azure, Azure, Azure...
What code reviews?
Indeed, we're looking to migrate our on-prem to VSTS sooner rather than later. In the long run it'll save us time and money.
How about just checking if its null? Or throw exceptions where parameter values are expected, and using good logging tools?
Great!, we are just getting started here. Is there any way I can connect with you to understand how we can make C# better for your scenario :), I can be reached at aasthan@microsoft.com
It means "Internal and protected" since `protected internal` means "Internal or protected".
Well technically you're in charge of keeping your Elastic Beanstalk EC2 instances up to date, but not really: You're hardly even supposed to RDP to those instances, let alone install any software (like a .net framework) directly. The point is that you script everything so that Elastic Beanstalk can set up a whole environment for you which runs on a fully up to date windows image. Ideally you'd boot up a few instances and put them in a load balancer. When you have a new version of your software, you don't update the old instances, you just bootup new instances with the latest, up to date windows image, and then you hang those in the load balancer and kill the old instances. Ideally you'd script your build server to do all those things for you So as long as Amazon maintains their images and keeps everything up-to-date, you'll be fine. If you don't update your versions regular enough to stay up to date with windows, then in the Elastic Beanstalk site there's also some button to recreate with the existing software.
This might be the most important thing. Learn the theory! Patterns, concepts, designs
how so? what were you using before?
Email sent! Sorry, I forgot to include the email subject line.
Visual Studio + a Virtual Box VM for linux related tasks (our frontends run windows and everything else is linux). We are slowly migrating to a full linux stack.
.NET Core is just going to keep getting bigger and bigger
I can't answer either of your questions ('Why is anything to do with oracle do damn frustrating?' and 'Anyone come across this?') but https://docs.microsoft.com/en-us/dotnet/framework/data/adonet/oracle-data-type-mappings suggests that for any `INTEGER` value Oracle internally returns an `OracleNumber` which .NET converts to `decimal`. In the past, in similar contexts where I couldn't be certain of the data type returned, I would get the value as an `object` and use `Convert.ToInt32` to convert the value (whatever type it actually was) to the type I needed.
Well, since I got downvoted I'm obviously doing something wrong. The thing is, I mostly maintain 2-3 years old mvc applications, and all are pretty heavy on jQuery. I often have to dish out new modules for those applications and I almost exclusively use jquery for ajax driven dynamic pages. What would you recommend as an alternative if I were to start a new project today?
Those mappings are if you use the obsolete System.Data.OracleClient library from Microsoft. Oracle has its own Oracle.Managed.DataAccess library on NuGet that maps the INTEGER(38) to OracleDbType.Int32 --&gt; https://docs.oracle.com/database/121/ODPNT/OracleDbTypeEnumerationType.htm#ODPNT2286 The OracleDataReader class has a .GetInt32 method that then returns the C# int type --&gt; https://docs.oracle.com/database/121/ODPNT/OracleDataReaderClass.htm#i1005172
Use this library: https://www.nuget.org/packages/Oracle.ManagedDataAccess/12.1.24160719 Use the OracleDataReader.GetInt32() method to return the count as a C# int type.
I don't think the downvotes are "personal" - people just disagree about using Jquery I guess. Now what I recommend is highly subjective - we are switching more and more to Elm (with Bootstrap - but that's not the point I think) because I have a strong FP background, enjoy the language, it's easy to teach people and it's just sufficient for our use cases (if you need much interop with other JS stuff it might not be the number one) As you are using jQuery it might be worth a look - don't know. If you want something more mainstream you should probably take a look at Angular - from what I hear many C#/ASP.NET MVC people are really happy with it - especially when using typescript. If this is to heavy for you than probably React but this probably comes with a overall high learning curve as you have to pick and choose more parts then that to make it work (it's only the "view" part - I think many combine it with redux, etc. - on top you probably need webpack, babel, ... the modern web-stack insanity ;) ... I don't know much about it - another reason why I like elm so much - I don't have to care much about this stuff)
Hi No i have a console desktop application. i finally managed to acess the namespace and read ibeacons. Now i have the problem with the time intervals that windows scans for Bluetooth beacons, its only every few seconds but i need it under 1 second. I remember reading comment from some emil in stack overflow about how to do this so i will try to find it. thanks for the link you sent btw ! I will update the winmd file. 
Thank you. That is the library im using, and as other comments say, you can use Convert.ToInt32 to convert the decimal result to an int.
Thank you - this has worked for me :)
great - thank you that works.
Hvad dælen. Er du også herinde :) Gratis upvote herfra :) 
I'm everywhere ;) Thanks J.
Also the image moving and changing size :(
Had the same issue, problem was that the server didnt have .net core 2 installed. Run command dotnet --version and check.
Mixing is easier for a demo. It will probably depend on what your client app is doing. We use AngularJS to provide better usability in admin pages, so its just part of our scripts, not a standalone client app.
If by AngularJS you mean Angular2/4, not actually AngularJS, in .net core for demo's simply do `dotnet new angular`. If for production app, or Angular 1, I would always go with creating a separate project for it.
Sorry, I'm confused. I thought Angular and AngularJs are the same thing, no? And the latest version is 5? What is the Angular 1, 2/4 you are referring to? I'm trying to learn it with ASP.NET MVC 5 (not core)
https://angular.io/guide/ajs-quick-reference `Angular is the name for the Angular of today and tomorrow. AngularJS is the name for all v1.x versions of Angular.` AngularJS refers to Angular v1 (I'm assuming because they went fully TypeScript and wanted to remove the JS part of it), it's just Angular for anything above that. And yes, latest version is 5, but it's only been out for like a week and a half, not many toolings support it yet.
Ah, ok. That makes sense now. Thank you. So then I'd be using Angular 4 with MVC 5
The framework was called "AngularJS" for version 1 (and 1.x, which is acrually still maintained), but was renamed to "Angular" as of version 2. It now follows semver, so there's no such thing as "Angular 2", "Angular 4", "Angular 5", etc. These are just newer versions of Angular.
Article missed a great opportunity. **Guard** could have been **Relegate**.
Here is the link to the pdf: https://aka.ms/microservicesebook. It has been updated for .NET Core 2.0!
Pretty nice, thanks!
I agree we really need to keep TFS up-to-date but TFS 2017 requires SQL Server 2016 or higher. So we would also need to update SQL Server thus making it not the "easy fix". If we planned on keeping TFS long term we would do it but we will probably go to VSTS instead. 
Appears to be built using same framework as Visual Studio Code, hopefully the release cycles are just as frequent. Download - https://docs.microsoft.com/en-us/sql/sql-operations-studio/download Announcement - https://blogs.technet.microsoft.com/dataplatforminsider/2017/11/15/announcing-sql-operations-studio-for-preview/ 
I am working on an angular app inside of MVC for work. We are set up that way due to the requirements of the project. I think it would be easier to make them separate. There are some extra steps to get angular working inside of .net.
I unfortunately agree. JS development has diverged so much, and moves so fast now, that we stopped trying to keep our client side apps in VS. We separate them out into another directory and use npm / gulp build tasks to copy the resulting built files into the MVC / WebAPI directory structure. Most of us just use VS Code or Notepad++ to edit those projects now outside of VS.
Looks a lot like `Microsoft.Extensions.CommandLineUtils` to me
Yes. Finding out the hard way. I've managed to run it successfully when I am debugging. But if I start the app without debugging, I keep getting an error message on the console. And I can't figure it out for the life of me
For retrieving data, do you just use the controller methods and return JSON? Or do you use the web API?
Ideally WebAPI, but nothing wrong with MVC either of you have to use it... There's a smoother transition to core from WebAPI later. 
Thanks. Will to with the API route
Am I supposed to use RDP to connect to the t2.micro and install .NET Core myself? Installing it should not be difficult, but I was just wondering if it is designed so. Then, the burden of updating the .NET Core (including security patches) is mine, is it?
Awesome, this looks like it has a lot of potential. Figures crossed they [add support for other SQL variations](https://github.com/Microsoft/sqlopsstudio/issues/56).
Nice list. [Here's](https://coderscoffeehouse.com) mine FWIW which is more focused on the .NET / Linux space :-)
Aaaaaaand it's Electron. Great.
If you think this is worse than it being based on the Visual Studio shell you’re insane and have no business computering.
Oh, no, the Visual Studio Shell is horrible. I don't know whether to like the VS Shell more or Electron more. I'm torn.
Of course it's based on electron. Writing three parallel native code implementations is expensive, and Microsoft is already working quite successfully in the electron space with VS code which means even more reuse. I know people don't like electron, but it's really not practical to do three native clients. Maybe if core eventually gets a functional ui framework that will change, but that's the reality at the moment. 
&gt;I know people don't like electron, but it's really not practical to do three native clients. Using Microsoft technologies (minus Electron), no. But I've seen good results with people using Qt for cross-platform stuff. The Qt license sucks though.
I'll take Visual Studio over Visual Studio Code any day of the week.
Qt still requires three native code implementations. You save a little bit of time on the UI, but not really that much and you end up with neither a full native solution nor something fast and cheap to develop. From a development point of view I just can't express how amazing electron is as a platform. Your code works pretty much instantly on every platform electron supports. It's why releases of code are so fast and why this thing will probably replace ssms by this time next year. 
Hm, that's true! I have to admit, I actually used Electron for some of my projects at one point (and nw.js, too). It really was amazing. Sucks that it literally _eats_ CPU power and memory though. :/ 
The nice thing about electron though is that if Google ever bothers to make Chrome less of a horrendous pig every single electron app gets that improvement. 
&gt;horrendous pig You're being so nice to Chrome right now :O _Sent from Chrome_
The new Firefox is really awesome. Sadly positron died because electron has a lot of weird ass scoping rules in it. 
Yeah, I've taken a look into it and it's really fast! Unfortunately, the convenience of having Authy at the click of a button on my toolbar is too much to lose for me. Also, the single (good?) popup Cantonese dictionary available for Firefox is now dead from Quantum dropping the old plugin API. Both first world problems, I guess. What's positron though?
Positron was a Firefox equivalent for electron. You can find the code on git hub but it's dead. 
Oh. Ouch.
FFQ is the new hotness; gotta keep up. *Sent from Chrome*
heaven forbid they did that consistently. internal (and implicitly, notinternal) should mean only accessible within this assembly. private, protected, public should talk about inheritance. Then you can pair them up any way you like. This thing where you have a protected member that is accessible for the assembly is confusing, and i suspect nobody actually uses it. 
totally. If i could replace "build all" with "does intellisense think this works?" i'd get a lot of mileage out of the interpreter. Most of my changes are small, incremental things.
Old school kool 
From what I can read it basically required huge changes to Firefox to make it compatible because v8 puts everything in the same shared declaration scope so a lot of electron apps just didn't work. Aside from being a lot of work it was a direction they didn't want to go and something that's not a direct equivalent doesn't work. 
I'm really hoping they support SQLite, as suggested. I love using a light weight database for one off apps. But there aren't any good IDEs for it. So it's a pain in the ass to use. At the very least, someone should be able to make an extension for it.
What are some good QT based projects?
Wireshark 
The node guy is a classic case of the so-called "resume driven development" and the "rewrite in [insert tech du jour here]" hipster. He is right if he can pull it off. The merits of either ecosystem **do not matter**, by and large. Whatever you're doing can be done in either with a similar effort. So what tech will be used is a political question in your organization, something reddit/internet can't help you with.
It's not the fault of Chrome though. The ~~horrendous pig~~heavy stuff are the HTML DOM, CSS and JavaScript.
VirtualBox, Telegram Desktop, Wireshark, Roblox Studio (yes, seriously), VLC (I think it's Qt4 though)
So far I like it, but it's missing a feature from Management Studio that I use often. When editing the top [1000] rows, I can't see any way to modify the query. SQL Management Studio let's you do this, and I use it all of the time to make quick manual edits to my data without having to write an update statement.
No, chrome is pretty bloated these days.
OMG; thanks, I share it.
So, except Telegram is just horrible UIs. 
&gt; complaints about Electron A PC with 8 GB+ of RAM can't handle it?
&gt; Microsoft.Extensions.CommandLineUtils There's also this ... https://github.com/juniorgasparotto/SysCommand
You can create a new Asp.Net core project that uses MVC. It does not have to use .Net Core. This means it’ll be fully compatible with any libraries you already have. You can use Visual Studio 2017 to generate your project, which will handle server side rendering, debugging, and other SPA related tasks. I, however, choose to go with a separate project. I have several front end programmers on my team and I don’t want them to be forced into Visual Studio 2017 or even to have to run the back end locally.
As mentioned there are other frameworks / libraries for this but this does look the easiest. It appears you can just annotate the methods of an existing library and you're good to go. Nice effort!
The one that caught my eye was "Microsoft joins MariaDB Foundation". Does this mean EF Core will support MariaDB? I prefer MariaDB over Postgresql simply because you can use MySQL tooling which is much better but I've not trusted the 'just use the MySQL EF Core package' approach as the 2 databases aren't strictly the same and if I end up with an issue in production 6 months down the line I'm screwed.
Curious if you've tried dbeaver. I just recently found it so haven't used it much, especially for sqlite, but it looked good.
I’ve recently been using DataGrip by JetBrians. If Microsoft add support for multiple RDMS, I would really consider switching to this 
AWS has different kind of AMI's which contain different software (You need to find public AMI with .net core 2), and yes the burden is on you to update the AMI's when you need different kind of software on your instance to run your application.
Already have ssms, sell me in this.
Have you considered jfrog artifactory?
I have. But since we are primarily.net shop. We would have to purchase pro version to get nuget support.
When your SQL tool uses more CPU &amp; RAM than your SQL server...
Telegram isn't exactly award winning either.
Do you like DataGrip? Is it worth the price?
Right now it's not especially compelling; but it indicates them creating a ssms equivalent using the electron framework like vs code. My hope is we can expect rapid iterations adding new features targeting cross platform development, competing with Jetbrains Datagrip, with support for PostgreSql, Sqlite, MariaDb, etc.. 
Yup, it's expensive. I have had some experience with nexus in my previous job , and it's a little unstable in my opinion. Like with many "free" tools. they don't charge you, true, but they end up costing you a lot.
See that is why I'm mixed. Maybe start of something great. If they open up extensions like code I will move to it for sure. 
Man, I stoked for this..
You can run this on your Mac and not have to boot into BootCamp. 
I hate the crazy message alignment. Specially the differences between different window sizes... 100% inconsistent
Qt is basically a way to spend almost as much time as it would take to create a native app to look and feel really shit. Electron apps aren't great looking either, but they're much, much faster and cheaper to build and users get better features faster. VS Code still has its downsides, and I'm not sure it's ever going to be able to compete with visual studio for development, but for the kind of stuff where decent IDEs have just never existed, it's fantastic. 
Does this work with ssdt projects?--can't seem to find any info on that. Looks like it uses it's own project type, .sqlops.
Windows is a little bit more expensive, but for t2.micro the price difference is just 30% or something. Anyways, if I use Docker (which I have never used before), can I still use the [official Amazon extension](https://marketplace.visualstudio.com/items?itemName=AmazonWebServices.AWSToolkitforVisualStudio2017) to upload the project directly within VS? Or do I have to use some SSH or other manual command lines?
If that means "getting fucking work done", then sure.
We use Artifactory and it has been well worth it. Builds, npm, NuGet, Docker Images, it's been fantastic.
Database.NET does alright with SQLite.
r/me_irl
&gt; Google Wave died because not even non-programming folks liked to work on a document while someone else was working on it. Google Docs is very much alive.
Of course MSI is in there. Just amazing how a company can lack a significant feature for 5 years, implement it completely incorrectly, brag about features that it doesn't support, mis-sell it because you know it fails to achieve the goals of the equivalent services in AWS/GCP. Sigh. Too much breakfast drinking. It's embarrassing.
Just keep it simple and use MVC. Once you knock out the site you can iterate on it and experiment with other frameworks.
What do you think I used in my above example?
Google Wave?
Doing this from scratch is going to be a lot harder than you might think. I'd suggest start with something like DotNetNuke, and then doing some customization to get more experience.
I wish I could migrate to microservices and have workflow in sagas, but my DBAs won't let their monolith databases change.
you maybe should just look into something like wordpress. i love dotnet, and this totally can be done. but you might find it faster and easier to use something already set up for blog sorts of things.
i suspect this is supposed to be a joke but i don’t get it.
Database.NET is my secret weapon of choice.
First world problems.. but seriously, I would like that feature too.
SSMS has many great extensions.
DDD is great when used in a project that it makes sense. The most important thing to learn about design patterns is what the strength and weaknesses are of each pattern. There is no pattern that fits all projects. In my opinion one of the biggest differences between a good senior dev and a junior dev is the knowledge of what will work best in a given scenario. From what pattern to use to the stack used. Also, and this can get on people's nerves, but if someone reviews your code and says to change X to Y, ask why. Phrase it appropriately, ask "why is this a better way? Is there a case when X would be more appropriate? " instead of "why should I change it". If you feel strongly and the other person is receptive, open a dialogue about it. There may be merits to how you did it that the other person doesn't see and vice versa.
Agreed. I mean go for the asp.net core site if you really want to take on the challenge/work but know that wordpress would fulfill her needs much more simply. 
Agreed with the others. Your sister is going to want an easy way to upload photos, give them a categories, descriptions and that is just the basics. I don't want to doubt your ability but that is a lot of effort even for a development team of 3, it would take you at least a good few months minimal on your own and the outcome will be a simple CMS with little customisation. I recommend getting your sister up and running with something like WordPress with a good portfolio theme. You can then work on your version as a side project, which will eventually replace what she has. This will Give you the flexibility and opportunity to experience your and produce a website which will be kick ass and brilliant for your own portfolio.
This is really cool!
Don't waste your time, use the right tools for the right jobs... Blogging CMSs (like wordpress, mmm... can be more than a blog) are designed especially for this purpose, period! Not mentioning that hosting like godaddy has super easy setup for wordpress with a very cheap price ($12 per year using coupons, renewal price is much higher though).
whats a good example of a scenario for using this? 
Your DBAs are smart.
Yeah, I get the point of tried-n-true backend. But when they don't communicate changes, I end up scrambling new releases to regain schema compatibility. Pros-and-cons as with anything. 
relevant [msdn blog post](https://blogs.msdn.microsoft.com/dotnet/2017/11/15/welcome-to-c-7-2-and-span/) and [decent clip from Connect event](https://channel9.msdn.com/Events/Connect/2017/T125)
I didn't see any explanation of it in that first link, just further links to a video and msdn magazine (which isn't out yet). Where's a good one page write-up on this class? 
I haven't seen much (or looked much, tbh) - [this lengthy page](http://adamsitnik.com/Span/) was linked to earlier in /r/programming - haven't given it a full read yet but I notice it doesn't mention Memory&lt;T&gt; :[ 
Removing unsafe code. 
The Kestrel web server which powers ASP.NET Core applications is a pretty prime scenario for this. Kestrel needs very fast, zero copy buffers. Span can be used to efficiently subdivide one large buffer into many smaller buffers represented by Spans, effectively creating a memory pool. This saves the GC a lot of work, since there's no need to allocate extra arrays. Additionally, since Span is a stack only type, memory pools can be implemented in a safe manner, so that the lifetimes of the Spans are controlled. Kestrel also needs to work with different kinds of buffers on different platforms (On Windows, RIO works best with native buffers. On *nix, Libuv works best with pinned native buffers). Span can operate over both of these types of buffers. Span effectively abstracts the underlying type of the memory away, so the same code can operate on both managed and unmanaged memory safely. Currently Kestrel does all of this already, but has to accomplish it with large amounts of unsafe code, including raw pointer arithmetic. Spans greatly reduce the amount of unsafe code required, which is very important for making safety guarantees in something as public facing as a web server.
ah interesting, so basically when there is unsafe code and provides a better way of disposing objects and we don't have the luxury of GC.
You an interop with Node within .NET to get all those shiny features though. This is exactly how react server-side rendering works.
It's brittle, lacks community help (x10000 more resources to learn node) add a changing .netcore .... Are you really recommending it? possible sure , but you know I reckon I could build a house out of matchsticks too. 
Not just for unsafe code. Here, a practical example is, when you need to parse a part of string. Normally you'd create a substring and pass it to TryParse. With span you don't have to create a new string, you pass just Span. 
Anyone have experience with these?
It looks like another "boxing hell" :-)
Which is a C-ish approach that goes againts (old) CLR one that strings are immutable. I understand the goal to minimize GC pressure but the referenced value types makes it harder to understand.
$30 and you can do 40 hours of courses a week for a month... That's 4 to 15 courses...
I am doing his latest updated course and find he is a bit short on the detail as to why we're doing things but I don't find it too bad as I've done some tutorials in a C# book and a few courses on other c# concepts. 
* Do you want to use Highcharts for a personal website, a school site or a non-profit organization? Then you don’t need the author’s permission, just go on and use Highcharts. For commercial websites and projects, and special pricing for startups. See License and Pricing.*
They’re still immutable. It's just that you can create different views into it.
That is the one I'm talking about. In the later Angular chapters he much a bunch of changes between videos doesn't mention or show them.
C# 7.2 includes language features to enforce rules that prevent these types from being boxed.
Microservices can't possibly help with that, you know... strange that data model changes "from the back", mind.
Genuine question: I am a fan of chartjs because of the ability to do realtime updates, what advantage would this server side rendering provide?
* https://docs.microsoft.com/en-us/aspnet/core/ * https://github.com/dodyg/practical-aspnetcore * https://www.ntu.edu.sg/home/ehchua/programming/webprogramming/HTTP_Basics.html * http://eloquentjavascript.net/ * https://basarat.gitbooks.io/typescript/content/docs/getting-started.html You don't need a book on asp.net core just yet.
What do MS consider to be a "large" number of projects? It's a shame they don't have numbers because this blog post means Not Much™ otherwise. if, say, the threshold is only solutions with 100+ projects will see any benefit then it's quite a vapid feature.
&gt; What’s every time a shining light of how Microsoft mismanaged its own data-access APIs is Linq to SQL. It keeps kicking Entity Framework (core)’s ass, while it’s barely updated nowadays. Oh and don’t forget the DataTable based approach, which is hard to beat, even in 2017. I doubt we’ll ever beat it. I for one don’t know any more tricks to add to my own framework without cutting corners to get passed it and I doubt others will too. If I am not mistaken, Matt Warren (MSFT) was the sole developer of Linq to SQL.
He was one of the developers who started it but later on the team was much bigger, e.g. with a dev per feature of the linq pipeline. 
If you want to learn got for it, but you can probably get most of the features if she registers an account on imgur. Edit FAA is $30/year for a lot of features https://fineartamerica.com/membershipplans.html 
Tl;dr? Mainly putting this here to remind myself to look at it later, but a tl;dr would be appreciated.
Nice. Is this production ready?
In places where you would MD5, use this instead. At least that's what I am reading. 
Close. MD5 sum is a cryptographic hash function, albeit a bad one. Farmhash is not designed to replace cryptographic hashes (think SHA-256), instead it focuses on speed. Use cryptographic hashes for anything security sensitive. To answer GP, there are two use cases where I prefer non-cryptographic functions. One is for string interning, so instead of having 1,000 instances of strings each pointing to duplicated contents in RAM, have them each point to a single instance (remember .NET strings are immutable). I've used this to great effect when parsing JSON where keys and values are often repeated in a large payload -- reducing cpu and memory usage to a fraction of a previous implementation. The other use case could be for web scraping and hashing the results to find if a two pages were the same or if a page was updated. You'd be network bound traditionally, but you could front-load pages to fully realize the efficiency that farmhash brings to the table.
Interesting. He responds to feedback. When I come across it I will notify him, though, I feel something like this has already happened and I kept going whilst being suspicious something was up.
Farmhash.Sharp passes the same tests as go-farmhash and rust-farmhash. I've hashed billions of bytes with Farmhash.Sharp in internal projects and a [little experiment of mine](https://github.com/nickbabcock/Pfarah/blob/78a6c15d163653e2c68d7d3deac3a46f1d8f34bf/src/Pfarah/ParaValue.fs), but I definitely invite you to see if it fulfills requirements of your projects. 
Why not just buy some of the top rated books on amazon? they are cheap like $50 or less
thnx
We used MurmurHash2 on one of my past projects that we needed a non-crypto hash on. Performance was very fast.
[ASP.NET Core in Action](https://www.manning.com/books/asp-dot-net-core-in-action) is coming out pretty soon. From what I've seen so far, it's very well done.
This is great. The problem,and I may be wrong, I don’t think solutions should ever get this large in most business solutions. Things can be broken down into their own solutions. Some of them turned into nuget and some of them running stand alone. It’s always driven me crazy working somewhere I have to build 120 projects because I changed one independent service that had nothing to do with 99% of the other projects. Then the monolithic build server that comes along with it....
Have they slimmed down the memory usage and improved performance? Lots of delays, hangs in VS2015... very annoying 
ah OK. I remembered he wrote a long series on Linq to SQL implementation on his blog. I never understood EF and I am glad we don't have a single project in my company using it.
DLR has a weird position in .NET framework. When it was announced, it was talked about everywhere. The year after it disappeared as if nothing has happened.
I personally just bought Pro ASP.Net Core MVC 2 (http://www.apress.com/gp/book/9781484231494) - it's currently on early Cyber Monday special (I would have bought it anyway, the timing on the special just worked out well). I haven't received the book yet, but the author is quite decent based on some of his past books.
Nice! Any plans to use the new `Span&lt;T&gt;` hotness to remove the need for those unsafe pointers?
Not everyone wants to or needs to set up webpack and react/angular. It's completely overkill. JQuery and Bootstrap are plenty fine for many applications.
Yes a number of improvements here. But depends on what issue was causing your slowness (eg project size issues are partially resolved by lightweight like ad feature) 
Of course, projects that contain stand-alone components can be made into NuGet packages and have their own solution, but all projects that are directly referencing each other (as in, not a NuGet reference) and distributed together should be in one solution, and one solution only, otherwise you will likely run into issues with different projects referencing different versions of NuGet packages. 120 projects in a solution does seem a bit extreme though.
But building a solution already only builds the projects that were changed or have a dependency that was changed.
The docs at Microsoft are a pretty good introduction to Asp. Net core.
I was very annoyed by that it froze the first time I used the find symbol feature in a opened solution. The buffer that I typed would then be outputed to the current document. That this was fixed in 2017 was reason enough for me to upgrade.
Yup and it is constantly updated.
User management can be quite overwhelming in .NET, especially for newcomers. I knocked together a project [here](https://github.com/matthewblott/simple_aspnet_auth) for a really simple solution.
I have no idea but I was wondering what would happen to MonoDevelop myself. I use macOS but would imagine those using Linux for development will be using VS Code - or maybe even other things like Vim and Emacs. And there's also an excellent commercial product as another option - JetBrains Rider. I suspect MonoDevelop will soon become abandonware (if it isn't already).
The docs can be confusing, not the best learning resource imho. I'm a seasoned developer and they've caught me out a few times, they go into low level detail where it isn't necessary (or should be marked as 'further reading') and miss out more important bits and the out of date examples have cost me hours.
Looks nice, but I'm curious how this framework handles more advanced cases that fluent validation does : - nested objects with their own validator - collections - rules requiring multiple fields 
Hey dude, thanks for this! Currently playing around with code now. One thing worth mentioning is that John is an Admin: new User { Id = 3, Name = "john", Email = "john@domain", Password = password, Groups = new List&lt;Group&gt; { new Group { Id = 1, Name = GroupNames.Admins }, } On your project, you have him listed as just a user ha! 
This is nifty but I think I'd prefer to create a single instance of a validator per class and use it for all the validations rather than creating a new validator on every validation, which would be easily done by removing the "for" method and taking the object as an argument to "validate".
* Use https://github.com/mbdavid/LiteDB so you don't need a DB * Use https://docs.microsoft.com/en-us/aspnet/core/mvc/razor-pages/?tabs=visual-studio * Use http://getbootstrap.com/ * Use https://github.com/SixLabors/ImageSharp to process the images Do it. It will be a good starter project for you. 
.NET Framework 4.7.1 supports .NET Standard without deploying all of the standard DLLs with your code. You don't need to wait for 4.7.2.
Hi! Actually the version 0.2.0 will introduce support for two of mentioned features, so nested objects and validating collections :) We'll probably release it at the turn of November and December. Valit is still very fresh project, so obviously more advanced features will be introduced in next releases ;) 
Apparently (haven't verified) the support in 4.7.1 was botched. From [Martin's answer to my SO question](https://stackoverflow.com/a/47366401/50151): &gt; The idea was that .NET Framework 4.7.1 would contain all the necessary assemblies "inbox" so that a netstandard.dll, System.Runtime.dll etc. are part of .NET Framework and any .NET Standard 1.0-2.0 DLL file would "just work", the problem was that these "inbox" dll files had a too low version number for some assemblies so libraries would fail to load - this was fixed by changing the tooling again to include DLL files with higher version numbers as support libraries which in turn forward to the "inbox" .NET Framework assemblies. This is planned to be fixed in .NET Framework 4.7.2.
Hm, it must at least be partially working, because it stopped deploying extra DLLs when I targeted 4.7.1, and there haven't been any issues with stuff failing to load. Probably depends on what you're actually using from NETStandard.Library.
Yes, I'm excited about `Span&lt;T&gt;` too! Though I'm afraid that grabbing the next 64bits in a `Span&lt;byte&gt;` won't be as efficient as: ulong Fetch64(byte* p) =&gt; *(ulong*)p Even though a Span is a contiguous area of memory, I'm not sure if there's an operation that is as similarly optimized as pointers. I'll make a Github issue to track this as well. 
Very interesting. I shall have to investigate. Thanks for the tip.
I'll also have to investigate when 15.5 comes out. :)
&gt; here Ah, good spot. Thanks, I'll get it fixed :-)
There are a few points earlier in the course it happens, but not nearly as bad. You'll have to jump around and click through a couple of videos until he opens the files that were edited and copy it over. No explanation of why he made those changes though. I emailed him two weeks ago, never received an answer. I asked him about the video that we set up the the core Identity. He sets up "Audience" but the video cuts before he types in what the "Audience" should be.
You can mix MVC and WebForms in the same project, so if you stick with the .Net Framework, you can add new stuff using MVC without rewriting everything.
- The longer you wait in moving away to webform, the more expensive it will get in the future as the number of programmers willing to work with webform dwindles. - Convert to ASP.NET MVC Core. MVC 5 is going legacy. - Convert incrementally. You can start by moving APIs to MVC Core then load it up using typescript. Once all your APIs are transferred, it will be easier to move the portal to MVC core.
I'm currently reading this book. So far (1/4 of the book) it's really well written and it is a good introduction to .net core with mvc
Yes it does, which is the (potential) problem :(. I’ve had some experience with this. 
I was having this issue when I was still on 4.6.2, and before I knew about PackageReference. Seems like they *almost* got there with 4.7.1, it's a shame they can't just fix the version numbers.
Well you better get started with that business case then. Can you document how much time you spend on maintenance due to old technology or bad code? Are there features the management requests that's impossible or very expensive to implement with Forms? Are there features they haven't requested but you can give them easily with new tech? Are there performance or UX gains with new tech that can save the company money?
You can change the hashcode algorithm used for string interning?
Rider is far from excellent. I had nothing but problems with it on Ubuntu and just found it slow and buggy. I personally love MonoDevelop and hope it doesn't go awat. I like it so much better than Xamarin Studio
My way of doing is to target both, netstandard and net461. If you reference from a net471 project, the net461 dll will be used.
There is no issue in your case: https://github.com/tdwright/contabs/pull/12 tl;dr target also `netstandard2.0` for .net 4.7+ and `net45` for .net 4.5+ to avoid additional packages being installed
For the record, this boilerplate has been a savior. Have been grabbing bits and pieces out of it for months for my own projects. Not to mention really helped me understand claims in a better way. Kudos to you, sir.
This is very nice! Thank you!
This is very nice. Thank you. 
Same here. 
No thank you. I've been using a fluent validator on my project and it's a royal pain in the ass. I'd much rather use attribute-based validation for the bulk of my logic and a small validation function for the rest. That way validation is encapsulated in the model. When you have separate validators it is 1. way too easy for them to get out of sync 2. annoying to have to open the class and validator side-by-side to see what's going on. Also, fluent validation takes a lot more code to express the same concept compared to attribute based validation. I really see no advantage in it.
Ah, the old "prefer stateless objects to stateful ones" argument. Also phrased as "prefer immutable objects to mutable ones". Not as popular as "prefer composition over inheritance", but far more useful in my opinion. It makes DI easier and improves performance. 
Its funny how much this comes up, you are not alone sir! I have actually been getting a ton of contract work helping people get ahead of a potentially steep learning curve on these sorts of things. And if you would like some extra help, let me know! But the good news is that it is far more intimidating than it is difficult. Change is always scary on some level, and even more so when you feel like you are already a little left behind. But I assure you, it's not that bad. As far as business case I would say it's 2 main points for moving away from webforms and moving to MVC. I know its supposed to be the rule of 3 when you make these lists, but velocity and flexibility are so close to be the same thing: 1. Velocity and flexibility. Webforms is relatively rigid in what you can do, and how fast you can make changes compared to MVC. Making new pages, services, and working with other platforms/devices are first class concerns for MVC. This means once you are setup, making changes and enhancements become much much easier so your work velocity increases with it. You will be following the semantic web much more closely as well. 2. Better separation of concerns. I think this is underplayed when the topic comes up, but the idea of being able to keep my visual layer (views) completely independent of my logic (controller) and data (models) is very valuable. Easier to track where bug happen and easier to divvy up work. A very common practice is have the front end completely ignorant of the data layers, and simply call apis. Putting numbers to this would be on you or a consultant find out the roadmap, business needs, future capabilities, and even planning for the things you will need you don't know about yet. Its really hard to recommend libraries and platforms out from just this amount of information, but all things being equal, going with Core MVC would be a great starting point; I love it and so does MS, they are going to keep investing there. However, the paradigm for Core is a new step for MS so there might be a few more days of understanding with that route. But personally, I think well worth it. All of my new projects are in Core and I enjoy being able to get a bit lower level independent of IIS. As far as frontend frameworks, this is a religious debate and everyone thinks they are right (usually). Popular ones I have enjoyed working with (in no particular order) [Angular](https://angularjs.org/), [React](https://reactjs.org/), and [Vue](https://vuejs.org/). All of those have a big following and you will find a ton of community support. However that's not to mention the dozens of other frameworks you could use, that others will recommend, and be completely valid. Honestly, frontend frameworks is the wild west right now; a new one comes out every couple of weeks and everyone has their own favorite. Personally, I have just taken to just using Jquery and Handlebars for all of my needs, I guess that makes me a minimalist. However if an app becomes big enough and there is a specific need, I would lean towards react. All personal opinion, there is no wrong answer and they are all surprisingly solid. Try them all out and figure out which ones you dig the most. As far as css/grid frameworks, bootstrap is the gold standard. I really dig [Foundation](https://foundation.zurb.com/sites.html) as well simply because for a long while, EVERYTHING was a bootstrap site and working in something new was refreshing. But again, there is no wrong answer and no reason not to try both. I hope this helps, and if you are looking for any assistance, let me know!
Well, now. Thank you for that tip!
&gt; So it looks like I’ll be waiting until .NET Framework version 4.7.2 for ConTabs to work seamlessly across all flavours of .NET. Since 4.7.1 was only released in October of this year and given releases seems to come around almost annually, we may be waiting a while for this to come about. * 4.7 came out in May. * 4.7.1 came out in October. * Author concludes that point releases are annual based on these dates...
I agree. At best it's breaking the assumed rules. As a veteran C# user, when I saw "private protected" it just made me think this was some kind of hack-like solution. 
This is the first thing I tried, before 4.7.1 was available, and I couldn't get it to work. It was still using the NETStandard package, and adding a ton of DLLs to the deployment.
Actually, I grabbed [a table of the release history](https://en.wikipedia.org/wiki/.NET_Framework#Release_history) (focusing on v4 onwards) from Wikipedia, then did some maths: Versions|Time (months)| :--|--:| 4 --&amp;gt; 4.5|29| 4.5 --&amp;gt; 4.5.1|14| 4.5.1 --&amp;gt; 4.5.2|7| 4.5.2 --&amp;gt; 4.6|15| 4.6 --&amp;gt; 4.6.1|4| 4.6.1 --&amp;gt; 4.6.2|8| 4.6.2 --&amp;gt; 4.7|8| 4.7 --&amp;gt; 4.7.1|7| Average|11.5| I feel like 11.5 months is close enough to a year to use the term "almost annually". I will concede that the trend recently has been closer to 6 months than a year.
Thanks, I appreciate the feedback. It can actually be simplified further, you don't really need policies and can use the old roles. I had intended on knocking together some further examples.
Well why I really appreciated that was for one of my bug projects I was building in a system to accept a certain type and value of claims for certain permission, your example did that well. Heck if you are up for it, I wouldn't even mind some feedback on that project. It's still very alpha, but I have some some code up if you would be willing to take a look. 
That’s actually not grey, but yellow, since the red and green components are both ‘ff’, while the blue component is ever so slightly less intense. The lightest pure grey you can get with CSS is `#fefefe`
This is a very fair point!
Make it open source so it's easy to request help
IMHO, KISS. Especially if you aren’t already well-versed in front-end frameworks. Avoid them completely if you haven’t already made a few client portals using them. Unless you have dozens of clients on at the same time, the responsiveness boost just isn’t worth the extra development time. Plus, you can always go simple for your v1, then start introducing responsive features in subsequent versions. This allows you to more effectively convince your boss on the benefits of migrating legacy Web Forms projects to MVC. If you want to remain on the most current overall platform, go for DotNet Core v2. Just keep in mind that actual documentation for it is rather thin on the ground, and 199/200 posts on the Internet for DotNet Core will be for pre-v2, and will have a high chance to fuck your shit up six ways to Sunday (wasting gobs of time) if you aren’t careful. If you haven’t done much MVC work yet, stick with DotNet MVC 5. There is a metric arseload of relevant material out there, and much of MVC 3/4 will also be applicable. Plus, oodles of NuGet packages to draw from. In the long run, though -- moving away from WebForms will be a godsend for you. MVC - especially the more rigorous Code First and Model First methods - will take more time to spin up, but the overall development process is much cleaner and aesthetically pleasing, and changes/additions are much faster to develop and extend. I can create sites in MVC that need a quarter the typed-out code that the same sites would need in Web Forms. There is just soooo much boilerplate stuff that is abstracted out. Especially once you get into [repository patterns](http://timschreiber.com/2015/01/14/persistence-ignorant-asp-net-identity-with-patterns-part-1/), dependency injection, fluent API, fluent validation and other really nifty tools. Just my 2¢ worth.
Ah yes I remember that!
Shameless self plug here but you might want to take a look at this book: https://leanpub.com/evolvinglegacyaspnetapplications 
That's right. Nevertheless you will hit some issues: - Code duplication in master pages (unless you stick with the WebForms view engine) - You probably have some user controls for common functionality, you need to reimplement those too
&gt; MVC 5 is going legacy. Microsoft has made no such statement.
This did the trick! Thanks /u/kukkimonsuta!
This did indeed do the trick. I will publish an update soon.
Yep, that's what I ended up doing as well, though it did take a lot of searching/troubleshooting to realize just targeting standard wasn't gonna work out of the box
MVC 5 was released 4 years ago. There have been two major MVC framework releases since then and it is called MVC Core, which is not compatible with MVC 5. There is zero news about MVC 6 development.
I have seen some libraries offer a "Library"+"DI Implementation" for each of the popular ones so that it's done for you. Honestly I don't see anyone changing DI libraries often enough to make this an issue, but most have their own implementation of the scan/register functionality so it shouldn't be hard to change out.
Thanks for the comment. That is a good point with the "Library"+"DI Implementation". The library either provides a good API with any registration being in-house, or a sort o mechanism for doing so, as you mentioned.
Now I think it's a more viable alternative to WordPress. Will run on Linux and be less hungry on resources than the full .NET version on Windows, and be faster (and more secure) than WordPress that runs on PHP. Can't beat the Themes and Plugins on WordPress though. Thoughts? 
As a Linux/.NET developer, I've been using VS Code and am continuously shocked by how pleasant is. With the right plugins/configuration, it comes *very* close to being able to call it a full IDE. That said, I'd still like it if Microsoft put some weight behind an actual C# IDE that is crossplatform. VS Code can handle web development with ease, but has no support for other parts of the .NET ecosystem. (like mobile development with Xamarin)
Just tried it. 2 simple lines of code and a NuGet package to get started. I'm amazed, I hear positive stories about used technologies and best practices that are being used within the project. Currently looking for a simple use case to put it to the test.
What a time to be a .NET developer. Now they only need a Wordpress theme migration tool (using Peachpie maybe?) and this could get some serious traction.
You could just use Identity... And add a role of student or teacher on sign up. I'm currently in the process of implementing this it's easy. I'll post the code tomorrow on the phone here at the minute.... 
Sure, probably easiest to stick it on Github if you have an account.
MS have Windows and Mac covered with Visual Studio offerings so I don't think they're interested in Linux.
Fair enough. I've not tried it on Linux but it seemed okay when I tested it on macOS.
I'm interested in feedback both bad and good as I'm looking to use the material I cover in this 4 part series as a foundation for speaking engagements at user group meetings and potential conferences.
It also seems to only target .NET Core, which means I'm out of luck when trying to do mono desktop apps
Create a WebAPI project and add a reference to the library or project you're trying to work with. 
Or, if possible, make it a nuget package and create your own private repo.
Give it some time, themes and plugins will come. 
Not really. The primary reason for putting in interfaces is testability, not specifically about using multiple implementations in production code. If you're writing a console app you can essentially resolve that without DI, but for something more complicated it's very helpful bordering on necessary. Autoregister allows you to sort out that wiring in production without having to write a lot of code. You can also generally override specific mappings either through code or config after using auto register to sort out the bulk. 
I recently did something similar using Azure KeyVault. Just create an App in Azure’s AAD, get a token using your app id and secret key, call GetCertificateAsync on the KeyVault client using the token and you’ll have a X509Certificate2 that you can feed into an HttpClient. 
the output from a webapi controller should automatically be JSON return Ok(myObject); https://docs.microsoft.com/en-us/aspnet/web-api/overview/getting-started-with-aspnet-web-api/action-results
Indeed, been able to stay relevant in the marketplace. Just when I thought my career as Windows (Phone and Backend) development was over, Microsoft go and re-invent themselves and play nice with the other kids in the park 
How much are you paying to those you select to bring on board? Salary or equity..or both? No is going to work on your vision for free.
Equity of course...and nothing is free. 
This actually looks pretty neat. I'm gonna try it out over the holiday.
OrchardCore is a goldmine of awesome source code to learn from.
Finally with OrchadCore.Modules we have something that resemblance Django Pluggables. It only takes 17 years!
You may try installing my package https://www.nuget.org/packages/NBitcoin let me know what it references.
The average from 4.5 onwards is 9 months, assuming you had enough sense to exclude the obvious outlier of 29 months.
I built this http://innolabs.me/ with a pre-beta version of Orchard Core. It took me some digging in the documentation to figure out the object model in the templating system, etc but the software has a lot of potential. 
I think we can beat WordPress with recipes+themes. The idea is that it's not just a theme but all the configuration and behavior associated. Including seeded content to start with. For now we have a blog and a web agency ones, but we intend to build more, and they are available as nuget packages which makes it easy to distribute or reuse. I hope the community will make more complex ones targeting vertical solutions.
I use a lot the case you described. One abstraction, many implementations that are picked at runtime depending on the current context. It's an object oriented switch case, I agree. But it keeps the code clean by separating what gets done from who decides what to do. We got plenty of samples in complex application frameworks like ASP.NET, value providers, custom model binders and so on. The easiest way is for the abstraction to have a `can do/do` behavior. Obviously you get a linear behavior, so use it only when the items are few and the `can do` part is quick to evaluate. Another alternative is to have a strategy picker. You can get linear behavior but, depending on your implementation, you might not be able to use transient dependencies. e.g. All implementations are passed to the picker who stores them into a dictionary using some key to select which implementation to use in each context (often some handled type).
True, there is smoke (to use a figure of speech), but we have still not seen any fire. With your argument you could also argue that the regular .NET framework is legacy, because all attention is now about .NET Core. I would expect that, like the core ASP.NET framework, some features are backported. Take configuration providers for instance, those have been backported already.
I dont get why. asp.net already has webforms, which are forms controls and events specifically optimised for the web.
You're probably right. I didn't expect this small detail to get scrutinised like this, so I didn't give it all that much thought. Still, the point I was trying to make basically holds true - it's not like releases are coming along every week.
That's massively overcomplicating it for no reason.
&gt; With your argument you could also argue that the regular .NET framework is legacy, because all attention is now about .NET Core. It is.
Open the REFERENCES section, right click, ADD, find the assembly you're looking for. Once its imported, open the controller you want to access it from, add a "using" statement, and then use the assembly like any other internal one.
- ASP.NET MVC Core 2 runs on .NET Full Framework. - ASP.NET MVC 5 does not run on .NET Core. So yeah, the .NET full framework is not legacy but MVC 5 definitely is.
[Little ASP.NET Core book](https://nbarbettini.gitbooks.io/little-asp-net-core-book/content/)
Wow. Haven't used in years but so glad Sebastian persisted with it. It was great and infuriating at times but I really enjoyed it.
If you're greenfield I would check out the dotnet angular template. It's effectively an angular 2 project rendered on the server. I always like to keep front and back separate as much as possible so this really helped because your interaction is now through the api.
No chance for remote work from Australia?
It is super easy and reusable. In fact, in recent versions of VS it is easier than adding a reference and more reliable. 
I will check into azure key vaul, thanks
Thank you for your response. This is great information. I will defiantly keep you in mind if we find our-self's over our heads.
I would use The Razor view and duplicate what is needed.
We've gone full-circle.
The sample link doesn't work.
&gt; The primary reason for putting in interfaces is testability, not specifically about using multiple implementations in production code. Uhm. No. The primary reason for using interface is **decoupling**. Testability is a collateral effect. E.g. a service living in your 'business logic' or 'domain' project needs to persist state, i.e. write to a database. Of course you have a separate project for your persistence code, so you _define_ an interface in the domain project, which your service can then call, and you _implement_ that interface in the persistence project. 
Please keep going. Subscribed :)
Horse shit. You can write code that's got interfaces galore and still has tight coupling and you can write code that's loosely coupled code without using interfaces. There are lots of projects where no, you don't need a separate business logic and domain project and where loose coupling is not necessary for any production reason. You write the interfaces to allow you to test. In doing so you will loosely couple your code, or write really horrific tests, and you'll have loose coupling if you ever need it. Regardless though you'll have tested code which you do need. 
Maybe link to the next parts at the end of an article. I read trough all of part one, when I got to the end it just said "**In the next part of this series we’ll look at VSTS and how we set up CI/CD.**" Without a link, I was under the impression that part 2 wasn't written yet. It's only after I looked at your profile that I saw that they're all written already.
I know I’m nitpicking but the “we harvest “ text on mobile isn’t centered. 
Maybe link to the next parts at the end of an article. I read trough all of part one, when I got to the end it just said "**In the next part of this series we’ll look at VSTS and how we set up CI/CD.**" Without a link, I was under the impression that part 2 wasn't written yet. It's only after I looked at your profile that I saw that they're all written already.
I'm not saying interfaces will magically give you decoupled code, but that's _what they're for_. Testability is **not** the primary reason of existence for interfaces. Yes, it's true that they make generally make things more testable. On the other hand, if you create an interface for _everything_ and mock out everything in your tests then you really haven't proven anything other than your SUT works with its dependencies according to _how your tests think they work_. Which is pretty much useless.
Yeah, that's true but note there was this communicate saying to stop using the Microsoft.Extensions.CommandLineUtils for creating new apps. https://gist.github.com/iamarcel/8047384bfbe9941e52817cf14a79dc34#gistcomment-2137680 Also, I took slightly different approach than CommandLineUtils.
Thanks for all the good words. It motivates me to work harder :).
Thanks, didn't know that one before TBH.
Its included in the github repo.
An itch to scratch. It demonstrates how versatile Xaramin Forms' rendering is.
My favorite is the shared-button demo, which broadcasts the state to multiple browsers/computers.
 The original creator is doing work and accepting pulls in his free time, it's just no longer an official asp.net core project. We're on version 2.0.1: https://github.com/natemcmaster/CommandLineUtils
I see there's "Source Control" support - does anyone know if that's just for scripts or is it for database schema as well?
As @LetMeUseMyEmailFfs said, using interfaces is meant to add a level of abstraction between the layers of the application. It's part of the philosophy of the SOLID design principles, the "D": Dependency inversion principle one should “depend upon abstractions, [not] concretions.”
Yes please can we chat on skype? I live in Ripon California. I have programming background. I am passionate about start up. I have an application that is live now, that could possibly be built upon. Would love to chat on skype TEXT ONLY! how do we exchange skype ID's privately . . 
Sorry about that. Yes I have completed all 4 parts. They can be accessed by just going to my home page - https://mikewilliams.io/ Thanks for the comment!
The fact that you need a multiple page multiple part guide to do this is exactly why I'm leaving .NET.
Yes I know, this one ... http://ooui.mecha.parts/ It doesn't work.
I want to believe you but I can't. No way you're gonna beat WordPress any time soon.
Thanks for explanation and great work you're doing!
Yeah you are right, what I meant is that we can provide something better, different than just themes. But surely can't "beat" WordPress in usage.
I find that attribute-based validation doesn't work beyond simple cases (Required/NotNull, MaxLength, etc). As soon as your project requires validation of properties against one another (ie. Date1 occurs before Date2), or requires different validation rulesets ("Save" validation versus "Submit" validation, etc), it falls apart. You will just end up with the bulk of your validation code in ad-hoc 'small validation function' which isn't so 'small' anymore.
I wouldn't call it "ad-hoc" because there is an interface for self-validating classes. An interface that is widely supported by UI frameworks. Fluent validation is the "ad-hoc". You don't have any polymorphism or framework support and it's up to the developer to properly match up the objects being validated with the validators. 
But I will grant you that, on the rare times you need it, fluent validation almost makes sense for "different validation rulesets" scenario. I say almost because I still find the syntax clumsy and verbose. 
I gotta be frank with you, this post alone will lose you tons of potential experienced devs. Working for equity alone is very risky and most experienced devs are risk averse since the job market right now has no shortage of positions for experienced devs.
So you think is better to explicitly register the interface/implementation pair in a project ?
&gt; Better separation of concerns. I think this is underplayed when the topic comes up, but the idea of being able to keep my visual layer (views) completely independent of my logic (controller) and data (models) is very valuable. Easier to track where bug happen and easier to divvy up work. A very common practice is have the front end completely ignorant of the data layers, and simply call apis. This is super important, and I agree gets downplayed too much. We also did a transition from Web Forms to MVC last year, and since then we've gone though *two* UI changes and implemented a public API, all of it effortlessly (when compared to what it would have been like if the site was still in Web Forms at least).
Out of curiosity, what are you switching to?
my first thought also
It could all be in one page but /u/atombase has broken it up into logical chunks (at least that’s what I assume is the reasoning). It goes Coding / VSTS / Docker / Azure.
Great set of articles - didn’t realise how easy it was to get up and going with Docker. Think this article just saved me $$ I’m hosting fees! :)
Can you run this in Electron?
Yes. I don’t like magic. 
I think what /u/bjoac is saying is that with .NET alternatives like Node or Go, the process is even simpler... not the physical structure of OP’s blog...
Thanks for the feedback. I felt that splitting it up would result in a better reading experience.
I'd be interested to hear why it's even simpler. Theoretically, you still need to set up some sort of API endpoint in whatever tech, deploy it somewhere and then host it.
just fyi, you can try posting on the [xamarin developers sub-reddit](https://www.reddit.com/r/xamarindevelopers/) also.
Why do you think it should work best on Windows? Xamarin's background is from guys trying to get .NET working on non Windows platforms.
What exactly is working wrong? 
Mostly renders incorrect or doesn't render at all on windows. Scaling is off on windows, and fonts are mostly wrong. In addition it doesn't always look proper native on windows even though it uses UWP
Fair enough, however Microsoft bought Xamarin quite a few years ago and it appears has been investing big in their purchase. 
If you can embed Xamarin.Forms into Electron, then maybe.
Yep, same experience over here. Works best on macOS. Cannot develop for Windows Phone on macOS though and not for osX on Windows.
Yes, there are tons of improvements in VS2017.
No, you'd have to write your own interning mechanism.
You must have missed the memo, windows phone is dead (:
It’s an excellent guide, one of the better. It’s dotnet I dislike, I’m in enterprise and the last thing I needed was for the dotnet configuration to become a skill set on it’s own. We have streamlined processes for everything, or we had, now we have a bunch of programmers doing it their way like it’s the 80ies all over.
How do the images alone weight, Netcore Debian vs Alpine? I believe the runtime for Netcore 2.0.3 is below 100 MB. The article says the image weights 83 MB with alpine, does that include the binaries for the app? 
Gotta tag this!
O,8888889ß888888889i8iís,íssSLOLO,LIOsOSaLerr
You do realize that most of it isn't even .NET related? Containers, cloud hosting, unit testing, IDE / Editor setup, Continuous Integration. These are all things that you would do in any other language / platform, and the guide would be just as long if not longer.
Thanks. I'll fix it.
Dependency inversion is about abstraction. Interfaces are not abstractions, at least not in and of themselves. You can create an interface for any class you want in about 3 seconds, won't make it an abstraction. 
Here too? -.- I'm scared to open the fridge, cause net neutrality will jump out of it... USA isn't the center of universe, if net neutrality gets abused in there, much of stuff will move out of US, simple as that.
I'm not in the US, I'm doing this 50% because of the .NET pun and 50% because no net neutrality in the US would be bad for people there, which would make less people use my sites and projects AND it would danger net neutrality in the EU
NET neutrality is covered by EU law. Not everything from the US ripples out to the rest of the world.
Just because there is a law doesn't mean ISP-s and operators will follow in correctly
Yes but they bought it for x-platform development. Windows was already covered.
No, they're not for that. They provide syntactic sugar on top of pure abstract classes and allow for a subset of multiple inheritance without the diamond problem. That's about it. They can help with decoupling and implementing patterns, but they're not decoupling. In the OPs context they're not giving him decoupling they're giving him testability. Beyond that, while the fact that your code does what you expect in isolation isn't everything, it's definitely not nothing. 
Fuck off.
Actually it could. Most internet traffic goes through the US. The rules would not just be the last mile but the backbone as well. So you could still get throttling, higher costs, etc. Also considering places like Germany's censorship rulings with regard to the internet, the EU's net neutrality laws are actually rather weak.
&gt; Not everything from the US ripples out to the rest of the world. Yeah... but this kinda does... International traffic coming in and out of the US can be throttled. So if the website or webservice you want to reach is hosted in the US, then US carriers could simply refuse your request or only provide a trickle of bandwidth. If the folks running the web service want your business they would need to pay more for a different plan. Now you might think this idea is very tin foil, and that "they'd never do that because no one would find that acceptable". Yet we're living in the reality where they are pulling off something as ridiculous as killing NN in the US...
On the brighter side, if this worse case scenario does happen, this may motivate companies to move hosting away from the US. I was under the impression though that this was more about domestic ISP's wanting to charge customers for using sites that take huge amounts of bandwidth?
I'm Mexican and currently live here at México. As you may not know, we have no net neutrality. I don't agree with what is happening to our USA brothers, but as much as I want to, I can't relate or have a very strong opinion about all their net neutrality issue. It's just over my mind. That being said, I don't blame then for their strong convictions, and we can always mute posts that we don't like.
https://www.google.com/amp/s/www.forbes.com/sites/joshsteimle/2014/05/14/am-i-the-only-techie-against-net-neutrality/amp/
I remember someone once saying "Million dollar ideas are a dime a dozen"
I heard you like false equivalencies so we put a false equivalency inside your false equivalency.
Says the rpg programmer...
Really, because with Java spring boot I can standardize the process into one click and centrally control all the configurations of our projects. With dotnet core I have to teach fresh hires how to even make things run in production.
I can see why he's the "only techie against NN" . His reasoning is typical "government can't tie its shoes so free market is best" BS. 
Not all criticizing here but how is this different than the official spa templates?
You may be better off using Serilog and message enrichment. https://github.com/serilog/serilog/wiki/Enrichment
https://github.com/annymsMthd/small-docker-test here's an example of a self contained app with ILLink.Tasks for tree shaking. Image comes out to around 49.8MB.
Being someone who is new to asp.net and spa, what I REALLY want is for someone to make a video going through each file in these templates and explaining what they do and which files I need to change vs leave alone.
The last time I looked at a an Angular SPA template, it didn't seem to have an option for user authentication, does this one have working registration and login features?
USA isn't center of universe, but it is a huge portion of Reddit. So USA-centric affairs naturally get a lot of attention. It shouldn't be surprising. 
I'd pick Hangfire instead
an XF dev on their forums said most of their devs use primarly windows phone as dev devices. Although I believe this was pre-MS take over.
Is he wrong?
I agree. Hangfire is dead simple to set up.
I was hoping the was about .NET neutrality, as in multi-platform now. Oh well.
In my opinion very much. The current state of the ISP "free market" in the US shows they are certainly not to be trusted. Plus it's funny how ISPs ask for regulation but only to limit competition like when it's about limiting towns from making communal ISPs. But when it's about protecting the customer it's all of the sudden the devil's work.
You do understand that the only competition is the one govt allows? There isn't anything the govt doesn't already claim to regulate. There is no free market in the us other than than the black kind.
You do understand that the only competition is the one govt allows? There isn't anything the govt doesn't already claim to regulate. There is no free market in the us other than than the black kind.
Whilst I am for a testable system, I kind off incline to the view that using interfaces is a way to decouple the code. The abstraction part is in the contract that is between a client code and a library code, for example an interface on a method says you give me some params, I'll return something. That's all, no client code cares how you do it, so the lib is free to reorganize itself internally but has to maintain its API.
They double dip. They charge the customer more for using services, and then they charge them again indirectly by charging the service, who then push the costs to the customers (because they're a business they aren't gonna just take a loss). The latter strategy is one of the main reasons Netflix costs increased. 
Not sure whether to be impressed or dismayed that a 'Hello World' app is 50meg.
his article reads like it's coming from a political shill. yes he's wrong. 1. He hasn't provided a single technical reason for his opinion, and only uses his "techie" title to bring false credibility to an otherwise completely illogical set of arguments. 2. He's conveniently ignoring that these big companies have already been handed all the infrastructure and it is next to impossible for there to be future competition in that space without government intervention. 3. He uses terms like Freedom and Privacy to appeal to the lowest common denominator. A blatant deception, since a pure free market pretty much allows the companies to sell your Freedom and Privacy to the highest bidder and repealing NN will do nothing to reduce the amount of access the government has anyway. 
Gosh. Some people don’t support this you know. This is not the place for political discussion. This is a programming subreddit, not politics...
I try telling them, but they won't listen.
Having a well designed **interface** between classes is necessary, but not sufficient to have loose coupling. Writing an **Interface** is neither necessary, nor sufficient.
I would recommend doing angular project external to the project that had your API. Then any guide for angular will tell you what to modify and what to not modify.
I mean, there are hundreds of other places to discuss this topic... in what way does it pertain to the .Net programming language... none.
As a web developer, yeah he damned well better be. There's no better way to stifle my entire fucking sector than eliminating net neutrality. You could make us all write in java and it wouldn't be half as a bad.
Precisely. Same thing I have been saying. It's all about Karma whoring now. Everyone knows what Net Neutrality is but keep on posting about it to spread "awareness", mhm, it's for Karma.
How have I never heard about hangfire before?! Looks awesome thanks for mentioning it
As against the concept of asking goverment help to fix issues, I oppose net neutrality. Without government intervention there would be more competition to make any cartel taking advantage of the situation at the mercy of new comers. (Happened in france with the ISP 'Free')
Look up John Papa. He’s got some videos just like that. 
I just thought it was a ~~great~~ pun
I just thought it was a ~~great~~ pun
Memory usage also dropped quite a bit. Memory usage, per iteration ------------------------------------------------------------------------------ 1. LLBLGen Pro v5.3.0.0 (v5.3.1), Poco with Raw SQL : 15,166 KB (15,530,744 bytes) 1. Handcoded materializer using DbDataReader : 15,170 KB (15,534,168 bytes) 1. PetaPoco Fast v4.0.3 : 15,207 KB (15,572,896 bytes) 1. LINQ to DB v1.10.0.0 (v1.10.0.0) (compiled) : 15,976 KB (16,359,872 bytes) 1. LINQ to DB v1.10.0.0 (v1.10.0.0) (normal) : 15,978 KB (16,361,552 bytes) 1. **Tortuga Chain, Compiled v1.1.6458.20592 : 16,148 KB (16,536,384 bytes)** 1. PetaPoco v4.0.3 : 21,107 KB (21,614,472 bytes) 1. Handcoded materializer using DbDataReader (GetValues(array), boxing) : 30,798 KB (31,538,128 bytes) 1. Dapper v1.50.4.0 : 30,800 KB (31,539,712 bytes) 1. Raw DbDataReader materializer using object arrays : 31,015 KB (31,759,488 bytes) 1. LLBLGen Pro v5.3.0.0 (v5.3.1), Poco typed view with QuerySpec : 31,880 KB (32,645,688 bytes) 1. Entity Framework v6.0.0.0 (v6.2.61023.0) : 32,448 KB (33,227,496 bytes) 1. LLBLGen Pro v5.3.0.0 (v5.3.1), Poco typed view with Linq : 32,704 KB (33,489,880 bytes) 1. ServiceStack OrmLite v4.5.14.0 (v4.5.14.0) : 33,744 KB (34,554,504 bytes) 1. Linq to Sql v4.0.0.0 (v4.7.2046.0) : 34,972 KB (35,811,960 bytes) 1. NPoco v3.9.2.0 (v3.9.2.0) : 41,017 KB (42,001,640 bytes) 1. Entity Framework Core v2.0.1.0 (v2.0.1.17303) : 48,537 KB (49,702,296 bytes) 1. LLBLGen Pro v5.3.0.0 (v5.3.1), DataTable based TypedView : 81,178 KB (83,126,584 bytes) 1. Massive using dynamic class : 87,849 KB (89,957,888 bytes) 1. **Tortuga Chain v1.1.6458.20592 : 90,984 KB (93,168,040 bytes)** Versus Memory usage, per iteration ------------------------------------------------------------------------------ 1. Handcoded materializer using DbDataReader : 15,165 KB (15,529,944 bytes) 1. LLBLGen Pro v5.3.0.0 (v5.3.1), Poco with Raw SQL : 15,174 KB (15,538,224 bytes) 1. PetaPoco Fast v4.0.3 : 15,208 KB (15,573,808 bytes) 1. LINQ to DB v1.10.0.0 (v1.10.0.0) (compiled) : 15,976 KB (16,359,888 bytes) 1. LINQ to DB v1.10.0.0 (v1.10.0.0) (normal) : 15,978 KB (16,361,840 bytes) 1. **Tortuga Chain, Compiled v1.1.6458.20592 : 16,167 KB (16,555,272 bytes)** 1. PetaPoco v4.0.3 : 21,112 KB (21,618,944 bytes) 1. Handcoded materializer using DbDataReader (GetValues(array), boxing) : 30,799 KB (31,538,896 bytes) 1. Dapper v1.50.4.0 : 30,800 KB (31,539,496 bytes) 1. Raw DbDataReader materializer using object arrays : 31,015 KB (31,759,488 bytes) 1. LLBLGen Pro v5.3.0.0 (v5.3.1), Poco typed view with QuerySpec : 31,880 KB (32,645,688 bytes) 1. Entity Framework v6.0.0.0 (v6.2.61023.0) : 32,448 KB (33,227,496 bytes) 1. LLBLGen Pro v5.3.0.0 (v5.3.1), Poco typed view with Linq : 32,705 KB (33,490,264 bytes) 1. ServiceStack OrmLite v4.5.14.0 (v4.5.14.0) : 33,744 KB (34,554,504 bytes) 1. Linq to Sql v4.0.0.0 (v4.7.2046.0) : 34,972 KB (35,812,168 bytes) 1. **Tortuga Chain v1.1.6458.20592 : 36,992 KB (37,880,400 bytes)** 1. NPoco v3.9.2.0 (v3.9.2.0) : 41,018 KB (42,002,744 bytes) 1. Entity Framework Core v2.0.1.0 (v2.0.1.17303) : 48,537 KB (49,702,128 bytes) 1. LLBLGen Pro v5.3.0.0 (v5.3.1), DataTable based TypedView : 81,178 KB (83,126,584 bytes) 1. Massive using dynamic class : 87,833 KB (89,941,504 bytes) 
you are right it is not different. it's the same template but on steroids.
Wanna see how slow change tracking is for EF? ------------------------------------------------------------------------------ 1. DataTable, using DbDataAdapter : 256.17ms (8.44ms) Enum: 33.64ms (2.50ms) 1. Linq to Sql v4.0.0.0 (v4.7.2046.0) : 299.44ms (23.10ms) Enum: 1.57ms (0.28ms) 1. LLBLGen Pro v5.3.0.0 (v5.3.1) : 316.69ms (20.21ms) Enum: 13.56ms (1.29ms) 1. Entity Framework Core v2.0.1.0 (v2.0.1.17303) : 445.67ms (16.74ms) Enum: 1.67ms (0.09ms) 1. Entity Framework v6.0.0.0 (v6.2.61023.0) : 2,511.10ms (34.17ms) Enum: 1.91ms (0.41ms) 1. NHibernate v5.0.0.0 (v5.0.1.0) : 2,888.08ms (53.38ms) Enum: 1.94ms (0.37ms) 
So whats the minimum code example of using `Delegate.CreateDelegate` to set a property?
I'd go with a separate Windows Service/Linux Service running FluentScheduler. This decouples my architecture.
It does indeed, but it's not easy to use that in a shared hosting environment. Hangfire runs entirely in the web app cpntext
Also what is the context here? 
This is job for logger scopes. https://docs.microsoft.com/en-us/aspnet/core/fundamentals/logging/ app.Use((context, next) =&gt; { var logger = context.RequestServices.GetRequiredService&lt;ILogger&lt;Startup&gt;&gt;(); using (logger.BeginScope("Tenant:{0}", context.GetTenant&lt;AppTenant&gt;().Name)) { return next(); } });
https://docs.microsoft.com/en-us/visualstudio/test/getting-started-with-unit-testing
Hi guys! This is my first post. Here, we show you how to store information in your database separating the data layers from the controllers. Hope you enjoy it!
EF is a repository in itself. You gain nothing from putting your own repository in front of it, but cripple yourself significantly. If you want to augment EF, you can create helpers which return IQueryables with the necessary includes; or helpers which generate common predicates.
Go code first wherever possible. If you need EF to generate a database with a particular schema for interop with something else later on, you can specify all the table and column names manually with attributes. Only reverse engineer an existing database if you actually need to map to an existing database, don't create one manually and reverse engineer unless you have to. The reasoning is that if the application you're building is the primary user of the database, it might as well maintain the schema and migrations for the database, otherwise you're throwing away a massive advantage of EF, which is its ability to maintain and update the DB schema automatically. Also, I recommend not using any of the GUI DB design tools, since they're mostly defunct in .NET Core. Everything is code first moving forward. 
Did you look at the difference in the generated IL? I'm guessing the `Invoke` path is having to look stuff up every time but I'd be interested in the details.
Don't use the db first stuff. If you really want to design in the database, use the wizard that generates code first from an existing database to re-create the models after you change your db. Create 2 data contexts, one for each db.
- Design your DB first - Implement it using FluentMigrator - Start your EF thingy. - Use MVC Core. It does not make sense to start a brand new project using MVC 5.
Abandon usage of MS Test for xUnit and don't look back. It's a cleaner and more powerful implementation than what VS provides out of the box.
Code First is more about you approach your data access layer which is independent of general layering in your Application (mvc). So you can do either. I would recommend that you go one step further and do WebAPI (RestAPIs) and build ui as a single page application (say in AngularJS). This will probably give you a cleaner design and quicker dev time - it feels tweaking asp.net mvc application takes a bit longer than tweaking angular application independent of stable rest APIs. But this is just my personal observations. Unless you have non-performant (such as over normalised) db design, 300 users should not be a problem. However, if you really want to scale (which you don’t need), I would rather look at DDD (Distributed Domain Design) and J Oliver NEvent Store. However the learning curve is much steeper than a trad CRUD + ORM approach. Kind Regards
In case you want a screenshot [[1]](https://i.imgur.com/RUMdKF6.png)
True. You can have abstract classes, callbacks, enums, lists, all system types, lists of system types, rest APIs...
Code first is one of the stupidest design patterns I’ve ever seen. I’ve had to fix so many projects where programmers just wrote whatever without regard to data storage. Put together your basic dB first, then move up from there. 
I tried this, it doesn't work
Which do you prefer: Cinnamon toast crunch, or life cereal? Both have their disadvantages, but neither is significantly worse than the other. It's more important that you think through and learn from every step of what you're doing than it is that you choose what comes first correctly. Pick one and stick with it. You'll fuck it up and hopefully fix it either way.
I would go even further and recommend not using entity framework! 
I've tried it too - it does work. Do you know how to work with scopes? https://docs.microsoft.com/en-us/aspnet/core/fundamentals/logging/#log-scopes
This subreddit is for programming related discussions, and even if this were a tech support forum (again, it's not), your problem is a bit too vague for anyone to be able to help. I'd contact the people who created the app and see if they can help.
 //what I was using var propertyInfo = typeof(TTarget).GetProperty(propertyName); var reflectionSetter = propertyInfo.GetSetMethod(); //new line var delegateSetter = (Action&lt;TTarget, TProperty&gt;)Delegate.CreateDelegate(typeof(Action&lt;TTarget, TProperty&gt;), reflectionSetter); In my real code I had to jump through some hoops with generics/reflection because I didn't know what type TProperty was until runtime. 
Materializing complex objects from an IDataReader. https://github.com/docevaad/Chain/blob/master/Tortuga.Chain/Tortuga.Chain.Core.source/shared/Materializers/StreamingObjectConstructor.cs https://github.com/docevaad/Chain/blob/master/Tortuga.Chain/Tortuga.Chain.Core.source/shared/Materializers/MaterializerUtilities.cs I need to go back and clean up the mess so try not to cringe. 
No, and I'm not sure how. I know that I've eliminated the need to allocate the `object[]{propertyValue}` array. But aside from that everything is hidden in the delegates rather than my code. 
Personally I would never go code first. I always want full control over all of the database properties. But I also wouldn't use the "EF DB first" design with .edmx files either. Usually I create the database first with SQL (while it has some downfalls, Visual Studio Database projects are really nice and allow you to compare existing databases with your current SQL source and lets you autogenerate migration scripts. Then I generate an EF model/context from that database (both EF6 and EF Core support this with tools without using what most people call the EF DB First approach). If you change something in your db either manually change your model or run the generator tools again (partial classes are helpful if you want to keep customizations in that case). In my opinion Code First should only be used for very small projects with 5 tables or something like that. Most people using Code First don't really know how to design and utilize a good database, most specifically you almost never see good indexes on Code First database, which is one of the most impactful things for performance.
I use ilspy to look at decompiled assemblies. It's a pretty useful tool.
Personally I would never use code first for anything, just design your database.
&gt; This subreddit is for programming related discussions, and even if this were a tech support forum (again, it's not) Where do you take this information from? I can't find any information in the sidebar and there's no sticky with rules.
Full of poor practices. :-\ - Making the `MasterRepository&lt;T&gt;` use `DataBaseContext` you immediately have your entire repository tied to EntityFramework, making the repository pattern an absolute farce and just useless. - Why the heck is the `Context` property creating a new context **in the getter**? That's just very very poor style. Getter should not create instances like that, **especially** not something critical like a database context. This also prevents the caller from controlling the lifetime of the instance, as you control the instanciation and dispose of it all the time. This makes transactions impossible. Make use of Dependency Injection! - Don't write `throw new ArgumentNullException("entity")` - make use of `nameof()`! - Your get methods should not return lists, they should return enumeration instead. - Why the heck is the `id` for methods like `Details` or `Delete` marked as optional? It should be required, not optional! It should be a mandatory part of the route. - Why do you return `View(user)` when you delete a user? You should not be able to view a deleted user. - Wrapping trivial access methods like `UserRepository.UserExists(id)` in small private helper methods like `UserExists(id)` is pointless and just code bloat. It adds absolutely no benefit.
Your choice of database is an implementation detail. Consider dapper from day one, or even stubbing it persistence entirely and adding it once you understand the full requirements. 
I've used nUnit in the past.
I don't think nUnit exists for dotnet core
I think Code first is still a good idea. You can’t do it without consideration to the storage, though. The general idea is application first, not Vice versa. Whether it’s stored in SQL or NoSQL or LevelDB or Redis, the definitive source of the data should be the application. That doesn’t mean you should just forget about the storage and ignore its own inherent performance implications, just that you shouldn’t *start* with a data-centric viewpoint...
What are your top three reasons that it doesn't make sense to use MVC5?
I normally have no problem looking at IL, but this is pretty deep magic.
&gt; Visual Studio Database projects https://www.infoq.com/articles/SSDT-Intro
Neither. I hate Entity Framework with a passion. Especially with pre-existing databases not designed around EF's limitations. If you want something that's easy to use, try Tortuga Chain: https://docevaad.github.io/Chain/Introduction.htm If you want to really learn how to work with databases, don't use an ORM that generates your SQL. Use Dapper instead: https://github.com/StackExchange/Dapper 
&gt; &gt; Use MVC Core. It does not make sense to start a brand new project using MVC 5. Why? What are the advantages of using MVC Core today?
&gt; Also, I recommend not using any of the GUI DB design tools, since they're mostly defunct in .NET Core. Everything is code first moving forward. That's not true. EF Core doesn't support a GUI, but EF Core 2.0 is a broken piece of shit that doesn't even support views and so shouldn't be taken into consideration. LLBL Gen Pro is considered to be a really good GUI DB tool that supports .NET Core.
"Code first" doesn't actually mean "use code to design your database". It's a bad name for "design your database objects in C# rather than XML". 
Dapper is good. Chain is better. https://github.com/docevaad/Chain/wiki/A-Chain-comparison-to-Dapper
xUnit is just a different set of problems and design mistakes. For example, I always end up creating my own replacement for Assert because in their infinite arrogance they decided that you should never have two asserts in the same test and thus messages aren't needed. Also, xUnit doesn't support Assert.Inconclusive. This makes it painful for integration tests where I need to tell the difference between "The test failed" and "The test didn't run because the database is down".
Although this sub is mostly about development and programming, if you post the name of the app, there might be someone who is familiar with it. 
Maybe we need some rules here :)
https://github.com/docevaad/Chain/blob/master/Tortuga.Chain/Tortuga.Chain.Core.source/shared/Materializers/StreamingObjectConstructor.cs#L231 That indexer looks like a potential performance minefield. `IsDBNull()` is known to be slow and `GetValue()` needs to box. I guess though you are going to box anyway to store the parameter collection to invoke the constructor the way you are doing and there isn't a reliable high performance way around `IsDBNull`. Couldn't you build a delegate though that provided the signature `Func&lt;DbDataReader,T&gt;` and call that on line 193 instead of `(T)m_Constructor.ConstructorInfo.Invoke(parameters)`? This way you could build the method using `DbDataReader.GetFieldValue&lt;T&gt;()` instead (or specialize in the member generation and create something out of the more specific methods on `DbDataReader`). Something like this: private T ConstructObject() { var cachedConstructor = CreateConstructorInvoker&lt;T&gt;(); //cache this var result = cachedConstructor(m_Source); if (m_PopulateComplexObject) MaterializerUtilities.PopulateComplexObject&lt;T&gt;(m_Dictionary, result, null, m_MappedProperties, s_DecomposedProperties); //Change tracking objects shouldn't be materialized as unchanged. (result as IChangeTracking)?.AcceptChanges(); return result; } private Func&lt;DbDataReader, T&gt; CreateConstructorInvoker&lt;T&gt;() { ParameterExpression reader = Expression.Parameter(typeof(DbDataReader), "reader"); ParameterInfo[] constructorParameters = m_Constructor.ConstructorInfo.GetParameters(); var parameters = new Expression[constructorParameters.Length]; for (var i = 0; i &lt; constructorParameters.Length; i++) parameters[i] = CreateParameter(reader, m_Ordinals[constructorParameters[i].Name], constructorParameters[i].ParameterType); return Expression.Lambda&lt;Func&lt;DbDataReader, T&gt;&gt;(Expression.New(m_Constructor.ConstructorInfo, parameters), new[] {reader}).Compile(); } private Expression CreateParameter(ParameterExpression reader, int ordinal, Type parameterType) { // might be reasonable to cache typeof(DbDataReader).GetMethod("...") as well // potentially pass in something that allows you to skip the dbnull check for some values var isDbNull = typeof(DbDataReader).GetMethod("IsDBNull"); var GetFieldValue = typeof(DbDataReader).GetMethod("GetFieldValue").MakeGenericMethod(parameterType); return Expression.IfThenElse( Expression.Call(reader, isDbNull, Expression.Constant(ordinal, typeof(int))), Expression.Default(parameterType), Expression.Call(reader, GetFieldValue, Expression.Constant(ordinal, typeof(int))) ); } 
There is still a reason to add the new layer - if you want to make your repository independent from the technology. On the other hand, POCOs + IQueryable&lt;T&gt; are mostly enough to abstract from the underlying framework. 
Well I wasn't fully aware of where to post this, sorry. Also I've already tried contacting the developers of the app and they have no idea why their app crashes (this only occurs on windows 10). They are trying to fix it but I've tried to find fixes myself, this one worked but then somehow stopped.
Great analysis.
Rule #1 tabs, not spaces I'm JOKING! Seriously, I think the time to introduce rules is when we have a PROBLEM (which we don't?). Until then, everything's OK without rules. 
Windows Phone maybe dead, but UWP platform is pretty much alive.
I know a guy who says that about Metro too (:
I've reported things before without realizing that this sub doesn't have the same rules as csharp :S
There's two approaches that I'm aware of in .NET, and there might be additional ones that I'm not aware of. The first is the code first approach that you've described. The second is database first using SSDT (which keeps the database in code anyway, and automatically generates database change scripts to bring a target database up to date). I don't know how 'big' big is when ORMs like Entity Framework start frustrating people, but one of the key criticisms is that they become clunky at some point. I was previously a proponent of Entity Framework 6, and had a good experience with it. Our team used SSDT to deploy the database, and then we used the EF Reverse Poco Generator visual studio plugin to code-generate the EF DbContext. But the application grew in terms of its functionality, and I daresay EF isn't such a great fit now. There's a palpable difference when using the application in terms of its performance. When I compare it with applications that have data access layers code-generated using CodeSmith templates, the CodeSmith approach wins (it is using stored procedures, and thus doesn't have to go through any of the runtime query generation that an ORM does). There's far less network chatter too when using stored procedures. With this being the case, I'm less eager to use Entity Framework in new projects. Anyway, in my experience, key barriers to using the stored procedures / CodeSmith approach are: 1. There are many developers who don't understand SQL, databases, or transactions well enough. Their understanding stops at the existence of tables as a place to store data. 2. A lot of developers seem to feel icky about the whole T-SQL thing. 3. Code-generation using a generator like CodeSmith seems to have fallen out of vogue? I'll be honest, when I first encountered the concept the thought going through my head was something like 'this is *so* 2008'. But if you can get over this hurdle then you'll probably be able to develop snappy applications with minimal chatter between the web application and the database, and minimum 'thinking' work at runtime (i.e., things like SQL generation that must occur for an ORM to function). If you pair this approach up with SSDT, and put some rudimentary governance in place with respect to successive database schema evolutions, then you'll have a lovely boring but reliable application that just works.
Interesting. I have to admit I need to do more research into lambda generation. Most of my research thus far has been into the SQL generation side. (e.g. doing things like upserts without a multiple round trips) *** I would like to get rid of boxing and DB Null checks, but from what I've read it's one or the other. *** 
It would be difficult to get the IL, because it is generated magically by the runtime, and we don't know its memory location (it might disappear or change too). However it does indeed seem that `MethodInfo.Invoke` has to do some kind of lookup/code generation every time it is called, simply because of how slow it is. On the other hand `Delegate.CreateDelegate` somehow eliminates the need for this. I guess it has to do with the fact that delegate creation generates a small piece of native code (a "thunk"), that hardcodes the result of the messy lookup process `MethodInfo.Invoke` does. This is not special to delegates from`Delegate.CreateDelegate`, as all delegates contain a `RuntimeMethodHandle` and a thunk that calls it. The overhead on invoking them remains low.
&gt; // potentially pass in something that allows you to skip the dbnull check for some values Oh wait, I'm being silly. I read the database schema at runtime for SQL generation. Therefore I know what's null for table reads. (Views not so much, that metadata is unreliable.)
Entity Framework is already an abstraction over the underlying technology (database engines). Swapping out an ORM is more akin to swapping out your DAL or all your repositories - it's not something you do a lot, so it needn't be easy. By hiding the IQueryables you lose all the composability you get there. 
I'll just throw this out for you. Don't use Entity Framework unless that is some kind of requirement. Look into some of the more popular micro ORM's like NPoco, ORmLite, etc. They are really fast, much easier to use and you'll be doing the database part in the database. I don't know what you mean by bridge the data, but if you have access to both db's you can easily query them in any technology and combine data in some composite classes.
Rule 1, no jokes allowed
Can you provide a standalone reproducible example?
Thanks
See the ReflectionTest in this scratch file for my experiments. https://github.com/docevaad/Chain/blob/master/Tortuga.Chain/PerformanceTest/Program.cs The 2.5x speed up includes other things needed to work in context, so your results may vary.
Probably better to read the actual assembly, but I never learned how to use the native debugger on Windows. It's very different from the IDE debugger.
Here is a great GitHub repo and presentation done by a guy I know. https://github.com/bruce-dunwiddie/ReflectionPresentation 
Works exactly the same as VS15. Build a test project, add references, profit.
* It's lightweight. * It can run on Linux and Linux is more popular as hosting platform. * If you're considering Docker then it's much more stable on Linux. * All the stack is open source, not just a top part of it.
Use the NUnit 3 Test adapter instead
You're assuming that his application can run on Linux. That won't be a the case if he needs Active Directory or another Windows only feature. And being "open source" isn't necessarily an advantage. EF Core is open source and it's garbage even compared to the original version of EF. As for "lightweight" well everybody says that. It's just a meaningless buzz word without context. **** Now I'm not going to argue that your premise is wrong. I honestly don't know why one would or would not choose ASP.NET Core over ASP.NET in the general case. But if you are going to argue for one other the other, in the general case, you need a better argument.
Lots of options for bridging the data: In memory joins. (popular with the microservices crowd) Copying the data into the application database (essentially a reporting/read only database) Cross-database joins, maybe with linked servers What else am I missing? 
That's why I asked what they meant. 
Right, but for some reason I think there was a fourth option. 
Took the words out of my mouth. MVC Core has some really nice enhancements over MVC5, particularly in the view layer. But if you commit to .NET Core, you commit to it across all your dependencies. Of course you could split things up into different class libraries, but that could get messy. And some libraries that claim to have Core equivalents, just aren't quite up to par, EF Core being an obvious example. If you're running in an MS/Windows environment, using MVC5 isn't a wrong choice.
The thing is, you can run ASP.NET Core on the .NET Framework. So it's still debatable which is better even for us Windows fans. You can also run .NET Core itself under IIS for Active Directory integration. (Your app doesn't know about AD, it just gets a user from IIS in the request object.) So again, I don't know what to recommend.
My barely informed guess is that when you're calling `MethodInfo.Invoke`, you're doing stringish look ups for things against type tables to figure out where in memory the thing you're trying to invoke lives. When you create a delegate, I'm guessing you resolve those look ups to a pointer and capture that. Or more probably, a pointer to a pointer that's then memory tracked so that when GC moves things around in physical memory, the pointer pointer can be updated to point at the right place still. Ultimately the thing I'm interested in, I think, is what happens when you call `MethodInfo.Invoke`. I assume all that is going to be in the platform code that's not been open sourced. If that's case, the performance difference could change between platforms or runtime versions.
Fair enough. The user count is listed as "24,315 programmers", and all of the related subreddits are also software development related.