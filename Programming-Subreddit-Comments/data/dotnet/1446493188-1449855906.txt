I have the same problem and didn't found any solution. 
To be efficient, I think what you have to do is keep a flag that gets flipped on new message receipt. Then, since you have to retrieve all the messages anyway, keep a flag on the messages that say unread. Then, since your user gets these messages only when they're online, you can just pull the most recent messages until you reach one that is read. That would be O(unread). If you want something a little more robust, you can query for just unread messages and your db will handle it. DBs are optimized for a number of data arrangements so the Big O of an individual query would vary depending on what you have as a PK, index, etc, along with the DB implementation.
Ah I see, I appreciate the insight but I'm focused on the default ASP 5 templates at the moment. Understanding the reasons for their choices, how I can maximize the potential of these templates, when to use them and for what projects. I'm not really interested in a 3rd party template at this time. Thank you though.
Is "/project/website" setup as a virtual directory? By doing so, it will appear as if it is contained in the web servers root directory.
I believe so. I have it set as an Application Root under the IIS folder options. (like this: https://www.godaddy.com/help/create-virtual-directory-4141)
I'm sorry if my synopsis didn't include enough information to produce an accurate assessment of what my company is intending to build. However, I'm not sure where you derived the two points from. 1. I mean, obviously I don't have a complete architecture decided upon (hence my question about Wordpress). 2. I don't know why you believe I am un-prepared for the magnitude of this project. What about my inquiry gave you that idea? (A) The backend would be a RESTful service architecture using ASP 5 WebApi. We would either use MVC or SPA project type for the front end and hopefully allow those pages to be editable via wordpress. (B) Why is "business analyst" in quotes? That's a well defined role in enterprise software. So the BA would be updating copy and images. I'm fairly sure that is the standard use for CMS tooling (outside of blogging). I'm sorry I took that as a given. (C) Well, it doesn't *have* to be wordpress. That is just the technology I am looking into. I've also looked into some .Net CMS tooling like dotnetnuke. But I am only interested in wordpress for this thread. (D) Of course we could role our own but "role your own" is hardly ever a good choice for something as standard as CMS tooling. Not to mention the pure overhead of doing something. It's just not a wise business decision unless you have a very very very specific and immutable business requirement and lots of cash to burn through. (E) IF we chose Drupal... could that operate ontop of ASP.Net pages? That just leads to the same set of questions from above except... exchange Drupal for Wordpress. Is there any other information you require in order to answer my questions about the architecture of using WordPress and ASP.Net MVC to develop a website? 
You can certainly use Identity with WebForms...
This is really cool.
I did a quick google and found this old post. http://stackoverflow.com/questions/1391730/full-folder-path-prefixed-to-application-root-for-mvc-at-godaddy Sorry for the formatting, mobile. Looks like the virtual directories are the problem. This is an old post and they are using iis6 but should still be relevant.
Not sure what you mean by "use MVC". Often its the other way around, MVC projects use the membership provider through some scaffold code. Anyway, the guys at ThinkTecture did a membership Reboot a while back. I think it's a lot easier https://github.com/brockallen/BrockAllen.MembershipReboot/blob/master/README.md
I have checked out (via library) most of the MVC books, but honestly find the tutorials online are much more current and functional. I also subscribe ($) to Pluralsight and think there are some great tutorials on there. You can even get the project files. Not all do unit testing since they are showing something else. But there are some that are specifically about unit testing and setting up scalable solutions.
I'm investigating several cms tools so I'm not tied to WordPress. However, as part of my investigation into content management systems I need to find certain information about them. Such as how and if they integrate into .Net MVC architecture in some reasonable fashion. I didn't dismiss droopal as an option it was simply not the current area of research. I understand that wordpress is built on php. However I was not aware if the wordpress code base had been extended to the point that it could integrate with .cshtml pages and allow it's wysiwyg editor to manage the content of the .net .cshtml pages. It appears that wordpress does not currently have the ability to allow content based updates of ASP pages. Also, just so your informed my research has told me that wordpress can be compiled into .net dll and hosted in iis. So it's not required to run on the php runtime. However that's no matter to me what runtime it's on. What mattered to my research was if this tool could allow a non developer to update copy, text, images of our website without developer interaction while allowing our team to build the website with the ASP.Net MVC framework inside visual studio 2015.
like the others have said asp.net identity isn't coupled with mvc at all.
First, team site is a cms tool that allowed for integration to .net via their sdk. So it is possible and some tools do have it. Second, the compiled dll of wordpress significantly beats the php version in benchmarks. Third, your being very rude and pretentious about this whole thing. You continue to claim I know nothing about these things and I'm not providing any information all while you are not providing any in site into how these things do work. Short of a brief mention that http is the .net contract... which I can only surmise you are referring to the rest WebApi framework. Because the MVC fretwork uses soap contracts which is why they are merging MVC and WebApi in asp5. I but don't worry about it. The other posters in this thread where far more informative and helpful. So much so that they answered my original question without asking 20 more and ridiculing me. Thanks for nothing but a hard time pal.
Google 'onion architecture'
holy shit?! I only thought of this in dreams!
Why? There is a reason why Microsoft stopped supporting WPF 3 years ago. 
Please look at my history of posts for the last five years here on this sub before you a use me of not being a dev.
College kid range is strong in you lol. Grow up dude and get your puberty rage off dotnet. No one needs your bull shit.
I second Pluralsight. 
Get myget
30 projects in a solution is pretty massive and you'd be well served to cut that down to a much smaller number (like half a dozen or less). With so many projects in a single solution, not only do you have the references issues you're seeing, but build times get annoyingly long, and it takes forever to load the solution. We only put projects together in a solution if there are direct dependencies between them. Break up the projects into a set of services and have a single solution for each of those services. Have the UI in its own solution that will talk to one or more services. Loosen up the coupling so that you don't have to build and deploy components that haven't changed. 
The list you gave us on what you have been focusing so far lists just generic stuff that should be your very basic knowledge after 1 month of learning the language. If you are talking to experienced programmers you will sound like a child when you say "you have been focusing on abstract classes and inheritance". Knowing the language should go without saying when you claim 2,5 years of experience. Tell them what you have achieved so far. I hope you wrote some programs that actually do something, that you can tell them about. 
Gosh, I've been brushing up on terms and concepts I unfortunately don't use on a day-to-day basis at work, but which I feel I do have a good fundamental grasp on. Thinking it can't hurt to make sure I haven't forgotten anything important since leaving college. This is not going to be an interview where I "tell them what I've accomplished". I've already done that. It's a technical interview. My technical understanding of the .NET platform and the Javascript ecology will be tested. As stated. What sort of understanding that outranks the baby's by 29 months could I be put to the test for? I think it's safe to assume I've "written programs that actually do something" in 2.5 years of working.
Just know oop. I didn't know any .net when I interviewed for my current job (Microsoft affiliated consultant)
Yeah, well, I already know that they are going to see how .NET knowledgeable I am. And while I sit and think, I realize that there *are* concepts and features I haven't worked with at all. Such as async/await. And I'm not too comfortable with delegates.
I just manage my packages at the solution level. Problem solved. We all use the same versions, if someone adds a new version, I upgrade them all and test each upgrade in isolation.
Thanks! Testing is a huge blank in my knowledge. Didn't learn testing in school, have barely seen it in my professional life. I mean, I am an avid reader of programming blogs and the like, and have some knowledge of various testing related concepts. But I should probably read up quite a bit, to make up for lack of experience. And be upfront with my lack of experience, of course. I do have some limited experience with Typescript, but it does make sense to study it some more over the coming days. Regarding collections, I'd say I know them quite well. But it couldn't hurt going over some of them again. Just to make sure. Brushing up on SOLID is also a good tip!
While it may be nerve racking, they are typically looking for how you solve problems, whether you know the answer outright or not. I was in an interview and was unfamiliar with something they wanted me to use. I asked to use documentation and they said that was fine. Looked it up and implemented it in a few minutes. I got the job. I have also ran a few technical interviews (from front end) and I didn't care how they got the answer, as long as they were able to do what I asked. This was mainly because we tested them only in things we actually work on. All of our technical tests were something we had done in the past few months to make sure they could specifically handle what we do. 
(1) Name all the access modifiers. (private, public, protected, internal, protected internal). (2) Explain what each is and when its used. (3) Where and why can you and should you use 'abstract' modifier? (4) You should know about EF entities and the DBContext. (5) What is the difference between value types and reference types? (7) How is WebApi (REST) different from WCF? (Hint: The difference is in the communication protocols. Explain:) Well that sums up my Junior level exam. After that we get into memory management, architecture, and much deeper into libraries. 
The best way to prepare for technical interviews is to take other technical interviews and practice. Apply for jobs you don't necessarily want and get the interview. If you pass, great. They may offer you enough to change your mind, and if not just turn them down. When you are confident, apply for the jobs you do want. 
As someone who has interviewed about 50 people related to .NET over the years I say just write some of your own code on GitHub and bring it with you and show that you enjoy coding.. That was so surprisingly hard to find yet easy to do.. unless you really hate coding then I don't know what to say
Curious, why? Isn't WPF really the best way to make C# desktop apps?
protected internal? Who uses that?
I found something that helped me tremendously (more so for algorithms versus concepts) was just doing a few problems from hackerrank. 
every day sadly, we are moving all our code to .net though.
seen this?: http://outofrangeexception.blogspot.co.uk/2013/03/how-to-zoom-picturebox-with-mouse-in-c.html and XAML: http://www.silverlightbuzz.com/2009/05/19/zoom-in-and-out-using-the-mouse-wheel-in-silverlight/
&gt; protected internal? Who uses that? No one. But these are the types of questions interviewers love to throw at you for some reason. Forget knowing about the stuff you are actually going to be *doing*, it's more "let's see how badly we can trick this person". I gave tech interviews for C#/T-SQL for years and *never* asked questions like this. I always asked about the basic, essential knowledge and the "nice stuff to know" like LINQ.
I've been through my share of Google/Microsoft type questions in interviews. Usually I'm not too disappointed if I don't get the job if they ask questions like that. At my last job I did interviews and we would have an informal interview just asking them what they worked on recently, what they like working on and some general tech questions like what is MVC or if they are familiar with SOLID principals. I never ask them to explain SOLID because no one knows the textbook definition. Just looking for things like encapsulation and single responsibility answers. I actually got away from that question and just ask them if they have any "best practices" for coding. We also gave them a simple coding test that they could do at home. Never understood making developers write out code by hand with people watching, unless that is how they code day-to-day, which would be strange. Companies that ask to explain "protected internal" or the difference between value/reference types are either, 1. companies that think they are Microsoft/Google but aren't or 2. probably a company I wouldn't want to work for. I'm sure some companies do work that requires you to know niche tech, but those aren't companies I'd want to work for anyhow.
Yeah, I've done tons of problems from various sites, including Hackerrank. So while me personally am confident with these, I'd say this is generally good advice.
Might be a bit much for the interview but if you're interested in things like how the GC works, the Type system, Generics, CLR, DLR and so on I highly recommend this book; I have the 2nd edition but I'm guessing this edition will cover "newer" topics (DLR, Rosyln etc) as my edition only covered up to .NET 2.0. It's a really great read: http://www.amazon.co.uk/CLR-via-C-Developer-Reference/dp/0735667454/ref=dp_ob_title_bk . For Javascript info I highly recommend these videos which cover the quirkier and powerful sides of the language which should stand you in good stead both for the interview and whilst coding: https://www.youtube.com/watch?v=JEq7Ehw-qk8&amp;list=PLoYCgNOIyGABI011EYc-avPOsk1YsMUe_ . Other than that look up how to sort a string alphabetically (this is a common question) or as others have suggested search for common programming interview questions on Google. Always be honest, if you don't know the answer dont try to bluff your way through as they'll probably spot it a mile off. 
I'm pointing to smaller organizations with less of a code footprint. Sure its useful in large scale development, but why would you lock a class to an assembly if you know Frank three teams over may want to use it. 
wow, that actually looks very good :) too bad still in development
Another use case for internal even with a small project is when you are developing a library for the general public. Anything you make public can be referenced by code taking your library as a dependency. Therefore anything you make public will be public forever until you can afford to make a breaking change and I gotta tell you breaking changes aren't popular. Private sounds nice out of the gate, but then unit testing becomes quite difficult if you have a very limited interface exposed to the public with quite a bit of code underneath it. Since you can designate a "friend" assembly that can view internals with an annotation in the AssemblyInfo that's your vector for unit testing while still being effectively private to the rest of the world. 
Thanks! I'll definitely brush up on some of these. I'll have to say though, that perfect hashing sounds about infinitely harder than Fizzbuzz or Fibonacci.
Please acknowledge that you're in over your head.
Yes he did.
I came across this blog post series while working on my own blog post about DNX, DNVM and DNU. Although a little bit old, this series provides an in depth look at how DNX applications are executed.
[Here's](http://programmingwithmosh.com/csharp/csharp-collections/) a good summary of collections that was included in a recent email from [csharpdigest.net](http://www.csharpdigest.net)
Lol
So I don't need SignalR right?
If you have no experience testing, you might want to look at writing some simple unit tests. It is valuable to understand how the basics work, understanding arrange/act/assert steps of a unit test. I would personally devote say a few hours to reading beginner tutorials on the topic. Doesn't matter really what unit testing framework you use to begin with, just follow a simple guide and use what they have.
It is unique to programming. But all you have to do is show that u can code and have passion for code and I'll overlook if you dropped out of high school
Windows forms may be but people are still using it and Microsoft shows no signs of putting it out to pasture yet. WPF is much better, I don't disagree, I'm just saying that it's worth using.
Only if you want to send messages to live pages, which it seems like you do.
You know, WPF isn't very difficult to learn and it's power is worth getting close to. I agree that WinForms is easy to use though. I'm taking a college class that is being taught with 100% WinForms and I understand why, it wouldn't be feesable to teach WPF out of the gate since this is an introductory class. 
Worth using for an existing app, not worth creating a new one with.
In this case it's VB.NET and WinForms. The focus is on VB.NET. 
Yup.
That will work. If you are using entity framework just be careful iterating through that list, you will end up hitting the database once per user. I make it a habit to disable lazy loading and if you need to access the friends list, do it like this: db.Find&lt;User&gt;(1234).Include(u=&gt;u.Users). Of course then you could be loading millions of friends records at once depending on how popular your user is. 
Are the servers on the same domain? 
Thanks. How do I add friends to that list? I am sorry, I am completely out of touch on this.
So windows xp is just mature and we should be installing it on new computers?
If I was starting out again, I would rather go with a multiplatform toolkit. Whilst WPF might be superior, it does lock you into Windows, and makes me reluctant to invest the time in learning it, when today, I can whip up a nice gui with winforms.
Is win10 calculator a universal app? It feels like one :P
Your server(s) could trust the issuer of both Oauth2 tokens. When you authenticate the tokens, you have rules (signed, not expired, from issuers I trust) - just trust more than one issuer. Maybe I'm missing something ...
New to C# and have been advised to never use it if it can be helped. Was told that it should only be used if its unclear what would be coming back form an asignment. I was told if it is clear what the type was then it shoud be used as it is "Lazy" not just use var. This results in lines like the following: dictionary&lt;string,dictionary&lt;string,List&lt;int&gt;&gt;&gt; complexItem = new dictionary&lt;string,dictionary&lt;string,List&lt;int&gt;&gt;&gt;();
https://github.com/mono/xwt
That's just one person's opinion. Our standards where I work actually say to use it everywhere possible because it makes the code less verbose and let's you focus on the form and functionality. I also agree with the other commenters that it makes sense to use it if it's not clear what's coming back on the right hand side. Again, rationale being making your code easier to read.
That's just plain crazy rule. I use var everywhere it is possible - type inference is never a bad thing.
Is the API REST, or SOAP or something else. This has nothing to do with MVC or WebAPI anymore, it could be a Console App.
I use the Explicit type since _I_ like to know what type i'm dealing with. I feel I can read the code better, since selecting a type should also be part of the design.
A headsup, it uses ASP.NET 5 beta 3, and the K stuff before it became dnvm, dnu etc, so everything is outdated and YOU need to update the information
WinForms is a fairly thin wrapper over Win32; Mono does include an implementation of WinForms for Linux, but I doubt it works for non-trivial apps that manually handle Win32 messages and other not-so-nice internal details.
Seeing as the changes to Windows Workflow Foundation is listed just below the changes to WPF, I suspect you merely missed the header. Just scroll a bit up.
&gt; it is "Lazy" not just use var Well, [a good programmer is a lazy programmer](http://threevirtues.com/), so I don't really see what their point is.
MSDN has recommendations here: https://msdn.microsoft.com/en-gb/library/ff926074.aspx
Thats actually my threshold... If i feel like i or another person on my team would feel compelled to mouse over a var due to an odd method name or a big chain of linq, i alt enter it and make it explicit. 
From my informal survey, it appears var is preferred when the returned type is obvious, such as upon instantiation. var x = 10; var y = new Monster(); However, my /personal/ opinion is to only use var when necessary, such as select statements that return anonymous types: var query = from table in database select new { table.name, table.value }; Besides cases like that, I personally always explicitly define the type, because I want to know unquestionably what type it is without having to mouse over stuff or read any further. I have, on occasion used var on temporary code, but that's it. Also, I am comparatively old... so... I am probably biased, haha. As for your instances when you have nested generic arguments, like a list of dictionaries, or annoying Tuples, etc, to me that's probably a good time to make a little class or struct. As if a random person reading your code is going to understand your list of dictionaries of tuples at a first, second, or fifth glance... Might as well write a quick class that clearly defines the purpose of each part with good names. And of course comment! Apologies for typos. On phone.
I don't think that's actually true. Type may be inferred at compile time, but all the friendly type names for the explicitly typed variables are still converted to the fully qualified internal type name with metadata during compile. It's all syntactic sugar, C# is too strongly typed for that to matter.
If you can't change the method name, you can definitely change the name of the variable you're assigning it to.
Personally I only use var when working with LINQ as (1) previous experience in C so I'm use to it and (2) I frequently run in to type mismatch issues when working in PowerShell that are difficult to debug. Having said that, VS should have a refactor option to convert var x = SomeInstance.SomeProperty; into SomeClass x = SomeInstance.SomeProperty; as well as warn when there is ambiguity as to which class to use. If I can't remember what class to use I will type 'int x = SomeInstance.SomeProperty' and let Intelisense figure it out for me. 
&gt; as well as warn when there is ambiguity as to which class to use. There is already a compile-time error whenever there is an ambiguity regarding the type (e.g.: var x = true ? 1 : "0"). Type inference is not dynamic typing; if you want to know the actual type you can simply put your mouse over the "var" keyword and Visual Studio will show it to you.
Depends on the context/usage IMHO. I tend to use it for LINQ queries and things, but I prefer to be explicit rather than implicit just to make sure that anyone reading my code in the future knows what to expect.
Although the first part in the series, written on 15^th April 2015, uses terms like klr, k, kre etc, in the subsequent parts author has updated the information as the new betas were released. I can't update it as I am not the author of this series. Here is the list of all the parts - * [Part 1](https://luisfsgoncalves.wordpress.com/2015/04/15/an-inside-look-at-asp-net-5-execution-part-i/) 15^th April * [Part 2](https://luisfsgoncalves.wordpress.com/2015/05/05/an-inside-look-at-asp-net-5-execution-part-ii-native-host-managed-entry-point/) 5^th May * [Part 3](https://luisfsgoncalves.wordpress.com/2015/05/19/an-inside-look-at-asp-net-5-execution-part-iii-dnx-application-host/) 19^th May * [Part 4](https://luisfsgoncalves.wordpress.com/2015/06/04/an-inside-look-at-asp-net-5-execution-setup-for-debugging/) 4^th June * [Part 5](https://luisfsgoncalves.wordpress.com/2015/06/08/an-inside-look-at-asp-net-5-execution-part-iv-asp-net-hosting/) 8^th June * [Part 6](https://luisfsgoncalves.wordpress.com/2015/06/11/an-inside-look-at-asp-net-5-execution-part-v-request-processing/) 11^th June
REST, and true it could be a consoleApp but then Why not make it an MVC hence I am searching for a more intermediate tutorial. 
&gt; From what was explained to me, it had to do with the fact that our build tool completely recompiles everything. This means that the platform projects that any rational person would just pull completed dlls for are all also recompiled. So two gigs of source code are completely recompiled every single time. I can't see how using var would affect whether something was built or not.
This guy has the best roslyn articles/tutorials ive found so far. It got me up and running on my project. https://joshvarty.wordpress.com/learn-roslyn-now/
var has one really important feature that shouldn't be discounted. Often using var means that a refactor that changes the type of something doesn't have to touch as many lines. I use var whenever and wherever I can. Giving the type a name adds little to no useful information 80% of the time. Your editor/IDE will usually tell you what the type is anyway so it's not like the information is lost. And the benefit of not having to modify that line every time a return type changes is not inconsiderable.
&gt; How does that differ from traditional approaches at heap management By traditional approaches are you referring to deconstructing your objects explicitly or is there another answer you have in mind? &gt; The stack why structs are important Why are they important? The only argument I can think of is memory footprint. Maybe there are other reasons I'm not aware of? To me the use case where that memory difference effects performance enough to matter is such a small subset of systems that it's not really a good interview question... unless your system actually requires this. &gt; Shadowing vs overriding So I understand the syntactical difference. However, I don't understand the technical difference. Could you expand upon this? Thanks!
This is the right answer. If you use the standards as published by MS, then you can use StyleCop. If you use StyleCop (and FxCop, for that matter), you get the benefit of years of best practices basically for free.
&gt; Summing up, my advice is: &gt; •Use var when you have to; when you are using anonymous types. &gt; •Use var when the type of the declaration is obvious from the initializer, especially if it is an object creation. This eliminates redundancy. &gt; •Consider using var if the code emphasizes the semantic "business purpose" of the variable and downplays the "mechanical" details of its storage. &gt; •Use explicit types if doing so is necessary for the code to be correctly understood and maintained. &gt; •Use descriptive variable names regardless of whether you use "var". Variable names should represent the semantics of the variable, not details of its storage; "decimalRate" is bad; "interestRate" is good. http://blogs.msdn.com/b/ericlippert/archive/2011/04/20/uses-and-misuses-of-implicit-typing.aspx
&gt; This is lazy. In what way is it lazy? It has exactly the same meaning semantically as explicitly stating the type. Would it be less lazy to write: System.Boolean something = false;
Bad example, but if you have an expression that returns a bool, it's 1 single character to declare the variable as a bool instead of using var. With LINQ you get complex types back where it makes more sense. And you don't need to type System.Boolean it would simply be: bool isSomething = [expression]; as opposed to: var isSomething = [expression]; When glancing at the code it's much easier to see in the first example that [expression], no matter how complex it is, returns a boolean value. In the second example, without the debugger, you have to go and try to determine what the expression does and what it is returning.
Tell them to prove it.
Good news. There is a roadmap for [WPF 4.6 and Beyond](https://channel9.msdn.com/Events/dotnetConf/2015/WPF-in-46-and-beyond)
It's annoying that there is a choice in a strongly typed language. 
PHP doesn't have the equivalent of C#'s "var"
No. You lose no type safety.
How so?
In what language are you programming? In C# this would be "bool" not "global::System.Boolean". Does your chosen framework language not have a keyword for a boolean?
&gt; That's a strawman example. No it's actually not. I'm a Senior Application Architect and I've worked on all kinds of code bases, all over at least a million lines of code. And was responsible for doing code reviews. Developers will use var and then combine two or more complex LINQ or lambda expressions that do actually produce a bool, but when reviewing the source code it's hard to tell. You actually have to go to where the variable is used to tell what type it is without a lot of extra effort to work out the expressions. If they just typed one extra character then it would be far easier to follow. Trust me, I'm not saying var is without its use. I use it all over the place, more often times than not. But on simple expressions like: int securityRequired = 4; I see no reason to do: var securityRequired = 4; That is laziness, plain and simple. It's the exact same number of characters and you are being much more explicit when you specifically declare the type.
I find that various advice MS gives is bad practice... in *general*. Use common sense; a lot of coding advice that MS provides makes sense in *some* context, but realize that microsoft's code is likely to be vastly different than your own. Do you write a lot of code whose primary purpose is not to run, but to display on a website? Do you upgrade a lot of library dependencies for projects without recompiling them? I'd recommend to explicitly avoid following MS coding guidelines without prior consideration. That above linked coding convention, for instance, clearly aims at code for lowest-common-denominator demonstration purposes on a website. So they emphasize pretty layout, explicitness, and limited C# expertise. They don't consider IDE friendliness, brevity, and playing well with version-control systems: - Short snippets for demonstration and sample purposes need to be readable without context and without IDE. Most people reading your code will *at least* know what project they're in. For instance, you clearly don't want to fully qualify the namespaces on many things you're writing, and you *do* want to change the names of objects that were created by using the visual studio designers. As snippets, such a guideline makes sense, but not for real code. - Adding superfluous parenthesis does not make code more readable, but less so. However, in online sample code that only shows trivially short expressions the cost of extra nesting isn't high, and the value of catering to people unfamiliar with basic operator precedence is higher than usual. The value of this depends on your team, but it's likely to be low. - "*Do not use var when the type is not apparent from the right side of the assignment.*" again, makes sense for sample code, but in visual studio? - The preferred array initialization syntax makes refactoring noisy. Why would you want that? - Aligned code behind variable initializers is a really bad idea in a codebase that can change. That just invites spurious version control changes. But again, in sample code it's no problem and looks nice. Another such example of advice that clearly comes from a different world: they advise to use properties, not fields (but for reasons that clearly don't apply to the vast majority of code in many projects); the motivation behind limiting optional parameters (which are terrible, but not for the binary-interop reasons that are particularly emphasized), and likely more. I.e.: my preference is to be caseful with those guidelines, and not automatically assume that what microsoft advises internally makes sense for your (likely very different) use case.
Saying "I'm a Senior Application Architect" is not an argument. And the fact that you can't support your position other than by throwing your title around is a good indication that you didn't deserve the title.
Both versions would fail one of my code reviews. I couldn't care less what type x is, but I would really like to know what it is being used for.
I disagreed with that style guide since it was first published a decade or so ago. It is the same one that wanted us to put using statements inside the namespace.
&gt; And the fact that you can't support your position other than by throwing your title around is a good indication that you didn't deserve the title. I have over 20 years of development experience, including programming in .Net since beta and and am a Microsoft MVP. I'm not throwing around my title, I'm using it to show that I've seen a *lot* of code and I know when to use var and when not to. I've sat through more code reviews then you can imagine, and I know what to watch out for, because it causes real world problems. Wasting my time trying to figure out what a variable "var" actually *is* is a huge waste of time. Don't use it when you are dealing with primitive datatypes. As I said, I use it all over the place. More often than not, actually. But there are situations where it should *not* be used.
&gt; Would you bet your company on WPF's longevity Nope. I'd only use UWP or MVC at this point.
No DSL or XAML-like object graphs? Constructing forms using code would kill it for me.
Because you should never need to specify the type. Var all the things. Let the compiler see if the types are correct.
The problem with that is twofold though: This encourages encoding the type name into variable name (Hungarian notation), and might leave you with misleading variable names after a refactor. A variables name should tell the reader of the code the intent of the variable not the underlying type. 
² That. I dislike creating GUIs in general and rather be programming the logic/back-end, but creating a GUI with WPF is just fun. 
I'd argue the hidden type change of refactoring is a dangerous side effect of vars. A slightly convoluted example, but illustrates the point: var bet= RouletteTable.GetBet(); //returns type uint value 2147483647 i.e. max int value string.Format("You doubled your money and have {0}",x+x )//You doubled your money and have 4294967294 after refactoring GetBet to return int: var bet= RouletteTable.GetBet(); //returns type *int* value 2147483647 i.e. max int value string.Format("You doubled your money and have {0}",x+x )//You doubled your money and have -2 whereas if you had the following you would not have had any problems with the refactor uint bet= RouletteTable.GetBet(); A more real world example would be passing a type to another method that takes Object as a parameter, and the type might actually matter, for instance it might be some sort of serialiser where you initially wrote it as a string, but is now an int, so your output use to look like "balance" : 2 and has now become "balance" : "2" and whatever was reading that now blows up. Having said that, I strongly believe in DRY (don't repeat yourself) so the following are good usages of var: MyInterestingDataType data = new MyInterestingDataType (); //Ugly var data = new MyInterestingDataType (); //Pretty, and type is clear to the reader MyInterestingDataType data = iocContainer.Resolve&lt;MyInterestingDataType&gt;(); // Ugly var data = iocContainer.Resolve&lt;MyInterestingDataType&gt;(); //Pretty, and type is clear to the reader
I tend to hate the 'var' keyword. I feel like it encourages sloppiness, and inhibits future readability. However, I'm usually willing to compromise if the line positively identifies the type in some other way. Constructor lines are one of those places where I don't bitch about it, even though it tends to trip my code nose no matter what.
Haha. I'll start doing that right away! ;-)
That makes total sense then. When you said "out of the gate" that seemed to mean the start of teaching programming. Professional programmers are far from "out of the gate" .... that's more like the "home stretch".
Well we differ on opinions then. It doesn't matter. Here's an article from Microsoft themselves (well, Eric Lippert, one of the best when we're talking about .Net) about the usage of "var": &gt; One of the most controversial features we've ever added was implicitly typed local variables, aka "var". Even now, years later, I still see articles debating the pros and cons of the feature. [Uses and misuses of implicit typing](http://blogs.msdn.com/b/ericlippert/archive/2011/04/20/uses-and-misuses-of-implicit-typing.aspx) Note how this isn't "var" everything. In fact, his blog post is exactly the same as what I'm saying. And he was a key architect in writing these language features!
That's a lot of variables to be declaring in one place. You should declare them where they're about to be used and maybe think about refactoring
Also add Blend into the mix and life becomes infinitely easier. Fucking wysiwyg data binding? Sure. Granted it's easier to type, but for visually creating item/data templates and such its a god send. 
I'm not sure what you're getting at here. My point is that WWF is still being updated as well and that shit is objectively dead.
You know what, I actually did just that. The only proof they had was that the build time got 30 min shorter after they changed roughly 7300 vars to the underlying type. So one incident with that could have had a dozen different causes.
Have you investigated the [Gmail API](https://developers.google.com/gmail/api/quickstart/dotnet)?
Exactly. Descriptive variable names are a million times more effective at communicating than explicitly typing
No but a webserver doesn't have to be a special machine on a network, you can spin up a version of IIS on just about any kind of Windows and host a .net site over a local network. You don't need a domain name for the server, you can access it using the network IP of the machine once you open the firewall.
Ah, ok. I was mainly interested because I have an access database that my organization currently uses and I wanted to slowly work on migrating it over to ASP. However I do not have any location to setup a web server currently as all the access front ends/back ends are hosted on a shared network. Guess we will need to stick to access until I can figure that portion out. Thanks for the response!
They use Wine, I believe, so it's not too far fetched to believe that it may be able to do everything Windows can to the extent that Wine is compatible. 
smart and lazy; use it all the god damned time because your variable names should be good enough that their underlying type doesn't need to be immediately visible
I've done it with qt, gtk and swing. It's not as nice as xaml/HTML but it's a lot better than winforms.
Have you looked at [MailKit](https://github.com/jstedfast/MailKit)? IMAP always seems to be slow in my experience., but playing around in LinqPad (and obviously guessing at your models), I get roughly 50% faster speed with Mailkit on my own gmail account than with the library you linked. Might be worth checking out if you have to use IMAP or the API route /u/unndunn linked doesn't suit your needs.
Hi, you can apply based on your profile. We shall come back to you after viewing your profile. Thanks 
&gt; explain why particular patterns or technology stacks were used I'd be surprised if a junior dev was able to do that, as these choices are made by senior devs and quite often only the final decision is announced, not all the thinking that went into selection process. 
Here is a REST Client for C# [RestSharp](http://restsharp.org/). You can use this for consummation of any rest api, and you can do it in any project type. So your question &gt; I am having trouble doing an MVC in .net using some api's, does anyone have an recommendation of good current tutorials that cover this well. makes zero sense then :)
Ah, sorry, I misread your comment.
Not knockout, only have used Angular. 
This is awesome. If .NET Core gets more features and enterprise cross-platform support, what will happen with Java/JVM?
Java/JVM will do like anything that gets solid competition: evolve or fail. Hopefully they go with the first one as .NET needs healthy competition to keep it on its toes.
I'm not sure it would have that big of an impact really. The only way Java would go away is in a very, very, very long and slow death by essentially stopping development on the language itself. Which I don't see happening ever.
Your post was downvoted too. I think there are a lot of academics/first year students on here that don't appreciate when someone disagrees with something in their textbook.
The JVM, as a platform, is actually better than the CLR in terms of performance. Furthermore, just like we prefer .NET frameworks like ASP.NET MVC, there's people out there that prefers Java EE 6+.
Aren't those performance tests pre RyuJIT, .NET Native, CoreClr and LLILC? Actually I'm using Java (with IntelliJ Idea) for some projects :)
Java Browser Apps are/were insecure as fck, but that doesn't mean that the whole JVM is bad. This is a bad reputation from the past. (However Java updates try to install toolbars, lol)
Nothing. Java is going to own Linux land for a while longer. I find it hard to believe many places will actually use .NET on a Linux box in production. Nothing about it makes any sense. Anyone have an opinion on why anybody would go the route of using .NET on Linux over java on Linux or .NET on windows?
Fair enough - it was more of a question than a statement, which is why I admitted to not knowing the platform. But my last point still stands, but it sounds like they are working towards making it better.
I would probably start with just some basic Javascript. Learn how to manipulate DOM elements with it, etc. Then I would move into Jquery and focus on AJAX and spend some time really understanding it. AJAX is really important for any modern web apps, so make sure you give yourself a good foundation there. After that, then I would say you're probably ready to move onto something like Angular. Also realize that Angular is currently going through a rewrite, so anything you learn with 1.x will be completely different when Angular 2 is released. Even spending time with Angular 2 now in it's alpha / beta builds is probably not recommended because things are changing from build to build. I wouldn't let that info scare you off from learning something awesome like Angular, but it's definitely worth noting.
You can probably grasp the basics of javascript in a day. Do another day of jQuery and you will realize why no one does javascript without jQuery anymore. Once you have the basics of the syntax down it's just a matter of practical experience. At that point I would try to just put a few pages together that use heavy jquery/javascript/ajax. This should take about a week. You will start to learn some of the nuances of javascript like the order the files load, the 'Window' scope and maybe a few patterns/anti patterns. Once you feel comfortable in this realm (there is ALWAYS more to learn!) then jump into Angular. My rational for this is because Angular is a framework and it forces you into doing things it's way. Which is perfectly fine but it can become very confusing as what *is* Angular, what *is* jQuery and what *is* javascript if you try to do all 3 from the start. I had a similar issue when writing a REST Api using WebApi and MVC. After getting through the whole thing (TWICE!) from my company I realized.... I don't know what part of this comes from what framework! [Don't worry I have since done a lot of learning and am no longer confused lol]. Anyway, that's my suggestions. Build from simplest to most complex and you should be good enough to accept FULL STACK jobs, with a learning curve.
Thanks for the insight. Could I learn jQuery and javascript together with a course like this: http://jqfundamentals.com/ I skimmed the site. Since jQuery is a library on top of javascript it would save me from having to learn all the basics. However, I think that would be like learning linq without ever learning about for or foreach loops beforehand.
It probably wouldn't matter either way, you'll still be writing regular javascript inside of jquery callbacks, etc anyway though (with a few exceptions of selecting dom elements). Javascript isn't difficult to get your mind wrapped around if you've got 3+ yrs of .net under your belt. 
Css is unavoidable if you're doing front end anything. Often your JavaScript will be manipulating css in some way. Be smart about it and manipulate it via classes. There are some nice and short books out there that will expose you to the more nuanced parts. Those account for the 20% to learn for 80% effectiveness. I got a lot out of the book handcrafted css and reading posts on css tricks. Bite the bullet on this one, you'll need to if you really want to build up some front end skills.
At our company, our back-end database was RDB on VMS. We're porting this over to Oracle on Linux. Most of our front-end web sites are either C++ or C# developed using Visual Studio and hosted in IIS on Microsoft Server. We'd like to switch to one common OS, so we're interested in this.
Depending on the size of your company it may be better to port the c# apps over to Java. Otherwise, why not continue running the apps on iis? Db and app server don't need to be on the same box.
.NET Native is targeted for Universal Apps. Core CLR, LLILC and RyuJIT are Windows only.
My advice, don't touch Visual Studio at all while you learn client side web development. Install Node, and work with it and your favourite text editor (I like Visual Studio Code at the moment) and work your way through a good book on the topic (something like [this](http://www.amazon.co.uk/gp/aw/d/1118531647/ref=mp_s_a_1_1?qid=1446746427&amp;sr=8-1&amp;pi=SY200_QL40&amp;keywords=javascript&amp;dpPl=1&amp;dpID=41PhOmFQTTL&amp;ref=plSrch)), then go back to normal Visual Studio once you have properly grasped the concepts. Also: * Don't use Nuget for client side libraries (jQuery etc), use something like Bower * Don't use MVC bundles, they suck, use a task runner such as gulp to contact/minify/uglify your css and js Just pointing out a few of the mistakes I made when I transitioned from WPF/Console apps/Windows services to web development a couple of year ago. I spent far to long working in Visual Studio, within the context of MVC, and picked up some really bad habits.
I'm using .NET on Linux. On the server side I'm way more confident and experienced with Linux than Windows and GCC (I'm using C# and C++) gets first class support on Linux.
Is Typescript knowledge applicable in the javascript or jQuery space or does it lock you into Typescript conventions of javascript?
jQuery is so essential to modern web so you can basically treat it like "Standard library", the same way BCL is for C#. JS = C#+mscorlib, jQuery = System.dll. 
Typescript to JavaScript is like C++ to C. You still write basically JS code and can easily use JS libs, but on top of that you get a lot of nice features like static typing.
Typescript is a JS superset in the sense that it compiles into JS. So you can use other libraries but you aren't writing vanilla JS so I would recommend against it *for learning*. Once you learned the ropes of JS and want the tooling Typescript offers, go ahead. 
Use federated authentication. WS Federation. And then use ADFS.
In terms of the language itself, I think Oracle has done a lot better than Sun in this regard. Remember that Java 7 was late by something like 2 years and Java 8 finally added things like lambas and streams that put it closer to where C# was a couple of years ago. The current hate seems to stem more from Oracle's lawsuit over Google.
We've got a few million lines of code for our Windows applications, and recently there was a very unpopular set of people who tried to port to Java. Between the amount of time it would take to port and getting past peoples' grudges, porting would be tough. Right now one idea is to continue running on IIS in virtual servers ran in Docker containers. We may not, though. Depends on what the product owners depend on prioritizing. Edit: Not sure why people are downvoting you. Seems like a constructive comment to me.
My company would definitely be interested. We're running .NET in AWS, and the startup time for a windows instance is awful. Plus, we get things like docker on Linux that would fit our needs quite well. Windows Server Nano or whatever it's called should fix some of these issues, but that's still some time away. Also cost. Check the price of a Windows vs Linux spot instance. Linux can be cheaper by a factor of five or more. 
I thought the windows server nano was already out. That kinda clarifies things and I can see some demand for .NET on Linux. My main thoughts were more about getting personnel capable in both Linux and .NET.
It's still in tech preview I think and not yet available as an AMI. Good .NET devs can learn Linux and good JVM/Linux devs can learn .NET. Its not too much of a problem, I think. Most languages are fairly platform agnostic these days. 
Here's where I see development: .Net, with traditionally a quite weak open source community but newer toys, gets to bump into Javas mature open source communities (after a slightly bumpy few years for the language maybe?). They're not going to notice much, but as those tendrils spread deeper into the .Net ecosystem I think there's a lot of 'win' to pull out of there.
Learn javascript first since it's the base for the other two. You'll need to learn CSS if you're doing any kind of front end work. Start [here](http://eloquentjavascript.net/) for the javascript 
Maybe. .NET Core, iirc, doesn't work on CentOS.
I would love to see VS got x-plat. If that happens I think you got a real shot at converting a lot of people. As far as IDEs go, I've never found one that is nearly as good as VS. I love that they are pushing open source at MS now and in the long run it is the right move. But as it stands right now, Java is everywhere and there is a large talent pool to draw from. Those two things lead to a strong entrenchment of Java and it will be hard to break that. It will take a very, very, very, very long time to put any sort of significant dent in Java's usage.
What the, how does that even work? One, why not. Two, how do you operate without it?
I find JQuery quite overbearing and quite frankly there are better tools. It's pretty easy to write a function that works like JQuery's selector engine and that's the only relevant thing the library has nowadays IMO. I work almost exclusively with Knockout or AngularJS so all its actually considered better design for my MVVM structured code to have no DOM interaction. If I need a specific feature I'll go grab a better library for it.
Don't listen to the guys about typescript. Sure it might be nice to use but I've never seen a job posting asking for experience in it. It's a Microsoft specific thing. Better to get general javascript experience then it won't matter what framework you use. 
Typescript is great, but if you don't know javascript yet stay away from it. Advanced JS users only.
Check out [Codeschool.com](https://www.codeschool.com/paths/javascript). They have a series of JavaScript courses that start with JS, cover jQuery, and they have various frameworks like AngularJS too :) Not to mention courses on CSS and web design as well.
I've seen a few benchmarks and I don't think there's much in it between the two. They've both had years of skilled engineers working on optimising for best performance and they're both solid fast VMs.
https://www.codecademy.com/ is very good for JS/JQuery beginners IMO
I would say go for Javascript because all those other things are just frameworks based on javascript. Once you master javascript or even intermediate knowledge of it, it will be very easy to make use of the other libraries e.g jquery, angular etc..... Also note that libraries like angular can just change their syntax and implementation at any time like what angular just did on its transition to angular 2.0...
but you may end up with hundreds of libraries in an single project cause everybody is making a library that implements some feature
But he probably won't. 
&gt; Javascript isn't difficult to get your mind wrapped around if you've got 3+ yrs of .net under your belt. There's some pretty advanced concepts, especially in modern JavaScript that OP might never have seen before in the .NET world. I totally get where you're coming from; that experience will be very useful when learning *any* new language. But I certainly wouldn't say that JS was easier to learn when comparing the 2 directly.
Shout out to /r/learnjavascript - some great resources/people over there!
Thanks Alot for the advice u/wasabii. I'm gonna check out your UcmaKit and twilio today.
Sounds more like RouletteTable.GetBet() could benefit from better unit test coverage.
&gt; "Every time a return type changes" Why are you changing return types more than once a decade?
I agree that OP should acquire vanilla JavaScript experience first, but Typescript is **not** a Microsoft-specific language. It's being used by Google in AngularJS 2.0 (replacing AtScript). And it's an open source, free language.
Off topic I want to see more up and down voting by the users. Good, well thought out, on point posts can end up with a small handful of votes. 
Thanks all, we'll investigate ADFS.
Nice write up. I have yet to integrate logging into our asp.net 5 app so this will be useful. Please keep making these posts. Your articles are excellent and are really helpful for anyone on the bleeding edge of .net development.
Why?
I'd suggest you to check out http://www.asp.net.
GHI has a large offering of boards that run .NETMF https://www.ghielectronics.com/catalog/netmf The .NET Gadgeteer line is nice if you want a more "plug and play" experience. 
can confirm, nearly built a commercial device using this setup
The killer combo is Raspberry Pi w/Arch Linux and Mono. The packages are fairly up-to-date and setting up a .NET daemon is as easy as writing a console app and a config file. Windows IoT isn't bad either, it just doesn't support as much. 
My day job involves a lot of refactoring. I change return types all the time.
I'm not seeing the advantage of this over just using log4net. Once it's configured, you don't bother with it. I feel like internalizing logging within the framework itself is just adding more overhead to something that worked just fine already.
A couple of months ago I needed to use a third party lib. That used log4net version "some years ago" (uncompatible with the current nuget version). I'm using NLog in my libs. Maybe someday I'd like to switch to SeriLog. So the answer is compatibility. However, for small self containt projects you'll not always need it. But who knows in advance ...
I'm not sure what charts have been included in ASP.NET packages. I've used Highcharts for a long time, but you probably would need to contact them for the commercial license.
Our team's powering our robot with a BeagleBoneBlack + Debian + C# stack this year!
The first time you need to actually use the log file rather than just write to one you'll be so thankful you switched to semantic logging. E.g. It takes me a couple of seconds to search for all log HTTP requests &gt; 1000ms with an HTTP response &gt; 400. Need to find log entries related to account 122978? Piece of cake. 
Any specific course in particular?
Can confirm, we used this at my last job to build color spectrophotometers.
Go tell whoever does the initial design of your software to be less shit :)
Scott Allen's courses tend to be really well done. I think the one that covers everything MVC from start to finish has MVC4 in the title. He did a follow up to cover the changes from MVC4 to MVC5 as well.
&gt; WebForms would be the closest analog to JSP. ASP.NET MVC is more like Java Server Faces (although the philosophy of how models/views/controllers connect is wildly different), while the MVC WebApi is more of an analog to Servlets. I think you have that backwards. If anything JSP and servlets are more like MVC, especially with Spring MVC being built off of those and being REALLY similar to .NET MVC. JSF is more like webforms.
&gt; Running ASP.NET on a Raspberry Pi with **Mono** and OWIN Mono is not .NET Core.
I just tried the MaiKit library but I still wasn't happy with the result (it wasn't fast enough for me). So since I didn't get more alternatives, I started testing multiple IMAP libraries. I found the [AE.NET.Mail](https://aenetmail.codeplex.com/) library, and it was the fastest library I could find. That library lacks documentation, but it's open source, simple to use, and it works. Thanks for you comment!
Microsoft actually has a list that they've tested against: https://msdn.microsoft.com/en-us/library/windows/hardware/dn914597%28v=vs.85%29.aspx As for recommendations, I've never used them, but I have a friend who use SharksCoves and MinnowBoards for testing and certifying that bus firmware and drivers work correctly with Windows, and they've never complained about the boards. They won't be the simplest to set up though.
Oh right, yes. To be honest I'd be inclined to teach it on a first programming course too. The simplest WPF app is quite simple in F#: open System.Windows [&lt;System.STAThread&gt;] do Application(Window(Title="Hello world")).Run |&gt; ignore WPF is almost a great way to do graphics but the way it transforms shapes on a `Canvas` is a bit daft. 
&gt; To be honest I'd be inclined to teach it on a first programming course too. Functional programming is an advanced concept for developers who are already very familiar with the basics of the widely-used design of OOP. I would say starting a .Net course in anything but C# at this point is doing a disservice to your students, regardless of how "quite simple" the code may look. The paradigm is different and the vast majority of jobs are looking for C# OOP developers and not F# functional ones.
C++/CLI lets you interface with .NET Seamlessly. C++/CX is, AFAIK, for other things. Why are you adding C# into the mix? You can develop on Windows with pure C++ just fine.
Bitbucket, Jira and TeamCity for us. I know of many teams that use TFS, but I don't know anyone that uses VisualStudio.Com. It's at this weird middle-ground between a "proper full-Microsoft TFS" and "Bitbucket/Github". I'm not sure what MS are trying to achieve with it, really.
We are using VSO for source control via Git and builds. Our initial plan was to also use it for managing work but while you can have custom columns on your main backlog board, you can't customise columns on your Sprint board so we went with Jira for that. Our company has a bunch of MSDN licenses which makes VSO free for those users. I have no complaints with their Git hosting. It just works and the web ui is nice. For builds they have a lot of good tasks in there to do nearly anything you need to do. My only gripe is that you can occasionally be waiting for a few minutes for a queued build to start. It doesn't happen often but it's something to keep in mind. Another thing I found strange was they don't have many good build options for the latest version of Asp.net 5. We need to use PowerShell scripts to install dnx on the build host and dnu restore the projects. This is something I really would have expected to be on the build hosts rather than us having to use build minutes to pull all that stuff down for every build. There are some nice integration options too. We use slack so are notified of failed builds through that. Bringing other developers onboard can also be a pain. If they are using an MSDN license then there is a period of validation their account has to go through before they can start using VSO. That has taken nearly 24 hours for some team members. 
TFS is garbage
We use it. TFVC sucks. Use git. The VS integration isn't bad. It seems that the integration pieces tend to lock up VS which is incredibly aggravating. I don't have much experience in the bug tracking part. The CI seems like it sucks just because it's new and there's no documentation on it.The scrum board isn't that great, but I think that's because we are using it wrong. I'd like to see an example of how to use it correctly. My previous employer had SVN and I was a big fan of that. I guess it' s not that bad for being free (for us).
That is not the topic of this thread. visualstudio.com is not *just* TFS.
The Xbox app
The concept of "SPA" and EF are completely independent of each other, so what you ask for does not make much sense. I suspect you want a step-by-step tutorial. If this is the case, then I have to say that there is no such thing. You should look for each of the things and learn them individually.
Correct, I figured this would be the majority of responses. What I was hoping for is a SPA tutorial that goes into some depth on the CRUD aspect of EF from the data binding perspective of AngularJS for example. The tutorial on asp.net seems to go into the level of detail but as I said its mostly useless since the content is not download able. So how about just a good tutorial on SPA with JSON Get/Post? I can fill in the EF side myself I guess.
Yeah, this is what /u/AngularBeginner was referring to - EF is *entirely* server side (somewhere behind your API layer) and Angular or any other SPA framework is *entirely* client side. The only relationship is through the API layer, so there are tutorials that cover building an API with EF and tutorials that cover consuming an API with Angular but few that cover both topics in one - and of the ones I have seen, won't cover one half or the other particularly well.
Is this what you're looking for? http://www.asp.net/web-api/overview/getting-started-with-aspnet-web-api/build-a-single-page-application-(spa)-with-aspnet-web-api-and-angularjs#Exercise1
Are you at queens in Belfast? I literally helped somebody do this for an assignment a few hours ago haha
Haha weird, some students up at Queens are doing this atm as an assignment None of the above is difficult to figure out, so going to leave you to it. Good luck!
If you can as an option, Entity Framework. If for whatever reason you can't, raw ADO.Net (SqlConnection, SqlCommand, SqlDataAdapter), etc.
I agree with both of you. I'll take the advice and individual look up tutorials for both sets. The part that seems to get me most confused is just starting the project correctly for what I want. MVC or WebAPI or MVC with WebAPI or use OWIN for custom middleware (I think?).
That is what I was referring to. The download is broken (at least for me). The GitHub has the finished tutorial files but it's not helpful for the walkthrough. 
I like how you don't give any reasons for your opinion.
Entity Framework is no Silverlight. Trust me on that. That one is here to stay and the way you want to go.
This is the best answer here. I've got a program which builds an IEnumerable model from a connection string. That's how routine it is.
EF can paint you into corners, for sure. If EF is off the table my go-to is Dapper.net. Honestly, the more I use Dapper the less I want to use EF, except for the migration functionality.
I made a video last year that walked through using Angular with a standard MVC backend. It should help getting you started, unfortunately I'm missing the source code though... https://www.youtube.com/watch?v=vwF1mxZH_hE 
https://github.com/curran/screencasts/tree/gh-pages/introToAngular https://github.com/johnpapa/angular-styleguide (follow this guide for angular coding) https://daveceddia.com/directives-demystified-with-3-examples/ http://stephenwalther.com/archive/2015/01/12/asp-net-5-and-angularjs-part-1-configuring-grunt-uglify-and-angularjs Forgot this: This [tutorial](https://app.pluralsight.com/library/courses/parent-child-data-ef-mvc-knockout-ajax/table-of-contents) on pluralsight (with Knockout though) has a good EF walkthrough 
ADO.Net is really bare metal whereas EF does a ton of stuff. Have you looked into in-between stuff like Dapper? It allows you to write a SQL query in a string a basically say "here's a query, here's a Type, give me the results in there" with as little plumbing code as possible.
&gt;I told thing going from Hg to Git would be a big deal Going from Hg to Git won't be too much of a deal workflow-wise. Having gone form Git to Hg the only thing I miss is some specific tools (actually, I just miss GitExtensions).
You might take a look at [ng-admin](https://github.com/marmelab/ng-admin). Use EF to build your backend and generate a configuration for the front end angular app.
If you're building an SPA app, usually you'll want a WebAPI project. It's only going to serve as your backend, where the SPA project will be managed from somewhere else. There is an SPA project type in visual studio, but it includes knockout as the default js library, instead of something more popular these days (AngularJS). It's also worth noting that WebAPI is built on top of MVC, so the project structure for the 2 types is going to be very similar, except for the fact that WebAPI shouldn't have any views in it (this is off the top of my head).
I find it funny that one of the most helpful members of the reddit .NET community has "beginner" in their username.
Yeah the Hg tool scene is really weak. But I do still prefer a lot of things with Hg. But they are close enough I am willing to take the path of least resistance. 
No, not yet. Wasn't sure if it was a complex question or a simple thing that I just hadn't been able to google properly. It's also not directly development related... 
Thanks. Funny enough I wrote the post about a week ago, same wavelength I suppose.
yeah stephen walthers tutorial is great starting point.
Why not use CppSharp to generate P/Invoke bindings?
The routing part was bugging me when I started using angular with .net. But turns out that it is very very trivial: https://imgur.com/eSJQUT1 
Yeah, and things like async/await are nice when dealing with UWP. Ideally I want to create bindings that I can use on the desktop and with UWP alike, but it looks like that's not going to happen. For now I've dropped the wrapper and started building the app in C++/CX outright, and so far it's actually been a breeze. C++ nowaday's ain't so bad.
I wasn't aware of this project. Having a go at it now.
You need to modify your web.config file and increase the timeout value. &lt;sessionState mode="InProc" timeout="20" cookieless="false"&gt;&lt;/sessionState&gt; Switching to C# wouldn't hurt either. :p
Wow - 20 years - I'm guessing you did VB2/VB3 programming on Windows 3.X? I did quite a bit of ASP/VBScript &amp; VB6 (gui and COM) from around 99 to 2004, however my first ASP.NET sites were C#. The syntax felt similar to JavaScript and Java, so it was an easy transition for me.
Or don't use session state.
&gt; You need to modify your web.config file and increase the timeout value. &gt; &lt;sessionState mode="InProc" timeout="20" cookieless="false"&gt;&lt;/sessionState&gt; &gt; Switching to C# wouldn't hurt either. :p Sticking with VB.net wouldn't hurt either. 
Why the derision for Serilog? I'm a huge fan of it.
No Serilog hate here! It's impressive they've already on boarded in fact. Just trying to communicate the limited state of affairs since everything is so new. I actually have plans to write a post about some of the cool things we can do with Serilog.
Give this a read, Microsoft Application Architecture Guide, 2nd Edition. It's a $44.99 book, but the PDF is available for free. You'll find info and the download link here: https://msdn.microsoft.com/en-us/library/ff650706.aspx 
No exact dates given: * https://github.com/aspnet/Home/wiki/Roadmap For release, Q1 could be 1st of Jan or 31st of March. 
I agree with this. WCF is neat and all how you just load up the reference and you have a strongly typed library but the hassle isn't worth it to me. I'm much happier just building my own library for my service with MVC and if other developers have to interact with it they'll hate you much less. We have a vendor built WCF service we have to integrate with where I work and every single time you add a reference to it (or update one) you have to go through and change a bunch of multi-dimensional arrays to normal arrays in the autogenerated code or it won't work.
WCF has it's place - you can build an API that can be called simply by feeding messages into an MSMQ. That's pretty sweet for firehosing data, but the .NET runtime still has a hefty overhead for that, and there's other technologies out there that can do it way more efficiently.
What is it about a 3 tier architecture that is appealing to you? Unless you're working on enterprise applications it's probably overkill, and even then a service oriented architecture may be a better option. There's also the CQRS pattern which is great for some systems. For technology, as mentioned you probably want MVC and Web Api as the backend of your application. This SO post is quite old so thing like SOAP are out of date but it describes the architecture: http://stackoverflow.com/questions/312187/what-is-n-tier-architecture Tiers don't have anything to do with technology, so WCF/Web Api/NodeJs doesn't really affect the architecture. What you're doing with tiers is separating the code of the application into different layers, like a data layer/repository + a business logic layer + the presentation layer (website).
create new EDMX then "create from database" and use the wizard.
Theres no option to add ADO.net data entity in asp.net 5, and ef7 doesnt support this. You will have to create a asp.net 4.6 class library project for your data layer access, refer to this project in your asp.net 5 webApp and remove DNXCORE50 dependency. Also you can only use EF6, not EF7.
Check this link http://stackoverflow.com/questions/29300777/is-there-an-entity-framework-7-database-first-poco-generator
&gt;That sort of interview is just masochism. Sounds more like sadism to me. 
Knockout does not pass anything to the server- it is strictly a client-side library for handling templating. Under the hood, any client-side framework is going to use an XMLHttpRequest object, and the payload of the request- the XML or JSON document you want to send to the server- is passed in the body of the HTTP request. We use the body- not the URL- not because of any security considerations, but because the URL represents the *address* of a resource, and shouldn't contain the *details* of the resource. It's fitness for purpose.
Funny thing about log4net is that you can't do line level instrumentation while using it.
Sometimes when we get too comfortable in a job, we tend to relax and no longer try to improve our skill set because we can get by. I've felt the same way specially now that I'm trying to find another job. When you go out there, there's just too much expectations from you. The interviews are much tougher and it feels like every interview nowadays are conducted by a panel where everybody tries to one up everybody :) I'm trying to catch up now on just about everything, including the really basic fundamentals of .NET because much of it I already forgot. Without tooting my own horn, my prior bosses can vouch for my great work ethic but the tech skills/knowledge is what gets you to the door. 
Such a cool concept to pick up as well is Hexagonal Architecture. Thank me later.
Most of what I know I've learned on my own. I've taught myself C#, ASP.NET HTML and Javascript. The issue I have is that I have no professional experience in the areas I listed above. I hear about MVC all the time for instance but in the jobs I have held we haven't used it. 
Thanks, I attend .NET meetups around me monthly. That and on my own are the only places that I get exposed to new technologies. I actually think I'm going to have more time because I'll actually be at home more and not going to 100 places on the weekend because my wife will actually want to stay here with the baby, at least that's my hope. 
Who cares? Throw up some sample project ups on github and host them for free on azurewebsites. Then put that all on your resume. Employers don't care as long as you can do what the job asks. Sure they might grill you with questions about experience - I'd just offer to the whiteboard and write some code. You've made a lot of excuses in your post/thread, stop doing that.
This is a great question and it applies to me the same way in a lot of ways. Can't write more now but do share your experience. I had some early frustrations doing mvc and instead started something new recently with a barebones webforms bootstrap and traditional data layer. My biggest beef with mvc is the orm layers. Either I've got an existing database that's complex and I don't want to try to force orm onto it, or I am starting something new that's doing dynamic reporting and specialized querying. The only thing ef might work on is the really simple data entry bits, but meh. 
Mediator, Adapter, Facade, Observer, Factory, Singleton. Those are pretty common for me.
Design patterns are generic solutions to common problems. You surely used a lot of design patterns already - you just can't name them. Knowing the design patterns is important for two reasons: - Knowing what solutions already exist, so you faster get to a solution. - Having a common vocabulary between developers. This is a very important point.
Probably Singleton, but it was part of the big ball of mud antipattern :(
I will echo what the others have said in direct response to you, but they're pretty much right. As long as you can go into an interview and talk about the nitty gritty parts of what makes MVC work(or anything else .Net related that you're interviewing for), it won't matter if you did it for your real job or if you did it for yourself. If there's any way you can actually present it(i.e. toss it up on the web somewhere), that's even better, as a lot of the stuff I've done has been for companies that I can't exactly go showing off in interviews. It doesn't have to be an obstacle for learning and doing.
Please no. The Gang of Four book is by far the worst book on design patterns. The useful information is in the introduction is usually overlooked for the huge collection of poorly thought out examples. A much better book on design patterns is the **.NET Framework Developers Guide**. Besides having examples that are actually useful, they spend far more time explaining the theory behind design patterns.
You are 100% correct when it comes to the excuses, that is something I need to stop doing and just making things happen. I really needed to hear that. 
Thank you all for your insights, You guys have helped me realize that I can be the dev I want and its a matter of actually doing it and getting out of my own head, I appreciate all of the feedback
I'm glad you realize. Just start coding in MVC or whatever. Stop thinking of why you "cannot" do it and just do it, lol. My story - I was working a boring winforms job for a few years and literally spent a year learning a ton about mvc/angular/etc (in the evening) and got hired on as a mid level dev at six figures. The company did not care because most candidates in the field are worthless and couldn't code at all. I built 3 sample webapps and hosted them on azurewebsites for free. I then posted all the source code to github and had all of this stuff on my resume. The best part about it was that I made the one if the apps interactive enough that it actually stored the recruiter/interviewer's data so I knew exactly who was considering hiring me. I used this to focus my interview about their ux on my app and we talked about that the whole time. They did ask me about my 0 years of "professional" MVC experience and I simply responded by telling them my story and how I'd sopent the last few years teaching myself. I finished by offering the build a complete sample repository pattern with DI MVC app from scratch (no scaffolding) in less than 5 minutes. I did so and was given an offer the next day. The interviewers (there were 5 guys in the room) also offhandedly mentioned that I was the first person they had interviewed who could do that.
I finished it, took me 2 days because I was already familiar with some of the concepts the author was discussing. As I noted it's written for experienced .Net developers wanting to make the transition to MVC. You need to be experienced in .Net and the fundamental idea of web design (client/server, HTML, Javascript). This is not "MVC for Dummies" :) But outside of that it was very informative on the parts of MVC I was less familiar with (like model binding, routing, EditorTemplates, etc) and I was able to jump right in after that. The humor in the sidenotes in this particular book is also quite amusing. For the record, I am now working remotely in a great position doing strictly MVC development. All I did was read a book, write a bunch of code to try out different areas of it, and then I was hired to do what I'm doing.
OK. You should start with a plain MVC site. Lots of good resources around for doing something like that depending on your preference for books, videos, articles.
I'd say it's waiting for tooling or just to be packaged, because unstable feed switched to rc2 already.
Thanks for your response! What would you do with the SqlProject? Also, I can't change the data layer to use EF. I've been away from things for a while, what's ALM and CI? I'm sure it's something I already know, but haven't talked about technology for a while, so I don't remember/recognize those acronyms. Will the web.debug.config approach work for a Web Site running under IISExpress (added from file system)? It's not a Web Application and not a Web Project.
Not classic ASP, but a somewhat class ASP approach. By old-school, I mean not- MVC, but using markup with C# hitting our objects.
Application Lifecycle Management &amp; Continuous Integration basically are the practices a dev team use to manage source control, integration and deployment. Basically SqlProjects enable you to break your SQL Server database down like application development. You check in individual artifacts (tables, procs, etc) as .sql files to version control then invoke the publication process locally or remotely to create the database from that source. This saves having to share heavy and outdated .bak files to the local environments. I wouldn't lean on web.debug.config in this scenario. Though you're close to leveraging config transforms here. You'll have some friction trying to get your classic ASP.Net site to play well with those. You could just set the connection string to something like .\ or localhost and then just use a comparison tool or the Mk1 eyeball to integrate config changes to deployment environments.
Visual commander is really powerful. Noone had mentioned it on any subreddit until I found it randomly once
OK just out of morbid curiosity are you talking about a Website project? Which I always thought was web forms but just built differently?
Exactly
As wasabiiii pointed out above, it's a directory with pages in it that the .sln points to.
If you want to quickly get up to speed on the most common patterns and good usage examples you should read Adaptive Code via C#; http://www.amazon.co.uk/Adaptive-Code-via-Interface-Principles/dp/0735683204 As stated, you use patterns daily but often don't recognize them. Pretty much every lambda to a linq query is basically a strategy pattern. Like most things they are just tools and context is everything.
Ah, yes didn't think of that, very good idea actually. Thanks.
Although recorded during the beta 7 period this video explains the basics of ASP.NET very well.
A big part of all programming languages north of micro assembly is to implement common design patterns. The fact that one pattern may require others doesn't make it less of a pattern. Design patterns are just commonly recognized patterns of code. So MVVM is no less of a design pattern than observers for example.
I use Refit for most all my REST interactions. Pretty light weight, as I just define an interface and my models and just fire off some calls. https://github.com/paulcbetts/refit 
I was hoping someone would provide him this answer. Patterns of Patterns are indeed valid examples. 
It would give you more control, but I can't think of any reason to optimize in IL that way. I would see it as an academic kind of pursuit. The main reason to learn it would be so that you could develop your own framework language that compiles into it.
That is a very interesting design! I'll take a closer look at it.
Another that I know of is the ability to have a generic attribute. These are supported in IL, but not in C# or VB.Net. [Example&lt;long&gt;(123456789L)] where the attribute is public class ExampleAttribute&lt;T&gt; { ... }
Sound like a pretty poor bit of table design. Not only should parent keys be nullable they should also be constrained to not be self referencing. 
1. IL has more features that might not be supported in C#. For example you can create methods without classes. 2. You can generate assemblies and code in runtime using Reflection.Emit. 3. You might want to make custom compiler for your own language.
Not saying I'd do that. Just offered as a possibility. Also, there's lots of valid use cases for self-referencing. 
Isn't this where CTE's (Common Table Expressions) come in? You can find all the subordinates of an employee with it
Saw the announcement on twitter https://twitter.com/mbracethecloud/status/664441083351404544 Interesting samples in https://github.com/mbraceproject/MBrace.StarterKit 
Writing applications that emit and compile il on the fly can give you amazing performance benefits, but its not for the faint of heart. http://www.devx.com/dotnet/Article/28783
I agree from past experiences, but I don't have control over this situation. Our deployment is done through .bat files for dlls, and by hand for everything else. I'll take a look at them again to see if they'll work in our situation. It's been nearly 5 years since I've used a Web Application. My most recent obstacle (noticed at 5:59 pm) is linked SQL Servers in production and needing to set up something to mimic it in a dev environment. I was thinking about taking the same approach I did to solve multiple servers with same-name db's in production: I used multiple named-instances on my dev machine. Each instance is named after the production server. e.g. mymachine\mssql01, mymachine\mssql02 If you have other suggestions, or ideas for the linked server, my ears are open. Also, to ease configuration of the sites on developers machine, I copied the production file over, changed the conflicting properties, and then created a utility that allows the developer to update the credentials for the sites, virtual directories, and app pools in one shot... that's it so far.
You didn't include all relevant details, for example: what is `texturePtr`, exactly? Same goes for `outputPtr`...
Without being pedagogic, I think this kind of self-referencing structure is prone to just this sort of confusion. This is a legacy system that is not worth changing, but I think my preferred design would have been a separate organizational hierarchy table that defined the relationships between Employee records.
This is my go to https://github.com/restsharp/RestSharp/
Is this for UWP or traditional Windows applications? 
Sounds like you need to be using the roles if your trying to show or hide.large swathes of site. If its table or grid data, the controller can fetch the identityuser and thus, the id. Then use whatever db statement 
I'm sorry you are having these issues and you may be in a place where there are no easy workarounds. Can you work remotely some other contract? 
I found this to be a great write up. I feel it really helps move people into what ASP5 is really about. Opensource + Front End development.
People here have listed benefits to coding this way.
Uploaded a blog post describing the whole process on my GitHub http://gimly.github.io/vsonline/2015/11/13/vs-online-build-squirrel-windows.html
Direct Draw in almost all likelihood.
Makes sense. Thanks for the tip.
Thanks, I'll check them out.
This is a possibility. Direct X is very high performance, but low level. I've used SharpDX that is a thin CLR wrapper to the C++ apis. However, you'll need to do manual garbage collection of native objects.
I totally needed this right now in my project. You are awesome!
Its mostly in the main pixel drawing loop - which can't be functions as that'll introduce the overhead of function calls, and push/popping. I can make it lots more readable though!
Here's the code: http://untamed.co.uk/miscfolder/PixelShader.zip http://untamed.co.uk/miscfolder/PixelShaderSource.zip
Can confirm. Done that, have beard.
Good post - but be aware that Kestrel is now meant for production use with e.g. IIS or NGINX as frontends. WebListener is gone.
There are three big concepts in WPF which arguably make it WPF, and one of them translates pretty well to Win32 concepts (Events), one has some similarities (Styles), and one which is completely new, and which is probably the strongest feature (Binding). First off, though, the important thing to understand about WPF is that it doesn't use Win32 windows. The core of Win32 is a procedure (WndProc) which gets messages from the OS, processes them, and then returns. This model is used for both input and output (specifically drawing). In the middle, you have the logic which makes up the window, and composing windows via a parent/child relationship makes the app. WPF separates this by building a tree data structure ([the visual tree](http://www.codeguru.com/images/article/13347/WPF03.gif)) and maintaining connections from parent to child visual elements in this tree. This tree is then separate from the logic used to process input and direct output. WPF itself then does the job of drawing the UI specified by this tree to the screen (no more handling of WM_PAINT!). With this tree structure in mind, we can look at events, styling, and binding. * Events - Events in WPF are like WndProc messages. Note that these are different than COM events (i.e. IConnectionPoint and friends), which are more like callbacks (or in .Net speak, delegates). Events in WPF are two kinds: messages that start at the root of the tree and travel down to the leaves (named 'tunneling'), and ones which start at the leaves and travel up to the root (named 'bubbling'). Many logical events (like a key press) have a pair of events, one called a "preview" event (tunneling) and the other the actual event (bubbling). With these two kinds of events your UI can observe or handle all kinds of input. However, due to wanting to separate our actual UI and the logic of the UI, "handling" usually means passing off the input to a helper class which will then update the rest of the UI via binding (see below). Most of the time, using events directly is not really needed, since a WPF UI control will usually use the input to change some internal state, and this can be read via some property on the control. How do we know when some property has changed? Binding! But first... * Styles - Styles in WPF are very powerful, and only have a weak analogy in Win32. When you create a [Window Class](https://msdn.microsoft.com/en-us/library/windows/desktop/ms633576\(v=vs.85\).aspx) and create a window of that class, the properties (icon, cursor, wndproc, etc.) that you setup for that Window Class are used in the window, along with any specific overrides for that window (i.e. subclassing). In WPF, visual controls instead have a core type (e.g. 'Button') which defines the logical UI behavior but the visual appearance are constructed from basic UI shapes (e.g. Border, Panel, Label, Rectangle, etc.). How these shapes are arranged comes from the style of the control. There are default styles to make all the UI elements in WPF look like Win32 UI, but this is not a requirement. Styles are so powerful that you can completely change how a control looks by creating a new composition of basic UI elements. It is important to note that this arrangement is all done by making a tree of these elements (this is why XAML is natural: the parent/child relationship of XAML elements mirrors the parent/child arrangement of visual elements at runtime). All of these elements are then rendered and drawn by WPF: the WPF developer just arranges them. This makes the WPF UI 'declarative' vs. 'imperative': we don't say how to draw it, just specify what to draw, by using styles usually written in XAML. Styles can also be declared to react to events or property changes and change how the control looks, and there are many ways to control how the style changes the visual appearance depending on which events are happening in the visual tree or how the control properties are changing. This leads us to how to change control properties... * Binding - WPF is really at its best when the UI is setup to react to property changes. The goal of a WPF developer then is to create a UI that is like a garment for the body of the UI logic. When the UI is fitted to this logic, it conforms to it, but can be changed without changing the logic itself. This pattern is now called MVVM - Model, View, View-Model - where the core application logic is the Model, the UI (typically declared in XAML) is the View, and this logical UI is the View-Model (VM). The VMs are just plain .Net objects which have properties that can be read or written, but each time they change, there is a special event that is raised (NotifyPropertyChanged). This is a .Net event (think IConnectionPoint), not a WPF event. WPF knows about the .Net interface which defines this event, and automatically listens to it (when the VM is connected to the View correctly: i.e. it is the DataContext). This allows us to declare a special receiver on the View called a 'binding'. The binding changes some View property when the View-Model property changes. When the View property changes, WPF detects this and redraws the screen for that control, depending on what the property changes. For example, if I have a VM property called "BackgroundColor" and I change it to 0xFF0000; if I use a Binding to set the Background.Color property of my Window to whatever "BackgroundColor" is in my VM, WPF will notice the new value of Background.Color in my View and repaint my window for me (nice and red). This is a straightforward example, but bindings can be created for very many properties in WPF, and because of this, very much control can be had by just changing properties. There are a number of benefits to this separation approach including much better separation of concerns, testability, and resilience when changing the UI. Notwithstanding the above, WPF can still offer direct pixel manipulation when desired (via RenderTargetBitmap) but this is widely considered a feature of last resort. WPF also offers a more Win32/WinForms like experience by allowing you to handle WPF events like they are WndProc messages and performing logic in the control itself. Due to the power of styles and binding, however, these approaches are often considered suboptimal. EDIT: I should add that this doesn't talk much about what is below the VM layer: the Model. There are stronger analogs between .NET objects and COM objects and it should be easier to pickup on, but it really is a large subject unto itself.
This has to be the single most comprehensive comparison between Win32 and .NET I have ever read. I cannot thank you enough for providing me this ample Rosetta stone.
Right on! I agree, existing tutorial material doesn't go far enough comparing all the UI stacks on Windows. I'd imagine it's a surprise to authors that some of us have lived through 3 or 4 different UI stacks, and really would love to anchor the new concepts in things we already know! Feel free to PM me if you have specific questions, and I'll offer what pointers I can.
You're welcome, tell me if you have any issue.
MVVM - It's a design pattern. WPF - Instead of .designer files with code generated classes, you have an XML file (xaml). C# has events, similar to COM events, where you add and remove listeners. You can even use COM objects in your C# projects via the add reference menu. You can also pInvoke your Win32 libraries from C#. Try reading through the [tutorials](https://msdn.microsoft.com/en-us/library/aa288436%28v=vs.71%29.aspx).
&gt; Functional programming is an advanced concept for developers who are already very familiar with the basics of the widely-used design of OOP. At my university, they teach functional programming first (using ML), and OO programming only much later on. The first year functional programming course is used as the basis for many other courses. IMO, neither FP nor OO programming are more advanced than one another, they are just different, and require different ways of solving problems, especially if one is using a pure functional language like Haskell.
&gt; IMO, neither FP nor OO programming are more advanced than one another, they are just different, and require different ways of solving problems, especially if one is using a pure functional language like Haskell. I agree, but if you want to land a job as a developer the chances of getting hired at a company doing OOP over functional programming is far better. Teaching both is fine, but to get computer students in a "functional" mindstate before they learn the basics of OOP would seem to be the wrong direction to me, with the state of the industry at large in mind.
Dapper derives its performance from caching both reflection information and generated functions. It doesn't appear that any of the reflection operation results in this library are cached. Something to consider.
I'll look into that
An event in .net is basically a callback function. In C you can pass a pointer to a function that you want called when something happens, and an event is basically this same mechanism. The event is a delegate (a typed function pointer) and when you "subscribe" to the event you are adding the function you want called to the delegate's internal list of functions. These are then called in turn with the parameters you see in the "handler" function signature. In the handle function you perform the behavior you want to do when the callback is invoked. Events are often used to communicate some state change you want to be notified of, for example when a file copy operation completes so you might notify the user by changing the UI.
PropFacEventArgs is a "struct" with date, code, a message, and the context of the event (an enum). So my handler would have some sort of switch inside the event handler based on the code then? I figured I'd have to make a new event handler for each one of these events.
Wait. How can you have an installer for UWP apps? I thought you could only install UWP apps through side loading, or the Windows store. 
How do I make that into a constructor? I need to create a reference to it for use in my application.
An event handler is actually a collection of delegates, (which is why the += operator is often used) I would argue that a func/action/predicate is more akin to a function pointer in C except that they are typesafe whereas C doesn't give a damn.
I see. Since I'm using that other assembly, would I need to have a using PropCompany.PropFarmEngine; at the top of my class? I only ask because the way I understand it, this event handler needs to be inside their class in order to receive events from it, but I don't have access to their source, so I can't do that.
It's a good idea, but you don't strictly need to. As long as you have a reference to the assembly you can refer to the types in that assembly by using the full name, including the namespace, like `PropCompany.PropFarmEngine.PropFacEventArgs` but that gets tedious really fast. Adding the using statement at the top lets you reference them without the namespace, so just `PropFacEventArgs` will find the type correctly. 
As long as the class and the event are public you can easily create an instance of the class and subscribe to the event. Adding the using statement just means you don't need to use the full name space path when referencing it.
It's actually almost as simple as you're saying. Setup your web site, and deploy the files. Change the connection string to point to your new server and off you go. Your database migration will take place the first time you hit your site or any endpoint. From there on, not to get too deep into it, as long as the models don't change your auto migrations won't happen again. A good example of doing this is setting up a canned MVC app with individual authentication. You'll see that upon registering a user for the first time code first creates the initial migration. But as long as all that stays the same, you're good to go. Now initially seeding the db and all that is a different story. 
Yes, it is almost that simple, but over time you can make it even more simple. I chose a host that has WebDeploy configured, and use the free instances of Visual Studio Online to check in my code and trigger a build. Once the build completes it uses Web Deploy to push my app to the cloud. I would also look into web.config transforms as they will make your life a lot easier.
Don't worry about setting up the database first. It'll do all of it for you. 
I've had a similar feeling when looking for log tailing software using baretail for the last year. I'll give this a try and send some PRs for anything I can. Good job. You thought of adding in any specific functionality for data types as JSON is a common logging format these days?
Why not just use NPoco. It is superior. https://github.com/schotime/NPoco
This is excellent. I have several log files I monitor constantly during development (not my design choice) and I've been piping their output to [PaperTrail](https://papertrailapp.com/). Your app makes this way simplier.
&gt;occasionally they get stuck in a bad state and wont refresh to get into a good state. This is the problem and the best place to fix it.
This doesn't directly address the way you want to do it it, but why the complexity? Just run a service on the box that checks to make sure sharepoint is responding, and if it stops, kill IE. When it starts responding again, spawn IE. Maybe there's a reason you can't.... but... starting a local app through IIS just seems crazy to me. Perhaps you could even monitor the sharepoint farm with ajax, then refresh the page every so often until sharepoint responds again. 
ignore the sharepoint farm. there is no fixing it. Also you're not answering the question your just coming up with your own solution. Given our infrastructure its the best solution. 
Stop trying to change the problem being solved. 
All I can say is that if you find a way to do this, please report it as a bug to Microsoft. Cause you just opened a huge door to remote code execution vulnerabilities.
From his description that is exactly how I took it as well. "The server being up, but the page down." Just really adds confusion. 
Have you looked into trying it with config protected section?
I'm not even going to ask why. What you're doing sounds like a horribly, terribly bad idea, but... Most service processes can't spawn UI elements, even by spawning a child process. If you absolutely MUST do this bad idea, you'll need to go to the services manager (services.msc) and open the properties page for the IIS service. Under "Log On", there's a check box "Allow service to interact with the desktop". That checkbox allows a service to spawn UI threads, and *should* solve your problem...or allow you to cause yourself more problems, depending on your perspective. :) 
Nice, didn't think of that. If he did that though, in order to run IE in the users context, would IIS Service have to run in that context as well, or would running the app pool under the user context work? 
Why not add a third application responsible for [starting iis](http://stackoverflow.com/questions/4958799/how-can-i-programmatically-stop-or-start-a-website-in-iis-6-0-and-7-0-using-ms) *and* starting IE?
Alright so I was able to remote into my work PC. 1. IIS Admin is not used for IIS7+ 2. WWW Publishing Service is what's used. I tried flipping that "allow interaction with desktop" no dice. I tried enabling it on a series of services that are inter-related. No dice. It is however a good starting point, but doesnt seem to work in my case. is there a specific service that I should be using (IIS 7.5) that I havent dug into yet?
Well done! I'll be forking this one. 
Is your IDE elevated ("running as administrator")? Windows prevents elevated programs from receiving drag and drop events from non-elevated programs (such as the Windows she'll).
Seems more like a complement. I have quite different methods, but I can use it for inspiration. 
Baretail has also been the tool which I had been using and pleased to say I am glad to see the back of it. I had not considered JSON (or other data type) style logging but I see no reason why I could not introduce some mapping / schema functionality. Feel free to raise an issue request on github and if possible get me some sample logs
Thanks. Your feedback or suggestions will be welcomed
this thread here contains an answer to your question: https://social.msdn.microsoft.com/Forums/windowsdesktop/en-US/f8f91e8f-5954-43a7-8bc4-80ed2ff1e3b1/allow-service-to-interact-with-desktop-does-not-work-on-vista ( three quarter way down a Abdollah Kokabi answers) there is also an discussion going on why or why not it is a bad idea to spawn a gui app from a windows service (like IIS)
Why don't you PM me a more detailed explanation of what you're trying to accomplish, and I may be able to help more. I promise I'll only editorialize a little on how bad of an idea this currently seems. ;)
&gt; The next step depends a little bit on requirements. Can someone say "give me major 2nds in groups of 2, moving in minor 2nds", giving a sort of back-and-forth sequence like C,D, C#,D#, D,E, D#,F,...? Thanks for your response, this is great! Yes, the above could happen. Is that back-and-forth sequence tough to implement?
At first I thought it would be (I was going to use alternating Skip and Take to get each group of notes), but it's more flexible to just have two "from" clauses, which should handle the back-and-forth just fine.
I think ill do the 8 tables. In all the tables where it name what do you mean by that?Also Would COlorID, StoreID, SizeID etc all start at 1 and go up?
Okay so Itook your advice and made all the tables and numbered them and updated them. So I would now link them somehow? Thanks for all the help btw!! You are a lifesaver!
You link them with the foreign keys.
http://imgur.com/Q6JQKMb A link to see where I am at!
what the heck is zip? "Applies a specified function to the corresponding elements of two sequences, producing a sequence of the results." https://msdn.microsoft.com/library/dd267698(v=vs.100).aspx
You can't use C# code in external JS files, so this line $.getJSON('@Url.Action("Months")', { year: selectedYear }, function (months) { in your site.js is a problem. If you check the source in your browser you'll see that it comes through unevaluated. You can add the URL as a data- attribute on the year dropdown in Index.cshtml: @Html.DropDownListFor( x =&gt; x.Year, new SelectList(Model.Years, "Value", "Text"), "-- select year --", new { data_postback_url= Url.Action("Months") } And then parse it out in the change handler in site.js: var url = $(this).data('postback-url'); $.getJSON(url, { year: selectedYear }, function (months) { 
Ever try [SwiftTailer](https://github.com/dasjestyr/swifttailer)?
Awesome! Thank you for the links.
No problem. It's a cool idea, and as you can see, something others before you have tried. I just added a new link with examples done in python and javascript. http://www.ghacks.net/2014/01/09/ultrasonic-communication-chat-client-using-sound/
Your design is broken. You should never need to do this. There isn't going to be a "nice" fix for this one. If you cant fix it by css instead, and if you REALLY need to do this (as i said, bad system design) you should be setting the visibility in the code in the master (page that owns the control) and TRIGGERING it externally. Eg, have a : bool headerVisible = true; And then have the master page set the visibility based on that variable near the end of the page cycle Or create a SetHeaderVisibility function.
Pages should not be dependant on specific code/controls in another page (including master page-child page relationships) Setting / getting properties is one thing (should ideally be avoided, sometimes unavoidable) , directly accessing literal page items in another page is a whole other world of broken design.
Post it to chocolatey.org
I will do soon 
Azure
I had a look at most of the shared hosting providers, but none of them were really what I was looking for (bad support, uptime, overselling their servers, ...). I now have my own VPS with Plesk installed on it. Maintenance of a windows VPS is not that hard. It's not a cheap option for 1 website, but you can host multiple websites on a VPS, and if you notice that you are using most of the resources, you can normally always upgrade your VPS configuration. If anyone else knows a decent (EU based) shared hosting provider, please tell me.
AWS, Rackspace &amp; Azure. 
I second Fody costura. I used to use IlMerge but ran into quite a few problems. Costura is more elegant/easy to use and seems to work better with multiple assemblies.
For viewing apps in progress, either a VPS or a small server in my DMZ at home. For actual hosting, Azure usually since they can handle their own hosting costs.
It could be cheaper in some cases.
Upvote for SmarterASP.net. Small company, but good software and good prices for .NET sites.
[Winity.io](http://winity.io) VPS
Then what you are saying flies in the face of virtually every book on ASP.NET out there. Almost all of which, for example, recommend doing things like adding `runat="server"` to your &lt;head&gt;, &lt;link&gt; and &lt;script&gt; elements in your master pages so that you can do things like change URLs on the fly or even bring in whole chunks of additional HTML into the master pages from the child pages. Please explain that, because that’s exactly what I am doing here -- trying to use the .Visible functionality to hide the DIV tag instead of trying to modify some other aspect like its URL. What I was doing was working with simple Master/Child pages, but now that I have introduced sub-master pages this seems to have broken. Edit: sorry, first thing in the morning for me. Wording above, addition below. &gt;Basically, master pages are nice for templating your general design. That's it. Not for handling logic. My master and sub-master templates do not handle much logic, and what I am trying to do here *is* to keep logic out of them. The sub-master has the DIV that needs hiding on only one page out of dozens. I have added the `runat="server"` to it with the express intent of accessing it from the regular page in question and using the logic on the regular page to hide it. Nothing exists on the sub-master page or its codebehind to deal with this aside from the `runat="server"`.
By installing it? I mean, my advice would be to use Chef to deploy ASP.NET to a stock Linux AMI, but that might be overkill depending on your needs. You could just install it and snapshot an AMI, although that has some long term maintenance considerations. [Installing ASP.NET5 on Linux](https://docs.asp.net/en/latest/getting-started/installing-on-linux.html).
Pretty sure Digital Ocean does not support .NET.
thanks for the tip! i was looking for something like this and will definitely try their free host... ;-)
Arvixe
Definitely this. It's just to damn easy.
Looks useful. I'll check it out. Thanks!
Personally, I would always use NET controls instead of just adding runat=server to an html tag. It gives far more flexibility. Want a div? Use asp:panel Want a select? Use asp:dropdownlist Etc etc As I said, the main problem you've got is the design structure itself. Calling code from one item to another one a few levels away will pretty much always cause problems. If you REALLY need to (and it's REALLY rare you would need to do this) , I would always only talk to the next level in the design. A page would call an event or property of its containing sub-master, which would react and pass an event/property change to its master. Don't try to communicate directly over multiple levels. A constantly changing H2 tag is a good example of something that should not be in a master page though.
The h2 tag itself does not change. Across dozens of pages, it needs to be hidden only *once*. The h2 *itself* is *very* static. Its *content*, on the other hand, *does* change on a per-page basis. But that has already been handled, and it continued to work well even after the change from single master to master/nested master.
Cheap, good performance for what you pay for, excellent dashboard, stable, love it 
So are these a replacement for a RenderAction?
I have 5 .NET applications running on Digital Ocean droplets.
I'm a fairly new C# developer, so I might not have this 100%, as I'm new to VS as well - we push directly to production on Azure, with different slots that allow us to swap if necessary. 
Slot is basically an instance of the site, I want to say its analogous to a subdomain? Or utilized through a subdomain. not 100% on that. We have a "Testing" slot, an "Acceptance" slot, and a "Production" slot. For the most part, we push to the testing slot, and then move to acceptane and then production when ready, but sometimes we will push directly to production if we really need to. Rare, but it happens. 
Do you use a linux solution with mono? Are you using windows? Could you give me some more details? https://www.digitalocean.com/help/technical/general/ Do you offer Windows servers? &gt;No, we do not provide Windows-based servers.
[FUCK IT, we'll do it live!](https://media.giphy.com/media/q7UpJegIZjsk0/giphy.gif)
Iaas or Paas?
With large app's there is a continuous integration doing all the builds when any member of the team checks in changes to source control (I really like TeamCity for CI but TFS can do this as well). This can also do a deploy in some cases If you're really fancy your contentious integration service just does builds and unit tests and then deployment is handled by a deployment service like OctoDeploy or Buildmaster. Doing this seems really heavy but when it setup correctly you can create a proper deployment process (ex. Dev Server -&gt; Staging -&gt; Live) and you can roll back any of those servers to any previous version of the app. for small apps: [FUCK IT, we'll do it live!](https://media.giphy.com/media/q7UpJegIZjsk0/giphy.gif)
You're on the right track. Put price in the SKU table (different stores will have different prices for the same item). Can you elaborate on Style? Is that a type of shoe or what do you mean by that? You also need a Store table.
it all comes down to the big red button. Does it really matter where that button is? 
http://imgur.com/88ODqD3 So this is the basic idea. I need to have a those 4 drop down boxes select and create a details view from the database when clicking the submit button. It can pop up right there. The store and prices are obviously made up. Any ideas? I changed most the things you said!@
Nowhere that I've ever worked. FWIW, typically you get it to QA (publishing would work), QA blesses it and passes the baton to operations who handle the migration.
It's not only safer, it's defensible in that it is a practice that can withstand any audit, assuming it's done properly. Rebuilding after test and then publishing has so many holes, so little trace-ability, you don't ever want to do it. I can not imagine a valid argument for not publishing properly tested files. It sounds like a sure-fire way to lose one's job to publish untested production files.
Yes, but you'll need to provide more details about what you're trying to do and what you have attempted so far in order to get a useful answer here.
You could also theoretically make a docker image of it and deploy with elasticbeanstalk.
This is generally not a good practice. Even on a separate branch it still is fraught with issues. 
I was laughing my ass of at this and am still not sure if it was a joke or autocorrect.
For simple side projects (e.g. you're the only dev) where you're not worried about an audit trail, conflict resolution, or user anger at a bad migration, simply using VS to migrate to production is fine. But, for a company intranet or customer facing internet app/api, you really should have a defined process that's reversible and repeatable. As others have mentioned, there's tooling that can certainly help in that regard (google "continuous integration"), and the depths you go to are largely defined by your particular needs/situation. Some places have strict audit/documentation needs and/or separation of concerns (e.g. where devs aren't actually allowed to migrate anything to staging or production).
^ What this guy said. Anything else is nuts if you're serious. We do 4 levels of releases. Development (free for all), Test (build/deploy), Staging/Final QA (build/deploy), and Production/Release (deploy from Staging copies). Everything is built from sources. (C, C#, and others) Nothing is checked in without a work item. Builds are deployed by someone other than the programmer. We've done this for 12 years without problems. We've used everything from homebrew scripts to Microsoft Release Manager and Build Manager. Same process, different tools. Even *emergencies* can be handled -- if you do it right. (In fact, that's when you should stick to the process even more.) We're in the financial business and our process is audited regularly. Our software department always gets a "well done" with our methods, and are used as a model. Companies and departments that don't follow this, well, let's just say their audits go more... poorly. 
I don't think using slots for a testing environment is a good idea. They are designed as a staging environment so you can deploy some (already tested) code, give it a sanity check, then swap it into production. If anything goes bad, you can swap the previous known-working instance back. I would recommend a seperate TEST web site (ideally with it's own database) for proper test execution. 
oops! proof reading skills, not so good. ty
We do the exact same thing. The same set of binaries go from Dev to QA to UAT to Prod. We embed the git SHA commit in the AssemblyInfo, in addition to the version, so we can easily trace every it back to the exact commit that it was built from. The few times we've had to a do a production hot-fix, it still went through that exact process, it only takes about 15 minutes to promote through the entire sequence.
would probably depend on your CI environment to set that on build.
Set the [AssemblyInformationalVersion](https://msdn.microsoft.com/en-us/library/system.reflection.assemblyinformationalversionattribute%28v=vs.110%29.aspx). Unlike AssemblyVersion and AssemblyFileVersion, which take a tuple a 4 UInt16s, AssemblyInformationalVersion can take a raw string, so we just shove the SHA1 code in there
Fair enough. The purist in me still feels weird about the view CALLING for things without the controller as the intermediary, but I guess I'll just have to get over that. They've kind of merged the idea of Html Helper and Child Action here, and added the ability to do DI with all of it, so really my only objection is that the controllers are not the only top level components anymore and it kind of breaks the old MVC separations of concerns (e.g., I never would have had a partial view, html helper, etc. reach back for data, rather I always treated the flow of data as unidirectional here, now I'll have to actually remember to check these "View Components" as well when tracking things down). Seeing them as a new RenderAction though does kind of make me feel better about them though.
vultr.com excellent prices and haven't had any issues with them. I even saved on the costs by using my own Windows Server 2012 R2 ISO and MSDN license. 
When they want to give me production credentials, I refuse. When they must, I dare not store them anywhere least of which is visual studio. Production is a special thing. I ask for twice the testing when pushing directly to prod and I never click the button myself. If this is something you have created yourself, and you feel confident... Publish from VS. If your butt is on the line, then at the minimum have someone else turn that key with you before your let it loose on the world. (And do it at a downtime, notify if there is no down time and just generally be aware of your shit.)
It is very, very common. It isn't a good idea, but most shops don't have the time, skill, or interest in a proper automated deployment server. I've been on multi-million dollar projects where the client disabled even our most basic build server.
Azure is bloody brilliant, apart from their UI, which needs a little love (I'm referring to the new one...)
azure is very expensive for anything in production. edit because of downvotes : Just to be clear, unless you consider the free trial as viable for production , and no matter how good the quality of the azure stack is, there is no scenario in which a dedicated server is more expensive than a comparable counterpart solution in azure. even microsoft (or any cloud provider actually) shift the money discussion on everything else because they never pretended azure to be cheaper than a on premise installation unless you include the cost of maintenance, the wages of the team of sys and network admins etc cost which are 0 for the op's scenario 
No, the community seems to be moving away from other languages on the CLR aside from C# and F#. If I were you I would jump into C# as quickly as possible. On the plus side it's a really nice language to work with!
I've used www.smarterasp.net with decent results, azure would be nice but it's more expensive 
Depends on how you are building, typically I use a build extension to generate the assembly info with the SHA embedded in it with each build.
Smarterasp 
Beautiful.
i never sugested to buy a $2k server, thats completely absurd. You can rent something very decent for $15 a month
Can you decompose your app into smaller single-function apps and link between them? If so, that might work for me. &gt; * Apps must meet size restrictions(128k of compiled C# or F# code), include only managed code (not Objective-C/Swift, Java, or C/C++ libraries), and use Xamarin.iOS/Xamarin.Android, not Xamarin.Forms. Is Xamarin.Forms that useful?
I have no idea, never used Xamarian before. I just remember the price being ridiculously high in the past and thought I'd check out what the current price is. I posted my findings, that's all.
Their own IDE was terrible last time I used it. And one of the best things about c# is VS, so removing that severely cripples the dev experience.
How much are you willing to pay?
basically I need it to fetch data from the database
Pay attention updating the nuget packages of your test projects, the test runner for NUnit 2 is not compatible with NUnit 3 and you might end up with an unusable test suite (unless you also update the runner). 
My favorite part was the new Azure 2.8 SDK.
I would like to see everything from dnu and dnx roll up into dotnet, which I would then alias as dn.
Yes! It's a really nice framework, I've been enjoying it for a past couple months. I put together some posts here on some of the basics / new stuff: http://dotnetliberty.com/index.php/asp-net-5-vnext/
It looks like that's what they're planning right? &gt; The CLI tools present the "dotnet" tool as the entry-point tool. It provides higher-level commands, often using multiple tools together to complete a task. It's a convenience wrapper over the other tools, which can also be used directly. "dotnet" isn't magical at all, but a very simple aggregator of other tools.
asp.net sorry
Still getting invalid :(
yay!
Never, never, never, ever insert user entered content directly into a SQL statement. http://software-security.sans.org/developer-how-to/fix-sql-injection-microsoft-.net-with-parameterized-queries 
It's not clear from the text whether they're making all commands available from the new dotnet commands, or just the high level commands. If it's just the most used commands, that'll just be annoying.
Ah yes, you're right about that. If that's the case, maybe we can write a bash function "dn" instead of aliasing that would know how to delegate to the correct dnu/dnx/dnvm commands underneath. A bit pesky but should work.
Buying a server $500 or $2000 is completely irrelevant in op's case so i don't understand wtf you are talking about. 
Are there any hosting that supports .NET Core yet? E.g. Heroku, OpenShift, etc?
They've modeled it all after the node ecosystem mostly (with similarities to others like python, Ruby). I think dnvm and specifying a runtime version for your app and dependencies confuses a lot of people. The benefit is that you can have multiple versions of .NET hosted on the same machine, and you can cross compile your application for multiple versions. dnx and dnu are the ones that trip me up. I've remembered them as "dotnet execute" for dnx and "dotnet nuget" for dnu. They're equivalent to node and npm, which I use everyday. Even so, I try to run *dnx web* almost every time. I know it's like running npm scripts, but my brain is always working like '.NET me' and not like 'node me'. And that's knowing how they correlate to the other tools I have used regularly for years (and I use a *lot* of embedded npm scripts). I don't think it's too complex, maybe just too different from the previous .NET coding experience. Microsoft used to focus on minimizing context switches to the point that I've worked with many people who don't know where the client request ends and the server code begins. These new tools are a big context switch.
Put your inputs in a form tag and add a submit button. Pushing the button will post the selected values to your app.
I know this isn't a "proper" program, but still: - Beware of SQL injections (never insert user info into an SQL statement - use Parameters for this) - Do *NOT*. *EVER*. Save passwords in clear text. This is what hashes are used for. 
Thanks for the info.
Check http://www.asp.net/mvc/overview/getting-started/introduction/adding-a-view for correct usage. and the classes to link http://stackoverflow.com/questions/1444495/how-do-i-apply-a-css-class-to-html-actionlink-in-asp-net-mvc Sorry, on mobile so its easier to copy paste :)
Make the char a string before converting it to an int: (lol never-mind I didn't read the last sentence of your post xD) var myInt = 5231; var myList = new List&lt;int&gt;(); myList.AddRange(myInt.ToString().Select(x =&gt; Convert.ToInt32(x.ToString())));
 &gt; up until 4.6 Why, what changed? They added the new compiler platform called Roslyn they've been working on for 5+ years, and made a bunch of all round general improvements including one's to WPF. &gt; JIT ones (RyuJIT) and AOT ones (Roslyn) What? I don't understand how you could have got those mixed up they are entirely unrelated. JIT32 and JIT64 are the one's that have been around since the start. RyuJIT replaces JIT64 for 64 bit applications, it's that simple. Roslyn is simply a new compiler (that can target any .NET version). Roslyn is written in C# and VB.NET. It has nothing to do with AOT. Any .NET compiler (including the old one and Roslyn) emit IL. The IL then get's compiled at run time by either JIT32 or RyuJIT. &gt; Still the same languages -There are far too many compilers. JIT ones (RyuJIT) and AOT ones (Roslyn) -But the runtimes... ".Net Core, .Net CoreCLR, .Net Native" have become too many to get my head around. * .NET Core - A cut down and limited version of .NET, personally I'd use Mono because that's an actual implementation of the full .NET Framework. * .NET CoreCLR - The CLR used within .NET Core. .NET Framework full still uses the normal CLR. (It's worth mentioning CoreCLR has it's roots from Silverlight) * .NET Native - Think of this as NGEN but with more features, I guess. It currently is only supported for those crappy Metro apps, there's hope it may one day be used for desktop and web applications. &gt; e.g. 1: I want to create a standard Windows Desktop app using C#. What technology (compiler/ runtime) would I use. Again this highlights your misunderstanding of the whole thing. You use WPF. Just like you always have, the underlying compiler and JIT is irrelevant. Install VS 2015, and assuming you target 4.6 then boom, your using RyuJIT for your WPF application or whatever application your writing. If you set it to AnyCPU or 64bit CPU then your using RyuJIT. This explains most of it: http://blogs.msdn.com/cfs-filesystemfile.ashx/__key/communityserver-blogs-components-weblogfiles/00-00-01-36-93-metablogapi/0741.clip_5F00_image002_5F00_452042C7.jpg Edit: What the hell is going on, every time I check this post it keeps getting downvoted and then upvoted, every few seconds? Is someone really offended I pointed out how crap Metro apps are?
What about: myList.AddRange(myInt.ToString().Select(x =&gt; (int)Char.GetNumericValue(x)));
&gt; Also... I kinda hate this use of the word "isomorphic". Is it too late to avoid contaminating languages other than javascript with this usage? Agreed, and probably :/ 
Mono has had a REPL for some time. http://www.mono-project.com/docs/tools+libraries/tools/repl/
Have you looked at continuous delivery tools like octopus deploy, go/cd or Microsoft release manager?
+/u/CompileBot C# using System; using System.Collections.Generic; public class Test { public static void Main() { var i = 1234567890; var l = new List&lt;int&gt;(); while (i &gt; 0) { l.Insert(0, i % 10); i /= 10; } Console.WriteLine(string.Join(", ", l.ToArray())); } }
https://app.pluralsight.com/library/search?i=1&amp;q1=course&amp;x1=categories&amp;q=asp.net
Pretty sure scriptcs has a REPL. http://scriptcs.net 
Your talking absolute shit. The IDE is fine (on OS X, it does suck on Windows) and with the indie license, you can absolutely compile the samples. What you're doing is trying to build complex samples using the free edition which has the size limitation. I for one like that Xamarin ship real world samples even if that means you can build it without a trial or a license. 
Forms is pretty good for LOB apps and POCs. Lots of people hits issues when they push it to the extremes of what it was designed for 
http://www.asprangers.com/post/2013/09/24/Web-Deploy-command-line-(msdeployexe)-Scenario-bash.aspx I am pretty sure this is what you are looking for.
We only have a one year course, the time it would take to learn Java, just to make apps, is not worth it. But yep, I think Xamarin is the one we will continue with. 
Http://www.asp.net
 using System; using System.Linq; using System.Collections.Generic; public class Program { public static void Main() { var i = 1234567890; var explodedI = new List&lt;int&gt;(); foreach (char c in i.ToString()) { explodedI.Add(c - '0'); } foreach (var digit in explodedI) { Console.WriteLine(digit); } } } Alternatively, if you prefer linq, using System; using System.Linq; using System.Collections.Generic; public class Program { public static void Main() { var i = 1234567890; var explodedI = i.ToString().Select(c =&gt; c - '0'); foreach(var c in explodedI) Console.WriteLine(c); } }
Wow, cool! Thanks for the link.
&gt; Ionic Thanks :-) That looks really interesting
Unity 3d ?? you can build non game apps with it !
This. Also given how similar the languages are, the biggest change in mentality is the IDE. Correct me if I'm wrong but Xamarin licenses cost money, native android dev via Java doesn't.
I assume that you use parameters (?) https://msdn.microsoft.com/en-us/library/ff648339.aspx 
yup 
Then you're fine. 
Okay cool. I just do it as a hobby, and everyone says its the biggest pitfall, but that solution just seemed to simple. I felt like I was missing something.
&gt; It's a problem that has its roots in PHP where it started out being pretty standard practice to build sql queries dynamically from user input It's been a problem since long before PHP got popular. I'm pretty sure most of the Classic ASP apps that I worked on 15+ years ago were full of SQL injection vulnerabilities.
Just make sure you never EVER glue SQL statement strings together with variables which hold values that are indeterminate and/or come from user input. This goes for your C#/VB code as well as the code in your stored procedure. If you follow that one rule then you can avoid SQL injection. So if you find yourself building SQL statements with +/&amp; or concat/format/*printf/etc. then that's a red flag and you want to stop and evaluate what you're doing and evaluate the situation, get 2nd opinions, etc.
I remember using php 20 years ago in middle school geocities.
Mvc music store.
I didn't say PHP was newer. I said that it was an issue before it got *popular*. And CGI has (had) the same problems too.
This can be run on unix like OS?.
&gt;quite a bit older Not really. Php at best was released in 1995. At that time I recall it not being very good and not using it. Cold Fusion was also out then, it was better than php and some of the earliest ecommerce sites we worked on were written in it. Classic .asp came out around the end of 1996. Its performance was good and it was easy to work with and so we abandoned the other two in favor of .asp. tl;dr: Classic asp, php, and cold fusion were all released about the same time in 95-96.
Only if you are using complex SPs. If you keep them to simple CRUD SP then you should be OK. You don't need to build SQL on the fly, just use simple SQL SPs to pull the data then do the logic with the data in your web server code. Then use the simple SQL SPs to put the data back. There are a few occasions when you still do need to write SQL on the fly (usually with advanced search features against large data sets which you don't want to pull into your web server's memory to search against) but for 99% of everything simple CRUD SPs are fine and good.
I'd rather have my SQL along my code than in the DB. More convenient for release management and source control.
I read that thread earlier. My application pool identity was already set to what they suggested. I'm pretty sure the app pools were untouched so I don't think that was the issue
You don't put your DB SQL into source control?
As I recall it in the early days of the web, Microsoft was not respected at all. Everything was Unix based. There was no client side scripting yet, it was all static html rendered on the server. CGI was the dominant technology for producing dynamic html. Cold fusion was the first successful wysiwyg html editor (or whatever you want to call it) and became pretty popular with the business types despite most of the technical types hating it. Outside of the corporate world where almost everyone was self taught, PHP was by far the most widely adopted tech when it came on to the scene. It was decently good at manipulating text and that's all html was at the time, just a static document. The problem was that so many of these people knew absolutely nothing about security and didn't want to bother knowing anything about it. It just wasn't important to them and there was no one above them that knew enough about what the kids were doing to tell them otherwise. These were the kids that were providing all the air to inflate the dot com bubble. Terrible practices proliferated because as long as every one was making their imaginary money, no one questioned it. All of the tools sucked back then and doing things the right way was a ton more work than the easy way, so that's what people did. If you were doing things right, you were not keeping up with your competition and at that time, being first was the most important thing in the world. Asp and Microsoft didn't really start getting taken seriously on a broad scale until around the time of .net 2.0 (2004 or so). Yeah there were places like you were at that were early adopters but that was just a tiny slice of the Web server pie. By that time people with formal education in Web development were entering the work force and pushing on management to take security more seriously. Also the bubble had bust by then and extreme pressure to be first out of the gate had subsided some. That was the way things looked from the perspective of a non-corporate developer at the time, which I would argue represented the overwhelming majority of Web development at the time (it was too turbulent and risky an environment for most big companies to want to get in involved in yet). 
Are you running VS.net as Administrator? 
Event viewer mentions this: Faulting application name: vbc.exe, version: 14.0.81.0, time stamp: 0x5584f0f2 Faulting module name: s\SYSTEM32\MSVCP120_CLR0400.dll!__crtGetFileInformationByHandle, version: 6.3.9600.18007, time stamp: 0x55c4c16b Exception code: 0xc0000139 Fault offset: 0x00000000000ec4e0 Faulting process id: 0x23e0 Faulting application start time: 0x01d123b4df2f1608 Faulting application path: C:\Windows\Microsoft.NET\Framework64\v4.0.30319\vbc.exe Faulting module path: s\SYSTEM32\MSVCP120_CLR0400.dll Report Id: 1cdebe9f-8fa8-11e5-82ae-9cd21e5af3fa Faulting package full name: Faulting package-relative application ID: Problem with the compiler?
Yes definitely running it as an administrator
You've probably seen this thread, correct? http://forums.iis.net/t/1159648.aspx?Compiler+Error+Message+The+compiler+failed+with+error+code+128+ Edit: Also try this: - Create a new website, put basic page with Response.Write() in it and see what happens - Make sure your projects are configured to target the 4.0 framework in project properties (or whichever framework you're using that isn't 2.0). I've run into issues with this before. Wasn't sure how/why it changed, but it did. - Are app pools running under Integrated or Classic? - Does the app pool have 32 bit enabled? Switch it to the opposite of what it is, and try it. If it doesn't work, switch it back. I'll post more if those don't work. 
And testability.
That too but releasing a specific version is easier with the SQL along with the code. You only need to run DB upgrade/downgrade scripts for the DB structure and not the logic.
&gt; Asp and Microsoft didn't really start getting taken seriously on a broad scale until around the time of .net 2.0 (2004 or so). In 95 I was a partner and lead dev at one of the first web dev shops ever. We built sites for some rather large corporate clients, including some of the first eCommerce sites. In 95-96 a lot of what we built was static websites running on unix (solaris and later Silicone Graphics). Back then 98% of what we built was static. If we needed something dynamic we relied on CGI and Perl (gadz that was ugly). Cold Fusion was a server side scripting language that had code embedded with the html. It was quite popular for a while - I think even MySpace was using it until it collapsed. I think its even still around in one form or another, but I never see it as a sought after skill. The WYSYWIG tools you were thinking of might be Front Page? Dreamweaver? They all sucked and we rarely used them. We built an ecommerce site or two in Cold Fusion because the language allowed easy interaction with a database. (BTW from what I recall SQL injection attacks weren't really even a "thing" in 96.) Prior to Dec 96 Bill Gates and MS regarded the internet as a toy and even made a few of those quotable comments about it that turned out wrong. In Dec of 96 MS released IIS with Active Server Pages. In fact I think it even was Dec 7th (a day that shall live in infamy). We weighed all three technologies: Cold Fusion, .asp, and php. We looked at performance and things like server cost and ease of use. In early 97 we adopted MS, IIS, MS SQL and asp for all new projects. The servers ran Windows NT 4.0 on typical x86 desktop/server hardware. Honestly, it all worked beautifully, and it made our lives easier. We had little problems and found that it all worked a lot more seamlessly than the cobbled together unix stuff we were using. We still had some of the unix stuff around, but we relied on it less and less. From what I recall, when we looked at the server market share, unix had the bulk, but MS was fairly high - 30-40%. For a variety of reasons unique to us and the situation, we avoided .NET for a long time. I'm still not a big fan of webforms, and used php until a few years back when I started working with ASP.NET MVC. Man, what a long, strange trip its been. 
Yep. Mac and Linux and Windows. Runs against Roslyn and .NET Core, so any supported platform. And completely open source. 
Why not? You may want to use Linux as host for your web app because of cheap hosting, container support and many other reasons, but you don't need to force your team/product to learn a new rdbms because SQL server on Linux is not cool. Use what's best for you when it's best for you, not because you are committed to a stack. Besides, I could never leave SQL management studio for MySQL workbench...
I have a friend that works for one of the biggest companies in the world. He works on their intranet applications. It's all cold fusion. He hates it. It's all like 20 years of accumulated garbage. It's such a delicate mess that no one is willing to take responsibility for rewriting any of it so it just keeps getting more junk tacked on and becoming even more risky to rewrite. What sucks really bad for him is that's kind of all he knows and like you said, no one is looking to hire for that. At least he gets payed well. I've never worked with it but I had thought it was a full suite for authoring Web sites, both front end and back end. I guess I was wrong about that. I had a job to build a site and they wanted me to do it n Dreamweaver. It spit out the most horrific html I'd ever seen. I ended up just writing it myself in a text editor and the html was maybe one tenth the size and far easier to make changes to. Those were the bad old days. It's been a long time now since I've done front end Web work. 
I think it's [grammatically weird](https://www.reddit.com/r/javascript/comments/2y0mas/complete_isomorphic_react_app_in_less_than_5/cp5cfy4?context=3) and hope that the term can be replaced with "cross-tier" because at least that alternative explains what is similar to what.
Well, that just cinched it for me. Outstanding work. Thank you to the whole team. If they just made VS for Mac...?
Let me see if I get what you're saying. You have 3 drop downs that when you click the submit button, those dropdowns are populated with data from the database? Or are you trying to submit the user selected values of the dropdowns to your app when clicking the submit button?
Ok, so you want to take the data that the user selects in the dropdowns and then save it to the database. So are you held up at how to get the information from the user to the server side code or how to save it to the database?
Sprocs are very useful in the right scenario but I see them overused in scenarios where a minor code change would remove the maintenance of the sql database work.
He is my favorite of the lesser Scotts.
I did know about this but I am so up in Sublime Text I am a bit timid about making the switch. I should give this a try again for sure.
Not anytime soon. MS just released the core libraries for Linux. Not even close to releasing a dotnet VM or runtime that's native to IOS and Android. It will be a few more years - at the very least - before this happens.
you use an IDE. You may want to rethink that. real programmers code in vim /s 
Conversely, Microsoft has an open-source source-compatible [Objective-C compiler and runtime](https://github.com/Microsoft/WinObjC/) in the works for Windows right now. They're also working on an Android runtime for Windows, but AFAIK details haven't been announced yet. Hope this helps.
I disagree with your comment on performance, stored procedures will almost always perform faster than ad-hoc queries. SQL will pre-optimize stored procs eliminating the optimization overhead that comes with ad-hoc queries. That being said, I rarely use them in .Net apps, except for batch-type operations that require several database updates.
Is the degree schema the same for each campus? If the biggest barrier to integration is the data is simply in separate tables you will be fine. You can create an abstract Degree entity and have an implementation for each campus, which maps to the table. E.g. CampusADegree extends Degree and data is in table CampusADegrees - EF will work this out. I'm assuming it's not possible for you to combine the data at the database level - this would be the solution that makes the most sense. In any way, sounds like you just need a Service (e.g. "DegreeService") which has a method GetDegrees, which takes in a parameter (some campus identifier). If the degree schema is different, I would still go with a Service to abstract this away from the ViewModel and have it contain methods such as GetDegreesCampusA(), GetDegreesCampusB() etc. Simply decide which method to call from your Controller and populate your ViewModels with this data. Displaying the data will be trivial if schema are the same. If not - I guess it depends on if you want to implement a full-on framework for this. The easiest thing to would be create separate Views for each schema. You may be able to create one View if each schema has a simple sub-set of all the data a degree could have and decide to display fields or not if they exist. This may be difficult if each campus has different terminology i.e. "qualification" instead of "degree". Hope this helps.
More and more packages add support for core every day. It's a matter of time or finding alternatives. Looking at some open source libraries, I've found that very often there is already an issue filed on their github project page about Core support. In the responses you may get an idea if it's something they are working on already.
I'm not false starting on this until it's out and on version 2.5. It took old .net 15 years to be as solid as it is. 
They've frozen the Android product and most details of the iOS one are vague at best. Besides, the goal is to avoid java and objective c/swift and write a single app in c#, not the other way around.
I think it's just a matter of time. If there's an urgent need for some dependency and this dependency is open source, there's always a way to fork and work on .NET Core compatibility yourself :)
1) C# is statically typed, and the semantics of C# provide for rich application abilities within ASP.NET via Aspect Oriented Programming provided via Attributes. 2) Node sucks for CPU intensive work yes, and maximizing throughput is pretty hard. C# is better. C++ is better. C is (ever so slightly) better. ASM is better. Machine code even more so. 3) Yes you can have a career/survive on the open source stack. Also, most would consider Java/PHP to be part of that open source stack. Java and C# are much better at scaling than python/ruby/js etc, mostly due to compilation and static typing, and some where between the groups lies PHP, especially with Haxe's existence. 4) No it's not becoming obsolete. It's the language of choice for Azure and Windows, and can be compiled to JavaScript, IOS, Android, and Windows/Linux/OSX*. The ecosystem also only grows richer due to F# et al. 5) Java is where C# took inspiration from, and then C# left it in the dust in terms of language design and framework capabilities. Reflection API is where it's pretty damn apparent, along with reified generics (c#) vs type erasure (Java) Also, there are a bunch of ways to get around knowing a proper server language and a proper client language. But just learn C# or Java and Javascript (or Typescript if you decide to learn C#, these days it's fine and you'll survive in a Javascript world afterwards too). EDIT: Slight change for clarity.
1. dunno lol 2. Yeah, but like everything there's ways around that. Using C# with linqtosql is probably slower than pure sql queries ... but not as fast as pure C would be or assembly so why not learn that? Where does the abstraction stop? C# is a great language with a very mature base and Microsoft supporting it, people like to shit on MS but they're still a very large corp who do at points in time figure out their shit and come up with something awesome. This is one of them. 3. Yeah, C# is open source too now though (wpf (pls m$ make this oss)/webforms/winforms aren't). https://github.com/dotnet 4. No, lots of people will have you think that but they're either lying or don't know what they're talking about. WPF hasn't received any new controls for a while but remains supported and doesn't really need any because you can make everything yourself, unlike winforms. Winforms is old and pretty dated now, for a heavy app, use WPF over it. Wpf in the last iteration of .net did in fact receive some updates. 5. Java as a language is alright, imo the windows guis are absolute shyte compared to wpf, I've used swing and AWT and they were both really clunky and looked old, that said it's been a while and if they supported gtk it'd be fine. Wpf at least looks fairly new and supports hw acceleration/dx accel (apparently java guis do too). Java has had lots of security issues of late and although Oracle have fixed them, some have taken time. That said I've got a mate who's doing a major webapp in STS + a few javascript frameworks and it looks real schmick, is quite secure and the only downside is it takes a while to start. Irl it's started once and runs forever or instances are onlined/offlined as they're needed so that's really not an issue.
Probably the best solution for the problem
As of the most recent version, the short answer is yes. They just added debugging. So you can add breakpoints, watch variables, step through stuff, etc...
Then definitely check out the OmniSharp project if you haven't yet.
To sort of echo everyone else, I suggest moving over to the new framework and targeting 4.6 or 4.5 just as you have before. I personally thought there were many improvements to project organization/building for my RESTful Angular app that it TOTALLY was 100% worth it, can't even look back to Web API 2. Then in the coming year as more of my requirements gain .NET Core support, I can start the process of switching to targeting to that. 
wat
&gt; What you're doing is trying to build complex samples using the free edition Yes, that's exactly what he said. How are you supposed to experiment and get a feel for the platform before purchase, if the free version is utterly incapable of even building vendor-supplied sample code?
it's because I really don't know which to choose
&gt; Can you afford a rewrite after the time constraint (if there's one). Wandering by... What do you mean by that?
Is MVC really that much faster than WebAPI?
There are a few points to consider. * Maintaining large libraries of legitimate Microsoft software licenses can be expensive. Windows, Visual Studio, SQL Server, etc. * .NET is resource hungry compared to other open source alternatives. The servers will require high-end hardware if they are servicing large numbers of concurrent requests. * A scalable and redundant database cluster (SQL Server or otherwise) requires a lot of powerful (and pricey) hardware. None of these points should really stop you from choosing .NET for your project, but they're important to consider. You can apply for BizSpark to avoid the software costs for 3 years, or so. Likewise, the hardware costs you won't really have to worry about, too much, until your product has grown. Ideally, by that time, you can find the money to pay for everything. At my organization, in our 6th year, our .NET server bill per month is nothing to scoff at. We previously hosted on Amazon EC2, but determined that it was not cost-effective to provision a SQL Server large enough to handle our needs. We ended up switching to a dedicated and managed hosting provider in order to reduce our bill to the _still rather large_ number that it is today.
[Image](http://imgs.xkcd.com/comics/efficiency.png) **Title:** Efficiency **Title-text:** I need an extension for my research project because I spent all month trying to figure out whether learning Dvorak would help me type it faster. [Comic Explanation](http://www.explainxkcd.com/wiki/index.php/1445#Explanation) **Stats:** This comic has been referenced 65 times, representing 0.0729% of referenced xkcds. --- ^[xkcd.com](http://www.xkcd.com) ^| ^[xkcd sub](http://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_cx8ubio)
Don't listen to them about stored procs. People who don't understand SQL get this silly notion that everything should be done in C# code. Use procs when they make it easier, use C# when they make it harder.
Relevant XKCD: http://xkcd.com/378/
C# and Java are so syntactically (a word?) similar, it really doesn't take long to apply one's C# skills to Java. Especially since you're only learning a slice (the Android libraries) of it. Download the Android Studio IDE and you're golden...for free.
Output: 1, 2, 3, 4, 5, 6, 7, 8, 9, 0 [^source](http://ideone.com/Gm5GiD) ^| [^info](http://www.reddit.com/r/CompileBot/wiki) ^| [^git](https://github.com/renfredxh/compilebot) ^| [^report](http://www.reddit.com/message/compose?to=compilebot&amp;subject=Report%20Abuse&amp;message=--report%20https%3A//www.reddit.com/r/dotnet/comments/3th61q/how_to_fix_my_incorrect_solution_for_a/cx6bf5x%20Include%20your%20reason%20for%20reporting%20here.) 
Output: 1, 2, 3, 4, 5, 6, 7, 8, 9, 0 [^source](http://ideone.com/wBynAh) ^| [^info](http://www.reddit.com/r/CompileBot/wiki) ^| [^git](https://github.com/renfredxh/compilebot) ^| [^report](http://www.reddit.com/message/compose?to=compilebot&amp;subject=Report%20Abuse&amp;message=--report%20https%3A//www.reddit.com/r/dotnet/comments/3th61q/how_to_fix_my_incorrect_solution_for_a/cx6bf5x%20Include%20your%20reason%20for%20reporting%20here.) 
I've seen SQLs limitations on dynamic queries get worked around and actually create new sql injection attacks even though parameterized queries were being used.
If you've got any sort of dynamic conditions, such as a search page, then ad-hoc queries can be a lot faster.
An event. 
Indeed you can, here's an example I wrote to call 'cpuid' directly from c#: http://stackoverflow.com/a/7964376
It's a common trick for video games. I have no idea if it actually slows anyone down...
I don't think it slows anyone down at all. Even if you're unfamilliar with x86, the above code is just going to be MSIL anyway, ILSpy it and disable anything that changes the x86 code.
True but again, you could just edit the MSIL to set those global values. Even if you don't know what the values are going to be, it's not difficult to see what they are at runtime.
/r/angularjs might be a better place to ask. 
k thanks. I think I just jump right into angular 2.
It would likely be useful for writing trampolines for runtime method redirection, so that you could "redefine" methods at runtime. This is incredibly useful when used in REPLs.
I have heard, on a few podcasts with Google devs, that if you want to publish sometime next year that 2 is fine. That is probably just cya. It seems stable but that doesn't mean there won't be a big change or two.
Sweet! I'm about to have to do this myself. I already tried to just change stuff in project.json and that wasn't sufficient so I put off the upgrade until later. Your article will save me a good amount of time. Thanks!
Completely ignoring that the tools `dnx` and `dnu` will be replaced.
Source? I haven't heard that, and it seems extremely unlikely now.
They will be going to a full dotnet system. They demonstrated this for ubuntu in the RC1 demo video from Microsoft. Expect sometime next year, you'll be able to compile natively to linux, windows, ect using "dotnet"
Slowness comes from indexing the file. I will definitely speed this up as my priority
Wow this is useful. Why isn't it on Chocolatey?
The easiest way is to use a SQLDataSource as the source for your DetailsView. Then use the drop down lists as ControlParameters for your SQLDataSource. Here is a link that will help [Using Parameters with Data Source Controls for Filtering](https://msdn.microsoft.com/en-us/library/xt50s8kz.aspx).
There must be a problem with the encoding. I allow the built in StreamReader.CurrentEncoding to determine the encoding but it obviously does not work perfectly. Would it be possible for you to create an issue here https://github.com/RolandPheasant/TailBlazer/issues and attach the file to the issue? That would make it easy for me to do a diagnostic. Thanks 
For free? [ReportViewer Controls (Visual Studio)](https://msdn.microsoft.com/en-us/library/ms251671.aspx) [Report Viewer in asp.net ](https://www.youtube.com/watch?v=Y0MV7NDNc-o)
Quick thought: if you're meant to be tailing files with this, why load the entirety of a huge file by default? Say you're looking at a 1GB log file containing logs for the last few months*, you may only really care about the previous ~500 lines or so, plus anything coming in the future. Maybe add a button if you scroll up enough to "Load More" that indexes and loads the rest of the file. \* rotate those logs, though!
I was an angular dev on contract for about 6 months. I've done a little research about angular 2, but since it's still changing from release to release it's hard to get on board with it right now. I'm currently learning react though, and have been enjoying it so far!
I saw that but i didnt know how to get it working.
The example is very straight forward, what did you not understand? string path = @"c:\temp\File.txt"; //string array containing each line of text in the file string[] readText = File.ReadAllLines(path); Just populate your text box with readText.
I see. Well it's a great program! Thanks for sharing it.
can react do background services, listen to event broadcasts ? isnt it just like phonegap?
Don't forget to set the Multiline property on the textbox to true.
Read the Parameters section of the documentation that was linked: *append* Type: System.Boolean **true** to append data to the file; **false** to overwrite the file. If the specified file does not exist, this parameter has no effect, and the constructor creates a new file.
will do
What is this index? Is this some legacy Windows timezones thing?
I'll run that link you sent me. My global looks like this. { "projects": [ "src", "test" ], "sdk": { "version": "1.0.0-beta5", "runtime": "clr", "architecture": "x86" } } With a schema as http://json.schemastore.org/global
Hmm, the latest global.json should look like: { "projects": [ "src", "test" ], "sdk": { "version": "1.0.0-rc1-final" } } Looks like your SDK version is out of date.
I see. Alright. Yeah I downloaded my current version of visual studio about 3 months ago. I decided to run a repair on it with the install exe just in case. I'm hoping that it should update it. If not I'll have to reinstall it. So its going through the repair right now, may be a bit. I'll be sure to reply with what results I get. Thank you for your help. 
~~The log4net reference is jacked. I'm trying to fix it, but I'm having trouble. It's missing and nuget can't restore it. It's kind of a weird issue.~~ ~~*edit*~~ ~~Looks like the log4net package is missing from the packages folder. Are you sure it's checked in? Everything I've done to try and restore it has failed.~~ Finally got it to work. But for some reason, it just wouldn't accept log4net 2.0.3. Had to remove 2.0.3 from the config and install 2.0.4.
Those steps fixed it. Thank you so much. I'm being told by a friend that this tutorial is supposed to "have a lot of errors because VS 2015 is new and the tutorials aren't up to date". So I'm hoping that this will also fix those errors. 
Thanks. Yeah I tried to go through it again, but still errors. There are a lot of differences between our two files. [I got down to the entity framework] (http://aspnetmvc.readthedocs.org/projects/mvc/en/latest/tutorials/mvc-with-entity-framework.html#configure-entity-framework) and the startup file looks way different from the one I'm using. Mostly the "using" statements at the top. When I replace them with the one he's using, just more errors. Were supposed to do this for a project. We were basically told "Do this tutorial. It is outdated and has errors, you're supposed to figure out the errors.". Considering we never really worked with this stuff and the most we did was c# programming, everyone is lost. Talked to the smartest kids in the class and they have no idea what to do. Very frustrating, haha. I suspect that since the tutorial is outdated, there's quite a few things in different files that need to be changed. Nobody has any idea which one (in our class at least). 
Application base path probably doesn't need to be passed into the configuration builder. This was a change in the default web application template between beta 8 and RC1. Jump down to the Startup.cs section I wrote about here: http://dotnetliberty.com/index.php/2015/11/23/asp-net-5-beta-8-to-rc1-annotated-diff/ You can probably safely remove appEnv altogether from the Startup constructor.
The constructor of `ConfigurationBuilder` does not accept any arguments, but you're trying to pass a string. You need to call the method `SetBasePath` instead. Be prepared for a lot of situations like this. There are still breaking changes happening, and a lot of documentation (especially blog entries) are deprecated and wrong.
Haven't really done anything honestly. Just going through [this tutorial](http://aspnetmvc.readthedocs.org/projects/mvc/en/latest/tutorials/mvc-with-entity-framework.html#add-entity-framework) and making the changes it has. So all my code is whatever the default given code is. The thing I'm seeing is that this tutorial seems to be using an older version of visual studio. I looked at his github and it's using "1.0.0-beta8" while mine is "1.0.0-rc1-final". I'm not sure where/how to post the code though. Since, from what I'm seeing, github needs a subscription and I'm not sure if I'll get the full use out of it. I mean some differences I'm seeing (after doing the whole dvnm upgrade thing) is that I don't have a config.json file by default. I have to make one. I've been experimenting around and the part that had mostly errors I was able to get down to just one error. public void ConfigureServices(IServiceCollection services) { // Add framework services. services.AddMvc(); services.AddEntityFramework() .AddSqlServer() .AddDbContext&lt;BookContext&gt;(options =&gt; { options.UseSqlServer(Configuration["Data:ConnectionString"]); }); } The thing that is giving the error is services.AddEntityFramework(). The error is "'IServiceCollection' does not contain a definition for 'AddEntityFramework' and no extension method 'AddEntityFramework' accepting a first argument of type 'IServiceCollectiong' could be found (are you missing a using directive or an assembly reference?)" Now it has potential fixes/suggested fixes. However when I do those it just creates more errors then I have now. Something I noticed compared to the tutorial is that the "using" statements at the top are different. The tutorial has the following. using Microsoft.AspNet.Builder; using Microsoft.AspNet.Diagnostics; using Microsoft.AspNet.Hosting; using Microsoft.Data.Entity; using Microsoft.Framework.Configuration; using Microsoft.Framework.DependencyInjection; using Microsoft.Framework.Logging; using ContosoBooks.Models; using Microsoft.Dnx.Runtime; While mine looked like the following. using System; using System.Collections.Generic; using System.Linq; using System.Threading.Tasks; using Microsoft.AspNet.Builder; using Microsoft.AspNet.Hosting; using Microsoft.Extensions.Configuration; using Microsoft.Extensions.DependencyInjection; using Microsoft.Extensions.Logging; So I went through and added the ones I was missing. However, if I change using Microsoft.Extensions.Configuration; to using Microsoft.Framework.Configuration; it pops more errors. So I left those out. I added Models, Diagnostics, Data.Entity, and Dnx.Runtime since those didn't produce more errors when I added them. Though I still have that one error I talked about above. 
Here is the project setup up to the migrations point (http://aspnetmvc.readthedocs.org/projects/mvc/en/latest/tutorials/mvc-with-entity-framework.html#use-data-migrations-to-create-the-database). http://www.filedropper.com/webapplication1 Hope that helps you get started. Please compare mine with yours to see the differences (mostly in project.json and startup.cs).
Yeah, it just sucks because this is 10% of our grade and we've barely done anything outside of C# programming with visual studio. So most people have no idea what to do. I personally almost have a 100%, so if I can't figure this thing out I'll probably still have an A in the class. But I'd still like eventually, even after I get graded, to figure out whatever this tutorial is supposed to teach us. 
Yeah there are some differences. In my project.json file here are the differences i have. At the top where yours says webroot, i have. "version": "1.0.0-*", "compilationOptions": { "emitEntryPoint": true }, Under the "exclude" section I'm missing "bower_components". Under the "publishExclude" section I'm missing everything except the .user and .vspscc lines of code Let me make those changes and see what happens. 
So I compared mine to yours and we did have quite a few things different in the project and startup files. Mainly the dependencies and using areas. I made them identical to yours and my error has changed. Let me see some more things with your code and see if I can get fix it. I'll reply back with results. 
Alright so what I noticed is that the class files you created have different code (such as in sample data). When I try to make my SampleData and other classes that are having errors look identical to yours, i get a lot more errors. So by just making the changes to the startup and project files I'm getting the following errors.. http://i.imgur.com/WdmTanz.png For example your context var looks like the following. var context = serviceProvider.GetService(typeof(BookContext)) as BookContext; while mine looks like. var context = serviceProvider.GetService&lt;BookContext&gt;(); 
You're graded when you're using a **preview** software? What kind of bullshit is that? You should spend time with the stable stuff, like most C# developers, and not the (not finished) cutting edge stuff.
If dapper never existed then maybe I'd pick nhibernate over EF.
NHibernate is abandonware. The founder must have gotten bored of maintaining the code and fucked off for greener pastures years ago. The documentation for NHibernate is hideous too - the best answers are on stackoverflow - which is what your google fu will turn up. I'm not even sure if they have official docs. Anyway, forum solutions are fine for the most common issues but when you start heading into no mans land you can really find yourself in a bind. Of course, by this time you'll have invested heavily and you'll feel committed to finding the answer..... I'm not saying EF is all is perfect but man, it clearly aspires to be. It's stable, has a strong community, keeps getting better with every release. Plus it's so fucking easy to use.
Glad to hear that. In the near future I will create a packaged release then these problems will go away
Jesus Christ! So I guess I just wasted my time learning it. How come some companies are still using it? I saw a job posting asking for knowledge of Hibernate.
why?
It's very mature and usable. We still build new software on it. It's still more powerful in the ability to express a domain model based on .Net types than EF.
Flex-Nhibernate makes setup and mapping a little easier. As to why you would choose NHibernate over EF, there is very little good reasons left now. I'd say around EF3, NHibernate was the better option. It was more mature, had cool features like second-level caching built in etc. Around EF4 the feature gap seemed to start closing and now I wouldn't go back to NHibernate.
Honestly, I wouldn't pick NHibernate either. Personally, I feel EF and other frameworks are often unnecessary bloat and over-complicating data repos, which are very basic in nature and don't really need all that overhead. I always found it more efficient to just write a basic reusable data class. Then dapper came along and expanded on that idea, but is still probably the most efficient and painless way to manage data repositories.
NHibernate is way way more capable than EF, even in it's current incarnations. The proxy and lazy loading support is better, the range of supported databases is better, mapping expressions, interceptors, events and queries are all better. The session is a better abstraction than EFs Contexts, it's stable and mature. QueryOver is expressive and predictable. EF is still playing catchup to NHibernate and FluentNhibernate. Designer driven EF is a joke, but at least the Code first bits are reasonable now. Basically, if you're just mapping to SQL Server, and in greenfield, sure, EF is fine. Got a weird legacy system? Want to express a complex domain model? NHibernate all the way.
Oh, and Simple.Data &gt; Dapper in just about every way, if MicroORMS are your thing.
While you will spend more time creating your POCOs by hand rather than EF generating them for you (or creating a DB from code), dapper runs at almost the exact same speed as normal ADO.NET, which runs an order of magnitude faster (x10) than EF in most performance testing that I have seen. I have started to swap out our data layer in some of our more data intensive applications due to confirming this performance increase on our own code base.
Yeah, I had to update that to be compatible with the latest SDK version. The code in that tutorial appears to be out of date.
Insight.database (look on github) is awesome. Entity is slow and had a lot of bugs that came up during production. Also, mapping children is hell on a complex aggregate. Insight gives you really fine control over what you're getting back and how.
If you're stuck with Oracle 11g as your primary data backend and ODP.net 11.x on your servers b/c the business won't upgrade, then getting EF talking with the DB is an exercise in futility. NH worked. Otherwise, they each had their quirks. I think Code First beats NH, but NH to EDMX is pretty comparable. They each have their quirks, but neither completely outshites (unintentional typo, but it works) the other.
Just goes to show that manpower, support and integration can overcome anything. Microsoft dropped enough manpower to make EF more friendly, capable and faster. They offer enough support and it's easy to find documents/answers/solutions on just about anything you want to do with EF. And they have integrated it so well into the rest of .Net that people hardly even think twice about another choice. It falls under Good Enough , Why Not principal. You only move away from EF if you have a reason to.
/u/awesme is probably using the Release Candidate version of ASP 5. You and the tutorial use the Beta-8. It will be very important to follow the tutorial exactly or you will crash and burn. Also I noticed that what /u/AngularBeginner said about SetBasePath is actually *in the tutorial*. This means you mis-typed some code and didn't read close enough. Not that I blame you or anything, happens to the best of us. Just wanted to let you know the tutorial works.
The appeal of these drop-in ORMs is that they optimize for the problem at hand - they speed up development by either creating your database or your POCO classes. The illusion of rapid progress is very attractive, especially if you're trying to sell something to management. The problem is that, in the long run, this is a terrible optimization. What you should optimize for is the performance of your application and your ability to maintain it. For this, simpler wrappers like Dapper and PetaPoco are ideal. However, if you do Code First stuff with EF, it might be worth keeping around for its ability to manage database migrations extremely well.
Sounds like that may have been the best thing to happen for your career...
That wouldn't be a problem if MS would extend SSDT to work with other database formats. I hate it when I have to use something other than SQL Server mostly for that reason.
&gt; While you will spend more time creating your POCOs by hand rather than EF generating them for you (or creating a DB from code), If you are using EF-generated classes you are probably doing something wrong. Selecting every column from a single table is almost never the right thing to do.
&gt; worse performance Really? Others are saying that it is faster than EF 6, but I haven't seen benchmarks either way.
Designer driven EF is dead. You won't find it in the next version of EF. 
my colleagues all tell me that lldb isn't working for C# on linux, and that gdb can't be used for C# code.
So, you use EF without using any of the objects that it maps for you? Maybe I am not understanding, but this is a pretty typical EF use case IMHO public void SaveItem(MyViewModel model){ using(var db = new DbContext()){ db.MyTable.Add(new MyTable{propertyA = model.PropertyA}); db.SaveChanges(); } } public MyViewModel GetItem(int id){ using(var db = new DbContext()){ return db.MyTable.First(x=&gt;x.Id == id).Select(x=&gt; new MyViewModel{ PropertyA = x.PropertyA, PropertyB = x.PropertyB * 1.5 //just trying to show some data transformation }); } }
&gt; NHibernate is way way more capable than EF Bullshit. I cannot group by an anonymous type with NHibernate in a Queryable.
In my experience, the View is the UI, the ViewModel is the "codebehind", and the Model is any POCOs you are interacting with. I would suggest (if you haven't already) looking into a MVVM framework like Prism; it comes with a lot of the infrastructure for handling binding, commands, etc for you. Let me know if you'd like to see some examples.
safaribooksonline.ocm all the information you need about everything in the world is on there. Also, Angular is not a visual studio thing that's a web world thing. (to be used with MVC/Web Api) 
I thought about going just straight-up with a few books, but thought snagging labs would be easier from an online courseware site. I'll give them a look. And as for Angular, yep I got that - Just wanted to add getting up-to-speed on the framework to my to-do list :)
Taking a quick look at daper: daper is faster becuase it's closer to the sql level to do most basic things. you basically do all the chewing for it and I'd consider it a very loose ORM (its like one level above manually writing sql queries) EF on the other hand I can use LINQ to write functional programming based queries to generate the SQL for me. if your sql is weak or you want your developers to focus on writing/maintaining code in only one language EF is the way to go. As for Nhibernate vs EF I am unsure...the nice thing about EF is that its built into visual studio and basically does all the bitch work I dont want to do for me. Edit: My only hang up is that there is no Liquibase like thing that's mainstream for .NET. This would allow you to version control your database and mak esure your table structure is correct without having to write a SQL query and ensure your users need to execute it for every freaking upgrade. 
If you are already familiar with the concept of "single page application" and have worked in one framework, don't pick it up right now. Angular is going through a major transition (much like python 2 vs python 3) Angular 2 is coded using typescript. No matter how much every company tries to reinvent javascript with some other transpiled language they fail but create a series of hard to maintain, short lifespan applications. Getting back to the point. If you have one SPA framework down, don't worry about learning a new one unless you actually have to use it (or just want to create a new application using it) they change like flavor of the week. There are so many of them and they change so often that they are hard to keep up to date on and there is always a new one: React just came out in the last six months and everything (notably OkCupid) is using them even though its still technically in beta. People are moving too fast for their own good and not working enough with mature, well-documented and stable technologies. (say what you want about entity framework it would fit the mark for a mature and stable product) ALSO: http://todomvc.com/
I looked at a [simple MVVM code sample](https://code.msdn.microsoft.com/windowsdesktop/Learn-Simple-MVVM-and-8beb6bf0?SRC=VSIDE) that I found via the Visual Studio Gallery, and from that, the ViewModel essentially appeared to be a collection of the different Models/data and then the MainWindow's functionality was bound to the ViewModel... So, if I'm getting the gists correctly, then the Model is like the class objects, representing the data... then ViewModel contains the code that collects/stores the actual data objects and does different things with them, and the View is just the method for calling/executing the ViewModel methods? #&amp;nbsp; &gt;I would suggest (if you haven't already) looking into a MVVM framework like Prism; it comes with a lot of the infrastructure for handling binding, commands, etc for you. I have seen a few references to Prism in different places but haven't actually looked into it at all, yet... but I will be doing so immediately. &gt;Let me know if you'd like to see some examples. I would ***love*** that! Honestly, for things like this, one of the best ways for me to learn and begin to *truly* understand the principles is being able to actually take something apart and see how it works. #&amp;nbsp; The majority of tutorials that I've seen rarely really explain the *why* things work/why you should be doing it **this** way, they just give you the steps on how to do it. That's all well and good, but if I want to apply those concepts to a different/larger application, I actually need to know those things. Documentation is wonderful for learning the fine points and specifics, but it often assumes and requires a substantial preexisting knowledge base in all of the other closely-related objects and components in the framework... which, at this point, I don't have, so that hasn't been extremely helpful to me, yet. #&amp;nbsp; I swear I am **not** lazy or just asking in hopes that somebody will find the answer(s) or just tell me what I want to know... the problem is that I've found so much, and none of what I've found has really been the kind of thing I'm looking for, and I feel like much of it just leaves me with more questions than I had when I started... But it's pretty clear that WPF and XAML are going to continue to be important technologies--at least in the Windows ecosystem--for the foreseeable future, so I feel like it's worth sticking with it and trying to learn it.
&gt; if your sql is weak or you want your developers to focus on writing/maintaining code in only one language EF is the way to go. If your SQL skills are weak, that's all the more reason to not use EF. You are far more likely to do something horrible because you don't understand what it is that your database is doing. EDIT: Unless you are a hobbyist, in which case performance doesn't really matter.
I think about View,ViewModel and Model the same as /u/celluj34. Possibly adding that I view ViewModels as a [Decorator Pattern](https://en.wikipedia.org/wiki/Decorator_pattern) on top of the Model. [Caliburn Micro](http://caliburnmicro.com/) is my favorite MVVM framework. I actually think learning it at the same time as learning WPF is simpler than learning WPF without Caliburn Micro. I also feel like Caliburn Micro's conventions push you towards structuring and decomposing your XAML the right way.
Most of the time for me at least performance doesn't matter. I just want it to store my shit. If I could have stored in memory for some of my things I would, but I need persistence. (there is always SQLight....) 
While im a fan of Dapper (and Subsonic before it) I think this is an overly simplistic view point. Your customers don't just care about performance, but a myriad of other things. While im a performance snob for some things, saying that you should focus on performance first often neglects your customers more. You need to know when its important, and when EFs terrible query creation and slow Object Materializer are totally acceptable. Developer time is expensive. Hardware/Infra is cheap. Optimize accordingly.
&gt; latest visual studio mvc 5 tooling installed and not just the latest mvc 5 framework nitpick: It's *ASP.NET 5* and *ASP.NET MVC 6*. Yeah, it's not confusing all...
Yeah I don't mean to diss it completely because I used it for 3 years (2011 to 2014) but I just find setting up an EF project much easier. I suppose your statement about NHibernate bring stable is more accurate. 
True, though I'd rather not hand craft sql if I don't have to. When the logic changes I'd need to rewrite it anyway. That's the whole point if using an orm in the first place.
I wrote an app that will write my poco files from the database. I use that to build the classes then add them to my project
Oh please, using EF doesn't actually cut down development time for most projects. Last time I used it was for a bench mark comparison between EF, Dapper, and our own data access library. I literally implemented the same methods for each library and EF took me just as long as the others. You're optimizing for people who type with a pencil.
Did they ever get around to supporting async?
So why would I want method interception?
If you are not an expert or have not read extensively about EF, don't even try it on a commercial project. The amount of pain we're having to go through because someone on the team has watched a couple of TechEd videos and has decided that EF is THE thing...
Unity is good/fine. I really like Caliburn Micro for their [Conventions](https://caliburnmicro.codeplex.com/wikipage?title=All%20About%20Conventions) where it will bind controls in your Views to properties on your ViewModels. For instance, if in your ViewModel, you have these properties (I'm not implementing INotifyPropertyChanged for brevity): public BindableCollection&lt;SomeViewModel&gt; Things { get;set; } public SomeViewModel SelectedThing { get;set; } The normal XAML you'd need to bind a ListView to those properties would be: &lt;ListView ItemsSource="{Binding Things}" SelectedItem="{Binding SelectedThing}"/&gt; But with Caliburn's conventions (that binds to data in the ViewModel based on the Name of the controls), you get this: &lt;ListView Name="Things"/&gt; Caliburn Micro knows to look for a Things property on your ViewModel and bind it to ItemsSource, and it looks for properties on your ViewModel like SelectedThing, ActiveThing, or CurrentThing (I think those are the 3 defaults it looks for) and binds that property to the SelectedItem of the ListView.
If it were actually faster to write you may have a point. But I've seen far too many cases where the EF code is far more verbose than the alternatives.
What are the benefits over Dynamic Proxy?
Actually, I thought doing it the way he is doing it here WOULD only generate the SQL to select the two that he wants, not the whole row. At least some preliminary research seems to suggest that: https://visualstudiomagazine.com/blogs/tool-tracker/2014/12/restrict-columns-entity-framework.aspx 
CodeCop operates at runtime. PostSharp, unless they've changed since I last looked at them (which was half a decade ago) operates at compilation time. 
I'm sure that one single feature invalidates everything else. You have a point though - NHibernate's Linq provider is really very limited - but QueryOver and the Criteria API are far far more powerful than anything EF has gotten close to.
Yep. Terrible idea to start with too - as bad as when everyone was using LLBGen to generate terrible NHibernate models back in 2008.
React has been around for well over a year, but yes your point is valid only learning one SPA right now is very good advice, also i'd recommend looking at the musicStore repo, and partsUnlimited repo on github which are good example projects for getting started with ASP.NET 5.
Do tell, I missed that disaster.
Such arguments ring a little hollow for me. You can shoot yourself in the foot with most of our tools if you don't know how to use them. I'm not sure you are any more or less likely to do something bad if you're writing bad SQL anyway. For me, the use case is more about complexity of your model. If it's fairly flat in nature, I'm more apt to look at Dapper, etc., but if it involves a lot of sub entities or I'm looking to do OData projections or something like that, EF just makes more sense. We've found a lot of the performance issues are alleviated by doing CQRS and turning off change tracking on the read side. It's just a tool and has it's place.
Thank you.
No proxy creation overhead, you work with the real objects. So this kind of stuff (var proxy = new Proxy&lt;MyRealObject&gt;() doesn't exist). No limitations whatsoever on what you can intercept, public, private, internal, static everything is interceptable with CodeCop, even BCL methods like for instance Console.WriteLine or other. As it was already stated, it works live, at runtime so you can literally change the method in a continuous fashion if you like or even restore it to what it was. It works via a Fluent API or unobtrusively via JSON and it even has a Process Injection API.
Just to complement your excellent answer @alexdove, other use-cases are mocking, boilerplate code reduction and any kind of cross-concern logic that you can separate from your business code like e.g. logging, code security, auditing, exception-handling, performance monitoring, transaction management, caching (memoization), etc.
Please stop using these subreddits as your cheap marketing platform.
Here is a version removing unnecessary casts and replacing the power, exponent, and square root functions with functions I found online which are supposedly faster. The Pow() function is the only one that might not get inlined (because it has a while loop in it), but you were already calling Math.Pow() so it's no different in that sense and this power function is supposed to be faster than C#'s. http://pastebin.com/2aNcc2BM But again, I suspect you will gain a lot more looking at the rest of your application.
Hey @AngularBeginner, this fits you like a glove: http://www.hanselman.com/blog/content/binary/WindowsLiveWriter/ThisDevelopersLife1.04BeingMean_1240F/image_3.png. Since our very first post here at Reddit you never, ever write a useful comment, that adds real technological value like others users so nicely do, whether they like the technology or not. You have the right to dislike CodeCop, we respect that, but hey man stop being a purist and waste your keystrokes in writing useful software instead of these negative, low-value comments. 
I wrote plenty of useful comments, plenty of people appreciated my comments and some were gilded in appreciation. I may sound rude and harsh, but at least I give a lot of valuable and less valuable feedback to the community. What did you post, besides your product promotion? Your history is pretty straight forward on that. Have you ever wrote a post here that was not purely to promote your product?
msdn is a good source to learn mvc framework. They have mini projects which tell you how to create asp.net sites with mvc 
Pro tip: If you don't want your sockpuppetry to be exposed, don't make the exact same mistake of referring to users by @-handles rather than reddit's /u/.
Marketing platform? So If somebody creates some cool product for .NET community, they must not use this subreddit to tell people about it? Then please go and make the same comment to all posts about Resharper, or any other tool for .NET community. 
I did the benchmarks as a favor about six months ago. I don't count spending an hour writing half a dozen CRUD methods as "using it" in any meaningful capacity. 
That's exactly what I've been working on. Unfortunately it's not a public site and I'd get in deep shit if I shared. Maybe I can make a sort of boilerplate one day
/u/Aethec thanks for the pro-tip :) But /u/dchirutac is not a fake account but a real user who happens to like CodeCop, that's all. Like me, felt sad having to deal with /u/AngularBeginner rude comments every time a CodeCop post is made. If he doesn't like it, fine we respect his opinion and we don't offend him, so don't offend us nor our users calling them socketpuppets. These kind of attitudes only serve to alienate people from this subreddit.
Good to know. Is it only .NET 5 or will there be a 4.6 equivalent? I haven't taken the time to start messing with the new framework since its pretty big shift, I know we won't be migrating immediately anytime soon :(
[removed]
First of all this post is not promote **updates of product**, as you said, but show what you can do using **CodeCop**. Please don't try to induce people into error.
Glad you liked it. I'm also a bit new to Docker myself, but from my experience things like configuration can be handled using environment variables. For example, you can create a single Docker image that contains your application, and then you can inject an ASPNET_ENV environment variable to tell ASP.NET 5 whether you're running as Development, Staging, or Production (or whatever other stage you might have). I wrote a bit about that here: http://dotnetliberty.com/index.php/2015/11/04/using-docker-env-with-asp-net-5/ As for release processes, I haven't explored this area closely yet but I eventually will. What I'd look for in a real production application is having 3 separate environments (development, staging, and production). With Docker I could probably run them all on the same EC2 instance. Next I'd want to use something like Elastic Beanstalk to monitor a git repo for changes, and automatically build a new Docker container when it detects changes. That container would get deployed out to my development environment and ideally I could trigger some automated tests (hit some web APIs, perhaps even UI testing). If tests pass it gets promoted to staging. Staging would be as similar to production as possible. This is where I'd do some manual sanity testing (in addition to my automated tests). I'd then probably have a one step deploy to production, where the same set of tests would run. Basically a continuous deployment (CD) setup running fully in the cloud. When I get to that point I'll definitely document my learning and share it here.
I don't know how you find the time to be so prolific with your asp.net 5 posts but kudos to you. As a developer trying to find his feet with the new framework, your work is really helpful.
too bad core is not yet supported
I think of it as an implementation (package) of React for your .NET app so you can use it...
&gt; doing it all over the place. &gt; There's only so much you can do in processSectionAdditive() ... you're getting into the level of micro-micro-optimization at this point. I have not looked at th Thanks for the focus on casting. I've realised if I copy the bytes of the image into arrays of "single", then I can do the calculations on them without any of that nasty casting. Also, if there's animation frames in a grid as often is the case, I can lose the framing and chopping necessary just by adding them all into that 'single' array, then an animation frame selection is a simple 'frameNumber x frameByteLength', no stride tweaks and the JIT will be happily reading ahead in the array to put in the L3, L2 and L1 cache. (I've been reading about it!) The final cast of single to byte for the storing in image memory will still be happening. I don't know how fast that particular type of conversion is, or if I can improve it somehow by reading the 'single' storage locations and pulling an int out. (doubtful, that sounds massively slow) As for the rest of the code - it was a framework to provide a GUI for adjusting all the layers I piled on: dirt, glow, gloss, specular, normal, texture... I'm going to re-code the drawing algorithm this Christmas - removing dirt and recreating it by pre-adjusting the emissive, texture, gloss and specular textures. (dirt hides emissive, changes the texture to rust perhaps, and reduces specular for instance). In fact - rather than doing that by hand while making the resources, I could STILL include the dirt layer as a programmatic adjustment that permanently edits the in memory texture, emissive, and specular where the dirt layer isn't fully transparent before it starts getting drawn. I can lose gloss - that's just how large the specular is. A big price of an entire render pass for a low impact effect. I'm going to split off the others - like "reflective" into their own render pass call, so that if they're not needed, they won't be part of the drawing process. Right now, they're all included in the same pass, and it's just the maths that removes the gloss/reflectance/emissive. So the uncommon effects will go. I'll have a main rendering class of "LitSprites", which will contain a "Lights" list, and "Sprites" list. Sprites will contain an optional "Animation" class, that stores the current animation frame, total frames, and dwell time for each frame. The program just says, "display this sprite here", and any animation is handled internally to the class, and so are the lights. The "sprite" will consist of just a single animation sequence, such as "run left", or "balance right". I've discovered pinned data! It mentions a performance hit for small images, because of the data ending up on the stack, and not heap. http://www.codeproject.com/Articles/16403/Fast-Pointerless-Image-Processing-in-NET In my tests it's excellent - just editing the array contents, and then invalidating a PictureBox redraws the updates. For this sprite system though, the sprite will be processed (texture, light, gloss) in its own small pinned block of memory so I can use a simple index into the image array. (no pesky strides or nested slower loops). That'll get me a JIT optimisation with bounds checking off. Then I'll do DrawImageUnscaled to the users draw surface. It'll handle the clipping on the screen edges. OR Do you think I should pin the entire user display surface as an array, and then process the sprite on to the array using an X,Y loop and a stride? Hm, I'd have to handle the clipping and cropping too. I don't know which would be faster. Probably the X, Y loop with a stride addition between. But I don't know, there's the clipping I'd have to deal with too. The .Net BLIT of DrawImageUnscaled will probably be faster. There's so much to think through!
I totally missed this post, Thank you! 
Without going into detail about performance or asking why you'd even want to do this - it appears to run full Windows 10 so I see no reason why not. You won't need anything special so you can follow any tutorial aimed at Windows. You may want to take a look at Kestrel over running a full blown IIS server though 
Full Windows 10? Interesting. I assumed it'd be some variant of Windows 10 Mobile or Embedded or something along those lines
It certainly appears to be full blown Windows 10 - infact, based on some of the reviews dotted around the web it seems to perform quite well for the money. You may well be pleasantly surprised.
Hello there and good luck! You might also want to ask in /r/learnprogramming. Although it's not directly a specific coding question, there's a chance that senior devs will browse the sub.
Technically - yes. Morally - no.
Is there some reason you're doing this programmatically instead of using the history view in source control explorer?
Doesn't TFS have a compare option? You could try comparing the label version to the current version. I think TFS opens all the files that have changed.
IMHO, using source control for this type of operation is a bit more laborious than using tooling designed for database change management. SSDT (Sql Server Data Tools) allows you to do Desired State Configuration of your server schema and automatically generates a change script for you as part of the DACPAC output. https://msdn.microsoft.com/en-us/library/hh272686%28v=vs.103%29.aspx. You also get compile time validation of your sql files and intellisense for creating stored procs etc. You just maintain the original create scripts as you would a class in a .vb or .cs file. You need a new column? Just add one to the create DDL and the changescript will be generated for you. No more ALTER TABLE ADD COLUMN. Its a free extension and tooling that has a utility called SqlPackage.exe that will do the deployment and packaging as part of your CI and CD pipelines.
I totally agree. I just find generalizations always over simplify the "dos and don'ts". If you're working on a large codebase that's all written in EF, you're not going to rewrite your DAL before fixing a customer issue.
I don't have a TFS instance handy and I'm too lazy to create a VSOnline one and populate it with history, but I think your example already has all the pieces you want. Note the QueryHistory call in your example. You can see what all those params are on the [MSDN docs](https://msdn.microsoft.com/en-us/library/bb138960.aspx), but you should be able to change the first param (path) to only match things in your Database folder and the 6th param (versionFrom) that you've currently got set to ChangesetVersionSpec(1) (the first changeset) to get all changes from the [LabelVersionSpec](https://msdn.microsoft.com/en-us/library/microsoft.teamfoundation.versioncontrol.client.labelversionspec.aspx) you care about. You'd probably also not want to include the user in 5th param, since you don't care which user modified one of the scripts. And of course you'd need to eliminate duplicates, as this would get you a list of every file changed at every step of the way. FWIW, I don't know why you're iterating over the results of QueryHistory as objects and then casting them to a changeset - it's [already an IEnumerable of Changeset's](https://msdn.microsoft.com/en-us/library/bb138960.aspx#returns). And I have no *#%&amp; clue why you're then instantiating a new VersionControlChangeset and pulling out only two of the properties. EDIT: Got rid of the annoying MSDN versions in the URL that break parsing of links.
Don't hold your breath.
Can you explain your use case a little more? Why are you trying to load this from the database instead using the standard asp.net pipeline?
If i understand you correctly, this control will be used to represent a product that you have in your database. If that's the case, you should be able to do this all from the code behind. In your aspx you have a place holder. In the code behind you get your content from the db. For each record returned from the db you can create a control and then add it to the place holder.
Read the reply I just wrote to JustRamblin, that explains a bit more. It's for a blog, so only some articles will have products, and all in different areas of the content from the DB. 
1) Pretty much. Xamarin does a good job of keeping their API's up to date. 2) Phonegap runs a website inside of a browser. The phonegap browser gives access to some native functions. I think Xamarin will make it look more like a native app, but I'm not sure, since I haven't done much with Phonegap. 3) It varies widely by the type and scope of the app. The downside of Xamarin is you have to pay the fee every year. Since Google and Apple release new operating systems every year, you have to renew your license each year if you want to keep developing. There are a lot of native libraries out there provided by third parties (analytics, logging, facebook integration, etc). Xamarin does offer a toolkit to create wrappers, but you need to understand the syntax of Objective C and Java to work with them. At least as of a year ago, Objective C wrappers/bindings had to be created manually, and the automated tools for Java croaked when handling name collisions resulting from inner classes sharing the same name as normal classes, since C# doesn't have inner classes. While this sounds like a rarity, since most libraries obfuscate their method names, it happens more than you'd think. Xamarin has created some wrappers that can be downloaded, but I wasn't able to get them to work. Edit: Sorry, I had a brain fart on the Java bindings. It's usually just internal methods that are obfuscated, and you can just tell the binding generator to ignore entire namespaces/packages. That was my solution. This assumes the collisions are restricted to certain packages.
Xamarin is great but it is a massive framework. For a quick start you might want to try React Native.
Any content that helps us be a better developer and expand our knowledge about the present and future of .NET development practices should be allowed. Even if it's not free.
The guy who spoke at future decoded absolutely wasn't from Xamarin. 
It sounds great, but I've always been thrown off by the cost.
Oh, that makes more sense now. Instead of trying to use a control like this you could drop an iframe into the blog post that loads whatever product page you're after. Then you don't need to worry about securing the blog site and the store. You'd just have to secure the store. This set up would also allow you to have other blogs review your products so you get more exposure.
Perhaps message queing would fit the requirements. https://en.m.wikipedia.org/wiki/Message_queue MS: https://en.m.wikipedia.org/wiki/Microsoft_Message_Queuing
For your specific case you could have a remove orphaned images operation 
The biggest problem we have with Xamarin is that the Android apps are very large (25MB vs 6MB native). Each Xamarin Android build has to ship the Xamarin Android runtime libraries with it. Hoping they do something about this soon, or we'll likely dump Xamarin in favor of native.
Generally two approaches used in combination. 1) Google "Unit of Work" aka database transaction. Basically, all the actions that are going to take place in the database are wrapped in a unit of work transaction. So if the server goes down in the middle of it, all the work done up to that point is cancelled as if it never happened. Think about how an ATM works. If, in the middle of your withdrawal, the system goes down, it ensures that the money is not removed from your bank account unless the bills were actually dispensed from the machine. 2) You have a periodic background task that goes in and cleans up orphaned images. Generally its okay to have orphaned files since storage is cheap nowadays. You get an Amazon S3 account and just leave images hanging in there. While it's great to keep it pristine, it's not the end of the world if it gets out of sync.
Ah, ok. Thanks.
I would start pretty small and just make sure that all the database operations are performed in a single database transaction. Either all the operations will succeed or none will, so if the server crashes right in the middle then your database will be left in a consistent state. Once I know that the database transaction has succeeded, I would go ahead and delete all the image files from the file system. It should be pretty simple to recover from a server crash in the middle of this process, we'd just have a program that we could run against the database to delete any orphaned files once the server comes back up. As traffic increases, I'd then introduce a service bus into the architecture in order to keep everything scaling. We'd update or business logic to send a message across the service bus to delete the files so our web server isn't blocking a thread while potentially hundreds of files are deleted at once. We could also make sure that the message queue that the service bus is listening to is replicated across multiple servers in order to make everything more resilient.
I think this might be the correct course of action. Since MQs are external and persistent with very good reliability, when one of your servers goes down the single operation it was working on will fail, but the rest will still be in the queue and can be performed by some other server. In order to recover from a failure, you need some reference of the operation you're performing and what state it is in. That reference should be a list of every step in that operation, and every single step should be repeatable if the operation halts from a failure. That way you can pick up right from where you left off with no problems. In your case, you might have a list of all of the photos you want to delete, followed by the album you want to delete. Each photo deletion has some steps (a database call, deletion from stoarage, etc), and then when the photos are deleted, the album is deleted last. Some have mentioned here that a database should be able to handle these transactions for you, and they should be able to if all of your data is stored in the database. If your photos are stored elsewhere, I'm not quite sure how to ensure that both the DB record and the corresponding storage were deleted. Someone mentioned that deleting the storage, then the records would work. So it might work like this: server receives deletion request -&gt; server puts request into message queue/topic -&gt; deletion worker reads message -&gt; worker makes db call to get all storage references -&gt; worker puts individual deletion request for each storage reference into storage deletion topic, adds marker for receipt return -&gt; storage deletion worker reads message -&gt; storage deletion worker makes deletion call to storage -&gt; storage deletion worker puts deletion receipt message into deletion worker's queue -&gt; when all are complete, deletion worker makes db deletion call to remove records. If deletion receipt times out, that storage reference is put into the deletion queue again. I'm sure there's a more than a few things you'd have to work out with the above, but at least with this approach your app will be scalable, reliable, and redundant.
Yes, the business logic can be standard for the most part, but I suspect even then, there are some things that Xamarin must be doing to abstract the underlying differences between the OSs in order to provide a common surface for the developer, which in my opinion is some sort of sacrafice. I guess I'm just a purist and prefer to write code using the native frameworks. I played around with something called RealBasic some time ago which allows you to write a single app for Mac and Windows but it had a runtime to be deployed and lots of compromises.
The messaging options are good choices. Look at MassTransit or something to make the messaging easy. 
If you use the linked then the app size should be much much smaller. The overhead can often only be about 2 or 3mb 
Output caching would help your server handle higher throughput and alleviate the ddos concern. Also I'm not suggesting you iframe in the normal product page. You would make a new one that is trimmed down to just what you want to show.
13,000 rows doesn't seem like a lot to me. If the data doesn't have a high rate of change, consider caching it in memory. Look into full text search for searching on names. You may also want to consider SOUNDEX for the name data. Use parameterized queries to prevent SQLi.
AFAIK the minimum overhead is ~3.5mb?
First, don't send SQL from the client to the server. One way to send your data would be to encapsulate the query in an object of some kind of query class: class ContactsQuery public string NameCriteria public string CityCritera then send a query to the server (as JSON for example) {"NameCriteria": "*ric*", "CityCritera": "Sydney"} Once you have your ContactsQuery object in your .NET server application you can do it the quick, easy and fast but not scalable way: Load all your contact objects into an in-memory collection and perform a LinqToObjects query. Maybe AsParallel, but probably not necessary. You need to translate the wildcards to startsWith, endsWith and Contains string methods. For a more scalable (more "best practice") solution create SQL statements based on the ContactsQuery object in your server-side .NET code.
Deleting files after deleting the database records could be very inefficient if you have to check all of the files against the database. I would delete the records after deleting the files, maybe even have a flag in the DB to mark files for deletion. That way if a process is interrupted, it can just check the DB and delete those files with the flag. If a file doesn't exist it can skip it or mark as deleted and move on. Then you can just delete every record with a deleted flag.
It sounds like it is hitting a different database than the one you'd expect. Double-check your connection string and make sure your dbcontext isn't being polymorphed into its parent (an issue my coworker and I created by accident on a recent product). Also, maybe run a profiler trace to see what database it's hitting.
Interesting. Do you know the specific code that caused it?
That worked great, thanks!
forgot to add - desktop
What's wrong with the base .NET libraries provided for this? It's really easy to send toast notifications.
A db guy I know recently told me "if you know postgres, you can write your own check.". 
Is exploring a "big data" database like hbase or Cassandra a niche that I shouldn't worry about?
They are in use, but for very specific things. There's a bunch of database types out there for specific things, like graph-based databases, etc. It's probably best to focus on the common ones first: standard 80/20 rule applies.
Redis as "universal awesome cache and more tool" (with the stackexchange.redis client) and Elasticsearch as fulltext search engine. Then some messaging technology. Maybe RabbitMQ or Apache Kafka, the new kid on the messaging block.
which libraries are those?
https://msdn.microsoft.com/en-us/library/windows/apps/hh202967(v=vs.105).aspx
So so many companies work with MS SQL and Postgres. That's all I ever work with. But I have had a few MySQL or Oracle. Truth is with .NET, once you understand one, such as MS SQL, there's not much of a learning curve for the rest.
Since we're talking about desktop, I presume it's [this one](https://code.msdn.microsoft.com/windowsapps/Toast-notifications-sample-52eeba29)
I'm working with Oracle at the moment, after a lifetime of SQL Server experience. Oracle is a bastard. Especially if dealing with stored procedures. It kinda works with Entity Framework but it's pretty painful. 
I am so glad to be a .net developer right now. Linux support for this kind of thing is a real game changer! I've never used Amazon EC2 much, out of curiosity what kind of hosting costs are involved for a small ASP.net site like this?
Look into cloud infrastructure. It is a whole new world for databases. When developing an app for a enterprise-level cloud environment (AWS/Azure) you get to leverage a lot of very cheap, highly scalable and reliable data storage options, starting with relational SQL databases up to some superfast low-level key-value stores and data warehouses. From Azure you can have a look at: - Azure Table/Blob/Queue Storage for very cheap, fast and reliable nosql storage options - Azure SQL for affordable and easy to scale relational db - Azure DocumentDB for document storage (like mongodb) From AWS you can have a look at: - Amazon S3 / Glacier / DynamoDB (Azure Storage equivalent) - Amazon Aurora (Azure SQL equivalent) EDIT: bottom line is that cloud providers have their own ecosystem innovations which you should be able to take advantage of without the hussle of installing and managing them yourself. Also it tends to work out much cheaper the bigger your team is.
I have used Postgres when working with node and Python. Do a lot of .net shops use Postgres? I assume that with the new .net core running on Linux we will see it more.
I agree DocumentDB is pricey that's why its good to explore Azure Table Storage first (there are good libraries that emulate DocumentDB's behaviour). That said, in DocumentDB you pay for the things that are hated the most about mongo: scalability and configuration. Also compare cloud-hosted MongoDB prices with DocumentDB - very often DocumentDB works out cheaper and scaling it is as simple as moving a slider. Have a look at these: - https://github.com/Mailcloud/Hydra - https://github.com/yevhen/Streamstone Most of Azure Storage libraries are build around Event Sourcing concepts, so a new pattern to learn, but very very scalable, cheap and reliable.
Getting experience with different database is a good idea, but I think you should also think about trying understand the theory going on in the background of the move towards NoSQL dbs. I'd recommend reading [NoSQL Distilled](http://www.amazon.com/NoSQL-Distilled-Emerging-Polyglot-Persistence/dp/0321826620/ref=sr_1_1?ie=UTF8&amp;qid=1448894264&amp;sr=8-1&amp;keywords=nosql+distilled) as it has pretty great detail on the different kinds of NoSQL stores, along with an explanation of when you would use each one. 
I ran this on a t2.micro instance. It's $0.013 per hour, or about $9.50 a month. I can scale up as needed too.
Only assuming your app can live within the constraints they artificially place on it (no more than 30 queries per connection, can't return more than 1024 records as a hard line maximum, don't need to do reporting, etc.) It is easy to get running with, but was too limited for our needs specifically (and octopus deploy just dumped it for a lot of the same reasons).
We just got the OK to migrate from Raven to SQL. "Safe by default" caused way more pain than expected.
Let's see some code. We don't have any clue what you're trying to do. And realistically, creating one thread per item could get out of hand quickly. Threads aren't the easiest thing to work with.
Yeah OPS was an issue for us too - as well as client expectations: "what do you mean you can't just give us a report with data XYZ?". And when things go wrong, they go wrong in a big way. Run out of HDD space and SQL server will stop writes and fail gracefully, Raven will corrupt the database. I still like Raven, but it's no silver bullet.
Thanks. I'll have to give that book a read. Looks exactly like what I was looking for.
Do you need a login model and stuff? When we did this, we changed IIS to use Windows Authentication with the HTTP 401 Challenge. That pops up something in the browser asking the user to log in, and they must enter their domain credentials. It keeps track of authentication cookies, too. If the site is marked as an intranet site, it will automatically use the Windows credentials in Internet Explorer. Edit: [Here are some directions](https://technet.microsoft.com/en-us/library/cc754628.aspx), which are for configuring IIS on the server the application will run on. Like /u/madman86 said in [the other answer](https://www.reddit.com/r/dotnet/comments/3ux1l3/how_to_set_up_simple_accountcontroller/cxikdfi), in your MVC application you can force everything to be authorized, then allow anonymous in certain spots. Or vice versa. If you have any questions, feel free to ask; it took me a few more hours than I'd like to admit getting this to work.
Thanks for the input. I went with using dynamic sql with parameterized queries to handle the search, the parameters of which are supplied from a search view model. I tried some common sqli techniques and everything seemed to work just fine. The query performance is also much better now (it was previously static sql with option recompile). Is dynamic sql okay or is this also bad practice / old technique? We dont use an ORM like entity, just have daos repos and service layers.
i can confirm that the most recent versions of toastr does not have these problems.
Thanks, I'll try that in the am!
In addition to the other suggestions, Sqlite is also a good DB to consider. It's the most popular embedded database these days, and it works remarkably well.
If you are to learn ASP.NET MVC you might as well start with ASP.NET 5 RC (latest). Start here: https://www.asp.net/vnext There is a nice template you can use from yeoman repository: https://www.npmjs.com/package/generator-aspnet which will set up the basics for you. If you have an existing database use the EF tooling to generate an entities model from it. These are the Data Access Objects you will be using. Keep in mind that it may require your database to be in 2nd normal form at least. Tip for working with EF or any other ORM: always use SQL profiler to see what queries it issues.
I am not going to update the threads after they started running. Basically I load a couple of accounts into a listbox and then I am trying to log in to a game and because I don't want the UI thread to freeze, I am forced to start a new thread which I am able to but not one per item and thus I am only getting the result of the last account tried.
This is my current code, which utilizes only one thread and thus I am only getting the result of the last account that tried to "log in". For Each item In ListBox1.Items ' Create a new thread, set it's worker to checkAccount sub Dim checkerThread As New Thread(AddressOf checkAccount) ' New parameters to use Dim datatoSend As New checkAccountParamters ' Set parameter we want to pass to username of combolist datatoSend.data = item.ToString() ' Start thread, pass parameters and let the thread do the work checkerThread.Start(datatoSend.data) Next
&gt; xsd2code looks good.. I hate command line anyways 
You're making sense, no worries. Having each type with its own `Edit()` kinda blows, yeah, but there's really not another way to do it. Any way you slice it, the GenericListView is going to have to attach the click to the edit event of the item. You can make it more indirect, but that dependency is always going to be there. The Edit windows form of the item's type is specific to the type -- I think that's okay. Not ideal, but okay. If you can, though, maybe consider using a PropertyGrid to edit your items. The GLV displays a form with a PropertyGrid. The PropertyGrid figures out what elements to display based on the POCO's Properties with reflection. To tweak the grid's behavior, use attributes on the POCO. The downside is that PropertyGrids can be a bit weird to work with if you're trying to do anything too fancy.
That's the rub, ultimately all these data types are very "fancy". How about if I made the Edit(); a method on an interface, that interface can be injected into the POCO at runtime? Would that work? It would at least let me strip out any winForms reliance from the "core".
If you want multiple things done asynchronously, but you don't necessarily want them done *in parallel*, the simplest solution is to do the multiple things in a single thread. With only a few adaptations, your code can become: Dim checkerThread As New Thread(Sub() For Each item In ListBox1.Items ' New parameters to use Dim datatoSend As New checkAccountParamters ' Set parameter we want to pass to username of combolist datatoSend.data = item.ToString() checkAccount(datatoSend)) Next End Sub) checkerThread.Start() But for fun and practice, a more modern approach would be to start a Task object to handle the asynchronicity, and to process the operation as a Linq chain of functions: Dim outcomes = Threading.Tasks.Task.Factory.StartNew(Function() ListBox1. Items. 'We must know the type of the objects in a collection to use Linq Cast(Of Object). 'We create the "dataToSend" objects from the items Select(Function(item) New checkAccountParamters With {.data = item.ToString()}). 'Finally, we invoke checkAccount on each object we just created Select(AddressOf checkAccount) End Function) *outcomes* will be a Task holding the various outputs to your account checking functions. You can then check its *.Result* property to get the outputs, or use its other ones to check whether it's still ongoing (ex. *.IsCanceled*, *.IsCompleted*, *.IsFaulted*). 
From what you're saying it seems the part your having no trouble with is what happens at the end of your method. I'm guessing you want to update the UI in some way to show the result of your attempt to log in to whatever it is you're trying to log in to. You haven't shown us any of that code. The code you've shown isn't very helpful at all. What we need to see is your checkAccount method. And as others have stated, threads are probably not the best way to do this. It's possible but there are lots of unintutive pitfalls there, especially with regards to updating the UI. 
Okay, here's what I'm currently thinking. My "GenericListView" needs to know what editor to use, that's basically the crux of the issue - so why don't I just give it that? The thinking is that this gets passed in during construction. So my new "genericlistview" looks something like this: public class GenericListView&lt;T&gt; : System.Windows.Forms { T m_items[]; IGenericEditor m_Editor; GenericListView(T items[], IGenericEditor editor) // Concrete edit form is created when this generic form is instantiated ... OnEditButtonClick() // When you click the form's edit button, it just calls concrete editor, which may (or may not!) be a Windows form. { m_items[selectedIndex] = m_Editor.Edit(m_items[selectedIndex]); } } That makes sense in my head. Does that make sense to you?
An example of my own code doing sort, filter and paging on the DB side, works with &gt;500K registers on table: public List&lt;Something&gt; GetLatest&lt;TKey&gt;( bool filterPrioritario, DateTime? filterFechaVencimientoStart, DateTime? filterFechaVencimientoEnd, string filterRCliente, string filterREntidad, int? filterPoliza, string filterEstadoEntidad, int? filterEstado, DateTime? filterFechaSiniestro, string filterProvincia, DateTime? filterFechaModificacion, string filterDireccion, string filterServicer, Expression&lt;Func&lt;Something, TKey&gt;&gt; sortExpression, bool isAscending, int pageSize, int pageNumber) { // Construct base query IQueryable&lt;Something&gt; query = from s1 in _dbContext.Set&lt;Something&gt;() join s2 in _dbContext.Set&lt;Something&gt;() on s1.IdSiniestro equals s2.VersionAnteriorId into rec from r in rec.DefaultIfEmpty() where r == null select s1; query = query .Include(s =&gt; s.Estado) .Include(s =&gt; s.Poliza) .Include(s =&gt; s.Poliza.Entidad) .Include(s =&gt; s.Poliza.Cliente) .Include(s =&gt; s.VersionAnterior); // Add filters if (filterPrioritario) query = query.Where(p =&gt; p.Prioritario == true); if (filterFechaVencimientoStart != null &amp;&amp; filterFechaVencimientoStart.HasValue) query = query.Where(p =&gt; DbFunctions.TruncateTime(p.FechaVencimiento) &gt;= DbFunctions.TruncateTime(filterFechaVencimientoStart.Value) &amp;&amp; DbFunctions.TruncateTime(p.FechaVencimiento) &lt;= DbFunctions.TruncateTime(filterFechaVencimientoEnd.Value)); if (!String.IsNullOrEmpty(filterREntidad)) query = query.Where(p =&gt; p.ReferenciaEntidad.Contains(filterREntidad)); if (filterPoliza != null &amp;&amp; filterPoliza.HasValue) query = query.Where(p =&gt; p.Poliza.Id == filterPoliza.Value); if (filterFechaSiniestro != null &amp;&amp; filterFechaSiniestro.HasValue) query = query.Where(p =&gt; DbFunctions.TruncateTime(p.FechaOcurrencia) == DbFunctions.TruncateTime(filterFechaSiniestro.Value)); if (!String.IsNullOrEmpty(filterProvincia)) query = query.Where(p =&gt; p.Provincia.Contains(filterProvincia)); if (!String.IsNullOrEmpty(filterDireccion)) query = query.Where(p =&gt; p.DireccionOcurrencia.Contains(filterDireccion)); if (!String.IsNullOrEmpty(filterServicer)) query = query.Where(p =&gt; p.Servicer.Contains(filterServicer)); // Add sorting IOrderedQueryable&lt;Something&gt; oQuery = null; if (isAscending) oQuery = query.OrderBy(sortExpression); else oQuery = query.OrderByDescending(sortExpression); // Execute with paging return oQuery.Skip(pageNumber * pageSize).Take(pageSize).ToList(); } Example of call: Expression&lt;Func&lt;Siniestro, IComparable&gt;&gt; sorterExp = null; if (search.SortOrder == SortingRCliente) sorterExp = x =&gt; x.ReferenciaCliente; GetLatest(search.FilterPrioritario, search.FilterFechaVencimientoStart, search.FilterFechaVencimientoEnd, search.FilterRCliente, search.FilterREntidad, search.FilterPoliza, search.FilterEstadoEntidad, search.FilterEstadoWillis, search.FilterFechaSiniestro, search.FilterProvincia, search.FilterFechaModificacion, search.FilterDireccion, search.FilterServicer, sorterExp, search.SortDirection.ToString() == "ASC", search.PageSize.Value, search.Page.Value);
Examples? The only tedious operation I have dealt with is stored procedures returning multiple result sets, and even that wasn't too verbose.
If you don't know EF very well you can run into performance issues, but that is true of any technology. I spent a weekend getting pretty deep into EF and learned a shitton; it definitely helped me avoid lots of common pitfalls and I found things pretty logical.
When you are just starting out, it really doesn't matter. Time spent deciding between languages is not going to make you a better programmer. Writing code and learning concepts will, just pick one and run with it.
Lets say you want to read just the FullName and PhoneNumber columns from a table. 1. You create an EF data context 2. You create your query `.Where(entity =&gt; entity.State == "CA")` 3. You add `.Select( entity =&gt; new NamePhone() {FullName = entity.FullName, PhoneNumber = entity.PhoneNumber})` 4. [Implied disposal of data context via using block] My DAL: return await Dispatcher.FromTable("Customers", new {State = "CA"}).AsModelCollection&lt;NamePhone&gt;().ExecuteAsync The DAL is smart enough to generate a select query based on just the properties on the NamePhone class and uses the anonymous object for the where clause. 
You get pretty terrible quality with speakers and microphones, I would recommend using the line out on a soundcard to run a cable to the other computer, or it will be very difficult to get a clean signal. Binary Frequency Shift Keying is probably the easiest format to experiment with this, but it is still quite difficult to wrap your head around DSP concepts! I have been trying to do it for the last few months to decode pager signals, you might find Software Defined Radio very interesting.
Or you can just attach the entity to the context and set its state to modified and call SaveChanges(). 
My problem isn't that you can have performance issues. It is that they are hard to see just by looking at the code.
Congratulations, you just stomped on some values that you didn't mean to change because the UI only provided the primary key and the columns it was altering. (Heck, the UI might not even have the other columns.) 
Hopefully a production app would be using view models and mapping them back to the entity to avoid that situation.
Sorry, getting a HTTP 400 there. 
I'm using bootstrap. But it does not appear to have any classing for Gridviews. At least none that I could find.
Thanks for letting me know. I couldn't reproduce the bad request, maybe something I need to take up with my ISP if it's widespread. Please try the github link: https://github.com/dsuryd/dotNetify
I haven't read the site yet but your message certainly resonates with me. I actually quit my career because I couldn't bring myself to go back to the dark ages of sucky software development tools. I'll check it out... 
Everything else looks decent but... Seriously??! A method called "Create" that's a property that returns null on get and adds to a list on set?? WTF??
We deploy via a ZIP file. Our build process sets an output path for the build, and we zip that up. It's then copied to our deployment server (just a file server). It's an automated manual process after that. We have a script that creates a new deploy directory (we track build numbers in the dir name so we can always easily roll back), unzip there, change IIS to point at the new folder and it's done. It's not as cumbersome as it sounds, but it is definitely rough around the edges. 
The `Edit`and other inherited methods would reside on the View Models. So you'd use your POCOs just to transfer data, your view implementation would still be specific to your UI, and it keeps the overall architecture fairly similar to what is already in use while building in a good separation of concerns.
We are using Octopus deploy and it is great. If there was a viable open source project out there we would have definitely considered it, so long as there was an option for support as well. 
Msdeploy does the work. Automated by Powershell scripts (e.g. Psake). Either executed manually or by the CI server (TeamCity, TFS, etc.). It would be awesome if Msdeploy were open source; as powerful as it is, I think the community could do a lot to make it more user friendly.
I put together a report at the end of last year about the state of deployment tools in .NET - http://www.davidwhitney.co.uk/Blog/2015/01/16/deployments-in-net-20142015-report/ - might be useful. 
Are you doing anything with your view state? Post backs? Can you add some kind of trace to get some more information?
How is this supposed to be invoking strings as functions without throwing errors? Am I missing something? This code doesn't look remotely like it would not error.
I'm not arguing, but with having that in a self executing function, does that make it easily minifiable? Frankly I don't give a crap about minifying (and I should), but I'm wondering if that was the intention.
Reading the comments here I realize now that showing that code in that first page without proper explanation a bit jumped the gun - I hope that if you go through the live demo page it will be made clear to you why that is.
If your using Azure and the whole MS stack the VSO build and deploy services are great. 
I tried various linker options and it still was &gt;20MB. Is there some trick you are referring to?
Yeah, to combine SP's for the update script.
Cool, thank you.
Thank you!
I don't do a ton of .net development at home, but when I do, it's on my MacBook. I use parallels, boot camp is a pain - I used it on my last MacBook. Switching between OSX and Windows has some quirks with with the keyboard - I have to do ctrl C in Windows and cmd C in OSX but it's not a big deal. 
I've been using Parallels and VS for a long time (on Windows 7, 8 and 10), worked like a charm. The only quirk is keyboard shortcuts, you need to spend time configuring Mac, Windows and VS. I switched recently to VS Code and .net core for my Asp.Net developments. Windows is no longer needed :) If you're using WPF for example you'll still need the complete .net framework. VS Code is starting to be mature. But it has limited intellisense, no resharper or scaffolding options. 
My team all uses Macbooks for developing .NET. I use Bootcamp and I've had no issues, and a few others use Parallels (but I've heard no end of issues they have had in Parallels including serious performance drops) I can't personally speak to these issues since again I use Bootcamp, but I never have need of going to the Mac side, so there's no reason for me to use anything other than Boot.
Bootcamp, so no quirks, all native. 
You just hit command-left and command-right. It's completely a non issue.
Whats the purpose? It lacks a description...
Maybe https://www.nuget.org/packages/SnarlInterface/
looks good, thanks!
I use a 2014 Retina MacBook Pro, 16GB &amp; 1TB SSD with Nvidia GPU. I appreciate a MacBook for its battery life primarily. I also like the multiscreen support (I have two Thunderbolt monitors in the office). I run Windows 10 Enterprise on Parallels for Visual Studio 2015. Works fine, no issues. The performance is fine. I've gone back and forth between Parallels and VMware Fusion many times, and I own up to date licenses for both. My latest experience is that VMware Fusion has a very slight performance advantage when benchmarked by compiling our large .NET applications. However, VMware Fusion had video defects that made it difficult to use so I went back to Parallels. Over the years as I've switched back and forth, Parallels always seems to win out. VMware Fusion used to have better Linux support for my Linux VMs, but with Parallels being based on KVM and virtio support baked in to any modern distro that's no longer the case. I don't run Bootcamp, because I take advantage of the fact that I have two OSes, OSX on one Thunderbolt and Windows 10 on the other to multitask more effectively. Bootcamp also has some severe limitations, such as Apple doesn't enable hardware virtualization in the EFI (firmware aka BIOS) so with Bootcamp you can't use Hyper-V for example. It's stupid, because the hardware supports it, Apple just flags it off. Bootcamp treats Windows as a dumb OS that it has to run in BIOS emulation mode with all fancy flags disabled, when it is in fact a (U)EFI supported OS and could be installed on its own GPT partition and the hardware features should be left on. The downside to having a Bootcamp partition and then using Virtualization to boot it is that because VMware Fusion or Parallels has to use direct disk access to get to the Bootcamp partition, it's actually slower than a virtual disk backed by a file. Basically, VMware/Parallels has to load a kernel driver and route all disk I/O through that kernel driver to work with your Bootcamp partition. I found as of 1-2 versions ago that there was about a 10% disk performance penalty in using a Bootcamp partition under virtualization. Overall, it's a positive experience, I have no desire to change anything. I'm glad I picked the highest end CPU, the discrete GPU, memory size, and SSD size. I would make the same decision today. I wish there was a Windows laptop that was of this caliber, I'm hoping eventually the Surface Book will get that good. But at the moment, this setup serves me well.
My job provides me with a Macbook Pro as my development machine and I had previously purchased one for home use before taking this job. * I decided to use a Macbook because I couldn't find a Windows laptop that could really match up to the Macbook in terms of durability, specs, and battery life for the price. Also Xamarin development for iOS requires OSX to build apps. That didn't weigh into my decision of purchasing the laptop at the time, but now would be a major factor in my decision as I develop in Xamarin a lot. * Parallels. I'd do Bootcamp but I like having OSX there for some tasks and I need it when developing iOS apps for the Xamarin build host. * Not too many weird Mac quirks. I don't use the laptop's keyboard a whole lot because at my desk I have a decent keyboard and mouse as well as two Thunderbolt displays. The laptop usually gets put to the side as a third screen. When on the move though I use the Macbook keyboard and it feels a tad clunky. * I don't run into too many performance issues. RAM is your friend when virtualizing, don't skimp out on it. I got the 16gb model knowing I'd have to run large projects in VS while virtualized. I don't notice slow down's unless I'm running Resharper and I load my company's master solution when has nearly 200 projects in it. We have smaller solutions we work in 99% of the time, though. * Yeah, I'd say I would. With Xamarin it's nearly a requirement if you want to do iOS. If you remove Xamarin from the equation I'd be more up in the air about it, but I'd probably still lean toward the Macbook. People like to hate on Apple, but honestly the Macbook is one of the best pieces of hardware I've ever owned. Also having the power of a Unix based terminal when necessary is fantastic. Very much more powerful than Window's command prompt (in my opinion). I really like having the abilities of both Windows and a Unix OS at my disposal at any given point.
I did for over 2 years, so my answer as of a year ago. **Why did you decide to do .NET development on a Macbook?** To facilitate both iOS and .NET development. Do you run Windows in Bootcamp or virtualized? Parallels or VMware? Parallels from a Bootcamp partition. Do you run into any weird Mac quirks when trying to use Windows? Mostly because I come from a long history of Windows usage, so keyboard shortcuts were weird. **What is the performance of Windows and Visual Studio, particularly when virtualized?** For the most part it was acceptable. I was running on a 2011 Macbook Pro 17" (I7/16gb Ram/512gb ssd). That laptop still runs great is now Windows free since I have a dedicated Windows laptop for development (we stopped our iOS project). **Knowing what you know now, would you still do .NET development on a Macbook if given the choice?** Not being a primarily Mac user, not by default. However, it wasn't a bad experience and I would not have any issues doing it again. Battery life for me wasn't as good when I was doing .NET development / running Parallels. The biggest thing I miss is: * Hardware build quality. * Screens with swipe left / swipe right. I never used "Cohesion" mode in Parallels either. Parallels integration with the file systems was nice. Networking sometimes was an issue when switching between my network at home vs work. I often had to change my virtual nic from bridged to nat and back for the different networks. Irritating but easy enough to do.
&gt;I miss having a Windows button that will let me just start typing and open a new application. Command + Space. &gt;I miss having a 'delete' key to remove the character in front of my cursor. Fn+Delete &gt;I miss having page up / down keys. Fn+up &amp; Fn+down &gt;I miss being able to use my mechanical keyboard for development. Plug your mechanical keyboard into the laptop? 
Yeah, I get it, there are alternatives. I obviously use them, but it's not as nice as having to press a single key. Thank you though. The mechanical keyboard (das keyboard) is not recognized by the macbook as an input device.
I do, and have been for over a year and a half. * I like my MBP, and didn't want to lug around a second Windows laptop. * VMWare Fusion Pro * No quirks come to mind * I've seen sluggishness in Chrome, but VMWare and/or Google seem to have fixed that recently. The biggest problem I have seen is with ReSharper, particularly with 10.0.1. The code completion lag makes it unusable. I had to disable it. * Definitely. Never had a MacBook, but it works very well on a MBP.
If you have experience administering a server then try Amazon Web Services. [aws.amazon.com](http://aws.amazon.com)
Currently I use my macbook and remote into my Desktop Windows machine using the [Microsoft Remote Desktop App](https://itunes.apple.com/ca/app/microsoft-remote-desktop/id715768417?mt=12). It sets up a second desktop for the remote window, and I still use my browser on my Macbook. Only annoying part is switching between command key and control key.
Cool, thanks for the super constructive feedback!
I'd have to read more about the "this.create" function which in the context of this snippet doesnt make any sense. this.Create would imply that it's a part of the StudentsVM object HOWEVER, your object literal does not define a "Create function" "this" should typically be used to refer to the object you're currently working with, otherwise it depends on the [context it's executing in. ](https://john-dugan.com/this-in-javascript/) without even testing it, I can make a general assumption as to *this* is why you use a self executing function. (because your "this" context is all screwed up. 
This is a really great resource, thanks for posting!
The free version of Octopus is enough for us. What limitations it has we can work around with a few scripts. If we're ever big enough that we need the full version, I suspect it'll be fairly easy to justify the few hundred dollars it costs versus Developer hours spent trying to work around it. 
You could use runtime interception with Unity, but you'll probably take a performance hit.
Surface Book is only dual core, lame.
Define "pricey"? The free tier is free. The shared tier is like $10/month. Not sure you can find anything cheaper.
Not exactly. This one is free and open source
Check out [PostSharp](https://www.postsharp.net/), specifically [this page](https://www.postsharp.net/diagnostics/net-logging). I think that'll do what you're looking for. Look in to Aspect Oriented Programming (AOP) if you're interested in a more generalized solution, it's a "pattern" developed to address this exact type of problem.
I press "^" and "$" instead...
if instead of a dictionary, you return: class Foo { public string Bar { get; set; } public string Baz { get; set; } } ...this serializes as: { "Bar" : "some value", "Baz" : "some value" } which is what you want i think.
Your OSs and development libraries make a difference, too. In general, .Net will ignore the GPU and do whatever it can through the CPU, so your CPU is going to be your bottleneck. WPF will take more advantage of the video card than WinForms, so that might be worth a try. Or develop something simple in Unity.
I suppose my point is your Angular controller could be just about as small if you wrote it in a more idiomatic way, so the comparison strikes me as unfair.
There seems to be only a 2x difference in terms of bandwidth between PCI-E 1.0 and 2.0, so that wouldn't explain it. According to Intel's documentation, the Xeon even has more bandwidth than the i7, and their performance are roughly equivalent, so nothing that could justify a 13x performance difference. Could you try some performance benchmarks and see if their results reflect your findings?
The WebSummit 2016-2019 is gonna be in lisbon, but that shouldn't be too technical... If I know more I'll provide :)
NDC London is in January. I guess that counts as 2016... http://ndc-london.com/
That wouldn't explain the 13x difference, though. They're not *that* far away performance-wise.
The command line stuff won't give you anything Visual Studio related. You get them from the undertaker at get.asp.net. We need more info as to what failed when you tried to install this however?
http://www.swetugg.se/swetugg-2016 They will speak english if a listener asks for it
So the answer was kinda silly. In production we have two webservers behind a load-balancer and at some point I decided to test the two servers independently by hitting them directly. This allowed me to discover one server was throwing the error 90% of the time and one server next to 0% of the time. I restarted the website and app pools for the server that was throwing it often and it seems to have stopped. One of the things that clued me in was that I had updated my error logging routines to try and log additional info about the error and I was still seeing the error being thrown without the newer details. I think the issue is that the dlls being used were old despite the code being updated. This is a web site and not a web application so the code gets compiled on first request. By resetting the site I think it re-compiled everything and things started working as intended. I am currently rewriting our deployment scripts to ensure the app pools and web site are reset/recycled on code changes to try and prevent this issue in the future. Thank you for all your responses and I hope this helps someone else at some point.
[Sdd Conf](http://sddconf.com/) in London
Sure, I made it. That's a generator of random documents to populate test database. I've tried to upload several hundred (edit- several hundred thousand) of such docs into the database using single DB Context. 
I think you are looking to [encypt the relevant config section](https://msdn.microsoft.com/en-us/library/zhhddkxy.aspx).
We definitely get similar exceptions in production, but not enough to concern me. To determine if 300 a week would be an acceptable number to me, I'd have to know traffic and usage patterns of the app. If it's 1 million users with ~20,000 active at peak time and your app is chatty, 300 in a week doesn't sound like a lot. If it's 100 users with ~3 active at peak and the app isn't very chatty, then 300 a week kind of sounds like a lot.
Thank you for your response. The API manager is not on premises. We use a cloud provider that acts as a proxy, transforms/filters requests (I think they are Java based?), and then forwards it to us with proper credentials for us to do real work. I really like the angle you are coming from on your suggestion. I haven't thought of that approach. It will probably take lots of convincing, but I'll see if I can work with IT to see if they can give me some visibility into the network-level monitoring on production.
No prob. Hope it works out for you. I used to play a ton of online games, pre-steam, and attempt to diagnose lag issues with similar tools. It's funny how those skills have helped me immensely in my professional career. 
All the failures aren't webhooks callbacks. Most of them are though. However, failed webhooks/total webhooks is about the same as failed other calls/total other calls, so I don't think the issue is the consumption of any particular type of API resource. Also, errors come from a wide range of API consumers. The reason that the webhooks ones matter a lot to us is because we want to keep our third parties that bring us lots of business happy and the APIs they are hitting are transactional in nature. If most of our API calls were only randomly breaking a UI, I would have been a bit more okay with straight up ignoring the exception. But yes, it's totally possible for some of these errors to be legitimate client disconnect errors. I think once I try a solution based off of /u/codegork's answer and see the exceptions diminish, I will start to ignore all these exceptions like the stackoverflow links suggest, that way I cover the highly probably case that you mentioned. Poorly implemented clients shouldn't show up in my logs (or at least in my exception logs).
I would use 4.6 but the specific tutorial I was following on pluralsight required use of this specific version (which granted seems odd).
The layout system is pretty simple, you really just need to know how `ViewBag.Layout`, `RenderBody`, `RenderSection`, and `RenderPage` work together. [Here's an article on dot net curry that I just googled up.](http://www.dotnetcurry.com/ShowArticle.aspx?ID=636) When you say you want to connect views to the database, I think you may be missing a strong design foundation. Data access in your views is going to reduce how much you can reuse your code and inevitably leads to maintenance headaches. Sometimes those headaches are unavoidable growing pains, especially if you're working on your own. I highly suggest finding a good asp.net mvc book and reading through it. It's been a few years since I read one, but at the time it was common for them to include a good walkthrough of building an application in the first few chapters. It may save you a lot of confusion. Just because you can find **a** way of doing something, doesn't mean it's not going to cause you trouble later on. 
I liked the tutorials over at www.asp.net. 
Meetup is a good place to find groups like this; there are lots of groups that meet weekly to give short work shops and recruiters attend those looking for talent.
Sounds good. Thanks!
The purpose is development the User Interface practices with differents frameworks using #Asp.net #MVC. I use the next css web frameworks. - bootrasp - materialized - foundation - blueprint - jqueryui - jquery - Skeleton - jQueryMobile - HTML5 I search people to come to the project to start to colaborate. 
namespaces methods fields and files as well https://msdn.microsoft.com/en-us/library/ms229026(v=vs.100).aspx
Generate regular checkbox markup and write it to a literal control. Then use jquery and Ajax client side to post back to the page using a [webmethod] You get full control over making standard HTML that you can access in JavaScript and jQuery, plus you get debuggable server-side code in the same aspx page to handle the post that doesn't require postback and can eventually be moved into a web service or another aspx codebehind. 
There are a lot of things wrong with it. And that's why it doesn't work.
Do you happen to have an example you can point me toward? I’m a little rusty on AJAX, having been mostly HTML/CSS/server-side for my career. I mean, I was hoping to avoid client-side crap (I’m a traditionalist where fallback is concerned) but I’m willing to get dirty to implement this functionality if it can’t be done entirely within ASP.NET.
You're wrong and my job is, in fact, exactly to teach other developers new technology. I'm going to guess that your job isn't guessing other people's jobs.
It's a paid tutorial, however I really like the courses they have at tutsplus. They had a building a CMS from scratch video course on MVC and it really helped me get spun up quick.
This is a very simple one that talks using JQuery instead of the scriptmanager. You don't even need Viewstate. http://encosia.com/using-jquery-to-directly-call-aspnet-ajax-page-methods/ As far as being dirty, this is actually cleaner. Webforms has a postback mechanism that's clunky. JQuery does a post that occurs without leaving the page, and the jQuery post is specific to the method you want to call on the server, so you're not throwing the entire Viewstate and page at the method. I use webforms without Viewstate or script managers and use webmethods to save records, retrieve data for display, and do about everything else using simple Ajax calls to update divs on the page. You'll learn good jquery practices you can use elsewhere, you'll learn about json, and you'll learn a lot more about JavaScript that isn't proprietary to Microsoft's older packaging. I know where your head is. Mine was there, too, for a long time. I've been using a stripped down webforms on my eventual path to mvc. My biggest hangup is not needing the bloat that's entity framework, but that's a different story. Good luck! 
VS 2015 has edit and continue during debug. May not be 100% like app_code, but I've had a fair amount of success. You can inspect runtime variables and code against them.
Have you considered using a more traditional project structure, instead with your 3 development websites manually set up in IIS itself rather than running them through Visual Studio? That would achieve your goal of always having your sites running without need to start then manually. You would of course need to compile manually but IIS is able to pick up when you do, and it is pretty straightforward to debug with "attach to process". It sounds like you are trying to fight against the framework too much which I wouldn't really recommend. 
Ditch the web site project.. Nothing but headaches
Well with your attitude and obnoxious comments, I feel sorry for them.
What's the advantage of this over Raspberry Pi ~~or Arduino~~?
Wouldn't it make more sense for your IT teams to have their own dev image?
I guess using the .Net language, and Visual Studio as the IDE? 
You can use both with Arduino and Raspberry Pi. Why do you think I asked the question? *edit* For those unaware, I should've linked the relevant info. For Arduino, the Windows 10 IoT Core supports the Arduino Wiring API. Which may not be all of Arduino. I'm not intimately familiar with that platform. &gt;Windows 10 IoT Core also supports the easy to use Arduino Wiring API used in Arduino sketches and libraries for direct hardware access. From [here](https://ms-iot.github.io/content/en-US/IoTCore.htm) As for Raspberry Pi, you can look at the bottom of [this](https://ms-iot.github.io/content/en-US/win10/samples/KitBlinky.htm) page and see the C# code they're running on the Pi. That entire page is a tutorial on how to run a C# app on Raspberry Pi. But even before IoT, you could run the mono framework on Raspberry Pi.
Have a look at the products from GHI electronics which use .NetMF. Http://ghielectronics.com 
Dev teams are quite small (10-20 person) and only few guys have same same of development tools. This way our guys can choose which tools they install (by commenting out or adding unneccesary tools) and we don't have burden to maintain multiple images. Software at images will easily go out of date and you don't want to update everything as a first thing to do when you get new machine. Your point is still valid one. I create my own image for virtual machines which I use as base if I want to test things out at VM. :)
In the interest of full disclosure are you an employee or do you own shares?
Thanks.
I see thanks! Let's see what else is in this thread...
If so, that's surprising! I don't get his question...
I could've sworn it was possible. I thought they made a version specially for it. IoT or something like that. But maybe that's just for the Raspberry Pi. Either way, I don't see why you'd use this over Raspberry Pi.
Thanks for mentioning this, I'll correct this if possible and if not, I'll delete this post, if you know about any good article about key storage, I'd appreciate it if you share it with me.
Would seem to me that the calling code is ALWAYS going to have to have a key to decrypt, no? In which case, what does asymmetric keys give you here? This is pretty standard fair for in place encryption in case the web.config gets LEAKED. If you make it onto the server itself, I'm already beyond the door.
Basically it depends on how it is written, some applications would have settings like that in the app.config file, some wouldn't, it's impossible to say without more information. .net code is de-compilable, by design. You could get a .net developer to use a tool such as [dotPeek](https://www.jetbrains.com/decompiler/features/) so have a look at the underlying code and see if they could figure out what was going on under the hood. Alternatively, contact the vendor and ask, but nobody on here can really help you further.
You get used to it and it has other benefits. As your builds get more involved your approach will not scale.
asp.net
Glad you liked it.
No worries, out of curiosity what is the application?
&gt; Keep in mind that this is within a try-catch-finally block, so even if the first if didn’t exist and the second if throws an exception when ds == null, it’s handled no differently than if the first if existed and was false. **You shall not use exceptions for flow control!** Seriously. Avoid exceptions like this if possible. And in this case it is possible. If `ds` can be `null`, then it is simply **sane practice** to check whether it is `null` before accessing it.
If ds is null, the second if would throw a NullReferenceException when accessing the Tables property. It's quite standard defensive programming (could be even more defensive...), though you could argue that an API that makes you repeat the same if clause over and over in your code, is a broken API. The method that returns the DataTable could be modified so that it either always returns *something*, and if it can't, throw an exception – the programming equivalent of what the Spartan "with your shield, or on it" principle.
Thank you.
Well, not only could .Tables throw an NRE, .Tables[0] could throw an IndexOutOfRangeException, and then .Rows could throw an NRE as well... Should you check for all that? As you see life can get miserable very quickly with defensive programming. An API you can rely on and that works for the code that's calling it is much better. As for combining conditions instead of nesting them, that makes the code harder to unit test and for tools to generate reports on the code coverage.
Its probably running .net micro framework, why you'd run this (or the few other boards like this netduino/ghi) over using Windows IoT on Pi2: Faster boot time (a second typically) - IoT can push a minute! Much lower power - couple of AAs last for a long time Simple interface without any messing to SPI, I2C, GPIO. Microframework is interpreted IL though, so its not the fastest thing. The successor to netmf is https://github.com/NETMF/llilum and that will compile C# directly to ARM thumb2 code to run on these low power micros (ARM Cortex processors) at very near C like performance. Also like you said in the other post, you can run mono on the pi, I think that is actually a better solution than IoT currently - I had a custom image built with buildroot + mono + opengl gui (gwen.net) booting in 2 seconds - on a Pi1 - IoT is far too bloaty imo. 
I do not remember specific tutorials that I've looked at. But here are two open source projects that have the 3-tier architecture that might be of some help to you. * [SmartStore.NET](https://github.com/smartstoreag/SmartStoreNET) * [MVC Forum](https://github.com/leen3o/mvcforum)
Thinking of the [Netduino](http://www.netduino.com/) probably?
You mentioned oauth 2.0 - I'm so confused about where it's officially at, its wikipedia page claims its got some [security concerns](https://en.wikipedia.org/wiki/OAuth#Security), but I still see it used quite often and hear about it a lot
It might not be perfect, but its pretty standard for sharing user data between services. It probably is easy to make mistakes in the implementation but I'm not aware of an alternative that is more widely accepted than OAuth 2.0 right now. Sure it may have security "concerns" but is by no means flat out broken.
Here's I think a useful article: http://nickcraver.com/desktop-build/
I think I found a pretty good compromise actually. I built a new MVC project from scratch. I moved all the code folders (App_Start, Controllers, Filters, Models, etc.) into an App_Code folder, then point IIS at the project folder as a website. And it works! With only 2 caveats so far: 1. When you build, your binaries conflict with your sources, so you'll need to delete the app's DLLs after builds when running it in IIS. (Need to look up how to make custom builds...) 2. Make a copy of Global.asax.cs and put it in App_Code. Don't add to VS project, it's just there for IIS to pick up. Now I have quick, on-demand compiles for most of my development time, with package management, debugging when needed and all the other extras from having a solution/project. EDIT: Caveat 3. Launching from VS results in conflicts with App_Code and compiled DLLs. After doing some searching, apparently the App_Code folder is hard coded into IIS (whaaat??) and you can't rename it or turn it off(!) Haven't found anything on configuring IIS Express in VS so it won't run App_Code. To get around this, I created a development build configuration to output DLLs to tmp instead of bin. 
NVMe ssd drive, like Intel's 750 series, is the best way to gain speed, in my opinion.
Try dnu restore and dnu build of the project from command line. That should show you what target monikers are missing deps. You might have to add a framework assemblies section to net451 if you are targeting the full framework.
Have you tried setting the proxy username and password in the address field itself? &lt;configuration&gt; &lt;system.net&gt; &lt;defaultProxy enabled="true" useDefaultCredentials="true"&gt; &lt;proxy proxyaddress="http://username:password@xxx.yyy.zzz.net:84"/&gt; &lt;/defaultProxy&gt; &lt;/system.net&gt; &lt;/configuration&gt;
generally you would expect that each layer would only access the layer below it, so if you create three projects in visual studio and use the Add References tool to link them up that should get you started. Something like 1. Foobar.Web (ASP.NET web application project type, MVC), which references; 2. Foobar.BusinessLogic (C# class library), which references; 3. Foobar.DataAccess (C# class library, probably has a reference to EntityFramework or something like that) You might also have; 4. Foobar.Common /or/ Foobar.Models (C# class library) which contains code which is shared across layers. 
running those commands work fine, however my referenced class library doesn't appear to be listed when running dnu build. What were you referring to by "add a framework assemblies section..."?
All calls to the DB are within a separate class that gets called. These separate classes are within the App_Code folder. Basic reads are just within that class (direct SQL statements), but inserts/updates/upserts are done within stored procedures. Everything seems to be hand-rolled instead of having Visual Studio build it out based on framework. Consistency in naming functions and methods are moderately inconsistent.
Sorry, I was a little hasty in recommending asymmetric keys. It won't buy you any extra security. As far as your code goes, the best you can do is use a per user store (useMachineProtection=false) so that other users who may access that machine would have to know the account password of the NT account before they could decide your passwords. In general what you have now would only protect you from someone downloading your web.config through iis which is already impossible with modern versions of iis. The user-based key storage would also help with others who may login to your machine but not as the special account you set up for your app pool.
Sorry, I was on mobile. Something like this: https://github.com/ashimoon/dotnetliberty-http/blob/master/project.json#L12 I had to pull in the System.Runtime assembly for example since I was using DataContractJsonSerializer and DataContractAttribute.
yes, accessing ds.Tables[0].Rows can throw an NRE, if ds.Tables[0] returns null.
Side related, data tables and data adapters are about the worst possible code you can have. The only acceptable use of a data table is for sql bulk insert and that's more of a limitation of the bulk insert api. Kill it with fire. Use dapper and real objects.
Windows Credential Manager for git. It stores git credentials in the Windows credential store so I don't have to enter them each time (which is why a solution where I don't have to enter proxy credentials each time it needs to connect is important :-))
Ah can you not just setup an SSH key and authenticate with Git that way? https://help.github.com/articles/generating-ssh-keys/
Tried that, didn't help unfortunately. I'll probably just wait till the program gets updated to allow me to specify proxy details directly. But thanks for the suggestion.
You're not the boss of me!
It depends on what the 'file path' is. Sometimes I get this error on assemblies if trying to build the project while it is running.
The file path is the default folder from wich other project can run. Nothing about it is running, no processes to be found with its name :(
I have this setup and I can use git over HTTPS, with no issues Something to look into
Then it's not rows throwing the exception. It's table.
&gt; Sure I don't really have a single program that would even need a 64bit visual studio Almost all of Visual Studio is still 32-bit.
Sorry I didn't see you replied until today. "I'm a bit curious what this interface would look like or how it would be used, though. Would you mind explaining this piece a little more?" Ok so typically the Model only has the properties that are being stored in the database. The ViewModel has those same properties but it ALSO has "special" properties, such as ones that have magical gets that do some sort of operation. For instance in my application a Model might have properties like int LineStartIndex{get;set;} and int LineEndIndex{get;set;} but then I might want int TotalLineCount {get{ return LineEndIndex - LineStartIndex; } . As this property never needs to be serialized, it doesn't belong in the model, so it is implemented in the ViewModel, which wraps the model. My application is pretty huge, and we provide an API for OEMs to develop with. I don't want OEMs to have to rely on my implentation of the ViewModel, so I have an interface that gets implemented by the ViewModel which is used in almost all places that would need to access any of the members of the ViewModel. So if I have: class ModeSettingsModel { int StartLineIndex{get;set;} int EndLineIndex{get;set;} } I also have interface IModeSettings { int StartLineIndex{get;set;} int EndLineIndex{get;set;} int TotalLineCount{get;} } then class ModeSettingsViewModel : ViewModel, IModeSettings{ internal ModeSettingsModel _Model{get;set;} public int StartLineIndex{ get{ return _Model.StartLineIndex;} set{ _Mode.StartLineIndex = value; RaisePropertyChanged(()=&gt;this.StartLineIndex); } } get{ return _Model.StopLineIndex;} set{ _Mode.StopLineIndex = value; RaisePropertyChanged(()=&gt;this.StopLineIndex); } } public int TotalLineCount{get{return StopLineIndex - StartLineIndex; } } and then anywhere else in my application where I use this I would just use a reference to IModeSettings rather than ModeSettingsViewModel "Alright, so the Project Model would have its own ViewModel for handling the loading and saving of project data to/from the database... and then each View has it's own ViewModel that essentially handles the Views' behavior and functionality? So the View's ViewModel would call the Project's ViewModel for the "hey, give me a Project model for {this table key's} project", and then that Model would be it's DataContext and handle modifying the Project Model data and all of the user/UI stuff? And does then the main, root ViewModel only hold the ViewModels of the various Views, or would it have the Project Model's ViewModel, too? Would the Project ViewModel be a child of the root ViewModel, or would it be a child to the ViewModels for the Views that use it? Am I getting this right, at all? " Ok, this part might get a little complicated. So for all of the ViewModels that are wrapping a Model that gets saved to database, I instantiate the ViewModel using a Factory class which looks like: public interface IViewModelFactory { void RegisterViewModel&lt;TM, TVM&gt;(object model, TVM viewModel) where TVM : ViewModel; TM GetModel&lt;TM, TVM&gt;(TVM viewModel) where TVM : ViewModel where TM : class; T GetViewModel&lt;T&gt;(object model) where T : ViewModel; } so if I have a Model Hierarchy of several related models, the wrapping property in the ViewModel will look like this: private ModeSettingsViewModel _ModeSettings; public ModeSettingsViewModel ModeSettings { get { if (_ModeSettings == null) { _ModeSettings = ViewModelFactory.GetViewModel&lt;ModeSettingsViewModel&gt;(_Model.ModeSettings); } return _ModeSettings; } } IModeSettings IThisViewModelsInterface.ModeSettings{ get{ return ModeSettings; } } The second part allows me to define everything through interfaces and reduces dependencies. then when I'm getting entities from the database I will do something like DbContext.Modes.Where(m=&gt;m.DoesMeetSomeCondition()).Select(m=&gt;ViewModelFactory.GetViewModel&lt;ModeViewModel&gt;(m)) so far this is just for 1:1 Model to ViewModel type database entities. Then using MEF I have mode ViewModels which are 1:1 ViewModel to View. These are all instantiated with MEF and are application independent. public interface IApplicationContext{ IDbContext DbContext{get;} } [Export(typeof(IApplicationContext))] public class ThisApplicationContext : IApplicationContext{ private ThisApplicationsDbContext _DbContext; public ThisApplicationsDbContext DbContext{get{ if(_DbContext == null) _DbContext = new ThisApplicationsDbContext (); return _DbContext; } } [Import(typeof(IViewModelFactory))] public IViewModelFactory ViewModelFactory{get;set;} } [Export] //This tag is for exporting in MEF public class ModeConfigurationViewModel : ViewModel{ [Import(typeof(IApplicationContext))] //import through MEF public IApplicationContext ApplicationContext{get;set;} public List&lt;IModeSettings&gt; ModeSettings{get{ return DbContext.Select(m=&gt;ApplicationContext.ViewModelFactory.GetViewModel&lt;ModeSettingsViewModel&gt;(m)).ToList(); } } [Export] public class SomeOtherViewsViewModel : ViewModel{} public class MainWindowViewModel{ [Import] public ModeConfigurationViewModel ModeConfigurationViewModel {get;set} [Import] public SomeOtherViewsViewModel SomeOtherViewsViewModel{get;set;} public ViewModel CurrentViewModel{get;set;} } and MainWindowViewModel can just hold everything while CurrentViewModel will manage which is currently displayed and you can set up hierarchies like this. Then all databinding is handled by using the ViewModel as the View.DataContext member. None of this will compile I typed it all up in this tiny little comment box lol but if you need more help it would be easier over skype if you want to send me your contact info. Good luck!!!
Multiple times, but i went to my rdp and it worked like a charm. So i guess it is fixed now
There is no advantage over the Raspberry GPIOs per say. It is the same thing but for Windows and the programming language C#, vb.net, powershell.
I have the exact same problem and I have not come up with a solution. I have just been ignoring it, because as you said, everything build/compiles, we just get syntax errors for everything in the library. If you find a solution, please share it. 
With Nusbio, Yes you can use any Visual Studio 2012, 2013 or the new 2015 community edition which is free now. Any .NET languages, there are demo on the web site in C#, vb.net, Powershell and F#.
You can if you aren't querying. When all you want is a bucket to stuff shit into, it doesn't matter if the bucket is DynamoDB or .ini files or Entity Framework or dapper. 
Is it a webserver? Your app pool user must have read/write permission to the folder. 
Devperez , thanks for your answer. I actually was not asking. But I was trying to introduce Nusbio. Nusbio is a USB device that brings 8 GPIO pins to Windows and to the .NET Runtime and the programming languages: C#, VB.NET, F#, PowerShell. All the code is written in C#, it is a more native approach to controlling GPIO than using an Arduino and Firmata. It is also very .net friendly. That's all. Your feedback would be appreciated. Thanks 
Even then issues of transactions can come up, but I agree that it matters less then.
Have you tried running vs as admin, this usually means either a file is locked or a permission problem. Can also mean a full disk. Also, check that any external references are able to be reached and copied. 
No it is on a local machine, winforms
start here https://github.com/approvals/Approvals.Net.Asp 
you could also check if the number of DataTables in the dataset is larger than 1 if(dsL != null &amp;&amp; dsl.Tables.Count &gt; 0 &amp;&amp; dsL.Tables[0].Rows.Count &gt; 0) { } 
Yes...this is due to the license on a control library it depends on. I will build a Release copy and distribute that, and explain further on the README shortly...
I like your blog posts, but it would be **great** if you could participate and contribute to this subreddit besides self-promotion.
He Does... Futhermore this link is to a dotnetcurry article... not his dotnetliberty blog...
A lot of his recent stuff is definitely blog posts. It's probably because ASP 5 is red hot right now. I imagine after release it will die down as we have all covered the topic a million times over. But in general I agree. Self promotion is cool.... just don't post every blg you write... let others discover you.
Testing controllers proper is a bit of a pain - for the most part, you're testing external dependencies, which is kind of a no-no. If you have logic in them, consider moving it out to service classes that hold the logic that you'd test (handle exceptions in your controllers and try to farm the meat of the work elsewhere). If you have logic in views, consider using view models - wrap your business entities with view-specific logic, test the view models. If you didn't decompose your logic into small, easy-to-test chunks (and this is the biggest benefit of unit testing, at least on par with preventing regressions), testing it now is going to be painful, so be ready to refactor.
* I don't believe it's possible by default. * It's unlikely that it's possible even with a bytecode cache, but the performance could be close enough not to matter. * It might be possible under [hhvm](http://hhvm.com/) or similar, which should give php somewhat similar conditions to .NET, except .NET jitter is (most likely) much more mature.
Also, .NET 4.6 brings SIMD support to .NET which can improve performance by anywhere from 10-30%. I know very little about PHP but kind of doubt they've got a well-baked SIMD module.
My coworker claims to have written an ERP system in PHP. I shudder just thinking about it.
&gt; while I agree your views should be skinny, Do you mean controllers? Cause I have never and wouldn't even consider testing a view, regardless of any logic it contained. 
I'm forced to wonder if he's like the grade school loner kid that just wants to be liked and appreciated. But anyway, yes, I don't see how PHP could possibly be faster since it keeps all variables as arrays and is an interpreted language.
I wouldn't "unit test" them, but I would test views through the UI.
The long and short of it is. No PHP is not an optimal choice and C# would be better. That being said, it could be possible for your friend to beat the benchmarks. Either he finds a php compiler that is optimized for numeric calculations or he builds his own php compiler targeting numeric calculations. In software, you can do anything with anything. There is a saying "If all you have is a hammer every problem looks like a nail". With enough brute force it's possible to make his statement true. However, I don't see it being possible with out of the box stuff. 
Indeed, it is an anti-pattern to unit test controllers. If you want to test controllers it should be as a functional/integration test where real http requests touch the controller.
He is trolling you. As long as he isn't in charge of making architectural decisions on your projects, he's harmless. Under the right conditions anything is possible.
Did NuGet die?
nuget is for server-side libraries
Package management is a mess in asp.net 5, for beta 8 we had to configure gulp to only take files we needed from bower_components and put them in /lib. With RC1 they introduced the bower package management (ui) and that thing copies EVERYTHING into /lib creating a MESS in my wwwroot. In a perfect world we should only ever have to use nuget, prior asp.,net 5 i never cared for bower or gulp or grunt or this or that. MS needs to really just make a new package manager that encompasses a clientside/server side that we can use and exclude files we dont want that come with client side libraries. 
Bower/NPM + Grunt/Gulp are the new fancy kids on the block. To me, it feels like javascript developers are taking over. I use these tools in our enterprise projects but they are a pain. I still prefer NuGet but am trying out the new stuff. A major pain for Bower/NPM is getting them to work properly over an enterprise proxy. One release they work, the other they don't. So now I have to run Fiddler to have them traverse the proxy but that just causes our endpoint "security" software to use up 25% CPU permanently.
I was looking into gulp-copy so I could copy from node_modules into wwwroot/lib and remove bower altogether. At that point, I think I decided to drop back to MVC5 and use Nuget for everything. React Core + React Mvc4 is working after some hair pulling.
Yes Fiddler can be. What happened was a couple of months back, I discovered that NPM and Bower supported the "http_proxy" and "https_proxy" environment variables. The awesome thing was that one supported it only in lowercase and the other only UPPERCASE. There was a GIT bug and the way they fixed it was that they added an extra if with the upper and lower case and copied the code. WTF right? Why not lcase or ucase check... Anyways, their proper proxy support was far behind anything else in the Microsoft world (I guess it must be a relic from the Java side of doing things, which can also be an enterprise nightmare). I discovered that while trying to figure out what calls BOWER/NPM made using Fiddler, everything would work. Closing Fiddler I would get 407 proxy authentication errors. So now, I open Fiddler at the same time I open Visual Studio and those tools now work. For the API management isn't too too bad, but you have to remember to set versions once you move to test/prod or else each deployment might update the versions at each deployment/build (though you must also do that for NuGet). I liked using NuGet for server stuff, NPM for deployement tools, Bower for web frontend stuff and Gulp to move/uglify/minify the Bower stuff. The problem is that I am not able to find all required frontend stuff in any of the three repositories (NPM/NuGet/Bower) so it's a mix. Also, for some server NuGet packages, it downloads frontend code such as Javascript. SignalR is an example of this.
Hey I think we use that ERP system. At least its as terrible as that sounds like it would be.
I've been trying to find a defentive answer to this too. It used to be so simpler.
reading the comments on this thread -&gt; https://www.youtube.com/watch?v=xZDK_LG9DuU
Because it would be almost useless and more effort than any possible return you could get out of it. How would you even go about testing a view? running it through the compiler to get the html output and testing the dom (these tests would break with any related html changes that have no effect on behaviour...)? At that point you're not even really unit testing since you're including a whole bunch of additional components.
PHP isn't compiled...
here's how to unit test them (without additional components). https://github.com/approvals/Approvals.Net.Asp/blob/master/ApprovalTests.Asp.Tests/Mvc/MvcTest.cs the relevant 2 lines are 32 MvcApprovals.VerifyMvcPage&lt;TestableExampleController&gt;(c =&gt; c.TestName); 52 return ControllerUnderTest.SaveName(new Person { Name = "Henrik" }); as for whether or not the view is considered behavior I guess might be a bit of personal option, but I find that if the web pages don't work then my customers are very unhappy.
Async in fact makes everything slower, except when it intelligently runs everything synchronously anyway.
Why not just try it and see for yourself?
You don't need SEO for your web pages? Because AngularJS is awful for SEO.
4.5.2 is still fully supported
If he really said "given *the correct conditions* PHP could *approach* the same calculation times as .NET" he's basically right. Just like C# can approach the performance of C and C++ in the correct conditions. In the end it's all about the efficiency of the algorithm that's being performed and how your data is aligned, does it fit in the cache and so on. The PHP interpreter might end up producing something really fast in some cases.
Can you post an example of that? I'am curious how you translate that to Javascript.
3.5 SP1 is still supported. Makes sense, as &gt;= 4, each version was an in place upgrade of any 4.x versions that came before it, but before 4.0, the versions were installed in seperate directories.
That doesn't test any behavior in the view.
4.5.2 is still supported which is the upgraded version of 4.0 so it makes sense to stop supporting un-upgraded versions. Also, 3.5 sp1 is still fully supported until windows 10 support stops.
Correct, traditionally php is not compiled. However, you *can* compile it. Just google PHP compiler and several options will come up.
So then at build, the rules are translated into some JS, and then on a submit, or event, JS checks the form value against whatever JS function rule you have created?
I wasn't aware that people actually wanted to have VB supported anymore
SEO for the site should be fine. Static content, like landing pages, will be indexable where as the user pages will utilize angular.
And here I am, overjoyed that my shop has approved 3.5 finally.
Why .NET? Why not? Its great for web with ASP.NET MVC; its great for web api; C# is a language used in Unity for 3d games and whatnot; Mono can make .NET work everywhere; Visual Studio 2015 is the best IDE there is.
It was always open source, welcomed outside help and had a great communicative team. Being able to run the wealth of Python code on .Net is very useful too.
I haven't heard of a web application being certified. They may mean that they have MS Certified developers on staff.
Open sourcing is a huge push for MS right now... I mean their basically open sourcing almost everything under the sun at the moment. It takes time to move that much code int open source! Also, they are integrating with a lot of open techs like git/bower/node.js. Ontop of that... one of the reasons they are ditching support for old frameworks is because ASP 5 .net CORE is supposed to run on open source OS like Linux or OSX. If anything the last year has been a massive righting of the ship for Microsoft. I for one couldn't be *more* happy with what they are doing in the open source world.
&gt; Check out the new DMX stuff with .Net 5. Sorry, what is this in reference to? I looked around but I only saw lighting controls...
'n' damnit. Sorry. dnx http://blog.tonysneed.com/2015/05/25/develop-and-deploy-asp-net-5-apps-on-linux/ http://docs.asp.net/en/latest/tutorials/your-first-aspnet-application.html Use Code as well. It's free. It's fast. I just found out about it two week ago. I am loving it on Mac.
Yeah, but VS code doesn't really have anything to do with .NET
Sure, but in that quantity you will surely find some quality? No different to any other tech? 
Yeah WebApi.Client is nice, especially the whole MediaTypeFormatter abstraction :) PS. Dunno if you used .Result for brevity in sample code, but it's generally considered bad practice to mix await and .Result / .Wait. Depending on whether you have a SynchronizationContext available or not you may wind up running into deadlocks...
Do you do c# in vs code? I'm confused how c# works in vs code without the compiler. Also how is code nav/gen compared to visual studio + reshaper?
Just to the very short tutorial. It will show you the differences pretty quick. Code nav is surprisingly great. The compiler is done via the command line but writing an extension to Code would be trivial if not already done.
Cool yeah was just reading up on c# in vs code. Doesn't seem like an ideal ide for heavy backend dev but a solid option for the front end.
I would increase the connection timeout in the connection string. My guess is the query return sometimes takes longer than the default depending on machine load.
A few things that look like code smells are that the Sfhelper, Zdhelper, salesforce and synctollcontroller classes look like they have too many responsibilities. Things like cases, accounts, and users could be grouped together for better cohesion. Another thing I would want to know is the purpose of LogOutput? If it's for logging as the name would imply, I would suggest looking at log4net or Nlog. No point in re-inventing the wheel. Edit: a word.
Java's dynamically typed!?
Agreed. I run the tech side of a startup and we have built our app in C#/MVC/Knockout/MSSQL/Azure. Every time the conversation of "why" comes up the answer is pretty simple - yes we are small now, but some day we hope not to be. If we have a R&amp;D team of 30 some people I sure don't want the server side code to be written in JS on Node. Although in Webforms/early MVC days I wouldn't have made the same choice. 
Once you use LINQ, you can never go back to Java.
When deciding on what stack to use for my next project, I prototyped in MEAN stack, it had everything I wanted. It didn't take me long when I was prototyping to realise I really didn't want MEAN. As a professional .NET developer I have a few beefs with ASP.NET. I considered just using WebAPI as a thin client and going mostly client-side. I looked into ASP.NET 5 MVC 6 and Angular. I prototyped in beta-8 and was blown away. It's beautiful, I've actually paused production to wait for the RTM which is anticipated early 2016 IIRC. They're introducing so many breaking changes currently, understandably. I wasn't too sure about using server side MVC, and client side MVC (Angular). I was considering using a library like Knockout instead. But the routing sold me, server side route to say /user/settings, then client side routing on top /user/settings/#/security. I love it. .NET just got a lot sexier since they've open sourced.
No, it's statically typed, early versions were too statically typed if anything.
Runs only on Internet Explorer?
http://ejie.me/ I use Clover, its a little buggy at times but works well enough.
Exept you couldn't support a family on that. What a stupid argument. 
I use [Total Commander](http://www.ghisler.com/), which is awesome but takes some getting used to. Awesome because two panels with unlimited tabs, plus shortcuts (F5 copies selected items to the other panel, insert selects an item, numpad + allows for very flexible mutliselection, ...) and fully customizable.
No, I meant that it drove people to dynamically typed languages by being a statically typed language that made the type system a chore to deal with rather than something people actively wanted to use. Sorry for the confusion. 
[**@Nick\_Craver**](https://twitter.com/Nick_Craver/) &gt; [2015-10-03 21:30 UTC](https://twitter.com/Nick_Craver/status/650422589068836864) &gt; @kevindente Until you’re out of BizSpark it’s awesome - honestly trying to change the after story…for everyone. ---- [**@Nick\_Craver**](https://twitter.com/Nick_Craver/) &gt; [2015-12-04 00:40 UTC](https://twitter.com/Nick_Craver/status/672576232303828992) &gt; Maybe we won’t upgrade to Windows Server 2016. Core-based licensing? And 1:8 conversion when we have 18 core procs? http://www.zdnet.com/article/microsoft-windows-server-2016-to-move-to-per-core-licensing/ ---- [**@Nick\_Craver**](https://twitter.com/Nick_Craver/) &gt; [2015-12-04 00:45 UTC](https://twitter.com/Nick_Craver/status/672577398362238976) &gt; Core-based licensing does not scale. You know what does? Moving to a free platform where the cost savings keep on growing. ---- [**@Nick\_Craver**](https://twitter.com/Nick_Craver/) &gt; [2015-04-02 13:44 UTC](https://twitter.com/Nick_Craver/status/583626021636706305) &gt; The most unreliable, inconsistent, and frustrating part of SQL Server: licensing. ---- [**@Nick\_Craver**](https://twitter.com/Nick_Craver/) &gt; [2015-10-03 22:04 UTC](https://twitter.com/Nick_Craver/status/650431296800329728) &gt; I certainly see why people move off of SQL Server due to licensing. It must be about 50/50 between "the price” and just "the licensing”. ---- [**@spolsky**](https://twitter.com/spolsky/) &gt; [2014-02-11 19:35 UTC](https://twitter.com/spolsky/status/433323487961178113) &gt; Wondering if anyone has ever ported a very large, super-optimized, high-TPS database from MS-SQL to PostgreSQL and lived to tell the tale ---- ^This ^message ^was ^created ^by ^a ^bot [^[Contact ^creator]](http://np.reddit.com/message/compose/?to=jasie3k&amp;amp;subject=TweetsInCommentsBot)[^[Source ^code]](https://github.com/janpetryk/reddit-bot) 
The Raspberry PI is great, but it is not my Windows machine.
Interesting. I had never seen those. The one from Joel is particularly telling. Consider me corrected.
Neither is it mine. Give mono a shot. 
Works perfectly fine for me on Windows 8.1, though I've heard it doesn't work that well on Windows 10 at this time. Also, Clover's best feature IMO is the ability to have favorites folders.
I'm looking for an alternative to Clover. It's OK, but it's buggy as hell.
For now, yes. Check out this video: https://www.youtube.com/watch?v=mSeN_N3mOxg Skip to the end to see the native docker stuff. 
&gt; Also, Clover's best feature IMO is the ability to have favorites folders What feature is this? I don't understand exactly. You mean bookmarks?
I don't think the author is saying there are no C#/.NET jobs... more that there aren't many **startup companies** using C#. I'd agree with this, although there are certainly some - startups are cost conscious, moreso than most large companies, and for them the licensing of SQL Server alone can be prohibitive. I've certainly found .NET to be much more heavily used by established and enterprise companies, rather than startups. Add in the fact that a few years ago Visual Studio had no free version (and is still non-free for many of the team based tools), plus .NET hosting being more costly than most other hosting, the need for Windows based servers (not cheap), and the .NET stack can be fairly expensive.
I find many startups use something like RoR/PHP initially, before migrating away later. Especially with "API first" being more and more common, it's becoming much easier to start with another language then migrate later.
I have but usually for things like "Why does this antiforgery token not pass verification when shared across sites using shared cookies?" Kind of edge case stuff that isn't likely to be documented because its outside the default usages. For those curious, it was because site A had authentication, and site B didn't, and the Antiforgery token handlers will use the authenticated user, if they are logged in, as part of the generation and verification of the token. Meaning if the token was generated on one side, and a cross site call was made, it couldn't be verified on the other side. Something which we would not have been able to figure out if the source code wasn't available for MVC, given that we weren't able to find ANY documentation about that behavior.
I guess it depends on "organized" you want to get. I either pin it to Explorer or just add it to the favorites menu. The favorites menu works best for me. http://i.imgur.com/mtJH8Ky.png
thanks! i didnt find that link
&gt; high quality libraries ignores that .Net, C# doesn't need them. Sorry, what? I disagree completely. While the core .NET Framework supplies fairly decent defaults for 90% of cases, there are plenty of places where better libraries are needed. Off the top of my head, the file access abstraction is SLOOOOW and the FileWatcher stuff is basically unreliable due to the buffer fill issues. Don't get me wrong, I love .NET and it's my bread and butter for a reason (and there's reasons Java ISN'T), but lets not fool ourselves into thinking that Microsoft's answer to these problems is the only one we need.
An interesting edge case, although that's the first I've ever heard of someone needing to check to this level of detail. Still, though, I'd argue that should've been documented in my **ideal** stack :p
&gt; lets not fool ourselves into thinking that Microsoft's answer to these problems is the only one we need. I didn't say that. I said that Java as a language and framework has fallen behind and needs quality third party libraries. .Net already provides great libraries, however I also said: &gt; With the exception of a few like Json.Net So you can add your file access stuff to those exceptions. But I'd argue that you can do the same in .Net with the provided libraries that would take you 20 or 30 dependencies to do in Java. Even something so basic as making http calls is a nightmare in Java unless you use the Apache Commons libraries, while System.Net is great. Microsoft's way isn't the end all be all. But you don't NEED third party libraries in .Net. In Java, without third party libraries, you are fucked.
I'd agree with this - the benchmarks in the original post are with apparently stock PHP setups, which is very much an unoptimised environment. In **ideal circumstances** I agree with you that with bytecode caching it should be close enough to not matter. More importantly, PHP can be compiled.... PHP as used by most people is slow. PHP can be made pretty damn fast, however (see: Facebook)
More importantly, there's nothing to say PHP has to be interpreted... Compiled PHP is fast
I don't have that command. MSDN says it's a part of the System.Data.Objects namespace, but that won't add for me either. Clearly I'm missing something stupid here...
Microsoft does provide some decent defaults, I'll concede that. I just run into too many people that will ONLY use the Microsoft solution, even when it's obviously worse than others, simply because its the built in one. That's one area where I'll say that Java's approach to this is better, because you get less developers afraid of branching out into third party land. The fact that Microsoft is basically scrapping the framework and instead putting out first party NuGet libraries with the Core framework kind of gives me hope though that people will stop treating the Microsoft framework as a monolithic solution to every problem.
That's actually a really great idea. Extension methods are probably the biggest thing I miss from C# when working with Java at work, such a nice way to extend functionality and not have to use ugly *Utils static classes everywhere. That and real generics (Java compiles down to &lt;object&gt;, generics are essentially for compile time warnings only)
Its actually a kind of hard thin to document in this case. The implementation details were so specific that without looking at the actual code it would be difficult to really explain what was happening. I've had other ones too, like how selected works in a SelectList for the MVC Dropdown helpers. Its better documented now, but back around MVC 2 / 3 it took some tinkering to get those to work the way you'd expect them to. I'd actually argue that while good documentation is a godsend, nothing beats being able to look at the actual code / logic that is executing. That's not saying anything about any real examples of documentation, just that I totally agree with OP on this.
This is just wrong dude. You should NOT use NuGet for frontend package stuff. The developers of the frontend stuff don't package it for NuGet, so now some random guy has to repackage it for NuGet and he will always be behind. Plus the extra abstraction that ain't needed. We don't live in a Microsoft world, and Microsoft have acknowledged this and embraced it. I would encourage everybody to do the same :) 
Bower/NPM are not "new kids on the block" they have been around for some time now. They are frontend packaging like NuGet is .NET packaging. I just suspect that some/most .NET developers have lived in a Microsoft boble, and it is bursting atm.