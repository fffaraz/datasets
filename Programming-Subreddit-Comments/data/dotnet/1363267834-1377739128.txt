Ok, but when you are long gone, and they need someone to make a change to your application, they will curse you to no end when an iOS developer tells them "uh - the previous guy wrote this in a non-industry standard manner...youre going to need a complete rewrite, or I cant help you." Anyway, to each their own. Easy is not always best. This is *bad*.
You don't need to use strong naming to get InternalsVisibleTo to work. This article doesn't mention the most common use of the attribute, to test internal classes from a separate test project
I still have no idea what this does
Most people writing cross-platform mobile apps are using C++ and then write the right amount of Objective-C, Java and C++/CX (or C#). In fact I think that people writing iOS apps are writing C++ mainly, and Objective-C only when they have to.
Any thoughts on how to clarify? The general idea is that any metaprogramming over the internal structure of classes via reflection, you can do using this framework in a type safe way. The examples provided are binary serialization, tests for transitive immutability, and deep copying without needing to serialize a whole object graph.
Sure, that's what I did. But it's not a paticularly good answer except for games where you might need c++ performance. C++ has low productivity compared to c#. 
I agree with you. I'm just saying that most companies out there don't code iOS apps using mainly Objective-C. For them C++ is the main language, Objective-C is something they can't evade.
We regularly push thousands of messages per second through rabbitmq and it doesn't break a sweat. I'm not sure if ironmq is slow, or your client code, but 26 messages per second is nothing. 
&gt;I learned C# in about a week. I learned Objective-C in about a week. No.. you didn't. This line of thinking both terrifies me, and tells me volumes about you. &gt;Learning a new C-like language once you already know one of the other C-like languages is pretty easy. (By C-like languages, I mean: C, C++, Java, C# and even Objective-C) Learning statement *syntax* is less difficult, with prior knowledge of another similar language. There is an *incredible* amount of detail that is in there and in the frameworks that should be learned. Assume knowledge of Javascript based on your C knowledge and you will be in for a rude awakening. Just like learning an equivalent word in French does not make one fluent in French, or even good at it. Now, I know nothing about you, so please don't take that as a personal attack. I'm trying to be fair to you in this. &gt;Learning the full framework API takes more time (if anyone ever really fully learns it), but with languages like C# where your IDE provides intellisense/code-completion/etc, it really helps speed the process along. The language is not even relevant without the API. &gt;Actually, it can. Their C# compiler can most definitely compile itself. It's also not a precompiler, it's a real compiler. It compiles the code to IL. What translates the IL to code that the iOS devices and Darvik devices can use? &gt;People who use Xamarin don't have to learn both iOS and Android APIs, they can pick just one if they want to. Wrong. There is no common framework between these two platforms. You have to pick one. Show me C# GUI code that will run as-is on both platforms. The CEO over there even boasts that this is not their goal. I would almost appreciate it more if that was their goal. In essense, HTML 5 *does* state this goal however. And yes, they *could* pick just one if they want to, but then....why use it at all? &gt;You can;'t come up with a single good reason not to use it, all you've got are logical fallacies. Afraid not. I've got plenty of experience in the industry, over 20 years to be exact. I've witnessed these things come and go, and the havoc they eventually cause. I was there when CoBOL was being replaced and "layered" by other "tools", to make development "easy" and "cross platform". Those guys? Yeah, they are back to writing code the normal way, and those tools are long gone. Those companies who invested eventually paid more when their applications needed to be re-written. &gt;Hence why you so obviously feel threatened. You are afraid that your elitist ways will land you in the poor house because you were unwilling to adapt to new technology. Yes, I feel threatened for not "adapting" to new technology. That must be it. Should I tip you in bitcoins or dollars? &gt;And just like C# and other higher-level languages have largely replaced the lower-level languages on desktops and servers, so too will they on mobile devices. Wha? C# hasnt replaced C++ in anything but *business applications*. Android uses a flavor of Java which the community is quite happy with and isn't going anywhere. Any iOS developer will tell you that Objective-C is the language for them, and is the core to their desktop OS as well. And Microsoft is pushing their mobile development with .NET. Nothing is getting replaced. &gt;The great thing about C# is the ease in which you can invoke code in lower-level languages like C if/when you actually need it. Not sure how this is relevant. Android can make calls to the NDK. Objective-C can call C *by definition*. You seem to be confusing Java and Objective-C with Logo or Commodore BASIC. &gt;I do. What's best for them is a better product at a lower cost that they can ship sooner rather than later. I don't agree with your premise. That a translator will create a better, cheaper application is less time. I would challenge a competent developer with Xamarin vs a competent iOS and Android developer for speed, performance, feature set, and *maintenance cost* anyday. You are dependent on the features provided by Xamarin. An Android and iOS developer only depends on their direct platform. Seriously - you must understand that you're adding another layer of dependency that your company requires now, in order to further development. This isn't cheap or wise. Not to mention the additional cost of purchasing licenses of Xamarin itself for the developers. How many $0.99 apps do you need to sell to pay for the enterprise license of Xamarin? An Android developer pays exactly $0.00 for his/her tools... An iOS developer pays $0.00 for theirs. &gt;C# is a far more productive language than Objective-C, This kind of statement just makes you look silly, sorry. I actually prefer C#. But productivity has nothing to do with it. You learned both in a week, remember? XCode has "intellisense", Eclipse is quite well versed in Java. &gt;the app is done sooner Says who? &gt;the app has fewer bugs You think that C# and Xamarin magically creates less bugs than a competent iOS and Android developer? Really? I would be interested in the evidence to support your position. &gt;the app costs less to produce because developer time is the most expensive part of the overall cost I dont see how you make the leap that the app costs less to produce because you're using C# and Xamarin. A developer costs what a developer costs. Sounds like you're selling yourself short, or over-estimating what a real iOS or Android developer costs. These three points are all marketing-speak. &gt;I am an iOS developer. I know the iOS APIs. I've written dozens of iOS apps. How does that not make me an iOS developer? By definition, an iOS developer would know how to write iOS software using the Apple-anointed language, which happens to be Objective-C. Same with Android and Java. Same with Microsoft and .NET. If you apply for a job as an iOS developer knowing C# and Xamarin, you have misrepresented yourself. I think I stated that before. You indeed may be - I dont know. What I believe though, is that you *prefer* this tool (or are an employee of Xamarin). Preference is fine for personal opinions. But none of your assertions make any sense. You know, many Linux guys are accused of being "elitist" because they push vi or emacs or other hard-to-learn text editors. They aren't elitist though. The reason they do this is simple - it's something that can count on being there. Just like you know on every Windows system that you will find notepad.exe. It's important to be able to rely on a standard. When you choose a style, product, solution, whatever - when it comes to other people's money - you should always think about industry and conventional standards. You are protecting them by doing so. 
Must be my client code. How would you speed things up though?
Rabbitmq is just fast, but you can do things like make queues non-durable, ack in batches (or disable acking), tune prefetch counts, use fanout over topic exchanges, etc... If you're interested in rabbitmq I've been working on a C# library (https://github.com/jonnii/chinchilla).
Some VS solutions show all errors on build. If you hit build for the ASP.NET solution you are referring to does it list them all?
Nope. It will show the code errors (C#) on build, but the HTML warnings only show up for any pages that are open in the editor.
ReSharper may help
[Telerik JustCode](http://www.telerik.com/products/justcode.aspx) will do that.
You could write an app that uses the XHTML schema and validates each file against it while writing down validation errors to a file or database. Since XHTML is XML you can validate it the same.
And I apologize in advance for making you look at /r/visualbasic's subreddit style.
I use VS2012 Pro and get this all time. Not sure what it is either.
Eh? They are separated by newlines.
Do you have any extensions installed? I had this problem with an older version of Resharper. Updating it fixed the issue for me.
It's not an extensions issue, as I was having the same problem with the Express edition, but just in case, all I have installed is VsVim (for those sweet, sweet keybindings).
It's more like Haskell's guards: http://stackoverflow.com/questions/4156727/what-is-the-difference-between-pattern-matching-and-guards
VS used to lock up on me all the time before I put it on a SSD. The prevailing theory is that VS and the virus scanner they make us use at work were fighting over files causing constant contention.
I haven't had any issues with it when I copy/cut, the only issue I ever run across is when it (very infrequently) decides to randomly make all aspx pages read-only except for the delete key until I close and re-open.
I have this happen all the time on several machines, I do have resharper also. On my dev machine I do not have av, so I am dubious of that hypothesis. 
I don't get it either, but I'm wondering if I've missed something. Why would anyone want to use this?
Is it the same source code on each machine? The issue might be in your solution files. Did you install the latest vs2012 update? The first vs2012 update fixed a lot of bugs I was seeing. It could also be, unfortunately, VsVim (what is \^c bound to anyway? :) ). 
F# supports pattern-matching syntax that works just like Haskell's. This library might be a good choice if you must write the entirety of a project in C#; if not, you'd probably be better off using F# to implement the functionality you need pattern-matching for, then referencing that from your C# projects.
If you have to be pedantic like that, I fixed it with a `Then` operation I added in 1.2.
You.. dumped it and not using anything else? I wouldn't want to work at your place lol :p
Doesn't matter. It's time to linq to reddit.
What antivirus are you using? I get odd lockups when opening a solution sometimes while it's doing something Intellisense-related.
I wonder if this would be against the G-Voice TOS. I mean using it as something like a Twilio replacement.
Errm "Protocol". Please read my question. Please read : http://en.wikipedia.org/wiki/Communications_protocol
Whoah, you must be a l337 HAX0r. Either that or a supreme troll.
Such a smart ass, doesn't know the real meaning of the question.
It's not based on a protocol. I'm parsing the json included in XML pages to get messages. Sending requests is just passing the right post parameters to a corresponding page for the request example: * Call is at https://www.google.com/voice/call/connect * you need to pass outgoingNumber, forwardingNumber, subscriberNumber, remember, and phoneType parameters in POST Edit: I'm reading your question and I feel I gave the wrong answer. I don't know what protocol Google Voice itself is using for calls. I just play with the http frontend.
I haven't read the TOS so I don't know for sure. I should probably get around to that... Edit: Via the [Google Voice Program Policies](https://www.google.com/intl/en_US/googlevoice/program-policies.html), the only thing I see that I would be violating under Prohibited Actions is "Modify, adapt, translate, or reverse engineer any portion of the Google Voice Service". I would consider my library to adapt the service to be used in programming. Should I contact the Google Voice team and ask if I am allowed to continue development?
I don't think your project is the problem, it is how people use your project. If I use your project to send unlimited free sms messages for free then I am probably violating my account's TOS.
We're redesigning our UI for the release of VDownloader 4. Are you a designer or do you know a designer? Win $700 USD and gain international fame by submitting the winning design for VDownloader at crowdSPRING!
You can do it manually at the command line: VS2012.2.exe /LAYOUT Ends up being around 1.8GB
Sadly this update does not fix the horrible scrolling performance when view white space is enabled
You have to remember that MSIL is not the end of this. MSIL is just instructions to the JIT. In theory the JIT can do all the same optimizations that any other part of the chain can do. In fact it can do a better job, even, because it knows precisely the target hardware. I don't know the details of what optimizations the .net JIT compiler is capable of. I assume it's plenty, because Microsoft makes a pretty good optimizing compiler for C, so they certainly have the knowledge.
Any code capable of inlining isn't that far away from tail call optimization. Anyway I believe that the focus is speed of compilation raher than optimal output. Do you know anything about Mono?
It looks like it has something to do with compatibility mode. So none of this shit works in IE. Fucking great.
Here is some more info on .NET: http://blogs.msdn.com/b/clrcodegeneration/archive/2009/05/11/tail-call-improvements-in-net-framework-4.aspx I don't know anything about Mono's optimization strategy. EDIT: An interesting fact is that tail calls are not necessarily faster that normal calls.
&gt;Microsoft is considering adding Hotspot-like optimizations in a future version. And then people will say that their desktop .NET apps are slow as fuck just like their desktop Java apps.
Have you seen the bitch list for WPF? 
No but I have been using a lot of WPF apps that I didn't even know they were written in C#. They were working as good as native apps.
I wonder what's different between the apps you were using and the ones that were performing badly. Some guesses * Overuse of dynamic layouts (all that measuring isn't cheap) * Overuse of data binding (how expensive is it?) * Overuse of borders, gradients, etc. (I've seen controls with 9 borders for a drop shadow effect) * Bad design/implementation that has nothing to do with the framework 
How about actually sharing a link to it and describing what it does...
&gt; Don't initialize to null or 0. Struct have a default zero value and pointers are initialized null. Being explicit doesn't hurt.
Each line of code has to be maintained and can be a source of bugs. Therefore remove all dead code. Always. This is a simple example, but having several lines/pages of dead initialization code can very well hurt you in the future.
Again please consider that this is not a single line issue. Any code you don't have uou don't need to read, don't need to debug. You can spot an experienced dev by the smile when they can remove some code.
No, but wasting cycles on what is effectively a no-op does. That's why FXCop flags those.
Don't remove code at the expense of clarity. Remembering an implicit default value is just one more thing you have to use mental cycles on. Maintenance is all about ease-of-understanding, not minimizing the number of characters in a file.
I am just reporting what the documentation says, I haven't actually looked at the final assembly after the JIT compiler has been at it. But I agree, it seems like a pretty obvious optimization.
I have to argue the opposite. Having to read all those useless initialization phrases distracts me from what's important. They reduce clarity by adding line noise. And it isn't like the defaults are tricky or hard to remember, it is always null/0. EDIT: These days I don't even use "private" anymore. Why tell the compiler what it already knows? Especially when it makes public functions stand out less.
I tried using the exact steps in that article to no avail. As for placing a button or something else on the canvas, I didn't try that, as I didn't realize it'd be necessary.
Yeah its just a guess, but the thing is I don't think a canvas is focusable by default. This is based on wpf thoughts, but if there is nothing focused as a child of the control which has the event listener, you won't get notified. It sounds like hooking the current core window might be a better solution for your app, but if you find that you want to ignore keys unless a certain region has been hit, investigating the focusable and focusmanager would be a good bet I'd say. (I been a Metro n00b, but proficient WPF/Silverlight)
[VS 2012 Update 2](http://support.microsoft.com/kb/2797912), released a few days ago has a fix that might be related. * *You encounter performance issues the first time that you copy text from the editor if the toolbox is invisible in Visual Studio 2012.*
The shims don't seem to play well with NUnit. I suppose I could use the stubs as a replacement for moq but getting this to work is turning into a massive pain in the ass. Why would this even let me compile if at runtime it's dependent on an assembly/framework that's not included. That just seems sloppy to me. Not to mention adding "Fakes" quadrupled build time cause it has to regen everything on build. I think I'll deal with the headache of adding my own shims, it's nice in theory but like so much MS stuff, unless you're using it in the absolute happy path scenario, you're gonna have a bad time.
Would not have thought to do that. Seems kinda cool.
I'm going to use this today. Do you jetbrains dotTrace? That's the current profiler I use.
The best advice would be not to use VB. Other than that there are conversion tools you can use, or you can compile it into a DLL and reference it from your VB code.
Yeah, the site was in VB already. Nothing I can do about that. I have the dll referenced, just not sure about a lot of things. I guess I'll figure it out, and start a blog or something.
Looks interesting. Do you have any experience using pex?
I think you need to be more specific - what exactly are you having trouble with? While the languages may be different, the framework and the way of doing things is mostly the same - you just need to look at the C# examples, figure out what they are are doing, and implement the same thing in VB. If there are any specific C# things you don't understand, post here and myself or another helpful member of the reddit community should be able to help :)
What are you trying to do? Kayleighswift is right, .net languages are pretty similar. Which c# example are you trying to convert? we can help you but probably need specifics.
Ok, the site says you need to do something like this to send a token (with CC info), but it's in PHP, I guess I'm wondering what the equivalent is in VB. I checked out stripe.net, but it covers so much that it's hard to decipher what I need to do to just send a token. // Set your secret key: remember to change this to your live secret key in production // See your keys here https://manage.stripe.com/account Stripe::setApiKey("test key"); // Get the credit card details submitted by the form $token = $_POST['stripeToken']; // Create the charge on Stripe's servers - this will charge the user's card try { $charge = Stripe_Charge::create(array( "amount" =&gt; 1000, // amount in cents, again "currency" =&gt; "usd", "card" =&gt; $token, "description" =&gt; "payinguser@example.com") ); } catch(Stripe_CardError $e) { // The card has been declined } **This is what I currently have on my page:** &lt;script src="https://js.stripe.com/v1/" type="text/javascript"&gt;&lt;/script&gt; &lt;script type="text/javascript"&gt;// &lt;![CDATA[ // This identifies your website in the createToken call below Stripe.setPublishableKey('test key'); var stripeResponseHandler = function(status, response) { var $form = $('#payment-form'); if (response.error) { // Show the errors on the form $form.find('.payment-errors').text(response.error.message); $form.find('button').prop('disabled', false); } else { // token contains id, last4, and card type var token = response.id; // Insert the token into the form so it gets submitted to the server $form.append($('&lt;input type="hidden" name="stripeToken" /&gt;').val(token)); // and submit $form.get(0).submit(); } }; jQuery(function($) { $('#payment-form').submit(function(event) { log("Stripe $('#payment-form').submit..."); var $form = $(this); // Disable the submit button to prevent repeated clicks $form.find('button').prop('disabled', true); Stripe.createToken($form, stripeResponseHandler); // Prevent the form from submitting with the default action return false; }); }); // ]]&gt;&lt;/script&gt; Thanks for your help.
Hi, I've got a good bit of experience so I'll try to help you out. In the past year I've interviewed around 20 people for .net positions and I just got a new job myself so I just went through a round of interviews myself. I'm not trying to brag, just giving some stats for my credentials. In my latest job search I had 4 phone interviews that lead to 4 face to face interviews that lead to 4 offers. I'll start with what I look for in a candidate, then I'll go into my personal tactics. First, don't lie on your resume (I'm not accusing, just stating it). It will reflect in your answers. What I look for is where a candidate is based on the level of experience that's on the resume. If a person has 5 years of experience, then I expect a certain level of understanding of the more advanced features. I'm actually a pretty brutal interviewer (at least that's how it seems). I just ask a lot of technical questions. I'm not asking to get correct answers, I'm asking to get an idea of your experience level, and how you handle your self. Things that I don't like in a candidate. * Obvious lying * bullshitting. If you don't know the answer, just say so. Don't ramble on about buzz words that you think might be related. It really just makes you look bad. If you don't know, then just say so. However, if you have *some* experience related then it's okay to say that. * Answer the questions. Don't go politician on me and take any break to ramble on about what you want to talk about. I don't like to stray from my path. If you make me jump around to follow you I'll get annoyed. * Dress nicely. I'm not talking about a 3 piece suit, but show up looking like you want to get hired. Most of the shops don't care how you dress for work, but it's just a good practice. What some people might not like. I'm really forgiving when it comes to things like this. * try to speak well. Even if a job doesn't explicitly state "good communication skill", they still want it. Speak clearly and try to limit your um's. * Don't fidget too much. It doesn't really make too much of a difference, but it can be distracting. I've gone through a few interviews where a candidate has a weird tick, then after a while that's all I could notice. It became too distracting, and negatively affected the interview. Now, what I do is pretty straight forward. * I talk about what I know, and I admit what I don't know. Honesty is very respected. * I speak clearly and confidently, but I sit at ease. * I ask question. ALWAYS ASK QUESTIONS. I can't stress this enough. Do some research on the company. Know what you're applying for. During the interview set up some questions based off of what they asked you. If they ask you how much sql experience you have, ask them if they have a full-time dba. If they ask you about entity frameworks, ask them what ORM they prefer. During the interview they will set up dozens of questions. Asking questions shows 2 things. 1 You're paying attentions and 2. You're already in the mindset of contributing to their company. * relax. Seriously, just relax. * You're a professional, and you need to approach this in an "I'm interviewing the company more than the company is interviewing me". Let them know that they are fighting to capture your interest. The tech questions may make an impact, but the bottom line is that they need you just as much as you need them. You have to carry yourself in a manner that illustrates this. What you should know. * Generics * Delegates * Page life cycle. You already mentioned this. You don't need to know everything, but you need to know enough (which I think you do). * Interfaces * Abstract classes * Entity frameworks * n-tier architecture * OOP basics. How classes interact with each other. Inheritance, friends, public, private, static.....all that jazz * Learn about client side programing. Brush up on javascript, jQuery, and css. * Look into linq and lamba expressions. (they are pretty cool). You're best bet is to pick up .net 4.0 book and read it cover to cover. Just so you can get a good understanding of the principle behind the framework. [here's a pretty good resource](http://it-ebooks.info/) It's all free. I hoped some of this helped. Feel free to ask me any questions if you'd like. 
I think the answer is to practice. While you're driving around, explain to yourself what delegates (extension methods, lambdas, micro-ORMs, async ops) are and when to use them. Talk about your experience on particular projects; talk about opinions you have about things (Entity Framework is abstraction-XML-overkill, here's why, etc.) Do this again and again and again. Then some more. This will get you comfortable with it and expose any gaps in your reasoning. I do this stuff *all* the time which means I always sound prepared and cogent. I've never not received an offer from an interview and I'm by no means a naturally gifted programmer. Similarly, write a programming style guide that articulates how you think about writing code. This will make you research things you don't know about, expanding your knowledge base. And, of course, teaching is one of the best ways to learn a thing. In this case, how to talk and write about code. I did this in my department mainly to get one dev to stop doing stupid shit, but I also realized the secondary benefit of research and practice. Questions to answer (again, to yourself): What is your core philosophy when it comes to writing code? What is your opinion of Unit Testing? Talk about a project you really kicked ass on - why it worked, what you did, tools, libraries, etc. Books: Are you reading books? Are you reading blogs? Do you follow MS devs on twitter? I do all of these things, so I never have any shortage of concepts to talk about. I think I'm the opposite of you. I can credibly talk about code for long periods of time, but I'm not so sure I'm a very good coder. But. I would argue that one isn't necessarily better than the other. I've worked with a lot of programmers who couldn't talk about programming abstractions. Totally frustrating. In my department (I'm merely senior; we don't have structured hierarchy because that is stupid), I make everyone speak about their decisions and explain their reasoning. Some still can't do it well, which drives me nuts, because they write good code. But that's just means they need to practice more. Like you. 
Thanks. I think this is a HUGE help. I think my confidence in my ability plays a big role in this. I think I'll pick up a bunch of books. Any particular 4.0 book you'd suggest?
[This is the only one I could find that I liked on that site](http://it-ebooks.info/book/652/). The important part is a good understanding of the concepts. Companies would always rather that you have real world experience. But learning concepts on your own without having to apply it is also a good sign. It shows that you take your career seriously.
I've used it some.. it works as intended. [Here](http://www.infoq.com/presentations/Contracts-Library) is a great overview of using it.
I have real world experience, very little concepts. My old boss said I always went "eh, this works" instead of "why does this work?". It has really hurt me. Thank you. I think I'll pick that book up. 
**PRACTICE INTERVIEWS**. That's it. Do practice Interviews. This, by far, is the most useful, under-appreciated thing I have done for my career, and one of the only reasons I still think college was "worth it".
I'm trying to convert the Stripe "Charges" section of the getting started documentation to .Net. This is the code they use, what is the equivalent on Stripe.Net? # Set your secret key: remember to change this to your live secret key in production # See your keys here https://manage.stripe.com/account Stripe.api_key = "secret key" # Get the credit card details submitted by the form token = params[:stripeToken] # Create the charge on Stripe's servers - this will charge the user's card begin charge = Stripe::Charge.create( :amount =&gt; 1000, # amount in cents, again :currency =&gt; "usd", :card =&gt; token, :description =&gt; "payinguser@example.com" ) rescue Stripe::CardError =&gt; e # The card has been declined end 
can this replace assert in anyway?
I'm not sure specifically what you mean, but the code contracts library do have an assert function too: Contract.Assert(bool condition, string message)
I wonder if he could have achieved the same result of he had used an invariant. Code contracts are great and all but they do have some issues. For example, interfaces are a nightmare, requiring you to have a separate concrete class for the contracts. 
&gt; I wonder if he could have achieved the same result of he had used an invariant. Check the stackoverflow link I mentioned at the bottom of the post. structs invariants are allegedly ignored, but they end up suppressing errors when they shouldn't. &gt; For example, interfaces are a nightmare, requiring you to have a separate concrete class for the contracts. I haven't found that to be too bad, it just requires a class per interface. Unfortunately, this feature seems buggy and I've already submitted a connect bug, as it seems there is no way to satisfy the postconditions in some cases, and in some cases the preconditions aren't properly applied.
humm i see, if they are from the same class, they are probably different, and seems right 
I tried to use it several times. Problems: 1. Too verbose (esp. for interfaces and auto properties). No reuse until 4.5's ContractAbbreviatorAttribute. 2. Needs rewriting for most things. Some unrewritten methods do Assert (or did in the version I tried), which kills the whole w3wp, for example. 3. Contract checking is async (you have to wait), and hard to configure (what is not a warning, suppress something, etc). Now I use ReSharper annotations — they might not be perfect, but they are significantly more useful practically. I also use custom Argument.NotNull/NotEmpty/etc thing for actual exceptions. Contracts in 4.5 seem better, especially [ContractAbbreviator] and [ContractArgumentValidator] — I may try them once more when I get to a 4.5 project.
After trying it out I'm certain it has promise, but currently it's too slow. Once it gets out of beta I hope it's faster. 
I agree, although I'm sure it's currently at one of those borderline proof-of-concept / beta phases. I'm sure there are likely tons of improvements that can be made performance-wise, especially once they start gaining a bit more steam. It will be exciting to keep an eye on though.
Great tutorial for a beginner like me! :)
Why use anything other than TortoiseGit?
This is an IDE. The mono compiler has full support for async/await. 
Programming C# by O'Reilly should fit you well - I liked it when I was (sort of) in your position. 
Get a wpf book. Apress is good for that. Wpf is what you'd use for building a desktop app as win forms is obsolete.
The Pro C# 5.0 book should be good (I have a couple previous versions). I think he has a good writing style that isn't too boring and the book should be nice and detailed although organized well enough to look up various topics of interest. I wouldn't say it is a migration book though from other languages to C# but I think you could probably skim over the relevant parts. Also, you might look at a nutshell book from OReilly.
A 'desktop project' covers all manner of sins! What kind of thing is it you're making? Will it be graphicaly intensive, or have lots of configuration. Will it be talking to a DB or middle tiers or making lots of WS calls? C# is a very different discipline to PHP, C# punishes you far more for bad design decisions but brings you great flexibility and powerful language features (such as LINQ or TPL). C# apps are also generally easier to maintain because the scope of change is better understood (static typing). But as to which book is best, depends on what your going to be making!
It will be talking to a DB and it wont be graphically intensive. 
MS SQL or other? It would be worth getting something that covered using ORMs. Linq to Entities is rather easy for simple tasks. Will it be having lots of grids and stuff on the screen? The more info, the better we can help suggest resources to help, MS have also produced some good screen casts which are a great way of getting started.
I'm considering their videos as well, but I need a book too. Maybe I'll just buy a C# book and get the .NET related stuff from the videos.
The DB is my choice, so I'm leaning towards MySQL/PostgreSQL. It will be a rudimentary user management app at first. 
oh IC, so a simple app that gives you a view on a table of Users and allows you to edit them, standard stuff like name address. With a bunch of roles? I'd consider using MS SQL as it would probably fall into the free tier of use (SQL Express), it has a bunch of really good dev tooling around it, far more so than MySQL. If you get something which covers Linq-To-Entities you can just write your app against some model objects, not really thinking about the database at all, as that will be generated by the domain model objects, you will not have to write a single line of SQL! This makes testing and deployment so much easier! I would suggest looking at WPF for the user interface side, as it is really trivial to make such a thing nicely extendable in WPF. Winforms becomes spaghetti + glue code.
Is that a language book like Jon Skeet's or is it more .NET oriented?
I'll add my vote for Pluralsight - definitely worth a subscription. I don't really bother with books anymore; between pluralsight and blogs/tutorials and stackoverflow I'm not sure you really need a physical book these days.
More general C# one. The art of WPF is really MVVM. There is a book by Josh Smith on this, but its really rather pointless. Knowing your SOLID principles is much more use, and working through some tutorials online on the matter. Trying to be really polite, but PHP is a language I would say encourages bad practices left right and center, its an inconsistent mess, a thin veneer around a bunch of C functions. The C# stuff will be very differen't, and a bit of a status shock. I'd recommend learning about Linq to Entities first, using some unit tests (they'd be called integration, because your talking to a DB instance, but they run in the unit test framework), getting to grips with how it all gets built, how it hangs together. Once you've done that a bit, trying some MVVM tutorials and making the app that consumes these model objects shouldn't be too hard.
&gt; Trying to be really polite, but PHP is a language I would say encourages bad practices left right and center Haha, you don't have to be polite, PHP is one of the more rubbish languages out there. Is this worth getting then? http://www.amazon.com/Programming-5-0-Building-Applications-Framework/dp/1449320414/ or perhaps something like Jon Skeet's C# in Depth? 
I have a pluralsight subscription that I use to keep sharp and I absolutely love it for keeping fresh/learning new stuff. If you can afford it I'd say definitely go with it, it can get pretty steep in cost though if you're a young guy.
Like TheAnimus said, I'd look into using MS SQL Server. Linq to SQL and Entity framework are very nice to use, and I'm not sure if they work with MySQL or anything other than Sql Server. Warning though, free version of SQL Server can only grow to 10GB before you need to pay.
I switched from php to C# about a year ago. Honestly, I love it. It took a while to get used to declaring variable types, but other than that I'm a big fan. Syntax and stuff shouldn't take long to figure out, it's a pretty nicely written language. 
Seems like. Differing views out there though: [It's dead, Jim](http://www.riagenic.com/archives/963) [We're MS - we'd never do that to you!](http://social.msdn.microsoft.com/Forums/en-US/wpf/thread/d18cc391-0c95-40fc-a9b7-269116a46426/)
We're working to improve startup time which I guess is what you mean when you refer to "performance-wise", correct? It has been launched pretty recently but it went already through millions of files during the tests done in development: tons of merge-replays from public repos too.
It's language oriented, but not a language reference - the actual spec/MSDN is good for that. C# In Depth (Jon Skeet's book) is more down-and-dirty and shouldn't be used as an introduction to the language, not even for a moderately experienced programmer in my opinion. It is a VERY great book though, so feel free to pick it up as a third read or so. Programming C# by O'Reilly isn't "this is how you write a for loop" (Learning C# by O'Reilly is good for that), it has a bit more focus on using the language (as opposed to just learning it). 
Thanks, that sounds exactly what I need.
MSDN can be a really good source in terms of a reference but I think you'll find that more helpful once you've got some general C# and .net fx knowledge under your belt. I would probably go with the book that has~33 reviews. I've been programming in .net, C#, asp.net for about 8 years and there isn't one book that is like my go-to reference. Point being, between MSDN and whatever book you choose you'll be up and running in no time. I highly recommend making sure you understand how to use generics and some of the multi-threading features like the new-ish SynchronizationContext and EventWaitHandle (plus way, way more). Delegates will be important too for correctly communicating from background threads to your .net Windows Form App, but I'm getting very specific and I'm sure most books would cover this. Last seemingly random tip, always remove/unregister event handlers from events in your code when you are done with them! 
This blog post introduces Cloudinary's add-on for the Window Azure cloud platform: powerful image uploading, manipulation and CDN delivery for .NET, PHP, Python, Node.js and Java web applications developed and deployed using the Windows Azure Platform. Disclaimer: I'm one of the Cloudinary's co-founders.
What a poor article - the security researcher seems to have no idea how strong names are actually used. While he gives a few valid methods of removing a strong name from an assembly, this in no way "breaks" strong names - anything that examines the SN on that assembly will now fail it as modified. This is like a tamper-proof seal. Sure, you can completely remove it, but then people looking for the seal will know it was tampered with.
Pro c# and .net is extremely thorough. If I could only have 1 book on the topic, it'd be that one.
Honestly when I first started with C# I was pretty intimidated. I'd only used Php and VB up to that point. (besides some messing around in python) Started writing a decently sized application in VB MVC only to see most tutorials and information was shown in C#. Took me about 2-3 months, but I got the hang of it and I can honestly say that C# is my favorite language to work with. Been using it now for about 2 years, but I'm about to start jumping into some Php frameworks to broaden my skills.
Don't be the fucking prick that you are on reddit.
Correct! :) I was also just making a rather generic statement that there are probably lots of other improvements that could be made is the product is still within the beta stages so I'm sure there are more exciting things to come. I'm actually working on a blog post about Semantic Merge that I hope to get out later this week :)
You're going about this the wrong way. Stop labeling yourself as a PHP developer or a C# developer, you just a developer, and you happen to prefer one tool over another. Think about it like this: would you ask r/carpentry *"I'm a carpenter and I'm used to DeWalt power drills, but I want to switch to a Bosch." ?* You need to learn about the (software) environment, then programming should be pretty natural. Just start. What's IIS? How does it work with ASP.NET? What's a web.config file? you'll learn that shit quickly. Get down the basics of C#. If you're going to get a book, [I really like this one as a beginners guide to C#](http://www.amazon.com/4-0-Complete-Reference-Herbert-Schildt/dp/007174116X) (note that it's not for beginners in *programming*, it's for people new to C#). It's a good overview of the language and covers most of what you need. You should already be familiar with most of the concepts there; functions, classes, variables, types (to some extent), object oriented design. What might be new to you are delegates and functional programming. Set up an IIS server. Get Visual Studio Express and create a Hello world MVC application. Create a small blog system. Add an ADO.NET database connection. Each item on that list can be learned in isolation, each item can be Googled. Final tip: don't just churn out project after project that all do the same thing. Don't build ten web sites that all have the same featues. You won't learn anything new and you'll end up an [Expert Beginner](http://www.daedtech.com/how-developers-stop-learning-rise-of-the-expert-beginner). Instead, try something new, get familiar with more libraries, etc. tl;dr: Be good at programming, and your choice of tools doesn't matter after working with them for a few days.
/r/carpentry 
We launched today 0.9.20 with several perfs improvements :) Please take a look. And you're right: the are many exciting things to come so all the feedback is really, really welcome! Thanks for the blogpost you're working on! We're eager to read it! Thanks!
It's for transforming XML data from settings appropriate in one build configuration to settings that make sense in a different build configuration. It's currently used in VS.NET for transforming the web.config file used for a debug build into one that should be used in a release build. For example, you might replace a connection string pointing to a local SQL server with one pointing to a staging server when using a release build.
Yes. Absolutely. If you actually put in 20 a week, you'll have it totally down in less than half that. Depending on your style, you can reuse almost all of your middle-tier skills. The browser is still the browser, and you are dealing with the same OOP constructs. Outside of convenience libraries like LINQ (you'll see!) and syntax, basically 100% of your experience is still applicable. Honestly though, in my experience, you may want to start looking into entry level positions at companies that will let you be involved in .Net projects quickly. Many dev shops will do both PHP and .Net, so that could be an easy in. Additionally from a "getting hired" perspective, one or two projects that you had a hand in plus a .net reference or two will go considerably further than a polished git portfolio (though it doesn't hurt!) If you REALLY want to get hired fast, learn a CMS or two once you are passable in C#. In the Boston area at least, there is a massive need for Sitecore developers, and my firm sees smaller Umbraco and Ektron projects frequently.
Excellent advice. One thing i consider as a dev to stay "stack agnostic" is that the server shouldn't be doing that much work anyway - offloading presentation logic to javascript is good for performance, and a well-crafted database should be able to deliver pretty close to the results your business rules and model warrant. Your middle tier does a little data transformation, spits out some html and json, and you save the headache of constantly learning new server-page lifecycles.
also PHP to .Net protip: you're going to miss var_dump, and yes, you really need to use the VS debugger. 
I have experience with both PHP and ASP.net MVC in C# and I think about the last thing I'd miss is var_dump. Visual Studio is really annoying sometimes but it is an excellent tool. The debugger is excellent. I think you can become more than proficient in 10-12 months. I would look for a position that would hire you now to use ASP.net MVC. You may need to come in at a lower salary (I'd strongly advise you to look at market price and get the agreement to be something like I start at 40k but after 12 months I'm at 65k or whatever the numbers are you want). In a couple months, you can get a lot of experience and start to understand how things work. It'll take longer to get used to all the options on database access and design methods but if you're working on simple projects it should be okay (I'd look for somewhere that does simple projects over starting at some big company that needs internal developers to support existing stuff that is hairy and complex). You can go the CMS route but you may end up hating it. It seems like every .net shop either uses a CMS or has their own written one. I spent two years working on a new CMS in ASP.net MVC that had an old one in classic ASP. It was interesting but not particularly fulfilling because in reality most people don't seem to actually use the CMS features all that much. It's like a big selling point but kind of a waste of time in my opinion. I'm sure there are exceptions but why settle for it? By the way, Visual Express is great and free. Pick it up and use it for a while before spending any money on tools. Get started with the basic ASP.net MVC examples. Consider picking up a book like ASP.net MVC in Action. Learn a bit about the different ORMs and try them all at least so if asked you can say you have used it a little. If I were you, I'd spend 3-4 months outside of work getting up to speed and then get a position where you used it daily. If you're in the USA where people change jobs like underwear, consider picking the best place to learn over the most money. You can always jump ship later if they don't want to raise your pay as you become proficient. Lastly, read about REST and try some projects where you are using client-side JavaScript to like Knockout.js or Backbone.js and using ASP.net MVC as REST endpoints that speak JSON to your application. This is a really hot area right now and you might like it and get a much better position where coworkers are as interested as you in learning. Today, I work at a place that does all kinds of things but we don't do all that much PHP or Microsoft technology. So look around -- there is a lot out there. Edit: I do agree with you in spirit though about var_dump -- the simplicity of PHP and the ease of getting started matters a lot. ASP.net MVC is better than Microsoft's earlier efforts but it still isn't the easy thing to get going with.
I've been a C#/.NET developer ever since I was a win32 developer. My thought is, the .NET ecosystem might not be where you want to go. Looking at job listings, and the companies you want to work for, are they using .NET, or Ruby on Rails or NodeJS? I work at a good company now that is a .NET shop, and worked at some good ones before that. That said, when I look at whats out there, it seems like Ruby on Rails is really in demand, especially at the kind of companies I'd want to work for. I also see Node coming up more and more. I just started the online videos here: http://www.letscodejavascript.com/ for learning node. It looks like this is a person who knows how to do continous integration properly, so I'm excited to learn from the course. You may want to check it out as well. 
Oh nice. I never looked into that but as soon as I work in an orderly workplace I'll use it!
Don't forget AngularJS! That's my recent clientside obsession. On the CMS point, even if you don't stick with it its a good general skillset. Like you said, a lot of organizations have them. Because of that, it is a good entry point because people need to support those. And while many of them are totally feature overkill, its nice to have them around for those less inclined to writing it themselves - even blogging platforms like wordpress and tumblr are viable as a full CMS for small to medium organizations! And everyone: please stop writing your own CMS's for your work. There are SO MANY out there. As a side project, for your own site? Sure! Yeah, it is easier than learning another system. Less so for the new guy when you leave in 4 months. 
No, just NO!
Am too had a Similar question 2 years before. But i had my best friend to give a similar advice. Software development is an art. Its not depend on which tool you use , but on which problem to tackle in the best way possible.
We use this all day to deploy various configurations to different servers because screw manual deployment. 
It really depends on location, but in most major cities you have lots of enterprises that are actively hiring for .NET and especially ASP.NET MVC. This is especially true in large Metropolitan areas. I'm in Southern California and there are simply way more .NET jobs compared to rails and the ASP.NET jobs pay more. 
Yeah, that is why I say look at job listings. Besides regional variance, people have preferences as far as the type of company they want to work for. There are plenty of .NET jobs in my region, but when I focus on the jobs I want then the distribution changes a bit.
I hope so. The ones I missed sound cool. For example the first, *Advanced Debugging with WinDbg and SOS* by Sasha Goldshtein I may sound boring, but I saw a presentation by Bart De Smet where he was messing around with these things at the techdays, and it was pretty awesome..
Id like to watch the nosql one.. i havent checked that out and its about time i know a few things about it too.. Other ones Id watch are: Test Driving .NET HTTP the Right Way with ASP.NET Web API Rediscover JavaScript Advanced Debugging with WinDbg and SOS and Git in my TFS! 
I just watched the Git in my TFS! one, it was pretty good, besides the video dropping a bunch of times. During that presentation they mentioned they were going to upload that though, so I'd guess you'll be able to watch the other ones later too
Practice. Go on as many interviews as you can. You should start getting a good idea of the sorts of questions they will ask.
Only for libraries and static methods. The idea is great but too limited. Good start tho. 
This was one of my only hesitations about doing the write-up about it, as it is currently very limited. (The Power Tools for earlier versions of Visual Studio that are mentioned have less limitations than the Code Digger extension however) Hopefully it interests enough people to possibly follow the project in general so when the next release comes out people will be more familiar with the idea and know what it is capable of.
They are posted on youtube btw: http://www.youtube.com/user/dotnetConf/videos
Thanks
Why but to not use Entity Framework? 1. Ideas are not different and sometimes there. 2. Inability to not have the previous helpful methods. 3. Can be advantageous not in most cases.
Because I don't really care how the storage engine works, and all I really want to do is create and store object graphs?
Not slow in .NET 4.5: http://www.outofmemory.co.uk/entity-framework-5-dramatically-faster-in-net-4-5/
I love EF, but this reads like a bad homework submission. 
Except there are quite a few areas where object dbs cannot perform as reliably as relational dbs. They do scale better though!
"Database performance is improved"?
Not the most interesting read. I would be more interested in Entity Framework vs other ORMS and where does it stand out as a clear favorite for a given problem domain.
An I the only one who thinks entity framework is fast and easy enough for 85% of projects I'd use it for? Does anyone need to shave a few microseconds off of an insert or update? Are you writing reports with it and the shorthand notation is b becoming confusing? I genuinely don't understand the criticism. Var answer = dbContext.StuffIDontGet.Where(x=&gt;x.WhiningAboutFreeShit == true).Single;
yeah what? For anyone who has taken a look at the SQL generated by EF, you know this is just NOT true :)
Not better than a finely tuned purpose specific sql query. But quite often, without an ORM, queries become more general purpose (to save time) and these can become much slower than something an ORM would generate.
I've not really had that one myself. For me its always the RDBMSs that perform poorly, but offer data integrity. The performance of full outer joins of disparate tables is so poor that it doesn't really matter that it outperforms the poorly performing object/document stores. In memory caches, Vertical stores, document stores, all have their benefits in performance, I seldom find they loose out on that front. But a Relational Managed Database System is so bloody useful if your domain has a strong set of relations! I find people forget this a lot, it is like Exceptions been used for non-exceptional circumstances, the clue is in the name!
What is the merge interface like, a decent one or a watered down idiot proof one like github for windows?
Sorry to hear that, the top down micro management system controlling which buzzwords your allowed! Take it something like Redis wouldn't fly? Even if you used the &lt;preferedPlatformDB&gt; as a back end? That way write performance can suck, but read would be great. &gt;suggest an LDAP-based solution LDAP or OLAP? It's late here :) It amazes me how companies will try and force a hammer as the preferred solution, even when they supply you with screws! But the screwdriver weighs less, and we even have pilot holes, it will be faster and better...... No fetch the hammer. Later today I'll be helping a client that has decided they want to make their own in memory cache. I can't advise against this enough, if you think that your domain is so special you need your own in memory cache, at least have someone who's worked on one before. Tomorrow I solve *Rx can not subscribe multiple sources at the same time, only in order sync* issues :(
As Charles Stross once explained, bureaucracy is *not* the method for getting the best possible output for a certain input- it's the way you get a *consistent* output for a given input. As such, bureaucracy is an incredibly valuable tactic for survival. My company doesn't make software, they make paint. As such, they're not terribly invested in producing the best possible software, unless somehow that software helps them produce the best possible paint. If a technology is new, that simply means we can't trust it- we should go with something we've been using for years. By this time next year, the Tandem mainframe should be dead, including the COBOL code that's meant to emulate a Burroughs calculator from the 1940s. I mean, who would even administrate our NoSQL DB? None of the developers are admins- they're developers. And we only have SQL Server and Oracle admins. None of them know anything about NoSQL. Besides, why should *they* learn something new? And yes, LDAP. No, seriously, the data we're storing would actually work well in an LDAP tree. If one wanted to get really creatively abusive, you could hack DNS to do this, if you creatively misinterpreted what the various record types meant.
You know ORMs use prepared statements that (with sql server at least) use a query plan. And the sql generated can automatically adapt to run time requirements, something stored procedures struggle with.
[Why is Entity Framework slower than ado.net for Queries?](http://stackoverflow.com/questions/12102283/why-is-entity-framework-slower-than-ado-net-for-queries)
First one I've found (link doesn't work): http://technet.microsoft.com/en-us/library/ms175528(v=sql.105).aspx I also remember reading long ago that internally Sql Server treats a stored procedure the exact same way as a prepared statement, as in a query plan will be generated before it is run and it will cache the query plan.
Everything I've read indicates that EF is slower. It has to be. It's on top of ADO.net. It's an abstraction layer. More code on top of ADO.net. Stands to reason.
[Is there a major performance gain by using stored procedures?](http://stackoverflow.com/questions/325803/is-there-a-major-performance-gain-by-using-stored-procedures)
All the top rated answer's basically come down to "it depends".
But EF, or any ORM, can make run time adjustments. Let's say we have a search form where users can filter results by column A on table A and column B on table B. To filter against column B you obviously need a join. If you were using a stored proc you would always have to join on table B, even if it wasn't necessary, and join operations are relatively expensive. An ORM on the other hand will create the join at run time only if the user has selected to filter on column B, so the ORM solution in this scenario comes out much faster. I've seen similar results with dynamic where clauses as well, Sql Server (at least the 2008) didn't deal well with semi-dynamic where clauses. In some of the tests I did at the time it ignored the indexes and reverted to full table scans, so an ORM was faster in this case as well. &gt;Everything I've read indicates that EF is slower. It has to be. It's on top of ADO.net. It's an abstraction layer. More code on top of ADO.net. Stands to reason. Only if you ignore potential run time optimizations.
&gt;However I have observed an interesting performance characteristic with EF5 vs ADO.Net and a low number of rows (either queried or inserted). EF5 appears to be consistently faster than ADO.net for under 10 items. I imagine this is due to an optimisation at connection setup time however I haven't yet tracked down what this is. So again, the answer is "it depends".
And again, it's an abstraction layer. It's difficult to find claims that EF can outperform a sproc on any specific task. Given the same well written query, a sproc will outperform any EF call. edit:spellimg But I'm willing to entertain an example otherwise.
I gave you one in another reply.
without either creating a hard to understand sproc or multiple variants of basically the same procedure? Well, there's the problem. If you want the best performance you have to understand how SQL Server works and how to write good queries rather than let some framework do it for you. The best performance is not the quickest middle tier code to write. 
Best performance is obtained my measuring and optimizing where it's most appropriate. Trying to optimize everything leaves you no time to optimize anything.
Correct. No example of a well written query used in a sproc and EF call and the EF outperformed the sproc?
Best performance is obtained by a well designing backend and queries that utilize that design. Depending on a framework to do your homework is a recipe for disaster. When the app gets to production, users are hitting it, and the database is growing no framework will save you. Telling the manager there was "no time" to consider optimization will not go well.
If the client is down because no one can open the UI and you tell your manager it'll take a day to fix it because you didn't do the due diligence then you'll probably be talking to HR.
If the difference between a sproc and a prepared statement is all it takes to do that then you have bigger issues to worry about.
It's no the difference it's the indifference.
They key here is the kind of company you want to work for, like you said. Yes, it can vary by region and does, but the commonality is that the majority of .NET jobs are corporate, non-software-company jobs; or giant medical/systems/banking softare corps. It's just plain true - look at job postings. We've had a hell of a time finding good .NET devs where I work. Nearly all the applicants are Rails and php people who've done some .NET. I find .NET jobs usually pay better than other stacks, but it's often with a Big Corp tax, and that's never good. That's how it is on the west coast anyway. I think 2-3 years ago I might've had my feelings hurt by your post (sullen downvoters abound), but these days I agree. I'd rather be working with hipster neckbeard goth coffee-swillers than the squares I encounter in .NET world. Too much church and sports and bureaucracy; not enough rock-n-roll. I'm looking to move companies soon here, so maybe my opinion will change. So far, it's business as usual. I do see cool .NET companies, but they are by far the minority. Mostly enterprisey boredom incubators. 
Is it really an audit log, or just a log? For me an audit is something to do with the business whereas this t=is to do with the technology. The idea is good though. I did the same thing recently, except mine was in the base controller (might look into moving to a filter) and I only bother logging after an exception.
A list action with a search parameter and an action filter to handle json request would have cleaned it up just as well, without the additional complexity.
I experienced significant slowdown on the "merge" screen. To the point that it was nearly unusable. (i7 2.8ghz, ssd, 8gb ram) Other than that, very impressed with the concept/presentation.
This is very important. When I got to college, I needed to develop some people skills. I volunteered as a crisis counselor and went through some training for that, got involved in a peer counseling group, did some human development type activities and I also got involved in ballroom dance. Those activities helped me to develop a bit more confidence, to look people in the eye a bit more and to enjoy interaction a bit more. I interview well now in large part because of these kinds of things. It's ok to be human though, don't try to nail every little thing on the head and congratulate yourself on the little improvements that you make in this area. Interviewers are used to people being a bit nervous -- at least initially. From my experience, enjoying what you do and having a good work ethic (and references who back that up) count for a great deal with employers. Depending upon the employer, if you have the basics in the area of programming that you're getting into and the software, the existing leads can "teach" or show you what they want and how they want it in a relatively short time. It takes a hell of a lot longer to teach you people skills that make it possible for you to work with others. On the other hand, there are jobs where they really don't give a shit if you can talk to other people or if you take a bath every day, they just want specific (and usually "rarer") skills and an ability to meet deadlines.
Could you please contact us to sm at codicesoftware.com and we will be more than happy to check the issues. BTW we released version 0.9.21 today... Please check.
We just announced VisualBasic .net support today http://codicesoftware.blogspot.com/2013/05/semanticmerge-now-ready-for-vbnet.html
Just a few thoughts on performance and memory limitations. I'm going to add some constraints to the problem, to see how that would affect a solution. Let's assume that: 1. Memory is too constrained to create any additional objects 2. We want to avoid use of a stack for stack overflow avoidance 3. The array elements are 32-bit nullable integers (conflict with 1., I know - but bear with me) 4. The problem is single-threaded Please also bear in mind that I'm a C sharp developer... Now let's treat the problem as a 1-dimensional nullable integer space to iterate over in a single pass, raster-fashion. Start with colourIndex=1. When "land" (0) is found at index N in a "sea" of nulls with width W, set its colour to array[N-1] ?? array [N-W] ?? colourIndex++ N.B. in C sharp, ?? means "unless that's null, in which case :" If setting from the array AND array[N-1] != array[N-W] then you are joining two islands and you can recolour the island. (Not time efficient - using an colourPair hashtable would be faster). Finally, re-iterate the array, counting the number of each colour. Finallyfinally, re-colour the land back to 0's if necessary. ---- Well, that killed a happy 1/2 hour while waiting for my plane - thanks :-) 
Neat. Your first constraint really changed the whole problem. Nice analysis
Cool, thanks for the explanation and link. I've never heard of a bit board so this is nice to know!
How have I only just found this guy's blog, there's some awesome stuff on there. Thank you for posting this.
Thanks! There's no right approach here, of course. Incidentally, I used this approach in my final year computational physics course to determine the critical bond density required for conductivity in a 2-dimensional conductive array (it was 0.5). I extended it into three dimensions - the answer was 0.3333. Good times, good times...
Good call, but please describe where you will store the information. The bitfield is only any good for the input. What about the intermediate variables? You are correct that my solution is not necessarily memory-efficient, but a solution that could run out of memory is no solution. Now, I'm cheating here - I have enough (bad) experience with out-of-memory, new object creation and garbage collection problems to avoid any-and-all memory allocation. However, that means I can see the "no new memory EVER" solution too easily, lazily avoiding looking for the FAST answer that MIGHT throw an OutOfMemoryException. I suggest that the "best" answer would have provably faster execution with provably less overall memory allocation... Your move ;-)
Xamarin are doing some really cool stuff!
Github for windows has a merge interface? Last time I checked it just told you to go to the command line and deal with it.
Git Source Code Provider already integrates with VS. It may not be stupendous but it works quite well. Also: *barf* TortoiseGit. Git Extension is a million times better and doesn't have that SVN smell to it.
Interesting. I never tried Git Source Code Provider. I'll have to check it out.
There's always Mono! You don't need IIS!
It's got drag and drop merging that gives you no indication what it's actually doing. But then it breaks on the simplest of merges.
It's true that F# makes much of this possible with less code. However (not being an F# expert by any definition) I don't think F# can do most of the interesting mutation operations on its immutable objects that the types generated by the T4 template can, nor as efficiently (with Builders, etc).
Um… connect the report to the underlying database? If you have some unusual projections or business rules that don't appear in your database schema, you will either need to recreate them as views in the database, or otherwise mirror that using custom reporting models in SSRS. Now, it's possible that you could install your data access assembly into SQL Server and create CLR-stored procs. I think that the overhead for that would be unbearable, but it would probably work.
http://www.gotreportviewer.com/
Why use EF with reporting? 
tl;dr This post links to a commercial post which links to this site: [learninglineapp.com](https://learninglineapp.com/courses/1/getting-started-with-csharp) anyways, they ask for money per course (around 29$). I don't like it.
On top of looking like an ad link, it troubles me that this advice skips over learning how the web works and the basics of HTML. I've interviewed tons of candidates for ASP.NET jobs that don't know the difference between POST and GET. This kind of advice is probably what leads to that.
Yes. Most asp.net webform guys won't but if they've been exposed to asp.net MVC or other languages like php, perl, java, they usually will know. webform makes it super easy to do things though 
http://www.asp.net/signalr/overview/getting-started/introduction-to-signalr 
If you're not using asp.net, I'm sure there are other libraries that can solve your problem. 
It really depends on what you are looking to do. Might want take a look at the "service stack" project also.
Your question is pretty vague. What are you trying to accomplish by ".NET to JS conversion"?
Visual Studio keeps a history of cursor position. Press Ctrl+hyphen to jump to the last cursor position, Ctrl+Shift+hyyphen to jump to the next cursor position. Visual Studio also auto-saves documents. Click the menu "Tools &gt; Options" then navigate to "Environment &gt; Auto-Recover." By default, VS auto-saves your work every 5 minutes and keeps the data for 7 days. The files are saved in the folder "\...\My Documents\Visual Studio &lt;version&gt;\Backup Files\&lt;projectname&gt;"
Thanks for the hyphen tip! Have some Reddit Gold!
If the autosave not been on a time interval is good enough (it also doesn't modify the underlying files, only in to the temp cache) you could quite easily do this via the API. Whack record macro, press save all, you'll get the code for saving all. Then its just a case of finding which object you need to find to listen to focus changes on a document. Myself, I'd happily let it go to the timer autosave mind! If you're new to VS and C#, get resharper. I can't use VS without it.
Modern web applications built by programmers who prefer server side .NET and want greater integration between front and backends?
Perhaps you're thinking of things like [SharpKit](http://sharpkit.net/) or [Script#](http://michaelsync.net/2007/10/29/script-c-to-javascript-converter)
I'm checking R# out, I don't really understand what it does, but I'm willing to try it out. Is it worth it if I'm using VB, or only C#?
Only time I use VB.Net is when I'm having to endure XML, so I shouldn't say, because I really hate VB.Net. R# makes C# easier in a way, because it provides helpful warning and coding convention, plus if its easier to refactor the code you've just written, it makes for better code. If you've got a bunch of lines that should be split up into two or more methods, you have to be really lazy not too highlight it and Ctrl + Shift + R. Plus with .Net how it is now, there are some really confusing things, because its halfway between languages, is it procedural or functional. This means things like Closure can be problematic for newbs. In fact *Access to Modified Closure* is one of my must have interview questions due to LINQ / Rx. R# gives you a little warning 90% of the time!
You need to take a look at this blog post from the Kendo UI blog: http://www.kendoui.com/blogs/teamblog/posts/13-04-23/sublime-studio-replicating-sublime-text-2-features-in-visual-studio.aspx
A smaller step for front/backend integration would be exposing JSON endpoints your clientside code can communicate with. The server-side code can also embed JSON data in a page response to get the client-side behaviors started. SignalR would start to be appropriate when you want to push notifications from the server to client at the server's request.
Tools like Resharper are useful but I find the added instability and reduced performance aren't worth the benefits for me.
Does it actually save as you type to the file thou? I thought it saved to a temp one that it was doing its fake compilation in. I am not a fan of .Net demon. This might be because I think RedGate are a bunch of cunts (SqlPrompt, Reflector etc), but I just don't see why I'd use this tool over R#. If you want this kind of thing, why not look at Crunch, constant compiling and unit testing, its a great way to make *test first* development actually happen.... Does need some beefy resources mind, and it turns my laptops in to space heaters, but on a desktop its brilliant.
Yes it saves as you type. You wouldn't use it instead of resharper, you use it alongside it. I use Ncrunch as well for continually test running too. I actually turn off the save continually feature however but have it build on save. It can replace the built in VS system which helps speed up builds as well. I understand the hate for RedGate, but it makes my dev workflow work easier.
I have a few that people *should* know, so that when people don't, it weeds them out very quickly. For example: Q: My company makes paint. Paint comes in a bunch of different materials, but largely they're water-borne or solvent-borne, and we have a few different kinds of solvents. For most of our business processes, they behave the same way, but because of environmental considerations, there are a few different rules for the different kinds of solvent-based paints. What object oriented technique would help us implement this easily? A: Inheritance is the textbook answer, but a discussion of design patterns is also acceptable. If they get it right, I segue into: "What would the role of an abstract class be in that solution?". Then I go into: "We also sell what we call 'tier-2' products- stuff that isn't paint we made, but things like rubber gloves, etc. Like paint, we sell them, but we don't apply any of the same business rules we use for paint. How would interfaces help in this situation?" Now, none of that is .NET specific. But missing those questions is an automatic thumbs down, since that's CS101 object orientation.
For the most part, you will be totally rewriting all the asp.net part. There isn't really any commonality between webforms and mvc. Obviously you can keep our business logic and data access, but there is no conversion path between the 2 types of applications. Unless you are just doing this for the heck of it, is there a reason to make this change?
i would not do this. there is nothing inherently wrong with webforms. it is however very different, and you will probably end up just rewriting everything.
If ComboBox1-8 are properties of current class you can easily do it. If they are local variables you are out of luck.
That would be extremely bad practice. Variable's names should not affect the program. What are you trying to achieve here? I don't see why you have so many combo boxes.
I assume ComboBox1..7 are controls on a form you have and you are storing them in an array for some reason. Why not just do this (Form.FindControl for non web pages (I think)): for (int i=0; i&lt;4; ++i) { componentDropdowns[i] = Page.Findcontrol("Combobox" + (2*i + 1)) ... ... }
You haven't asked about it but here is an extension for [Simultaneous Editing in Visual Studio](http://www.hanselman.com/blog/SimultaneousEditingForVisualStudioWithTheFreeMultiEditExtension.aspx)
Properties or fields of the class.
I'd also do a user control. I also wouldn't be using WinForms, though, so what do I know?
I've never suffered any instability problems, but I have noticed the intellisense going slow sometimes.
I've not found any instability in 2012, in 2005 yes, hell yes, buckets of it. I even upgraded my RAM just because R# was eating it. Luckily in 2013 my desktop has 24gb of RAM and the things I've been working on make R# footprint tiny by comparison. But even in 2010, I find R# a blessing, it makes my thoughts into code faster, far faster. But also helps with so many little mistakes I'd make when I'm not paying full attention.
Believe it or not, I've interviewed folks with MVC experience who don't really grok the web.
My local library provides access to Safari Books Online. It's an awesome resource - I don't think I will ever need to buy another programming book again. 
LinkedIn Login
Abstract Class
Add Bookmark
Normalization
This is only applicable for CTP 2. For Update 2, the unit test can be done in VS itself. It still run the emulator though for few seconds to push the app to the emulator. So all the tests condition are fully testes in the right environment. You can still do normal unit test but it won't guarantees whatever API you are using is compatible with WP8. 
I have had a gut feeling recently that a shift is coming. It would be really neat to see it happen. If there were more people writing about positive experiences with open source .NET (Mono and frameworks) I think it could get more traction. Sadly though it seems people want to read about doom and gloom. Just look at the comments for the article on r/programming. It seems nobody even read the article and just assumed that because it has .NET in the title and refers to the future it must be a ".NET is dead" post. http://www.reddit.com/r/programming/comments/1edtfn/where_is_net_headed/
/r/programming 
/r/programming hates the idea that anyone should ever have to pay for anything. It's a clearinghouse for the worst attitudes of the entire OSS community. I really hate that attitude, especially considering how horribly written the majority of OSS is. All cowboy, all the time.
Totally agree. OSS/free software is an option, not the only correct option. Also, .net is fast and supported by the biggest software company in the world. Why not use it?
I think a lot of what people miss in reading these articles lately, and especially if you're not a .Net developer, is that .Net does two big jobs - Windows apps and web. Almost everything being discussed as a problem is on the apps side; the web stuff is doing great. So yeah, there's a problem but talking about .Net as a whole dying is a bit extreme.
I think you nailed it. According to /r/programming, using the most bleeding edge, still full of bugs new language is extremely important to being a successful programmer. After you've spent some time working you realize that writing code that's easy to understand is pretty much the most important criteria for what makes good code. I had similar beliefs when I was in school and doing all kinds of small scale pet projects. That approach just doesn't work very well when you scale up to millions of lines of code written by 10s to hundreds of different people.
i would agree with this. app side is a little shaky but for web apps .net, especially with MVC is growing well and actively being improved. i do not think its going anywhere for a long time.
I think the criticism on the desktop app side is less related to quality but more about stability. Big changes too often.
From my perspective, the main things that have changed have been the best practices, which have evolved as the technology has improved. I haven't seen anything being broken so far. That might be different if we were developing with Silverlight though. If anything, I kind of want them to slow down and think about the future of the new stuff they're producing. It definitely doesn't do any one any good for them to shutter things they were advertising as the future path of development just a handful of years earlier. I think it's great that they're advancing the technology the way they are, but since they're the only people that can support that technology, they've got to be committed to actually doing that. There's only so much of that kind of bullshit people are going to put up with before they really start questioning if they should adopt the next new thing MS tells us is the future again.
My boss is currently trying to get Visual Studio for us, and in the meantime I've been using [SharpDevelop](http://www.icsharpcode.net/opensource/sd/), which is free, and it's a joy to use.
Ugh, I know what you mean. I need to super glue my eyes in the socket to keep the from rolling right out of my head when reading the comments there.
Have you/your boss looked into WebSpark or BizSpark? Both of those will get you a bunch of free tools/OS/Azure/etc for several years
Isn't Visual Studio 2010/2012 Express better than SharpDevelop?
While its still not great I have been feeling less hate on HN for things related to Microsoft in the past few months. I read it the moment I wake up so I have a chance to read some Microsoft stuff posted by people who I can only assume are in European time zones before people in California can wake up and bury them.
Good question. I prefer Visual Studio over SharpDevelop, so it might depend on what kind of limitations come with the Express editions. I'd have to look that up.
I've noticed that mentality on r/programming as well as on r/coding (to a lesser degree). I think Xamarin/Mono may well help the situation, and the Monkeyspace conference as well. 
/r/programming /r/coding 
MS is retiring Web Site Spark program. Unfortunate, but that is how I got hooked up. I have long contended that MS should make what they currently call "VS 2012 Pro" the free version (or at least low cost - ~$100 or so) to lower the barrier to entry to VS, and .NET. Big shops will still have to license appropriately. Current pricing on VS Pro tends to run upwards of $500, too rich for the blood of many new/indie developers trying to decide what platform to learn/work on. 
Based on what you described as past experience, you definitely should look into EF and Linq to entities as I feel this will have the most dramatic impact on your productivity. I'd suggest starting with Linq because: * It has a far reach - Linq to Objects, Linq to XML, Linq to Entities (need this for EF) and then custom implementations out there like Linq to Flickr, Linq to LDAP, etc. * Linq has been written with optimizations to automatically handle things like searches utilizing multiple processors/cores Once you have a general feel for Linq, get a crash course on EF and you'll love not having to write large data layers! For Linq [this](http://tech.pro/tutorial/1152/demystifying-linq) is a pretty good article
LINQ is such a core part of the language now. It seems like I use it for something every few lines of code. Definitely catch up on that first. Lambdas are also important for LINQ, and take some getting used to. The Parallel extensions are really handy for certain types of problems. If you do web stuff, definitely learn ASP.NET MVC (and Razor) EF is a must-have if you do any database stuff. Learn EF code first. It sounds like a lot to learn, but so many things are easier now than they were back in the 2.0 days.
So LinQ first and then EF? 
Agree completely as I was (still am a bit) in OP's state a while ago. One more thing I'd add, if you ever did any traditional asp.net webservices try and read something about WCF - this is the field I completely left out and it's starting to show. [WCF vs webservices](http://www.codeproject.com/Articles/139787/What-s-the-Difference-between-WCF-and-Web-Services)
One small point: You will want to get comfortable with 1) lambda expressions 2) anonymous types (see var) and 3) extension methods - all before LINQ, because LINQ makes heavy use of all of them. Don't worry, they are all conceptually easy and not a lot of work to learn, though LINQ itself can be. Start with those 3 first and LINQ will make a lot more sense. 
This... LINQ is extremely powerful, but these three are very important. Otherwise you will be using LINQ and never have a full understanding that these can also be used outside of LINQ. I would definitely learn LINQ afterwards, but these will help out everywhere even when querying of collections or data is not involved. 
Depending on who you are MVC may be a great option. It also depends what you want to do with the framework. Some developers find MVC much faster to develop in, some don't, but it's definitely worth looking at. For web applications that are very data centric MVC with Knockout JS can really speed up your development time and allow you to make pretty awesome applications.
Even for IPC wcf removes so many headaches.
After reading 3 articles this week proclaiming the death of .net, I'd say: Rails 
I suggest making sure you understand the paradigm shifts each major release of the .net framework has brought. Once you've worked through these I think you'll find you're mostly caught up, or at least will know what you should focus on: 1. Extension methods, LinQ, WCF &amp; WPF for .net 3.5. 2. Tasks, async and await for .net 4. Briefly: 1. Extension methods let you write static methods that look like instance methods. These were developed to make LinQ possible. 2. LinQ takes a lot of the work out of common tasks performed on collections. 3. WCF simplifies and standardises networking; once it's configured you can switch between different networking protocols without code changes, which is much handier than it sounds. 4. WPF makes GUI work *really* hard. Actually it does stuff like let you apply styles to all controls within a specific scope, and separates view and control logic to try to make UI apps more maintainable. It's very powerful but there's a steep learning curve here. 5. The Task type, and async and await keywords simplify thread synchronisation. After that you can start learning the specifics of how to implement solutions with these technologies. I'd leave entity framework until you need to use it. It doesn't seem like the kind of tech you can just pick up by reading about.
THE SKY IS FALLING THE SKY IS FALLING THE SKY IS FALLING!
I don't think you should feel shame. The worst developers I have worked with have been those not yet crushed by the wave of the Dunning-Kruger effect. Regarding learning material I have found that I end up helping others at work not with MVC or LINQ but with more primitive concepts such as basics of C#, how the CLR works, and WHEN to use things like LINQ. While I think learning some of the baseline buzzwords such as MVC are important for resumes and interviews I think things like Code Complete (maybe) and the CLR via C# (even with it's age) can have a larger impact on overall software quality.
ASP.NET MVC has gotten a bit ahead of this tutorial, but it's definitely still an excellent resource. Back when I was first learning MVC about four years ago, this tutorial was integral. At the time, I didn't know MVC, jQuery or Entity Framework and I learned all 3 at once. Seriously helpful. http://nerddinner.codeplex.com/
Yes, Linq is a query language for objects. EF is built on Linq.
I don't know exactly how to do it in .Net, you could do it via implementing your own mixer in C++, if you look at the Vista platform SDK I think there was an example of this mixed in with something else. If you are hoping to do this via WSAPI you'll be SOL, as per the documentation here: http://msdn.microsoft.com/en-us/library/windows/desktop/dd316551(v=vs.85).aspx They don't want people making loopback adapters that you can easily sample, due to DRM, this is why many drivers don't have any loopback at all. I think you might have more luck posting in a non-dotnet subreddit, because I fear your solution will lie in the kernel, or at the very least finding a custom device driver that does the loopback how you want.
I know plugins aren't available to Express, which sucks as ReSharper rocks.
node.js
Agreed. The article I linked to does a decent job of introducing lambda expressions and extension methods in the context of Linq. Those things are certainly useful outside of Linq too so it's a good idea to study them on their own.
I bet if I looked I could find articles talking about both the death of MS and the death of .net no more than 5 years after the release of the .net platform!
Last I checked, the model can not be inherited from and expanded upon without modifying the original model, which means that creating a new EF model now means creating a new version of my DAL per customer, instead of simply adding a new method to deal with a new column, or no longer having to deal with a particular foreign key. If I want an application where the database and software will always be one and the same, then yeah, EF is great. But if I want a loosely coupled environment then EF is the devil's playground, and working with it will only end in tears. And all of that is to say, the only reason to work in EF today is to be able to say you've done it (or the aforementioned fusion of your data store and your application into one giant Microsoft Voltron), because 9 times out of 10 you're doing more work than you would to simply query SQL in the first place. If you're competent enough to produce a conceptual model that isn't terrible in .NET code, you can do it just as easily in SQL. If you can write your query in .NET, you can write it in SQL. EF is "hip" and it gives people the impression they don't have to know shit about SQL, but it doesn't make a better outcome, just a more constrained one.
Why don't you just use the window.onblur event to use the Youtube API to mute the videos?
You would be wrong in your assertion that EF is only useful to say you have used it. Do me a favor, take a gander at [this list of ORM packages](http://en.wikipedia.org/wiki/List_of_object-relational_mapping_software) across ever major platform and tell me you still think that object relational mappers are irrelevant if you know your way around SQL? &gt;because 9 times out of 10 you're doing more work than you would to simply query SQL in the first place Yea, I love doing more work now than I was 15 years ago, I really do, it's so fun going backwards in productivity.
Nope! You are free to write your DAL.. but even if I wrote a business entity layer (doing domain driven design this is how I have approached my DAL for the last 10 years) I would still use EF and Linq today to speed up and simplify the process of retrieving data and converting it into domain entities.
EF is only useful to say you've used it. I didn't say all ORMs are. Maybe there are better ORMs, but EF has left a bitter taste in my mouth. I've yet to work at a company on a product where using EF was better in any way (other than sprocs) than not EF. All of the theoretical benefit is wiped out the minute you have to abandon code-first, and you're left with twice the code you needed because some fucking code hipster swore EF would make it easier. Then you refactor and remember why you weren't using it to begin with.
A bit of a warning... I found LinQ very difficult to get into, but Resharper kept insisting on refactoring my code to use it. Entire nested foreach loops with continues scatter through them would disappear into a single line of highly readable code. example: if(carList.Any(car=&gt;car.Manufacturer == Manufacturer.Ford)) { // There is a Ford in the list } Each time it did it, I spent some time working out what it was doing. Each time I had an "AHA" moment and after a while I just found myself writing the code direct into LinQ. This is a really, really easy way to learn LinQ. I'd recommend it. Get the free Resharper trial. I ended up paying for Resharper, but you could uninstall once you're done.
Why are you stuck on "code-first" as an approach? I have never approached EF from the angle of creating classes and then having EF create the database, but you *can* do that. I have always started at the conceptual modeling level using [Object Role Modeling](http://www.orm.net/), which I then use to generate the physical (rdbms) schema. From the physical schema I simply add tables to the EF model and it provides an object oriented DAL that mirrors my conceptual model saving me countless hours of laborious work. I'm sure your experience has been different, as you obviously feel it has. I don't understand why you had such a tough time having to "abandon" EF and being left with "twice the code", I really don't understand what individuals at your organization were doing so wrong to end up with such a mess.
Not abandoning EF resulted in twice the code. Reading from EF? Trading a less than appetizing DataRow translation into my objects for translating the EF objects to another, identical set of objects. Writing through EF? Completely obnoxious, and worse in every way than writing an explicit update or insert statement. At the end of the day, its faster to market, less code, easier to refactor, and far fewer headaches than ramming EF into a solution where it lacks every single convenience that folks like Hanselman swears it offers. I didn't have a tough time abandoning EF, I had a tough time justifying not tearing it out. So we did. And our code base is now half the size, more flexible, extensible, and everything that EF markets itself as.
I understand, faster to market fo-sho when the developer coding doesn't know how to use EF effectively and can't stand it. If I had to go back in time to your method of approaching software, my shit would not to get to market fast either. It's a great time in software though! You keep on with your bad self, knocking out those SQL updates vs. using an object state manager that knows how to write your updates and inserts for you. As long as you're enjoying it, more power to you.
They don't even go together though. F# is for special cases more so than general development.
forget ASP.NET. are you allowed to use MVC 3 or 4?
yes. i want to use mvc4, and that was what i was referencing when i said VS automatically generates controllers with all of your code for you. i followed some mvcmovie tutorial and after creating one same model the next step generated the entire functionality for me, which wasn't helpful at all. i didn't even know asp.net was diff from mvc 3/4, i just thought the difference was either web forms or mvc.
ah, i see. yes, i refer to web forms when i say "ASP.NET". you absolutely don't need to use code generation...and that's about as helpful as i can be, because i've only written an MVC application once, and that was a couple years ago. 
Are you planning to use Entity Framework?
You can just create a new empty controller and code what the controller does yourself. 
Ah - I gotcha. Thanks, that's good to know.
I was in your shoes about five months ago. I wanted to learn C# to modify some programs like [iSpy](http://www.ispyconnect.com/download.aspx) and to also do my own projects. I picked up a book "Head First C#" that is pretty good, but I had a hard time staying motivated to stick with it. Then I found out a coworker was teaching a class for unemployed programmers through a federal grant and the local community college for the 70-515 Microsoft MCTS certification. I just paid to take the four month course at the college and just finished the class and am about to take the certification exam. A lot of the class was about learning my way around the development environment but taking the class made that second nature so that I could focus better on coding. One option I think you might have is to use another IDE other than Visual Studio. I think that for C#, you could try: MonoDevelop, SharpDevelop or Parakeet (and probably some other alternative IDE's). Or just use console and text files along with some program like Notepad++.
cool. 
I don't see any plain JavaScript in your experiences. Make sure you get *real* familiar with it before you go very deeply into jQuery. ASP.NET MVC (v. 3 or later) is a good framework (it's really a design pattern) to know, too. Web development is much more client-focused than back in the .NET 2.0 days. Good luck!
VS does try to 'help' you and certainly I, too, like to know how things work in the more _bare metal_ sense. So as others have pointed out, you are not obliged to use the templates that VS fills in for you - for a controller, just create a new class in the Controllers folder, for example. This is the case for most things. As for general knowledge of ASP.NET MVC: The [official ASP.NET site videos on MVC](http://www.asp.net/mvc/videos) have a lot of decent content - if you look at the MVC2 and MVC3 videos that should help you a lot, even if you're doing MVC4. Also, if you like videos/screencasts, the [Dimecasts MVC tagged videos](http://dimecasts.net/Casts/ByTag/MVC) should also provide some very good tutorials on things. Also ,TekPub has some [free ASP.NET MVC content](http://tekpub.com/productions/aspmvc). They also have a [420 minute ASP.NET MVC3 real-world video series that frankly is worth more than the 15 bucks they are charging](http://tekpub.com/productions/mvc3) - if you ask me, that is. These are good videos (if I recall correctly) to address your concern about VS helping you too much. The authors of these vids tend to show you how things work, so you aren't just relying on tools to get any work done. Hope this helps 
I don't recall anything like controllers in ASP.net 4.
ASP.NET is not synonymously with Web Forms. ASP.NET is a family of frameworks for developing web applications on .NET - Web Forms, MVC and the Web API are all ASP.NET. 
Apparently the OP can't deliver so does that mean didn't happen? The better question is why is OP in the .NET subreddit if they believe .NET is dying... 
I've been out of the .Net shop for a while, but isn't MVC 3/4 a part of ASP.NET?
You can create an empty controller or if that feels too much like code generation, just create a class in the controllers folder and inherit Controller. You don't have to use any of the template stuff if you don't want to.
Also those scaffolding templates can be edited.
Yes. Web Forms and MVC are both different flavors of ASP.NET. 
It makes boilerplate templates for controllers and views, is this what is hanging you up? The templates are editable as well.
There is a feature in Windows 7 (vista?) and up that allows you to lower /mute other sources from the audio panel. Google voice, Skype, and others take advantage of this 
If you re- `throw` the exception it allows things to bubble up in the stack trace so you can diagnose the issues. Some will argue it's not best practice, but you could let it float up to your programs' entry point ( http://stackoverflow.com/questions/7572995/how-can-i-get-winforms-to-stop-silently-ignoring-unhandled-exceptions ). There are various tools to log these, or you can log it to DB/disk yourself. But, if you just try/catch the exceptions 3 layers down, you may never know what really happened. 
You throw an exception when your current execution path cannot continue - for whatever reason your code just can't complete what it wants to do. This communicates to the calling code that something has gone critically wrong. At this point it's up to the calling code to decide what to do - log the error and give up, or wait and try again, or try an alternative method for completing its task. The most appropriate response depends on the application. EDIT: punctuation
But don't exceptions get thrown themselves? I know if something is wrong I get sent to a page that lists the exception and the piece of code that threw the exception, so what is the point of throwing one? My thoughts are that I can use a try block to try code, catch block where I can throw the exception (although I still have no idea what that really means or why to do it), and then a finally block. In the catch block is code that will be run if my try block fails, and the catch block will end at the point that I throw the exception. After that my finally block will execute, correct? I'm just missing the point I think...
So, what you're saying is that throwing the exception will give me a better idea of where the exception actually occurred? Is that really about all it does? I sometimes get methods that the exception will show on an abstract class, since I'm using a method of a concrete class that is derived from the abstract class. If I put a throw statement in the concrete class is that supposed to just narrow down exactly where the error is occurring?
How would you clear the error? Is that what the throw statement does? Also, I don't have an application_error method/class in global.asax, is this something you made yourself and you're just simplifying it here, or are you using a certain library?
Sometimes if one function fails, the code may still continue. Example (Python code, same concept). def load_config(): f = open('config.ini', 'r') .... def main() try: config = load_config() except IOError as e: print("Config failed to load because of %s...using default config" % e.reason) The point of exceptions is so that you may HANDLE errors further up the calling stack, not so you can display an error and quit. load_config failed and was unable to continue, but main may still continue, we just need to handle the config not loading and do our own thing.
I think why you are having an issue with understanding is that you are overusing the catches. If your catch is empty, why do you even have the try in the first place? If an exception has been thrown, it should not be silently swallowing because the exception was thrown for a reason. This can lead to bad user experiences as well when they cannot figure out why something did not work or worse that it looked like everything worked fine but an exception was thrown and silently swallowed causing them to lose whatever they were doing.
If you're building a web app (and since you mention "error page", I'm guessing so), NuGet in ELMAH and call it a day. try/catch blocks make sense if you can add some context to an exception being thrown ("I'd like to know what Foo ID my BarMethod is choking on; here's where I can add it") or if you want to add a global exception handler so that exceptions that would otherwise force your application to halt have a chance of being caught and displayed to the user/logged somewhere.
Let's say you get an I/O error somewhere deep in your program. You can see that `foo.ReadFileFromDisk($bar)` threw the original error when using `System.Text(...)`. If you don't properly re-throw or simply catch the error, it's somewhat a mystery where this failed. At least, that's my understanding of the idea. 
Kudos to the author for giving me yet another reason to work on adding Castle.Proxies to my tool belt, but I'm left wondering if this isn't a really big hammer for a problem that might not be a nail after all. Maybe I'm just suffering from a contrived example, and please correct me if I am, but I immediately had to wonder why on earth we would want to write: student.School.District.Street.Name It seems like a violation of "Tell, don't ask". I don't want to pretend I never violate it myself, but generally speaking, I've found avoiding the need for statements like this to be a lot better for my code than adding Castle.Proxies.
So, basically it ends the method/function that actually had the exception but will continue on with the remainder of code? I'm guessing this is only true also if I have it programmed that way...
Things are starting to make sense, but now I'm starting to think that maybe I don't need exception handlers like I previously thought. It seems that they're more of a way to tell where the problem occurred, but not much else... am I correct in this?
It ends every caller until it hits a catch. The code then continues from the catch (In whichever function caught it). If no catches were in place for it, it quits with an exception output.
Okay, it's starting to make more and more sense to me. One question I have is how bad is it for the exception to travel up the whole program? Does it really just depend on my application and how it was programmed?
Thanks. For some reason, this comment made a lot of things make sense to me.
It's your choice to throw or not to throw. Depends on your need. If you throw you halt execution within the scope of the method being executed. A good time to throw would be when you encounter an error that shouldn't happen. You go to insert or update a record and the command fails. Well do you want the user to continue on add if nothing happened, retry the command or be shown an error message and redirected elsewhere? As a general rule, you should throw for a major error and handle specific errors otherwise.
I definitely agree, but sometimes those kinds of chains happen. For me, I find it happens a lot when you are working with data objects that map to database schemas. Just as an example, here is a random line from one of the NHibernate's unit test fixtures: &gt; Assert.AreEqual(2, hc.SessionFactory.Events[0].Listeners.Count); No null checks, though anything here could theoretically be null. In general, the article was just an experiment to use castle. I wouldn't use this in production if only because I couldn't get it to proxy all enumerable types. If you did do that, you'd get a type cast error at runtime which is just as bad as a null ref error Anyways, glad you liked the article!
Yeah, I think I have a lot of specific errors handled by checking certain things. For instance a user is trying to upload a file, I test if there is a file first, if there is, I allow the upload, otherwise I return a view and set tempdata to let the user know the upload didn't happen. Since I do this, I'm guessing I wouldn't need whateverexceptionhandlesmissingfiles. Correct?
Yes exceptions will get thrown by code that you invoke. Put simply you should throw an exception when you encounter a situation where you know you can't complete your current task. That's not necessarily within a try block or a catch block. You wrap the method that can throw an exception in a try/catch which allows you to react to a failure condition should the exception be thrown. It's not an intuitive concept to grasp but stick with it and you'll reap the benefits.
It's completely dependent on what your program does and how it failing affects the user. Worst case scenario is that program exits and stops running, possibly leaving some persistent data in an unknown state. For example, a program that writes some data to file sequentially might only write some of it before it crashes and that file might then be useless. It really depends on what the program is doing. If you've allocated unmanaged resources (things garbage collection doesn't clean up for you) they might stay allocated to a dead process and be unavailable to anything else that wants to use them, but given the topic at hand, I doubt you're doing anything crazy like that (you have to go quite a bit out of your way to do this). The whole thing with exceptions is that they're a way for *you* to deal with unexpected errors as gracefully as possible. It might be the case that your application *should* crash if something unexpected happens. In a web application, that's typically not the case though. In that context, all that error message crap is at best meaningless to the end user, and at worst, possibly helpful to a malicious user who's *trying* to break your application. If an error occurs when processing user input data, it's probably best that you redirect them back to the input page and have them try again (or better yet, validate the data before trying to process it and tell the user exactly what they did wrong). It is generally really bad form to put empty catch blocks unless you really do want to ignore the error. One place where I will do that with some regularity is in my exception handling routines. For instance, maybe I'm logging my errors to a database, but if the error was caused by the database being unavailable, that's not going to work, so just swallow the error and move on. I will typically do a couple different things to log the error, put it in the database, send an email to the dev team, and put entry in the event log. I'll put all of these in their own try with an empty catch block so if anything fails, it keeps going. Ultimately logging the error is less important than the whole application imploding, so I make sure that doesn't happen at the expense of possibly not logging the error. You should be thinking about where things might fail and at what point in your code you can recover from a failure. You want to try and recover as quickly as possible while maintaining a known state of your application. If you get an exception writing to a file for instance, it's probably best to assume that that file is now corrupt and that you'll have to start over the whole process of writing it. Something that can help you a bit with this is by using multiple catch blocks on a single try. Say you're calling a method and you're worried that it might fail if a parameter is null (this is a bad example because this would be better done by validating the data first, but just roll with it). You could do something like this: try { BlahMethod(parameter); } catch (ArgumentNullException ex) { /* handle the case where parameter was null here */ } catch (Exception ex) { /* handle any other error here */ } The thing to remember about this is that the first catch that can handle the exception in question will be the one that is run. Since all exceptions derive from the `Exception` class, if you declare a catch block for `Exception`, it will catch every exception thrown. So start with your most specific exception and work towards the most generic. This is only necessary if you want to handle different errors in different ways.
VERY helpful. Thanks a ton. Exceptions have been bugging me for a while because I just didn't quite understand. Now I feel like I'm getting it and it's all making some sense. I don't really have any exceptions being thrown/handled, but now that I am better understanding I can already see a few places where I'll need to add them. 
Starting to get it now. This thread was REALLY helpful to me actually, glad I asked this question. I may not know everything or much about exceptions, but the answers I received here have given me a lot of insight and will allow me to continue looking up info by myself. I just wasn't getting it before by reading MSDN pages and such.
Thanks, I'll be awaiting your response. I'm starting to get it better now, but anymore info is also helpful.
Just wanted to add, what has really thrown me off when trying to learn exception handling was how a lot of tutorials/examples were. From what I recall, when I was looking at such, almost all the time I could swear that the examples were like the following: try { //something } catch nullexception e { throw e; } Maybe I'm remembering wrong, but when I was looking through them, it seemed that this is how all the examples I could find were. I thought I understood that throw meant to return that exception, but in the context above it didn't really make sense to me.
I don't think it's dying, Twitter/blogs do in reaction to Scott Guthrie's latest post on the future of .Net. Regardless of the direction MS may or may not take, .Net only dies if people stop using it.
Yeah that looks about right. This way instead of returning your regular class you return the proxy which subclasses your class at runtime and can do work on method invocations. Castle can only proxy virtual methods though 
Cool. Pro tip: don't send an email for every exception. You'll end up with an issue in production and give someone a very bad email day. 
&gt;All I'd need to do Assuming all your methods a re virtual already.
Yeah, that's totally pointless. It would effectively be the same thing as not handling it at all. There are a lot of crappy blogs written by people that don't know what they're talking about nearly as much as they think they do. Some people do it because they think having a programming blog will make them a more appealing job candidate so they just spew ill informed idiocy all over the internet just so they have something to post.
You can explain to me all day it is, and it will be all day explaining it to me.
The return values from the If statement must be the same type. See here: http://stackoverflow.com/questions/330471/c-sharp-why-cant-a-nullable-int-be-assigned-null-as-a-value
`Nothing` is not `null`. `Nothing` is C#'s `default(T)` where `T` is inferred from the context. Thus, the behavior you're seeing makes sense; `If(xxx, Nothing, 5)` is inferred by the compiler as `If(xxx, 0, 5)` since the other option is an integer.
Off topic, but VB's syntax reminds me of cave man speak. If me.nofire then me.makefire else me.cookfood
I'm pretty sure IF can only return one type, 5 is of non-nullable integer type and so vb is casting nothing to non-nullable integer type and getting a 0, which is why its returning 0. If you set 5 to a nullable integer variable before running the IF statement you'll probably get a nothing back from the result as all values passed it can be nullable therefore the response can be as well.
As if saying `this.makefire` is any better. At least it understands first person perspective.
Is nothing indicates when a variable is null. By setting the nullable var to nothing, you set it to zero. Just don't set it if you wish it to remain null. There is no setting equal to null like in c#.
That's great. You funny.
It's not a hard rule but the current compiler implements interface methods as virtual. 
For most of our stuff I use LINQ to SQL. Its fast and easy. For more complicated stuff I try to do the hard work on the database, but Im also the DB admin. I do want to learn Entity Framework since we do hit some Oracle databases.
Hand writing a DAL doesn't seem to be trendy any more. Almost all articles I read (which isn't many in honesty), or stackoverflow questions revolve around using EF, LinkToSQL or similar. I hand write my DAL code using ADO.net still and it works a treat. Ok, maybe I spend a day or two writing it more than if I used EF (depending on size of app), but I personally prefer the versatility.
We have a few projects here. Our old stuff uses ADO.Net but without any real data persistence (old developer used bad techniques) and then we have some new projects using Entity Framework. Unfortunately, I'm stuck fixing/maintaining all the old stuff. :(
LINQ if performance doesn't matter. Dapper if it does. Ideally, though, DBA should be doing some work (sprocs, etc).
This looks really interesting.
I have found benefits with multiple approaches. What I choose depends on the situation. The following sums up when and why I use what I do. **Micro ORMs (Dapper/OrmLite)** When: For applications where most of the work is done in a stateless environment. Web services, web applications, or small tools. This makes up the bulk of the work I do these days. Why: I love the simplicity and the speed I get. I can use a standard ADO connection and debugging is super easy. Most of the time I just simply drop some SQL down and have it easily parameterized with minimal performance impact. If I want all the Employees with a name matching a search string I rarely need to worry about FK relationships or an expression tree to SQL generator. Simple. **Behemoth ORMs (EF/NHibernate)** When: I rarely use these anymore. I found them very useful for applications that kept objects in memory for a long time, had heavy mutation, or lots of crazy FK relationships. Think WinForms and WPF. Why: Because I was just as lazy as I am today. **Do It Yourself** When: Nearly never. Why: The only thing I can think of is database specific bulk operations like loading huge hunks of data.
&gt;Hand writing a DAL doesn't seem to be trendy any more Yea it really isn't. ORMs are more "cutting edge."
It's a shame cutting edge has so much focus. People go into job interviews being expected to know all the new stuff when they could write a supportable and well maintainable app using tech which has been out for a few years. *Not using EF and MVC?, GTFO ...* An app developed using EF is not going to be any better than an app written using ADO.net code. Just sayin'.
Agree. In 8 years the current EF implementation will be obscure for developers to understand, updates might break functionality, maintenance might be more difficult etc. 
I would love to go, but a trip to London is unreasonable currently. I can't wait to watch the tutorials.
The main application which I inherited is written in VB.NET. I do prefer C#, but I can appreciate VB.NET's place in this world. It may be the laugh of most developers, but I'd take VB.NET over many non-.NET languages any day.
Maybe the guy will make me want to use it. Currently the documentation sucks and the library has so much backward compatibility but has changed so much it is hard to know which objects do what with what objects. I really do hope this guy make it better.
Yeah. I prefer Moq myself.
I prefer Moq, but this goes back to when rhino had an explicit record/replay style, which I don't think is still the case.
They still have the record/replay style if you want (does anyone?), but it can be even easier than that. [This article goes a bit into the changes from the old, fugly way.](http://dumians.wordpress.com/2012/08/19/rhino-mocks-vs-moq-best-net-mocking-frameworks/) var foo = MockRepository.GenerateStub&lt;Foo&gt;(); foo.Expect(f =&gt; f.Bar()).Return(true); foo.Expect(f =&gt; f.Baz()).CallOriginalMethod(); The documentation is kind of iffy, but I can't think of anything I've needed to do that I couldn't puzzle my way through with IntelliSense and a little Googling.
I switched to NSubstitute, working great so far 
Aw maybe another year =) Should be uploaded shortly after they are recorded on the day!
you don't? ... as the smallest example possible ..what happens when you dbl click a button? ..code generation. How do you create forms and controls? .. code generation.
Heads up to folks. REST API's with MVC are easy but VERY limited with regards to data and transport portability. If you know you will only ever need the one transport and the one data format for your site then go for it! It's likely one of the easiest ways to get to a REST system in .NET land at this point. However if you need multiple transports, support for more than one message or handling of other service concepts that MVC does not account for then you are much better off digging into WCF.
I'm curious what type of data and transport do you require that WebAPI is not providing for you?
WebAPI = HTTP transport only WebAPI and MVC are meant as lightweight service endpoint tools at best. Together they provide a subset of WCF capability. I have written applications that expose services both over standard transports and via custom sockets with binary transfers using formats like protobuf sometimes the same service must support both at the same time.
I guess technically, using the IDE to give you an event handler, so you don't have to spend 10 seconds coding it is code generation, but I don't think that's what he's talking about when he said the code gen "does the most important things for me." 
I've built a REST API with Web API and since tried [Nancy](http://nancyfx.org/). I found Nancy better suited to rapid REST development as it includes baked-in functionality for a lot of the stuff I was having to add-on to Web API (IoC, authentication, fancier routing, et al). YMMV.
Nancy is a great project. So is ServiceStack
Honestly, drop the 30 bux a month on pluralsight. They have fantastic mvc4 videos, along with hundreds of other amazing lessons. I promise I'm totally not affiliated with them.
Also, yes there's a lot of auto gen code, but the guy on PS goes into a lot of it and explains what is happening.
Although not mandatory, REST and HTTP typically go hand-in-hand. So, if you are going to do REST, web api's http limitation is going to be fine. Also, SOAP seems almost universally despised these days. Most of the major cloud service providers seem to be scraping their SOAP Apis in favor of REST. Since WCF=SOAP, I would say use of WCF should be given careful thought as well.
Note that WCF != SOAP. The default transport for WCF is HTTP and the default messaging format is SOAP but neither is required for WCF to operate (it was simply the big standard of the day, had WCF come out today, it would have likely defaulted to JSON over HTTP which WCF does just fine). It is a message and transport neutral inter-process communication framework. 
We're looking to change aspects of the project, but we can't change the fact that a project is required because of HR politics. :-/ &gt;Why is this unfortunate? Web Forms is becoming more and more synonymous with "work on legacy code" which is a big turn off for a lot of people. &gt;Are you going to want to retain this person and move them into another position within your organization once they're more skilled and know your business rules and culture? Ideally, yes. &gt;Do you want to grow the position itself? The position has some growth, but more than likely overtime the person would be promoted and another person selected for that initial position. If doing a small CRUD app, do you have any ideas on how to improve that? I haven't been able to think of anything good thus far. Just stuff like a basic pet store's inventory—that sorta stuff. It seems like it could be improved. 
Have them do FizzBuzz or a similar small programming problem. If it's an entry-level position you're going to have to train them extensively regardless - school cannot adequately prepare students for industry programming, and a decent programmer will be able to pick up your frameworks - so weed out the sea of candidates that literally can't program.
&gt; If doing a small CRUD app, do you have any ideas on how to improve that? I haven't been able to think of anything good thus far. Just stuff like a basic pet store's inventory—that sorta stuff. It seems like it could be improved. Make it about your business. Then you could see what they know/have researched about your business already. You could also walk them through your existing site's front end (maybe the development version) and ask them what they'd do to improve it. There are a lot of people who are content with working on Web Forms, legacy code, etc... Not everyone is able or looking to do bleeding edge development. If you're looking to retain someone for a while, you might want to avoid hiring the brightest, most ambitious and upwardly mobile candidate with the great portfolio and the latest skills. Some police departments have IQ tests and if your IQ is too high, they won't hire you because they assume that you'll be bored with routine police work and you won't be around long. You might consider an older worker. I've also noticed that women tend to stay in positions longer (maybe they value stability and relationships more?).
Yeah, plus testing knowledge of webforms it dumb. You might turn away someone who has never done webforms or .net but could be a excellent programmer. If you could turn the test more to understanding web stuff, like post or get, etc. If they have a little .net experience have the build simple chat program that logs to a database, lets them set a username, either built using post backs, ajax,or maybe even give them options like signalr , if they don't know signalr have a little example or reference of it to see their ability to learn new things. Could add in some other things, like another page to look up query chat history etc. seeing what tech people choose or asking them why they did it that way would give more insight into people, even of they don't complete it. Honestly a little larger than they could do would also help you see how people focus, are the big or small picture etc. My last thing would be to make sure you tell the interviewee when they are called for one. Just say "there is a technical test, it takes x hours, it will be using these technologies", and you can then see how prepare people are as well. Edit: if that is to much, make a small app yourself and have them add a feature to it, tests if the and read and understand code.
One of the best I've seen was there was a small code base that did a really naive implementation of building questions on a page. Basically it was a really poorly done "test creator", but it was a very small project, maybe 100 lines. The full test was write unit tests for the current code, re-factor the code, then add some feature we'd decide at the time. Skip unit testing, or the new feature depending on the time frame and how much sample code you want from the applicant.
Don't limit them to web-forms and you are good to go. This will let you see people that are more ready than others. But really for an entry level position even this seems to be a bit much.
If you don't already have it all worked out it may be nice to have them work on build automation, test automation, portability (do I really need Oracle installed to run the tests?), and other SCM stuff. While it often is light on programming it may help them to get acquainted with all of your software, existing processes, and the team for when they can be brought into other projects.
&gt;Web Forms is becoming more and more synonymous with "work on legacy code" I'd disagree. It may not be 'flavour of the month' but the recommended tech seems to change every year or so. It used to be MVC then Razor then MVC3 then whatever it is these days...It's tried and tested and in 99.9% of situations it does the job perfectly well. Anyway, "work on legacy code" is what (from my experience) a lot of web development work actually involves in the real world. Sounds like a damned good test to me. I've built a few projects lately that have HAD to be webforms based because we agreed that an MVC / MVVM scenario would've caused a nightmare on the server for one reason or another. &gt;We're looking to change aspects of the project, but we can't change the fact that a project is required because of HR politics. :-/ Still no answer to the question of WHY are you TRYING to change though - from the OP : &gt;You don't say why you want to change from what you're doing now, 
Maybe ask them for ideas on what kind of app they would want to build and have them do it. Frame it such that it is simple, can be done within a few hours or so and needs to be "working". So it becomes a little bit more about showcasing their creativity! If you asked me to come up with my own project, some things I might come up with include: An auto scheduler for employees, An organizer for someone who needs to keep track of medications, A planner for programming projects which allows you to create tasks and subtasks and to log your progress, A netflix helper of some sort These are off the top of my head. Have them pitch an idea and then alter it for what you think is good
&gt;Edit: if that is to much, make a small app yourself and have them add a feature to it, tests if the and read and understand code. This is a much better approach. You can have database migrations, unit tests, IOC, naming conventions, etc all setup already. Remember your not the only position they are applying for and can't expect people to spend a full day or more on each application.
Ok dude I'm stumped, when would webforms ever be a better solution than mvc.
Answering my own question: You can see a complete error description in the "logs" section of your Stripe account. I wasn't seeing it at first because I thought I was using the testing keys, but my logic was wrong in a place where I automatically set the key based on environment, and the errors were being posted to the Live Logs.
Not a bad idea
If you're currently a webforms shop and you don't do MVC, you don't have the money to hire someone who knows MVC (which is what it sounds like here) and the legacy project that you're working with is webforms.
My test... 1. Allow the user to upload a CSV file of names, addresses, and birth days. 2. Allow the user to enter a month. This will call a stored procedure that gets everyone born in that month. Use that info to generate mailing labels for birthday cards. Tell the candidate that they can ask followup questions and give them a week so there is no excuse for not doing their best work. Code review during the interview. And bonus points if they have enough sense to actually ask about requirements like filtering out duplicate records. P.S. I never specified the technology. They could use WinForms, WebForms, console, or even Perl. What I cared about is their ability to think about requirements and explain their design. I can teach people to code, but not to think.
http://nuget.org/packages/Nancy.OData/
Hmm cool thanks!
&gt;Still no answer to the question of WHY are you TRYING to change though - from the OP : It is hard to say, but those closest to it feel like it is suboptimal. For one thing, nobody finished it last time it was used. :-/ There were partial solutions, but never complete solution out of the pool of applicants. We don't think it is too hard, at all, so it must be unclear or too time consuming for the average applicant. http://www.reddit.com/r/dotnet/comments/1f7gdg/anyone_have_ideas_for_a_small_project_for/ca85u1f gives me some ideas. 
I would think if you set someone up with VS and say write me a simple mvc page that performs CRUD operations they should be able to do it. If it is timed then they should be able to make an average progress (even if they don't finish).
&gt;the recommended tech seems to change every year or so. It used to be MVC then Razor then MVC3 then whatever it is these days It went MVC1 -&gt; MVC2 -&gt; MVC3 (which added razor) -&gt; MVC4. It's simply linear progression/improvement. &gt;It's tried and tested and in 99.9% of situations it does the job perfectly well Argument from ignorance. &gt;I've built a few projects lately that have HAD to be webforms based because we agreed that an MVC / MVVM scenario would've caused a nightmare on the server for one reason or another. How exactly would it have caused a nightmare on the server?
&gt;If you're currently a webforms shop and you don't do MVC, you don't have the money to hire someone who knows MVC That's a case where web forms was a better decision, not a better solution. And it's not like MVC is hard to learn, especially in 4 years.
If you ever have a chance to see Scott speak at a conference or lecture, please do so. He's one of the most intelligent, enthusiastic, and funniest presenters in our field.
For those wondering - copy/paste a few ᗤ, ᗧ (pacman) and ᗣ (ghost) characters, which are actually [Canadian aboriginal letters](http://en.wikipedia.org/wiki/Carrier_syllabics), as well as ◯ (pills) which is Unicode char "Large white circle". Then enable white space display (Ctrl+R, Ctrl+W or Edit &gt;&gt; Advanced &gt;&gt; View White Space), and use spaces instead of tabs.
I think it's safe to say that us .net developers have a nerd-crush on Hanselman.
The class CustomerViewMode (sic) in the post is not a typical model object but rather a ViewModel, and wrapping a ViewModel in another ViewModel is a giant code smell. So while it is "possible", it certainly isn't recommended. The problem with this question is that there is no "right" answer. Developers who work on really simple systems (e.g. the ones for which LightSwitch is a serious consideration) can get away with exposing the domain model out directly to the view, and they end up writing far less code. View related concerns will inevitably leak into the domain model, but then again, every line of code written is another line to be maintained. In the case of startups, where your cost of capital is 50% and every dollar spent erodes your percentage of the company, just doing enough to make it work is ideal. 
&gt; The class CustomerViewMode (sic) in the post is not a typical model object but rather a ViewModel Uh, yea. The class that immediately follows the text "And here is a typical ViewModel that would go with it:" is in fact intended to be a view-model. 
So now we are right back to "webforms is code for 'you will be working on legacy stuff.'"
Might be able to just watch a successful run with something like [Windows Sysinternals Process Monitor](http://technet.microsoft.com/en-us/sysinternals/bb896645) and tease it out from there.
Thanks for the suggestion but unfortunately I have already tried that. Process Monitor doesn't show me what is called when the .application file is loaded. Only shows me what is currently running. It all happens so fast I cannot get a capture of what EXEs are called. I was able to look at this... http://msdn.microsoft.com/en-us/library/aa719097(v=vs.71).aspx ... and I got that when ClickOnce is called, rundll32.exe and dfsvc.exe are called. They are white listed. Also, the main application that ClickOnce runs in the end is white listed, and on its own it can run. Edit: Also AppLaunch.exe is whitelisted as well.
There is a school of thought that every model must be "wrapped" in a view-model. Under that philosophy you never, ever directly data bind to a model. There is another school of thought that you data bind to whatever you damn well feel like. View-models are just models that hold data relevant only to the view like which item is currently selected. 
It's going to be somewhere under the C:\Windows\Microsoft.NET\ folder I believe. We had a nasty time with this too but the policy got set up years ago and I no longer remember the details. I'll ask our AD admin about but I bet he's not going to remember either and he's probably too busy to entertain me with digging up the answer.
Yea .NET is a nasty beat conjured from MS. I ran the following command when building my whitelist *C:\Windows\Microsoft.NET\ dir /s *.exe &gt; output.txt* to gather all the EXEs in that directory and subs and white listed those.
It might be a dll that actually handles the .application file. Unfortunately I don't really handle any of this admin stuff so I'm not real clear on what's going on under the covers of ClickOnce. It's an opaque son of a bitch.
&gt; If you are just using WPF and data-binding, why do you need a ViewModel? I'm glad you asked. Reasons to use a View-Model include... 1. To store data about the view such as which model is selected or which toolbars are visible. That's why its called a "view model", it is the view's data model. 2. To store ICommands, especially those that call out to external services so the models can remain "pure". For example, load and save. 3. To hold a reference to the aforementioned models that were returned from the service calls. 4. To store business logic that is too specific to be put in the model. Especially true when the model itself is designed to be reusable. 5. To wrap the model if and only if the model's structure doesn't lend itself to being directly data bound. Not all views need view-models. For example, and edit dialog with a cancel button usually just needs a model that supports the IEditableObject interface. (That's the one with BeginEdit, EndEdit, and CancelEdit.) But if your model isn't designed with that in mind, then you can use a view-model to simulate that functionality. That said, most of your important views will benefit from them. ***** The problem I've been seeing for the last couple of years is a lot of people thinking that each and every model has to be wrapped in a view-model, even when that wrapper adds nothing but indirection. In the best case, their "model" as a place to put their member variables. Simple merging the model into the view-model fixes the problem without actually changing the effective public API. (That stupid MSDN Magazine article by Josh Smith does that.) The harder case is when the models were actually created using domain driven design. By that I mean they are actual domain objects with encapsulated functionality such as calculated properties, validation, etc. When that happens I usually see tons of memory leaks and synchronization issues caused by the view-model trying to listen to events on the model. Collections are particularly problematic. For example, if you call ObservableCollection.Clear you don't get the list of removed items in the CollectionChanged event. 
I found this old ass article but it might lead you somewhere: http://msdn.microsoft.com/en-us/library/aa719097(v=vs.71).aspx From the article: "The ".application" extension is mapped to the ClickOnce loader called "dfsvc.exe." " It also mentions AppLaunch.exe
You sure it is blocked by group policy and not Cas? What error you getting? Best of my knowledge secondary exe aren't involved in click one
The best way for you to learn is to participate in an Open Source project. For example the OWASP WebGoat .Net project could do with some help Take a look at https://www.owasp.org/index.php/Category:OWASP_WebGoat.NET with the latest version of the source code being at https://github.com/OWASP/WebGoat.NET/tree/VS_2010 and a mailing list at https://groups.google.com/a/owasp.org/d/forum/webgoat-.net This not only will give you a way to learn new things, it will also give teach you about Web Application Security (which is a great skill to have) 
Well learning the whole .Net framework may take a while, I've been using it heavily for 10 years now, and all I know is how little I really know it. Are you wanting to focus on Web or Applications or anything in particular? There are some great tutorials on some of the newer (and better) Asp.Net technologies on the asp.net site, try some of the MVC 4 Razor ones.
I agree. Learn web dev with the MVC4 tutorials and use c#. That'll show you enough to make you dangerous.
Some of it is rather dated. Some of it is more in line with trivia. Some of it will help suss out if someone knows their stuff. Of course, that's all my bias and my biases aren't universal or necessarily helpful.
I'd say I could competently answer (or argue why it's a dumb question) about 70% of those with most of my shortcomings in ASP section. I feel this list is not very generic though. It's more of list of things that people who have done a lot of work with backend service infrastructure would be familiar with (which I happen to be) and even then, some of it is so esoteric that I would still want to check with google to make sure the best practices haven't changed in the last 5 minutes. I'd hardly say this is essential to identifying a great developer. I suppose it's a list that fit his agenda for hiring the specific kind of developer he was looking for. And as others have mentioned, it's a little dated now.
I am also self-taught. Looking past the dating of the info, I would also say that there are likely few developers who know ALL of it. But, given certain areas, the list might be considered representative of broad categories, within which one might be expected to know the bulk of what is there, or at least be familiar with the concepts. Good analogy about learning an instrument without reading music/theory. That's how I feel, most of the time. 
In general I disagree with using trivia to screen during interviews. I might use a few of these just to probe at some deeper knowledge but I wouldn't expect anyone to know all or most of them. When I develop I typically have access to a team and the internet, so it isn't worth my time to memorize every nook and cranny of the language. I'd rather focus on memorizing business logic/rules/structures for my particular employer. 
I don't think anyone would be expected to get 100%. It's more for gauging where someone's skill level is. I had to do a technical interview a couple of weeks ago. The test wasn't (thankfully) as long as this one but was very similar. There were still a couple of things I didn't get. And I've been a .Net developer since 2002. Since you're all wondering; I did get the job.
A lot of those questions are really subjective or even downright unanswerable. Strong vs weak typing? We could spend days just arguing about the definitions of those words and still not come to a consensus. 
My suggestion -- from very recent experience -- would be to not focus on either .Net or C# first. The first thing I would focus on would be setting up your development environment and getting aquainted with the model of Visual Studio that you want to work with, along with the model of the database that you want to work with (I would suggest that you use Visual Studio Express 2010 and SQL Server Express 2008 r2 because those two are common currently and very well documented at this point so you'd get stuck on the least number of errors). There's a lot involved in just those aspects and if you want to learn in a hurry you probably want to cut down the number of variables. Find a tidy, organized place to work that is free of all your normal distractions like TV, Netflix, phone, etc... I didn't learn very well at home until I completely cleaned out my home office and just left a desk, since most of my house is cluttered. Another thing I would suggest is that you set up your programming environment in a "fail safe" way. I began a class in C#/.Net and had to re-image my laptop (luckily it was a work laptop and we had good images I easily could load from PXE boot) twice because of malware (just from looking at Reddit -- and other -- links on programming -- the only thing I did outside of programming on the machine). And that was on a fully updated Windows 7 laptop with updated McAfee, etc... I finally went out and bought VMWare Workstation for $200 (you might be able to use something like Virtualbox also), put minimal Ubuntu server on it and updated that, loaded VMWare on that and updated again and then put the Windows 7 image on top of that, ran updates and installed all the software I needed ( the express editions of SQL Server and Visual Studio along with SQL Server Management Studio -- which I find easier to work with databases then from Visual Studio -- and a few other things) ran updates again and then I backed that image up to a good quality Western Digital external drive. I now have two Ubuntu virtual machines and two Windows 7 virtual machines for redundancy. I run an Ubuntu virtual machine at the same time as I program on a Windows 7 virtual machine and use the Ubuntu machine for most of the research I do online and any casual browsing. I also take snapshots of the images every time I install more software or do something that I consider important or difficult and I back up my Visual Studio website directories to the USB drive also. If I get malware now, I can just revert back to the last snapshot, Visual Studio websites archive from the USB drive, and be good to go in under five minutes. If my disk drive dies, I can install a new one, put minimal Ubuntu and VMWare back on it, import the image and Visual Studio websites archive from the USB drive and be good to go in under an hour. For me, this was all worth it to be able to do my studying and development with the fewest possible interruptions. Once your environment is set up, then I would begin learning basic .Net crud application development. The book I began with is Microsoft's Web Applications Development with Microsoft .Net Framework 4 (Tony Northrup and Mike Snell). This book focuses on .Net (with examples in VB.Net and C#.Net) and mostly on Web Forms with a chapter devoted to MVC. It's also an official comprehensive study book for the MCTS Exam 70-515. There may be more suitable books for you out there, but this is the one that came with my class and I'm planning on taking the exam after a bit more study. I took a four month class because I found it difficult to work in a busy job and to be able to focus. I used to work with VB6, ASP and stuff like Oracle Forms a few years ago for basic crud applications and reporting but 95% of what I did was procedural programming and the OOP stuff I did was mostly hacked from templates our lead programmer developed and made us use for consistency. I found it difficult to get through the seeming multiplicity of styles of syntax that people used in OOP from the verbose to the concise. So I took a local community college class (that was created through the state's workforce development agency to help unemployed programmers) that was taught by a coworker from the IT department and that was very helpful. Now I'm also using a book called "Head First C#" to learn C# in more depth and I'm building some basic Web Forms websites. I'm not looking at MVC at all yet and won't be until it's more prevalent in my area. I apologize if my writing sounds imperative, I'm in a hurry at work but wanted to share my experience and also to make the post applicable to anyone in a similar situation who might read this.
&gt; Strong vs weak typing? We could spend days just arguing about the definitions of those words and still not come to a consensus. Well, there a pros and cons with the concepts, I think your answer is good, because you know what it's all about, right?
Aren't a lot of them pretty hands-on? Out of interest, what terms didn't you understand?
I think a bigger tell is if someone lies or refuses to admit they don't know. That is more dangerous then ignorance.
and this is why I don't ever want a "job" again.
That reminds me of my experience trying to find a developer to hire. Back in 2010 I asked this question, &gt; I've been interviewing a lot of .NET programmers lately and I haven't met one that knows what IDisposable is or what it is used for. Is it really unreasonable to expect someone with 4-6 years experience to know that? http://stackoverflow.com/questions/2852769/interview-questions-is-idisposable-hard-to-understand
I should update by saying that I'm working on windows 8 with visual studio 2012 and SQL server 2010. I've been told MVC is what I should be learning by my brother, who is very successful, so I'm inclined to believe him.
&gt; no, those are specific terms meaning (basically)- keeps hold of a reference to the object or has a reference but doesn't prevent GC from collecting it Did you respond to the wrong comment? That's not at all what a type system and the terms strongly/weakly typed mean at all. [Info](http://en.wikipedia.org/wiki/Type_system) and [more info](http://en.wikipedia.org/wiki/Strong_and_weak_typing).
I thought the world had settled on the idea that "strong" means "a type system I like" and "weak" means "a type system I dislike."
these are a bit outdated.
I think there are times I pick up a book, but mostly that is to get at the nuts and bolts. Like EF4, I have Julie Lerman's O'Reilly book on it. There is so much under the hood in there, it's hard to find the practical knowledge. I start reading some of it and realize it's to close to the metal for what I'm trying to do at the moment. Then when I get a good feel for how it works, and how I can use it, I never go back to peel off a deeper layer cause I can now do 99% of the things I need it to do. 
&gt; How many processes can listen on a single TCP/IP port? That's trivia. &gt; Explain the importance and use of each component of this string: Foo.Bar, Version=2.0.205.0, Culture=neutral, PublicKeyToken=593777ae2d274679d This is a full assembly name. Scott at the time (IIRC) was doing a lot of reflection style work and would need to know these. Many people can go for a long time without having to pick a part the details of this. However, again this is trivial. &gt; Why are out parameters a bad idea in .NET? Are they? IMO this is like a question on religion. I like out params when they make sense. 
well i feel slightly better about his list. I have added assemblies before, but couldn't tell you about the publictokenkey. I don't like out parameters, I think it goes against what I would consider 'clean code'. I don't use them, but I've been exposed to people that think they are better than returning an object. Thanks for the info.
If you are interested, [CLR via C#](http://www.amazon.com/CLR-via-C-Developer-Reference/dp/0735667454/) will provide one with a metric fuck-ton of trivia on how it really works. I read the 2nd edition about 7+ years ago, but most of the really trivial stuff fell out of my head. However, a lot of that knowledge isn't needed to actually build a working product. One reason I like out params is the patterns similiar to bool TryParse(string text, out T value). This way a single if statement can shorten code up considerably if I need to write other conditions limiting the value to perform default or special case logic. The more I can reduce boilerplate/noisy code the better IMO.
jesus fucking christ. these are ridiculous trivia questions. i despise them.
No worries, figured something like that had happened. 
The problem is the software industry. **DON'T FALL IN THE TRAP PEOPLE**
I was just on a project to setup a DNN cms at work. I feel sorry for you. I found DNN horrible and the documentation out there isn't great. Content staging is broken, you basically need to roll out your own xcopy and database compare job. The workflow is horrible as well. Not to mention it's webforms. It isn't open source unless you pay for the enterprise version. But to answer your question. There are a few videos to get started. i think its called beginning DNN module development or something along those lines. I'd be interested if anyone knows of any other better .net CMS, Orchid looks interesting to me, it's open source and MVC, seems to be getting popular.
There are several books out for DNN. Thats how I started, but its been 5 years or so since I've touched DNN so I couldn't recommend a particular book. Find a bookstore and try reading through a few while you're there. If you're looking for work, you might want to check a few potential employers and see what versions of DNN they are interested in and focus on those (sometimes the newest isn't what is being used).
&gt;dotnetnuke.com forums are not too good. questions dont get answered. evey posdt is moderated. the dnn subreddit is dead. That's a major clue. It's a dead product with zero community. Try to convince project leads that it'd be better to start development on any other CMS. See those being offered on Azure. 
I have to agree with the other comments, I used DNN for my first client site as I have a .NET background. I have since moved to Umbraco which is also open source .NET based and is just a dream to work with. There is a cost to sign up to their video series but I've not needed that yet - there are module dev tutorials out on the internet for it. 
OMFG.. all the comments have me practically pissing myself in fear.
Abandon project project now! Move to Vermont take up organic farming and never touch a computer again. DNN will leaving you looking a feeling like a fool. 
I don't think it's actually that bad. We've been using it at my company for a while now and it's worked well for us. I think they've improved a lot in the last few major versions. They do have bad documentation... And that leads to a lot of usage errors. For example, nobody ever recommends running more than one site in a single install... But people do it anyway because dnn supports it... The reason it's not recommended is that an error in one site would take down all of the sites in the one install... Which is exactly what you're describing. 
To clarify something here... It is definitely open source. They have a professional edition that adds some features - those additional features are closed source no different than many other dnn modules that are privately developed 
DotNetNuke is not as bad as people here are making it sound. It definitely isn't great on documentation, but few open source projects are. The framework itself is really flexible - it's basically exactly like developing in normal asp.net, you just have the framework you can use when you want. A lot of the complaints you hear boil down to bad documentation, which leads to usage errors or developers reinventing some wheel or fighting a battle that has an easy, but hard to find solution. With that said, I think dnn spent a long time trying to be the "easy" cms... One your grandma could install and use... So there is a lot in it by default... Which pleases some customers looking for an easy solution, but annoys the types of people you find on reddit because they want to build and customize things more. Like many things, much depends on what you are going for. Feel free to PM me if you have any specific questions. 
Thanks for that clarification, we were actually going to upgrade to the professional to get the source code. But based on what you are saying those additional features are something we may want to take advantage of and have the source code. Can you point me to where those are listed?
Yeah... It's a tough call. Professional is about 3,500 a year too... So it's real money. They have a list of professional edition features on the site, but it's misleading because many of them are in the community edition as well. I'll try to list the big ones... It's basically a better workflow for the html module (which you may or may not want), some better permissions options, module and page caching, a document management module, an e commerce module, a telerik developer license, and product indemnification... There's a bit more, but that's what comes to mind. Most of the stuff in pro can be found in other third party modules... But the dnn modules are pretty good... Which is a big argument in favor of pro. 
Dump it and pick up [Orchard](http://orchard.codeplex.com). I have built a product and my day job around it, and it's bloody fantastic. If you don't like the look of Orchard and want something a bit more established, then maybe look at Umbraco.
I also recommend Umbraco.
If you need any help PM me, I've used it for years (much to my chagrin) but it's a pretty solid CMS for what I need it for as a dev (getting a page to display my content with a decent user management and CMS wrapper). The documentation is shit, I basically learn how to do this by searching through the object browser in VS. 
It can be a steep learning curve at times. I'm dev through and through so that codiness didn't bother me too much when it came to doing the more designy side of things. Some of the newer functionality like projections, rules, workflows etc is amazing and the amount of coding required to get a basic site up and running is getting smaller. I hope you revisit Orchard again for another project :)
I must admit that I know maybe 20-30% of these answers. Part of the problem of never having discovered an answer to these are posts like this which pose a question and never give an answer. I simply do not have the desire to discover what boxing is because my head is already full of jargon. When I did look it up I have discovered that I have implemented boxing/unboxing many times having never learned what the terminology is. That's because it probably never came up in conversation with anyone who didn't understand what I meant when I said 'converting'. 
For mostly all topics posted, there is video training available at pluralsight.net. This is my favourite training resource. They have many presenters and it's pretty cheap. You could buy it yourself or see if your company would pay for it.
That... pretty much sums up my experience learning how to skin DNN.
I've written a number of modules and skins and haven't run into any problems like that. Also, what's so hard about skinning? You're just basically making a normal .net page... There's not much to it. 
Orchard has grown quite substantially since its original release and if you have any experience with ASP.NET MVC, it should help make the learning curve a bit more tolerable (as it can be rough if you don't). I have used it for a variety of projects and I would very highly recommend it to anyone looking for a .NET oriented CMS. If you run into any issues within it, it has a reasonably strong and helpful community that can deal with most issues as well.
Hosting for the most part. WPF apps can be run anywhere in a connected or disconnected environment where as an internal web app must be hosted internally or you need to pay for external hosting costs as well as building in security. Personally I'd say for a business type application such as the one you're talking about, we web app is absolutely the way to go.
&gt;Why would someone build a WPF app when most of the same functionality can be created in a web app? Because it can't. Not even close. WPF is a flawed, unloved barstard ginger child of Microsoft. It is still better than any mixture of JQuery/Nockout/SignalR/Rx I've found, or even heard about. WPF also I think has a learning asymptote, rather than a curve. It suffers from false friend syndrome, people think they can forget about things like performance, then next thing they know they have a screen with 12,000 visual elements and wonder why it runs so slowly. I'll say that wearing a .Net had many people find a bit tricky coming from a background such as PHP, it is rather anaemic to the styles of .Net. You would probably find it a lot easier to make it as a web app, because that way you'll only be learning a new set of frameworks and one language. If going for WPF/Silverlight it's going to be a bit harder. If you know that you can happily have all the HTML control to provide the level of functionality the client wants, then definitely go for HTML, WPF is dead, well that's a lie, its on life support. Check out some of the videos on Asp.Net, look at things like Entity Framework and Razor MVC4. Entity Framework is quite good, but a bit of a pig of technology to get to grips with if you try to use it like you would a standard 3NMF database.
Web applications have gotten to be so rich that it's easy to forget why we ever used desktop apps in the first place, but if you need proof that native apps still have a place in the world, then just look at the Apple app store and you'll get all the proof you need right there. Research WPF and what it can do in desktop apps and you'll find all sorts of capabilities that a web app could only dream of without significant plugin support. That said, WPF may not be what you want at all. You mentioned this is an association with limited resources. Under those circumstances, wouldn't it make sense to move to an off the shelf product? I mean, I don't mean to steal your fun, but really it's probably the most responsible use of your resources. As for specific recommendations, I don't have any. You could start with Microsoft's own excellent CRM product, but I suspect that may be too much product for your needs. On the other hand, it would most certainly keep up with your needs. Apart from that, I would have to do a product search and find something suitable within the constraints you have. There's a lot we don't know about your situation here, so even recommending rewriting it in one technology vs. another is kind of premature.
Thanks for the reply! That's a lot of good info. I got ahead of myself saying that a web app could have most of the functionality of a WPF one. I was thinking in terms of what we need; which is kinda of a Salesforce type application. In which case HTML...like you said, seems to be the good choice. So WPF is dying? What are the new Windows Apps being built with? 
WPF is dead. Don't even bother. 
&gt;So WPF is dying? What are the new Windows Apps being built with? Good question! Microsoft don't appear to realise I've had virtually no one even inquire about making a MUI application. They are neglecting their core business. WinForms has been on maintenance rather than active development for almost a decade now, and WPF has completely shifted focus. Microsoft has had a lot of turmoil, XAML is owned by the windows team, they historically mistrust the .Net team. XAML is of course used in MUI now, but its a lot less powerful. If someone asked me to build a rich client application, I would use WPF, rather than say Qt or even HTML. But I wouldn't say its got a good future. About 3 years ago I was able to charge a lot for consultancy on WPF, now I don't see much future left in it, hell tonight I've been playing around with more design patterns for HTML. A lot of the perceived problems with WPF and silverlight were voiced by people who never used the technologies. But they were very useful and popular tools in the LOB market (line of business) sadly, Microsoft doesn't care about markets it owns, I mean LOB stuff is sewn up Microsoft, they have no competition, no need to innovate. They have gone off chasing the tablets and this 'HTML5' whatever that might be.
Man, I'd love to contradict you but you're desperately spot on...
Build Conference is going to be interesting.
This might be a good list of questions. But I'm really sick and tired of bloggers advertising their articles as something a "great programmer needs to know." The whole notion behind it is to play on everyone's insecurities about not being a great programmer. 
&gt;except that the majority of .NET developers still don't know the answers. Which suggests that in a practical sense they can survive just fine without knowing the answers to those questions! OK, OK, sure.. everyone's code can always get better. But I think there's an important difference between a normal human being who looks at all the material one is expected to know and develops a strategy to address it, and a person who has both photographic memory and obsessive-compulsive disorder who thinks it makes sense to memorize *everything*.
What annoys the fuck out of me is that some retard is going to take this list and use it to screen people in an interview. You know, 'cause that's how you tell a bad programmer from a great one - by how well they memorize stuff that could arguably qualify as obtuse trivia.
Looking at the Wikipedia article on Dunning-Kruger, it states: &gt;...studies suggesting that ignorance of standards of performance is behind a great deal of incompetence. I think there's a tremendous amount of misinformation on what should be expected of programmers. And much of this is exacerbated by annoying blogs that proclaim "only great programmers know these items." There's a missing set of standards for performance in our industry. Perhaps we programmers were unionized this would be less the case. But that's never going to happen. Largely because employers have decided to downsize rather than re-train their workers, we now have a pool of workers who are constantly chasing what they believe is the newest, latest and most lucrative set of tools. So much so that now *employers* cannot hire people if the company is using older technology. How's that for irony? It would be nice if there were realistic (not hyped) standards of performance for programmers that everyone could agree to. But instead we have this blogosphere that is always taking advantage of peoples' insecurity (the Dunning-Kruger effect as it works on *competent* people) about being good programmers.
Hurmm... but isn't Windows Presentation Foundation (WPF) basically dead now?
I'm the CTO, so I don't have to justify my choices to anyone. :) I don't worry about optimization until I find a bottleneck. You do need to understand what LINQ is doing behind the scenes, or you can run into trouble. However, it seems like most of my time with LINQ is not with databases, it is with data structures. 
As eluded to in other comments, what is it that your company needs that you can't get in an off the shelf product? It sounds like you may be trying to solve a programming problem and not the root business problem.
Is this custom CRM a core piece of your competitive advantage? No? Buy something off the shelf and focus on what your business is good at.
You can still build wpf applications for windows 8, they just can't go in the store as all store apps have to work on both x86 and ARM processors. Most people don't want to use the store anyway. I wouldn't say wpf is going anywhere soon
That depends on what you mean by dead - it's not cutting edge but people are still using and hiring for it. Also WPF represents a fairly major shift in how you (as a windows app developer) think about building UI applications so I think it's useful to research even if you don't learn how to use it.
jon skeet c# in depth Would be my take for c# is awesome book I have read all the editions and loved them
Why not do both? WPF which talks to web services for your application? Then you have the benefit later on, of writing a web-based front end also, and your service-based system is then accessible to other applications as well.
Thanks for commenting. Was that not the question? I didn't realize this was a web vs native app question. And yes, I was thinking silverlight. 
I'm with you on native apps. That's why my original idea was to build a WPF app for the staff to use combined with our customer facing ASP.NET MVC app/website. From what I've researched it seemed like WPF could be a good solution because of it's ability to adapt as our business changes. The modular aspect of it, rather the modularity(is that a word?) of an app built using MVVM(Prism, Lite MVVM, etc), where we can add and remove modules without needing to rebuild or tear down the entire app. Seeing some examples of amazing WPF desktop apps really had me excited. We've went with a few off the shelf products in the last 5-6 years and one failed miserably and the other is not fulfilling our needs...and we're paying thousands of dollars a month for it. And I really don't think it's the fault of the two solutions we've tried. I think it's our lack of due diligence and ignorance to what we were getting ourselves into. Our issue/problem is we have a unique business model that really doesn't fit into CRM or so it seems without heavy customization. We've tried to make it work but in the end the staff is frustrated with all the difference hoops they need to jump thru to get their jobs done. The quick of what we're looking to have is a system where we can track all of our members interactions with our assoc: web visits, webinar views, resource downloads, meeting attendance(and the sessions they've attended), . We also have a certification program so we'll need to track where a member is at with their certification and pull in data from an LMS and assessment tools. Then there's the meeting logistics managment: venues, rooms at the venues, session room layout, attendance tracking, scheduling. And also pulling in email marketing info. With all those different pieces it looked like the modular design and native app UI &amp; performance that WPF and .NET would be our enterprise solution. I'm a bit overwhelmed. And I thank you and appreciate your input &amp; feedback.
You might xpost in /r/jacksonville
Thanks buddy!
Is it a .Net shop? If it isn't and you're a PHP guy already (and you don't take captainjeanlucpicard's suggestion to get an off-the-shelf product if this kind of development isn't really core to your business), why not PHP/Mysql or Postgresql?
Sounds like a challenge. Well, there are a number of customizable xRM products out there, so maybe those would help as it's more functionality than I would care to build on my own without enough resources. Either way though, good luck!
my comment was pretty ambiguous, but I share the same opinion for the most part. .NET is huge, and it's good to know the ins and outs of the portions of the framework relevant to your specific work, but a lot of these are overkill for a typical .NET developer position.
Sounds interesting and right up my skill-set alley. I have 13 years application development experience. Unfortunately, the $40/hr is too low. 
Hey robodale, I'm sending you a PM asking for some more info
This is exactly the skill set that I possess, $40 is a bit low, but perhaps they would be willing to allow telecommuting, as I am just north of Nashville, TN 
Hey, Thanks you replying Depending on your skill and experience, the rate may be negotiable. I am not sure about the remote work that you would be wanting to pursue, but that may be an option. Please give us your resume and your contact info at: http://isgf.com/job/net-developer-c-wcf-sql/ and one of our Recruiting Managers will contact you to discuss the position with you. Thanks for your time!
wow $40/hour is low. I expected it to be about double for a contract hourly position.
For the record, contract to hire should be hourly over the salary rate in order to compensate for the risk involved. 
They are just looking for contractors and without a firm offer of permanent employment that possibility has nothing to do with the hourly rate charged by the contractor. Someone would be foolish to take a lower rate based on a promise of ..nothing.
Will you need alerts? That is to say, a way to immediately notify the user of events in the company? Will you need to interface with custom hardware? Will you need to support multiple monitors? Will you need to interface with legacy applications? Keep asking questions like this until the answer is yes or you run out of ideas.
FICA and everything else must be accounted for also
I had a manager once with a 50 page packet of questions (plus answers) like these he had compiled from the internet. Even though he himself didn't know the answer to 95% of them, he would use the packet for phone interviews and read the printed answer word-for-word for each question the candidate didn't get. Most of the questions he would pick to ask were absolutely useless in judging whether the person could code or not and not surprisingly my team had a lot of turnover. Listening to him conduct the phone interviews (I sat nearby) was absolutely infuriating.
why does everyone insist re-inviting the wheel?
I always worry when a programmer says something should 'never' be something. 
I disagree with the author. You shouldn't instantiate a collection or anything else "just because it shouldn't be null". Comparing item with null is pretty much the cheapest operation there is, while collection init is not. And if you really want to implement never-null "pattern", then the correct way would be using Lazy&lt;&gt;: private readonly Lazy&lt;List&lt;string&gt;&gt; _someCollection = new Lazy&lt;List&lt;string&gt;&gt;(() =&gt; new List&lt;string&gt;()); public List&lt;string&gt; SomeCollection { get { return _someCollection.Value; } }
 public static void @foreach&lt;T&gt;(this IEnumerable&lt;T&gt; collection, Action&lt;T&gt; body) { if (collection == null) return; foreach (T item in collection) body(item); return; } 
At the same time, a pretty common usage pattern is: for each(item in repo.getItems()) { dostuff } While the null check isn't computationally expensive, it definitely makes the code harder to read. While I wouldn't go so far as to have a hard and fast rule, by convention, I'd argue API methods meant for consumption by others should nearly always return non-null values.
I would say the consistency is the main thing to follow. If you create an API, either always have a non-null (and document this!!!) property or make it clear that every property and method result should be checked for null. It is pretty common for the repositories to return null, if the value isn't found. E.g. using (var entities = new MyEntities()) { return entities.Items.FirstOrDefault(item =&gt; item.Id == id); } which would return null if the item with a matching Id is not found. On the other hand, repository methods returning collections usually return non-null: return entities.Items.Where(item =&gt; item.Name.Contains("foo")).ToList(); In my own case, I almost compulsively check for possible nulls (partially thanks to r#), usually because if you are using repositories/factories/whatnot coded by someone else - and often using IoC/DI - it is better to be safe than sorry. 
That looks like a premature optimization to me. Well expect it might not even be an optimization because you are paying the price for allocating the Lazy object AND the pointer indirection each time you read from the property. You are also making your GC pathways longer, which adds its own cost. 
&gt; public IList&lt;string&gt; Phones { get; set; } Bad code monkey, no cookie for you. Collection properties should never have setters. That causes a lot of unnecessary problems. 
Congratulations, you've just make your for-each loop a lot slower. Don't you feel proud. P.S. And I just love the "if null then return" pattern. It makes debugging so much more interesting when `list.Foreach`no longer implies that `list` isn't null.
That reminds me of one is the stupid decisions made in .NET's Code Contracts. They don't have the concept of a NotNull attribute on return types so you can't use reflection to know if a method or property can return a null. That in turn means tools like R# can't tell you the right thing.
I really feel we don't need more of these kinds of tools and instead need more refinements to tools we have, and more code-oriented features like better runtime state visualization, F# support and more static (and other kinds of) code analysis. The graph-drawing tools for module dependencies are mature enough, whereas theorem proving on my code base is still pretty weak, and runtime state exploration is almost non-existent.
&gt; Congratulations, you've just make your for-each loop a lot slower. Don't you feel proud. Well, that depends on the compiler doesn't it. A decent compiler would inline the call to body(). I don't know enough about the C# compiler to say whether it does so or not. &gt; P.S. And I just love the "if null then return" pattern. It makes debugging so much more interesting when list.Foreachno longer implies that list isn't null. I've seen the alternative: If SomeCondition Then If AnotherCondition Then If SomeOtherConditionThatOverlapsTheFirstTwo Then ... 12 more levels of nesting Call ActuallyDoSomething End If x 12 End If End If End If No thanks.
Oh. I think I misread your comment. &gt; P.S. And I just love the "if null then return" pattern. It makes debugging so much more interesting when list.Foreachno longer implies that list isn't null. Just set your editor to highlight extensions in a different color.
No, the alternative is a Argument Null Exception because the nulls shouldn't have been there in the first place.
I use most features of ReSharper every day (including custom templates). I'm very glad that what is there is there. There could be more, however. I use NDepend for module dependency graphs and I'd rather not have to keep paying for tools that overlap. NDepend does way more than just module dependency graphs and will do things ReSharper never will, but ReSharper has static analysis than no other tool has. I get uneasy when tool vendors try to move sideways into other spaces since that means the reason I bought the tool becomes diluted.
I got your point. Static code analysis has always been and will always be ReSharper's greatest asset. It hasn't been only about this from the start though, with all the navigation features, refactorings, unit testing, internationalization and more. We could have broken all these features into separate products and sold them separately but we have chosen the other path. While we're strengthening the code analysis part, it just isn't the only thing there is.
Well, I'm happy they have all those ancillary features. I use them frequently and have a hard time when they are not there. What I'm saying is they are complete. What is not complete is code analysis.
Can you define what has to be done to make you feel that code analysis is complete?
Well, you've got me there.
Look into EF "code first" development. I think you will like it.
The problem isn't the extension, its the null. Whenever I see a function like that I can't tell if its legitimate or just a hack because the dev didn't want to fix a bug or just plain sloppiness.
Care to elaborate on your dislike of mvvmlite? I've been using it for a fairly large wpf application without any real problems. What patterns does it promote that are considered bad practice?
I've worked with two large Silverlight applications for the medical community and both experienced these problems to varying degrees. **View model locators** These are essentially globals that allow any part of the application access any other part. They aren't needed in small applications, but created but created by default. For large applications they make understanding how different models depend on each other incredibly difficult. It is also questionable for testing, as again they are essentially globals. You are better off creating normal object graphs that start at your main/root view model and go from there. If you need to access a specific VM from a control or view that isn't part of its data context you can always put it in the Resources dictionary. **Delegate Command** Even if you are using the overload that doesn't use CanExecuteChanged events, it still registers an delegate in the event handler. Not only is this wasteful, it leads to the next problem. **EventToCommand** First and foremost, this is a memory leak when combined with their delegate command. No ifs, ands, or buts about it. When you use this is permabinds the control to the view-model. So when the control is unloaded before the view model, its memory remains in use. It also encourages you to put event handlers in view-models instead of the control's code behind. View models are supposed to hold view data. They aren't supposed to deal with specific controls and their handlers. **Messaging** Last time I looked, the documentation outright lies as this leaks memory all over the place. You have to be incredibly careful to unregister for messages before your objects go out of scope. If you don't they are permabound to the global messaging system. And since controls, and thus view-models, don't have a destruction lifecycle (i.e. no Dispose method) there isn't a good place to put your unregister logic. 
What is the use case for these helpers? You can accomplish the same using Linq2Sql + dmbl or Linq2Entity and EF
I always thought that the notion of operator overloading was something best left to people who might write math-related libraries. It almost seems like a feature that's there "because we can". I just don't see any practical use for it in your run of the mill business app.
Which ones are you referring to?
Presumably under the **Effective C#** header at the bottom of the page. They mostly seem to be micro-optimisations which are going to have negligible impact in most cases. I just tested the parameter optimisation for instance - over repeated trials of 10 million calls the proposed optimisation makes no discernable difference.
Ergh. Is this just a nasty troll? I mean seriously, I gave up so quickly on reading this, when he overrides equality, whilst leaving hashcode to be default. This is the opposite of professional..... Not to mention events in a hashtable. ERGH. Making your own operators too? Implicit casting? ARGH. I could walk round the office with my cock hanging out if I wanted too, but I doubt it would be a good idea, and I doubt my coworkers would thank me, but it might be slightly more acceptable than overloading the bool operator to give it some obscure meaning, people don't normally think of an object being 'true' if it has some strange property. Not to mention the lack of an eplison in there too. Please someone tell me this is just a troll?
I know I said I'd given up on this, but after reading this post, I had to know, in the most masocistic way possible. Of course the guy is wrong. Just did a quick benchmark of BitShifting in a standard release console app, singlethreaded. * Version 1 13753 ticks. * Version 2 19083 ticks. Guess which one was 'optomised' That's right folks, the one that is almost twice as slow. Turns out two shifts and an add are slower than one IL instruction. Who would have ever thought that! **So boys and girls, if you want your code to go faster, ignore this blog** (on a side note, if your just dividing by two, or a single bit shift operation, there is no noticable speed difference....) * Version 1 8319 ticks. * Version 2 8310 ticks. If the guy who wrote this blog post works for you, fire him. Harsh as that might sound people like this are a cancer, they don't understand how little they know, they grasp one concept without any thought of the other. You know what, on my poxy 8 bit microcontroller I had to do this. Why would a compiled language, twice, and a CPU with incredibly advanced pipelining be any different. Hell lets tear this mother up. •Optimizing parameters Because when your making a JMP instruction, the thing that really kills performance is pushing something on the stack. Nuts to all the magic the CPU is doing with its cache paging. That extra 1 parameter matters, it really, truely does. Try it, test it. It matters so much on my system here (Xeon 5xxx range) it is so negligable I can't find any difference in performance. So yes, clutter your code up, reduce that re-use. •Using static fields and static methods ProTip: Install re-sharper, it will moan at you for not doing this. •Reducing function calls and using switch No, no, no. The inliner is pretty damn good here. Break methods up so other devs can understand them. If you think you get better performance by preventing any inling, then your in the wrong fucking language. •Flatten arrays Not true. In many circumstances its better to have an array of arrays, because contiguous blocks of memory are hated by everyone in 32 bit land. Having a flat data structure makes your life harder. If your bit twiddling then this matters, but if your bit twiddling, having the whole safety of GC and pointer validation is going to kill your performance. If this matters, your in the wrong langauge. Given the nature of the GC in .Net, and the fact you might be on 32bit and have to worry about the LOH which becomes fragmented and un-compacted (leaky if you will), this is really, really bad advice. •Specifying the capacity for collections Sort of. If you know it, but be careful, List&lt;T&gt; for instance grows by doubling. If you know its going to be 800000, probably, but sometimes 900000, give it some space, go for 1000000. Or consider you know, thinking back to intro to data structures 101 and use something which is designed for such things. •Using struct or stop using it Sterling advice. I have no idea how anyone could possibly find that anything but helpful. •Reducing string instantiations and reduce ToString calls Well thats because as your example shows, your trying to do too much yourself. Why not use string.StartsWith(), very handy if you are say using Unicode. Luckily its only 1988 for all C# devs, and we never have unicode, ever, no would we want any culture compliant matching. •Knowing when to use StringBuilder and reusing it Actually I kind of agree with that one. 1 out of 10. God I feel sad inside now. Nothing worse than someone wanting to bring the worst aspects of C++ to C# because they are 'missing'.
... I'm not sure what to say. Sorry?
the worst part about it all is that the OP isn't in the negatives. And I've been bitten by the LOH; I wish MS had included a managed way to compress it in System.GC instead of expecting us to work around it.
Cross-posted on /r/programming http://www.reddit.com/r/programming/comments/1go934/strings_methods_return_variables_and_il_code/
I have had a quite the headache from this last week. It was pretty weak for MS to add such a troublesome dependency before NuGet properly manages it.
I've learned how to do this in school. Many years since I've yet to see a case where that would be really useful. I'm not saying it's useless, just not in the cases I've seen.
I'm far from a very experienced WPF guy but the project I did I managed to do it fully using the MVVM pattern. In the end I was scratching my head wondering where the hell an external framework was needed. I coded my ViewModels classes with a bunch of properties and methods. The views have all the crazy bindings I could dream of so they where code-free.
I'll strongly disagree that a desktop client is more modular. Any upgrades and modules have to be pushed to multiple clients all over the company and sometimes outside. In a web application you can push a new feature (which can be modular) without interrupting the use of the website if you know what you are doing. Deploying, maintaining, upgrading and debugging desktop clients all over the place is no laughing matter. Plus it sounds like you want data to be shared so you'll depend on a central server anyway. A desktop client takes the cake when your app has to run offline or it has *very* sophisticated UI.
I recommend starting with a micro framework like [Nancy](http://nancyfx.org/). You can pick and choose other components that you want to use.
It's useful in the sense of, it's a fun way to fuck with the new guy.
There is a time and a place for it thou. This guy demo'd nicely how not to do it. Complex Numbers should support ASDM for instance. Just not going to bool. Last thing you'd want to see is if (derp.IsComplex) rather than if (derp) (sarcasam) But I feel I should mention an interesting use of them! Check out http://www.codeproject.com/Articles/22650/Irony-NET-Compiler-Construction-Kit Notice how you make a Rule or an Expression. Using + and | operators is actually pretty nice. I have a Rich Enum type class which implements |,&amp; to allow for flags. There are some places for it, which really make life better, but your right it's often used badly, in a *just because we can*
True. That's why they are there mostly. 
Yes, because it interprets the "http" as a label, and the rest is a comment.
Actually, it won't compile like that. It will *only* compile if there is a reference to the label `http`. Add `goto http;` anywhere and it will work *or* throw a semicolon after the colon. ` http:;`
It compiles for me in LinqPad just fine, but with a warning. If you have "Warnings as Errors" enabled, it won't compile.
Well, you aren't wrong about that then.
compiles for me too. just one warning: warning CS0164: This label has not been referenced
I like my warnings as errors.. makes me feel safe.
Because the existing ones are so crap! A small app, focused on their workflow is potentially much better than spending the same amount to "customize" a commercial CRM.
I guess their background could come into play here. If they have been doing web only then they probably haven't had as much of a need for IDisposable. On a related note, I've noticed a lot of programmer scared by the "using" statement, maybe it's because they don't understand IDisposable.
&gt; how many viewmodels do you see in the wild are ever reusable anyplace else? View models aren't meant to be reusable, they are an abstract representation of the view, it is decoupled from the view itself. 
Scared? Like what do they do?
They say things like "I don't like using statements". Some will refactor it to the old try..finally..dispose pattern. Some will think your a wizard for knowing what it does. This career depresses me.
Wow, that's insane. I really don't know what else to say. 
Did I mentions this is all from "senior" developers? The kind responsible for implementing multi million dollar systems.
No need. If they weren't then you would have just slapped them down until they learned their place, and hopefully how to code. 
I really, really don't. I'm a human being, I have lots, and lots of information hitting me. Some are more important than others. Thanks to ReSharper/nCrunch etc I'm getting bamboozeled with information. I need a way to know what is important, and what isn't. For example unreferenced local variable. That isn't an error at all, I might be doing something with it in a second, I don't want to have to keep putting GC.KeepAlive on it to placate the compiler. What happens is you downgrade errors to be the level of warnings, this isn't a good thing, but worse, warnings aren't some great panicia, you still need fxCop etc, and you should still be tracking these metrics in your CI just as you would coverage stats. I really, really hate warnings as errors. Effectively, you end up using a base rather than the correct subclass.
I personally think that warnings as errors are a Good Thing^TM on the CI/daily build box, but not necessarily on a dev's box. The reason being that, as you mention above, the dev may just be testing something out on the way to a goal and may just not have written the code that uses that variable yet. However, merging that unfinished code into the build codebase is a no-no; one should only check in clean, working code (ideally along with the unit tests that verify the new behavior, please!).
I agree with that, except for one little thing, depending on the way the team is working, and the size of certain blocks of work, sometimes you want people to be checking in code that is in no way finished and is still a WIP, so that the others have visibility on it. Whilst this would normally be a feature branch, it is sometimes handy to have two configurations, the strict and the relaxed. The idea is you can watch the burn down on the strict. Myself I much prefer the check code in constantly model or shelve at the very least. Source control features are useful, even if its only you!
Yeah, funny, it compiles ok see it at http://csharp-repl.apphb.com/65
I've used CTT for some of my stuff at work too for a while now too. I like it.
Absolutes are rarely right but sometimes to achieve something you have to set limits in order to force you to do things the way you planned them. So you tell yourself "no code in views" and find ways to not do that and force yourself to learn the more advanced bindings and templates and whatnot. Of course, if time or technical constraints force you to break the rule you should but the important thing is trying to do it in a certain way. I've done a small WPF project with that in mind and many things I was certain I was never going to be able to do in MVVM I ended up finding a clean way to do it with code in the view. I'm not saying there's not going to be a case where I won't be able to find the nice solution in the time that was available to me but I sort of set a bar to reduce going with the easy "dirty" solution. 
sure this can be added, but in general i wanted to have something that will automatically work with the process, even if i close and reopen it. another thing that can be done is to add a pid selection dialog when there are more than one process with the same name, and add a configuration which can take more than one process name, for those who want to track several processes. (this really depends on what you want to achieve, and there are many design options, some of which include creating a completely different UI), if you want you can fork the project, and play around with it, it shouldent be hard to change what you want. I also might come back to this project soon as it is full of potential as a base for constructing many other, more advanced projects i am currently thinking of... 
Well, OzCode is a re-birth of BugAid. It's a beta release, there were many things fixed and improved, as well as a bunch of new features. OzCode is free while in beta, so please let us know if you have issues with it. Thanks!
There should be a relevant ScumBagSteve for this type of post. They should have at least mentioned ServiceStack.
It seems the limitation is not really on the application, but on the connecting server. I would say most servers capable of installing any various database could handle 100+ connections easily. The real concern would be in the data being exchanged (simple demographic, address, names etc.). If the data being exchanged is simple and small in regards to the rows/columns i would say sql express would be fine. But if you're looking at complex relational data and lots of rows, perhaps a MS SQL Server or mysql, oracle would be on the list of choices depending on what you plan on doing. 
100 simultaneous connections to the same database, or to different databases? Either way it sounds like you're on a mission to piss off your DBA and network admins.
I have an application (well, a windows service) which queries 750 databases across 30 servers in order to send out emails as an asynchronous process from the web applications. About once a minute it queries every database and gathers outgoing mail to send. We don't strictly control the number of threads it runs (.NET 4 TPL takes care of that, usually there are around 80 - 120 on our 8 core Xeon server). The whole application is basically an infinite loop spawning parallel tasks where each task is the following: 1. grab the next connection string and database type (some are Sybase ASE and some are MSSQL) from the queue (a [ConncurrentQueue](http://msdn.microsoft.com/en-us/library/dd267265.aspx) shared between all tasks) 2. Using the correct ADO.NET provider and query, get the emails from the queue via a new DbConnection instance 3. Send mail 4. add connection string to the queue (there is some other stuff going on as well like logging and maintenance of the queue data; these numbers are all during peak hours, overnight we throttle the parallelism to about 32 per minute and only get 1-2 messages per queue loop) Our limiting factor on how many databases this application can go through per minute is network bandwidth. This machine has a 100Mbps interface which is regularly being utilized to capacity (the rest of the network is running 10Gbps) while cpu usage is around 75%. Our average email is around 4K and there is almost always at least 2 to send every time we check. This application uses standard .NET built in libraries and raw ADO.NET (the only non-System.* namespace we are using is the Sybase.Ase provider). 
Connection pooling only comes in to play with connections to the same database (or more specifically, connections with the same connection string). 
We've both written the same app.
It is probably a pretty common custom app in many SaaS environments. Our web applications are unable to send SMTP traffic through the firewall or touch any devices besides the databases they have access to and the related cache cluster. I doubt those restrictions are considered unusual by any sysadmin operating more than a half dozen servers on their network. 
I hope it's the same. I further hope that all the developers who complain endlessly about it make good on their threats to not use VS 2012+ and stick with VS &lt;= 2010.
WHAT ABOUT THE MENUS? ARE THEY ALL CAPS?
YES. MICROSOFT HAS SWORN THIS IS THE FUTURE. IT IS NEVER GOING AWAY.
This is largely frustrating because we just switched to VS2012. Yearly release cycles for an IDE costing thousands of dollars is an idiotic business model.
You think you want this, but you don't. There are so many regulations and such that you never want that data passing through any of your servers and you *definitely* never want credit card information passing through. I know some billing companies offer an iframe that you can put on your checkout page (so the data never touches anything you have access to), not sure if PayPal is one of them.
The should stop naming it by the year. Just Visual Studio x.x (version numbers). The platform is extensible, so its not like they are actually re-writing it each year.
I'm still on 2010 at the office. Just use what works for you and your situation.
Nolock should be avoided. It is syntactically identical to READ UNCOMMITTED. Be prepared for issues with data quality when employing this hint. http://blogs.msdn.com/b/davidlean/archive/2009/04/06/sql-server-nolock-hint-other-poor-ideas.aspx Instead, consider [Read Committed Snapshot Isolation (RCSI)](http://www.brentozar.com/archive/2013/01/implementing-snapshot-or-read-committed-snapshot-isolation-in-sql-server-a-guide/). Readers won't block writers, and vice versa. 
This guy knows whats up.
I wouldn't say that. I know what r# does, and I wouldn't have any problems doing it manually. If you don't, then you shouldn't use r# until you learn to do it manually. 
At this time, it's too early for us (JetBrains) to commit that the C++ support is going to make it to 8.x, so I wouldn't bet on that.
Open regedit, find the visual studio 11 section Create a new DWORD key called "SuppressUppercaseConversion" with a value of 1 Restart VS and enjoy. 
The future is... loud.
They want everyone to get MSDN subscriptions. They're quite expensive...
They haven't announced pricing, so if it's a yearly cycle, maybe it will be cheaper or go to something like Adobe's cloud subscription model. I really wish Microsoft would just make it free, maybe except for the Team edition. It would be a great way to get more Windows phone developers on board. The free (and fragmented) Express versions are really confusing to those new to the Microsoft development world.
Anyone had chance to see if you can actually use it? Since the whole Lambda thing, I found Edit &amp; Continue useless on 32bit because the method contained an anonymous type, so couldn't be edited.
Anything to not get that damn dialog box saying "Changes to 64-bit application are not allowed."
I'd definitely agree with this statement.
Exactly. Accepting that data is no different than storing it. You could decide at any point that you want to steel identity, or even if you didn't that data is stored in memory (and potentially paged to disk) which means you are storing it. Unless you are a BIG company with BIG funds, use a payment processor in an iframe or just redirect. As an example I've worked at several nation wide companies and chances are extremely high you've shopped with at least one of them and none of them ever let that data hit their systems (they went the payment processor in an iframe route). As Mechakoopa said though, if your company doesn't have the credentials for people to trust it, you will lose sales by having them stay in your page. EDIT: As an example of BIG company, my current company (per our publicly available data) brought in almost $4 Billion the last fiscal year and we won't let that data come anywhere near our systems.
Very cool!
Well you also look like a fool trying to develop complex applications in Notepad using the command-line compiler as opposed to working in Visual Studio. You also look like a fool fishing and hunting for wild deer in order to get something to eat as opposed to actually writing some code in order to earn money )
Light, dark, or blue.
Yawn. CodeRush has had it you years.
You can already develop WP8 and Metro apps using VS Express. No plugins, but hey if you don't know what you're missing...
I have a similar question in the same vein. What does deny ="" of deny ="*" mean. I'm taking a dotnet class and came across this several times. 
http://www.asp.net/mvc/open-source
http://msdn.microsoft.com/en-us/library/8aeskccd(v=vs.80).aspx
The[ .Net Micro Framework](http://netmf.codeplex.com/) (which is loosely based on the main .Net framework and targeted and low powered devices) is entirely open source.
I [just released v0.9.4](http://higherlogics.blogspot.ca/2013/06/sasa-094-released.html) of my own open source Sasa. Lots of general purpose code, so there's plenty to sink your teeth into.
Nice work - love json.net
I have two that I've written, I'd love some help, if you have time! http://github.com/jonnii/speakeasy http://github.com/jonnii/chinchilla
Microsoft's ASP.NET site has one for WebForms. It does not include unit testing, IoC, etc. though.: [http://www.asp.net/web-forms/tutorials/getting-started-with-ef](http://www.asp.net/web-forms/tutorials/getting-started-with-ef) However, might I suggest that you learn ASP.NET MVC rather than WebForms? The former is much friendlier to unit testing, and Microsoft's examples reflect that: [http://www.asp.net/mvc](http://www.asp.net/mvc)
Oh, and Microsoft's testing framework does not include mocking (at least, not without purchasing the ZOMGExpensive Premium version of VS). I personally recommend Moq, which has a beneficial side effect of easing you into .NET's lambdas.
Indeed, unless you're going to have a job maintaining legacy ASP.NET, there is no reason to learn WebForms. ASP.NET MVC is the way going forward.
If you like great video tutorials, [PluralSight](http://www.PluralSight.com) is the best I have ever found! 
True, MVC is the way going forward but Webforms isn't going anywhere, it's used extensively in Sharepoint.
Actually there is. If you are building an internal website that just has simple edit pages and grid style reports then Web Forms is probably still going to be the most productive route. MVC takes a lot longer to setup, though it is worth it if you want a highly customized site or have strict performance needs.
I'm pretty sure you can use ASP.NET MVC in Sharepoint.
I always bring up PluralSight when people ask me about .NET training. I'm such a shill for that company, they should be paying me every month, not the other way around.
Microsoft has free training you can go through at [Microsoft Virtual Academy](http://www.microsoftvirtualacademy.com). They are jumpstarts and will get you going. Some that might interest you: [C# Jumpstart](http://www.microsoftvirtualacademy.com/training-courses/developer-training-with-programming-in-c) [ASP.NET Jumpstart](http://www.microsoftvirtualacademy.com/training-courses/create-web-apps-with-asp-net) The C# one will probably be a little rudimentary for you, but you can jump ahead if it gets too boring. The ASP.NET one is actually pretty great and covers most of what you mentioned, but at a pretty high level. I went through it a while back because I got stuck doing Oracle development for a about eight months and wanted a refresher.
If you can get your hands on a copy of VS2012 install it and fire up a new MVC4 (you can also do the same with a plain ASP.NET site but Webforms is quickly falling out of favor in professional development) project setup as an internet site. Since you understand Java (and I assume a number of frameworks and such since you are more senior) this will be a good starting point. You will be dropped in a template site with a handful of pages already developed and a couple of Entity framework models already setup (against and MDB, change the connection string in the web.config to point it at your RDBMS). If you have used spring you will likely recognize many of the patterns in use. You may also want to look into Unity as it is a solid IoC framework that is included with .NET. The base template will compile and run (provided you have your data settings correct) without any modification, from there you can hack away. If you are looking to understand the relationship between ASP.NET, IIS and .NET itself, the easiest way to explain it is IIS = Apache/Weblogic/Websphere, ASP.NET = Javax.Servelet (kind of and just sits on top of System.Net/Web) and the .NET runtime. Loading of components is handled differently, so is garbage collection (though that should not be a concern) but overall they are pretty much the same platform with equivalent features. You'll notice a lot of Java code translates to C# and vice versa with just some minor changes. As for mocking, there are a ton, MS has Fakes, the Moq project is quite popular along with others. A google search here should give you a number of options. For the IDE, Visual Studio is your best bet as it is the best IDE for .NET, however like Java you can do everything in a text editor and use MSBuild (or just csc.exe for the hardcore) to build your projects. You can also use tools like Xamarin or even Eclipse (not for the feint of heart) for your projects.
Some people here have sited some pretty good sources. I'll just add that each of those few points are actually huge so don't expect one massive single tutorial to cover it all in any depth. Maybe checking out the source for a popular demo project like http://nerddinner.codeplex.com/ could be helpful.
I would recommend microsoft MVC over asp.net pages.
Moq sounds very cool, I'll have to check it out. I'm not actually sure whether the prospective job expects unit testing at all, but I'm really hoping it does. I've used mocking extensively at my current and previous jobs and I love it.
I find [NSubstitute](http://nsubstitute.github.io/) to be superior and easier to use.
Hadn't heard of that before, looks neat. In the end they all use castle dynamic proxy so it's all in how it's exposed 
Not entirely correct. With connection pooling in your data tier, connections will stay open after they stop being utilized. That way, the next connection that is requested with the same connection string will already be open, which avoids the expensive operation to open it.
Connection pooling is great (I really love it), but you can only utilize it if your data layer stays alive between clients/operations. If you have a data tier that is shared between clients, this should not be a problem. So OP should have a look if that can be a solution for him.
Pass by value is not the default
I find the PuralSight content to be very dry and I struggle to get through it. I've been a paying member for about a year, I don't think I've made it through a full series yet.
A couple things come to mind: You probably want to look at "web.config transformations" (google it), which will allow you to replace chunks of your web.config depending on the build configuration (debug or release): http://msdn.microsoft.com/en-us/library/dd465318(v=vs.100).aspx In VS2012 they've improved this functionality, when you do a VS package/publish command it automatically transforms using a web.debug.config and web.release.config to modify the "base" web.config. The catch is that you have to use the publish or package feature for this to happen, although you can "publish to disk" to build and create a folder with your site which is zippable and deployable through traditional means (ftp or RDP copy to server). Another option, the quick/dirty/easy way, would be adding a hosts file entry on both your local machine and on the production server and only use that hostname in the connection string. For example, call it "sql" and point it at 127.0.0.1 on your dev machine, and point it at the production sql IP in the production server's hosts file (\windows\system32\drivers\etc\hosts) One more thing - you could modify your msbuild file (the Solution or Project file) to include commands to copy/replace the web.config as needed depending on the build configuration. This is pretty much what the top two suggestions are doing for you already.
Awesome and thanks... Much appreciated!
Note that it doesn't work for console application. Try using the NuGet package XDT Transform. What they have done basically, is extract the way it's done with web.config and allow you to do it manually with any XML. It wouldn't be hard to create a deployment script.
If you are working with app.config, that solution won't work. Please see my other comment.
You're welcome. Since this is a common problem I thought I'd share one more possible solution... Prior to vs2012 our dev team built a config accessor class which allowed us to store multiple web.config settings like this: &lt;add key="appevents.servicebus.enabled" value="true"/&gt; &lt;add key="appevents.servicebus.enabled.debug" value="false"/&gt; &lt;add key="appevents.servicebus.enabled.FBGDEV01" value="true"/&gt; So the calling code simply requests the value of "appevents.servicebus.enabled", and the accessor class determines which value to return based on build configuration and/or machine name. If there is only a single key with a perfect name match, that value is returned. If built in debug mode and there is a "keyname.debug" match, return that value. If there is a ".machinename" match, always return that value. This let each developer override the "debug" settings by configuring their own values and still check the file into TFS without overwriting each other. Anyway the transformations or vs2012 packaging are probably your best practice these days!
You could set up a post-build event that runs [XMLPreprocess](http://xmlpreprocess.codeplex.com/) on your app.config (or other configuration files you have) and then you can set up all the connection strings and other configuration details in one file and XMLPreprocess will handle all the details. I've used it with a lot of success.
Mono is mostly written in C not C#. This doesn't really meet his criteria.
While using config transformations does work, that requires a separate build/publish for each environment. I would suggest that you use the SQL Server Client Network Utility to create an alias to use instead of the actual server name and use that exclusively (even on your local dev machine). That way the connection string doesn't ever actually change between environments. Here's somebody's walkthrough of creating an alias: http://sqlandme.com/2011/05/05/create-sql-server-alias-cliconfg-exe/ and after that you can just use the alias as your server. Only caveat is being thoughtful on x64 machines: http://www.airbornegeek.com/2011/08/a-note-about-cliconfg-exe-on-x64-machines/
The SQL Server Client Network Utility is much cleaner than a hosts entry: http://www.reddit.com/r/dotnet/comments/1hlr7r/moving_project_from_test_environment_to/cavtbng
It will if you import the task "manually": &lt;UsingTask TaskName="TransformXml" AssemblyFile="$(MSBuildExtensionsPath)\Microsoft\VisualStudio\v$(VisualStudioVersion)\Web\Microsoft.Web.Publishing.Tasks.dll" /&gt; and invoke the target from AfterBuild: &lt;TransformXml Source="app.config" Destination="$(IntermediateOutputPath)$(TargetFileName).config" Transform="app.$(Configuration).config" /&gt; 
Well yeah... if you modify the default to do what you want, it will do what you want. I was talking out of the box of course. Potential problem with your solution is with the build server. If the build uses MSBUILD instead of Visual Studio, it will need to have the Visual Studio Shell ([2010](http://www.microsoft.com/en-us/download/details.aspx?id=115), [2012](http://www.microsoft.com/en-us/download/details.aspx?id=30663)) installed to run properly. Otherwise, I guess it should work.
How does this compare to Pex?
Completely unrelated. Pex does white box testing by analyzing the implementation details of the code. Test Monkey is does black box API testing. In addition to properties, it tests methods that it understands the contract for. Which is to say, methods on the built-in interfaces. One nice thing about Test Monkey is that it is extensible. You just need to inherit from a base class and overwrite a method that says whether or not it should generate a given type of test. The actual test is templated using Razor from ASP.NET MVC. Test monkey does require some hand tuning at times. It emits a file called "ClassName_Custom" where you are supposed to put in constructors for classes that it can't automatically create an instance of.
I'm a Tekpub subscriber and I've received a lot of value from it. Especially from their Triage series - watching Ayende solve problems in seconds is fascinating. Jon Skeet's videos are interesting too. I find looking over the shoulder of a black belt is often more valuable than structured presentations. I hear good things about PluralSight, but I've never tried it. 
Good points. I stand corrected.
Yeah, I watched that...waiting to see how all that works. Hanselman, as always, did a great job. Part of what I was doing was trying to figure out exactly what was required for a WebApi project. I only recently tried building one out. Imagine my surprise when I first created the standard project. Good god, man. Even the minimal project still comes with a load of stuff, though. I understand The Nancy framework is an attractive alternative, so I'll be checking that out soon. Thanks for reading, and the feedback!
Nancy is just an implementation of OWIN. OWIN will bring you a complete decoupling of IIS. Let that sink in for a bit. IIS is just a complex wrapper for HTTP.SYS. You know why you can't have web sockets on Windows Server 2008 R2? HTTP.sys doesn't support it. Only on the latest Windows Server 2012 can you do Web Sockets. The way I see it, the more we go forward and the more agile Microsoft will need to be. Not just to keep the market but to expand their other interest... Azure. Can't wait 2 years to release a new OS just for the latest and greatest of the web. It needs to happen yesterday and IIS is bogging people down. Just my intuition I guess. :)
Agreed...I am still finding my way through some of what lies beneath all this (it should be clear that I M blogging my own learning process here!). However, my impression is that MS has begun to figure out precisely what you describe, particularly so far as Azure is concerned. On the other hand, I am actively also learning Linux, and some other languages/ecosystems at this point. I agree IIS is something of a bottleneck...
Bottleneck of Innovation. :) What languages are you on? I'm a 100% Microsoft guy on my end and I'm thinking about Python as a side-language to learn. Opinions? 
Right now, looking into Ruby and rails, just because it is so pervasive (although rails seems to be entering its own "bloat" phase). Also trying to get a better handle on JS, and Node. I don't know enough to have a solid opinion at this point! I'm a self-taught guy, gotta do this stuff evenings and weekends, so it is a slow process... Python might be an interesting choice too. Also, it's still MS, but F# looks cool as a total paradigm shift. 
If you are looking in the field of [NLP](http://en.wikipedia.org/wiki/Natural_language_processing), you'll see rapidly that Python is your only choice for running academic libraries until you know them enough to rewrite them in the language of your choice. I was first looking into that field to understand Lucene.NET and Solr.
Might want to cross post this to /r/aspnet
Someone else will provide questions, but a word of advice; never be afraid to say "I don't know, I'd have to look that up". As someone that's conducted more than 50 interviews (begrudgingly) there is nothing that makes my alarm bells ring like someone that pretends to know the right answer, speaks confidently, but isn't anywhere close. The first thing that goes through my head is "I can't trust this guy with my code-base". It's also completely cool to ask for clarification on a question. Were I you, I would bring a pad and a piece of paper to write down the questions you miss. Tell the interviewer its for study at home to make sure you're better prepared for the job (to make sure it doesn't look like you're copying their question list for your recruiter). Also, know the difference between value and reference types, and which go on the stack and heap. I don't know why everyone asks it, but they do. Everyone is practiced on this question and answers reflexively, even if they don't know what their answer means. Know what it means. A lot of the questions you get will be OO questions. Inheritance, polymorphism, bla bla bla. These ones you really need to get correct. Don't freak out if you miss a few non OO questions. Every time I've seen an interview question-set put together, it includes a few that the dude writing it couldn't answer without looking the answer up; you're not expected to get those.
Can you give some background as to what were you doing before? I think some of the questions I was asked many moons ago were about XML, Web Services if I had used it or coded and what I did. Obviously C# or vb.net is less of the question here and more of you communicating a complex problem easily. In addition questions were about stored procedures, debugging, lambda usage, billable types and so on. 
This is what you should do: Step 1: Download the free tools from Microsoft (unless you are willing to spring for at least VS Professional). Step 2: Build something. A website works best because everywhere you go you can show people. Even if it is on your phone. Step 3: Start interviewing. At you interviews show them your website. Explain about the design of the site and how everything works. If you are applying for the entry or even mid level you will be showing initiative. You will also learn something. And lastly, you'll have and be able to show what you are capable of.
I recently finished up interviewing for various .NET positions and this helped out for a good basis on what to expect: http://www.hanselman.com/blog/WhatGreatNETDevelopersOughtToKnowMoreNETInterviewQuestions.aspx The things that seemed to trip me up the most involved actually having to explain something that I had been working with for years such as inheritance, polymorphism, or interfaces. These are some that popped up multiple times across different interviews: * What is reflection? (Why would you use it and also why wouldn't you use it?) * Have you used LINQ before? Explain what LINQ can do for you. * What are the different ways to store state in ASP.Net? Explain how ViewState/Session work. * Explain overloading and overriding. * Explain the differences between public, private, and protected. * (SQL) Explain an inner join vs an outer join.
You site is erroring
Scare them by asking about the difference between abstract classes and interfaces, an example of using dependency injection (constructor injection is simple) and how to extend a base class. Then say you're joking and ask about... And I just reread your post so let me just advise you that if you know about that stuff then don't worry otherwise keep reading up on LINQ, entity framework, using SQL darabases and figure out how to make a class.
Thanks for the help! Since the original post I've re-written my project website from php to C# to have as an example during interviews. Between redoing my site, I've been looking up all of the questions you guys have listed. Thank you all so much! I appreciate everything!
[Hidden Features of C#](http://stackoverflow.com/questions/9033/hidden-features-of-c) &lt;-- Start here! Apart from what you need to know about C#, you also need to know basic Comp.Sci. I've been interviewing these past few weeks, although targeting senior/architect/project lead positions. But still, every interview starts with the basic **"prove you're not completely retarded"** questions :) - Stack vs. Queue? - readonly vs. const? - Linked list vs. array? - Breath vs. depth first search? - How does a garbage collector operate? - Interface vs. abstract class? - Locks, mutexes, semaphores / when to lock / why not to lock Then I usually receive questions on specific frameworks that I'm expected to know, i.e. for a WPF position I always get "explain MVVM". Frameworks vary, you can't be expected to know everything about all of them (although some employers do, and it annoys me a great deal). If the interviewer is asking about NHibernate but you only know Entity framework, then try to explain how entity framework does the thing the interviewer is asking about. It's amazing how much a one-night marathon session on youtube and wikipedia can net you. You don't need to get in-depth, sometimes it is enough to recognize the buzzwords, but remember, when you're out of your depth then admit to it. Good luck on the job hunt :)
Planning to, as soon as I find out what's up with my site!
Do you have automated builds? It sounds like you don't but I'm not sure. If you do then these settings just become config options on the build server that generate the correct web.config, or they merge files etc.
There is an issue with my hosting service at the moment, so the link errors out. Working on it now . . . 
Process vs Thread – process is an independent execution unit with its own state and memory; Architectural construct. Threads exist inside of a Process and share state and memory; coding construct. Abstract class – can be partially implemented. Cannot be instantiated Interface – a contract definition that can be implemented in a Class. A pure abstract class. Members of an interface are always Public and Abstract. Classes can implement multiple interfaces (quasi multi-inheritance) Base class – have their own implementations for methods. Hierarchy example: Base Class: Vehicle. Derived Class: Car. Interface: IsSteerable Poly-Morphism – two types: Overloading &amp; Overriding Overloading – same method name, differing signature and implementation Overriding – differing implementation in the derived class Virtual – used when overriding base class methods in a derived class. 
UPDATE: Theoretically, this is fixed now. Some App pool config issue on the host server was borking my site for the past 72 hours. Gotta love IIS. 
More importantly, how much do you want to spend?
As much RAM as you can get in there and a fast HD (SSD would be ideal). I feel most any current generation CPU should be fine as they're all quite fast now a days, though faster will obviously give you a snappier experience (though perhaps only marginally). You'll want as much screen real estate as you can get away with. These suggestions apply to pretty much any kind of dev work, not just .net. The biggest difference for me between a dedicated dev box and a more general purpose machine is I will always max out the RAM as much as I can afford to. The more RAM you have the less taxed the HD will be and the less it's slowness will matter though you definitely don't want to skimp on the HD either.
I think you want at least 8gig ram and a SSD drive. Visual Studio takes a lot of resources to run (as you work with larger projects).
Studio is a beast, but you can run it (albeit a bit chuggy) on most common laptops these days. MonoDevelop and SharpDevelop are fairly slim, I can run them fairly well on my POS Netbook. The command line is REALLY easy on the resources. :)
Optimally, less than $1000
Those specs are good enough. Contrary to a lot of posts in this thread - you don't need a super computer to run Visual Studio - it's not Eclipse by a long shot. For instance this $400 laptop would be more than adequate http://www.newegg.com/Product/Product.aspx?Item=N82E16834231073
When I interview candidates I generally stay away from too many technical questions. I prefer to have them walk through how they would solve a problem technically. Memorizing syntax doesn't impress me, being able to figure something out does. That being said, you still need to know your shit, but you can't really prepare for it other than by coding.
Depending on the project size, gotta go with an SSD. Everything else is gravy
What I would suggest is an SSD, because you will be building a lot, especially when you are working on bigger projects. I had an improvement of 400% when I installed a samsung ssd 840 pro. Go for the bigger screen resolution (full hd) unless that has an impact on your budget for ram memory. You don't want your ssd to be used for swapping, go for at least 6 GB (8 would be great). With full hd you can work comfortable which isn't the case if you go smaller. Always tabbing between files, your solutions explorer/team explorer that get in its way.
this
Get a second monitor, you will never regret it.
After starting on .Net last year, I was crushed twice by problems with Windows (malware and other issues) -- even though I'd kept it fully updated, kept our enterprise antivirus fully updated, etc... This meant I had to do backups, reinstall, etc... What a pain in the ass and what a loss of development and learning time. What I wound up doing -- and what I heavily suggest for you -- is to either get VMWare Workstation or try out KVM. Get the fastest laptop you can with the most cores and lots and lots of RAM (well, at least 8GB, but more would be better). Get an SSD like other people have said. I have a Lenovo T430s that I use through work and, although I was very resistant after having a shitty experience with their early desktops, it's been very nice. It's a very compact and sturdy laptop. I don't know if all laptops now are 64bit, but you'll want to make sure to get a 64bit one with max virtualization capability available in the BIOS. Install minimal Ubuntu (or other Linux) server as the host, add a light weight desktop like LXDE or Lubuntu in the install and update the whole thing and [secure the host as well as you can](http://www.cyberciti.biz/tips/linux-security.html). Next add either VMWare Workstation (~ $200) or KVM (free but I just started using it, so I don't know how it compares to VMWare -- the VMWare has been excellent). When you get the virtual machine host software installed, then create the perfect Windows 7 install, update it, update your anti-virus, put on all the software that you'll be using (add a good FTP program like Coreftp) and update Windows 7 again. Then take a snapshot of that installation. Then clone that virtual machine on your laptop a couple of times. Then back up a copy of that virtual machine image to a USB drive and keep it somewhere safe. Also install a lightweight Ubuntu (Lubuntu or LXDE or something like that) and all the software that you use for browsing and normal computer use and then update it and secure it like your host. Then take a snapshot and clone that image and back it up like your Windows 7 guest image to a USB drive and put it somewhere safe. Use the Ubuntu virtual machine for all your browsing, research, email, etc... Try not to use your Windows 7 development machine for those things. With at least 4GB of RAM, you shouldn't have any problem running both virtual machines at the same time and switching back and forth. With more ram, you can run more machines or get more performance. Periodically, (particularly after updating and installing new software) take snapshots of your virtual machines. Also back up your project/website folders. Once in a while you'll probably want to back up the entire virtual machine image again to a safe USB drive. I haven't had a single real problem since I did this and I think it has saved or will save me an enormous amount of time and headache. It will be a long time before I have to do another operating system installation I think and I've got multiple levels of fail proofing, barring a house fire that somehow burns up the fire safe my back up drive is in.
VS runs fine on my 8-year-old computer with 2x2.1 GHz processors + 4 gigs of RAM + 7200 RPM disks.
Yeah, my dated-but-beefy-at-the-time 8 gigger can usually keep a couple instances of VS running at once. I can even launch it on my netbook, although using it is an exercise in patience.
Rather than maintain a VM, I automated the installation of most of the software I use. The code I use for that is here if interested: https://github.com/fschwiet/fschwiet-boxstarter. All the code I write goes into source control on github or bitbucket, so if something is funky its not a big deal to just rebuild my machine. It does take a long time to download everything, but since its Mostly Automated (TM) its relatively easy. I also have a fat internet connection, so maybe its not so much an option for everyone.
Will that model age well ? I don't want to have to buy new specs and programs soon after to keep up
It seems like 4 GB RAM is abut as high as it goes for netbooks (I will not be purchasing a MBP), and that I can only get over 8 GB RAm in a workstation. Is that the way to go? 
Yes. Apple is only "expensive" if your intention otherwise is to buy shit. I mention Lenovo and Dell simply because if someone is so set against Apple hardware for some blind rage type reason they can at least get good hardware and support from the likes of Dell and Lenovo. Of course, they still have to avoid buying shit sold by both Dell and Lenovo but I can't help them with that part. :) 
An interviewer! Awesome! Let me ask you a few things (plz!): 1. When interviewing for my first ever coding job, will the interviewer expect me to have a thorough understanding of Entity and/or NHibernate? 2. Reflection/Attributes/etc... should I know this stuff inside and out? 3. JSON, tSQL, and the other stuff.. eh... should I know this stuff as well, or is knowing *something* about them good enough? I really appreciate your comment! Thanks for helping me out!
This is very interesting, thanks for sharing it!
You do not want to dev work on a netbook. They're a bit underpowered for that.
Before you buy it I would ask (Newegg) if the hard drive can be replaced with an SSD. This, like others have said, will be the most valuable upgrade/improvement you can make. And you could wait awhile for prices to come down. In the meantime you'll be fine with VS.
I've done a good bit of interviewing, and it's different for each candidate. I try to ask questions to gauge where they are compared to where their resume says they are. That being said. DON'T LIE ABOUT EXPERIENCE ON YOUR RESUME! It'll come through and make you look bad. When going through a technical interview, it's really not about knowing all the answers, it's about being able to do the job. The questions are there to gauge what your experience level is and whether you can grow into the position if necessary. Okay, so some questions. 1. Know about database connections. How to read data, the different ways to read data. What an ORM is. How to prevent injection. 2. If asp.net. Know about the page lifecycle, and what happens at each event. You don't really need to get this right, just show that you understand that some code should be placed in certain event. Knowing when the viewstate is loaded is a plus. 3. Know about generics. 4. The basics of OOP. 5. Delegates, what are they and why to use them. 6. if asp.net know about ajax, update panels, validators, gridviews. 
SSD is nice.. but expensive and not necessary. They will also wear out a lot faster. Especially with all the disk churn a compiler goes through - it's an extravagance. 
fF you have that budget I'd up that laptop to a i5 and at least 6GB of ram. you should be able to easily for that price and still have a ton left over. i would strongly suggest a SSD but it's not needed. same with a second screen.
i think i'd move CPU above DPI...
A SSD, and as much RAM as you can afford, even 8GB can be limiting. Unless you're working on a huge project like Chromium or Firefox, CPU performance doesn't really matter.
"◦WinRT still has a fundamentally flawed deployment/licensing model for business apps" Could someone explain what that sentence is supposed to mean?
Re deployment, he might be referring to having to use their store to distribute apps (outside of the very restrictive side loading option).
Do people actually still make desktop (non-mobile) applications? I haven't seen any of those in a while, most enterprise things I have seen are either 100% web or mobile/web+mobile. So I would say JavaScript and Objective C are actually more relevant on client than whatever approach Microsoft chooses with WinRT.
This guy is going for a budget system.
Visual Studio 2012 system requirements http://www.microsoft.com/visualstudio/eng/products/compatibility If you plan on running ReSharper (a common addon for .NET developers) those requirements jump up substantially. http://www.jetbrains.com/resharper/download/system_requirements.html Keep in mind that these are minimum system requirements. A lot of people here are claiming you may need a lot more, but that really is dependent on the type of projects you will be working on. For the most part, with good practices a lot of these concerns can be mitigated.
It means the author is unaware of the windows 8 enterprise deployment options.
Well I can't speak for everyone that interviews, but it will really depend on the job. If it's listed on the job description and you don't know it, at the very least you need to understand what it does and in what context it is used. Being an entry level position I wouldn't expect someone to be an expert in all those areas, but it certainly won't hurt you to know as much about the technologies that are used for that specific position as you can. I would recommend doing a mock interview with someone before your real interview, a candidate that is composed and well spoken always has an edge in the business world. If you are in or went to a 4 year college/community college they almost certainly have a career center that can help you with this. Take advantage of this resource. 
Yes we do.
New ones? What is the rationale for choosing desktop over web? Though to be fair I can definitely think of several reasons, just haven't seen much of those.
Yes, new ones. I myself am building a WPF C# application with a PostgreSQL backend. I've yet to use an enterprisey webified app that doesn't suck in one way or another (I'm looking at you, HP QC).
8GB ram minimum + an SSD. Visual Studio is an absolute resource hog, especially if you want a few windows open. Processor is important only if you care about improving compilation times.
The bottleneck for project builds is the processor, not the hard drive. You do usually copy some amount of dlls, but the difference in build times between SSD / HDD is minimal compared to a low end and high end cpu.
Are you talking client-server/standalone desktop app? What were the actual considerations involved in your decision to go with WPF? Was it to use Silverlight? Not questioning your decision, I'm just curious. I'm new to C# but I was hoping that anything I used to do on desktop/client-server (basic CRUD apps and media apps) I could do thin-client style with a web app, whether it was actually used over the web or just locally. I began building a C# app with a PostgreSQL backend (in the interest of migrating to totally open source app with PHP front end eventually) but decided to go with SQL Server instead, at least to prototype. It seemed like there was a lot of overhead to use PostgresSQL with Visual Studio.
To add on to this, if you need to trade-off between RAM and an SSD, go with RAM first. The difference between running VS w/ 8GB and 4GB is substantial. Some background: I have worked with .NET code for the past 2 years and have to do lots of context switching because of the projects I work in or on. I started with a 4GB / HDD machine and the amount of time I was losing on opening/closing/switching between diff VS windows was very large. Not to mention how unstable my box was. With some benchmarking, I was first able to convince management to get me up to 8GB. This had the effect of stabilizing my box quite nicely and allowing me to open more than 1-2 VS windows. Larger projects with bad dependency trees were still killing me, as I like to use ReSharper and the Intellisense add-ins create a local file cache. When switching between VS windows, this caused some heavy thrashing. Another problem was just opening these large projects was time consuming and it did not make sense for me to always have them open. Again, I convinced management to get me a small Samsung SSD (~100$). The upgrade makes VS function like a charm (for large projects). Overall, the time savings is roughly equivalent to 2-2.5hrs a day with just that increase in specs. I have not had a system crash or instability since the switch.
 Real time trading and data analysis, used by a sizeable chunk of the investment industry. Fidelity for example has a huge body of real time apps that are on .net and wpf. Oil, power and gas are other examples where real time data feeds are employed with extremely complex, multi-window ui's. Its necessary as the devices being monitored produce thousands of data points ever few ms. Not everything can be delayed for even a second and everything is not suited to a watered down full screen interface even if it is the hip thing for consumers these days.
Are all your applications that you run browser-based? Geez, does EVERY article about the future of .NET/desktop development have to have someone saying this?
False. IO is by far the bottleneck. compilation is cheap. Even if it wasn't an SSD will improve all the other things you do that incur io costs, speeding up the whole dev experience
It was really a question of needing a lot of disk I/O and CPU cycles. Since the users already have pretty new and powerful PCs, and our server budget is quite limited, our choices were limited. I chose Postgres because I knew it already (stored procedures-wise), and you can run it as a portable server if needed, which is a good thing on my overburdened laptop. It's not pretty with VS though, I'll give you that. WPF is a beast, and sometimes I wish I went the WinForm, Silverlight, ASP.NET, etc route (I/O be damned), but I've sunk too much time and effort in it already. WPF is for masochists only. 
I do much the same, I adjust the interview towards where I think the candidate is technically. We have all of our candidates complete a code review before we bring them on site, even if they have not worked with .NET. 9/10 times this gives us a really good idea of how to exercise the candidate during the technical part of the interview. Things that I personally look out for: * Candidates who becomes aggressive when they are asked to defend their implementation, or to discuss the trade-offs between an alternative implementation. * Candidates who have clearly not looked into the internals of how things work, who blindly and confidently answer questions when they are blatantly off. ("I don't know, I would have to look it up" is always a better answer) * Candidates who are communicative about HOW they approach a problem (we sometimes further look into this by asking a brainteaser). This is a really good indication on if they will play nicely in a team. * Candidates who think they are much better technically than they really are. I like humbleness. * Candidates who say they learn quickly but than do not back this up with examples. This sometimes goes hand in hand with passion for technology. The common things I ask for with a Entry level or Junior dev: * Have you heard of SOLID? (can you show examples in your code, does the code you submitted violate any of the SOLID principles?) * Have you heard of the _____ pattern? (example: MVC) Can it be applied to the code you reviewed? (example: what would be the Model, the View, the Controller?) * Have you heard of TDD? * What are the important qualities of a Unit Test? * How would you mock or stub a sealed class that does not implement any interfaces? A static class? * This one: http://simon-says-architecture.com/2012/10/30/interview-killer-question/ 
Can you point to a specific model that you'd buy if you were in my shoes?
Thanks for the advice, everyone. I think I'm going to just pony up and go for the [Lenovo Thinkpad 530](http://shop.lenovo.com/us/en/laptops/thinkpad/w-series/w530/index.html#customize). Lowest price I could find for it was a bit more than $1200. If anyone knows a place to get it for lower, lmk! Thanks
Actually with the SSD it will run me over 1300...oh well I guess its a good investment
Are you aware of any deployment options that don't InTune or manually running a PowerShell script on every machine?
What application are you talking about? All I see is "Windows 8 Company Store" which just offers links to websites and file shares. 
My buddy is working on a WPF application that manages robots in an automated warehouse. It is designed to run full screen on three monitors with the different views constantly in sync with one another. Building something like that in a browser would be possible, but insanely difficult.
Upgrading to an SSD at work took my build time from 25 minutes down to 2. On the down side, I have less room for steam games on my work laptop now.
Our office is slowly upgrading all our developers to SSDs as the time we save compiling is worth the cost investment. At home, however, it's definitely an extravagance.
So other there are four complete methods that range from small office to medium to large enterprise...so everyone can do it is what you are saying. What is it that they should be doing that they aren't? This isn't anymore restrictive than other "app store" type setups...even for business users. "Run a powershell script from a share" is probably the most flexible. Enterprise edition is the one with all of the enterprise features...I wouldn't deploy anything else. EDIT: Just read that guys pan-shitting...I mean...series of articles. Basically, if you are a business that wants to deploy modern apps then use Enterprise Edition. That's not a problem for anyone but the guy that wrote this article is going to have...or use intune. What's so hard about the message that the machine needs to be managed? Side loading onto non domain joined machines short circuits the security measures that have been built into the sandbox. If they hadn't done this that you guys would still be crying yourself to sleep about vulnerabilities and patches. Jesus, things can't change unless they change. Duh. 
Most companies aren't running enterprise editions of the desktop operating systems. Nor do they have the IT resources to acquire InTune or System Center, let alone manage it. Hell, a lot of small businesses count themselves lucky to have an working active directory server. So what are developers working at small companies supposed to say? Sure I can build that app for you, but you'll have to drop 3 grand on license keys for your 15 machines. Oh, and we don't get automatic updates like we had for ClickOnce so I'll need to manually install this on every machine once a week until we stop making changes to the app.
We started a new Rich Client in Q4 2012 based on winforms. The rationale for winforms was a powerfull third party grid, the learning curve of WPF and XAML, WPF performance concerns (quite a few of our pcs are older machines - and even on my core i5 2nd-gen laptop some wpf demos were a little sluggish). The statements in this [article on Windows Line of Business Apps](http://www.infoq.com/articles/Win8-LOB-Options do confirm) seem to confirm that our decision was the right one. I am quite certain that the cost to develop a rich client is lower than to develop a web app. If you have powerfull third party components the cost advantages are even bigger. Some features (multi monitor support) are as far as i know not easy or even not at all solvable with webpages.
&gt; Basically, if you are a business that wants to deploy modern apps then use Enterprise Edition. Small and a good bit of medium size businesses, buh-bye...is MS trying to be some sort of Oracle/Apple monster?
Our business clients run our software, a SAAS setup, you could compare it to SAP in terms of functionality, and there's no way we could support it if it was sold from the Windows store. Each installation requires a lot of customized setup, hundreds of computers at once for a client launch. We build a custom installer for each client on demand when they download it. There's no way you could organize that using any of MS's methods for installing RT applications. Our clients, obviously, aren't domain joined to us and are often sparsely distributed across the continent.
I agree an SSD would be a significant performance boost. However, even a 5400 spinner is good enough for most dev tasks. If he's trying to pinch pennies then SSD's probably aren't in his price range.
Thanks for the feedback . . . I get what you're saying about the plural in the URL, but since I was working with a Person model, and then a Person ApiController . . . it seemed weird to move to the plural. That said, I understand the Rails team went to great lengths to achieve plural mapping as a matter of convention. Point taken. Also good points about POST/PUT/DELETE. All items noted!
Actually the majority of business desktops deployed are enterprise edition. Sorry. If you need to star telling your customers something different that's a you thing. I can't help but think that most of you have this by the wrong end of the stick. Small businesses that can't be counted on to have a single functioning DC but have developers on staff writing custom applications don't sound like a deal breaker to me. If they do exist for whatever reason...they can keep using existing desktop tech. Also, for boutique developers that cater to small customers that want custom line of business applications written that want to use the modern framework (touch, sensors, NFC, camera, etc...) then you may need to build out some system that allows them to easily get these apps that are modern but somehow can't be distributed through the MS store. Honestly, I think that this is a mountain made from a molehill. We are talking about apps that are designed to be sold through the store and take advantage of the new features...Why can't they be sold through the store again? Side loading for the sake of side loading isn't a feature.
I agree - I posted a better reply about trade-offs and my own situation in this other comment http://www.reddit.com/r/dotnet/comments/1hyd31/new_to_net_developingany_hardware_suggestions/caznn29 
Look, we are talking about custom written applications that have been rewritten to use the modern framework. Not all apps are a good fit for that. The ones that are will be valuable enough to justify the expense will be converted. existing apps can still be deployed by existing means. How is this "evil"?
You don't have to do modern apps. Its not intended to replace all existing desktop apps. Your app isn't a good fit for a modern app. What you might be able to do is build some new functionality that your users would find valuable that takes advantage of touch and sensors and new form factors. That would be a good fit. Maybe one day the winrt subsystem might be flexible enough too replace your existing app...but why fuck with your cash cow? Come up with something new for the modern framework...try to reuse some code, but deliver new functionality. As for your existing application, it can still be listed in the app store, like MS office, but then link to your existing sales and delivery mechanisms. that sounds reasonable right? Of course its not perfect...but I'm not sure what "perfect" would be...people just drop by your house on Monday and drop off money? Other than that you might try stepping back for a minute and looking into this critically. Modern apps aren't meant to be a 100 per cent replacement for all applications. The store model can still be useful for shops like yours. There...all better.
I've seen multi-monitor support 'work' in a web app. Basically you have to think of it as two separate applications sending DDE messages to each other. It's not pretty.
&gt; Its not intended to replace all existing desktop apps. Then why have they stopped investing in WPF and WinForms? Is this a temporary situation or are we expected to put of with their correctable flaws forever?
They haven't stopped investment in WPF and Winforms. There were enhancements in the latest version. They are both mature platforms...they will be incrementally improved...think of MFC. It's still being actively developed. "The new hotness" isn't the only thing happening...and just because you read people on reddit or hackernews saying, "WPF WTF???!!!!?? AMIRITE???!!!!" And if you really care or this actually affects your business then there are whitepapers from MS about what technology to use and when... or you guys could just keep complaining about everything.
I was at Build. They unequivocally stated that WPF would not be getting any of the performance improvements slated for WinRT/XAML. On the WinForms side I still have crashing bugs in their grid control from over five years ago. Yes there were a couple of updates in 4.5 that made things better for WPF. But when was the last time you saw a roadmap for it? When was the last time you saw any movement in the WPF Futures or Toolkit projects? I don't make these proclamations lightly. I've been dismissing the WPF|Silverlight is dead mantra for years. But at this point the evidence is overwhelming. You better be happy with what you have now because it is not going to get any better.
Jesus Christ. People have said the same thing about MFC FOR YEARS. I didn't attend Build this year, but I did watch most of the sessions. (I have in the past.) Were there any improvements to WPF? (hint...there were. maybe not the ones that you wanted.) .Net 4.5 had lots of new work that affected all kinds of apps including WPF. BTW there's a reason why WinRT/XAML is faster...ars technica did a great article on XAML's drawing speed problems before Win 8 shipped. So, have they gutted the existing WPF and implemented the core of it over again? No. Will there be incremental support releases. Yes. I mean really...they never drop backwards compatibility...your stuff will continue to be supported and run for a very long time. As far as new work...I don't know about you, but I would be implementing new functionality with the web browser control in rich client apps if I were building anything other than forms over data. Designers already know how to build for it. It's the model that windows is going on windows phone and in WinRT. If all you are building is forms over data...what do you really fucking care? Suck it up and keep slapping forms on that data and getting paid. Its a good life. The idea that they are dead somehow means that your code won't work in the future...and it surely will. Silverlight is supported for 10 years. People are still building new apps with WPF because it's the best easiest way to build a desktop app right now. Are people going to stop writing for the desktop altogether? I really don't get it. You can only build something if the technology is "the latest thing"? What about people with existing C++ code that got no "buzz" over the last 15 years? Did they just stop or something? Is WPF and Silverlight no longer the object of buzz and hype? That I would agree with.
&gt; I mean really...they never drop backwards compatibility...your stuff will continue to be supported and run for a very long time. Visual Basic 6 will continue to be supported as well, but that's a cold comfort when there are serious bugs in WPF that need to be solved. No framework is perfect and they all have bugs, that is unavoidable. But the social contract is that the developers will agree to use the frameworks with the expectation that over time the bugs and other issues will be addressed and you can eliminate the nasty work-arounds from your code base. When you get to the point where you know that it isn't going to ever get any better than you have to ask the hard question, "Am I willing to deal with these problems for the lifetime of my application?" For a lot of people the answer is yes. That's why we are still seeing new feature development being done with Visual Basic 6 and entirely new projects in WinForms. But for others the answer is a resounding no. Those people were willing to put up with the flaws for a year or two, but not the decade or more that their application will be in service.
And they will go to what exactly for windows desktop development? Are you saying that they will jump platforms and take the trouble to rewrite their apps for Linux or Mac because they aren't getting their favorite bug fixed in the next release? You are saying that they WILL take the massive amount of trouble to jump platforms but WONT spend a fraction of that effort to do some work-arounds or use an alternate supported desktop API? (DirectX? There are managed wrappers if you would prefer.) Furthermore this whole thread started about distributing WinRT apps via sideloading and how that was just the end of the world. It isn't. You are making this out to be far more of a serious bad thing than it is. If you have WinRT apps that need to be distributed inside your org there are methods available that range from the small to the very large. If you are an ISV then sell your WinRT app through the store the way that it was meant to be. If your app isn't a WinRT app then just list it in the store and keep doing what you are doing. Try to find some functionality that you can deliver that re-uses some code if possible that takes advantage of touch and all the new hotness...sell it...make money...donate to charity. Yay for you. If WPF isn't cutting it somehow you could always author a component in C++ and use the Direct* API's and plug that in. The MS developer story has NEVER been about one technology to rule them all. Or you could just keep talking about it like Windows development is coming to an end and sit around with a furrowed brow and worried grimace screwing up your otherwise sunny countenance. I for one hope that you look on the bright side and realize that there has never been a better time to be a developer...and donate money to feed the homeless and hungry. Cheers.
Given completely open-source MassTransit I don't understand why would anyone care.
More options in any market is always a good thing. I don't understand why anyone would think that there should only be one thing of each type to rule them all. For any given problem in engineering there are 100 ways to solve it and for your particular problem context about 30 or 40 can apply to you. Picking one "just because" is never a good strategy. Objective analysis based on your needs should always be considered. Particularly for a core component like a queuing message bus which can become a choke point in your infrastructure if you fail to select the right tool for your particular problem set. If you don't see a reason that typically means your experience and context has yet to give you a wide enough view of the various types of conditions that make different options viable in that particular area. 
I just made the move to 64 bit because i wanted the 8 gb of ram. Great investment. Vs sucks up resource
Paid support?
I have 16GB and I would still like more!
If money is your limiting factor your better off buying a shit computer every 12-24 months than trying to get one that will last.
I have 16gb and even with multiple instances of VS I've never used more than 4.
Fair point.
No, installation of a transport might be required. But that's not different from any other bus.
I'll bite, what reason do you see?
Nservicebus runs quite well in embedded mode. And I'm a huge fan of being able to check out and click run.
I guess it comes down to habit. I have plural table names in databases as well, as I consider a table to be a collection (therefore plural) of whatever class I'm mapping to it. A resource seems the same to me.
Hard to say without taking a deeper look at both tools. It can be very situation dependent. Some things I have seen is supporting odd deployments. Cross-platform support. Sometimes something as simple as a single config option or how it is implemented can make all the difference if the situation warrants. This is why analysis and thought is required. Granted if you are just throwing together a small app its likely not worth the thought. If you are looking to build a large, highly available app that is worth millions a year it is extremely valuable to do your due diligence.
I'm wondering what sort of apps you write and what your response time is. VS 2010 is a little sluggish. Do you have performance tips on lightening the resource use?
As a small-time contributor on MassTransit I'm actually *informed* about the two, which is why I made my comment. 
Actually, I'm doing very, very well with WPF. When paired with lightweight MVVM framework it is, for me, the cleanest way of writing business applications, especially considering the declarative UI and data separation. But that's just, like, *my* opinion man... 
Are you informed about all the possible scenarios such a lib might be used? I highly doubt you are as I know I would not even with all the insanity I have seen. The real world has some interesting ways of surprising you. Also you have just informed me of your natural bias so I am going to take your opinion on the matter with a sizable grain of salt.
I understand WPF quite well now. It's the XAML crap I hate. It's all sunshine and rainbows when doing straight forward stuff, but try anything non-standard and you're up shit creek. The last pain in the ass moment I had was the need to rewrite the DateTime-to-int Convert/ConvertBack methods because the DatePicker control behaves differently when used in a DataGrid. And then you have DLL hell. My current project uses Npgsql, NLog, Quartz.NET (with Common.Logging), PdfSharp, IniFileParser and SimpleInjector. It took me a lot of time and Googling to get them working together. Not WPF specific but fuck you for that too, Microsoft. 
We ran two proof of concepts for REST API development, firstly WebAPI and then ServiceStack. ServiceStack won hands down. It also runs on Mono.
Have you considered something like Nservicebus to manage these queues?
We have an test web app this is part complete / buggy. The candidate has an as much time as they want (within reason) to get to grips with it, and try and complete it. More senior developers pick up on the more challenging performance issues and harder bugs. Junior developers still get a chance to make something of the app. It is good test, without the developer having to start from scratch. It also shows that they can jump into an existing code base!
Are you serious? Not everyone uses MassTransit, and there are plenty of products that are built and deployed which rely on NSB...
Completely unhelpful comment follows. &gt; What exactly am I doing wrong? Using web forms and DataSource objects.
Alright, so just use the Entity Framework and handle data displaying/saving etc. with my own code? Because that's what I'm doing right now, and it's working okay.
Like I said, it was an unhelpful comment. Were *I* writing this, I'd be using MVC. I loathe and despise WebForms.
Hahaha! Yeah I've heard that, WPF is apparently the new thing, I just didn't really work with it yet and I'm also relatively new to the whole .NET ecosystem. I am forced to work with Visual Basic .Net for my part-time job, and the Windows Forms seemed like the right thing. Oh well :)!
No, WPF is not "the new thing". WPF is actually quite old. Unlike WinForms, it's also designed according to principles that are far more modern and easy to maintain. It also benefits from GPU acceleration. VB.Net is a perfectly cromulent language, that is nearly feature identical to C# (VB has XML literals, which is awesome, C# has unmanaged code, which is cool in some very limited contexts, they treat interfaces differently, but are otherwise identical). You will regret using Windows Forms.
i wouldn't imagine most of them will be upgrading - new transports aren't exactly something you normally care about for an already deployed solution. Most the other features seem pretty small. 4.0 seems like a new project kind of deal at which point comparing against masstransit seems reasonable.
What were the advantages to ServiceStack? Perf, or ?? I will have to check that out. 
You can get it all in an ultrabook, but it's going to be pricey. Getting it all in a laptop cheaper, and a desktop even cheaper. 
Bullshit. Many small businesses don't run a Windows Domain.
Side loading for the sake of freedom-of-choice *is* a feature though. There's really no need to argue about it though since Microsoft's craptastic new ecosystem is going to be a miserable failure until they allow more freedom. The Windows Desktop is not a walled-garden and it's not hardware-restricted. That's why businesses use it. Once that stops, the customers are going elsewhere. 
I think he's a fake-ass fucking dip-shit.
you don't need to install the subscription service?
I don't know for sure. But the getting started guide starts off with instalation instructions, which doesn't bode well. If you know how to do (or a link) I'd like to know. 
Oh, I see...I must be whining...because I disagreed with you. How is anyone "throwing cake down when [they] get it" here? If that's what you think, then you completely missed my point. What I'm saying is that businesses will simply vote with their dollars and not use the new restricted environment. I certainly won't be investing any time, money or software into Microsoft's walled-garden. If you think I'm wrong - just wait and we'll see, now won't we?
Use what you know best and just get it done.
Mostly web apps in VS2012. IME the main thing that makes VS sluggish is the amount of projects in the solution.
The bottleneck for project builds is msbuild. Compile the same files with a nant csc task and watch how much faster it is.
Visit Lenovo's outlet site for great deals
I tried working with a "reports application" template that comes bundled with Visual Studio. Has anyone tried this? Are their tutorials on this? Can I use C# code?
Are you a programmer? Who is the target for the reports? Who needs to make the reports? What is the time frame for the project?
The WCF RIA template makes it easy to expose your object model as an OData service. Many reporting tools can consume OData, including Excel with the PowerPivot extension. I've used this on a few projects.
Who peed in your cornflakes? Do you work for MS or something? You've got the requisite butthurt of some of the failed astroturf campaigns... Name **ONE** must-have WinRT app or API.
I like ORM's for general/business code etc but reporting is an area where sql still kicks ass. I don't know the current state of report templating but for actually getting the data sql will always be the way to go.
good lord...and you say **I** am whining? I actually think Windows 8 is a great OS, I just think they're missing the boat with their WinRT strategy; keep insulting everyone you disagree with, if it makes you feel better, go right on.
these are all great questions, thanks
til I'm completely retarded
Not really *unit* testing. Also this could have been a great example of TDD, but instead it includes tests for intermediate incorrect states for some reason.
The 3rd party app is VLC. (Videolan Video Player) I modified axvlc.dll that ships with VLC. My app needs to use my version because it needs some functionality that's missing/broken in the original. I could replace the original file that ships with VLC, however I'd like to leave VLC alone and just have my app use my version. If I replace the existing version do I even need to re-register the dll or can I just copy over the existing file? Any ideas?
One thing I've learned with Microsoft is to not be an early adopter.
This works for my program: Private Declare Function SetDllDirectoryA Lib "kernel32" (ByVal lpPathName As String) As Long Public Function SetPathToWrapper(ByVal vDirectoryPathToWrapper As String) As Boolean 'returns true if the dll is found and the directory is set successfully Dim tempResult As Long Try If Not DLL_Path_Initialized AndAlso File.Exists(vDirectoryPathToWrapper + DFC_WRAPPER_NAME) Then tempResult = SetDllDirectoryA(vDirectoryPathToWrapper) DLL_Path_Initialized = (tempResult &lt;&gt; 0) End If Catch ex As Exception DLL_Path_Initialized = False End Try Return DLL_Path_Initialized End Function 
Very cool! Thanks! 
too long, didn't watch? Well shame on you, but here is a summary. http://www.infoq.com/articles/Async-API-Design
That `ConfigureAwait(false)` stuff is going to make my code a lot uglier :(
They also recommend it from a performance point of view though, not just to stop deadlocking occurring... [edit:] the difference is actually minimal, a few minutes later in the video. [edit2:] further on again... if you want your async methods to be called easily from the UI thread then basically everything in the call tree should be marked `ConfigureAwait(false)` or you'll be posting callbacks onto the UI thread where it isn't necessary..
True, but the benchmarks suggest that won't really help all that much. I think he said that he needed millions of iterations for it to be noticeable. 
I can imagine if you're doing some async file read/write operations which copy big arrays of bytes around then scheduling the callbacks on the UI thread is going to cause stuttering. Problem is if this is buried deep inside some other code you won't know until it starts happening... it seems like the ConfigureAwait setting should be inherited by inner awaits or something?
Good point, that would be really annoying. &gt; it seems like the ConfigureAwait setting should be inherited by inner awaits or something? Oh it does. ConfigureAwait(false) throws away the context. And once its gone, its gone. The inner awaits have no way of knowing that you were once on a UI thread. So if you have a badly written library you can create a wrapper around it to 'fix' the problem.
Hi there! I appreciate your feedback. I would like to know why you said that it is not unit testing. Also this is a good example on how to integrate application security and Unit testing. And I tried to illustrate how the workflow change depending on the requirements. The different states of the testing is to illustrate this workflow and that at the end of the day you can do a great job in the Application Security world. 
Ok, I give up. What's he getting at?
Thanks. I figured it's a timeout, because it succeeds fast when it does, but if it fails it takes a really long time. However, I'm not sure if it is the script that's faulty. I mean the problem occurs on presync, because that's the first time I connect to the service. Also the script itself is as simple as it gets: move %1\_App_Offline.htm %1\App_Offline.htm exit 0 %1 is the path to the site, so it just renames a file to take the app offline. Maybe it's denied access to the file? I can't think of anything else that can make it fail, really. Anyway, I'll just try it without presync to see how it goes, but right now I can't reproduce it - deployed like 10 consecutive times without any issues. That always happens with these random bugs, doesn't it? Fucking haisenbugs, man. **Edit:** So I got it to reproduce, but only once. I opened the site after a few deploys, deployed again and sure enough this time it failed. Cool, I restart the service, remove pre/post sync and start deploying and opening the site again - it works. Great, I'm thinking, snarfy was right after all. Until I tried it again with the scripts and, of course, it's still working even with them. Dammit! Now I'm confused. The only error I managed to get was this: Performing '-preSync'... Info: Using ID '6efde083-7948-49b0-8a6c-383c2d492888' for connections to the remote server. Warning: Retrying the sync because a socket error (10054) occurred. Retrying operation 'Serialization' on object MSDeploy.runCommand (sourcePath). Attempt 1 of 10. Info: Using ID '7d5c5ce2-86e5-4959-8c78-1992198b5ffc' for connections to the remote server. Warning: Retrying the sync because a socket error (10054) occurred. Retrying operation 'Serialization' on object MSDeploy.runCommand (sourcePath). Attempt 2 of 10. This is with presync btw. and it still deployed successfully just on the third or fourth attempt. I should add that I don't think I've seen this socket error when it fails before. 
Sorry, let me clarify about the networking issue. What I meant is that it could be that at random intervals the network is down for just the right amount of time that hangs your application. It could resolve itself by the time you login and fix it. In the networking backend, it could be a loose network cable, an overloaded switch or router, a misconfiguration of the ip settings, etc. All kinds of things can cause network issues, most of which you have no control over. All you can do is plan for it. Even something a simple as a nested try/catch will catch random problems like these. Try Run application Catch 'It failed, but it could be temporary so try it again Try Sleep 2 seconds Run application Catch 'It failed twice, must be serious Throw error End try End Try You can start pinging your server from another server and see the actual uptime. You can roll this yourself, or you can use a service like [Pingdom](https://www.pingdom.com/).
aha, got it. thanks, I might give it a try. Even if it doesn't help solving this it still looks like a useful tool to have.
There is a validator on price, with text for the user to enter a positive price. That wouldn't make any sense unless the user is allowed to override the price. I see what you are getting at, but without more info its a lousy example.
Actually that is not correct :) It is possible to change the price in the version that uses the DefaultModelBinder And in fact it is possible to set a negative price :), but that is just a side effect of the main ModelBinding vulnerability. The full code is at https://github.com/o2platform/Fork_SportsStore_ASPNET_MVC and all controllers are at https://github.com/o2platform/Fork_SportsStore_ASPNET_MVC/blob/master/SportsStore.WebUI/Controllers/CartController.cs you should be able to run that locally using VS2010 (only extra requirement is SQLExpress). You can populate the DB using the sql scripts from https://github.com/o2platform/Fork_SportsStore_ASPNET_MVC/tree/master/DatabaseScripts )
Unit testing is an isolated testing of a specific unit of functionality. Not a 'feature', but a unit in a code sense. In C# it is normally a single class. All other dependencies of the class are mocked/stubbed. Testing the whole system has different names, for example, functional testing. However, security is non-functional requirement, so in your case I would say it is "security testing with NUnit". Also, this could have been a good example of TDD which is red, green, refactor. In your case you start with a green (but incorrect) test — why? It is better to start with a red test, then make it green by implementing header hiding. To preserve the step-by-step demonstration, tests can be built in a more focused way, so that a single test only asserts one thing. Then you can make them green one by one.
Well it seems like the Application Security Testing via NUnit is a more accurate name. I wonder what would be the right name in the market for this kind of testing. You are correct with your definition "A unit test is an automated piece of code that invokes the method class being tested and then checks some assumptions about the logical behavior of that method or class".Taken from the Art of Unit Testing. I would say that my example meets some of the items of the definition but not all and I agree with the idea of a different name. In this case, the System Under Test (SUT) it is not a C# class, but it is an interesting approach on how to test application Security. I agree with the idea of the TDD and I could consider in a future blog entries. Generally speaking, what are your thoughts about the approach of testing Security via this way?
Congratulations to the whole JetBrains team, and especially the developers and Q/A groups for getting this out of the door. You guys make my life and those of my developers better every day. You make their code better, and you make them better developers. Thank you.
ReSharper is worth every penny. I can't imagine writing C# code without it now.
Except that if ModelBinding is allowed to happen, by the time Cart.Validate() does its thing, the data could had been all manipulated. So yes, Cart.Validate could detect a negative price, but it wouldn't detect a wrong (maliciously changed) price (and that is assumed that Cart.Validate is executed with all requests, since for example the exploitable scenario that data could be changed in controllers like "public PartialViewResult Summary(Cart cart)" )
After being introduced to it at work, I had bought a copy for home use within a month. Been using it ever since. That was probably version 4 at the time, too. I'm also extremely excited for the coming C++ support, as I do quite a bit of C++ at work, on top of what I do with C#.
The whole design doesn't make any sense. Why does the AddToCart accept a Cart object instead of pulling it out of HttpContext.Session? Oh wait, it does pull from the session because it uses a horribly hacked IModelBinder that doesn't actually bind anything. Fix the design so that it actually follows ASP.NET MVC design patterns. I bet most, of not all, of the security flaws will disappear.
Whaaa. I have nothing useful to say so I'm going to cry about arbitrary definitions.
I agree, my definition of 'Unit' is much bigger than most, and anything that runs under NUnit is a UnitTest by definition :)
Yeah, I do have the same feeling. And most important if it adds value to the SDLC.
I think the idea is good, but you have to consider additional details. For example, you would generally want to test header removal in all environments (especially production) for all your web sites/services. Moreover, you would want to test it periodically, so that any new releases/system maintenance/IIS patches wouldn't break it again. This means that you would set up a periodic task somewhere that would do that, and make ServerUrl configurable in your tests. This tasks should collect test results and notify you when any one of them had failed. Now, at that point, it is not very important whether you are using NUnit or just manually running some C# methods — the largest part is surrounding infrastructure. Later, if you want to quickly test several servers, you will find changing ServerUrl somewhat tedious, so it makes sense to make a UI that will allow to select a server. At this point you have a security scanner, and again the underlying NUnit is not important — NUnit is useful when you want to make a lot of tests quickly, but having just a few security tests may warrant different approach.
Why have second type — isn't it the same as the first type, but all assert conditions inverted with `not`?
The correct terminology is important, though. If I see a UnitTests assembly in the project, I expect that it has absolute 0 dependencies on environment — those are fast and can always run in the CI build without additional work. Tests that hit DB — even if they create DB themselves — need a DB serer accessible to CI, need correct connection string, etc.
In some cases yes, but not all the time. The idea is to cover the two scenarios: 1. how to I prove that the security vulnerability is there? 2. how do I prove that the security has been fixed? on the 1st case we try to cover as many exploit scenarios as possible (for example running an entire fuzzdb list on a particular control) on the 2nd case we try to focus on the expected behaviour and structure of an fix (for example even including an AST rule to check of stored procedures (in an SQL Injection scenario) were being used) I also found useful (when writing the fix) the worklow of making all 'red greens' and all 'green reds' (which give me the confidence that the original exploit is not working and that the fix is done)
I saw the architecture tools and started throwing my money at the screen but nothing happened. Does that work in 2012 as well or just 2013? I buy my own licences because work takes forever to get new ones (plus then I can use it at home), and I just missed the upgrade cutoff from 6 -&gt; 7 last time and someone from JetBrains gave me the upgrade anyways after I wrote them. I'm guessing that won't happen this time. :(
No irony was intended, only hostility towards those who confuse "unit of functionality" with "method on a class".
I just had a quick look at that MVC app (from the book) and found a couple vulnerabilities with it :) Take a look at: [Nice business logic vulnerability and CSRF on the ASP.NET MVC Design Patterns book sample](http://blog.diniscruz.com/2013/07/nice-business-logic-vulnerability-and.html) The main reason that code is protected against ModelBinding vulnerabilities is because 95% of the controllers don't use Models as parameters
Good thing office decided to get an update subscription, after we had to upgrade from 6 to 7 to make it work with VS2012. edit: Now I just would need to know how to make an upgrade.
I do not see why you can't make both green by inverting the reds — you would be able to keep the tests in this case.
You say *idea on how a Software Developer can take advantage of this technologies and make sure that they are mitigating a security risk in code* — however this specific test (headers) is a lot about the configuration of environment, and not the code. That's, I suppose, my main point against this approach — NUnit and similar frameworks are not really made for environment testing. If the test is, for example, validating AST of C# methods to prevent SQL string concatenation, then I would have a different opinion — it makes perfect sense to have it as developer test in NUnit.
We are removing the ASP.NET MVC version header (X-AspNetMvc-Version) by adding a code change. We are doing the same to remove the X-AspNet-Version header. The Server HTTP header is a tricky one, because that header is added by the server, as it name implies. That means if you are running it on Cassini for instance, that is the value displayed. My approach is on how to make sure that you are not exposing those unwanted headers in the environment you are deploying (either staging or production). I can understand that you disagree with the idea of having Unit Testing applied to environments (I believe we can call it infraestructuretoo ) and I respect it, but you should not ignore that this kind of testing is also required an needed, specifically when application security plays such an important role.
Subscription-enabled keys should just work with v8 (provided that the free upgrade subscription period hasn't ended yet). Do they work with v8 for you?
I guess you're Jura? I think I just wrote you an email. :)
Is there a way to tell (besides installing R#8) if my license includes the upgrade subscription? I have no idea what we had requisitioned here.
That is a really well written post. Would you be interested in writing a full length article or even a mini-book on the topic?
Nothing specific yet, I was just impressed with the quality of your writing. Would you be more interested in a shorter piece like these http://www.infoq.com/articles/ or a writing a 40-60 page book on web security?
Yes, I have used the Microsoft.Reporting objects bundled with VS. The API for these reports does allow you to bind them to business objects, and I have done it. The ones in VS are .rdlc files, which means they're processed locally by the .NET framework rather than by SQL Server (these are .rdl files). Rdl stands for Report Definition Language, and the VS report designer let's you build them with the GUI. These reports have fewer features than third-party reporting tools, but they have the basics (sorting, grouping, summaries, etc.). Can't beat the price.
Yeah thanks, I put a post up there but it's one of those quirky problems that not many people knows about. No one who does .net ever looks at soap messages really.
That isn't true. I deal with WCF services and inspecting soap messages is pretty common. That is an invalid tag. http://pic.dhe.ibm.com/infocenter/adiehelp/v5r1m1/index.jsp?topic=%2Fcom.ibm.etools.xmlbuilder.doc%2Ftopics%2Ftxsityp.html If the client cannot fix the xml, you might need to write a filter to fix it before it is deserialized. 
I hate such methods. You can't see what true/false means!!
I agree! Now that C# has named parameters I normally do like "parameter: false" in the calling code to make it more obvious what's going on.
Without being a Telerik fan boy this is definitely a good solution. It supports POCOs.
Oh thats really cool, James is a redditor :) Im afraid to join some of these projects only because to me they are already so polished.
Craig I use bits of your library all the time! You've saved hours of work and your code is rock solid!
Is this your own project? Its great to see this type of project because up until now this stuff has been entirely commercial libraries.
I would love to see Linq support in a library called [PetaPoco](https://github.com/toptensoftware/PetaPoco). I think its the best little ORM. Personally Entity Framework is just so slow, people have traded in designer features for a 500% speed reduction. 
Hi there. Is each job in its own thread? Are they separate app domains?
Perhaps you and Craig need to get together and share code bases? Make 1 ultimate utility library.
You can bind to the updatepanel's endRequest event with code like this: var prm = Sys.WebForms.PageRequestManager.getInstance(); prm.add_endRequest(function() { //bind events here. }); And you can use that to inspect whatever content you send back in the update panel and manipulate it with js/jQuery. BUT, having used the ClientScriptManager and UpdatePanels in the past I would highly recommend not using either of them. There are much better ways to do this, though they'll require more client side code (which you're heading toward anyway). What I would recommend instead is using jQuery's $.ajax() function to call to either a .ashx Generic Handler, or for what you're doing probably an .asmx Web Service. This will give you much better control over everything and you won't have the overhead and headaches of UpdatePanels and the ClientScriptManager. This will also be easier to pack into a user control, because you don't have to deal with the problem of the control's parent page having or not having a ScriptManager. Happy to answer any further questions. 
I commend you on learning more about server controls. I do however feel that updatepanels are the spawn of Satan.
Yep ditch them. Learn Web API and KnockoutJS. Job done. You will never ever return to anything webforms related. Hell you could even learn Kendo MVVM and use Web API or Node.js
Yep, We have a website with some controls using update panels and some new controls using WebAPI and JS. Web api area load instantly even if there is several ajax calls. Update panels take 2 -4 seconds to load. 
Looks like that Entity Framework connection string is being used by a normal SQL connection. To fix, create another connection string with just the content from the "provider connection string" section of the EF connection string and pass that to your membership provider" The provider connection string in this case is "data source=(LocalDB)\v11.0;attachdbfilename=|DataDirectory|\MembershipProviderTest.mdf; integrated security=True;App=EntityFramework".
I would look at the code and see why it is ignoring your proverName attribute. It doesn't look like EF is mentioned in the stacktrace either. I would expect to see some call mentioning System.Data.Entity.
 I ended up replacing the connection string with this. &lt;add name="ConnectionString" connectionString="data source=.\SQLLOCAL;AttachDbFilename=|DataDirectory| \MembershipProviderTest.mdf; Integrated Security=True; User Instance=True" providerName="System.Data.SqlClient" /&gt; For some reason it kept complaining about the format of the string. I'm sure I'm not using the Entity Model now. I'll have to figure something else out. This stuff is all new to me. 
Judging by those screenshots, I think you should be able to use a WPF grid - make each domino have a RowSpan of 4 and ColumnSpan of 2 or vice versa. Start out putting dominoes on the even Row and Column numbers, and when a double is played orthogonally, use an odd coordinate.
You could use a Canvas with data binding. Do the calculations for Canvas.Left and Canvas.Top in your ViewModels. It's hard to say for sure without knowing what your data model looks like.
This looks like a job for RX. eg: [this](http://www.gideondsouza.com/blog/implementing-simple-instant-search-with-rx-reactive-extensions) or [this](http://introtorx.com/Content/v1.0.10621.0/01_WhyRx.html#RxInAction).
This is approximately what I have in mind. In my model, my board isn't presently aware of any coordinate system - it's just a list of bones (dominoes). I'll probably have to implement something like this first before I can consider binding to it. Thanks for the input!
I'd prefer to have some nice animations and be touch enabled so that I can play nicely with Windows Phone. As of right now, I'm using a ListView to display all bones in the player's hand, and I was leaning toward having a Grid (as mentioned in another comment) to serve as the board. I'm not sure if this will allow for good touch navigation and animation (e.g. dragging a bone from the user's hand to the appropriate location on the board), which makes me think that drawing on a blank canvas might be better than my currently favored approach. When you suggest a custom control might be necessary, what are some examples you think I might need to implement? Is this mostly necessary if I'm drawing on a blank canvas? I'm curious to know what most games like this do. Are they typically drawn on a freeform canvas? I feel that most XAML elements are nice for very structured UIs, but when the form of what needs to be displayed is dynamic or complicated, you have to resort to drawing on a blank canvas. Perhaps this is the GUI noob in me speaking, though.
&gt;Yeah, I agree that the canvas drawing and data binding aren't mutually exclusive. Kinda strange that he mentioned that. WPF is pretty unique in that regard, if your not familiar with it then this is a logical assumption.
Sounds like good advice. I think for the immediate short term, I'll use a Grid until I can get some basic functionality going. It does sound like in the long run, I'll be best served by implementing your suggestion, though it sounds like a bit of work before I get a payoff - I'll look forward to your more on this tomorrow! :-)
It would be great if you give us an update when you are further along to show us how you did it.
Heheh, thanks. Don't worry about putting too much time into it, but if it floats your boat I wouldn't mind seeing what you come up with :-) I don't have too much free time myself to work on it, but at the moment I'm working on improving my Model to include a basic grid coordinate system that I can bind to. I'm not sure if this is just me, but this sort of stuff seemed a lot easier to me with ActionScript and Flash. Maybe it was because it was an integated tool rather than separate, as with Visual Studio and Blend..
Will do. Might be a few months though haha. My attention to this project seems to come and go :-P
Thanks for the tip!
I hope Jiri keeps up the good work. This data provider makes Firebird a viable choice for .Net projects.
That ASP.NET suspend feature may finally make shared hosting bearable.
That slide show was fucking awful. Microsoft is fucking up. .Net is their masterpiece but if their OS and Office software are any indication they'll be breaking .net next.
Here's the blog version if powerpoint slides aren't your thing. http://blogs.msdn.com/b/dotnet/archive/2013/06/26/announcing-the-net-framework-4-5-1-preview.aspx 
All I get is "Sorry, we ran into a problem. Tell us about this problem to help us fix it.". And then the link doesnt work.
8 and 2013 are great, imo, as long as you can get over change.
I was referring specifically to RT and how that slideshow worked on my phone. Windows 8 is great but the store apps are pretty useless on my desktop. I like the start screen though.
&gt; head.innerHTML = head.innerHTML + "&lt;script &gt;"+scriptfile+"&lt;/script&gt;"; Your script does not have a src set. Specify the src and type to start with.
Sadly it does not track external file easily. what I did I embedded the code and then called it once DOM was ready. It worked then, Thanks
Every time I go there I feel more and more that it's the Rust and Go circlejerk.
Ohhhhhh, thanks!
You do? Home come?
They send way to much data back and forth making them really slow.
You know what's even better? Giving people a choice and seeing what option they take. Change isn't automatically good.
This sub is for programming using the .Net framework. I would suggest trying a more appropriate sub, like /r/24hoursupport.
Alright, thank you friend.
Isn't this kind of just an ad for pluralsight?
Azure related only? Sweet.
It's great little tutorial but you should call it "autocomplete" and not "wildcard", because a wildcard search is something completely different (more like regex)
Good point. I was trying to think of what would best describe it. Yeah, it is REALLY entry-level basic, but I found myself googling how to do this simple thing with LINQ, so I figured I wasn't the only one...
Actually any connection that returns a chunked encoded response. Just that Azure is the most likely culprit and the basis of this particular bug report.
.NET Evaluates the expression tree of the LINQ statement, parsing known expressions, such as StartsWith and EndsWith into counterparts in SQL. Basically, instead of actually executing the methods, the method names/references are looked at, and used to write SQL. ... if that makes sense.
sweeneypng does have a point, though - I believe I rather incorrectly described these as LINQ methods. I agree, they are methods of the string class which, as you so properly describe, are parsed by teh LINQ framework. I may have to update the post to clarify and correct my misidentification!
Don't you mean *Reflector*-style?
From what I can read in the post, there is no real mention of LINQ to SQL, which is quite different than LINQ itself. It's also worth noting that I've encountered problems with LINQ to SQL when I used IEnumerable&lt;T&gt; instead of IQueryable&lt;T&gt;. LINQ to SQL would load the entire collection (or table) and then use regular LINQ, which basically just executes the lambda for filtering. Huge performance hit if the SQL is not affected. It might be worth it to explain that in the post.
Good points all. In this particular case, I am loading an IEnumerable passed in as a parameter with the assumption that it already contains the superset of item against which one might want to filter further. I agree it might bear mentioning important things like this. I'm on the road at the moment, but when I get back I may either update the post to at least mention these points, or write a new one exploring this further. Thanks for the feedback!
I miss the days when we'd code tries for this type of stuff. 
&gt; Export Assembly to Project: based on high demand, we have enabled saving decompiled assemblies as Visual Studio projects. Finally. At least now it becomes relevant to compare this product to [JustDecompile](http://www.telerik.com/products/decompiler.aspx)
So how do they compare in the big picture?
Well, comparing both products... I met a bunch of you JetBrains guys at Techdays this year, and I asked you about dotPeek, and why it can't decompile to projects. You started tasking about morals, and stealing source code, or something... So far I think JustDecompile is better because of the easy support for de4dot and reflexil. I have not used dotPeek in a while, but besides creating project files, injecting ILCode into assemblies is a must for a good decompiler
Got the point on de4dot and reflexil. Reg. the other stuff, not sure who you talked to when you heard about morals. (Which Techdays was it btw? Belgium? Netherlands? elsewhere?) With all my respect to the moral side or things, this is an absolutely irrelevant argument because the product is there to be used for legal purposes, and the two main use cases from my understanding are expressed in the two quotes in the [related discussion](http://www.reddit.com/r/programming/comments/1k0ksm/free_net_decompiler_from_jetbrains_updated_with/): &gt; Yeah, but I've had to decompile other people's shit to fix it. and &gt; My hard drive crashed a couple of weeks ago and I lost a bunch of source code. This will help me recover everything from the binaries. If someone is using the product for cracking, it's not a vendor's problem, it's a problem of law enforcement in a particular territory. For use cases that are legally fine though, it does make sense to provide features that simplify certain common tasks to the greatest extent possible. With previous dotPeek versions, you could still decompile all types in an assembly, hand-write a .csproj or create a solution from existing souces in VS and be fine with it, now it's just way more convenient to do if you need to do it.
Don't forget Contains also gets translated to SQL. Very useful. In any case, using a method that doesn't translates to SQL will give a pretty clear runtime error. Try using ToLowerInvariant() instead of ToLower() for an example.
Since there is no source I would venture to guess your using the built in membership provider and entity framework? You need to define 2 different connection strings, 1 for sql membership provider and another for your entity framework connection string?
I have tried others, ReSharper is by far the best, the least invasive and the most intuitive. I pay up for a personal license every release.
This doesn't really have anything to do with .net specifically but it's useful information none the less. It seems your serial downvoter is asleep at the wheel today (what's up with that?).
Uh oh, looks like the 12th doctor is only going to be in one episode!
I guess it's related because ".NET" is in the blog's name?
Yeah, might not have been "on the money" as a match for this subreddit. On the other hand, if you're a webdev working in .NET . . . might be useful. Sometimes I just get excited lol . . .
Have you looked at GameWave yet? It would be impressive if we had a .NET interface with that kind of functionality.
Just stumbled on this - how is this a wildcard search? This is just a startswith search.
SignalR is one of my new favorite tools to use. After writing so many ajax calls on timers, this was an awesome replacement.
WebForms and MVC are pretty different. If you want to get a low level view of how the webforms framework works (instead of just rote memorizing stuff) I highly suggest picking up a book like this: http://www.amazon.com/Developing-Microsoft-Controls-Components-Pro-Developer/dp/0735615829/ref=sr_1_2?ie=UTF8&amp;qid=1376688466&amp;sr=8-2&amp;keywords=custom+server+controls There are a few. Any of them should work. Once you understand how custom server controls are made, the lifecycle of controls, how the controls make it out to the output stream and the lifecycle of the page; everything else (in webforms) makes sense much more quickly. It's uncommon to start with custom server controls early, but it will be a massive help when you're debugging problems that don't make sense. 
treat webforms and MVC separately, the methodology is so different knowing one doesn't necessarily translate to being able to work with the other. As far as topics go, for webforms it is vital you have a good grasp on the page event life cycle and how this relates to master pages, user controls and the page itself. Also its good to know webmethods and if you use jquery, how to properly communicate with them through jquery. learn a sql connector and how to interact with a database, whether you use sql server (express) or mysql doesn't really matter, mysql's connector.net modeled itself after sqlclient so the differences between interacting with sql server and mysql are pretty much relegated to just the sql syntax you'd use. With basic database connectivity, master pages, user controls and page event life cycle (for webforms) you should be well on your way to being able to produce something of value, at that point its your imagination.
no problem. Good Luck.
IMO don't bother learning web forms unless you want to work on old code. Mvc is the way to develop any new application. 
Love SignalR, I believe the next version is out soon too. Great for rich UI on desktop &amp; web.
Seconded. Don't bother with Webforms unless you have a really good reason to.
Learn MVC first. You can take the concepts from there so you have a structured way of working with web forms. The tutorials from Microsoft will get you up to speed on entity framework, code first, c# and linq. Find some web forms tutorials after that.
In that case it's less important. I find MVC to be quite a bit less complex than web forms. There is a lot of power sacrificed to gain that simplicity; but it's power that isn't often used (or used correctly) anyway. You won't need to dive into the innards of server controls if you want to focus on MVC.
I disagree, to a point... In a perfect world I think you'd learn webforms first and then hop into MVC - mostly to understand some of the more fundamental points of how ASP.NET works deep down, and the gotchyas you'll encounter with types of integrations, or site changes. If you're going to do big, or hard, projects with ASP.NET (especially if it will have anything to do with legacy components), knowing how everything was put together "back then" will save you a lot of pain. It also makes what's happening at all points in MVC pretty 'shallow'. That said, and maybe more relevant for most of the web developers out there, in terms of getting up and running with greenfield web projects that are mostly customer-facing (ie most websites), MVC is the part of the stack getting all the love, it's faster, better, and the future. The flip side of that, is that someone who can muddle through server-side controls in webforms is a bit more employable. 
Argh. In the name of all turkish speakers, this error has to go away. Never use toLower or toUpper. Use the appropriate string comparison overloads.
There is a ton of stuff at the ASP.NET website, and a ton more (although more generic to all of .NET), at the Channel 9 site. http://asp.net http://channel9.msdn.com/ I agree with the basic sentiment that MVC is the future, but it doesn't hurt to at least understand WebForms (if you will be looking for employment). 
I wanted to chime and point out that you can strongly type signalr hubs using dynamic proxies. I show how to do that here http://onoffswitch.net/strongly-typing-signalr/
IMO the easiest way to learn any of this stuff is go learn from developers. PluralSight is the simplest resource. You watch videos, they walk you through it with projects. Below is a fundamentals course on MVC 4. http://pluralsight.com/training/courses/TableOfContents?courseName=mvc4&amp;highlight=scott-allen_mvc4-m6-mobile!scott-allen_mvc4-m5-async!scott-allen_mvc4-m1-introduction-i!scott-allen_mvc4-m2-introduction-ii!scott-allen_mvc4-m3-optimization#mvc4-m6-mobile
See the previous comment - bad choice of naming in the title. Was having trouble thinking of what to call it. In the past, I have done such things using wildcards, so . . .
Although I agree the MVC design is more universally used, is "the future", and ASP.NET MVC mostly follows the pattern, it also uses "HTML Helpers" which function in a *similar* way to ASP.NET WebForms server controls. Also, they make the markup look more Classic ASP markup, i.e., ugly. Learn both. :-)
I'll tell my boss. In the meantime send me an email at jonathan@infoq.com and I'll make sure you get a copy. EDIT: I'm told that it is fixed now.
I am getting a 503 after using my microsoft account as well. Thanks
umm... Unfortunately, there is no transcript available for that video. Please try a different one. I tried a lot.
Yes I am. Thanks. I turned the project in, but I still want to figure out what I did wrong. I'll look into it and see if I can get it working properly.
I've used these in the past. There might have been some settings elsewhere that caused my project not to function properly.
Hi mogawowo, Thanks for trying it out and sorry you were not able to get much use out of it :-( There are indeed some videos which do not have transcripts accessible via the Google API itself, so unfortunately I cannot do much about those. Are the videos you tried marked as having transcripts on YouTube? You can find out by adding ,cc at the end of your search term on YT. If it has no transcript there, then my tool cannot help out much. It goes off the video's existing transcript, it does not do anything to generate it automatically.
I have tried a LOT, can you provide at leasr 2 others that actually work, This should have a transcript: http://www.youtube.com/watch?v=t0usCKeFGfI
Okay I got one to work: http://soonerdev.com/videos/browse/GetSummary.aspx?videoexternalid=xX_6xylyE8I While this is a cool bit of code, it is imho, not very useful.. eg the extracted data doesn't really match the videos and I can't think of any real use for the code?
I find it interesting that his takeaway from TypeScript for C# was the importance of "dynamism" when dynamism was exactly what TypeScript tries to remove (to some degree) from JavaScript.
I just wish they would try to make the ide's for C# and VB.net more similar. Edit: for those who are confused, different teams made the IDE's for c# and vb.net, which is why there are many subtle and several major differences between them. Yes VS is considered the IDE, but each language actually has their own IDE inside of VS. VS is more of the backbone.
I think he meant it more in the sense of dynamic data. I would love to see F#-like type providers in c#.
They both share an IDE (Visual Studio) - so what do you mean? The mechanism for entering VB? Do you wish it was more like C#, or that C# was more like VB?
When VS was developed different teams made the IDE's for VB and C#, which is why there are so many subtle differences. My main gripe is with C#, VB's way of adding event page handlers through dropdowns is far superior to the near non existent way with C#. Adding a page event in asp.net in C# means that you pretty much have to know the name of every page event, while in VB, you can get a list of all of them and add it with a click.
I cant agree with you - but then I'm a C# dev :) I've used both, but not nearly as much VB as C#. Tell me if I'm wrong, but this is how VB has always worked? Whereas the C family of languages have always been straight text-entry. You'd be pissing off a large number of people if you changed things up, but I guess why not make it an option? Intellisense gets around the problem you are describing reasonably though, doesn't it? You can just type 'this.' (or even just Ctrl-K, L) and then you get a drop down with all properties, methods &amp; events - just look for the event icons.
So, this post is close to a week old. I hope I'm not too late. Microsoft actually has some pretty good training courses that you can go through for free. [C# Jumpstart](http://www.microsoftvirtualacademy.com/training-courses/developer-training-with-programming-in-c#fbid=4g7wjX7R5Yp) [ASP.NET Jumpstart](http://www.microsoftvirtualacademy.com/training-courses/create-web-apps-with-asp-net#fbid=4g7wjX7R5Yp) I used the jumpstarts as a refresher a while ago after I got stuck developing on Oracle for a while and they are both good overviews. That said, when you are looking at doing MVC .NET development you are really talking about three things. Learning C#, learning about the .NET framework, and learning how to develop in Microsoft's implementation of the MVC framework. I would learn in that order. Since you have experience with Java, C# should be fairly familiar to you. I'd still recommend skimming over the basic differences. Once you've got that in hand, it is good to learn about the basic offerings of the .NET frame work. I've found that [C# 5 in a Nutshell](http://www.amazon.com/5-0-Nutshell-The-Definitive-Reference/dp/1449320104/ref=sr_1_3?ie=UTF8&amp;qid=1377211583&amp;sr=8-3&amp;keywords=c+in+a+nutshell) does a great job at going over both C# and the .NET frame work. It is dry, but worth going over. Once you've been through the first few chapters, you can pick and choose where you want to dive in next. IMO, LINQ is great. Then, once you've got a good grasp for C# and the underlying framework, it is pretty easy to tack the MVC model on to it. The biggest problem I've seen is devs trying to learn every thing all at once. Depending on your experience level, you may be able to dig right in. Best of luck.
Ohhhhhh!
I wish they would just make a Format Code button, instead of having to drill down through the menus or memorize key shortcuts
Type providers are just .NET assemblies and they do not use any F#-specific types. The ITypeProvider interface could be consumed by any .NET language including C#, so if C# designers wanted, they could reuse all the great providers already built for F#.
&gt; You might as well call c# visual c C# has more to do with Java, J++ and Delphi than it does with C. VS2012 has a simplified editor screen mode, even full-screen mode.
There's no reason to bother with the intricasies of viewstate on the client and how it effects the control loading on the server, or the various event phases. That's just bullshit that needs to go away. Of course, if you need to dig in, there's no way around it, but I see no reason to seek it out willingly. I can still remember the first time I read infinite loops viewstate blogpost ... chilling stuff
This was a hard article to write. Very interested in feedback. The target reader is obviously more on the beginner side of the spectrum (at least, beginner to MVC). It was difficult to come up with meaningful examples without completely clouding the topic with explanations of business cases.
I've personally used eazfuscator (the earlier, free version) and Themida to protect my application. I previously used Obsidium, and someone eventually cracked my application, which is when I switched over to Themida.
It is less about security and more about decompilers, like DotPeek, able to recreate the VS projects now; no reason to give our competitors our code base without obfuscation. I'll check out CodeVeil, thx.
Honestly don't waste your time. If your code is running on a client machine, then you've already given them the keys to the castle, so to speak. It's better for the majority of your application to run on a server somewhere, far away, and interact with them via a common API such as ServiceStack or something else that's fast. Client side code, especially .NET isn't secure.
I'm a dot net fan and always prone to do anything to bring more people to the dot net world, but isn't that comparison a bit silly, and thus, missing its point ? 
I know very little about wordpress from a technical perspective, but on the other hand I know quite a lot about Umbraco. Based on that, that comparison chart is quite useless. The facts about umbraco are wrong, and afaik, so are some of the facts regarding wordpress. Also, the article really doesn't conclude which one is better. 
You can do much much better by understanding your profile: // ________ Compiled ____________________________________________________ Console.WriteLine("Compiled -------------------------------------------------"); stopwatch.Start(); Compile(expression); for (int i = 0; i &lt; TotalCount / 100; i++) { CallCompiled(_random.NextDouble()); } stopwatch.Stop(); Console.WriteLine(stopwatch.Elapsed.ToString()); stopwatch.Reset(); ... static Func&lt;double, double&gt; compiled = null; private static void Compile(Expression&lt;Func&lt;double, double&gt;&gt; expression) { compiled = expression.Compile(); } private static void CallCompiled(double value) { compiled(value); } This beats Func in my testing by 2 orders of magnitude (you have to switch to a log scale to even see it in the chart at under 0.01 seconds). If there is a lesson to learn here it is to not prematurely optimize. I took the slowest version, extracted a point which was constant relative to the loop and made it over 100 times faster than the fastest version without considering anything else in his code. Write your code in a way that is readable and easy to understand. After you have done this and you come across slowness, run a profiler and identify why it is slow and only then should you optimize. Anything before this may merely be an added cognitive load on your future developer (oh and by the way: don't get rid of the unoptimized path, there may be a future point where the correct optimization is different).
Actually it sucks hard. To create a good application with WPF even LOB you need to pay to get good DataGrid and tons of WPF controls that arent provided with WPF.Like devexpress/telerik / component one etc. Otherwise it is very painfull to do all these shit. But in a web environment you can do almost anything free as there are tons of free ready stuff. I 
Learn MVC first if you don't understand the architectural concept otherwise making the jump from Web Forms to MVC could be difficult to wrap your head around.
They all have their own equivalents. All ILDASM does is save a download.
Kinda handy . . .
Is that a Xamarin link in an official Microsoft document?
It does seem like a useful resource, however the PDF file is seriously unoptimized or just resource-intensive. Even on my relatively high-end system, Envice freezes for up to ten seconds whilst panning around or clicking anywhere and Chrome just does not load it at all. Where may I contact the creator, if possible, to let them know of the above? Would be a shame for such a resource to be inaccessible to others.
It would be cool to see a poster or interactive page for "Our .NET Universe" instead of the "Microsoft .NET Universe" from the perspective of VS2013. This... not so cool. The Mr. Infinity and The Professor posters that came with (I think) VS2003 however were cool in a very corny way. It is refreshing though to see Xamarin acknowledged on something like this.
Is it possible to get this printed as a poster? 
Because art.
hahah love that the Prism group hasn't been renamed after all the NSA coverage.
I think I'd feel less violated by the NSA's version of Prism than the Microsoft one...my God, it's just awful.
what's wrong with Prism? Just curious. 
Probably, but I can't guarantee the links will work.
With a title like this I think people are expecting code examples and links to acquire any need libs/docs. Not a tiny missive and instructions to "Go sign up"
What does ETW do for me that I cannot already do with the base System.Tracing libraries? Writing to the event logs is a core part of .NET and based on the fact that ETW is using tracing lib attributes for prioritization this smells like yet another wrapper for .NET tracing libs.
You're just not trying hard enough.
Kind of funny: click on OP's link...new site. Click on the .NET poster link...new site. Click the Download button...nav to the download page (with *Install* instructions). Click OK to download...save zip file. Extract zip file...expands into a new folder. Open folder...finally open the PDF of the poster. Vintage Microsoft rigamarole.
System.Diagnostics.Tracing is the .NET wrapper around ETW. ETW allows you to cheaply raise tens or even hundreds of thousands of events per second, something the Windows Event Log can't even remotely handle. The Windows Event Log Integration for ETW allows you to easily copy a subset of those events to the windows event log. That way you don't explicitly log your common, occasional events to both places. In summary... * ETW: Log everything, listeners will ask for what they want. * Windows Event Log: Only log the important stuff. Make sense?
Ahhh... one more swift kick from Microsoft to my Silverlight-balls...