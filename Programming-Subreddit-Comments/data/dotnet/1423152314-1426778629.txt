vNext, the .NET core assemblies being ported to Mac and Linux, isn't completely finished yet. When vNext is completed, you should be able to run ASP.NET on Linux or Mac. There have been a few tutorials that show you how to compile ASP.NET and run it on Mac and Linux. I recall seeing an example using Nginx as the web server. As for databases, there's already libraries for PostgreSQL, MySQL, and NoSQL that you can use. Those should also work once vNext is complete. As for docker compatibility, I think that's one goal, but I suspect there will be a future solution for Azure that does something similar. All this is still being developed. Pretty excited about this development, as it will give me much more flexibility in developing for different platforms.
&gt; As for databases, there's already libraries for PostgreSQL, MySQL, and NoSQL that you can use. Those should also work once vNext is complete. I was wondering if they were as stable as the sql server integration, are they? &gt; As for docker compatibility, I think that's one goal, but I suspect there will be a future solution for Azure that does something similar. All this is still being developed. Wasn't really talking direct docker compatibility but I heard in a talk when the first .net corefx was opened, that there will be similar functionalities for the deployment, were they talking about azure (probably not) ? 
&gt;I was wondering if they were as stable as the &gt;sql server integration, are they? That's something you're going to have to test yourself. Stability testing depends on more than just the Data Provider. If you're referring to maturity of codebase, I checked [Npgsql](http://npgsql.projects.pgfoundry.org/) and it's been in development since 2008. &gt;Wasn't really talking direct docker compatibility &gt;but I heard in a talk when the first .net corefx &gt;was opened, that there will be similar &gt;functionalities for the deployment, were they &gt;talking about azure (probably not) ? I'm pretty sure it's Azure. They already have one click development for websites, I don't see why they would just stop there. It would be nice to be able to adjust scalability of individual applications based on load, instead of a VM wide scale. 
Download VS 2013 Community 
&gt;My advice – use sparingly and carefully in places where your context is very clear from the rest of the code and don’t do it with many static types in the same scope because you might end up with less readable code. I have complained about this feature quite a bit (static using statements). Ever since the inception of var, people have managed to over use so much in some cases, I can't tell what type anything is. I have a bad feeling this is going to end up the same way. I just want to remind people that a lot of this stuff is very useful, but only when used properly. Var and static using statements can be useful, but they aren't the ultimate solutions to clean code. Putting *var* or *using static* on everything doesn't automatically make your code cleaner, nor was it intended to be used in such a way. I say this because many programmers learn a feature like *var* and proceed to wedge it into everything. Please take the time to stop and learn about the appropriate uses of a language feature. For the sake of the programmer who is going to be looking at your code later on.
http://blogs.msdn.com/b/webdev/archive/2015/01/14/running-asp-net-5-applications-in-linux-containers-with-docker.aspx
I'm think it's always good to keep track of what the tip of the iceborg is doing. Nice mention of the Open Sourcing .Net towards the bottom.
thanks for the answer, did you really miss the lack of async/await ? I really never used c# and I was a little bit excited reading about futures support in the language that are used heavily(?) across the framework (even the demo/base app for mvc project that visual studio uses them for the auth part), and being used to spawn a celery task even for minor things that a promise could handle that was a cool fact and a bunch less of services to maintain.
Haven't seen this before. I also haven't done .Net for a little while. Nice link. 
If this is yours, I'd suggest mentioning that VB has had static imports all along. Not sure how the implementation differs.
No, but to be fair I'm not a heavy user of async/await yet, so I can't speak to how good of a feature it is. ...and just because you mentioned celery, we have some cool alternatives to that in .NET-land like http://hangfire.io. More toys here: http://www.hanselman.com/blog/HowToRunBackgroundTasksInASPNET.aspx
&gt; Ever since the inception of var, people have managed to over use so much in some cases, I can't tell what type anything is. Use your IDE?
Winforms? Passola. Appreciate the amount of work that must have taken though.
What? No NCrunch?! :P Seriously though, I've been using [NCrunch](http://www.ncrunch.net/) for ~3 years now and it is by far the most useful tool a modern .NET Dev can have. Even more useful than ReSharper.
Can you show us the exact code you're using to OCR each image? I've done this before, but I forget exactly what needs to be done. But you have to set the right options to get it to work correctly. Also, try to crop out the lines and dashes.
This is great work. 
Thanks for your quick reply :) Currently, the code is this (for English, but I'd rather use it with a Korean font, "Dotum"): Pix img = Pix.LoadFromFile(imagePath); string lang = "eng"; using (var engine = new TesseractEngine(@"./tessdata/", lang)) { string textLine = ""; engine.SetVariable("language_model_penalty_non_freq_dict_word", "0"); engine.SetVariable("language_model_penalty_non_dict_word", "0"); engine.SetVariable("tessedit_char_whitelist", "0123456789"); textLine = engine.Process(img, PageSegMode.SingleBlock).GetText(); textLine = textLine.Replace(" ", ""); return textLine.Trim(); }
Coz WPF is newer. I find WinForms a lot easier to work with and you can build things far quicker.
Someone has taken the time upload an open source library and all everyone here seems to be doing is hating. You don't have to use it and if you want a WPF build one yourself. I wonder how many of the haters ever create any OSS libraries themselves.
I think one big reason is because WinForms is so outdated that most folks choose to let those skills atrophy and rightfully so since it's not exactly in demand. While this is an awesome library, i doubt many find a use in dusting off the ol' winform projects to give it a try for a greenfield app. That being said, i can see how useful it would be to those who are supporting legacy software and would like to update the UI.
I guess it depends on your area. Although I primarily work with WPF, there are still a crap ton of businesses who run off of WinForms.
Without a doubt; just like there are a metric ton of business still supporting pascal mainframe applications. Not only are winforms a thing of the past but they aren't fully supported on mobile; arguably the last bastion of new fat-client development work.
Can you add couple of screenshots to the github page?
have you ever used those frameworks instead ov mvc for some project? what kind of projects were?
That would be acceptable if people were polite with their criticism.
I don't see anything wrong right off the bat. I thought it might be related to the PageSegMode, but it looks fine. I can play around with it tonight, but it'll be awhile before I can get to it. The only other thing I would say to look into is the DPI of your image. I had a similar problem back in 2013, where a small block of text couldn't be read by Tesseract. Someone on SO mentioned the DPI issue and I'm pretty sure that fixed my problem. You can read the SO thread [here](http://stackoverflow.com/questions/16638861/the-tesseract-ocr-engine-isnt-able-to-read-the-text-from-an-auto-generated-imag).
WinForms doesn't work on Mono, that might be a reason
You've never seen letters in serial numbers? Also, what about dashes?
Does signalr work properly?
From the announcement... "Microsoft.IO.RecyclableMemoryStream is a MemoryStream replacement that offers superior behavior for performance-critical systems. In particular it is optimized to do the following: * Eliminate Large Object Heap allocations by using pooled buffers * Avoid memory leaks by having a bounded pool size * Avoid memory fragmentation * Provide excellent debuggability * Provide metrics for performance tracking" [GitHub repo](https://github.com/Microsoft/Microsoft.IO.RecyclableMemoryStream) [NuGet package](https://www.nuget.org/packages/Microsoft.IO.RecyclableMemoryStream/) More details in the blog post.
Shouldn't you be using the SecureString class to pass in password &amp; message? 
http://www.asp.net/get-started Good luck! You can do eet!
thanks. hopefully I can get it down in the next few months and get a bunch of tutorials under my belt to understand all the syntax's. I understand programming logic and can do much of the basic stuff, but when it comes to arrays and loops, i have a hard time with them. 
If you are not keen on development, why have you applied for a job that deals heavily with ASP.NET, C#, HTML, CSS, and Javascript :D
Fair enough, but Stay focussed on changing your role if that's what you want. Did my student placement as a dev, then took the best paying job I could get. It was Dev work. 7 years later, still a Dev. Degree is in networking. 
I know, for that you need to understand the concept of garbage collector. I will let you know when its done. This just an basic idea, that destructors are called automatically by garbage collector.
That's cool. Why is it not in the System.IO name space? Seems pretty redundant having two IO's...
You sound excited about your current position and the technologies you work with and pretty apprehensive about leaving for this new place. That should tell ya something...
Good point I think I will decline the offer, thanks for the reassurance :D 
I know I'm not really responding to your request but here are some tips from someone who's been working with asp.net for about a year now: * understand how the framework handles requests and the request lifecycle * templates and the like do a lot for you but become somewhat familiar with the routeconfig * model binding on posts seems like pure magic. Because it is. But read up on how it's done and especially how collections are handled on posts. And once you learn the current framework, prepare to relearn it (somewhat) as vnext is pretty different 
Don't ever chase the dollar. If you're in a tech stack that you love and the work is good and meaningful, then stay. 
Yeah I could see how that would be the case, thanks for the advice!
Best exercise is to just start writing it. You'll pick it up online.
In 2013, I left a job with C# that I mostly loved (except working remotely and gaining weight) to work on more open stacks--node.js, Scala, etc. I enjoyed that work, but not as much as C# and the community and tooling around .NET. By the middle of 2014 I was back onto a C# role. I've also experienced that companies *sometimes* pay more and offer better benefits because the work is less enjoyable or more demanding. If two companies offered exactly the same financially, but one was a shit place to work, then what would keep the talent from moving to a better company? 
I am currently using service stack instead of webapi. I haven't yet used their web framework for a site, but for web services it's worked out pretty well. I'm currently running my services on Linux as self hosted applications with nginx reverse proxying any requests. The only issue I've had so far with service stack is unrelated to Linux: the free version of version 4 is limited. I might try v3 for a website next as it is completely free. I went with version 4 for my services due to better Postgres support in ormlite.
I'm using Octopus in an enterprise environment with TeamCity and it's just a breeze to use. I'm really happy with the simplicity.
does it apply to non-web projects? i'm currently looking into options towards easier deployment for an application consisting of a distributed set of .net clients/servers and several other tailored software pieces (think of multiple unity projects or similar). 
A change could give you more experience with a broader range of technologies. A good developer should be able to program in anything. The extra money might be nice too. It's not like you have I stay there for the rest of your career. If you take the new opportunity then once you graduate you will have more experiences to decide on your career path. I've worked in .net for the last 10 years and recently started as a frontend team lead (angular, Cordova etc) for a company that mostly uses Java. I've been amazed at how similar it is to .net except that java has way more options in terms of open source frameworks to solve various problems. a lot of the .net libraries are ported from Java (nHibernate, nUnit etc) The one thing that would stop me from moving from .net if I had a choice is that visual studio is such a great tool. I find eclipse terrible to use in comparison. Sublime text, webstorm and the like don't offer great code completion. I've been using frontend node based tools (grunt, bower) and I'd much rather use VS with web essentials and nuget. So now I develop JavaScript in VS then test by running the java web services via command line with maven then run the grunt static web server with live reload. It's not something I would have thought about doing this time last year but it actually works well. If you want to have a look at a nice technology stack for java check out [jhipster](http://jhipster.github.io/presentation/) Lastly, I don't know about where you live but in Sydney financial industry jobs earn concise rant higher wages. 
You guessed it right, but I agree not every one will be able to. I'll add some help text. I still have my doubts if anyone would be interested to post anything there. I have also planned to add memory utilization and execution time, but at this point it will be too taxing on the server (time calculations would require multiple runs) and I have a limit on how much money I can afford to lose each month :(. Appreciate your feedback.
My group evaluated Octopus Deploy, Microsoft's Release Management, and IBM's Urbancode Deploy. For us, supporting many disparate development groups with many different requirements, neither Octopus Deploy nor Release Management could meet our needs (scaling big, auditing+reporting, etc.). *edit 1* Octopus seems ideal for smaller teams, and RM is definitely nice if you're sufficiently covered with existing subscriptions. UCD is definitely expensive, but has the major stuff we needed.
It pretty much has 2 requirements, can you: * Package it up into a Nuget package (they even have a nuget package takes care of this for you - OctoPack) * Automate the deployment steps with PowerShell? If you can answer yes to both then I recommend having a look at it. Out of the box it'll support Web Applications and Windows Services but if you want to do anything a bit more clever you can whip out PowerShell :)
We use Octo Deploy. It's inexpensive, straightforward, has great documentation and a nice interface. I highly recommend it.
Yup, applies to all sorts of projects where you need to deploy to many servers. We had a product that had various components deployed to VMs and physical hardware - comprised a bunch of windows services, command line tools &amp; scheduled tasks, and a website. Each had it's own package, and could be deployed independently from others. 
Someone mentioned pluralsight, that is a great site. I believe I got an email from code project the other day that said they were doing a trial for like 3 bucks. That is totally worth it. There might have been a code. I will look it up if you are interested. Microsoft virtual academy is good too. Especially if you are using ms. A lot of the classes are taught by or at least feature people from the team that builds that tool/api etc. On the JavaScript side I would get a book called JavaScript: the good parts. Sorry no link, it's a pain from my phone.
Estimating 80 Web/app servers (not counting DB, etc.), 200-300 apps (with varying components), and generally minimal steps per app. Certainly not "big" compared to some other organizations, but as I mentioned we have many different teams that would need to be involved and use the product.
thanks. i think i still have my javascript book sitting around here somewhere.
It added absolutely nothing to the thread. I don't understand the inferiority complex in this sub. The sheer mention of anything remotely legacy causes the know it alls to have a seizure.
Thank you!
Hi mcnamaragio, thanks for the suggestion, I've added one because the video quality isn't the best.
Without your code I can't say anything. &gt; .Net ISN'T Just-In-Time compiled! It's interpreted Common Intermediate Language This is absolutely and completely wrong.
No. It's time to see the C# code.
.NET is a framework. A framework isn't JIT compiled. You seem terribly confused. Please educate yourself.
What a load of bollocks. The JITter translates (compiles) MSIL (CIL) to native machine code. Just because some code runs better in JS doesn't mean that you also correctly translated it into C#. Have you even tried a release build rather than a debug one? Edit: Also 0/10 for the trolling effort OP.
The NGen Native Image Generator compiles it down to assembly... https://msdn.microsoft.com/en-us/library/6t9t5wcf(v=vs.110).aspx
I mean there's no JIT in the standard VS .Net workflow... it's an extra step bolted on, using NGen... : https://msdn.microsoft.com/en-us/library/6t9t5wcf(v=vs.110).aspx
&gt; The JITter translates (compiles) MSIL (CIL) to native machine code. Na-ah! What about NGen? https://msdn.microsoft.com/en-us/library/6t9t5wcf(v=vs.110).aspx
I will assume you are trolling
Yes, NGen exists. So? That doesn't mean the JIT doesn't exist. If you're not trolling, you're embarassing yourself...
My point exactly. Thank you for sticking up for me, I'm not even going to grace the op with a reply. I think mod should ban them for trolling. 
He wasn't a 'know it all', didn't even try to state how WinForms is taking a backseat to WPF for desktop publishing. While you may feel it didn't add anything to the thread, he's not alone. I had the same thought when I saw it. It's reddit, whether or not that's a good thing or bad thing is up to you, I prefer discussion/debate over anything else.
&gt; So does that mean I need to install Visual Studio and the binary rewriter to make use of Code Contracts? Yes, that is what it means. It happens after compilation and it rewrites the IL. If you don't do this, then (as you noticed) nothing will happen. Also your title and your content differ somewhat. You ask about using Code Contracts and Analyzers together, but in your post there's nothing regarding this anymore. But yes, they're meant to be used together, as they do two different things.
Could be both, I'm at that age that I don't mind.
So does the CLR. NGen just does it ahead of time while the CLR does it the first time a function is called.
Saw that it was creating a 2d context, even if it isn't gl that is some form of telling the browser this is gpu level stuff isn't it? Canvas is accelerated isn't it? Also the idea that js is natively faster than Dotnet even though js doesn't run natively anywhere. It has to run in some managed environment like a browser so if it IS faster it isn't the Javascript part of this that's fast. And if it were faster in dotnet that would be the jit, compiler or framework pumping the speed. I'm not saying the link wasn't neat but this was really someone who just likes bashing other people's opinions or is a troll. 
.NET or not the rest of your list seems very fun and impressive. Like others have said go with what excites you and keeps you driven. Money is just a short term solution if you're really not enjoying the work you're doing. (Java dev for General Motors)
C# does not really have destructors, but *finalizers*. Those are not to be confused with C++ destructors, because their respective semantics are very, very different. Also, `IDisposable` interface/pattern should be used to clean up all resources other than memory, finalizer is only truly needed on top of `Dispose` if your class holds on to unmanaged resources that need to be released. Finalizers also have some slight 'gotchas' associated with their implementation and behavior.
I got your point, thanks!
If you haven't already figured this out, Xamarin is free for students.
The really important point to take away from this article is the Error Kernel Pattern, which is an original design pattern from Erlang. Offload dangerous work to a child actor and send successes or failures to the parent actor. Unhandled failures (literally unhandled Exceptions) will automatically be reported to the parent, but you can use user-defined ones too.
I've been hearing a lot about the Akka.NET package and the actor model - and I'm glad for this - but could someone provide some real-world system they implemented using this programming model? What sort of problems lend themselves to this model?
Sure thing! Here's an example I wrote about how I used Akka.NET in production and at some considerable scale at my previous startup: http://blog.markedup.com/2014/07/real-time-marketing-automation-with-distributed-actor-systems-and-akka-net/ Unfortunately the business closed due to capitalization and sales cycle length (common problem for enterprise startups), but we were servicing a pretty considerable load (1,000+ HTTP requests per second) with Akka.NET in production from May 2014 onward. Here are the sort of problems to which the actor model is amenable: 1. Building physically isolated (i.e. run on their own machines) microservices - Akka.NET's location transparency (ability to send a message to any actor without knowing what machine it's on), automatic serialization, and extremely low network overhead (Google Protobuffs over TCP) make it a strong candidate for doing this. 2. Any naturally occurring real-time, concurrent, distributed problem - easy examples include multi-player online games and social applications. 3. Stream processing - actors make it very easy to break up a giant datastream into lots of small, stateful ones. The added benefit of this is that your code footprint with actors is tiny compared to shared state programming. 4. Analytics - it's really easy to aggregate events observed over a period of time with actors, especially if you have to aggregate events across lots of distinct sources and dimensions (i.e. time of day, country, etc...) 5. Reactive programming - need to build a marketing automation system that can "react" to what your customers do or don't do? How about a monitoring system that can react to changes in data observed from network devices? 6. Parallelization - write code to solve a problem once and actors can automatically parallelize it, so long as you use lots of actors (we call this "actor fan-out") I used Akka.NET for 1, 3, 4, and 5. Performs well and has a small code footprint. It takes a bit of practice to get the hang of the programming model, but once you start using it then it's power becomes apparent. "You mean the code I wrote for doing this thing once can do it for 1000 things in parallel if I just send the head actor 1000 messages instead of 1? Holy crap!"
Can't wait for the RTM version of VS 2015
This can be replicated in WPF without much trouble, WinForms on the other hand is much harder to style, thus making this much more valuable. I develop in both WPF and WinForms, and all I can say is I'm mind blown someone took their time to make this, AND made it Open Source considering how hard to achieve this would be for me in WinForms.
You must be living in another time then. Developing countries with small clients still care for cheap software development, and WinForms is both easy to develop, and mantain if it's something small. I'm sure a LOT of small part time developers will have great use for it. 
Edit: link is broken?
It's unnecessary clutter for the most part (since if _blah, it's a private field, if Blah, it's a property, etc), though with c# 6's static using methods, it's going to become a lot less clear, potentially. What bugs me is the huge amount of white space used for every control statement. Three lines for every } else { ... Really? Also spaces suck. :p
Both seem to be working for me. Which are you having trouble with?
Akka.NET: Why are actors reliable in large systems? http://petabridge.com/blog/how-actors-recover-from-failure-hierarchy-and-supervision/ Edit: I'm using baconreader on android. If I copy the link to a browser it works. For what it's worth. Carry on :)
What if I already code perfectly right now?
&gt;Three lines for every } else { ... Really? Yes. I've never seen a coding style that prescribed putting all of that on one line. The idea is to be able to quickly see where one block ends and another begins. If you want to argue for putting the opening brace on the same line as `else` that's one thing, but all three is madness.
Framework Design Guidelines talk about public APIs, not about private members.
I'm with you. No underscores unless it's a private backing member for a public property.
&gt; If you want to argue for putting the opening brace on the same line as else that's one thing, but all three is madness. As pointed out, this (K&amp;R) is one of the most common styles of C syntax. And it's very easy to see where a block begins and ends--that's what indention gets you; even out of the corner of your eye, it will be obvious due to the gross shape of the code.
yes
Thanks
I would argue that the Allman style makes it very easy to see at a glance the scoping levels of code. A single block is two curly braces on the same column with its body indented. Whereas with K&amp;R you could easily mistake various formattings of multi-line statements as new scopes or bodies, e.g. LINQ stuff, without visually parsing out "oh there's an open brace there, that indent on the second etc. statements is to clarify its a multiline statement". 
Sure you do, but you have to deal with Joe over there who still writes K&amp;R style braces and Wendy who can't keep variable names straight. Style cop was a great plan for the project I started at work. Comparing the codebase is night and day. 
ReSharper full code clean up will take advantage of new C# 6.0 features. Meaning it may change some of your code. If you have it that is
Yes, what your thinking of is what's called a "breaking change". This could be a method that gets removed etc, and in the case of a language would mean that something about the language has been changed in a new version. There are no breaking changes and as far as I'm aware C# 1.0 code will compile fine with the C# 6.0 compiler.
It's used all over the place. I personally think splitting it into three lines is dumb and much less readable. But again as others have said, it comes down to what you're used to. 
If you're designing an API, the two are not mutually exclusive - you don't expose private members. It doesn't give any clear guidance on how to lay out backing fields for properties, so it is entirely possible that you're entirely correct.
I hope and pray MS buy JetBrains so Visual Studio comes with reSharper out of the box. 
Oh yes, I picked up a personal license when work said "nope" to buying it for the company. The problem is, though, that if you don't have it it doesn't help you. My coworkers are quite a bit less willing to pick up this kind of software for work, so I have to work with other means. Right now I have gated checkins going through StyleCop, and it's working quite well. There was a short period of annoyance before the styles clicked in people's heads.
This sounds like a job for either your in house development team or a contractor you hire.
I would think that T-SQL would lead to Allman style ... in fact that's one of the benefits listed on the [Indent Style](http://en.wikipedia.org/wiki/Indent_style) wiki page: &gt; This style is similar to the standard indentation used by the Pascal programming language and Transact-SQL, where the braces are equivalent to the begin and end keywords. &gt; (* Example Allman code indentation style in Pascal *) procedure dosomething(x: integer, y: integer) begin while x = y do begin something; somethingelse end end I don't really care one way or the other. I use Allman in C# and K&amp;R in JavaScript. I just disagree with Allman being "less readable." Less *familiar* to some, maybe. But, to each his own.
Isn't pluralsight even linked on ASP.Net's official website?
New Dev, what are winforms?
I'll completely recommend the CE, it's great and at no cost
Resharper refuses to use Roslyn because they've invested so much already in their own "compiler/syntax tree". Since Roslyn it the new big thing in VS, any Resharper integration would probably be developed from scratch upon Roslyn.
I wonder how this might change iojs. 
I now feel like I actually trust MS. I've set up a full MS stack recently on Azure and I have to say I'm impressed as hell. 
Yeah, I setup a website, some queues, a redis instance, some scheduling stuff and connected it all together in less than an hour. It was f'n amazing.
When I come across really bad code I just start again and do not tell my bosses what I am doing. In my experience it takes much longer to sort out a mess than to write good clean code. When they see the results than I say I had to re-do it.
Which versions of the tools are you using/
I have Visual Studios 2013. I just did new project -&gt; web application -&gt; mvc. I believe I'm using .NET 4.5.
I highly recommend learning Entity Framework code first and using that. It will save you tons of time in writing boiler plate SQL and creating tables etc. 
I agree that it seems much easier. My only concern is using that much generated code, and if I make a change it all gets rewritten. I just worry about having the code that tightly coupled to the database.
Sent. If you message me, and I don't get back to you right away I may have stepped out for lunch.
If you use EF be sure to utilize the interfaces it provides and dependency injection so you can: 1) Inject fakes/mocks for unit testing. 2) Create a wrapper if there are breaking changes between EF versions. 3) Decide to later on completely replace EF and don't want to have to go through your code ripping all the tightly coupled references to EF classes. Older versions of EF require more work to fake/mock but the latest version is very mock friendly I hear. This also isn't a guarantee you'll be able to easily swap out your data access layer, but using the interfaces and injecting the instances instead of directly instantiating them in you code isn't much additional effort. 
Ha! In my experience, EF takes far more work that SQL for all but the most trivial of tasks. Hell, EF even sucks at dynamically generating SQL based on user-selected filters. And that's the one thing I actually need an ORM for.
It really depends on the nature of the application and what you are looking at. Basically, you should look for opportunities to logically group the data and limit the scope of it wherever possible to reduce the number of variables you are dealing with. You might try looking at areas where you could group settings into smaller units (DbSettings, FormattingSettings), look for areas where there are repetitions of related fields that could be put into some sort of collection, and moving fields into a more limited scope or dialog (maybe there's a field for file name that could be replaced by save or open dialogs, for instance, or some settings for connecting to the DB that could be moved into a dialog for them). Without seeing it though, it's not really possible to give any solid advice. Sounds like you are on the right track, though. 
This is just wrong. I can have a fully working domain layer with backing database and strongly typed model objects up and running within 20 minutes. Complex relationships and querying included. Spend some time to learn LINQ and its very very powerful. 
Okay that's what I thought. I made a model class for each one of these. Say there are 4 objects in my project. 1 contains a list of 2 and a list of 3, and 3 contains a list of 4. Would I need a ViewModel class or could I just pass it the number 1 here.
The objects that Entity Framework returns are referred to as "entities". In theory your EF-based entities should be able to serve as your model objects. In practice EF-based entities are so strongly coupled to the data context that created them that using them as models is very dangerous. 
Why bother? Just put your indirection layer one level higher in the stack and you don't have to worry about EF. And if you swap out your data access library, you won't need to change your mocks.
If my orm returns an entity that is the exact same as the object I want now, do I just call something that maps all the variables to my new object?
We might have different definitions of 'production' going on. If your DB is going to be touched by external sources that can't run through your DAL or you're developing a high-performance concurrent app then I agree - EF may not be the right choice. For a contained web application the convenience of an ORM (be it EF, nHibernate etc) outweighs the downsides. 
I use both, actually. EF for the quick model design/db CRUD stuff, Dapper for more intense work.
Yes, you can use something like Automapper to do that without having to write all the code by hand.
&gt; Then in a controller I try and create one of these classes, add to the dbcontext and save. The standard pattern I've seen is to fetch the model from the context, copy the new values from your source object to the newly fetched object, then save the fetched object. Perhaps with the right magic incantation you can do it your way. But I'm no EF expert, my job is to just fix whatever EF crap I find until I have a chance to rip it out. *** Side note: I'm working on my own ORM that avoids that shit. But who knows when legal will allow me to open source it so I can't share it yet.
I'm not really sure what you're saying that's different than mine. I don't currently have any data in the database, and I can't even see my tables yet. That's why I'm trying to add just a simple instance of what one of my tables would be. I'm hoping that when I add one of these it will show all of my tables.
Just because you don't know how to use it doesn't mean it can't do those things. You can use the fluent API to configure the relationships, cascading deletes, etc that aren't easily handled doing code first with class decorations. You can also do db first and get your entities that way. Oh and you can still use sql any time your heart desires. If your domain has no entities then how difficult is it to work with your code bases?
Why are there so many different ways of configuring EF? Because they all suck, so each acts as a work-around for the limitations of the others. Your example is pitiful by the way. I offered a long list of complaints and you answered, "it supports cascading deletes"? Cascading deletes, in SQL, is just a couple of extra keywords on the FK constraint. The fact that EF supports it isn't impressive. Though I will say that not being able to offer cascading options via class decorations is impressively bad. 
I had to hunt for your long list of comments so I could give you one quick answer: you seed the database and execute all of the Sql in your seed class. I've got full text search indexes written in raw sql being executed after code first builds the database. You shouldn't need to do all that stuff through the orm and if so please tell me which other orms do so I can check them out.
Raw SQL in you code, just like VB 3 developers. 
Or in external .sql files if you prefer...
Yeah, we usually have a repository layer to make entity calls. Easy mocking after that.
Try looking at the inner exception.
&gt; Also if I made additions to the project when it is in production Never. You should have a database project in addition to your asp.net project. Make your changes to the database project and push those. 
Hey, I'm a dev on the .NET team. I think you might be mistaken. IL is not interpreted but JIT'd to machine code at runtime. NGEN does exactly the same thing only before you run the code. Please share your implementation of the texture demo in .NET, and we'll see if there's something we can do to improve it.
You offered a long list of complaints, about half of them are unrelated to using Entity Framework. You'll need to setup security if required, *regardless* of using EF or not. The other half are about application requirements that transcend the need for a basic ORM, which is what OP is asking about. Yes, doing it in SQL gives you more expert control. No, this doesn't mean that EF isn't a really useful tool for applications with 'regular' db handling. EF works in 90% of all cases **because it's greatat handling everyday data storage**. Unless you have a specific gripe with EF (which inherently implies you've both tried EF, and have a working knowledge of why EF isn't the best option for your problem), use it. Especially in conjunction with LINQ, you can get a basic DAL up and running in no time.
For MVC learn about how it works with controllers and views, partial views, filters, modules, routes, actions, child actions, models, how validation works and that should be good. Hopefully they don't use webforms but you might want a cursory knowledge of that. As well knowledge of wcf might be useful to have
Upvote for Dapper. I've tried other orms like EF, Nhibernate, LinqToSQL. Dapper is just simple and fast, next to no learning curve. The others felt like overly complicated ways to make something simple, if that makes sense.
EF can write terrible, terrible, terrible SQL. Basically you have to become a linq to sql wizard which means you may as learn SQL. 
This is why having these conversations are hard. You think I'm talking about "expert control" and I think I'm talking about basic operations. Would you consider using inheritance and virtual methods "expert C#" programming? Would you feel like you are programming with training wheels on if I told you that you could only use static methods? Or for you web programmers out there, using EF is like being forced to try to create a modern website using WebForms. That's basically what you are doing when using EF. Like WebForms you do have escapes down to the raw SQL, but it is painful to use and everything is slower and clumsier than necessary. And like myself back around 2005, you have no idea how bad it really is because you never learned how to use JavaScript, or in this case SQL, properly.
Maybe even WebAPI, but it depends on what are they using
Yeah especially since it's being merged into ASP.NET vNext. As well an understanding of OWIN wouldn't hurt. 
The worst SQL. Its basically unreadable.
Are you talking about where to publish it on the web server? In that case, C:\inetpub\wwwroot is the convention and it's usually the best place. If you are talking about the source code, I don't really understand what you mean. Each developer should clone the repository on their own machine, and there's usually no reason to stop anyone from using whatever folder they want. For the origin repository, use whatever folder the git server defaults to. Or just use bitbucket or github. 
The way things are currently on our servers the files are all over the place. For Example: * Web code: "/inetpub/wwwroot/" * Class libraries: "/program files/ourappname.net/", multiple DLLs, installed in the GAC * VB6 COM+ applications: "/program files/ourappname/componentssource/" * a couple other places I want all of this in the same repository, but as far as I can tell git requires everything to be in one place for that to work. I'm looking to reorganize this into something like: * Web Code: /appname/www * .net class libraries: /appname/lib * com+ applications: /appname/com So that I could then have all of it in one organized place, I'm sure that I could get this working whether i put it at the root of C:\, or pretty much anywhere else, but I'm not sure what the best practice for locating it goes, or if there even is one.
Then you get a membership to the club.
your English is fine. I'll tell you what I learned after years of doing ajax in asp.net webforms. I don't like using asp.net ajax or the asp.net controls. I used to use updatepanels, panels, repeaters and the lot like you're suggesting. Now I'm using asp.net as a backend for webservices to generate the html and process users actions. On the front end, I use JavaScript, Jquery Ajax to call my webservices that render and process all the html and requests. The speed and control is amazing this way having done many ways. You get that true web 2.0 feel. just my opinion...
i think what you are looking for is visualping.io But I will gladly help test :)
Just set the control invisible, should be no need for a placeholder. Although having done lots of dynamic controls and web forms I agree with the other poster, if you can avoid web controls then you should. I'd suggest something like angular, jquery and bootstrap 
thanks for the feedback... yes this will remain free forever. i have no plans at all to commercialize it. as for your xpath problem; i made some code changes after looking into the monitor you created because it did point out a scenario i did not come across before. yours was the one trying to monitor a page for movie showtimes right? (that was the last one created and didn't belong to me). the reason why the xpath given by chrome didn't work for the low level element was because the page renders that element using javascript after the page has fully loaded. at the moment it is not possible for my app to execute javascript. i'm looking for viable solutions and will try to get something going soon. the best way to work with javascript heavy pages at the moment is to turn off javascript in chrome and load the page in order to find the correct XPath of an element. cheers!
EF tends to be bloated and unnecessary, but learn it for sure. A lot of companies use it. It's like T4 templates to me, auto-generated code makes me cringe and it's often a pain to update and maintain when you need to make changes. Some people swear by it and say it's okay to use now, and that it's "come a long way", but I'm not a fan. Personally I like to have tighter control over the data layer without all the hassle, so I use Dapper. Adding a column to data output is as simple as adding a one-line property on a class. You don't need to regen the whole data layer if things change, etc. For fresh projects I have a common object generator SP that just looks up the table schema from sysobjects and literally outputs the c# code for each field as "public long BlahId {get;set;}" with data types/nullable/etc. so initial setup is pretty quick and painless.
Doesn't Tinder limit the amount of people you can swipe now, though unless you pay?
Last I heard, it already rolled out for Android but the iOS version was still waiting approval.
a better way to monitor this particular page in question would be to setup an xpath monitor on the ajax result url instead of the actul url of the page. do this to get the ajax url of the page in question. load the normal page in chrome &gt; right click &gt; inspect element &gt; click the filter button &gt; enter 'FilmSessions' &gt; click on first match in the "headers" tab, copy the "request url" create a new monitor at changemon.com with that url. and set the xpath as "/" that should let u monitor the actual data feed/json result of showtimes. i've setup a test for that myself and let u know if/when that goes well :-) thanks! 
Just used this in a real-time chat application, worked wonderfully.
Thank you!
[Cmder](http://bliker.github.io/cmder/) is customized ConEmu with Clink and msysgit wrapped into a pretty awesome package.
Can you give me some resources for courses that you found around ASP.NET? I'm having a hard time to find anything outside of Pluralsight.
Did you know that EF6 has WinFS parts in it? It has old code.
Take a look at the ASP.NET Web API framework. **Very** easy to use.
Server sent events is just a standard for long polling where the server responses fire standard (W3C) events which you can listen to using addEventListener. For my particular scenario I ended up using server sent events for modern browsers and long polling with an iframe for old browsers. I was only doing server to client push though, I didn't need client to server. In my case most servers were using IIS6 and it was practically impossible to get SignalR working properly. :(
Spot on, this is exactly what he should use.
I read those ones (they cover many topics in one tutorial): http://azure.microsoft.com/en-us/documentation/articles/web-sites-dotnet-deploy-aspnet-mvc-app-membership-oauth-sql-database/ http://www.asp.net/mvc/overview/getting-started/getting-started-with-ef-using-mvc/creating-an-entity-framework-data-model-for-an-asp-net-mvc-application And also this tutorial in french (if you understand french, this website is perfect, I learned many things from it) : http://openclassrooms.com/courses/apprendre-asp-net-mvc
Having to create types is bloat and work? Then don't use a fucking typed language. Use some scripting shit like NodeJS.
Try Nancy. The syntax is almost exactly what you're asking for. http://nancyfx.org/
Your title says yes but your post says no: are you using actual migrations or not? Do you run the command Add-Migration and Update-Database?
Thank you very much, I appreciate your response!
It's kind of a crucial step to the code first migrations part :) You can update the DB by running these commands, and for production environment you can get a diff script from the same package manager console.
Take a look at asp web pages framework. It's html and Razor syntax, fastest way to get going.
There's a link near the end of the article: https://github.com/crockpotveggies/tinderbox
SignalR seems to be a way to keep real-time communication between server and clients. However, my issue always seems to fall on opening a client side file and *keeping* it open to watch for appends. All the examples and descriptions I've seen in the case of web technology is that a file on a client machine is always fully uploaded but I haven't been able to find a way to keep the file open and watch for changes.
No, do not do that, it's a maintenance nightmare waiting to happen. If you are coming from a java background, why is building a proper model structure such an odd concept, webapi isn't going to be that much different than say spring in java. 
XML has absolutely nothing to do with what you said before.
Thanks for having a look! I've found some improvements that helped - but it still feels laggy compared to the JS. http://untamed.co.uk/miscFolder/fastImageCalc.zip
The relevant stackoverflow answer: [What benefit does the new “Exception filter” feature provide?](http://stackoverflow.com/a/27082164/885318)
wow thats a really lovely console. any Idea how I can use it to replace all system consoles, when i use the con emu setting to do this, opening a new cmd just brings up a standard con emu with none of these improvements
I can use dotnet only.
Transforms?
Why is that?
hi, I am a noob in .Net. can u suggest me books or video tutorials where i can learn .Net for making a website. To be exact I have been told to make an intranet for a small company. I know html , css , javascript .
I'm struggling to understand the purpose of Akka. It looks amazing! What's it for? :-)
Do you use Webforms for the development of those web services? That would be weird...
[This link might be a little more applicable to this sub.](http://up-for-grabs.net/#/tags/.net%2Cc%23)
Great point, and I apologize for overlooking that in the post. Thank you for alerting me to the miss. I updated the post to address. So, what is Akka.NET? Akka.NET is a community-driven port of JVM Akka to .NET. Akka is a programming framework, based on the Actor Model, for building powerful concurrent &amp; distributed applications more easily. The framework itself handles all thread management, low-level networking, and the utility code and “plumbing” for you. You just focus on the logic and workflow of your application.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Actor model**](https://en.wikipedia.org/wiki/Actor%20model): [](#sfw) --- &gt;The __actor model__ in [computer science](https://en.wikipedia.org/wiki/Computer_science) is a mathematical model of [concurrent computation](https://en.wikipedia.org/wiki/Concurrent_computation) that treats "actors" as the universal primitives of concurrent computation: in response to a message that it receives, an actor can make local decisions, create more actors, send more messages, and determine how to respond to the next message received. The actor model originated in 1973. It has been used both as a framework for a [theoretical understanding](https://en.wikipedia.org/wiki/Actor_model_theory) of [computation](https://en.wikipedia.org/wiki/Concurrency_(computer_science\)) and as the theoretical basis for several [practical implementations](https://en.wikipedia.org/wiki/Actor_model_implementation) of [concurrent systems](https://en.wikipedia.org/wiki/Concurrent_systems). The relationship of the model to other work is discussed in [Indeterminacy in concurrent computation](https://en.wikipedia.org/wiki/Indeterminacy_in_concurrent_computation) and [Actor model and process calculi](https://en.wikipedia.org/wiki/Actor_model_and_process_calculi). &gt; --- ^Interesting: [^History ^of ^the ^Actor ^model](https://en.wikipedia.org/wiki/History_of_the_Actor_model) ^| [^Indeterminacy ^in ^concurrent ^computation](https://en.wikipedia.org/wiki/Indeterminacy_in_concurrent_computation) ^| [^Actor ^model ^theory](https://en.wikipedia.org/wiki/Actor_model_theory) ^| [^Yıldız ^Kaplan](https://en.wikipedia.org/wiki/Y%C4%B1ld%C4%B1z_Kaplan) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+coodfpv) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+coodfpv)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Akka.NET is a good consumer / producer for NServiceBus. It gives you the ability to add RX-like capabilities based on the arrival / absence of particular messages.
Wow, sounds powerful. Given this information, 1.0 sounds like a real accomplishment.
When you say port, is it a rewrite in .net or is it a line for line port like lucene.net and early nhibernate?
I would suggest an integer. (If I recall correctly, would need to double check to be sure) Since the clustered index will cause the rows to be stored in the same order as the index on disk, if you use something non sequential like a guid, you risk SQL needing to re-arrange the data on the disk if the new rows Id isn't sequential. (performance consideration)
You can use a sequential guid. The real advantage of an integer is size. Guid's are 128 bits, and int's are 32/64. If you're not worried about running out of integers I would use the integer. If you're needing uniqueness then a guid is a good idea, it could be unique across all db's and tables.
huh... https://msdn.microsoft.com/en-us/library/ms189786.aspx doesn't mention azure, something to test later tonight.
SQL Azure **requires** a clustered index before you insert any data. No getting around this. tl;dr - always apply a clustered index, even in on prem databases. If you apply a good one, it can make your select queries faster. The long version: Your clustered index determines how a table's rows will be physically sorted on disk. Think of it like a dictionary. If you don't provide one, you aren't guaranteed any particular sort order. This is called a Heap - because you just heap things on the pile with no sorting. Pretend our table has three columns: * WordId int identity * WordText nvarchar(100) * Definition nvarchar(max) If we were to insert three words, say: 'Aardvark', 'Zebra', and 'Monkey' (in that order), and our clustered index was on WordId, our table would be stored like this on disk: WordId | WordText | Definition ---|---|---- 1 | Aardvark | ... 2 | Zebra | ... 3 | Monkey | ... If we now changed our clustered index to be on WordText, the rows in our table would be physically re-sorted on disk and look like: WordId | WordText | Definition ---|---|---- 1 | Aardvark | ... 3 | Monkey | ... 2 | Zebra | ... Now, pretend that we've added 100,000 words. Which of the two clustered indexes is going to be the best way to find a specific word in our dictionary if you're going row by row? Just like it's easier to look up a word in a dictionary because it's sorted (clustered) by the word itself, when you add good clustered indexes to your tables, it makes it easier (read: faster) for SQL Server to find the data for your query. You'll still want other indexes to support quick lookups on things like WordId - e.g. if you already know the ID of a word and want to pick just that one. A couple of notes/misconceptions about clustered indexes: * You only get one - you can only sort a table and store it on disk once. * The data in the index _doesn't_ have to be unique. * You can use multiple columns. * The clustered index does not have to be the same as your primary key. * You can easily add a clustered index to an existing table with *create clustered index [IndexName] on [TableName] ([Column1], [Column2])* -&gt; note for Azure you'll need to create the table, apply the clustered index, THEN load your data.
Then take this opportunity to fix things like missing indexes, clustered or otherwise.
&gt; If you don't provide one, you aren't guaranteed any particular sort order. Even with a clustered index, you are **never** guaranteed a sort order in your result sets unless you use `order by`. Additional note on your CI - be careful to select one which won't cause a lot of moving rows around because you're inserting into the middle of the table (due to the sorting). Large numbers of page splits can cause performance issues. IOW, making a GUID your CI is probably not a good idea.
No probs.. excellent docs btw :)
If OP doesn't have a primary key there is no harm in creating one, because it is good practice. However they could also just add an index to an existing column... but that's poor design practice and how you get a slow clunky clusterfuck of a mess.
very nicely explained
My suggestion is change the name of the conference. This sounds too similar to Xamarin's conference name.
Will pass this on! Although may be a little late...
Ouch. Yeah. Very unfortunate naming clash.
Yeah, without transforms this isn't useful to me.
The difference between the actor model and a servicebus like nServicebus/mass transit is like the difference between a CLR object and a WCF service. sort of. Actors are lightweight concurrency primitives at heart, servicebusses are a means to get durability. You can use the actor model to solve things like concurrency problems in multi threaded code, take the classic "bank account withdraw" example. two or more threads try to withdraw money at the same time and you get race conditions and need locking. The actor model solves this. Actors are also location transparent, if an actor lives on your local machine or remotely, it doesn't matter, they behave the same. Lets say you are building an online game, think world of warcraft. You would not use a service bus to do it, it would be far to heavy, and you are probably not very concerned about messages that are 10 minutes old reaches the server. I'm not saying that you can build exactly world of warcraft ontop of Akka.NET, but it would take you alot closer than any servicebus ever would. So, not exactly the same use case. even if both can be used for distributed systems.
Take a look at [techorama.be](http://www.techorama.be). It was the first community-driven conference here in Belgium last year. The organizers are also involved in [visug.be](http://www.visug.be), our Belgian **V**isual **S**tudio **US**er **G**roup. This conference filled the void that was left by the disappearance of the Belgium's Microsoft TechDays last year. They were very successful, and this year's edition is ramping up to be a great success again. To me, it is a great added value to have a conference organized by people who look a bit further than only Microsoft's portfolio.
I'd definitely have to say I wouldn't recommend meteor or any of these server side JavaScript applications. Maybe it's just me, but they all seem like fads that aren't going to catch on long term. 
step1: stop learning mvc step 2: learn Web API. done.
Lmao, yes, this.
&gt; Agreed that regions in HTML seems a little weird. If you really needed a region, you will probably already have a surrounding element that you can collapse. I think it's a misfeature including it at all, it was only added so the drag'n'drop editors didn't fuck up your code. In general it screams a class/file needs to be broken up.
Meh just do periodic rebuilds. Guids have pro's such as not creating disk hot spots. If your data is deletable you're going to end up with fragmentation anyway. I've had varied success with both incrementing identity columns and guids.
I use JustDecompile with the Assembly Editor Plugin (Reflexil). It's pretty easy to modify .NET executable and assemblies.
It was for that particular case. That doesn't mean that it's always easy. 
&gt; For example if you had the following (admitably silly!) code: &gt; int area = int.Parse("200") * 500; &gt; We could use the introduce local refactoring to modify this to: &gt; var v = int.Parse("200"); int area = v * 500; Is this backwards? I was under the impression the refactoring would remove "temporary" variables to turn them into inline assignments.
Refactoring works both ways. The example as shown is "Introduce Local Variable" and the opposite method (going from the second statement to the first) would be an "Inline Temporary Variable".
I am rebuilding tons of old apps right now for my internship. We use the ASP.NET MVC Web API model. This is what I recommend for making easy webapps with VS and Azure, which lets you host in the cloud for free...to an extent. VIEW: HTML, CSS, JavaScript for the View. We use ractive, which is a two way databinding, template swapping library, excellent for SPAs. MODEL: Check out PetaPoco. It allows you to connect to a back-End(with connection string and some web.config alteration), such as Microsoft Azure SQL DB, and be able to handle data back and forth. Controller: These will all be in c#. They will be used to access the database using petapoco. AJAX to the max...hehe I'm pretty tired, but if you want to hear more let me know. The only thing I'm working on now is app size and how to minimize the amount of extra shit VS adds on when you start an MVC Web API project.
Look at ASP.NET 5 because they are combining MVC and WebAPI. If you where less snarky you may have straight up suggested to learn SPAs from the start. Not that I agree with you.
I really miss Visual Studio. Regards, The guy who has to use Eclipse
&gt; Microsoft needs to make everything free and open source I'm pretty sure they did that a few months back?
I have been doing .net for 5+ years. I don't wear a suit and tie. I have never worked for the government. of course, I am also not in DC. Maybe you should look outside DC.
He probably just doesn't have any .NET devs so he's trying to sell Python developers. No different than a shopkeeper telling you that nobody wants Playstations when really he just sold his last one and has a bunch of 1st gen Wii's that corporate sent him by mistake. It's hard to find .NET developers because so many people want .NET developers that most of them don't use recruiters. I can pick up the phone today and have three job offers tomorrow without leaving my home town.
&gt;Look at ASP.NET 5 because they are combining MVC and WebAPI. Wow, I had no idea. Totally not why I said this: &gt;I love getting downvoted with this suggestion even though it's very clearly the direction MVC6 is moving in. (Protip, have been using ASP.NET 5 (aka MVC6) (aka vNext) since before beta1 was published and I lurk in Jabbr every day) &gt;If you where less snarky you may have straight up suggested to learn SPAs from the start. Which is exactly what I did. SPA + {some API, probably WebAPI}.
So many recruiters I've talked to know jack fucking shit about anything other than making sales. That's all they are after all, sales people. But at the same time, of course young people coming out of school aren't very interested in the enterprise world. They all want to work on cool stuff, like games and trendy websites. There's hardly a lot of those jobs out there though and a lot of them are actually pretty shitty jobs when you look under the glossy surface. It sounds to me like this recruiter sucks at getting people hired for the type of work you're looking for. Find another, they're a dime a dozen. There are tons of people out there that will take whatever job you're offering. Unfortunately most of them won't be any one you want to hire.
I really need someone who can work closely with me.. It is just me and the person that I will hire to do all the development
I don't put logic in the model generally so their is no need to separate they two. This separates state from operations. Partial classes seem like the poor mams way of achieving the same thing. What your describing sounds like the active record pattern. 
Its all sales talk and bullshit. Recruiters are in it for themselves, if they have no candidates they will try to tell you that the tech is dying or that a certain skill is more desirable because they have lots on their books. .net is far from dead as far as I'm concerned, and a lot of the old passionless devs belong to java, Delphi and the likes. People always go on about .net declining and things like python being king, or one of the hipster languages being "the future" but there's no solid evidence to support any of it. Beware of stats as they tend to be flawed.
"The kids" these days will learn and use what you pay for them to learn and use. Passion is nice but I'll take a professional developer any day. You're going to get what you pay for and those developers are out there if you're serious. It's nice to get super cheap talent around a technology that "all the kids" are excited about, but it seems like you're simply hoping to leverage an over-hyped technology to get young cheap talent. There's nothing wrong with that I guess, but then you gotta go with what's actually fashionable in startup circles. .NET is certainly a great technical choice for any startup IMO, but it's far from being fashionable with fresh graduates. Heck, I'm not sure Python really qualifies there either anymore. Maybe node.js has that status now. I don't know. I'm only a "serious enterprise guy" not a "kid" so what do I know. 
Let me guess, 954-636-8496, 954-691-4588...All those calls probably came from the same outfit. Just headhunters out for commission. I would put zero stock in judging demand from that experience. Dice is a scam, as are many other job hunting websites. Most of the jobs are fake; they just want your resume. 
I think this ends up being very true in DC -- the .NET stuff is in government, DoD and in a few trade associations. All the hip / cool / young stuff is running around using ruby or node or whatever the stack of the week is for better or worse. And .NET basically doesn't exist on mobile which is where folks are focusing when they aren't having a hard on for javascript. Go over to 1789 and count how many PCs you see in the place. The most I've seen is 4. The last time I was hiring a .NET developer most of the candidates I saw were H1Bs or morts. On the flip side look around a cool, exciting job openings. Very, very few .NET based ones about and those are usually doing boring shit.
LOL. This won't be true for much longer. We're buying so much good will with devs by open sourcing the CoreCLR and by ASP.NET5 being open
Not much of a choice when working with XAML. If you have a ShippingAddressVisible property you need it pretty close to the ShowShippingAddressCommand. Of course there are asshats who shove all of the Order model's properties into the view-model as well, but that's not what I'm talking about here.
I know very few .NET devs who are interested in user groups. With jobs and technical knowledge so easy to obtain, they don't feel like they need that support system. They're wrong, these groups are often very useful in unexpected ways, but that's the mindset I see.
Properties are boilerplate most of the time. If I've got a complex view with lots of properties, I hate walking through page after page of nearly identical declarations before I see the actual commands. 
24, recent college grad, and C# is my favorite language(although Scala is starting to win me over). C# is the language that I wish Java was.
I call them Model Views because it sounds more like a database view. Both are denormalized views of the data. Doesn't seem to be catching on though.
One would think so but it shocks me how few folks who don't write C# have heard of it -- lots of the mobile guys I talk to who are taking on cross platform problems aren't even aware of it. 
For what it's worth, I'm a .NET developer in the DC area (just turned 30) and am happily coding in C#. Building a startup (http://goroutehero.com) at 1776DC with Azure and ASP MVC &amp; Xamarin. It might be a little harder to find, since the Go/Python/Rails/etc people are very vocal, but there are definitely younger people using .NET out there doing cool things :)
Seriously learn how to work with remote workers. Some of the best talent on my team is remote. Things like google hangouts and hipchat make things work almost as good as having someone right next to you. Sometimes it's even better.
I am 27, and in my head I consider myself a kid even though this is my 9th year being a .NET developer. I know .NET was certainly not taught in my CS courses, they stuck to the open source languages, and I don't think it's trendy, but it is still one of my favorites. I used to live in Denver (for the first 26 years of my life), and it seemed like about 40% of the shops were using .NET in some way shape or form, now I live in Seattle and the percentage seems a fair amount higher (70%). I know with a fairly strong .NET profile on LinkedIn, I get about a hit every other day on average from a recruiter looking to place me somewhere throughout the country. The nice thing is this allows me to be very selective when choosing my next employer. Note: All percentages are just guesses based on what I have seen in the job market.
Yep, all the new kids are using node.js and rails with their mongoDB, working on their hipstr.io domain while in the coffee shop wearing their fedora. 
I literally have about 10 recruiters a week contacting me. It's ridiculous. Too bad all the jobs will delete my soul. 
TL;DR: I think the recruiter is mostly correct. I have been a developer in the DC region for about 15 years now... this region is split up into two distinct groups, the start-up group, and the contractor group... I have spent time in both (currently on the start-up side). The start-up group are people who want equity and hot rising companies, and .NET is very rare among those, and extremely unpopular (mainly due to historical reasons). It is starting to turn around with the open-sourcing of .NET, the new excitement around F# and the community edition of visual studio. But the cost of deploying these solutions on MS stacks is still non-trivial and scares start-ups because with high growth it can be unbounded. The contractor group tends to work for big business, government, etc... they tend to have no problem with .NET but not much passion as they get paid either way and have no piece of the final product, good or bad. They make great hourly rates and get time to spend with friends and family. In this area the deployment costs of Microsoft (and the licensing overhead) is already baked and handled by someone else... so it is barely a blip on the radar. I suspect in a few years, this might not be as big an issue, Microsoft is actively working on it. But right now, .NET is the land of contractors and the mostly dispassionate (at least in the DC region). 
In Sydney (Australia) its hard to find anyone who doesn't use .net. From my experience it's quite common in Singapore and Bangkok too.
Out of curiosity, was C# incorporated in your college's curriculum or was that something that you explored on your own? I work for a company in DC that uses .NET. The reason I ask is because a lot of people that interview with us for internships or positions right out of college don't seem to have a lot of exposure tothe MS stack. I get the impression that C#/.NET is not used in most schools.
My wife is finishing her masters this Spring and went to her college's engineering career fair. All the undergrads were waiting to talk to Google, Amazon, etc. All the booths for companies looking for LOB devs were empty. Easy picking for her. The recruiters for the popular companies were barely talking to people they had so many people applying, while the other companies were practically doing the first round interview right there.
I just don't want to go to a meeting where people just sit around and circle jerk about python and bash on .net because "lol Microsoft is evil" then give me crap for not trying to force my clients to change their entire stack. I can write python, I can write ruby, but I can usually make the most money writing .net or Java.
Something I picked up on my own. All I got in college was C++,Java, and a smattering of LISP, python, and Ruby(On Rails). I did my senior project in C# though. Simple little game using SFML.Net
I'm a 39 year old ASP classic + SQL dev. Damn kids these days with their node and Angular. Get off my lawn... or come work for me. Whatever. 
Just like any point in the past (and probably future), there is always hype about new stuff. The young kids want to do Node.js, Angular.js and a document database like MongoDB. Or some other form of JavaScript stack. That is the 'hip' way to develop nowadays (or maybe that was last year). As someone who mainly does enterprise applications, I have to admit that a lot of the .Net tooling is very comfortable to use and allows me to be very productive. Also in terms of debugging and deployment, there is a truckload of tooling. Some of these things I have yet to see for Node.js. Does that mean Node.js is bad? Not at all. To come to my conclusion as a slightly older dev (33): * There is a constant stream of new tools and technologies, some of which are awesome solutions to particular problems. The landscape evolves and this is great! This is what I signed up for, perpetual innovation! * There isn't a single technology stack that solves all problems. You have to choose the right tools for the job. You can break up a piece of wood with a hammer, but a saw is more accurate and practical. * Younger devs gravitate towards the new stuff, experienced devs will use the tools they need to productively solve the problem. * You can always shape younger people by showing them experience. There is the occasional one that remains stubborn and doesn't want to learn anything but his tool of choice. But usually if you show them some stuff and ask them how to go about something like that in their stack of choice, you can constructively learn together and make the right choices.
Can confirm, having recently left my job of 10 years I was very surprised to see just how in-demand .NET skills are at the moment. I got accepted for a job, handed in my months notice, took my CV offline etc, and before I had even started the new job already had 2 other companies trying to outbid them and a further 3 offers of interviews.
This is a great book. Its fairly high level but covers a lot of common architecture things you'll see in the .Net space. http://www.amazon.com/Microsoft-NET-Architecting-Applications-Enterprise/dp/0735685355/ref=sr_1_3?s=books&amp;ie=UTF8&amp;qid=1424431055&amp;sr=1-3&amp;keywords=dino+esposito 
Move to nz. If you got exp you'll get snatched instantly. We're struggling to find decent .net devs. 
&gt; Startups just haven't been using .net because it's more expensive than free... until now. Then those startups haven't looked hard enough. [BizSpark](http://www.microsoft.com/bizspark/)
&gt; C# is the language that I wish Java was. Heh. That's pretty much what I said when I went to an MS pre-launch party in 2001. "It's like Java, but done sanely!"
It also depends on the profile of company recruiting. I assure you .NET is alive and well in the enterprise setting. The open sourcing of .NET etc. is likely to promote broader adoption within the larger community and also to make it easier to teach in school (an acknowledgement by MSFT that outside of the enterprise setting the situation you describe exists). Nonetheless, *inside* enterprise custom app development is still predominantly .NET and Java.
It might be a problem with WinForms and how it handles drawing of the form. I tried implementing a "duck hunt" game in Winforms a few years back and found the performance to be quite crappy. I'm wondering how well it'd hold up if it were done in WPF. Admittedly, that game I wrote didn't use any kind of multi-threading. Your version with multi-threading looks quite nice and to me it feels exactly the same as the Javascript version.
I think you need to do some more investigation. On my machine. The JS version is laggy to the point of unusable. The C# version smoothly follows the cursor around and renders a lot more realistically. I compared the JS with the non-threaded C# version. Also, having never used the LockBits method, I looked at its documentation. I noticed that in the example code, they marshal the bitmap data into and out of a 2D array. Any reason you didn't do that?
He is a recruiter. Same bag as estate agents, car salesmen, and accident claim solicitors. 'nuf said.
I'm so happy that Akka.NET is moving to 1.0. I have been following this project for a while now, and reaching 1.0 means - as an Architect - I have a certain degree of confidence in using it in a new system that I am designing for production use. Frankly, I don't like Project Orleans, and I'm a huge fan of the Erlang/OTP platform. Frankly, Akka.NET is making my life a whole hell of a lot easier. After our system is in production, I'll write all about it. For now, I'm restricted by our NDA. =( Anyway, thanks again for all of your hard work!
Look outside of DC for someone willing to move to DC. 
LOL. Yeah, now please show me how to do a regular line-of-business UI in javascript without having to resort to a bunch of retarded third party libraries because HTML is so fucking completely useless that it doesn't even have a fucking DatePicker. Yes, it might be better suited to do completely irrelevant useless bullshit no one gives a single fuck about, now show me something useful, please.
I'm a 23 year old with a .NET job. I've spent some time using linux, and I prefer working on that. However, I know the majority of people I graduated with just want good jobs. When I decide to find my second job, I'm just going to be looking for the best offer (that doesn't use php :)). If my my two options are a rails job making X and a .Net job making X + 10k I'm going to keep working in .NET. Sure I don't think a lot of the top people, from the top schools, are rushing out to work with .NET. However, I know there are a lot of capable young people that just want a job, and will learn anything.
This should be titled: WinForms and GDI are slower than JavaScript Canvas, to which most people would reply: well duh.
I agree. My team is made up of almost all under 30 year olds (about 10 of us) and we develop in .NET. I'm the youngest at 21 and I love it. There's nothing I'd rather use. 
On my box: The JS version isn't laggy, but it's not particularly smooth in FF 35 and IE 11. It's better, but nothing incredible in Chrome 40. The non threaded forms version is noticeably smoother and faster than the JS version (I see no difference in the two C# versions). 
Don't hate JS cos of HTML bro.. JS is sinfully simple at times
I just spent 6 months at Amazon, making very good money, building classic ASP apps. See, with classic ASP, those pesky session states become less of a problem when using load balancers... so cheer up! Oh, and I'm 47.
vNext is open, multiplatform and has all the cool stuff people rave about in other platforms. It'll bring people in. 
Yeah, I think this is pretty dead on and has been my experience as well. Even if it's not government work, but just a bigger .NET shop - the people who are truly passionate about programming and keeping up with current stuff are going to be the minority. That's probably more related to the size of the company vs. the tool choice though.
Do you recommend the first edition or the second edition? The first addition looks to cover more directly the topics I'm interested in but the second one may also cover those items in a more succinct way.
I understand what you are saying. However, IMO that's just the costs of doing business. No matter what platform you use, you will always have hardware/etc costs. Sure, you won't have CAL costs on a linux box, but you also won't have the support that MS offers either. I was generally talking about the tools (VS) being free now, though. Also, from what it seems, vNext is looking like it will be able to run on linux. Again though, the server support won't be there. Just my thoughts though (I could be missing the point), I'm just a developer, not a full stack evangelist.
I'm a .NET developer in DC.... you need a new recruiter, as others have said. I'm also 28. Probably won't move away from .NET anytime soon...or maybe I will once they stop paying me so much money...also not anytime soon.
Yea, I think "need" was too strong of a word. 
Q: "I'm looking for somebody with basically no experience in C#." A: "Sorry, all of our fresh-faced newbs are feigning knowledge of other languages." That's not a dig against other languages out there (you could easily swap any language for C# in this conversation). Just a dig against giving undo consideration to the whims of people who you're basically going to have to train up. But, don't feel bad about that, because most of these kids are just as useful to shops using whatever language-o-the-week they say they develop in as they would be to you.
Hey there SarahC, I'm a senior C# and Javascript / HTML5 engineer (game development). The web browser performs a lot of optimizations behind the scenes, and the canvas interface for Javascript is very high level. Therefore, you can expect to do a lot less work. GDI in .NET wasn't ever really known for draw performance, and there are several reasons for this. However, as far as I understand, the bottom line is that GDI is not hardware accelerated. HTML5 canvas is extremely modern and takes advantage of the various browser rendering pipelines, including hardware acceleration. If you really want to use C#, you should WPF or SlimDX instead of GDI. Lastly, you could embed WebKit into your C# app using various libraries/frameworks such as Awesomium.
.NET is a hard choice for startups to make, and startups are where all the kids want to be. Currently, it's still quite cost prohibitive. Open sourcing the .NET core and offering a free IDE will do a whole lot to change that. You need a different recruiter, it sounds like. Also, are you trying to hire kids or software engineers? As a .NET developer, I'm much happier at an established company rather than a startup that might not be around in 3 years. 
We simply disagree based on experience (I would love to hear about .NET backed startups in DC, I can count the number I am AWARE of locally on one hand... I can name at least a couple dozen Python shops). I can assuredly tell you that in the startups I worked at -- not only was .NET not used, but you would be mocked for recommending it in most cases. I have worked in Erlang, Go, Python, Node and Ruby at startups -- never even had .NET considered seriously except around when Windows RT was released and their were discussion on how to support it, we ended up not bothering (and what a good call that was!). Hell, at most of the startups I have worked at I was the odd duck for not running OS-X as my primary development environment. MBPs for development, Linux/BSD for deployment seems to be the overwhelming majority. As for in government/enterprise contracting, embedded isn't anywhere near the majority -- it is mostly boring apps in VB.NET or C# doing the rigamarole of government/enterprise work... crunching numbers, putting in orders, managing schedules, etc. Often 3rd or 4th generation ports of ancient software. 
&gt; Scala You should look into F#. It is a functional language but is completely .NET compatible, and influenced by Scala. I've started to use F# in my daily work, and it's fantastic. I prefer the syntax and approach of F# to C# at this point, and none of my .NET applications care.
eh... BizSpark is good but it comes with strings attached, which can be hard for some startups/SB owners to get over.
You can do that. Since Visual Studio 2012 you've had the ability to directly tweak the code windows. Check out CodeRush for some examples of them replacing the XML comments with formatted text blocks. http://www.skorkin.com/2011/05/visualization-xml-doc-comments-painter/
&gt; kids learning to program is limited to Visual Studio Express that doesn't allow plugins. They don't need plugins when first trying to learn the IDE.
this is exactly what i was after, thanks
I've read the book, and found it a bit too high level. Looking at the source code of the solution that comes with the book is useful. 
OWIN or Self Host. It's a very well supported scenario for Web API 2.
Well TIL. Never knew that. Thanks. 
Most of what I saw was out of date, didn't know if it supported latest .net version
Bitches love that MEAN stack amirite?
You don't even need an application installed on their system to do this, if you are on an Active Directory domain and you have administrative credentials just start the remote registry service on their system, connect to their hive and modify `HKEY_CURRENT_USER\Software\Microsoft\Windows\CurrentVersion\Policies\System\Wallpaper`. I used to do one better and set the login screen background to something obnoxious, most people couldn't figure out how to undo that one.
No, they don't need too. However the word 'crippled' gets tossed around when people talk about VS Express. Visual Studio used to have 3 or 4 level of tiers. You know that you are going to use crippled version (yeah the Ultimate version contains everything but that's out of reach to most kids). 
More comparisons, please! I need more convincing before I go full webscale.
A lot of kids are starting programming to be able program Apps for their mobile phone/tablet. If they have a Mac, xcode is available for free and complete. If they want to develop for Android, they will download Eclipse or Android Studio. There you go, that's what? 90% of the mobile market? Now if some (weird) kids somehow wants to developer for Windows Phone/Tablet, they have to get Windows 8 machine. If you only have Windows 7, it's pretty much 'fuck you, you are not welcome' experience. So if you have a slightly older computer, this gateway is pretty much out of the loop. So on the web development stack, .NET is facing Rails, Python, JVM languages, and Node. Especially Node because it means you only need to learn one language for frontend and backend. At least .NET has a fighting chance on this front. For the mobile development, Objective-C and Java rule the kingdom. .NET has no chance there.
As if anyone would give a single fuck about what a fucking dinosaur javatard from the 50's thinks. Go back to your cave, caveman.
I'm currently studying Windows Communication Foundation which is used for Service-Oriented Architecture (SOA). I will be reading [Windows Communication Foundation 4 Step by Step](http://www.amazon.com/gp/product/0735645566/) but I've already gotten started by following a few tutorials. Today I tried out WfcStorm which does performance load testing of WCF services. Combined with Entity Framework, Windows Communication Foundation seems to be the current Microsoft technology for enterprise solutions. 
I don't understand why this has to he a web app? Why wouldn't you go to a service or a console app listening on a port?
With the program, with the comparison, or with this post?
This is surprising! What CPU's do you have running? I would have expected the V8 engine to have unwrapped what it could, and have done the best job. Interesting, it would be cool to investigate.
Thanks for the tips joshrmtv, I'd not realised what the canvas was doing, and it was quite an eye opener on the ways hardware acceleration is used... It looks like a DX panel with SlimDX to interface managed code to it would offer a good and fast platform. I'm using SlimDX for DX 9 (no installers for Win 7, oh yeah!), but have no information on getting pixels rendered to a 3D device. Would a quad with no lighting, and a texture mapped 1:1 with screen pixels work? (is that even possible?) I'd not heard of Awesomium or those kinds of frameworks, I think I'll have a play around with them a bit.
HTML 5 sucks due to JavaScript and prototyping... everyone everywhere else (besides weird Haskell programmers) does OOP... JS comes along and says "Oh you can almost do what you want, but you have to do it alllllllllll a different way." Damn thing.
Nothing spectacular; i7 3770k, GTX 680. 
I've been a .NET dev since C# was named COOL. I've also worked in a 3 positions around the US and now working for a subsidiary of Amazon (Woot). The thing I've noticed is that almost everyone loves C# as a language and .NET's BCL is solid. However, not everyone likes Windows, which you are forced to use. Along with that come high licensing fees for Windows Server. As Microsoft pushed more multi-platform there's a chance it could do better. To be honest though the larger thing I've seen is fungible engineers. You shouldn't define yourself by the language/frameworks you know. A large portion of the engineers on the team had no previous .NET experience.
The high school CS AP test in US is Java. The courses at my kids high school are three levels of Java, beginner, intermediate and advance. No MS classes and his computer club is pretty negative on MS stack. They do JS, Java and recently Node. Similar for son at University. They do not have any classes that use MS stack. In talking to him the school professors are pretty negative on MS technology overall. MS has a brand issue with young people that they really need to address, IMO. 
Makes sense. Thanks for your input!
all those abstract classes make me shudder.. i hate to handle the class hierarchies that tend to grow out of that. 
All good questions. Yes, what are you making?
Db first. Thinking about the database comes naturally for me and you'll eventually need to know every detail of your database anyway when going beyond the most trivial of use cases.
EntityConfigurations's are the fundamental element of doing CodeFirst *right*, even if you're not designing the DB separately from the class model.
Code First. It's the way that always makes more sense - to me personally at least.
DB first all the way. A good database is the cornerstone of almost every good application, and it's just way too tedious to do in Code First.
There are some drawbacks to Code First that aren't mentioned here (other than just preference). I've done commercial apps in both and I find Code First to still be the way to go even though it can give some headaches. Why? Having your database structure with a log of the changes to structure, and being able to have test data automatically be setup for new environments is ridiculously useful. Unless you want to use RedGate for DB source control then Code First is definitely the way to go. If you go DB first then you just end up with a separate process and you're relying on how EF interprets the way you create the DB. Pain points for Code First: * Some migrations can be hard for EF to do itself so you have to hold its hand sometimes * If you have CI then it's not recommended to use EF to automatically migrate your changes on the production database, which means you still have to script the data (on the plus side you can generate the scripts through EF) * If your DB has complicated relationships then you have to be really careful about how you define them in the code, and it can take a while to figure out how EF wants you to define them. Saying that, the good points: * Source control for your database, plus a history of those changes! * Triggers end up being way more powerful due to being able to define them in .NET code (rather than specifying them on the DB, you just hook onto the event) * You can create some real powerful stuff with Code First that would end up being really confusing with Model First (inheriting fields from abstract models, etc)
DB first of course, a pure relational database doesn't quite work in real life situations. edit: I feel that it is better for us to assume both roles of the db &amp; app developer when necessary then attempting to consolidate them into a single role of app developer through the use of tools such as EF.
Microsoft's ADO.NET team has no idea what they are doing. They are just flailing about and have been since at least when .NET 4.0 was in development. Hell, the one really big win in this space was LINQ to SQL and that didn't come from the ADO.NET team. 
I believe this has the process you're looking for http://azure.microsoft.com/en-us/documentation/articles/web-sites-publish-source-control/ 
To add to this, we also have a develop branch. We do feature branches and merge those into develop. Then when merge to master on deploy. Maybe a little more complexity than op is looking for, but it is an option that might fit their needs. There's also a pretty good write up to read here if you want to get fancy http://download.microsoft.com/download/B/C/8/BC864212-F00D-483D-9CAD-CE5593EE010D/Continuous_Deployment_Using_Microsoft_Azure_Web_Sites.pdf
Thanks so much for your response. This was an extremely useful list of pros and cons.
Dont know? But thats what the Changelog says.
I was thinking the same thing. I thought I was missing something somewhere...
It's worth noting, that, at the core, this is the point of an ORM (Object-Relational Mapping). If you're planning on using an ORM, and don't fully understand the benefits or reasons for using one. You should look into doing some some research on your specific use-case and the best options.
I've done it all the ways and I have to agree this is the correct way. 
Same thing in out main product. I'm trying code migrations in a smaller product and I'm wondering how it behaves when a team bigger than 2 people starts working on expanding the domain layer...
You no longer need the powertools. This is just built into EF now.
I'm personally enjoying working with lightweight ORM's right now. Dapper, Petapoco etc. 
DB first for me but that's partly habit and also because I don't think the tooling is really up to it. I know you have Code First and it's a step in the right direction but it's not baked in like it is with Rails and Django.
One of them. And I don't feel bad about it. Web MVC is nothing more than old Model2 pattern which itself is a specialization of MVC family for web. Obviously web mvc can't have stateful viewmodels like mvvm can, but I still think that the name applies pretty well.
I had visions of wanting the same thing for my project, which was setup the exact same way (I use Azure Websites); however, I could not see the advantage of the deployment server pulling my project from git and building it itself. Instead, when I want to deploy (to testing or production), I pull the branch I want to deploy to my dev machine, build it and click "publish web site" within Visual Studio, and voila, it's done! http://azure.microsoft.com/en-us/documentation/articles/web-sites-dotnet-get-started/ I do think there is value in using Azure's Visual Studio Online to monitor git and perform builds whenever it changes... but haven't gotten there yet. Maybe someone can explain to me the benefit of having the server build and deploy in one step, because I can't see one. EDIT: a little advice, using 'publish web site' in Visual Studio does not copy everything (web.config for example I believe), so you have to FTP in sometimes, and the only way I could find to get your Azure FTP credentials is by downloading and searching through your publish profile
This looks like a standard REST implementation to me.
Great point. As for your F# comment, I'd be interested to know how that goes. I've heard db access through F# is insanely easy, so I'm pretty curious as to how plugging an F# data layer into an MVC app would work out.
Without seeing how you're instantiating your `Course` and `Faculty` objects, I can't say 100% for sure, but try this: public virtual Faculty Faculty { get; set; } By marking the navigation property as `virtual`, you allow EF to override the implementation and [lazy load](https://msdn.microsoft.com/en-us/data/jj574232#lazy). You can also explicitly load the related `Faculty` object eagerly using `.Include()` or lazily using `.Load()`.
~~Lemme give this a try, thank you.~~ ~~Edit: Will I have to drop/recreate my tables to get this to work~~ Edit2: This worked! Thank you!
UI -&gt; model -&gt; database. Code around your users, not your database structure. 
Ah yes, the [Object-relational impedance mismatch](http://en.wikipedia.org/wiki/Object-relational_impedance_mismatch).
Many upvotes for you! Thanks
At face value it seems git has more mainstream support. Especially due to native git support being available in Visual Studio, as well as Microsoft using github for their open source projects.
Can you give a bit more detail on that? We primarily use TeamCity and/or straight up Azure for our CIS. What advantage does Git give us as far as branching is concerned?
I used database first for a few years since much of the tables, views and stored procedures were already in use. Lot's of webforms stuff but recently doing new development with MVC and now I see the light. For new stuff - it seems to be the best option.
Mind numbing work and bad tools will rot your brain. Be the best you can with the tools you enjoy and you can write your own ticket. (Unless it's FoxPro) 
Sorry.. but I doubt Microsoft has *anything* to do with Git's success. Microsoft moved to Git and away from its own version system (Team Foundation Server) because *Git is where the developers are*, and Microsoft got tired of waiting hoping that developers would come to them. And no, I'm not some MS hater. I worked there until not too long ago. 
I'm learning about bump maps and normal maps so I can do a shader in DX 9 for illuminated sprites. It exists in XNA and Unity... but I want something that can be run from the exe, without an installer.
You can? I shall google in work, ta. I've read of writeablebitmap...
I think github is a factor, but I'm also kind of surprised that no one has mentioned Linus and the little open source project he runs using git.
A reply ought to be relevant to the comment you are replying to.. not the subreddit you are in..
well that escalated quickly
&gt; Mercurial, while being a fork of Git from a while back I don't believe Mercurial was ever a fork of git. They were both started independently around the same time.
ADO.NET team is in the business of rug pulling.
That's a good point. As a rule, I tend to keep my class hierarchies flat as possible. I'll stick to this rule throughout the tutorial series.
Why are nested block comments forbidden: http://stackoverflow.com/questions/2969198/why-are-nested-comments-forbidden
I dont think its the editor that is the problem here. You specify yourself that you want to end the comment there, so why do you want other behaviour?
Looks awesome :) Will have to give it a try.
Not a Lawyer, did not read the EULA, etc. So here is my (hopefully educated) guess : they won't. VSCE seems more in line in the opening of MS in the broad sense (Azure hosts a lot of technologies including php or node.js) and VS is more and more an option for other langages outside of the "pure" windows sphere. It will also increase the MS ecosystem with new programmers. The free editions were a bit too limited to allow their adoption on a daily use basis. I see it as a trojan horse on the MS Stack in a way. Once you use VS, you have .Net, azure, windows phone, nuget, etc. at hand. And I don't believe there is a better IDE than VS today (and I use a tons of various IDE for work reason). So why set a limit ? My guess would be to give them options to sue if need be, and also to prevent existing users to massively migrate to VSCE. Two options : 1. you're decent, conscious, law abiding company and then those values are indicators for you to know if (or when) you will have to budget using another (paid) version, if ever. 2. you are not going to respect the EULA, for any reason that you will deem good enough (no budget, little project, risk vs cost assessment, etc) and then you will use it or, while you are at it, use a pirated copy of a "paid" version. In number 2, in case of a control (if your country has that kind of thing) your company will be fined, some people might face jail time, etc. Probably more if using a pirated version, but that's just a guess. 
The question is why you want nested comments... The C# coding conventions implies that line comments should be used. Perhaps you should reconsider your approach? [C# Coding Conventions](https://msdn.microsoft.com/en-us/library/ff926074.aspx) &gt; * Place the comment on a separate line, not at the end of a line of code. &gt; * Begin comment text with an uppercase letter. &gt; * End comment text with a period. &gt; * Insert one space between the comment delimiter (//) and the comment text, as shown in the following example. &gt; &gt; // The following declaration creates a query. It does not run &gt; // the query. &gt; &gt; * Do not create formatted blocks of asterisks around comments. Is there any reason why line comments does not work for you? Why do you need nested block comments?
And what would you use nested comments for? They are comments arent they? They are there for commenting, what is the whole use of nesting then?
1. This blog post is **old**. It's from 2008. 2. The solution is **slow**, as it's using regex for this (but probably *fast enough*). 3. This will be obsolete with C#6.
I don't think I should have to explain. Sometimes I need to comment out a block of code and if said block contains block comment we have the problem.
Take a look at the [source code](http://referencesource.microsoft.com/) and find out for yourself!
Use the IDE functionality to append the lines with // and u can put whatever you want in the comments, option for you?
Yeah I hope for the same. Hope they'll have a trial when they go live. Currently you have to pay the $75 to try it.
It's not Visual Studio's problem. It's the C# specification you're fighting against. &gt; Comments do not nest http://download.microsoft.com/download/0/B/D/0BDA894F-2CCD-4C2C-B5A7-4EB1171962E5/CSharp%20Language%20Specification.docx
A company with 250+ users will typically have an Enterprise Agreement, and as part of the EA you'll be audited (or self-audit using MS tools) to "true up" your licenses annually.
I'd rather not, thanks.
Great, the early-access-game model has come to the software world. I will have to wait until it releases to see if they have a trial. 
Initial success of Git was due to who developed it. If Mercurial had anyone on that team with the same popularity then it would have been tied. But Git ended up with the initial push because of that. Then Github came along. It didn't need to be that great of a site considering the alternatives at the time, it just needed to be slightly better than SourceForge... I know, not a high bar. But that was enough to get the momentum going. From there it's just momentum keeping it going. In 10 years or so, something else will come along and knock it out of the top spot and the cycle will continue.
You don't think you should have to explain? Are you asking for help? If so, this is not the correct approach my friend.
&gt; Any fix to this most annoying behavior?
I went from Git now working with a company with Mercurial. They only things thing I miss is the better tools Git has. I miss you GitExtensions.
If you are pure Windows shop stay away from Git: * Git under Windows is second citizen (releases on Windows always stay behind Unix release - where is 2.3 on Windows?). * Git under Windows is slow (Git porcelain is inherently incompatible with win32 process model where process creation is quite costly and making tons of new processes to execute git rebase --interactive takes ages) * UI subpar support (VS integration too basic, Atlasian SourceTree slow / bugs, TortoiseGIT - you always have to r-click to get something and UI is not quite friendly) Bonus: Google for "Steve Losh Git Koans" (git command line is less than optimal to put it mildly)
Typical FUD on Mercurial: hg rebase is in standard distribution of Mercurial since dawn of it. 
No idea why you would want to, but can't you just set an hourly trigger on the CI server?
&gt; I'm currently studying Windows Communication Foundation which is used for Service-Oriented Architecture (SOA). Nope, it's used by people that don't understand SOA. They both have service in the name but that's where the similarity ends. Unless you have a desktop client or public API then there is no reason to use wcf.
I was studying .NET Remoting but then I read that it was superseded by Windows Communication Foundation. I need to create a shipping application which can get shipping quotes from many sources and figure out the best option. WCF seems very flexible and capable of doing that.
WCF is irrelevant to this. Not to say it won't be used to comunicate with third party API's, but it has nothing to do with the internal structure of your application.
It won't be any more distributed than a typical web application though.
It will be good enough. The project is doomed anyway. I'll just show the client something like the AppFabric Dashboard and WcfStorm and they will be impressed.
GitHub and the Linux kernel I would say are the two reasons why there's so much git out there.
true, hg/mercurial/bitbucket vs git*-everything. latter obviously have the better sense for marketing :)
: nods :
I've been using the plural of a keyword to get a list, ie; /api/employees Another alternative for creating a sick record is a POST to /api/employee/{id}/sick/{reportid} With WebAPI 2 route attributes this is nice and easy to do. At the end of the day though, my usage of REST comes down to the correct verb usage and a well structured and easy to understand URL convention.
Do you have any screenshots or videos? Sounds cool
It could just be that the mobile device can't keep up with the processing power needed. That seems unlikely though.
I think you're right that it's unlikely. The overall page size is less than half a meg. But I'm having some trouble understanding how to profile this correctly. Thanks again for your comment! If you have a moment, would you mind opening this up in your mobile browser and trying to help me determine the bottleneck? http://prokoreajobs.azurewebsites.net
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Link prefetching**](https://en.wikipedia.org/wiki/Link%20prefetching): [](#sfw) --- &gt;__Link prefetching__ is a proprietary syntax to give web browsers a hint about documents that it should pre-fetch because the user might visit them in the near future. It is proposed as a draft internet standard by Mozilla. A web page provides a set of prefetching hints to the browser, and after the browser is finished loading the page, and after an idle time has passed, it begins silently prefetching specified documents, storing them in its cache. When the user visits one of the prefetched documents, it can be served up quickly out of the browser's cache. It is most effective in cases where the content provider may be reasonably certain which link or links the user is going to visit next. &gt; --- ^Interesting: [^Fasterfox](https://en.wikipedia.org/wiki/Fasterfox) ^| [^History ^of ^Mozilla ^Application ^Suite](https://en.wikipedia.org/wiki/History_of_Mozilla_Application_Suite) ^| [^NetJet](https://en.wikipedia.org/wiki/NetJet) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+covq1ka) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+covq1ka)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
That filtering should go in the controller/below not in your view.
Apparently it won't be supported out of the box, but they will provide support packages to handle other languages, as noted here: https://github.com/aspnet/Home/issues/236.
That's possible. They likely went with this path because it is easier to support one language, C# being far more popular and also with the new open source push because VB is not open source.
Do you recommend any reading material for people like me who want to transition to C# when all they know is VB?
There shouldn't be much reading material needed. The major difference between VB.NET and C# is the syntax. Understanding the different keywords and object modifiers will go a long way, as well as getting used to putting parentheses and semicolons. If you turn the Explicit/Strict Options off in VB transitioning to C# might be a bit trickier. Also, VB is constantly compiled in the background but you have to manually build/compile for any errors to show/clear up in C#. Anyway, check this out for learning C#: https://msdn.microsoft.com/en-us/library/a72418yk.aspx It won't all be needed, but there is a lot in there about the syntax. A lot of MSDN articles have examples in both VB and C# and comparing the differences there would help as well.
^ This. I've seen a number of Java script libraries (and some server side ones) that do paging/sorting/filtering client side. It's essentially copying a large portion of the database on every request. It's slow at best and a security breach at worst. Let your database do what it does best.
The VB.NET compiler is just as open-source as the C# one, both are part of the Roslyn project.
That'll continue on for another 15 years. People still support classic asp. But I agree with the sentiment, even though there's a lot to like about webforms.
I suspect it's in a big way due to the uptake of GitHub. Bitbucket is good in its own way, but it's maybe not on the same level as GitHub, though it does have some advantages. I think that Bitbucket being owned by Atlassian is a point in it's favor. Also, Mercurial was written to be cross-platform, while Git was not, which makes me prefer the former more as a primarily Windows user. Tooling support for Hg on Windows seems better than Git on Windows, in SourceTree at the least. I haven't used either tools or platforms enough to say with authority, but at this point I suppose that momentum and mindshare are advantages in Git's favor. I'm a bit torn, having one foot in each camp.
I wonder if the tag helpers still work with refactoring. I use the lambda notation for tags for pretty much everything because of the refactoring support. 
How is this not top comment?? 
Sadly, no other IDE comes close to Visual Studio. I prefer SQL Server, but I can make do with MySQL or Posgresql. Hell, if they made SSMS for Linux, I'd be using RHEL.
To.. where? The program is fine to use, and it will be for many years. You can slowly extend it on a new base, step by step replacing old parts as you implement new ones. No need for reporgramming.
Thanks so much /u/Vizer20. It turns out you're right that the javascript "footable" plugin was having trouble rendering that many rows. On desktop it was great, but on mobile it couldn't handle the strain. There was a lot gained by sending all my rows to the view and doing the pagination/filtering client-side, but it seems like that's going to be impossible given the slow load times. I've already started converting my front page over to just rendering 10 records per table, and it seems to load up much faster on mobile now. Thanks again for your helpful advice!!
&gt; For the first time in the history of ASP.NET, you can run ASP.NET 5 applications on OSX and Linux. Nope, ASP.NET MVC app have been supported on Mono for a long time. I'm running two right now (and have for 2 or 3 years). &gt; GruntJS, NPM, and Bower Support This is a Visual Studio feature, not an ASP.NET feature. Also Gulp is better than Grunt, and both are supported. &gt; No More Web Forms Web forms are still supported. From the ASP.NET site: &gt; You can continue developing Web Forms apps and have confidence that Web Forms is an essential part of the .NET web development platform. We remain focused on adding new features to Web Forms to improve the development experience and keep the technology up-to-date with web practices. They won't get new features, but Microsoft are supporting them at least (I guess in the same way that classic ASP is still supported) 
You built a new app using Web Forms? The writing's been on the wall for a long time now. Microsoft have only made minimal changes to WebForms in recent years. They'll still support it for quite a while, but you should consider it mostly "feature frozen" now. All the new development is going into ASP.NET MVC (and WebAPI which is part of MVC now). Not sure about the ASP.NET 5 story, but the current version of WebForms and MVC can run side by side in the same project so you can slowly transition over. My previous workplace had a hybrid Classic ASP / VB6 + WebForms + MVC app. All the business logic should be totally reusable too, as long as you didn't couple it too tightly with the UI. You *did* use dependency injection and proper encapsulation of your layers, right? :) 
p.s. I've written a [blog post](http://dragablz.net/2015/02/25/material-design-in-xaml-mash-up/) which is a bit more tutorial-like if you want a walk-through.
Hate the syntax.
It's so amazing.. They're cleaning up. 
WebForms are not dead. You can still use them in VS2015 targeting .NET 4.6 Even if you couldn't people are going to be swapping VS2012 or 2013 for years. Even if they did want to swap them all in 6 months flat many projects are going to require maintenance and support for years to come. You can look forward to many more rounds of interviews with WebForms questions.
I understand and I completely agree with you. I'm just saying that from my *own* career perspective I still have the flexibility to be picky with what positions I take and that I wouldn't want to be in an environment that was exclusively WebForms. My team's software suite is at best a 50/50 MVC/WebForms+classic ASP split. For older applications we don't necessarily want to grow and enhance we're absolutely going to leave it as is. For applications that the business wants to grow, enhance, overhaul, and change, it makes sense for us to consider undertaking the migration effort to facilitate the longer term product strategy.
It is a lot more stable that CTP 5 and hell way faster than Visual Studio 2013.
It's really pretty easy, I've hired two straight VB devs in the past (we're a c# shop) and they were up to full speed in a couple of weeks. You don't have to learn a whole new ecosystem, just change your syntax.
I'm gonna go out on a limb and say your users probably won't understand CSS. Have you thought about using a CMS? You'd be able to setup templates to define your views and add properties for the things you mentioned (background image, colors, etc.).
I spent 5 years making the application and learning ASP.net along the way while running my company. That's interesting that MVC and WebForms can run in the same project. I'm going to just have to rewrite it one screen at a time. Fortunately I made almost everything out of user control ascx objects. It shouldn't be too hard.
If it's just a few small properties they want to change maybe you could store these in the database. They can then modify them like any other record. It's possible to serve up the CSS dynamically with properties set at run-time: http://stackoverflow.com/questions/4492748/dynamic-css-for-asp-net-mvc Not sure if this is easier but it is another option.
Why do you think Web Forms are going away? Microsoft indicates on their ASP.NET 5 overview page that Web Forms will continue to be supported. http://www.asp.net/vnext/overview/aspnet-vnext/aspnet-5-overview#webforms
Articles I'm reading are saying you have to target framework 4.6 if you want to use web forms. (For example: http://stephenwalther.com/archive/2015/02/24/top-10-changes-in-asp-net-5-and-mvc-6 which is just a couple lines away from this post at the moment)
 select * from tablename where column like '%searchstring%' Like that? I'm not 100% sure what you mean
You need to use LIKE instead of =, as well as the % wildcard for SQL before and after the search term will do it. But I want to warn you that it looks like the way you're writing that SQL string in code opens you up to SQL injection attacks. You should port your query to entity framework or a stored procedure so you're only dealing with parameters to pass. Especially if your taking user input directly from a search box. 
The equals in SQL does a direct comparision and will only return exact matches (case may or may not matter depending on your coalition settings). In order to match any item that is part of the search string, you should use the LIKE operator. Additionally, USE PARAMETERS IN YOUR SQL STATEMENTS! Sorry, not a rant directly at you, but anyone that comes across this and is not aware of parameters. strSQL = "SELECT * FROM CDReviews WHERE Artist LIKE @pro_type" Then, however you are issuing your SQL command, you set the parameter values on the command object itself. var myCommand = Server.CreateObject("ADODB.Command"); myCommand.ActiveConnection = myConnection; myCommand.CommandText = strSQL ; myCommand.CommandType = adCmdText; myCommand.Parameters.Append(myCommand.CreateParameter("@pro_type", adVarChar, adParamInput, Len(trim(pro_type)), "%" &amp; trim(pro_type) &amp; "%")); Note - it has been some time since I have had to break out ASP classic syntax, so the above code may not be 100% syntactically correct, however, it should convey the proper idea. Some information was taken directly from here: [http://stackoverflow.com/questions/14237755/t-sql-and-the-where-like-parameter-clause](http://stackoverflow.com/questions/14237755/t-sql-and-the-where-like-parameter-clause) and here: [http://www.w3schools.com/asp/met_comm_createparameter.asp](http://www.w3schools.com/asp/met_comm_createparameter.asp)
As others have pointed out, you want to use LIKE to search for the query text. You might also consider doing this: 1. First search for exact match and report that back 1. Then search for LIKE '%query%' to report back anything containing the text 1. Then split the query text on spaces and search for (1=1 and column Like '%part1%' and column like '%part2%' ...) This searches for matches containing EVERY word in the query. You could change to (1=2 or ... or ...) to search for matches containing ANY word in the query. Between these queries you should get a nice set of results with better ones on top. You can also run these in a union with an extra constant value to order on so the exact matches sort to the top. And be sure to avoid SQL Injection because you said you're taking the raw text the user has typed (Hint: make sure it doesn't blow up when someone searches for "Jon O'Brien")
[Here you go.](https://github.com/ilich/MvcReportViewer) This still requires including `Microsoft.ReportViewer.WebForms`but it does not require any aspx pages.
Ol' "bobby drop table users" at it again! :)
I'm glad my repository inspired you! This looks great, good there's a XAML alternative now. EDIT: typo
It reminds some people that they were VB6 programmers once and not considered real programmers :-)
Just to note, here... This seems like a terrible way of doing whatever you're doing. If nothing else, if you want to do this in SQL, you should use parameters to protect against injection attacks. 
I would recommend looking into **TCPClient** and **TCPListener**. I know you said you're looking for something peer-to-peer but it would probably be simpler just to have one person host the chat room (server) and everyone else connect to that person. Then you would just need the server to broadcast any messages it receives. [basic chat server](http://www.dreamincode.net/forums/topic/33396-basic-clientserver-chat-application-in-c%23/)
It will limp on of course, but you'd have to be crazy to be starting any new projects in it.
&gt; Plus, a good dev can make a good webforms app. I don't doubt that it's possible, but I've never actually seen this mythical "good webforms app" in real life.
&gt; We still use web forms for smaller projects because we have a large investment in architecture built around it over the last decade+ or so. It just wasn't a productive task to just rewrite everything while it was wholly supported as a first class dev platform target. I'm curious, what architecture have you built up? Only the UI parts should be relevant to web forms.
It's compileable, so at the very least you should be able to get compile time errors.
You might be confusing .net framework versions with asp.net versions. 
You should read up on sql injection. It's a common way for hackers to screw with your site and what you are doing could leave you open to it. The way to protect yourself is called parameterized queries. 
While I understand why everybody wants {1, 0} to map to {true, false}, it's something that I have mixed feelings about. A boolean is a boolean - true or false. That is the beginning and end of the domain of a boolean. Sure, under the hood, it *might* be represented by a '1' or '0' in memory, but that's really outside of what we should be considering. I'll give another example from another language - null, in C++. They were too lazy to actually define a real 'null' primitive/keyword and instead just used '0', because that's what it is under the hood. ... ... Except it's not. [There are certain architectures and platforms where the null pointer *isn't* 0](http://c-faq.com/null/machexamp.html), because memory addresses had flags or other bits stuffed in them. But the language has to enforce the convention-cum-standard, so even though you do something like `int* countPtr = 0;`, under the hood the compiler might actually assign a non-zero value to that variable, but everywhere that you do comparison to 0, it checks for the same Actual Null Value instead. You know what would've been a billion times easier? Just having a null keyword, and not trying to conflate the symbol (`null` or `nullptr`) with its encoding (0, or maybe 0xB000000000000000). So, for this reason, I don't think we should be trying to conflate the boolean-specific symbol 'true' with its in-memory encoding '1'. True is true and nothing else. I, however, have mixed feelings about this though, because we happily conflate the symbol or keyword `true` with its string representation `"true"`, even though they're separate concepts from a value domain perspective, and I can't defend a position where bool.Parse("true") does not work.
I am getting frustrated, because I am still stuck in .net 4. 0, 2010 paradigm. Mostly my fault, not blaming Microsoft at all. it's so dramatically different now. I don't even know where to start to try to get caught up.
&gt; Side note: their naming scheme went to shit on this version. That shiat's crazy.
Thank you, this is a very good argument. I guess I just expected something simple when the data source spits out 1's and 0's, they probably should have been created as bools in th first place.
Technology always changes, new things pop up, old techs grow stale. I dont consider .NET 4.0 ancient or anything. The easiest way to pick up something new is just to dive in, pick a technology/framework you are interested in and spend a weekend trying to develop an app using it. Even if you never make it anywhere you still learn something. I've found that as I'm exposed to more technologies, its easier to pick up the common threads between them.
It's still going to work, but it's pretty clear that WebForms is now in maintenance and not Active Development. As HTML evolves, WebForms will not be updated to reflect the various changes that happen to the standard. It's a pretty clear sign to begin transitioning away from it if at all practical. 
This will not work with the new CoreCLR on ASP.NET 5.
i managed to get rid of this error, but now im facing this: &gt;(Thu Feb 26 10:41:48 2015.1700796) : CLDAPInstanceProvider::CreateInstanceEnumAsync Indicate() FAILED with 80041033 &gt;(Thu Feb 26 10:41:48 2015.1700796) : XXXXXXXXXXXXX CLDAPInstanceProvider::CreateInstanceEnumAsync() Enumeration succeeded for ds_user
PluralSight is the way to go!
It should work in a windows environment on ASP.NET 5, right? The only cross-platform solution I know of is calling the SSRS web service and directly rendering the report as PDF or Excel. It sure would be nice if MS released a modern report viewer, but the SSRS team is separate from the ASP.NET team and they haven't changed it since 2005 (hell, it still uses active x to print).
In addition to the http://www.asp.net/mvc link given by kbst I'd highly suggest taking a look at this video course from Microsoft Virtual Academy http://www.microsoftvirtualacademy.com/training-courses/introduction-to-asp-net-mvc I thought it was a very helpful introduction and general overview of MVC. I'm not even a big fan of learning via videos, but I felt like this taught me a lot when I first started looking into ASP.net MVC.
I don't miss it. THG is also free as beer and SmartGit is 80 USD.
Great overview
would like to know aswell
I've tried the regsvr32.exe in both syswow64 and system32 and both cause the same problem. 
Well, I've been there; In Oracle your options for a Boolean are either a Char(1) (Y/N) or a Number(1) with 0 or 1. Yeah, many ORM solutions have ways to deal with this, but if you're hand-rolling ADO code you have to deal with it on your own. Especially fun when they're Nullable fields.... X_X 
MVA is great. Can't get a better source than the people who wrote it.
It sure isn't! If there's an expectation that you'll only have one element in a sequence matching certain criteria, Single() shouldn't be blowing up (and adding a second element to that sequence shouldn't be a problem). If you'll have multiple items that match, First() could be a band-aid, but you'll possibly want to address the reasons that you're inserting a new element as opposed to updating an old one. Restarting the server is rarely a good look.
Restarting IIS probably won't change the underlying issue, which is that the code is expecting 1 result from it's query but is getting 2 or more.
You're correct. The reboot is a fix for a problem, it's just not a good fix for that problem. 
To me it's weird that `true.ToString()` returns "True", but `bool.Parse("true")` works. 
Not at my desk or I'd give you some code but I don't think iis can do this. What you want to do is have a button they says "use desktop" and goes to your .net code and set the cookie and redirect to the desktop URL (where is can check the cookie). Alternately you could do the same thing in JavaScript if you'd prefer to do it client side. If you need some examples of c# or JavaScript setting cookies and haven't found it on here or Google by tomorrow PM me and I'll send you what I'm using. Edit: it should be noted I don't know anything about mobile versus desktop sites and the best practices behind redirecting to each. Response is only about when/where you'd set cookies.
&gt; Any suggestions on what I should say in this case to make him take me seriously? I don't want to launch this thing in a state where things like this are regularly happening with only a manual IIS reset as recourse! Just do your job and write good code. Make sure he get's the blame for the errors. If it comes up when your casually chatting with someone maybe mention that you know how to fix it but aren't allowed.
[LINQ: When to use SingleOrDefault vs. FirstOrDefault() with filtering criteria](http://stackoverflow.com/q/1745691)
Rewrite noob here, but have you tried this? First, if necessary [make sure HTTP_COOKIE is on the Allowed Server Variables list](http://www.iis.net/learn/extensions/url-rewrite-module/setting-http-request-headers-and-iis-server-variables). Then: &lt;rule name="Optionally Create Cookie From QueryString"&gt; &lt;match url=".*"/&gt; &lt;conditions&gt; &lt;add input="{QUERY_STRING}" pattern=".*desktopversion=true.*"/&gt; &lt;/conditions&gt; &lt;serverVariables&gt; &lt;set name="HTTP_COOKIE" value="desktopversion=true"/&gt; &lt;/serverVariables&gt; &lt;/rule&gt; &lt;rule name="Redirect Mobile Unless Cookie Is Present" stopProcessing="true"&gt; &lt;match url="(.*)"/&gt; &lt;conditions logicalGrouping="MatchAll"&gt; &lt;add input="{YOUR_UA_STUFF_HERE}" pattern="whatever"/&gt; &lt;add input="{HTTP_COOKIE}" pattern="desktopversion=true" negate="true"/&gt; &lt;/conditions&gt; &lt;action type="Redirect" url="mobile/{R:1}"/&gt; &lt;/rule&gt; I haven't tried it or anything, but maybe something like that would work. If your cookie is not necessary for other parts of the application to work, could you just use &lt;rule name="Redirect Mobile Unless Query String Says No" stopProcessing="true"&gt; &lt;match url="(.*)"/&gt; &lt;conditions logicalGrouping="MatchAll"&gt; &lt;add input="{YOUR_UA_STUFF_HERE}" pattern="whatever"/&gt; &lt;add input="{QUERY_STRING}" pattern=".*desktopversion=true.*" negate="true"/&gt; &lt;/conditions&gt; &lt;action type="Redirect" url="mobile/{R:1}"/&gt; &lt;/rule&gt; ?
You are a beautiful sexy person! 
&gt; reflect the various changes that happen to the standard As if webforms followed internet standards \*cough\*viewstate\*cough\*
Ooh I didn't know about Safari Web Inspector, thank you! I'll fire up my Mac and try to learn how to use it. I'm not using $(window).load() as far as I know, unless my fooTable plugin or something from NuGet is using it...?
How different is this compared to a plain old reverse proxy?
Your view model could be something like this (note I've got 3 pints of Guinness under the belt so syntax may not be 100%) public class MyViewModel { public virtual List&lt;Product&gt; Products {get; set;} public decimal TotalPrice { get { return Products.Sum(a =&gt; a.Price); } } }
If you really feel like you have to do it on the viewmodel, /u/ticman tells it true. That said, I wouldn't worry about doing it on the view, either. You're already enumerating over the products, so keeping a running total as that enumeration occurs isn't going to have any appreciable performance impact.
Hey thanks that is what I was talking about. How would you make this super light and eek out as much performance as you could from it? Can Owin be setup to act as a reverse proxy?
Yes I agree. My secret hope is that there will be a .NET 6 with everything open-source and x-platform :). Well allow a man to dream eh?
Thanks for the advice! I was writing on my notes thinking on how to achieve this and I came up with something like this but a little messier.
MVA has the best free courses and it should do it for you. It goes to very basic C# sometimes though so just stick with it for a while. And just an advice and I think everyone will tell you this: FORGET the development pattern you were used to with WebForms. You will not find it in MVC. MVC is not a replacement and not a better replacement for WebForms. (some will disagree) I keep WebForms a "legacy" as i call it. There's still a lot of money in it.
It looks like there is an object leaked per key, yes. How about this one: https://gist.github.com/bbarry/3301a9277742c6a76236
If you get stuck again feel free to post a question again. We are always happy to help if we can. I've been doing asp.net since it came out and I still get stuck now and again. I always find stack overflow to be really good. 99 times out of 100 you'll find that if you are having a problem with something; someone else will have been stuck on it before and posted something on there. And if not, just post a question yourself. They are helpful folk. But again, also ask us if you want. I'm not the guy who answered you by the way, (s)he beat me to it. Good luck. 
Something else you might want to look into is the use of "eval". While it works fine you can get more performant results if you ctype the bound dataset to whatever it actually is. However, since you are starting out I wouldn't worry too much about that for now. Something to bear in mind for the future though. If you want to look into it though give me a shout back and I'll post a sample when I'm at my pc. 
The performance improvement is great news. I was hoping 2015 would be better in that regard. 
I hate to be "that guy" but if you're starting out learning ASP.Net I suggest you don't start with WebForms and instead focus on MVC. Microsoft has taken the first steps of ending support for WebForms by removing it from .NET 5, and you'll need to target .NET 4.6 to continue building WebForms projects.
I've been using Nginx as a reverse proxy for an ASP.Net 5 project (specifically to allow two different servers to be available on the same "domain" to avoid CORS issues, ironically) and it's fantastic. 
Well surely the " indicates that it's a string, so perhaps it just assumes a string can't be a Boolean?
Yes I understand. Thank . looking forward
Just turn it into a lazy loaded property.
 Protected void register_form(object sender, EventArgs e){ If(myValidator.IsValid &amp;&amp; Page.IsValid){ // submit form } } 
Aa this works. 
Upgrade. I had an earlier CTP running side by side with 2013 for awhile w/o issue.
I've been enjoying this series immensely
Thank you!
You can use the standard ASP.NET web cache to reduce hits to the database. This is ideal for reference data - data that is common to more than one user. using System; using System.Diagnostics; using System.Globalization; using System.Web.Helpers; namespace Boobies { internal static class Cache { internal static void AddToCache(string key, object o, int durationInMinutes) { Debug.WriteLine("**** **** Added to cache: " + key); WebCache.Set(key, o, durationInMinutes, false); } internal static dynamic Get(string key) { return WebCache.Get(key); } } } You can cache an entire object/class, lists/arrays of child objects, etc.
DotPeek by JetBrains has a great Create-Project function that will completely reverse-engineer an assembly into a C# project. I have used this with great success in the past to diff two pre-built assemblies.
Neat but you should never publish from your local anyways, always go through a clean continuous build server. And those servers like Jenkins and team city can set up different targets to publish after build or separately and will make this kind of book publishing way easier. Don't encode your notifications into your msbuild, that's really mixing up your concerns there and making your build that much less portable 
I would highly recommend using something like Octopus and a CI tool like Bamboo or Team City to handle package and release management. Once a release is packaged, it should never change or be rebuilt. Octopus also packages your configuration and release schema so your process can change in the future but you can still successfully redeploy your app. Doing any of that from a devs own system is highly prone to errors.
At the time I created v3333 it was trunk bleeding edge. Now we're at v4444 and I'm recreating v3333 only to find it performs differently to the v3333 I built at the time. No, cherry picking, going back in time really.
We're a TFS shop, I'll look into octopus as at the mo I'm managing the config in a separate branch.
Octopus manages your config for you. You assign servers to roles and environments. You setup your config per role and/or environment. Configure your deploy process. It does everything for you. Your version control makes no difference in how you release.
We're doing fat and soak tests and close to shipping, getting any kind of nod to alter/fix anything is very difficult. We're both late and over budget, it's a shitstorm. 
Let's not even mention testing...
Many ex VB6ers* 
I'd propose you think about moving that logic in the second controller to a class library that both controllers would use to get the data they need, rather than have it inside a controller.
So I would end up with a hierarchy like so: apicontroller -&gt; classlibrary -&gt; repository -&gt; database effectively removing repository references from my controllers. Then all creation, updates and deletion of database entries happen through the class library?
Yep spot on. I have the same solution architecture. I've found the biggest advantage for me was keeping separation of concerns and reducing code duplication. For example, if you needed to access that logic from a console app, WPF project or an MVC controller there's no need to copy/paste code.
Thanks man, that's awesome! I've got some refactoring to do :-). Have a great day!
To piggyback on this, think of a controller just like you would a UI. You want it as thin as possible, and any business logic should be contained in a class library for that business logic. The only code that should be in the controller is code necessary for formatting your result object or formatting your parameters. Most of my controller methods are 2-3 lines max, calling down to a business method for the work.
You can easily do that with Octopus. Every time you push code, it is built and a release package is created. Octopus allows you to push to each env and it will apply your app settings and connection strings. This is where you feature toggle based upon environment. Unless you are sole dev on a project, deploying via the publish profiles should not be done.
What you're calling the "classlibrary" is commonly referred to as the model. I.e. the M from MVC.
It doesn't matter, as long as there is a separation. :) The Model is the "virtual model" of your application's non-technical logic (typically that of the real-life counterpart such as the business' logic), that's all.
Hmm, what can I use then to be able to learn game development without being "outdated" as such?
When I had a very similar problem, I didn't get too deep into customizing the Build Process (not the Template- custom Build Templates don't actually help you very much). It's a Windows Workflow XAML file that defines how to run a build. When I needed to generate a database change script based on code changes, I found a way to do it from the command line (Code Migrations can be managed from PowerShell), and then I added a step to the Build Process document to call the script. At the time, there weren't any useful primitives to do this directly anyway, so adding a script step was the easiest and best way to do it. I hate Windows Workflow, so I'd still suggest a script is the easiest way to do it (seriously, customizing Build Process documents is a chore, and there's no easy way to test it locally, they're basically impossible to debug, etc. etc. etc.).
I've looked and I've come up empty handed. We definitely came out ahead in the long wrong, the couple hundred spent on EasyQuery paid for itself with how quickly we implemented it vs time spent looking for and costuming another solution
That makes sense. What about DTOs? Should they be kept in the controller exclusively and the properties of these objects passed on to the business layer methods? Or should I pass a DTO straight from the controller to the business layer? How do you do it, if you don't mind me asking? :-)
Ah, thank you for the input. I had figured it was pretty hopeless, but thought I'd reach out just in case I had missed anything. I'll talk to the sponsor and see if they would be interested in adding EasyQuery to the budget. Hopefully they will, especially since the alternative is having to delay the delivery for as long as it takes to write a custom solution. Again, thanks for your help!
I like to see DTOs in a Model project (class library) or at least contained within the business logic's project. If you have to convert data passed into the controller into some other form, why not just have the consumer of that controller pass it to you in the correct form to begin with? If you need to perform a lookup to get additional data that the consumer doesn't have, just have the consumer pass in a key that can be used to search, and do the search in the business logic. 
It depends on your needs and requirements. Doing it from the CI server works if you've only got 1 or 2 machines to update. Octopus also doesn't work well if you have to install on client sites.
Take a look at bootstrap. http://getbootstrap.com/
Thank you. I'll go refactor this question to /r/learnjavascript. I'll leave the question on here in case others are tempted to ask the same thing. 
XNA is dead, but look into [Monogame](http://www.monogame.net/) - I have not got much experience with it myself, but it's an open source implementation of the XNA framework. It'll require some changes to your code, but not a huge amount and will be better supported than XNA, plus it's cross platform. Towerfall uses this and is a great game.
not really for every call, but you could potentially set the maximum number of worker processes on the app pool to some obscene number. That way each would get their own process more or less. I'd go back to the manager and ask for confirmation on this. This is highly unstandard and seems like he's asking to reinvent things that the IIS team would have implemented implicitly. Something has to have be missed in the communication...right?
He has no argument. He just wants to see processes.
Your manager is wrong. It is possible you could try to convince him otherwise, but he is an out-of-date fool. So, consider an alternative goal - how can you configure your application to give him what he wants, without compromising your architecture. That way if/when his poor choices cause problems, you'll be able to revert to a more sensible configuration. Also, typing out the below made me feel dirty, but I believe it will achieve what he wants to see (using IIS configuration alone). In IIS manager, go to the application pool that you're using to host your service, select it, and choose "advanced settings". Now we're going to change a few things: Set "Process Model\Maximum Worker processes" to a low number, maybe 10. With this insane configuration, this will be the maximum number of concurrently processing requests your server will handle. Do not set it too high, or IIS will eat all your RAM. Then set "Recycling\Request Limit" to 1. (I suppose you could try negotiating for a higher number here, but he seems dead-set on his ignorance). You've now achieved the poor outcome that your manager wants - each new request will create a worker process, and that process will recycle at the end of one request. You'll also find that the CPU usage is stupidly high for even a light workload, and the server won't scale at all. But now, when it all breaks under load, you can just drop those settings back to the (sane) defaults, and get on with your life. 
Is your service just sending mail? If so you should be using something like a message queue rather than a WCF service. 
Thanks! I will give that a try.
Actually, most of the services will be dealing with a database and won't be sending emails. I only needed to send emails as a "proof of concept". 
That is sort of what I did for the demo.
We are in the same boat. Couple of dozen clients running our legacy access application suite. Many of them have in house people that we have trained to write their own queries. We haven't found a good solution. One method we've done some work on is building SQL views that provide some of the basic analysis/flattening of the data and the pointing SQL reporting services Report Builder at it. It's not perfect, but it's a start.
Congrats on outgrowing your employer! Time to start looking for a better job, dude.
Haven't we all been there, though?
Great advice. Upvote!
Yes, *been*.....
This is a frequent problem: you were given a technical requirement when what you needed is a functional requirement, allowing you to choose the right tool for the job. It happens often when business types are being 'technical'. Don't allow it. You need to dig and get to the functional requirements that lead him to believe you need to spawn a process per request.
Good point. I have moved my DTOs into the business layer project. To me, it makes sense that they are located somewhere in between the points of access (controllers) and the domain models. I am not yet completely convinced that they belong in the models project, as they (in my project at least) serve the purpose of limiting access to certain properties in the models. That seems more like a business choice to me.
Yes, it could be written, without error, as initProc, but honestly, that's the least of the "WTF?" with this code. 
If you want to stick with C#, you're pretty much stuck with using [MonoGame](http://www.monogame.net/). You *can* go low level and roll your own engine/framework with [OpenTK](http://www.opentk.com/), [SFML](http://www.sfml-dev.org/download/sfml.net/) or [SharpDX](http://sharpdx.org/) but if you want to stay at around the "mid-level" that XNA offered you're stuck with MonoGame. The one big advantage is that if you're coming from XNA, you can usually just take over your XNA source one to one with only minor changes. If you won't mind going a level "higher" than MonoGame, you can give [Unity](http://unity3d.com/) a go. Keep in mind that that C# only plays more of a supportive role in Unity. You make your game in Unity, but you (can) write your code in C#. There's also [Wave Engine](http://waveengine.net) but I don't have any personal experience with it. It's been in my backlog of things I want to check out for a while but I never got around to it, so I can't say how it compares to XNA/MonoGame or Unity. If you're OK with leaving the C# premises, I'd recommend you have a look at [libGDX](http://libgdx.badlogicgames.com/) which is a really solid engine for creating cross-platform games in Java. What always was a bit of gripe for me with C# game development is that XNA and MonoGame require you to go through their content pipelines instead of using assets directly. I understand why it's necessary, but I just never really got behind it. Wave Engine seems to "suffer" from the same "problem" (all assets need to be compiled to wpk files before being loaded). It's why I eventually ended up with libGDX. 
Remember that it could always have been worse. 
It's written so that library user can swap out the TestOverlapProc delegate at runtime.
Assuming you are using EntityFramework, the entity framework profiler http://www.hibernatingrhinos.com/products/efprof gives you a list of the SQL created as well as the performance analysis of executing the code (ex: n+1 detection). I know its not a book or tutorial, but it is interactive and can help you tune your linq queries. 
Your manager is, probably, struck in Unix and has probably either heard of or used the fork system call. Tell him Windows does not support the fork system call, but do it softly so that it does not escalate into an ego battle. Add a few gratuitious statements about how unix/linux handles server processes much better than the crap called windows etc...and bang, he leaves you alone. NOTE: If he really insists on that out-moded model, you can always write a custom host for WCF, create a new process for each request, and allow it to crash the server spectacularly, and redirect all support calls to him.
[http://www.linqpad.net/](http://www.linqpad.net/) Linqpad will give you the resulting SQL query generated by your Linq query. It's a free tool, and $45 will give you Intellisense. Worth every penny, in my opinion. 
LINQ is designed to have any backing data structure, so it's difficult to tie it down to specifically T-SQL. I think they took quite a bit of inspiration from it but I don't think it was ever supposed to specifically be a counter part to T-SQL, MySQL, etc. I believe there are entity frame work providers for almost every database type out there. But the real reason they came up with LINQ is to handle collection manipulation, which can be anything from in memory, on hdd, in a database, etc.
Thanks for your input. Web.config looks ok. If a project builds without issues but throws errors during publishing, could that indicate the issue may be with the .NET settings? Since I'm having issues with the code that I restored from a backup as well (it was working at the time), perhaps I screwed up something with the machine.config file. Its just frustrating that I'm provided an error with a line number but it doesn't mention the name of the file with the issue. 
Its in debug mode. I essentially started a new ASP.net project and added some buttons and images. All settings are default with an exception of a database connection that was added. Below are the web.config contents: &lt;?xml version="1.0"?&gt; &lt;configuration&gt; &lt;configSections&gt; &lt;section name="entityFramework" type="System.Data.Entity.Internal.ConfigFile.EntityFrameworkSection, EntityFramework, Version=6.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089" requirePermission="false"/&gt; &lt;/configSections&gt; &lt;connectionStrings&gt; &lt;add name="DefaultConnection" connectionString="local\v11.0;Initial Catalog=aspnet-Cards-019ca1a0-8893-4632-97e2-ba400b84024c;AttachDbFilename=|DataDirectory|\aspnet-Cards-019ca1a0-8893-4632-97e2-ba400b84024c.mdf;Integrated Security=SSPI" providerName="System.Data.SqlClient"/&gt; &lt;add name="ConnectionString" connectionString="Data Source=TOWER1\SQLSERVER2014;Initial Catalog=Cards;Integrated Security=True;" providerName="System.Data.SqlClient"/&gt; &lt;/connectionStrings&gt; &lt;!-- For a description of web.config changes see http://go.microsoft.com/fwlink/?LinkId=235367. The following attributes can be set on the &lt;httpRuntime&gt; tag. &lt;system.Web&gt; &lt;httpRuntime targetFramework="4.5" /&gt; &lt;/system.Web&gt; --&gt; &lt;system.web&gt; &lt;authentication mode="None"/&gt; &lt;compilation debug="true" targetFramework="4.5"/&gt; &lt;httpRuntime/&gt; &lt;pages controlRenderingCompatibilityVersion="3.5" clientIDMode="AutoID"&gt; &lt;namespaces&gt; &lt;add namespace="System.Web.Optimization"/&gt; &lt;add namespace="Microsoft.AspNet.Identity"/&gt; &lt;/namespaces&gt; &lt;controls&gt; &lt;add assembly="Microsoft.AspNet.Web.Optimization.WebForms" namespace="Microsoft.AspNet.Web.Optimization.WebForms" tagPrefix="webopt"/&gt; &lt;/controls&gt; &lt;/pages&gt; &lt;membership&gt; &lt;providers&gt; &lt;!-- ASP.NET Membership is disabled in this template. Please visit the following link http://go.microsoft.com/fwlink/?LinkId=301889 to learn about the ASP.NET Membership support in this template --&gt; &lt;clear/&gt; &lt;/providers&gt; &lt;/membership&gt; &lt;profile&gt; &lt;providers&gt; &lt;!-- ASP.NET Membership Profile is disabled in this template. Please visit the following link http://go.microsoft.com/fwlink/?LinkId=301889 to learn about the ASP.NET Membership support in this template --&gt; &lt;clear/&gt; &lt;/providers&gt; &lt;/profile&gt; &lt;roleManager&gt; &lt;!-- ASP.NET Membership Role is disabled in this template. Please visit the following link http://go.microsoft.com/fwlink/?LinkId=301889 to learn about the ASP.NET Membership support in this template --&gt; &lt;providers&gt; &lt;clear/&gt; &lt;/providers&gt; &lt;/roleManager&gt; &lt;!-- If you are deploying to a cloud environment that has multiple web server instances, you should change session state mode from "InProc" to "Custom". In addition, change the connection string named "DefaultConnection" to connect to an instance of SQL Server (including SQL Azure and SQL Compact) instead of to SQL Server Express. --&gt; &lt;sessionState mode="InProc" customProvider="DefaultSessionProvider"&gt; &lt;providers&gt; &lt;add name="DefaultSessionProvider" type="System.Web.Providers.DefaultSessionStateProvider, System.Web.Providers, Version=2.0.0.0, Culture=neutral, PublicKeyToken=31bf3856ad364e35" connectionStringName="DefaultConnection"/&gt; &lt;/providers&gt; &lt;/sessionState&gt; &lt;/system.web&gt; &lt;system.webServer&gt; &lt;modules&gt; &lt;remove name="FormsAuthentication"/&gt; &lt;/modules&gt; &lt;/system.webServer&gt; &lt;runtime&gt; &lt;assemblyBinding xmlns="urn:schemas-microsoft-com:asm.v1"&gt; &lt;dependentAssembly&gt; &lt;assemblyIdentity name="Newtonsoft.Json" culture="neutral" publicKeyToken="30ad4fe6b2a6aeed"/&gt; &lt;bindingRedirect oldVersion="0.0.0.0-6.0.0.0" newVersion="6.0.0.0"/&gt; &lt;/dependentAssembly&gt; &lt;dependentAssembly&gt; &lt;assemblyIdentity name="WebGrease" culture="neutral" publicKeyToken="31bf3856ad364e35"/&gt; &lt;bindingRedirect oldVersion="0.0.0.0-1.5.2.14234" newVersion="1.5.2.14234"/&gt; &lt;/dependentAssembly&gt; &lt;dependentAssembly&gt; &lt;assemblyIdentity name="EntityFramework" publicKeyToken="b77a5c561934e089"/&gt; &lt;bindingRedirect oldVersion="0.0.0.0-6.0.0.0" newVersion="6.0.0.0"/&gt; &lt;/dependentAssembly&gt; &lt;/assemblyBinding&gt; &lt;/runtime&gt; &lt;entityFramework&gt; &lt;defaultConnectionFactory type="System.Data.Entity.Infrastructure.LocalDbConnectionFactory, EntityFramework"&gt; &lt;parameters&gt; &lt;parameter value="v11.0"/&gt; &lt;/parameters&gt; &lt;/defaultConnectionFactory&gt; &lt;providers&gt; &lt;provider invariantName="System.Data.SqlClient" type="System.Data.Entity.SqlServer.SqlProviderServices, EntityFramework.SqlServer"/&gt; &lt;/providers&gt; &lt;/entityFramework&gt; &lt;/configuration&gt;
Just tried that and still nothing. The project build successfully, so I think it must be something with IIS.
I am already incorporating css into my page. But I don't find the necessary info on aligning the items of a div-container/panel on a horizontal axis side by side. I tried horizontalalign, align-items, etc. etc. I skipped over something called flex-containers, what are those?
Do you have any config transforms? Maybe the issue is in one of them? 
You can even hook up to `Log` delegate, which will log all executed SQL. That way you can, for example, do: #if DEBUG dbContext.Database.Log += s =&gt; Debug.WriteLine(s); #endif to see generated SQL and parameters in Output window in VS when executing debug build - very handy to quickly assess whether generated query is acceptable.
&lt;div/&gt; is the standard block-level element in HTML. Block-level elements start on a new line and stretch as far left or right as they can, as opposed to inline elements which simply exist where placed and generally display the contents into the smallest space possible. CSS can order the browser to render and treat the block-level element as an inline element (with or without a height) by setting the object's *display* style. To force something to align to the left or right sides, CSS has *float* (which needs to be cleared after use). See [this StackOverflow answer](http://stackoverflow.com/a/14033814) for a good explanation of the CSS *display* style. See [this article from CSS-Tricks](https://css-tricks.com/all-about-floats/) for a good explanation of the CSS *float* style.
I found that [Npgsql](https://github.com/npgsql/npgsql) and [Dapper](https://github.com/StackExchange/dapper-dot-net) work very well together.
You could probably use [sqlite](https://sqlite.org/) and remove the dependency on a database. This is e.g. how firefox stores its information. I'm not sure if you'll get an ORM, but I'm not sure you'll need one either. Will your schema for a game be so complex it needs an ORM and complex business logic? For Postgres, Npgsql is the way to go. 
Business logic won't be complex, but I'm not keen on writing lots of SQL by hand. Looking for a more RAD tooling approach to database objects to streamline the development time. 
Are you certain you even *need* a relational database? Game databases like MMOs tend to be not very relational. Have you given serious consideration to a NoSQL option? 
Because Internet articles linger for so long. You will still find tons of OpenGL 1 and 2 tutorials as well. I think there is more misinformation available than information.
Ah, I see, thanks.
It was written because .Net 4 Enum HasFlag was so slow due to boxing and things. 
if a relational database is what you need, i.e. your data is relational as opposed to document-based or key-value pair based, then the next question is whether you need to read/write object graphs to/from the database, or if your read/writes are more row-oriented (as in basic CRUD). NHibernate and Entity Framework are the first thing people think of when considering a .NET ORM, but these can be real beasts, and if you don't need complicated read/write behavior, micro ORMs like dapper, massive, or petapoco.
Maybe give [FirebirdSQL](http://www.firebirdsql.org/) a go? * It has a decent .Net driver that supports Entity Framework and nHibernate. * It's lightweight enough to bundle in your game * If I'm correct, you can even run it in 'embedded' mode, so you don't have to install the DB engine to the machine, but it runs inside your application.
I use Postgre and NPoco every day. It's the best combination. No need to write sql but no need for complex orm. It has an iqueryable interface and is the fastest on the market. Also do you need help with your project. I'd love to help!!!
Dapper or protobuf-net
The Model definition spans across both Business/Logic classes and raw class objects. Basically everything that is not a Controller (router) or a View (presentation) is in the Model defintion. Of course, you can break these things down further in the Model, repositories, middleware etc. Although saying that Web API should only be Model and Controller.
RedGate may have a paid for plugin.
I have no sympathy for companies that are this irresponsible.
Any web application on any stack that is a decade old is screwed. Insofar as your ASP.NET 1.1 app goes upgrading to 2.0 was not horribly painful -- oftentimes just a recompile. You should have done that 5 years ago.
No, this ASP.NET 1.1 app was never upgraded to 2.0 by its original developer and it would be way too much work for me to do it. It uses 5 separate projects that compile into DLLs. Some of those DLLs handle the third party web service calls so they need to be recompiled. So its *Sorry, Out of Luck* for these e-commerce sites if I cannot cleanly recompile the DLL.
It's not about HasFlag, it's about trying to reinvent the type system inside of initProc. There's simply no reason to do *anything* in there. I don't have a .NET environment handy, but I'm pretty sure you can just use the bitwise and directly on enums without casting them to a different type.
Good. I hope this serves as a wake-up call for some of these companies that it's not ok to just keep running ancient code because "it works"
I know a guy that is still developing in Classic ASP. LOL!
Resharper gives you full intellisense in the XAML editor. If you're a student you can get it for free.
Actually, classic asp probably won't have problems like this being just a simple scripting language like php. Nothing to compile, no referenced dlls, etc. I love asp.net but I could foresee problems such as these when I first started programming in it years ago b/c it was too complex and required compiling which is just silly for web apps. I use asp.net daily at work but unlike an old classic asp site I cannot easily update any of the old 1.1 sites at all. 2.0+ are OK but I wouldn't be surprised if they just stopped working in the future for some reason such as this. I'm not worried about job security.
Yes, I still mostly use ASP.NET 2.0 because I got really good at it but I'm finally upgrading my skills now that Microsoft has made Visual Studio 2013 free for small businesses.
My company had to go out and contact all of the old (laid off) employees from 2 mergers ago to see if any of them had ever taken the source code home with them and kept it for our Legacy Classic ASP project, because things started breaking and we really needed the code, but in the confusion of all the merging we lost the servers it was developed on. Note: the original company never had source control either. That was a super amusing clusterfuck. Yeah, I'm sure all those old employees you fired after buying their company are really keen on helping you out...
Ok awesome thanks for the help!
Yes, dotPeek is quite useful to find any customizations that were added to the standard DLL. Usually this level of effort is going to cost too much for a business that has neglected to move to another e-commerce solution.
You misunderstand. You're using *web facing software* from a company that *no longer exists.* This means you have *no idea* what kind of security vulnerabilities exist in this software as nobody is bothering to even report them, let alone fix them. When the primary company was even thinking about folding you should have been talking about switching platforms. Now you should not even be considering staying on the same platform, especially trying to hack it to work for another couple of years.
There is a slight confusion here. Your Xbox profile I tied to a Microsoft account. Even though a userid is an email address, it does not mean it is the email. I can have more than one email associated with my account.
Well, "slight" is an understatement :) It looks like my main problem is associating the website's user account with an Xbox Live gamertag. I'm not sure how to do that and it's something I am going to have to research a lot. Any thoughts would be welcome!
Someone down voted you. This really the wrong subreddit for game dev. If he asked in r/gamedev they would not only question his use of a an orm even more. I question what kind of transactions he would perform. Short story, he will learn how game dev is very different from enterprise dev. Things like using more for loops instead of for each or how linq can really hurt you.
This is how you get a token to access the XBL information. You first go through the OAuth process with the live account, get the token, then use that token when making request to the Xbox API. 
I don't sell it. 
So, what's the line of code that you need to add/change to switch over to TLS?
Team Explorer, or whatever they're calling it these days (the TFS client part of Visual Studio) doesn't need projects to work with files under source control. You can just add them to TFS from the Team Explorer interface (instead of the Solution Explorer, which seems to be where you were looking). That said, you should probably use Database Projects to manage your SQL files. That can help you automate database portions of your build process. It's also worth noting that in TFS2013, when you create a Team Project, you can configure that Team Project to use Git as your source control method, which means you can just use a Git client to interact with TFS. &gt; I've read things all over stating that either the TFS system (which I think uses MSBuild) is either really easy or really dumb and some have said a 3rd party tool is preferred. Can anyone speak to that? These are two different things. There's MSBuild, which builds projects, and MSDeploy, which can be used to release projects. TFS makes MSBuild super easy out of the box, and it's worth using MSBuild to get your code compiled and dropped in a drop folder. MSDeploy isn't bad, but it can be cumbersome. Whether you use it or a third party tool really depends more on your Ops team and your deployment environment.
 ServicePointManager.SecurityProtocol = SecurityProtocolType.Tls 
That looks to me like something that you could drop in via global.asax (either create one if there isn't already and drop an extra assembly into the /bin folder; or do the same and extend the existing one if need be)... you could probably get around needing to recompile everything (though it's a bit of a hack, and tbh I agree with most of the comments about it being a bad idea to continue using random legacy pieces of software)
So um... what would you say ya... do there?
TFS is a turd all round. There are much better third party tools for a fraction the cost. The only reason it ever got any traction is by selling to clueless management, which sounds like what happened at your company.
You could make that $0 with a private bitbucket account.
No, probably not. It is possible somehow, but you may need a Xbox Developer Kit (for the API access).
Sweet. I just downloaded Resharper and it gives me 30 days trial. Thanks
I have never seen a decent microsoft SCM product yet, and I've been working with them since Source[un]Safe. Maybe I am jaded. Both github and bitbucket have issue tracking if you need an integrated solution. I would rather have best of breed solutions and make them talk because source control and issue tracking are a different issue. Project management is for idjits who need gnatt charts.
I'm shocked places like authorize waited this long to make the change.
&gt; I used TFS at my last company and it was fine. It sucked at merging sometimes, but that's not much of an issue if you're the only person contributing. Much better that Source Safe. It works fine in a limited scenario with a single developer and it's better than the most terrible SCM ever created. Not exactly a ringing endorsement.
&gt; There's nothing wrong technically with running old code with old frameworks It's old, unsupported code on old, unsupported frameworks. That opens up the business to all sorts of risks.
&gt; That was a super amusing clusterfuck. Yeah, I'm sure all those old employees you fired after buying their company are really keen on helping you out... Or admitting that they took code with them after they left the business. That sounds like a great way to get sued (AFTER the company gets the source from them, of course).
Will the unofficial XboxApi.com API work for you? I'm doing something similar and that's where I'm getting my data. It does not automatically link MSAs to Xbox live IDs though. You would have to bridge that in your code.
I think he does that because he wants to have explicit type handling - the Enum changing type based on how many flags it contains.
I made that exact change recently in less than 5min on a production server as a hotfix. 
My knowledge is somewhat limited (I'm not an EF expert) but based on the experience I have had with EF, I'd say no. Rather than pure ADO, I would create "model" classes that have the sproc parameters as properties, and a mapper that populates a SqlCommand parameter list with a class's property values. Take a look at Dapper or PetaPOCO for inspiration - the mapping portion is surprisingly straightforward.
Same here. Dapper for the win.
Dapper! Yup. Fricken awesome.
You can spawn up and destroy app domains, this is closest to what you want to achieve without the overkill of processes.
Wow, an overwhelming support for Dapper on this? I guess I have a new tech I should look into! I don't have any reason for it but hey... if it's this well known/supported I should at least read about it.
Make sense. I agree
Is this kind of like [automapper?](https://github.com/AutoMapper/AutoMapper) That is currently what I use
I'm going to throw my hat in here. We use Linq2SQL a lot at work. It works OK for stored procs, but gets funky with procs that make use of temp tables / table variables. Depending on your usage you can use linq2sql and map things with [LinqProjector](https://linqprojector.codeplex.com/).
&gt; Well, to start, a Windows Store app project comes loaded with Microsoft's default style dictionaries, which follow their guidelines for margins and sizes and whatnot. That is what I expected. Thanks for replying 😊 &gt; I don't personally subscribe to the belief that blindly following their guidelines is going to net you a beautiful end result. But it should give you a decent looking GUI. In my opinion, this is the case with my Desktop App. &gt; I can see that you have a lot of margins set in the markup for the desktop app, but no such attributes in the Windows Store version because it's all inherited from those styles. It's not a lot. Actually, there is only one margin of 8 pixels from the application window's inner borders and one margin of 8 pixels between the "console" window and the right panel. It just looks like a lot because I had to put them in a lot of Grids. The same applies to to the Windows App. In both cases, I use the default styles. &gt; Also I wouldn't mind seeing a screenshot comparison -- it's hard for me to visualize without actually creating the projects. There you go, I edited the first post. In my opinion, in the Windows App, the textboxes are huge in comparison to the labels. There is rarely any space between label and textbox, the button is smaller than the textbox, and the last textbox should stretch to the maximum height, as it does in the desktop app. Everything looks off! 😊 The beautiful thing in the desktop app is, that I can just drag and drop the controls and they look great. Just thinking about having to adjust dozens of details in the windows app makes me want to never start a windows app project again. 😴
&gt; Either way, if they won't even give you access to the dev database and schema, I'd run. Keeping people in the dark on how things work and hang together is how development goes wrong. &gt; We had a similar problem before where all our DBs had to be created through a special modelling tool, so I feel your pain. Luckily we made a case to senior members of why we need (not want) to switch to code first. Honestly, code first sucks IMO and you don't need it despite whatever short term issues you think it solves. The database should be designed with the purity of the domain in mind, not with the concerns of a single application. Most, heck maybe ALL, of the applications I've worked on that used databases were only one of the clients to that database. Generally speaking, multiple applications will use a given database, and they may not all even be on the same technology platform. Demanding a DBA cede control of DDL in order to allow for code first is generally not gonna fly on any but the most insulated projects. 
https://github.com/joewalnes/websocketd
I think its a "per project" case. Im not saying code first solves all problems, in fact I don't like some of the assumptions it makes when your doing a lot of linked lists. For the software I'm working on currently, our classes are created based around our domain, so the output we get from EF code first is pretty decent. I will note though, that our app doesn't *ever* share databases with another app due to the nature of the product so code first is perfect for us. I do get where your coming from though. (Edit: although I still personally think database first is a dodgy approach)
Comparing the performance I think I'm going to take a look at it, since I'm using a pairing of LINQ with Automapper. Dapper appears to do both.
Or sqlfu
Personally, for stored procedures I'd use [Insight.Database](https://github.com/jonwagner/Insight.Database), just because it's really easy to set up and pretty lightweight :)
I thought about that, but the rest of the implementation of SemaphoreSlim would be broken if that code ran when it didn't actually have the lock. 
Man, that's some weird looking code. 
I've been struggling with this recently too, the new Auth stuff is f-ing confusing. This is my login action (sorry I don't have a link to the original source): if (!Membership.ValidateUser(username, password)) return base.BadRequest(); var customIdentity = new CustomIdentity { Name = "Test", IsAuthenticated = true }; var identity = new ClaimsIdentity(customIdentity); var ticket = new AuthenticationTicket(identity, new AuthenticationProperties()); var currentUtc = new SystemClock().UtcNow; ticket.Properties.IssuedUtc = currentUtc; ticket.Properties.ExpiresUtc = currentUtc.Add(TimeSpan.FromMinutes(30)); return Ok(new UserInfo { Username = username, AccessToken = Startup.OAuthOptions.AccessTokenFormat.Protect(ticket), SalesRepId = 116 }); And in the WebApiConfig: config.SuppressDefaultHostAuthentication(); config.Filters.Add(new HostAuthenticationFilter(OAuthDefaults.AuthenticationType)); This is working for me, but if anyone can tell me if something is wrong with it I would appreciate it.
&gt; The database should be designed with the purity of the domain in mind, not with the concerns of a single application. Most, heck maybe ALL, of the applications I've worked on that used databases were only one of the clients to that database. This is a terrible idea, sharing databases between apps. It forces the complexity of every app into every other app. It's much simpler to have separate databases and an ESB or ETl process to shuffle data between them. &gt;Honestly, code first sucks IMO and you don't need it despite whatever short term issues you think it solves. Applications should be designed around the user first and foremost, not a pretty, 3rd normal form database structure.
&gt; That's where constraints should be. Database constraints simply aren't flexible enough. &gt; Please give examples. What's not flexible about foreign key constraints to guarantee data integrity? You can have optional or mandatory relationships, one to many, many to many, etc. Without them you can have a FooID in one table that does not exist in the Foo table. What's not flexible about check constraints where you can programmatically define rules for matching the constraint? Your statement without examples is unwarranted. &gt; &gt; I don't want to be duplicating tables just to satisfy foreign keys. This doesn't make sense. At best I grok your schema isn't very normalized. 
I don't think so. During the argument, he asked me to see how many instances of chrome.exe I have running. LOL!
No ThreadAbortException, but definitely a ThreadInteruptedException. By definition TIE fires *only* at a sleep, wait, or join. 
Microsoft Connect really
I am using MVC6 ASP.NET5. So I am kind of confused as to what you mean by WebApiConfig. 
Ignore that bit then :) In your Startup.cs you also need to use: app.UseOAuthBearerTokens(OAuthOptions); 
Wow, I think I'll give it a try in my next project. Thanks! 
Submit an Issue / Pull Request at https://github.com/dotnet/coreclr
This is not a performance bug, and in fact removing the if check would cause corrupted state under the right circumstances. The code is inside a finally block, which means it is running in a Constrained Execution Region. What this means is any exception not thrown by the code (for example a ThreadAbortException as mentioned in the code comment that you included) can not interrupt execution until after you leave the finally block. The if check protects against the situation where a thread is aborted while in ReliableEnter (which is called from inside Monitor.Enter) which could cause the internal (native clr) code to return without acquiring the lock (depending on timing). This lands you back in the SemaphoreSlim code on line 357 with lockTaken set to false. If you didn't have that check, you would incorrectly increment m_waitCount++ which then would mess up the count on the semaphore for the rest of the threads which are still running. The ThreadAbortException only gets thrown at line 361 as you except the finally block. Basically the key thing you've missed is that in case to where an exception can propagate out of Monitor.Enter, it doesn't necessarily stop subsequent code from executing until you exit the finally block. In which case lockTaken can be false. 
Isn't there some IL code mod to do this? Why does it require a recompile? Did you try out [reflexil.net](http://reflexil.net/)?
Acquiring a lock in a finally block for one.
That doesn't make it any less weird.
Myeah.. but this path is when we obtain the lock which, while pretty fast for unheld locks, is still much much slower than a single check. 
What? The *purpose* of bool.Parse is to parse a string into a bool. The documentation says what is recognized; 0 and 1 aren't. 
Typically just use the project name.
My concern though is namespace collisions - aren't namespaces supposed to be unique? (or at least have an infinitesimal chance of another namespace having the same name?)
No, that's rarely an issue. Even if namespaces do happen to collide, you can alias your way out of it in C#.
Ah, that eases my concern a bit, thanks!
I wouldn't make the attempt, this requires a deep understanding of the runtime and resulting machine code.
Your lack of understanding doesn't make the code weird, though.
&gt; It forces the complexity of every app into every other app. Actually, if you model the data appropriately, it does no such thing. &gt; It's much simpler to have separate databases and an ESB or ETl process to shuffle data between them. I know this is the current trend, but it's really wasteful to have to copy and then store the same data multiple times across systems. Not only that, but that data gets out of sync between the various systems. Yes, it can be necessary, but it's not a hard and fast rule that it should always be done. It should only be done when it's really needed; not by default. &gt; Applications should be designed around the user first and foremost, not a pretty, 3rd normal form database structure. That actually has nothing to do with anything I said and implies that you think that an application should be designed around the database, which I'll disagree in all but the most isolated cases. That's poor separation of concerns between layers and your business layer of APIs should protect your user interface layer from those concerns by exposing a reusable API design that will stand up over time regardless of what changes occur behind in the various database(s) and / or other services it may need to address. In some ways I think we're talking about two different schools of thought. You seem to be implying that every application must be an island (that's where the separation of concerns occurs) and can only work in a larger environment by messaging between the various systems. I'm implying that every application is a limited exposure of the enterprise resource layers where the layers take care of the separation of concerns. I'm sure they both have their place, but it should be noted that code first is really only appropriate for the former.
I rather stick to AutoMapper than uglyfying my code with GetFromDBAttributes.
I prefer value injector myself. AutMapper requires a ton of tweaks to get it injected correctly and their *maps* can be horrendous for deep objects that don't map 1 to 1. In fact... I prefer to map my own items over both techs because the compiler will tell me if a name changed where as if you rely on automapper or value injector you won't find out until runtime... unless you setup a unit test to validate every field which can be just as painful as writing the mapping manually in which case... what did it save you really?
Actually, you are misunderstanding a few things. The finally block is always treated as a CER, in that it won't interrupt a finally block with an out of band exception such as a ThreadAbortException (with some caveats which I will get to). It will defer throwing these exceptions until after the finally block. There are some conditions though (these are the caveats) which simply prevent being able to defer throwing the exception and carrying on executing. One example is if you don't have enough memory to make a required allocation, you can't just continue as if the allocation was successful. The PrepareConstrainedRegions call ensures that this guarantee can be be met by either limiting what you are allowed to do or taking advanced steps to detect the error condition before you start executing the code inside the CER. For example, it traverses the entire call graph for the code in the constrained region and makes sure that everything has been jitted or is ngen'd code. The reason for doing this is that jitting code can require memory allocation. If it can't allocate memory needed to generate the machine code into, the IL for a method can't be compiled to native and the method can't be executed. This causes an OutOfMemoryException to be thrown. In order to guarantee that an OOM exception isn't thrown inside a finally block one of the things that PrepareConstrainedRegions does is make sure all necessary code has been jitted up front. If it's unable to do this, the applicable exception is thrown before the CER begins execution. Without the call to PrepareConstrainedRegions, it's a best effort attempt to avoid throwing these exceptions inside the finally block. The interesting thing is that the code inside the method Monitor.Enter is not inside a finally block so is not considered to be inside a CER. The code looks like this: 58 public static void Enter(Object obj, ref bool lockTaken) 59 { 60 if (lockTaken) 61 ThrowLockTakenException(); 62 63 ReliableEnter(obj, ref lockTaken); 64 Contract.Assert(lockTaken); 65 } So what would be the behavior if the thread was aborted when line 60 was about to or had just finished running? There's no finally block in the current stack frame so the CLR is free to throw the abort execution or the current method. So the stack unwinds one level and the CLR finds itself inside of a finally block which means it needs to continue execution and only continue propagating the exception after the finally block has completed. At this point it hits the if block in the SemaphoreSlim.Wait method and lockTaken is false. If this guard wasn't there, then the thread could potentially increment the m_waitCount value without having actually acquired the lock and you corrupt state of the semaphore for other threads.
As a guy who once tried to create his own ORM, I don't want to sound negative, so I'll start with a compliment. Great job creating software that solves your problem. You probably learned a thing or two along the way about how object relational mappers work. That learning is valuable and will help you in the future. From a practical standpoint, where do you go from here? Are you going to add Linq support, prefetching, object tracking, fluent mappings, code generation, query caching, db2, oracle, postgresql, sqllite, mysql etc? With ORMs the slope is slippery. There are full blown, production tested frameworks that do all the heavy lifting and are free to use. The learning curve may be steep, but once you get rolling you will be more productive than ever. Take a look at EntityFramework, NHibernate and Dapper. Spend some time doing a simple query in each and build on that experience. Keep writing software and experimenting, its the most fun part of the craft.
Yeah.. Fugly name there.. Thks! I am wondering tho, do you know if Automapper saves the mapping of the class or does it calculates the mapping on each map? (most probably saves the mapping.. Cause if you are mapping 10k records..)
How could a third-party lib that uses System as a root namespace provide anything useful? I'd figure they were too stupid to provide an add function.
While this is true, you would still want to get all the DB logic out of the controllers and into some repositories. 
The reboot addresses the symptoms. It does not address the problem.
I'm a (mostly) self taught guy as well, and luckily I work in a shop where that isn't an issue. I have had multiple times where one of the CS degree guys will be doing something, I would provide an opinion, and they realize that what I suggested would actually be better. Don't let him walk on you because you are new or self taught. Acknowledge when he actually does know more than you, but stand your ground when you know you are right. If need be, talk to your manager about what is happening (unless he is your manager). And if he refuses to change, maybe look into a different place to work? You don't deserve to be treated as a second class programmer because you didn't do things the 'traditional' route. 
I use Npgsql with EF6, database first, on Windows and under Mono on Linux. Took a little prodding to get setup the first time, but other than that been smooth sailing. There is a Npgsql and Npgsql for Entity Framework 6 and above NuGet packages that make life pretty easy.
Is that what determines whether something is weird or not, whether I've personally done it before?
Duhh. *weird* * 1. different from the ordinary in a way that causes curiosity or suspicion * 4. noticeably different from what is generally found or experienced 
Honestly I just bought a nice looking template off wrapbootstrap (I think that's the name) and used that to build a nice looking portfolio back when MVC 4 came out. Just slowly build it out and incorporate an admin section and such. Bootstrap and MVC play very well together. Nowadays it's all about that MVC 5... which freaking rocks.
Are you looking for a general ASP .NET MVC tutorial or are you looking for a step-by-step guide on how to create a portfolio site?
Stay tuned!
a step-by-step for creating a portfolio site using asp.net
Is there any 'todo-mvc' style example for Akka.NET. I am trying to grokk the idea for a daily use.
Really nice! I saw some updates come through. One thing I noticed was one of my got canceled because a page I wanted to monitor didn't update in 7? or 8? days. Is it really that short of a period? The website (FBI BIO SPECS) rarely gets updated but I would have liked to have a notification when it does.
it's de-activated because that page failed to download due to their SSL certificate being invalid. it'll only deactivate once downloading a page fails for 7 days straight. failing to trigger an update for a whole year will also de-activate and send you a warning email. i will look in to a way to disable ssl certificate checking as soon as i get a chance. will post back here when sorted. thanks for letting me know :-)
Fork/pull-request it yo! I jest.
The first thing I'd recommend reading is Head First Design Patterns. It uses Java, but the lessons themselves are language-agnostic (though focused on OOP) and fairly important.
I can't watch this at the moment. But the latest version of ASP.NET is dropping support for WebForms. And VB.NET.
I don't think that's true. Where/when did you hear that?
http://stephenwalther.com/archive/2015/02/24/top-10-changes-in-asp-net-5-and-mvc-6 No more webforms and no more vb.net in asp.net. Apparently only 2 people in the whole world are building MVC apps in VB.NET. Whilst it's not my preferred language I must own up to being one of those 2.....
True, you can still recompile existing Webforms apps to take advantage of new language/framework features but you're locked out of any ASP.NET vNext specific innovations.
The main thing to grok when thinking about vNext is that it's based around the new core runtime. There is no more GAC. Every vNext thing you reference will be in your bin folder like a nuget package. You can still use .Net Framework stuff including WebForms, but it is not where new development is happening. 
Thank GOD. Fuck the GAC, my more experienced coworkers say it has a purpose but as far as I can tell its main purpose is to fucking ruin my day.
ASP.NET MVC with Entity Framework is the easiest to get started with. Follow the tutorials on the ASP.net website to get started. After you get the basics down, you can start exploring other ORM's if you don't find yourself a fan of Entity Framework.
I thought they're releasing a new version of vb.net. They're just getting rid of webforms.
That article days that webforms will be in Asp.net 4.6, but *not* 5.
You are confusing ASP.NET 5 with WebForms 4.6 and .NET 4.6.
Watched a bit but disagree. Webforms' weakness is not the page life cycle. The problem is its attempt to create a stateful paradigm when the web itself is not stateful.
They just released info on it. Like yesterday. It was on /r/programming. I can't look it up right now
The problem is perhaps that we're trying to create applications for the web, when the web itself was created just to host hypertext documents?
I got it to work by using the jquery.easing.min.js
&gt;Also, Rails and Laravel have pretty reasonable templating Laravel templating is called 'Blade' as it's heavily inspired by the templating in .NET MVC - 'Razor' (which itself is heavily inspired by templating systems that have come before it). The MS sponsored ORM is Entity Framework. It does a lot, sometimes people think it does too much. I don't mind it. Obviously one of the bigger changes is going to a statically/strongly typed language. Plenty of things to get started with from here: http://www.asp.net/mvc 
Try Pluralsight, great stuff for quick exposure, and they have some selection of higher level stuff. But in general it should get you on a good starting track with most parts of .NET
In addition to these, I also recommend [Adaptive Code via C#](http://www.amazon.com/Adaptive-Code-via-principles-Developer/dp/0735683204).
Just add your account to the git URL: https://tinkermake@github.com/user/repo.git
It was a good idea 15 years ago when we were experiencing "DLL Hell". It solved one problem but made another, sadly. But you can trust me on this... it was worse before we had GAC.
Am I correct in my understanding that we now have new tools to help avoid DLL Hell (package managers) and the GAC is outdated? I just can't stand scenarios where a windows update causes breaking changes, etc. I love explicitness in that versioning.
Windows credential manager. Same place it keeps outlook passwords. You go in there and change it.
Microsoft has stated they will have a wrapper class for VB that will encapsulate webforms for ASP.Net 5
This is not true. http://www.asp.net/vnext/overview/aspnet-vnext/aspnet-5-overview#webforms
A lot of this is wrong or misinformed. I'll just briefly state with certainty that web forms applications can most certainly non-html results. Also if you design your web forms applications with he MVP pattern they are every bit as testable (I'd argue more testable) as MVC apps. MVC has its advantages and WebForms has its drawbacks but this list doesn't accurately describe the difference. 
Web Forms and MVC are not the only two options. Personally I hated Web Forms from the start and refused to use them. ViewState alone made me shudder, and the event model - trying to make the Web behave like VB6 - just screamed "wrong" to me. Then there were those fugly IDs of course. But all the other wonderful things about .NET are still there without using Web Forms - separation of code and HTML, compiled libraries, web components and so on. The power and modularity is awesome. You can still use all that goodness but write web apps the traditional way - no ViewState or event model or MVC needed. It's all still just requests in and responses out, same as always. MVC is a brilliant paradigm for teams and testability, but like Web Forms, it's a choice not a necessity. Right tools for the right job and all that.
&gt; the web itself was created just to host hypertext documents If that were true, we would not have search engines, and you'd still be trying to find all those hypertext documents by typing in URLs from the latest What's On the Web magazine from the newsagent. The very existence of querystrings and forms in the HTTP spec. implies processing submitted variables on a web server, looking up values in some kind of database and returning conditional HTML to the browser. That's what every web application does, ever since back in the CGI days.
Laravel's ORM story is much nicer than ASP.NET. EF, the standard ORM that comes with .NET, is an abomination. 
I get to maintain an MVC app written in VB.Net. I've gotten to the point I'm trying to abstract everything out into C# helper projects (Since there is too much BL in the controllers right now anyway.)
I don't entirely buy into this dude's remark that in web forms case there's a "complicated" page life cycle before the button's method is executed. If anything, in the MVC case the URL request is routed through tons of layers just as well before it ends up in the action method. I'm not an MVC expert, but I figure it does some kind of conversion and validation of the request parameters just as well. Technically it's likely to be just as simple or complicated (your point of view) than web forms.
I've used [this article](http://www.philliphaydon.com/2013/06/setting-up-mono-on-nginx/) with success on a Raspberry Pi. You can skip the Nginx steps if you want (which is just a reverse proxy to protect the asp.net server) and focus on `fastcgi-mono-server4`part. If you want more than aspx pages, you could continue on to NancyFX tutorial and use Nancy or sub in your own preferred framework. If you want to be *really* future facing, use [kestrel on ASP.Net 5](http://pkula.blogspot.com/2015/01/production-ready-aspnet-5-mvc-vnext-on.html)
yes that is supposed to be the correct behavior. it's only supposed to notify if the watched element is different since the last notification. could u give me the id of the monitor that's got the issue and i'll look in to it. id is the 2nd part of the url: http://changemon.com/ID/xxxxxxxxxxxxxxxxxxxxxx thanks!
17 I think it sent me about 10 notifications or so throughout an 8 hour period.
[I've bookmarked this article](http://blog.markrendle.net/fun-with-asp-net-5-and-docker/) but I have not used it to set up yet. It could be of help to you.
Stick with Windows Phone development and get really good at it. Web development is a post apocalyptic nuclear wasteland.
&gt; ASPNET5 is easy to run on Linux. Only for development and testing purpose. Kestrel does not even support SSL or multi binding.
Who aim to use nginx? And how?
Do you have a source for that? I only read that Kestrel _might_ be optimized for production some time.
Jeffery Richter*
And it rightfully shouldn't, that doesn't really belong embedded into your application server. Go throw up a proper reverse proxy to handle SSL termination or any additional features you need, nginx or lighttpd are good choices for this.
Not all old frameworks are unsupported, and not all old frameworks are closed source.
Octopus Deploy is ditching RavenDB, and going back to SQL server. He raises some valid concerns about how RavenDB handles indexes and unbounded result sets. The issue is that the developers kept forgetting the limitations of raven, resulting in production issues later. http://octopusdeploy.com/blog/3.0-switching-to-sql 
I agree, but you still need server side data to come from somewhere, typically an mvc framework. 
 began this approach. Currently, I believe that nginx is set up properly for localhost, but when I run fastcgi, I get a NullReferencEexception at System.Web.Util.HttpEncoder.GetCustomEncoderFromConfig() Not sure why this is happening, but it definitely seems to remind me of the issues I always run into with Mono... Pardon my incredibly vague question, but is this probably due to the fact that I am targeting .NET framework 4.5? [This makes me think so.](http://www.mono-project.com/docs/about-mono/compatibility/) However, if I try to target .NET 4.0 in my VS Project, I go through DLL hell and think that it isn't even possible... Edit: Fixed the hyperlink
I don't believe that I'll need SSL for my website. I plan on running a simple site and don't have any need for private data transmission. Realistically, I would probably buy another machine to run a Windows ASP.NET server if I ever needed SSL. I'm just struggling jumping through the hoops of getting mono to run my very simple website now...
Shared/static methods mean you can never override, never use DI/IoC, never inherit... You aren't using DbConnection, DbCommand, DbDataParameter, DbDataAdapter, etc. .NET Core doesn't include DataSet, DataTable. Your code shouldn't rely on that. Just use Dapper. Find it on Github.
I shudder every time I see Visual Basic. Rolling your own DAL, just use Dapper or EF (depending on your needs).
[Here's](http://coderscoffeehouse.com/roll-your-own-data-access-layer/) my effort FWIW :-)
You do realize that Azure is just a Windows service and sooner or later the bits trickle out of the cloud and into product? Be it through baseline windows or in extension products like system center service manager. The cloud strategy isn't Azure. It's Windows which is slowly catching up to the azure release cycle.
Why would they call me? I do not think it has anything to do with my computer. I think it either the bug with .net framework or the windows.
Thank you I will try looking through that.
Thank you very much this might be exactly what I was looking for!
Aren't those concearns that go for document DB's in general? I'm genuinely interested to know what the Azure Document DB does better than Raven and Mongo.
&gt; That's no excuse. If static methods are bad, then Dapper is bad for using them. This has static methods on a high level interface, dapper is lower level, as you said. With dapper your likely going to wrap the data access in something else anyway to create the connection etc.
&gt; Dapper is missing a lot of features than one may need such as integrated caching and centralized logging. Or add them with dapper, just because it doesn't do everything doesn't mean you should reinvent the things it does do.
I've used RavenDb (up to version 1.0) and Elastic Search (up until know) extensively. Here's the problem with these storage system. Versioning is pain. In SQL Server, you can rename your database fields and you get to keep your data. There is no easy way to do it in document database. In ElasticSearch, you cannot update your mapping. You can only add fields but not modify. You have to drop your mapping if you want to rename or do other trickery. So now, if I need a Document DB, I never use them as my primary storage. I store the data in DB and produce a view for the NoSQL storage for further reading, etc. 
&gt; Web development is a post apocalyptic nuclear wasteland. ???
Set singleBranchExpandLevel to 0, maybe? http://help.infragistics.com/Help/Doc/ASPNET/2012.1/CLR4.0/html/WebDataTree~Infragistics.Web.UI.WebDataTree~singleBranchExpandLevel.html
Well, it looks like it is set to -1 now. I assume that means either all or none. Try changing it to 0, or 1, or whatever, see what happens when you set different values. 
Changing values of the value does not appear to change anything. im wondering if there is a way to see exactly what this drop down is using to create this tree
That's pretty much how I'm using ElasticSearch so far. Admittedly, my experience is very limited, but usually text data is stored either in SQL Server or flat files and then fed to ElasticSearch for further indexing. In the end, it's either SQL Server of file system that serves as a 'core' data source.
Bummer. Before you bother digging any further, are you sure that what you want to do is possible? Have you seen it being used as you'd like, on some other page? It is (probably) being created by the Infragistics package, probably in a Javascript library that is part of your project. The pages that use this control should likely have one or more &lt;script&gt; tags that includes some Infragistics javascript file, like "infragistics.js" or "infragistics.web.js"; one of those files is what is building the control. I'm basing that on what I saw in your code dumps. It is possible that I am misreading it and it is being done server-side by Infragistics .NET code. Is there a publicly accessible page somewhere that uses that control and that you'd be comfortable sharing the address of? A test system perhaps, or a demo page?
Try using Request.QueryString["parameter"]
 var value = this.Request.QueryString["parameter"];
you can use cookies if it's non-critical stuff
You can use w/e type you like and long as the compiler is happy about it and during run-time nothing breaks. :)
muchas gracias
There are whole bunch of different technologies available for that. QueryString parameters, Cookies, Session ,Cache, Application State are among them. Refer to https://msdn.microsoft.com/en-us/library/z1hkazw7(v=vs.140).aspx as good starting point to make a decision on what to use.
&gt; ElasticSearch unfortunately has a terrible Query API. They gotta do better than the JSON query interface. There are also no good stand alone query tools to get your data. I'm not sure. For generic queries I agree, it seems to be a bit too much, but when you compare full text search capabilities then SQL Server queries and the whole setup is, arguably, even more noisy
I posted it in three different places: https://connect.microsoft.com/VisualStudio/feedback/details/1172473/emf-image-generated-on-windows-8-1-looks-wrong-on-windows-7 http://answers.microsoft.com/en-us/windows/forum/windows8_1-hardware/emf-image-generated-on-windows-81-looks-wrong-on/da8901a0-5467-4c85-af96-2763db63b6c4?tm=1425571249333 http://stackoverflow.com/questions/28947836/different-metafile-rendering-on-win8-1-and-win7 
Not a great article. It implies you can't use VS for ASP.NET 5 or for hosting it on Linux.
this is just asking to get sued... you need to make sure this is opt in and make sure you put it in your privacy policy and your application is adhering to do not track requests. that being said you could hook into the browser location services(which requires user confirmation) and log it that way as far as writing to the iis logs that would a lot more difficult but i think Common.Logging has some sort of support for this but i am not 100% sure on that ... if not you could use a separate log file for this.. TBH IIS Logging is kinda clunky any more, Logging in most of the applications i work on use Common.Logging or a similar logging library or write the information to a database depending on the data being logged ( this is assuming are trying to track from a web UI and not through a web api or rest service) 
 nice.came in original box, brand new, and very comfortable. sneaker doesn't look like an imitation. and that is something that you need to be aware of now a days. I think it was worthy to buy it in such a reahoneyable price. Fits good and runs excellent! i really like, good quality. Worth the money.you can try. http://freejumpnike.de.vc/ 
The problem is the WebBrowser component is using the thread UI. When you deploy in your local machine the web page you are logged as a user and have an interactive session. But when you deploy to Azure there is no interactive session to rely on. It's no a good practice to use UI objects on the server side.
Do you need .Net experts who can work remotely?
Ah! That explains it. It sounds like you're right, and certainly I hesitated to use a UI object on the server side, but couldn't come up with a better solution. Under those circumstances, would you be able to recommend a better solution for me instead of using the WebBrowser control to get the post-ajax source code of a URL?
First time I've ever seen spam on reddit.
You might be right! I don't know how to do that. Would you mind pointing me in the right direction? I'm trying to get the page at: http://worknplay.co.kr/korea-jobs/?page=2 You can see that there's a section called "Line Jobs" that has a table with a job listing. That table is loaded dynamically. It seems to be a very complicated Ajax call. Do you know of a way that I could simplify all this?
I think you might be able to do it with a project template in visual studio. Like when you create a new mvc project except you'd choose your own custom project template. Since the other template come with code files I don't see why your custom template couldn't. I've never actually done it myself though.
Yes this, a lot of developers end up creating a project containing generic often used snippets of code that gets used in most projects they create. You can either just add the project or you can compile it and reference the DLL.
Open up google chrome. Press F12 to get the developer console. Go to the network section. Load your url and wait for the ajax to be triggered. Sort the list by Type and look for things that stand out (in this case `text/xml`). You'll see the URL you want is http://worknplay.co.kr/process/jobs_process.php?_=1426081038639&amp;xMode=select&amp;xPage=2&amp;xCate=&amp;xType=&amp;xCode1=&amp;xCode2=&amp;xCode3=&amp;xKeyword= That gives you some XML that you should be able to parse as well as some easily changeable parameters. You'll have to figure out what they all mean though (the `_` is probably a random number generated by jquery ensuring the response isn't cached by the browser).
Create nuget packages for your commonly used code, libraries, and resources. Setup a local feed hosting the packages on your machine, and away you go. 
This, that way you can avoid referencing the project directly, use different versions if needed, upgrade, etc. with no hassle.
If you look at the schema and are using websecurity in MVC, when you created a user you got a profile table with a row linking back to the user. I'd create either a link table that takes in a user(or profile) and a note ID or simply extend your note model to include a userId or profileId field, then when returning your notes from the controller, do a linq query to say "notes.where(n=&gt;n.profileId==i) where "i" is the current user profile (or user) Id you get from doing something like: websecurity.getuserid Sorry my example isn't brilliant, I'm mobile. Summary: extend your new model. Not the account model for this scenario
Is the web application an MVC or web forms based?
read up on how to correctly do NuGet package restore https://docs.nuget.org/consume/package-restore You should change a setting in Visual Studio so the package restore will happen automatically For CI/command line builds, you now need to run: nuget.exe restore yourSolution.sln (before calling msbuild on your solution) The only things you should need checked in is repository.config (for your solution) and packages.config (for each project) You can download nuget.exe from http://nuget.org/nuget.exe Download page is also here: http://docs.nuget.org/consume/installing-nuget
You can ignore specific files or folders from TFS/git/etc. Just because something was auto-added to TFS and your project, doesn't mean you have to leave it like that. Put it on an exclude list before you commit. Not sure how exactly you do that with TFS but with git you add a pattern in .gitignore. Some other comment talk about "Enabling Nuget restore". Don't do that. It should *just work* with both VS and TFS these days. The "enable Nuget restore" stuff is legacy and not recommended any more. In my experience, Nuget kind of sucks for client libraries. Better go with Bower from the start. 
No, local machine w. local IIS
You can access the Response.Cookies collection. What I did in MVC 4 was after a successful authentication, I encrypted our custom data and added it to the Response.Cookies collection. Response is a property of the controller class. // Serialize, Encrypt, and convert to a string userData.Value = Convert.ToBase64String(MachineKey.Protect(ByteStringConverter.GetBytes(JsonConvert.SerializeObject(cookieData)), "UserDataCookie")); Response.Cookies.Add(userData); Then in the Global.ascx I pulled the user data cookie in the Application_AuthenticateRequest event.
Either create a different site for testing on your local machine or build a real test server. Either way your build process should be able to quickly deploy to test.
Content files will *not* restore on package restore, they must be committed to source control. Anything that is explicitly added to the solution (including most javascript/css packages) will *require* you to add those files to source control. There is an open enhancement request with NuGet to add the ability to restore some content items on nuget package restore, but that is not the current method of functionality. It is an unfortunate limitation.
on the solution level, you need a `.nuget` folder with `nuget.config` inside telling VS not to store the packages into source control. you get this by right clicking the solution and enabling package management on the solution. it does add a copy of nuget.exe and some build targets that will only ever get in your way. as /u/fjanktomen says, this is not ideal for most builds. what you want to do to fix it, though is just delete the nuget.exe and nuget.targets file, then edit the project file to remove the two lines referencing nuget.targets. or just take the nuget config from a throwaway solution and don't worry about project files. either way, once you do this once, you can just copy the nuget config and folder around to hide packages from TFS in other solutions. edit: and for the love of all that is holy, fix the `allowedVersions` tag in your packages file to lock down every line to the current version only. when you're ready to test a new version, remove the old one entirely and readd. if it works, lock it down again. this keeps you from having to mess with project files not matching if an update rolls in between source and build servers.
Katana is a project and an implementation of a web server. Sounds like you're looking for SignalR. 
Yep. My team has been converting things to NuGet packages for internal development lately and this one one of our gotchas. Had to do a little clever finagling to work around it.
What will your client app look like? WIll it be the website or a desktop app or ssh or telnet or etc...
So far I'm thinking it'll be a single page web app in the browser. Big text area, some frames for extended data display. Since webclients are more ubiquitous than telnet clients these days, I'm probably going to use my own message format instead of raw telnet, hence the websockets. That will allow me to enhance the protocol for some new modern features.
Do you have any data or process outside of sql (like sending mail)? If no then sql transactions are just fine. If yes then you might need distributed transactions (which I believe WCF transactions use) or some other way to add some resilience. Instructor sounds like an idiot though.
So SQLTransaction does something interesting when a distributed transaction is "detected." It will, by default, auto enlist in that transaction. If you have multiple services that need to all complete or all fail, even if it is just a set of sql changes, it is probably a good idea to run the transaction at the WCF level. However, if you just have one service doing the SQL work for the given "transaction" (operation) the SQLTransaction will be sufficient. https://msdn.microsoft.com/en-us/library/aa720033%28v=vs.71%29.aspx Did Joval Lowy teach the course? He often makes mental leaps that leave people confused, assuming everyone is on the same wave length he is.
Well #1, SqlTransaction most definitely works. Now for some scenarios it won't scope properly, but there are many more gotchas to using the DTC that can cause runtime issues without proper planning.
It's the encryption of the cookie data that I'm having trouble with...
Could it be that return true makes it always valid?
Take a look at the articles below: http://www.itorian.com/2013/07/custom-data-annotations-or-custom.html http://www.dotnetcurry.com/showarticle.aspx?ID=776 It looks like you need extra stuff to get your validation working on the client side: GetClientValidationRules()
I'm not completely sure what you mean with *completely replaces the DAL.* Dapper usually would be part of your DAL yes. Dapper is a (micro)-ORM, so Dapper would completely replace Entity Framework or Nhibernate or something like that... You can still build your own repositories on top of Dapper, which would also be part of your DAL, I assume 
Dapper would be used within your DAL. It's a library, it does not replace any layer.
You use "navigator.geolocation.getCurrentPosition" in javascript, and have it postback to your server with the coordinates in the Query string. This will log to the IIS logs, and you can later extract it. Obviously this will require the user to "OK" location use. They'll get the "SoAndSo.com wants to use your location, Agree?" prompt. 
You'd have to run two different AppPools, then, with two sites. You could simply change the bindings to ensure external requests to to one, and local to the other. When a breakpoint is hit, all threads for the process are suspended, and there's no way around that.
They aren't checkboxes in this instance, it's just a list of services. So like you can pick a server from the list (i.e. Major Interface Server for ABC) and it would populate the list of services with all the services that require a restart to fix an issue. So they wouldn't get to handpick which service to restart, it's all of them. I'm wondering if the best bet would be to make them checkboxes but the users couldn't modify them and then when they click the button to cycle, it goes to the first one, cycles it, then updates the checkbox which would force the autopostback. That might not be a bad idea.
Right right. I think your method is probably the best way to go. I will give a few things a shot and let you know how it works out.
Also, [queuebackgroundworkitem] (http://blogs.msdn.com/b/webdev/archive/2014/06/04/queuebackgroundworkitem-to-reliably-schedule-and-run-long-background-process-in-asp-net.aspx) may be a good way to go. I know WMI can be all kinds of flaky. Not to mention, if the machine is down, and you need to wait for a timeout, or a name resolution fails or any number of things that can take multiple seconds to resolve... you are going to want to make sure that code is wrapped up ideally in it's own little worker thread. Otherwise you could stall the page and and get some pretty annoying ASPNET errors. 
FYI, this is the old MSBuild-Integrated Package Restore, prior to NuGet 2.7 the NuGet team suggests using the Automatic Package Restore and Command-Line Package Restore instead https://docs.nuget.org/consume/package-restore
Is there any better way to retrieve html source of page without using webclient/HTTPrequest? For now im retrieving it from httpcontext after onexecutingresult render the page. 
Could you edit your sample code and highlight the problem and solution? If somebody has the same problem they don't have to look as hard to find it :-)
I've been trying to get SignalR to work for the past few hours even with the most basic of tutorials and I'm just hitting a brick wall. I might go with /u/ExcuseMyTriceratops option and just continuously poll the services every few seconds as I'll know what services need to be checked and can update until all services return the desired state of running.
[Here](http://stackoverflow.com/questions/29008431/asp-net-mvc4-bootstrap-modal-validation) is the link to the same question on stackoverflow
I attended the Architect Master class taught by Lowy, and he did cover wcf transactions, which can be applied to just about any operation. 
They inherit from WebPart. Maybe that's the problem? public partial class Main : WebPart
I'll get a fuller code sample... But its breakin BootStrap Tab Pane navigation as the JavaScript isn't anticipating the extra divs
Rather than `controlCollection` being a server rendered div, try with an `asp:Panel` - see if the child controls behave in the same way?
Exactly. Now that I have my sort of solution in place I need to figure out how to get my two functions to call one after another. Like, I call the first one to stop all services and then in the middle of stopping them, the next one kicks off and tries to start them. I quickly put both functions together in one bastardized function: function cycleServices() { var id = ServicesListBox.GetValue(); for (var i = 0; i &lt; ServicesCycleListBox.GetItemCount() ; i++) { $.ajax({ url: "/ServiceDeskPortal/ServicesUtility/StopService/?id=" + id + "&amp;servicename=" + ServicesCycleListBox.GetItem(i).text }).done(function (msg) { ServicesLog.SetText(ServicesLog.GetText() + msg + '\r\n'); }) } for (var i = 0; i &lt; ServicesCycleListBox.GetItemCount() ; i++) { $.ajax({ url: "/ServiceDeskPortal/ServicesUtility/StartService/?id=" + id + "&amp;servicename=" + ServicesCycleListBox.GetItem(i).text }).done(function (msg) { ServicesLog.SetText(ServicesLog.GetText() + msg + '\r\n'); }) } } So what's happening is that the second ajax call is kicking off before the first oen finishes even though it's in a for loop. Any thoughts on what I should do? I was starting to read about jquery .wait but it's late in my day and my mind couldn't wrap around it.
Are any of the new features a way to compile .less files that doesn't involve spending hours on each project setting up all kinds of libraries and configurations? Or am I the only one that's having that problem?
You can either use an extension for this (like web essentials) or for asp.net 5 advised you can use the grunt task runner. All straight forward.
Web Essentials doesn't do it any more, specifically because you can use grunt in 2015 (I use it in 2013). Honestly, I'm not an idiot! I spent a couple of hours searching for a guide online to setting up and using grunt, and I ended up more confused than before I started. I don't understand why it has to be more difficult to do a task that was pretty much automatic in the past. 
I prefer gulp over grunt. Easier to set up once you understood the concept, and faster. It needed to change, because before the IDE was doing the build. That's bad. The IDE should just assist you in development, but it should not be responsible for building your sources.
Odd, I'm now getting this markup: &lt;div id="ctl00_SPWebPartManager1_g_0d4b9573_8118_4104_be98_54927b4ded23_ctl00_mainControlCollection"&gt; &lt;div id="ctl00_SPWebPartManager1_g_0d4b9573_8118_4104_be98_54927b4ded23_ctl00_ctl00_controlCollection"&gt;Foo!Bar!&lt;/div&gt; &lt;/div&gt; So that's an ASCX with two literals added in codebehind. That ASCX is dynamically loaded and added inside another ASCX. And that second ASCX is dynamically loaded with a WebPart.
Thank fuck for CKSDev. &lt;div id="ctl00_SPWebPartManager1_g_0d4b9573_8118_4104_be98_54927b4ded23_ctl00_mainControlCollection"&gt; &lt;div id="ctl00_SPWebPartManager1_g_0d4b9573_8118_4104_be98_54927b4ded23_ctl00_ctl00_controlCollection"&gt;Foo!Bar!I've had wine. Yep.&lt;/div&gt; &lt;/div&gt; The div: ` &lt;div runat="server" id="controlCollection"&gt;I've had wine. Yep.&lt;/div&gt;` Foo and Bar are first because I tried with AddAt() like you did.
Exactly - ajax calls are going to be async action. What I'd look at is to run the first call that updates your UI. So now you've called an API that says "Bad news, Service1 is down" and in the success part of the API call you update the element on the screen by ID. Independently, create a jQuery function that is run off the event for the onChange of that element (you can do a wildcard for ID's named like _WatchThisElement or whatever). When that Element changes, the event kicks off a seperate ajax call that runs to restart that service - and on success of that call, make that element green or something to show you that it restarted or red if the restart call came back negative.
Curious how some of these new features (particularly this whole lightbulb icon concept) are going to interoperate with Resharper...
Side note: The lightbulb icon concept isn't new, VB has had it for ages. They just finally got around to adding it to C#. (And making it extensible at the same time. Anyone can write their own refactoring rules using Roslyn.) 
I get what you're saying but I think I didn't explain my goal properly. I have to take care of a few things in the house but I'll come back a little later and be more clear. 
Thank you very much for your comment! If this is not a bug then it sure is a breaking change. In the situation of highly precise graphics this issue means that images produced on win 8 machine cannot be used on win 7 because user would never know if the value is 110 or 11. That said I have tried to give it an extra spacing and you are correct that fixes it, however the spacing is not consistent and seems to be dependent on the number of ones in the string. So the solution of checking font and OS every time I draw or measure the string does not seem to be too appealing.
Renaming variables safely, refactoring methods etc etc Whatever LINQ AND LAMBDAS IN THE IMMEDIATE WINDOW FUCK YES
Azure is windows and system center mate... there is nothing overtly special about it. It hits a faster release cadence but generally speaking the services trickle down into product over time. Expect these two product tracks to continue converging. https://technet.microsoft.com/en-us/library/dn296435.aspx
I retrieve HTML page and I convert it into JSON, would like to return as JSON response.
I will try it out, I don't think it will work, because after OnResultExecuted, the code doesn't go back to Controller, I can pass the object but the code in controller doesn't execute
Okie. Good luck.
Visual Assist X has had a number of these features for years too. It was hands down a necessary plugin for the old visual studios (vc6, 2003) but it seems that each new Vistula studio version brings in a few more visual assist x features. Still a great plugin though. 
I use the less bundler library that's on Nuget (can't remember the exact name and I'm on mobile). It takes maybe 5 minutes to get up and running after you have done it once or twice. That being said I'm looking forward to gulp in ASP.NET 5.
Hmmm. Might have to try CodeRush out. 
Easiest way to get the data from Umbraco is through their content api. I'm pretty sure you can find some existing code to it and then just tweak the data map.
Never heard of episerver before. The website made me laugh, no prices and a load of gobbledygook about how they can't give a price until they know how many servers you have. Any time I see a site like that I expect a massive price tag. Do they have an import tool? Most do. You just create a data map to realign fields.
Finally. Took them long enough.
Check out WinLESS if you haven't already done so.
It needed the Rosslyn compiler. Lambdas get turned into regular methods that capture whatever variables they use as parameters. Without a compiler available at run time, you can't evaluate a lambda.
I will check it out. Thank you!
Thank You! I'm working for a government customer that is providing the devices. All users have already signed the "consent to monitoring" forms upon working for this agency. 
I'm just surprised it wasn't here sooner. With the popularity of linq I constantly find myself cursing at the immediate code window!
I don't believe that PerfView bit. No way does that foreach loop take 4 seconds unless there is an intentional Thread.Sleep in that constructor or property getters/setters.
When you update NuGet packages, then.. well, you're updating the assemblies added by those NuGet packages. They can introduce new bugs and incompatibilities and thus breaking your project.
Ok so what my ultimate goal here is say that my services listbox has A, B, C as items. When I click the "cycle" button, I'm going to call my javascript function and need it to cycle in order like this: * stop A * stop B * stop C * start A * start B * start C Currently it seems there's an overlap. Look at this screencap from the log [here](http://i.imgur.com/yrzVAOV.png). You'll see that while there are a bunch of "STOPPED" lines you'll see 3 "RUNNING" ones and then another "STOPPED". I essentially want to block the start loop (my second for in my code above) from executing until the first loop finishes.
+1 Not the only one that cares.
I got that, I'm suggesting you don't use onresultexecuted and do your own ActionResult implementation instead. Then your action (not the filter) will call your post-processing thingy and return that. You are still wrapping that processing into a reusable element.
&gt; For the most part the irritations are minor and easy to fix until you get on a larger team. In a large team there should be a few person who are responsible for referenced NuGet packages.
I said you were correct and now you betray me!
Good luck!
Yes but you still don't want people running around fixing little things over and over (there are much better uses of RelEng/DevOps time). It is much better to just remove the offending script and publish your own package to a nuget system you control.
I was hoping for more than MS documentation.. Can you explain unmanaged vs managed code?
You're asking a question equivalent to "how do cars keep from crashing?" Well... There are a number of mechanisms that all work together that are relevant. If you want a simple rule, you don't need to dispose anything to keep from using memory, as .Net will clean that all up for you. Learn the basics of garbage collection. Otherwise, you'll have to be more specific.
True, but in a large team, how often do you update nuget (or other libraries) packages? I've never been part of any team, so I don't know; but I can't imagine it being very much from what I've heard around reddit and from friends because it seems a lot of teams are slow to adopt changes (which is both good and bad).
[Yep.](http://lmgtfy.com/?q=managed+code+vs.+unmanaged+code)
So, you made borscht. That's not the sort of thing you have in small batches, so you made a LOT of borscht. Every pot and pan in your house is full of the stuff. After a bowl or two, you decide: "Wow, that was good, but now I don't want any more borscht." Unfortunately, garbage day was today, so it's a week away. You now have a choice: you can either hold onto this, or you can find some way to dispose of it. Since you don't want to eat borscht for the next week, since you need those pots and pans, and since that borscht is going to smell like death warmed over with cabbage and vinegar by the end of the week, you really want it out of your house. So you dispose of it (probably under that annoying neighbor's front porch. They'll spend months suffering before they realize what's wrong. It's the perfect crime!) That's the difference between just letting the garbage collector worry about things and versus disposing of things yourself. The garbage collector's next visit could be a long way off, so it's nice if you make sure that things that take up a lot of room are chucked away before they get there.
Managed code's memory is managed by the CLI. Unmanaged code's memory is dynamically allocated and needs to be deallocated manually.
I think I'm understanding a bit more. Can you tell me if these assumptions are correct ? * You generate a model in your controller * you render that model as HTML * you send the HTML to the client browser * the user performs some action * the data for that action is sent to the server as a Json POST * the controller reads the Json data and serializes it to a model * the model is processed by the controller.
There's no explicit resource deallocation in C#. If you have some object wrapping some resource where it is critical to impose a definite lifetime on that object/resource, you use dispose. While it's often used in the context of memory consumption, it has nothing to do with memory consumption, and only to do with imposing a definite lifetime on some resource. Sometimes, simply setting the object reference to null isn't good enough, because you don't know the next time when the GC will run. For instance, lets say I have a Socket class. Having it implement IDiposable means that I have a surefire way to make sure I never leave it open or allocated any longer than I have to. Even better, static analyzers can look at what IDisposables I'm using in my code and warn me if I forget to dispose them. Neat, huh? Sure, there's nothing stopping us from just having a `Close()` method, or `Completed()` method, or `Release()` method on everything, but now we don't have a unified pattern, the static analyzer's job is harder, and I can't do things like ... keep a queue of IDisposable's that I invoke on another thread. The definite-lifetime pattern, in any incarnation, is a very common pattern. Giving it a semantic name ala IDisposable makes it easier to universally integrate it into code.
I agree that it's annoying, but don't think that it's a bug. To me it sounds like you made an assumption that doesn't seem to be the case (that a typeface name will always refer to the exact same font and that it will have consistent glyph widths and character spacing). There are a bunch of cases where I think this might not be the case - '1's on Arial on windows 7 vs 8 is one of them. If a different typeface is substituted it's going to be a different width (ie if Arial isn't available for whatever reason). Cleartype could have an effect (grid fitting is probably the reason that it displays differently). There's some discussison of some of the limitations of gdi and the issues that you could be running into at: http://support.microsoft.com/en-gb/kb/307208
There's a bunch of ways to to do this: but the fundamental issue is that you need a way to verify that all servers are done stopping before kicking off the start functionality. $('[id$="divServerStatus"]').each(function () { var serverInfo = $(this).attr("serverInfo"); ... check the status }); You can store the information in many different ways, arrays, lists, whatever - personally I like my UI to store/display the statuses so that the end user is able to watch all the servers flip from green to red and back to green or some such fanciness. You can kick off the 2nd loop that starts each item in the listbox once all the servers in the list box have an attribute like "currentStatus" set to "stopped".
What you are doing is composition, not inheritance. Container Control: &lt;UserControl.Template&gt; &lt;ControlTemplate TargetType="ctl:MyWin"&gt; &lt;Grid Margin="10" Background="Red"&gt; &lt;Grid.RowDefinitions&gt; &lt;RowDefinition Height="Auto"/&gt; &lt;RowDefinition/&gt; &lt;/Grid.RowDefinitions&gt; &lt;Button HorizontalAlignment="Right" &gt;[X]&lt;/Button&gt; &lt;ContentPresenter Grid.Row="1" /&gt; &lt;/Grid&gt; &lt;/ControlTemplate&gt; &lt;/UserControl.Template&gt; Form 1: &lt;Grid&gt; &lt;ctl:MyWin&gt; &lt;Label&gt;Hello&lt;/Label&gt; &lt;/ctl:MyWin&gt; &lt;/Grid&gt; Form 2: &lt;ctl:MyWin&gt; &lt;ctl:Form1&gt; &lt;/ctl:Form1&gt; &lt;/ctl:MyWin&gt; Refer the following for more info - http://www.ikriv.com/dev/wpf/displayingcontent/index.html ContentControl vs ContentPresenter - http://stackoverflow.com/a/1288353
OK so I did figure it out and while it might not be the most efficient solution it works perfectly... var listindex = 0; function stopService(startalso) { var id = ServicesListBox.GetValue(); if (listindex &lt;= ServicesCycleListBox.GetItemCount() - 1) { var xhr = new XMLHttpRequest(); var servicename = ServicesCycleListBox.GetItem(listindex).text; UpdateLog(servicename + " - Stopping Service"); xhr.open("GET", "/ServiceDeskPortal/ServicesUtility/StopService/?id=" + id + "&amp;servicename=" + servicename, true); xhr.onreadystatechange = function () { if (xhr.readyState == 4) { UpdateLog(xhr.responseText); listindex++; stopService(startalso); } } xhr.send(); } else { listindex = 0; if (startalso == 1) { startService(); } } } So this nice iterative function works well and will stop all the services in the order they exist in the listbox along with starting them up in the same order (calling the startService() function which is the same thing except for calling another webservice to start instead of stop services). 
It really depends on the company, the stage of a project and how many projects are running. Not all groups work in a single solution nor do all groups have consistent 3rd party API use (some groups are more progressive than others). Finally you can never really tell what someone may do on their own machine during development or debugging to get the job done so it is best to assume that any given package that has distribution across the group should be available and unobtrusive at all times. The last thing you want to do is have people wait for you because "oops hold on, just need to clean up this script thing".
Nice work, glad you got it figured out!
This. IDisposable is a generic interface that indicates something needs to be disposed when you're done with it, some syntactical sugar (using), and that is all. It doesn't have any special significance in terms of garbage collection etc other than that it is a reliable, predictable, and consistent way to clean up, and the C# finalizer / GC is not.
Grrrr lol
The last sentence here is key. A lot of developers think .net just cleans up everything auto-magically but that is not the case. It's best to be diligent and follow this advice.
Can you link to a source for "refuses to clean object if its to large" I hadn't heard of this and I am now curious! 
AFAIK only the "top level" package's scripts are executed (though I'm not 100% certain) so you could create an empty package with just a dependency on the package you want? Saves having to repackage.
There's a chapter in [CLR via C#](http://www.amazon.com/dp/0735667454) that covers it.
Yeah, Sharepoint sucks.
&gt; if you new an object within a method that objects scope is from the first bracket of the method until the last bracket of the method. To be pedantic, the object itself doesn't have a scope. It's just a bunch of memory on the heap. The scope of the *reference* to the object is between the innermost enclosing braces in which the reference was declared (not just the opening and closing braces of a method; many other syntactic constructs define blocks with their own scope). The object can outlive the scope in which it was constructed if another reference ends up pointing to it.
Whenever I render the current page I visit, I want to retrieve the html source, because global action filter able to know which action you're visiting.. Retrieve the source and return it as JSON response from server. Sorry if its not clear. Im sleepy and tired 😫 
I want to point out that the using statement is not a requirement and also cannot be used if the disposable object is returned from the function.
Any class with unmanaged resources needs a finalizer as well, which will clean them up. Disposable is more for *precise* deallocation.
Of it's Managed C++ that is true because allocations go on the managed heap.
Phonegap, no, just no.
Sounds like either, you have them in the wrong directory, normally with hosting you get something like public_html or www then your sites content goes in there. Oorr Are you sure you picked Windows Hosting from HostGator, if you just got "hosting" that normally means Linux and asp.net isn't supported or recognized. 
That's certainly untrue. But they are handled differently, as pointed earlier. Large objects (objects &gt; 85k bytes) get their own section on the heap ("Large object heap"). The reason of this is because the GC typically compacts the heap where normal objects live (Small objects heap) after it reclaims all the unused memory. Trying to do that with very large chunks of memory can lead to performance issues. In .NET 4.5.1 you can set a flag so that the LOH gets compacted after the next full collection (the behaviour will revert to default afterwards though). 
What happens after that month and say you don't pay? Does your Xamarin install delete itself or anything stupid like that? Can you for example pay for one month, not use it and not pay the next month, but then pay for it and start using it again the month after that?
I dont really know how this works on PC, but my iOS subscription expired after a month - without me knowing. I could still code, build and all that stuff on mac - but I realized it wasnt subbed when I could not update Xamarin. This could be an exception, though. So check it out before you go for an option like that. 
I have no experience with it myself. I just see it mentioned in almost any thread about Xamarin. 
My first guess was going to be he was validating client-side which skipped his check.
You are going to need to give more details here. 
Go through this tutorial...Depending on your familiarity with Azure you may be able to just skip directly to step 9. Good luck! edit...I forgot the link...[here!](http://azure.microsoft.com/en-us/documentation/articles/sql-database-get-started/) 
I setup a database in Azure. I ran a .sql script on it in VS and it got the tables I wanted. Not I want to create an MVC Application that can insert and query the database. How do I do see and access those tables in the MVC application? Thank you stranger.
Thanks!
You could put unmanaged clean up code in the finalizer, but then you'd be waiting for the garbage collector. Thus, my post.
Of course it's safe - well, as "safe" as a CTP can be, anyway. A long time ago, I started building an app with the beta of .NET 2... long story short, it was a great learning experience, and upgrading to the RTM was even a breeze back then. I'd say MS knows how to not break too many things between CTP and RTM - it's close enough.
Thanks a lot, no solution yet.
Also, only manage nuget packages from the solution menu, not the project one. Otherwise you can end up with all sorts of weird compatibility issues.
If it's just for a learning experience for yourself, sure, go ahead. But for production code? Hell **no**! A **lot** is still changing. The latest version of ASP.NET 5 (there is no asp.net 6) is incompatible with the latest preview of Visual Studio 2015. This happened a lot. If you want to deal with ASP.NET 5, be prepared for a lot of headache, barely no documentation and breaking changes.
In my experience, MVC 6 works great and is fairly stable. The problems you encounter will be more related to the VS environment and integration between everything. For example, I still haven't been able to get unit tests working reliably inside VS. There's also very little documentation so when you need to do anything beyond the basics you'll spend a lot of time looking through the source code and pulling your hair. I have been trying to develop a hobby project on Aspnet5 since the first CTP. Basically, I download them, do a File-&gt;New project and give it a weekend to see if I can get anywhere. And unfortunately, in my opinion, it's still not an environment where you can be productive. Still though, give it a try if you haven't. One thing I'm sure of - Aspnet5 is going to be an amazing step forward for .NET development.
You could, but ... no. Just no. Almost nobody uses those in .NET.
Why? That's the whole point of a controller.. 
Now, do I Protect the raw cookie data (ie the values I'm storing) or the cookie itself? Also, how do I read it out again once its encrypted?
I've been doing this for a university project, even running the webapi I created on Linux. You should be fine. Happy coding!
How big is your team? How many teams work on the project? Tests and documentation, done right, are both great things to have, but if you have a three person team, and you are the only team on the project, they will be of less benefit than they would be for a larger team, or for a project with more teams. What are your other pain points?
If refactoring is hard, tests can help. Test writing projects can be great tools for training up new team members too. Someone else mentioned build automation. The two go together like peanut butter and chocolate. They'll both make refactoring easier. You have a propper test/dev environment, yes?
So you are looking at the HTML result of a request, and using that to generate Json? Is there no other way you can generate the Json without seeing the HTML?
I'm not sure if it's entirely what you're looking for but Scott Hanselman has a side project that does speech recognition through Siri to word etc http://myechoapp.com
Aurix now acquired by avaya does simple phonetic matching, ie it matches based on the phonetic alphabet of a language. They do support a wide array of languages but I don't remember whether Swedish was on the list.
Improve on the problems that you run into. About the only issue that I've seen across multiple projects is not having CI and not having the product buildable/deployable in a single click (or deployable as easily as possible). Every project is different, so what works for you is going to be different for what works for me. The trick is to figure out where you fuck things up, and put things in place to prevent those problems from happening in the future. The flipside of this is not to spend time doing things that people tell you to do that add no practical value (eg if your code is 100% unchanging, writing tests is a waste of time until you want to do risky refactoring).
depends on what you mean by a proper test/dev environment. we use vs2013 and have a build process that we can integrate unit tests into it. I feel like investing in unit testing have circular dependency, it will protect me from mistakes in re-factoring but will also require me to do some re-factoring to make my static code testable
FWIW, I think the latest VS 2015 works fine with ASP.NET 4.5. Even Resharper (v9) is behaving well in that environment. It's just ASP.NET 5 that I've had problems with.
I find that adding unit tests to really old code can be a nightmare and produce very little usefulness. Honestly I think the thing that made developers happy was to isolate a particularly unforgiving module and allowing for that module to be re factored. Allowing for re-factoring and controlling the re-factoring will keep developers happy by showing them progress in the application &amp; it will add up to more reliable code. Hopefully the re-refactor will include some DI so unit testing becomes viable. Another technique I've used to improve quality and Developer turnover is not forcing them to rely on old spaghetti legacy code. I've had a team transition away from the old stuff into a nice neat new unit testable business layer. The one problem I ran into here is that the diverging code trees lead to old features relying on old code and no one ever having time + cycles to re-point it at the new code.. so when bugs pop up its in legacy or new and sometimes they have to be fixed twice. I wish I had watched the development a little closer because I would have enforced the concept that if you re-write the new code into the new layer you MUST remove it from the old layer. *Live n Learn*
That's not how the MVC framework works. There are no circles in the pipeline. Requests come in and end at the controller action. Responses are processed from the controller action and end at the ActionResult. When you say you want to parse the HTML and have it processed in an action filter, it is at the end of the pipeline and the HTML has already left the server and can't be captured in the way you want. You either return Json or HTML, but not both and there is no processing after one ActionResult has been set. Here is some information on the MVC pipeline http://www.dotnet-tricks.com/Tutorial/mvc/LYHK270114-Detailed-ASP.NET-MVC-Pipeline.html
Look into PetaPoco.
So you want to convert something like: &lt;html&gt; &lt;head&gt; &lt;title&gt;This is my title&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p&gt; This is my body &lt;/p&gt; &lt;/body&gt; &lt;/html&gt; to { html: { head: { title: "This is my title" } body: { p: "This is my body" } } } What do you mean by check out the response of youtube? Are you finding out if a youtube video is available, has been played, etc? Edit: are you sure you're not having something like returning a partial view? It processes the controller, renders the view and then returns the HTML that was generated without the headers, layout pages, etc.
Write integration tests rather than unit tests, only unit test new or re factored code.
I'm in the opposite position, at my work the team leaders have no clue about good practices and our manager thinks Singletons are good because "you can access them from anywhere". The managers are just happy to climb the corporate ladder and don't have a clue about modern software development. They only care about result... not about the quality of the code base, technical debt or maintainability. Or keeping developers happy... The present managers are the biggest contributors to the code base we have, and they think their code is great. They did it, so it must be good... I know I'm about to get shit for low productivity, because I can't work on those terms, I'm gonna try and go to the new department manager (who thankfully has a background in improving development processes and I think the old department manager was replaced because we needed that competence) and see what we can do about the situation...
Thanks for posting quality info!
What version of Linux? Sounds really weird that you have a distro that doesn't handle ntfs.
Debian. It's not so much that it can't handle ntfs, it's that the server housing the nfs share isn't integrated with Active Directory, so it has no knowledge of any Windows accounts and can't delegate ownership to them.
I would pick this as an answer if this is stackoverflow. thanks a lot. 
What do you use for deployment automation?
IME in this same situation, these 3 items in that order were extremely successful.
Thanks, But I was looking more for a SaaS. not a stand alone software
Thanks for the reply, I saw that blog post. Its not what I was looking for.
Jira, daily standup and talking to each other.
Waterfall is the process by which a product/module is decided then researched, requirements written and architecture fully documented prior to a developer writing a single line of code. The 'concept' goes down stream with each party completing their entire stack of work before it moves to the next party. Agile, loosely defined, Is all parties working on their respective piece (documentation, requirements, coding.. ect) together. Every day making small course corrections until the final module is ready. What you are describing is not either of these processes. You are describing what I call the development pipeline. Iterations like yours can be used within either methodology. I just wanted to help clear that up.
I haven't used TFS that much for issue tracking, but it's used elsewhere in my company, and it seems terribly clunky compared to some other solutions for bug tracking - VS integration or no VS integration. I don't have any experience with Jira, but I can easily imagine it being easier to use.
Everyone here is right about waterfall. I mistakenly left out some important details. Our sprints are 6-8 weeks long. Yes, that is not a mistake. In between sprints we have 2 week sprint gaps where the next sprint's requirements are carefully planned and laid out. This particular part is what struck me as waterfall masquerading as agile.
Oh wow, yes that is a very peculiar implementation of Agile. Usually sprints are 2 weeks but I can honestly see extending sprints to 6-8 weeks myself. I suppose a common theme of Agile is a demo-able product at the end of each sprint. This taken to the extreme can lead to long sprints. However, I find that approach to be very waterfall. It sounds like the process is not malleable. The company is supposed to be able to switch directions at any point without having such a large course correction.
We have our daily stand up via a conference call with the entire team. Historically our stand ups were these long drawn out affairs that everyone hated. I think we have degenerated too far in the other direction (?), in which now they are these super quick status updates and stand ups last less than 10 minutes now (which I actually kind of like since we are across 3 timezones and everyone can get back to their day)
Do you mind if I ask which TFS Template you guys use? We are on the scrum template and the workflow leaves a lot to be desired.
All relatively TFS core stack * Default ASP.Net Web App packaging (no WebDeploy Publish Profiles) * Web.config Transforms (SlowCheetah for App.configs) * [NuGetter](http://nugetter.codeplex.com/) for common library publication * [TFS Versioning](https://tfsversioning.codeplex.com/) for assembly versioning * Some custom Workflow activities for things like build promotion, specific project output pathing, stand alone config xforms * light .bat scripting for mapping drives across AD domains. Not as 1337 as PowerShell, but I like my C# and .bat files, and the admins don't like to open the remoting ports for PS. 
Mine is exactly the same, nearly verbatim, except for the hardening sprint which I actually like. We generally have a hard time bringing generally low priority bugs into a sprint.
You're my f-ing hero.
Thank you, kindly!
Scrum, and it does. I really wish they would let me customize it. When I was a lead at a small shop I customized the shit out of it and the project ran like a god damn champ!
Hardening sprints and good and bad. Sometimes there's nothing to do so all the deva complain. But I am a big self starter so I take that time to tighten my implementation fix low bugs no one notices or just to learn new architecture and patterns.
Um, wow. That's just insane.
This thread has been linked to from another place on reddit. - [/r/csharp] [Creating a Custom ETW EventSource for Debugging High-Performance Code in C# (x-post from /r/dotnet)](http://np.reddit.com/r/csharp/comments/2zdn11/creating_a_custom_etw_eventsource_for_debugging/) [](#footer)*^If ^you ^follow ^any ^of ^the ^above ^links, ^respect ^the ^rules ^of ^reddit ^and ^don't ^vote. ^\([Info](/r/TotesMessenger/wiki/) ^/ ^[Contact](/message/compose/?to=\/r\/TotesMessenger))* [](#bot)
&gt; No wonder C++ is impossible without a static analyzer, bjarne stroustrup is a madman or an idiot. At one point in my life, I naively declared that C++ was the best language ever invented. A short time later, Scott Meyers came out with his "Effective C++" book, and my eyes were opened to how many holes there are in the language. I kept using it for a number of years after that, but then "More Effective C++" came out and that sealed the deal. When C# came out I never looked back. It's kind of ironic that the books designed to make me a better C++ programmer did such a good job of informing me of the pitfalls of the language that I ultimately decided I wanted nothing more to do with the language. Am I a wuss? Or am I just pragmatic? The huge backlash against C++ I'm seeing recently makes me think I made the right choice.
This is incredibly idiotic, especially when members are layed out in memory in order of declaration as well. It basically tells you to go sod off if you are trying to pack memory when you have members that may depend on each other....
There's even more implications of ordering than that, one of them being exception safety. E.g. if one of the constructors throws during init, then you have to worry about stack unwinding of your constructor plus other fields you did or didn't initialize. Sounds easy until you have dependent fields. 
It doesn't stand up to the expectations of many more modern language users. The idea that order matters in a class between class level members is one example of an expectation not shared with C#, Java, Python, ... There are others, for example, C# inherited the C++ polymorphism concepts of virtual and nonvirtual functions. When defining class inheritance there are 4 options with respect to handling function/method overloads: 1. final, not replaceable 2. final, replaceable 3. virtual 4. abstract Just like C++, C# doesn't provide any mechanism to do #1 (without making the class sealed). 
Thanks! I've been pleasantly surprised by the feedback I've gotten over this post. 4 months ago, I was feeling a bit overwhelmed and questioned if I was going to be able to do the job or not but after posts like yours, I'm feeling much more confident!
I would create web services for the Android app to connect to within the MVC app. Don't let the Android app connect directly to your database. What would happen if the app landed in the wrong hands or someone captured the wireless packets that contained the connection string? Then I would create two separate user accounts on the SQL database. One for the services and one for the MVC app, granting the proper privileges to both accounts. This would require separate connection string with the different user logins.
I shared your post with the class as confirmation that we are heading in the right direction. :-) Nice going :-)
Sorry, I thought you meant you were connecting your android app (an actual android app) directly to your database. Does the mobile services need write permissions? Is there any authentication going on with the android app and the mobile services?
It is an actual android app, however I think it uses Mobile Services as a medium to interact with the database. Everything goes through the Mobile Service. Users of the android app must register with an email at the moment but I'm planning external (Google or Twitter) to be options also. 
Yes, they will be creating or deleting bookings, but only by selecting options, not by entering their own data.
So mobile service user should have delete, insert, update and select rights to the bookings table. They should also have select rights to any other informational tables needed for the app. Then, the MVC app user would have permissions for the rest of the app. Which should be controlled thru MVC authentication. Make sense?
I am looking forward to the stream dying and buffering constantly on my crappy office internet connection for the next 2 days.
They usually record them and then make them available for future viewing. Here are videos from 2014: http://channel9.msdn.com/Events/dotnetConf/2014 Here are videos from 2013: https://www.youtube.com/playlist?list=PL5i79H1f8hbezk9uLlorTmI7TypY56WF0
I'm looking forward to the stream dying and constant buffering when they use the same streaming infrastructure they used for the last Windows 10 event.
what edition of TFS did you use? things have changed a fair bit in 2013.
Is that declared and not defined?... wow. I understand it if the attributes are defined and declared in the same statement...
&gt; Got management to buy R# licenses for us all (again, a godsend) Err... what's R# and why was it useful? Surprisingly, nothing comes up in a cursory Google search.
It might be better to show us what you tried and we can help you fix it. I remember doing this a few years ago and there were a ton of resources out there.
I'm seeing different content.
Ohhhhhhh. *Resharper*. I've never seen anyone abbreviate it like that. Especially since that abbreviation makes it look like a language. I actually thought that it was a dot net implementation of the [R programming language](http://en.wikipedia.org/wiki/R_%28programming_language%29).
Might be in left field but... I think by connection strings u/Rec0de is meaning a different DB user account with a different set of permissions. Haven't had to do this yet but I'm going to have too soon. If it's at all like regular SQL database then you create a different DB user for each set of permissions you'll need. MyDBUser_ReadOnly, MyDBUser_Regular, MyDBUser_WreakHavoc the connection string then gets the appropriate user name and password.
The main link now redirects to the live stream. Here is a link to the agenda. It looks like this is where the recorded videos will live after they are streamed live. https://channel9.msdn.com/Events/dotnetConf/2015 
Are you creating your controls with an *if not postback* statement? With dynamic controls you have to create them every time. Also ensure you have unique ids per control and the ids remain consistent each time you create them.
I tried using the AsyncFileUpload control but it seems the upload can't be started after a button is clicked. It starts inmediately after the user selects the image.
Every team is different and every codebase is different. With each you're going to have your own fair share of challenges and difficulties based on the maturity level of both the team as a unit and the codebase. Here are the things that worked for me: 1. **Source control branching/merging** - We use TFS here running TFVC. Before we just used to have a main branch with all of our production code. Adding branches has made code far more manageable long term, especially when we need to isolate feature development and also have a copy of the PROD code available for troubleshooting/support/hotfixing. 2. **Continuous Integration** - Not having to worry about manually updating configurations and performing our own deployments saved our team a tremendous amount of time. 3. **Coding Standard** - Establishing a well-defined coding standard that is strictly enforced during code reviews has significantly improved the quality of code in our newer products and reduced time-to-deliver for future enhancements. Unit testing worked for *some* of our applications. We've built newer MVC apps from the ground-up using the service/repository pattern and program against interfaces, so unit testing has been trivially easy for our new stuff. Many of our old ASP.NET WebForms apps did almost all of their processing in the Page.Load() method, so they were nearly impossible to unit test. The cost to refactor didn't make sense for applications where we envisioned very little growth/change. What we opted for instead in those situations were Coded UI Tests. They aren't granular enough to tell us that this specific method failed for these specific test cases, but they can at least tell us that a specific use case is not working based on what we know about how the users use our application. Sadly they are database dependent so we do need to keep live databases available in lower environments with pre-defined test record data to help these tests pass. It's not ideal, but it has allowed us to automate some of our testing. 
&gt;Are you creating your controls with an if not postback statement? no, right now I have an empty Page_Load()-function and I create my controls within the OnClick-Function of the search-button when I click on the button I execute a function which is called DrawImages(pathlocal,pathglobal), pathlocal is the relative path to the pictures (~/Pictures) and pathglobal is the complete (c:/.../.../.../projects/Pictures/) path. the drawImages-function goes to the localpath and enumerates the files within the directory, it then adds each file to a collection, at last it copies the collection to an ImageButton-Array the size of the collection goes through the array adding stuff like ID, width, etc. in a for-loop, at the end of each loop it adds the control to my site. as ID I assign the name of the pictures, and they always stay the same.
How did you get your development team to buy in to the idea? Thinking of my current team now I already know three people who would just balk at me if I assigned them such a task. 
&gt; empty Page_Load()-function and I create my controls within the OnClick-Function of the search-button You have to always create dynamic controls with the same consistent id. So on the Page_Load(), mimic the functionality as what happens when the user clicks the search button. What's happening is that ASP.net is keeping track of the controls on your page via viewstate. Since you're creating dynamic controls you have to always create them on load so ASP.net can map them to the viewstate. Otherwise you get what you're seeing and get a null reference.
this is pretty much how my code looks, except that I moved populateImages() to a buttonclick and then I lost the link_click event of all the link_buttons. And I wondered if there is a way around that. Some said dynamic controls should be added in the Page_Init method but that way I have double the amount of images (ones from Init + link_click). I just watched a video about UserControls, but I am still clueless about those.
When a user clicks your "Search" button, what happens? You reading from a TextBox or something? Notice in my example I provided, I have a filter/search built in. It will always check to see if the user wants to filter out the results.
GitHub is what most people want. Whenever they move a project from CodePlex to GitHub they start seeing a significant increase in pull requests.
Doesn't necessarily affect the day-to-day, but it means you can contribute code and participate in the direction of the tool you rely on to compile your projects. They're also planning on adding Linux/OSX support, which will mean you can run msbuild on any platform.
Yes, it's the same reason why Google Code shut down.
If I click the button a post-back happens which executes the load_page() again, which I filled with the populateImages()-function again. but once the pictures are loaded, there is no need to load them again, is there? I wanted it so that if I click the search-button it takes the values from a drop-down list which determines color, and a radiobutton menu which determines size and renders by looking if the file fits the criteria if it does: it adds the imagebutton to the site, puts an ID on it and was supposed to add the image-click event. if not it ignores the file and looks at the next one in the array. I guess I'll leave it in the Page_Load, I mean it works, but I am not quite satisfied and don't know why.
Officially no, but I do more or less all of the development management. You're right about not having time to code, I still do but my workload is constantly increasing. 
Actually, according to ECMA-335: * A filter handler is "a user-specified set of CIL instructions to determine if the exception should be handled by the associated handler, or passed on to the next protected block." * The endfilter is required even if no control-flow path reaches it. This can happen if, for example, the **filter does a throw**. * Control cannot be transferred out of a filter block **except through the use of a throw instruction** or executing the final endfilter instruction. * If an **exception is thrown inside the filter block**, it is intercepted and a value of exception_continue_search is returned. So, not only do filters explicitly support the throwing of exceptions, but it is explicitly stated that an exception thrown by a filter should be interpreted as the filter returning 'false'.
The spec has to account for exceptions being thrown because the alternative is undefined. That doesn't mean *you* should be intentionally writing code in that manner.
I don't disagree that throwing an exception from a filter is bad practice. Only that filters support throwing exceptions and the behavior that is actually occurring is different from the behavior that is defined. Therefore it is a bug and needs to be fixed.
Rob Ashton often makes good points, but he definitely likes to troll. I was amused by his PR, but thinking about the internal work that must have gone into getting this release approved, I kinda felt bad for the people who made it happen. I'm assume it was months and months of paperwork and code changes to get ready to open source, only to have the first response be "your project is inferior to another OSS project and should be deleted". Even though it's tongue-in-cheek, I'd find that discouraging if I was on that team.
We have a development branch and a main branch. All deployments are from main branch. For releases, we create labels on the main branch. Developers merge into main when backlog items complete. The physical deployments are mostly automated, so it only takes minutes per service/application. Main branch has a gated check in policy, so it always in a buildable state. In addition, the Dev branch has a continuous integration policy, so every check-in is validated.
Make is not used because it's good, make is used because it is adequate and available. Makefiles get messy almost immediately.
MS has a [history](https://msdn.microsoft.com/en-us/library/windows/desktop/aa384187\(v=vs.85\).aspx) of this.
Shout out to FAKE, which we use to call msbuild as required + other things. Works great, given VS projects are msbuild files.
Ever have one of those days where something that should work doesn't work and you can't understand why.. and you just keep banging your head against the same wall over and over again? Now you can skip the wall part and reference the source. 
The short answer is that sending email in .net, with the built in methods, doesn't work for most providers who use https. There are several libs you can get to work around this. I mostly use a lib called chilkat. There are a few places, like this, where .net makes me really sad. I guess they can't do it all for us.
To be honest it wouldn't surprise me if Codeplex did as well.
It's probably just a matter of time.
*insert OSS push was start under Balmer's reign here comment*