Ctrl + arrow keys to move the cursor to the next word. Super useful for keyboard navigation. Works with shift to select as well. Works in delete and backspace. Works in damn near any program. Hold alt while selecting text (keyboard or mouse) to do column select. Amazing for repetitive lines. Allows you to type the same thing on multiple lines at once and paste something to multiple lines at once. Works in SQL server MGMT studio as well. REGEX. The pet of using regular expressions to search, replace, and parse text cannot be over stated. Learn them and learn to abuse them.
Switch to the console runner and look at the log. In the startup button there's a tiny drop-down where let's you choose between iisexpress and a console runner. 
True, I forgot about that but I do that too, often to prevent saving changes or to force an error condition to test error handling logic. 
Code is always harder to read then it is to write so stay positive. It may take a while to grasp all the moving parts but just relax, be yourself, and pack your brain with knowledge. It will get easier.
Maybe I chose the wrong example. The way I'm using this is I don't care if it parses but I don't want an exception. So that case I'd have to do what a poster below said ``` var maybeValue = int.TryParse(str, out var val) ? val : (int?) null; ``` 
The response I made to tulipoika applies to your comment as well. I do like your idea of explicitly saying what is returned in the method name. 
Yes I'm trying to get away from all of that boolean logic but I see your point. 
I‚Äôd stay off exceptions, either way, unless an unparsable string really is a process termination level threat. If you‚Äôre doing heavy data processing you probably want to go more into explicit validation and parsing steps anyway. 
No thanks.
Just out of curiosity, and I ask people this a lot, but what features do you typically use? My understanding is that most of the features are freely available using various extensions or built into VS now
Tools -&gt; Options -&gt; Projects and Solutions -&gt; General -&gt; "Track Active Item in Solution Explorer" 
Yeah, the TryParse method is that pattern, you get that though which is great :) Make a few changes, bring it back and focus on what problem you're solving. Give examples and those are the things it's easier for us to hack at :) It's great you're doing this as the whole parse and error handling thing is glossed over too much.
Yes, absolutely agree. 
In command prompt: nslookup host.domain.com In command prompt: ping [host.domain.com](https://host.domain.com) Go to [kloth.net](https://kloth.net), click nslookup on left, put in domain, click button &amp;#x200B;
I like 95% of the points this guy is making, I'm just curious about exception handling: "sometimes handling exceptions must be done in the controller, but I‚Äôve found there is almost always a better, more localized place. And if there isn‚Äôt, you can take advantage of **global exception handling middleware** to catch the most common errors and return something consistent to your clients." I do employ middleware to handle most common exceptions, but past that point placing try-catch on each controller-action seems to be unavoidable. I mean one could decorate the controller-action with a custom exception-handling \[attribute\] but common, introducing one such attribute-class just for one controller-action sounds like an overkill.
Agreed, with the exception that #1 could be fleshed out more. Chances are you will need to map the DTO to something that can be passed to your middleware, like a request object. Likewise, whatever the middleware returns might need to be mapped to an outgoing DTO. I fully understand you were talking about mapping to/from entities directly in the controller, which I fully agree with. I know I'm splitting hairs a bit here but only for the sake of completeness. All in all I think the points you make are right on target.
Like it, but I'm missing the examples how I should do it correct :)
I do both. I actually use a laptop keyboard with a TrackPoint on my full sized computer so that I can use the mouse when I need to without taking my hands off the keyboard. When reviewing or generally reading code, I use a full size mouse with a scroll wheel and back/forward buttons.
That code does care if it parses since it results in null if it doesn‚Äôt and that has to be handled separately from an int. But it depends on what exact situation is desirable. Larger code examples help much more than one liners usually to show how it helps. 
Perhaps he'd like it to use a strongly typed model for input, then have required attributes on that, and using a ModelState.IsValid check? Not sure though.
Code inside the controllers is not bad idea if you do it right. If it makes sense put it there, I have services layers for Business Logic and repos below that. My controllers do protect the rest of the application so if it makes sense use them. These are only guidelines 
Agreed, if you are using a structure that separates entities, from DTOs, from ViewModels you have a need to map your ViewModels to DTOs before sending hem off to your business logic. This is as easy as a `Mapper.Map()`
Does the interactive window have the same *using*'s as the foreground code window?
Interesting article, but the author doesn't justify most of these 6 items. Just spouts them off without clarifying the actual `Whys` behind them, and the advantages and disadvantages of each. It's surface level, and unfortunately doesn't convey much actionable info.
 nslookup -type=A google.com You should ask them for a list, though, because there is no guarantee that they have static IPs set up and they might load balance across a list of IPs, which is not always something you can query for
I second this. The moment I found out about class libraries and single responsibility was the day my controllers went from bloated with logic to very lean. Really, controllers should just be used for routing your response/data to the necessary objects for further processing. 
This will not work on a site that's load balanced between multiple IPs or has failover in the case of issues, because ping will only return one IP address
I thought the same thing. The suggestions make sense but there's no reasoning why these rules should be followed or examples of how to do it better. It feels like just personal preferences.
This article just seems like a front for his business. He wants you to pay him to see the examples of what to change. I feel like articles behind paywalls (or articles that lead you into them) shouldn't be allowed here :\
I honestly think its better the way you learned it. You can muddy the waters real quick trying to learn your first .NET language by tossing in all sorts of stipulations about how to code "properly" versus just learning syntax and what everything does. As someone who didn't learn that long ago, and who has friends going through college for the same thing, they definitely aren't teaching anyone unit testing.
I don't think I use standard shortcuts (I have mine set to match some older VB stuff), but a real basic one would be the shortcuts to comment and un-comment highlighted code.
As /u/DualFlush touched on already, browser's don't really get to fudge with the operating system itself. That's intentional for security. You may have good intentions making shortcuts or modifying someone's desktop, but if it were a thing, it could just as easily be abused maliciously.
My guess is that you want all logic to happen in their own modules, that you can unit test. 
Not to mention SSL is often terminated at the load balancer and sometimes it relies on the domain being used versus the raw IP
Crtl+alt+I
F8 next in find results Shft+ F8 previous find results
Generating the syntax for lambda =&gt; delegate methods makes it all worth it though
&gt; placing try-catch on each controller-action seems to be unavoidable I'm working on an app right now with 1000+ actions and not a single one has a try/catch in it.. 90%+ of the action methods are a single statement.
I think picking how dogmatic you are about design patterns in a project is just another architectural choice. The important thing is that the team members agree with the approach...that is more important than whether or not you include DTO conversion logic in your controllers or not. Hell, I've got a couple ASP.NET Core web api projects where I only have one endpoint and all of the code is in the controller, and I have others where we have dozens or hundreds of endpoints and we are pedantic about separating out business logic from the controllers.
The button is [here](https://imgur.com/ZABUCG7.png). I do not know if there is a keyboard shortcut though.
Use crtl+t to open a file quickly by searching for a class name, variable name, etc
Yeah, that's how quite a few pluralsight courses are as well.
Surprised nobody's covered block selection here (AKA column selection mode) Hold "ALT" and select some text, and you can select a block of text, then cut it and paste it or type something and change every line the same way It makes it easy to do stuff like this: (different editor, but it shows you what you can do) https://youtu.be/z_cT0ViHxWM?t=29
Watched this while playing some Diablo, it was really useful! Thanks
So true. This one at least backs it up with why some approaches are more testable. https://www.pluralsight.com/courses/architecting-aspnet-core-mvc-unit-testability
Is XBAP still a thing? You could do it that way
I dont have an answer, but want to say I am looking for the same thing! 
You're going to want to implement [IdentityServer4](http://docs.identityserver.io/en/latest/). Take the time to read and digest the documentation thoroughly, and maybe implement a test instance you can play around with before you add it to your project. IdentityServer4 is an OAuth server implemented in ASP.net Core. The OAuth protocol allows you to authenticate clients and users against a canonical identity store in order to access resources. It's incredibly powerful, but also mindbendingly complex. But you can figure it out. Good luck. üëçüèæ
I personally think identityserver is overkill unless you‚Äôre running an enterprise grade multi-tenancy application. Using Identity and rolling out a jwt solution is pretty straight forward. Check out Shawn wildermuth‚Äôs classes in pluralsight - he rolls his own in one of the vids. There‚Äôs also another identity jwt specific course for asp.net core on there too.
Then why have action methods at all? I'm sick of writing boilerplate transfer code.
That doesn't sound good to me. The treadmill of software design patterns keeps inventing places to put logic, and then spending the next decade working tirelessly to get all of the logic out of those places. But the places never go away.
How about trying Google or MS auth instead of setting up a new authentication system. 
It does not have the same *using's* (since you may change foreground window during a session) but Ctrl + dot and Intellisense do work, so it's no biggie in my opinion. Take a look at this: https://i.imgur.com/QJapqTf.gifv It enters multi line mode and adds the using... probably good enough for most simple snippets. Btw, you can clear the window with `#cls` without losing the session, meaning declared variables and usings stay available, or type `#reset` to reset to the initial state.
It's mostly the separation of concerns and clean architecture. I also think the biggest reason is testability. You don't want to test the controllers (unit tests or integration tests). You want to write test code that targets the inner layers of the app.
* **Authentication** = who you are. * **Authorization** = what you're allowed to do. * **OAuth (2.0)** = standard protocol made popular by social media/email sites to let you sign in using your existing account to another service. There are various authentication "flows" (ways to login and communicate with the app asking for permissions) and all end up giving this app your userid, email, and something called claims which are a simple key/value list of attributes. It could be personal info like birthday, other data like an customer id, or anything else. * **OpenID** = another standard protocol for authenticating to external apps from a single account but focused only on authentication. * **OpenID Connect** = **OIDC** = modern protocol that merges OAuth and OpenID into a single system that lets an app know who you are and also optionally ask for authorization/permissions data if available. This is used by all major services now including Facebook, Twitter, Google, Microsoft, etc. You should be able to easily add any OIDC provider to your app since they all follow the same standard. * OIDC can be chained. Your app can ask OIDC provider A for a sign-in, and this provider can then forward the user to another provider B to sign-in. Realistically limited to 2-3 at most to avoid browser issues and latency. * The technical concept is called **token-based auth**. OIDC providers send back a "token" which is an encrypted piece of data that contains the info. There are ID tokens and Access tokens. You get an ID token after the OIDC completes the sign-in process that includes the username/id info. Tokens can also expire and require going through the auth flow again. * You are still in charge of storing users in your own database if you want, or you can just rely on asking for these tokens again. Bigger apps will store a local copy of the user and merge any accounts with the same email since people may sign-in with email/password and another provider, or they may go through a transition, or the app just wants to be able to store their own user preferences and such. * **JWT** = javascript web token = badly named but standardized way that these tokens are created. It's just standard certificate-based symmetric encryption/decryption but bloated by the JS ecosystem. This format is also commonly used to send credentials to the backend or API from a frontend JS app without using cookies. I recommend just using cookies if you can. * IdentityServer is a token server that lets you setup authentication in a single place. It is also an OIDC server. Your apps can ask IdentityServer to sign-in the user and get a token back in your app to do what you need to. IdentityServer (because of OIDC chaining) can then handle both user/password logins or forwarding to another OIDC provider if you want, but your app only needs to have a single connection to IdentityServer which makes setup much easier and lets your users sign-in or logout from all of your apps at once. * IdentityServer is very customizable and can use ASP.NET's Identity system for storing your local users. It can also store all the configuration stuff in a database or in code. * IdentityServer only does Authentication (see above), not Authorization. Usually permissions are application specific and not reused between providers or companies. They do have a separate product called Policy Server but that's outside the scope of what you need. &amp;#x200B; Setup IdentityServer (there are plenty of quickstarts), point it to some social providers, configure the local membership system, and then point both your Vue and Xamarin clients to it for authentication. Your Web API can do any further authorization looks (maybe a separate database table or whatever you like). &amp;#x200B;
That is a super-useful response, thanks so much for going to the trouble of capturing the demo. This is going to save me a lot of time. I'll send karma (the real stuff, not mere *reddit* karma, each time it does so. :)
You just need to make sure your function declaration is above your function call - the order in which the views are rendered isn‚Äôt relevant, but rather the order in which the HTML is rendered is.
Also look into Key cloak (by RedHat). I prefer it to Identity Server and it has absolutely no licensing issues for production in a corporate environment.
Do you know what prevents execution from continuing? Every now and then I can modify code after a break but more time it tells me that the source code has been edited and can't continue
No trouble at all, happy to help! I like it, thank you for the real karma in advance ;) Regarding the capture: Have a look at [ScreenToGif](https://www.screentogif.com/) or /r/screentogif, easy to use for quick captures and it's free
 Agreed. &gt;This mapping logic is innocent enough, but it quickly bloats the controller and adds an additional responsibility. Whenever I see 'responsibility' or 'SRP' I can't help but think what the person is really saying is "this doesn't feel right, but I don't know why". 
## 1. Mapping Data Transfer Objects (DTOs) &gt; This mapping logic is innocent enough, but it quickly bloats the controller and adds an additional responsibility. Ideally, our controller‚Äôs single responsibility is only to delegate the next action at the level of the HTTP request. No. Well, yes you don't want it there. But not because of some vague notion of 'responsibility'. The reason you don't want it there is that you can't unit test it Look at the code again. public IActionResult CheckOutBook([FromBody]BookRequest bookRequest) { var book = new Book(); book.Title = bookRequest.Title; book.Rating = bookRequest.Rating.ToString(); book.AuthorID = bookRequest.AuthorID; //... } It is impossible to test the mapping logic without also dragging in the ` //...` part. (And no, mocks won't solve it.)
## 2. Validation Agreed, mostly. Personally I prefer to move the validation logic into the services layer because validation may require database calls. But yes, if you are going to validate in the MVC layer do it with attributes and filters. You don't need to clutter your controller code with imperative validation.
## 3. Business Logic Same objection as #1. Yes, that doesn't belong in the controller. But you need to say why. Which again, is because it is a hell of a lot easier to use a unit test against business logic in a pure model or a business rules engine than when its mixed into the controller.
What I believe is happening is that - at the view level - that function at the layout level doesn't exist yet, unless I have messed this all up that bad? I'm guessing I just need to load jQuery and all of the script I need for the notifications ... in each view, and not use the layout to hold the JavaScript? 
If you put the function declaration above the RenderBody() call in the layout page than it will be rendered above anything inside the View. If you put it beneath the RenderBody() call, than you are correct, it won‚Äôt exist yet.
So, when showNotification() is called, it doesn't exist yet. And, that's the way it works? From View to Layout?
## 5. Error Handling Microsoft disagrees with you. That's why ASP.NET Core defaults to using `ActionResult`. We had to fight with them just to get `ActionResult&lt;T&gt;` added. I, however, agree with you. My controller doesn't need to know about HTTP status codes. Just throw an exception and let the error filters convert the exception into the correct HTTP status code.
I don't think they are personal preferences. In fact, I just posted my justifications for following those rules because I firmly believe in them. Those are hard rules in any (non-toy) project I write. But yea, I do think being able to explain why you are making design rules is important. Otherwise we just end up with ignorant cargo-cult programming where no one can debate a rule because no one understands it. 
I don't like "separation of concerns" as a justification because it is so subjective. (And often it is also over-applied.) But testability, yea. It's easy to prove testability by showing a real test for each of these before and after the rule is applied.
&gt; Have a look at ScreenToGif Thanks again. *Feel the karma...* 
That's part of it, but not all. Consider the error handling. Rather than duplicating that code all over the place you can write it once as a filter and never have to think about it again. Which means you can't screw up when it's 2 am and you just desperately want to go home.
Alternatively you could put your notification call code within the View in an event be run on document load.
I understood the need to reduce the complexity of controllers. I‚Äôm assuming that it‚Äôs due to readability and maintainability of your code. In terms of validation, I believe the author is implying to use attributes to validate of invalidate parameters. It‚Äôs really quite silly since validation can get complicated. Authorization being done either in custom attributes or in base classes make sense, but once again, sometimes it‚Äôs just not possible. Overall, I dislike the single responsibility principle being used to argue against never repeating yourself ever. Some business cases are easier to reason about if they‚Äôre laid out plainly and not part of the magic workflow of a framework. If you explicitly check validation where your logic is, it could make that validation more maintainable than having to go hunt around your code base. I also dislike bloat in my code when it‚Äôs not needed, but complection can be equally dangerous. Reusing the same object in all cases begs for configuration which can increase cognitive overhead when reading the code. 
And in his example it's because it's not being handed off somewhere else, like Automapper or your own mapping code. The manual mapping in the example is already going to be a DRY problem no matter where it is.
It's not so bad. The bulk of my logic is in `XxxService` classes. These classes are thread-safe and shared between my website, command line utilities, and Windows services. They also get the bulk of the integration tests because I can test them without the ASP.NET crap getting in the way. *** As for try-catch, I almost never use it. I think it was Anders who said that you should have ten try-finally (or using) for every one try-catch. My one try-catch is in an ASP.NET filter that handles logging and HTTP status codes. 
Because we need boilerplate transfer code to convert ASP.NET concepts into normal function calls. It gives us a place to hang the crap like URL routes. It also means that my service classes remain clean so I can use them in non-ASP.NET scenarios. (I often have a matching Windows Service and/or command line applications for backend processing.)
&gt; &gt; &gt; Chances are you will need to map the DTO to something that can be passed to your middleware, like a request object. Likewise, whatever the middleware returns might need to be mapped to an outgoing DTO. I try to avoid that. My middleware is designed specifically for my REST layer and my ORM (Dapper or Chain usually) works directly on the DTOs without needing to be mapped to DB Entities.
You're absolutely right, thank you!
Agreed. But it is a mistake that I see quite often.
&gt; In terms of validation, I believe the author is implying to use attributes to validate of invalidate parameters. If database access isn't required, then I like using a validation interface on the class. https://www.infoq.com/articles/CSharp-Models Of course I cheat. Both EF Code First and Chain honor these interfaces so often I don't need to explicitly check if the model is valid. And if I do, then I just use a filter.
&gt; Authorization being done either in custom attributes or in base classes make sense, but once again, sometimes it‚Äôs just not possible. Even when it can't be done in a filter or base class, I still don't want it in the controller. Push it down into the services layer where you have to make database calls anyways.
I like to set my debugger in my controller and follow it from there. However, I do agree on catching global errors with decent logging in a shared middleware. I also go heavy into stored procedures over EF. I guess we all have our tastes. 
No problem!
&gt; I also go heavy into stored procedures over EF. I guess we all have our tastes. Same here. When I created Chain, it was mostly about being able to easily call stored procedures and map the results to... well maybe objects but also data tables, lists of strings, whatever. Not every result has to be a collection of objects. *** Oh, here's something that's true but most people don't believe. The first library referred to as a "Micro-ORM" was designed solely to call stored procedures. I created it as a way to demonstrate C#'s dynamic keyword. https://www.infoq.com/micro-orm/ 
I ran a sfc/scannow and even that turned out clean.. http://666kb.com/i/e1c2gt8pp5q6oyx2i.png what could this bug be :( anyone?
It could be a number of thins. Check out the document below, it describes the limitations on the types of code changes you can make with edit-and-continue: https://docs.microsoft.com/en-us/visualstudio/debugger/supported-code-changes-csharp?view=vs-2017 
I certainly could've implemented some custom implementations of various ASP.Net parts to eliminate the controllers and action methods, but that would be a not insignificant chunk of code for questionable benefit, along with the learning curve of figuring out how to appropriately override ASP parts. It also wasn't as clean and clear cut when we started developing. We learned our common patterns better and refined as we went along.
&gt; That doesn't sound good to me. Why not? The system legitimately has 1000+ commands and queries that it handles. The controllers encapsulate no logic. Our commands and queries are used from multiple ASP.Net Core, ASP.Net MVC 5, command line, and background service contexts. Action methods don't need a try/catch because that's handled at the level of individual commands or queries where needed, or in the dispatcher, with a final catch for anything missed attached to whatever higher level pipeline exists - whether that's ASP or DataFlow based message handers or a loop in Main. I don't care if you put your logic in domain objects, command handlers, or transaction scripts, but it never belongs in the layer that bridges to your actual executable project. 
Is this a public web app or an internal company thing? If it's for your work, you'd usually do this through a GPO. So much simpler that way.
If every action is literally a single expression, then the controller has no reason to exist.
I‚Äôm not disagreeing with removing logic from the controller. Just the implications of where I believe the author wanted them. 
The only purpose of the controller is to glue an ASP.Net route to your business logic. It really *shouldn't* be more than an expression or two. Personally I think it's acceptable to do mapping or minimal translations of error responses in the action, but if you're adamant about unit testing those things you would have to move them out of the controller. 
You can put any JS code in a window.onload handler to ensure it will wait for all scripts to load before running. Or like the other guy said scripts load and run from top to bottom anyway so any code that comes later in the output HTML runs after script files above are loaded.
Check this out. [http://jasonwatmore.com/post/2018/08/14/aspnet-core-21-jwt-authentication-tutorial-with-example-api](http://jasonwatmore.com/post/2018/08/14/aspnet-core-21-jwt-authentication-tutorial-with-example-api)
Yea, that's fair.
But on the other hand, the purpose of a route is to glue a url to a controller action. Why do we have all this *stuff* if we're not supposed to use it?
&gt; I also dislike bloat in my code when it‚Äôs not needed, but complection can be equally dangerous. Reusing the same object in all cases begs for configuration which can increase cognitive overhead when reading the code. This is the biggest problem I have at work when coding with other people. With good intentions, they try to avoid repeating code, and then we end up with a tangled mess of functions reused way too much, with tons of parameters to configure them for each use case. And eventually we run into a situation where just can't use it, and we end up having to refactor it into two functions instead. I'm trying to convince people that DRY can be abused. It shouldn't be treated as dogma.
&gt; The important thing is that the team members agree with the approach I think this is a big part of it. I tend to be one of those hardcore clean coders and I know I've driven people crazy about it. But if you pair me with someone equally zealous, we end up loving the things we build. It's got DTOs and tons of test coverage, tons of layers, but we love it. Coding is just as much about the people as it is about the code.
I was having a discussion with one of my friends from work about this topic. We decided that it boils down to experience and personal taste. One of the more junior devs in the group our company outsourced some work to pushes heavily for sonar qube. I don‚Äôt use the tool but it‚Äôs meant to analyze your code and look for duplication among other things. Sometimes you‚Äôll regret making something reusable and sometimes you wished you had. The other side of that is how you make something reusable. The ability to anticipate how others will use your code is important. Instead of passing in ever increasing flags, separating your code out into multiple functions and passing in a context diminishes those situations. I recently refactored a big new feature and now modifications are fast and less bug ridden. The key was to pass the decision making variables into the function along with the general context all as one thing. It creates a sort of waterfall of easy to follow steps rather than a labyrinth of ifs and else‚Äôs. Combining that with some common sense on which items need encapsulation made this refactoring a huge success.
Minor correction but JWT is JSON Web Token. Not sure if I agree that it's bloated, though.
\\o/ 
I was in your shoe 1 month ago, I done a lot of search, found that JWT is suitable for me since there is no third party app to involve. My case was making an API with two methods, first for user login and the second to get the data, of course you have to be authorized to make a request to second method so first a user must login and after a successful login a JWT token is created and returned so my authenticated user can do a request to the second method by providing the token he got, straight forward and simple. Maybe there is something better but at least JWT provide minimal security that you can trust, it wont let you or your application down. I'm very happy to discuss this practice or anyone points some mistakes with my way in this case 
My world completely differs because most of the time I have to fight with wrongly applied DRY. People like to create Add-n-Update because it looks the same and you just add one boolean switch riiiight. Then it turns out some fields you can only Add and never update, so it is hard to explain adding is different concern than editing for object. It is subjective because context is king, so it only depends if you and your co-workers are in the same context for the same code.
Creating your own identity server is somehow overkill. I generally advice to use a third party service handling authentication/account management: identity/authentication is hard. Let the experts do that for you :) Depending on your budget there are lots of Saas products: auth0, Okta, etc. You can use firebase as well: their authentication service is free. It works pretty well and it handles many use cases for you. 
I‚Äôve been using Azure Active Directory B2C for storing users and doing Openid Connect. I recommend that regardless of your hosting provider. 
Thank you! All of the separate pieces make a lot more sense now.
I don't envy you. I would rather deal with unnecessary duplication than excessive complexity caused by cramming too many things together.
One thousand commands and queries in a single app is a massive code smell to begin with, and in any kind of web application it's positively a code reek. No one can keep an API that crazy in their heads. Single responsibility isn't just for classes, your app itself should have some sort of coherence in purpose as well. Either you're using controller actions for what should be parameters to more generic points or your app is just doing too fucking much. Beyond that, yes your controller actions **look** light, but they're really not. All that pipeline code is run on every action, any change to it is a change to those thousand actions. Not saying the pipeline is a bad place to write code, but it's for code that is truly cross cutting, not just to keep your controllers lean. 
Please don't mix razor with js code because you introduce security hole. The @ symbol is for escaping signs in the HTML context and it is not valid for JS context. All your js code should live inside the \*.js files.
Yeah REPL is pretty cool. Something similiar but not in VS is LinqPad
How do you deal with db related exceptions? For instance if the user tries to delete an entry that has already been deleted by another user in the meantime, EF will throw a tantrum about it and this exception will bubble all the way to controller layer.
Didn't read the whole thing but sounds like you don't know much about JWT's especially when you are recommending that cookies are 'more secure'
If in Azure have a look at Azure AD, and relarted to that Azure AD B2C. That would then act as the "tokenserver" and you dont have to get your hands dirty on Identityserver (or similar).
Maybe read the whole thing then because I never used the words "more secure" in the entire post.
Right, fixed.
Stepping back in time here...
Been there. I also got confused when I started to look in API security. This is a summary of what I learned: Normally you would use cookie to persist user session and authentication. This is a tested matured approach and it works as long as you're using HTTP and your requests are not inter-domain. So let's say an API wants to serve a SPA or a mobile app, cookie is OK here. You send credentials, you get a cookie and from that moment you send that cookie for each of your requests (this happens automatically in browsers). Things get complicated when you want to expand your domain. For example consider Google. You create one account and you can use it in various services, GMail, YouTube, Blogger, Chrome, Android, Drive, etc. Not only that, but other websites can use Google for authentication too. Cookie can't handle this scenario, this is where OAuth comes in. Instead of cookie you work with token. So here a server is responsible for authentication. You send credentials and you get a JWT token. If only one key is used to sign that token (symmetric) then other services must have that too, to validate the token. If a private key is used (asymmetric) then other services must have the public key to validate the token. IdentityServer is for the second scenario when you have separate authentication server and 3rd party clients. If all your API needs to do is to serve a SPA and a mobile app then the normal [ASP.NET](https://ASP.NET) Core Identity is enough. &amp;#x200B; Some resources and books: [https://dev.to/rdegges/please-stop-using-local-storage-1i04](https://dev.to/rdegges/please-stop-using-local-storage-1i04) [https://dev.to/darraghor/be-careful-of-the-jwt-hype-train-3e81](https://dev.to/darraghor/be-careful-of-the-jwt-hype-train-3e81) [Essential Angular for ASP.NET Core MVC](https://www.apress.com/gp/book/9781484229156) (this book uses Angular and ASP.NET Core with cookie based authentication) [http://jasonwatmore.com/post/2018/08/14/aspnet-core-21-jwt-authentication-tutorial-with-example-api](http://jasonwatmore.com/post/2018/08/14/aspnet-core-21-jwt-authentication-tutorial-with-example-api) [OAuth 2 in Action](https://www.manning.com/books/oauth-2-in-action)
Extensions you'll find a lot of goodies on the vs extensions site. One particular fav of mine is Add new file extension which you can quickly add new files without having to load the add new file dialog. Can even do stuff like making a file start with `ISomething.cs` will make an interface and without the I makes a class. There's also Roslynator for useful refactoring tools and intellicode for better suggestions. I use alot of extensions and it really helps on productivity. 
&gt; One thousand commands and queries in a single app is a massive code smell to begin with Sounds like you've just never worked on a decent sized app. A few dozen aggregate roots and a few dozen commands + queries per root and you're over 1000.
&gt; the purpose of a route is to glue a url to a controller action That's exactly what I am using it for. That and nothing else, as much as possible.
So your app contains a few dozen completely unrelated concepts? And you're performing a few dozen completely isolated actions on each of those concepts? And it's an API hub? That's not a decent sized app, that's a monstrosity. Either you're creating endpoints for shit that shouldn't have an end point or you're doing too fucking much. How big an impact does taking this thing down have? How long does it take to get someone up to speed? How long does it take to fucking build? Why do you have a few dozen aggregate roots in an app in the first place? Especially one that isn't directly user facing?
&gt; How do you deal with db related exceptions? For instance if the user tries to delete an entry that has already been deleted by another user in the meantime, EF will throw a tantrum about it and this exception will bubble all the way to the controller layer. It doesn't bubble to the controller layer because in this system if it modifies the database, it's a command. And if it's a command, it gets handling behavior composited around it. One of those behaviors is catching exceptions, logging and alerting when appropriate, and replacing exceptions with failed command results. Every submission of a command for processing returns a common result object that includes a result, metadata, and error details. A middleware component (HttpModule for non-Core ASP.Net) translates the command result object into an HTTP response. Through the HTTP response code (e.g., 412 for optimistic concurrency violations) and body, the front end can determine how to handle the response in a general manner as well. &gt; Would you be kind enough to link an example which show-cases the technique you are applying? Sorry, this isn't something I read last week in a blog post.
&gt; So your app contains a few dozen completely unrelated concepts? That's not what aggregate root means. &gt; And you're performing a few dozen completely isolated actions on each of those concepts? Actions and questions, and some areas are larger than others. Not all are completely isolated - more than a few are reused within other commands that aggregate several actions. &gt; And it's an API hub? It's the API's that serve our internal tools, public website, and partner integrations. Some endpoints are shared, but most are unique to the app they serve. The underlying logic, however, is shared. We maintain multiple versions of partner api's as well as api's to serve more legacy internal applications. The code base is over 10 years old. &gt; That's not a decent sized app, that's a monstrosity. It's hard to imagine what world you work in where a few dozen roots in a system is a monstrosity. &gt; How big an impact does taking this thing down have? Why would I take it down? Deployment is seamless. The API and the apps utilizing it have fully 100% uptime over the past year, and better than 99.999% over the last 5. Also, not that much. The real meat of our system is the 1 billion+ dynamic data requests and 200+ TB of content we serve each month. The API just drives the store that customers use, the integrations partners use to provide our services in their stores, and our internal tools. It's fairly low traffic overall. &gt; How long does it take to get someone up to speed? New developers can be productive quite quickly since logical business domain operations and questions are cleanly encapsulated. &gt; How long does it take to fucking build? 3.5 minutes on our CI/CD server, which is just a moderate VM. Another 4.5 minutes to deploy. &gt; Why do you have a few dozen aggregate roots in an app in the first place? Especially one that isn't directly user facing? Because that's how many logical boundaries there seems to be.. It is mostly user facing. Most of the API exists to serve UI's.
What should the solution to 1) look like? 
Can you elaborate on the pros/cons of using the two approaches?
Am I wrong or does it also mean you have to expose IdentityServer4 externally as well? In other words if you have a public facing API (api.mycompany.com), you also have to have IS4 exposed publicly as well (auth.mycompany.com), something like that?
You are correct.
This is possible when your app is a Progressive Web App, the feature is called A2HS (Add to home screen) and works with newer Chrome on Android and Desktop. Check out: ["A2HS on Desktop" on MDN Web Docs](https://developer.mozilla.org/en-US/docs/Web/Apps/Progressive/Add_to_home_screen#A2HS_on_desktop) ["Add to Home Screen" on Google Developers](https://developers.google.com/web/fundamentals/app-install-banners/) &amp;#x200B;
I agree, this does seem possible.
That is the recommended approach. But you *can* host IS4 on the same server/domain as your application.
Sure I don‚Äôt have the code with me at the moment but basically I have a send email method that works fine. What I had to achieve is some kind of fire and forget send email. What I did is simply run that inside new thread with StartNewThread closure. But when I do it mail never get sent. Same code without using new thread works perfectly fine.
With IdentityServer you have the option of putting claims in the access token and accessing the users claims in the identity token. 
&gt; Sorry, this isn't something I read last week in a blog post. Fair enough. But please do bare in mind that pinpointing the problem while articulating the false impression that the solution is "oh so trivial" (by merit of the fact that it's not even being mentioned anywhere in your response or in the blog-post) can prove extremely dangerous in hindsight in the sense that people will go around looking for shallow solutions on-the-cheap where there isn't any to be found. The solution you propose sounds like it works and its very sound and clean but it's both cryptic and approach-specific (sounds like you are applying some DDD-specific approach - feel free to correct me on this one). When pinpointing problems -if you want to be true to yourself- be meticulous enough to also offer a couple of hints and links to possible healthy solutions just so that people will get on the right track. Placing a couple of links in this fashion is not hard and is bound to yield much more positive results than mere finger-pointing.
Chrome already supports A2HS (Add to home screen) on desktop: [https://developer.mozilla.org/en-US/docs/Web/Apps/Progressive/Add\_to\_home\_screen#A2HS\_on\_desktop](https://developer.mozilla.org/en-US/docs/Web/Apps/Progressive/Add_to_home_screen#A2HS_on_desktop)
I know EXACTLY what your problem is!
Thanks will try this could be the case 
Chrome already allows adding "shortcuts" to home screen/desktop: [https://developer.mozilla.org/en-US/docs/Web/Apps/Progressive/Add\_to\_home\_screen#A2HS\_on\_desktop](https://developer.mozilla.org/en-US/docs/Web/Apps/Progressive/Add_to_home_screen#A2HS_on_desktop)
I think identity server or external providers are a bit of overkill for a small project. You can try the asp net core identity (not the same as the identity server, kind of a simplified version). It can be set up very easily to use jwt tokens and it will be suitable for a simple appliaction. Also supports external login providers. I used it in multiple projects and the Microsoft tutorial is pretty good to get things started. https://docs.microsoft.com/en-us/aspnet/core/security/authentication/identity?view=aspnetcore-2.2&amp;tabs=visual-studio
Identity server ends up being a new service you have to manage / understand. JWT is a small bit of code that you can hook into existing user management systems much more quickly then identity server. I can copy / paste the same code from nearly every asp.net core jwt project I have with very little modification. 
Fantastic response! 
\&gt; My controller doesn't need to know about HTTP status codes. Just throw an exception and let the error filters convert the exception into the correct HTTP status code. I came here to find someone who can suggest a decent approach to jump-start people with for this specific issue. I am sure that things are more complicated in practice but at least now I have something to get started with. Thank you so much. 
I‚Äôd love to hear it. I was in a similar situation last month. I was exposing erp data to an application we are developing that would be consumed by a very small group of clients. My choice of creating a custom api vs using the erp api directly was made after my struggles trying to decide how to implement proper authentication and authorization
The sub nodes of an aggregate root are information **about** that node. They are expected to all be drawn in as part of that node. If something under your root is also an aggregate root you probably aren't using the right pattern. Then you've got a couple dozen methods on each aggregate root? That sounds like direct access to subnodes, which isn't really the idea of the pattern either. That's not necessarily wrong, but then it sounds like you've been so worried about having any content in your controllers you've lifted your service API straight up into the Web. It could be right for your project, but it reeks of code smell. And that's not how you rate impact. Every service will break someday even if it hasn't yet, and it can't be that low an impact with that many services. 
So basically you would just write var x = array[^ 1] Most of the time, right?
Well the most common case when going from the end is retrieving the last, but there are cases in proprietary code I worked with that counting from the end would be helpeful
I'm not sure what you mean. Even if your action is one expression it can still benefit from middleware, authentication, action filters, model binding, validation, exception filters... in fact I'm struggling to think off the top of my head of any features that you can *only* use within controller actions. Also, the argument isn't that you should avoid using these things, it's that most of them should be handled in the ASP.Net pipeline outside of the action. Also bear in mind that ASP.Net to some degree tries to be all things to all developers. If you're making a small LOB app that only needs two controllers, honestly you're probably wasting your time implementing many of the patterns that are discussed here... 
I love watching David Fowler's excitement about these topics
It‚Äôs overkill because it‚Äôs not necessary and it‚Äôs added bloat. If you don‚Äôt have multiple client apps that use the same user account, it‚Äôs pretty silly to go with identityserver.
Could be useful for things such as immutable state tables.
Am I just off and doing this all wrong?
Someone already did all of the work for ASP.NET Core, but I can't remember the name of the Nuget package. 
Pretty much. All modern Javascript should be done with webpack and NPM etc, your razor pages should just have a single &lt;script src="dist.js"&gt;
So my wanting to send a string var from the view through JavaScript is fundamentally wrong? It feels a bit lazy, and I'd really like to do this the right way
Yes that is absolutely the wrong way in 2019 however lots of devs and teams insist on using MVC in 2019 too soooo. Passing data via a string via window object is slightly better, but still crap. Really you'd have a REST API, probably with a SPA too. But a REST API at the very least.
Thanks for the input. Much appreciated. I feel my original post was ignorant now, lol.
Well, I'm not going to go searching around trying to hunt down articles that describe some parts of implementation similar to what I've done . This isn't some thing I just read about, or have a folder of links about. It's the result of actual software development over the course of years. In my opinion, it would be a disservice to post some cursory overview that doesn't come remotely close to addressing all the variety of concerns in real software. Those articles do a great job of covering the single most straightforward use while avoiding all the rough edges.
Extension methods on primitives are serious code smell. :-\
You're so hellbent on claiming I'm "doing it wrong" that you're just inventing some vision in your head and attacking it. Even a simpler root easily hits a dozen commands. CRUD is 4 alone FFS, but a dozen or two is a monstrosity.. right.. btw, how many 100k+ LoC code bases have you maintained for a decade?
https://anthonychu.ca/post/overriding-web-config-settings-environment-variables-containerized-aspnet-apps/ 
Looks very interesting, not loaded up in VS, and only slowly migrating to .net core, so have a couple of questions but they may be daft ones (feel free to say I‚Äôm wrong - it‚Äôs all learning) 1. Web api is returning results straight from the services. I‚Äôm used to returning specific status codes, 404,200,201 etc all formulated in the web api project, the services would return notfoundexceptions etc, Does mean more work in the web api. 2. In the services, you use unit of work and IUserrepository - I‚Äôve got an IUserrepo inside the unit of work - so uow.users.add(new user); uow.savechangesasync(); is there a benefit to one over the other? (I‚Äôm guessing this is one of the places where I fall down on SOLID) probably have tons more questions/learning as this goes on.
I don‚Äôt mind the controller knowing about HTTP status codes - I‚Äôm never going to use MVC outside of a web interface, so why not return HTTP status codes? They‚Äôre consistent and guaranteed to be so, rather than relying on the error filters converting correctly To me, an exception should be thrown when I need to either catch it further up the stack and handle it, or where it‚Äôs a fatal error... if I‚Äôm returning an error code, I‚Äôm not throwing the exception up the stack exceptions and error codes seem to me to be fundamentally different things 
One thing to keep in mind is that headers and cookies really don't have anything special to do with auth, it's just common behavior we've agreed to: Bearer TOKEN, or some specially named cookie. You can shove a jwt into a cookie and still use asp net core's jwt bearer auth, you just have to hook an event to put that cookie's value into the Token property (or whatever it's called). &amp;#x200B; When choosing between either using a header or using cookies, it's critical to understand your scenario and security needs fully. Does your site ever host untrusted content? Are you particularly worried about XSS or XSRF bugs? You can get reasonable security with jwts if you store them in a cookie with httponly, strict same site, etc. &amp;#x200B; WRT cookies and the built in DPAPI... it is great to start with, but becomes problematic when you scale to more than one server (managing shared keys on the backend). However it does enable you to hide information even on the client, which is good. It's all tradeoffs.
Perfect timing, pretty much what I'm doing in a big upcoming project üëç
I agree that it's okay for the MVC layer to know about status codes. But let's say your service layer throws a data not found exception. It's easier for me to simply catch that exception in a filter and turn it into a 404 one time than to put a try catch block in every MVC method. In fact I wrote my ORM to throw a data not found exceptions when a single record was expected specifically for this reason. (Originally it threw a generic exception that couldn't be distinguished from any other network or DB glitch. ) 
You can instruct users to click and drag to their desktop to create a shortcut. If they drag a link (you can create a button that says "drag me to your desktop!" or something) it will create a shortcut to that link. If they drag the icon in their address bar (at least in Chrome) it will create a shortcut to the current page. You can make a graphic to show them how to do it. Either way it's a pretty simple operation to bother trying to automate it considering the trouble involved.
The DNS response should list all the possible IPs. At least for some types of load balancing.
JWTs certainly can be encrypted. In fact, anytime you send 'em over HTTPS they are. What claims are you talking about? The header says it's a JWT but that's it. It's literally just what it is, what information it has, and a signature. Really struggling to see the bloat here.
I love this a great extra feature I recently found was you can load a project into the c# interactive environment and work with your custom classes and implementations, it is very useful 
Love me some snippets. You can create your own too, which is fun 
Why would someone do this to themselves? 
The payload of the JWT is not encrypted, it's just signed. The issue with frontend SPAs is leaving the tokens in the browser where there is no secure place to store them, not about the HTTPS connection.
Yes, agreed on tradeoffs. However most people don't consider all the details and cookies just have more protections around them due to full encryption of the values and strong anti-forgery/CSRF protections built into the framework and even browsers at this point. Storing JWTs in a httponly cookie seems awkward to me since it's just adding another layer of signing to an already encrypted value. True that DPAPI could be easier to configure for shared backends although they have libraries now that make it 1 setting to use Azure or Redis.
I didn't say the payload is encrypted. I said you can encrypt the token. Literally nothing is stopping you from storing it how you see fit. Again, still not seeing the bloat. JWT is *just* a structure, and a pretty simple one at that. I think you might be conflating it with something more. The fact you recommend to use cookies, when JWTs are commonly stored in cookies, is a tad strange.
Download an extension for middle-click = Go To Definition &amp;#x200B; This is so useful I'm surprised it's not a default setting in Visual Studio.
And you think that this is normal. Your **Web api** has over a thousand end points. I don't think Facebook has that many. The definitely don't have that many in a single deployable unit. Your aggregate roots have "a few dozen end points". You're not supposed to access aggregate root sub nodes directly, that's the pattern, so if we're using the common definition of few you're talking about 36 **public** endpoints **for one entity**. You're arguing for the **S** in solid, but what about the rest of it? Your public API is huge, and despite your tiny controllers I'll bet it's tightly coupled to your implementation too.
I'm trying to have the angular 7 project on a different layer. I am trying to get CORS and XSRF protection working but something isn't clicking on the angular side.
so i saw (this)[http://666kb.com/i/e1cxn6ik422mz2q32.png] in my event log, so i looked at that link, folder was empty. looked up C:\ProgramData\Microsoft\Crypto\RSA\MachineKeys, it had [3 sys keys](http://666kb.com/i/e1cxp3s83bgd7iiz2.png) created that same time so i moved them elsewhere and restarted the cryptography services and my net is working fine again and now i'm wondering if the issue will return after i shutdown ...tools using netframeworks do trigger the cryptography services to load those keys which kill my net.....is there a way for me to "read" whats inside those .sys keys?
&gt; I don't think Facebook has that many. Go count em up some time, I'll bet there's more than you think. And why do you assume my business domain is so much less varied? Size of user base doesn't equate. Those will also be only their actually **public**, published API's. How many API's and endpoints do you imagine they have behind the scenes serving their own internal tooling? Because that's the apples-to-apples here. &gt; in a single deployable unit oh no, a single deployable unit. Yet you won't be able to elucidate a valid reason why that's a problem for my system, only theoretical points on how it might be a problem for some systems. &gt; Your aggregate roots have "a few dozen end points". Are you really going to try to convince me that you can't imagine 50 different things you might want to do to, say, an Account? Or a couple handfuls of queries you'll want over Accounts, not just GET/GET {id}? A handful of entities are used differently enough to warrant separate bounded contexts as well. Small roots also add up quickly. Take something like discounts that can be applied to accounts or products. Discounts themselves are a root. Need to be able to define what's available in the system. Every object like that is GET, GET {id}, PUT (upsert), DELETE at bare minimum, and most get another few operations or queries. I'll want to know where discounts have been used, and I'll have some operations to perform on Discounts, like initiating a marketing email or UI notification for specific accounts in the public store to inform people of a new discount, for example. 7 endpoints for Discounts without even trying, there's more. How many of those smaller objects do you suppose end up existing? 1, 2, 5, or 10, 20, 50? It doesn't have to be (and isn't) 36*36 to get past 1000. &gt; **public** The only actually public API is our partner integration with about 60 endpoints. Our public store uses about 150 endpoints. Only those 60 or so endpoints from this web api are actually public and used outside of our organization. The rest serve internal applications. What do you imagine the average ratio for, say, Angular component to HTTP endpoint is? 4:1, 2:1, 1:1, 1:2, 1:4? If your admin app had, say, 15 main menu navigation items, and maybe 150 total sub-menu items, how many components and how many endpoints would be reasonable? &gt; You're arguing for the S in solid, but what about the rest of it? I argued that the boundary layer to your user interface - ASP.Net controllers in this case - should be a dead simple pass through with no logic, and that I see no need whatsoever for just about any action method to contain a try/catch. SOLID is a set of concepts that mainly apply at a lower level of implementation than this discussion. Does Liskov substitution or interface segregation seem the slightest bit relevant here? &gt; I'll bet it's tightly coupled to your implementation too. In what way do you imagine it is difficult for me to implement a particular change due to the architecture I've described? I routinely overhaul significant sections of the application. Last week in fact I deployed a major effort reworking the majority of our accounting. Hundreds of changed files and thousands of lines of code. Reporting that got no extensions needed no changes in the UI or controllers. Our public store needed no changes whatsoever beyond adding a some fields the customers can fill out in their account. Our partner api's needed no changes. Our legacy admin app that still runs - but has been deleted from our master repo and CI/CD - continues to function as usual. Our main admin app we had no trouble re-implementing the back end and verifying functionality before proceeding to clean up and roll changes all the way up through the stack so that everything was more 1:1 and didn't carry unneeded cruft.
Yes, there are a lot of operations you might want to do on an account, that doesn't mean you write an API end point for every single one of them. Public means outside the scope of your code base, because that's where you start saying "I can't change this because I don't know what it will break". That's also why you don't write an API for every single possible operation because now if you need a slightly different logic in one app you need another API end point.
we were using an external identity provider, so there was that. but jwt cookie really wasnt that bad. the jwt was provided to us, as a query to a redirect (we used openidconnect with some hacks) , so it was either local storage or cookie. so we went with cookie. but again, tradeoffs. with questions like this of a one-stop-shop of auth questions, it's unfortunate but the best answer is "you need to evaluate your options". auth is hard. dpdapi just seems like a lot of work for gains i dont understand. maybe we could have plugged in better, but it was just easier (and no less correct) to defer to an outside (reputable) party. 
Load a project as in import the namespace with 'using' keyword? 
I was just going to ask you if you use any screen capturing tool before I read this comment lol. Thank you! 
I doubt they have a public API. There are some sniffed apis on github but nothing guarantees that its gonna work or that its not gonna break in a few weeks. What do you want to use it for?
Thanks for sharing your Valuable Opinion
Not totally sure what you are asking - I presume you are aware of the remote debugger?
I am not
Auto swipe machine. I COULD just use bash (linux is installed on my pc) to autoclick on the desktop site
No, you right click on the project and there is an option to 'Initialize Interactive with project'
I ran into this the other day (although not for SQLite). Was just getting for current directory for a custom swagger.json and it died at startup. Annoyingly this was in Azure and before any of the logging had started so actually getting to the reason for the crash was a complete pain in the arse. Thankfully looks like it's being fixed for the next release.
Use IdentityServer for the easiest 'bespoke' solution. [https://identityserver.io/](https://identityserver.io/) Or even easier...don't and use something like Auth0 [https://auth0.com/](https://auth0.com/) 
Immediate Window works the same way while debugging in the context of your actual project whenever your code is stopped. Good for when you need to run code or check expression results and don't want to use the watch window (maybe you're only checking once).
I didn't realize that was a thing. Bonus tip: If you want to load arbitrary binaries into Interactive beyond the defaults, type: `#r "path\to\dll.dll"`. You can of course omit a path if the dll is in the GAC. Then you can do using statements and start using the classes.
that was awesome, any more videos on scaling and .net performance?
Thanks!
How do you import excel files to the database? Is it via an API you are building? If so, you could examine the request from there and either enrich the rows inserted with timestamp and username, or build a different table structure, mapping each import operation with its values and their respective user/import datetime. The second option might be more cumbersome at first, but saves you much redundancy.
Warp also does something similar: https://github.com/dgiagio/warp
To answer your first question, I'm using a controller that imports excel columns directly to a specific table. As for the first part of your suggestions, I have a question; is there a book you can reference that showcases that example? Because right now I can't think of a way or function to examine my request. As for the rest of your suggestions, I get what you are saying, I've been trying to populate a new column for every row that is imported using a for loop. But because is tricky and not maintanable I was looking for a more straight forward answer, like a function.
apples and oranges
that
I'm really unclear on the objective and what the definition of username is. Is this the windows ID of the user who last modified the excel file, the user id of the user who logged into your webapps to upload the xls or what? How are the users uploading the file is fundamental here. Depending on database engine, standard dB tools might even do the trick such as SSIS.
I don't believe Mac/Linux is supported by VS in debugging so you might be SOL there. There is MonoDevelop which has been rebranded Visual Studio for Mac which I assume can debug but I do not know what its remote debugging capabilities are. If you are using vS already for a Windows server you may wish to get the client running on Windows as well to make debugging easier. There are two capabilities in VS you should be aware of. First of all, you can launch and debug multiple projects in the same solution at once. In Solution Explorer right click your solution and clkc Select Startup Projects. Then you can select Multiple Startup Projects and configure which ones you want to start. Note that this can break the Package Manager Console if you use it as it builds the single startup project to perform some operations so if you use that console you may need to switch back and forth. The second capability is the remote debugger. You can download and install the Visual Studio Remote Debugger tools on any Windows PC. While it is running (or you can use its configuration tool to run it as a service) you can use the Debug &gt; Attach to Process menu and then enter the server address to connect to processes running on the server to debug them remotely. Note that this requires your source code and latest build made with VS to exactly match the server version running to work properly. Otherwise you cannot use breakpoints or see where the execution point is in the code.
Xddd
To answer your questions; I want the user's username, which is defined in the database and is logged in the webapp. The user uploads a multipart HTML form and the database is a Microsoft SQL 2014 
This seems really weird. I don't have this issue. I have the configs: appsettings. dev.json appsettings.stg.json appsettings.json In each environment, I set the environment variable. Except for prod. I've had to make no changes and it picks up the correct file.
Check your proxy.conf.json
If the user is logged into your web app, surely you can access that user's ID and then add that to the records generated when importing the Excel file?
I will check this out thanks!
Using a for loop to fill every record line that is being send? 
If every record is for that user, yes. 
You aren't actually saving to the database inside the loop, right? Use a loop to generate the records, then after the loop, save them to the DB in one batch. Do you use Entity Framework (possibly EF Core) or something? Are you generating the SQL insert statements yourself and then executing it for every record to add? - You're really not adding much info and it's making it incredibly hard to actually help you. If you don't really know what you're doing or using, then posting code snippets will help us help you.
We do something similar. Read all the cells as strings, insert into a landing table then load and validate using stored procs. Could probably do this more gracefully using entity framework and reflection though but to be infinitely extendable, we put the heavy lifting on the database side and the UI is just dynamically driven by the structure of these landing tables.
We're reading the Excel file using EPPLUS
You should break down your logic a bit. You have to do multiple tasks. The first one is to parse the excel. Each row i bet has some columns, and each column represent a specific information. You can make a class to represent each row, let's say the class is called RowData. So your first task is to parse the excel file and create a List&lt;RowData&gt;. The second task is to identify the user from the http request. You mentioned he is logged in, so he should be authenticated and you can grab his username from the http request. The timestamp can be the moment you process the excel. Next, you have to save the data you have collected to the database. I assume you have a table with the same columns as the excel, right? You have to add the information for the user and the timestamp. A good way that i think of is to have a separate table, witch is a kind of a ledger, who uploaded what. It can have the following columns: a unique identifier for each separate excel upload, the timestamp, and the user, as you wanted. Then you can have this unique identifier in every row of your original table to have a matching between the rows uploaded and this other table. Is this clear enough? What do you use for data access to the db? You could benefit a lot from an ORM (a fully featured like EF or a mini one like Dapper) 
are you trying to use ado.net rather than EF? 
If you create your environment variables in Windows or Windows Server, this won't happen. If you've created them in IIS, this will always happen. Alternatively set these values in the environment-specific appsettings.json files and you won't run into this at all. The only thing I generally use the environment variables for is identifying the environment name(eg DEV, SIT, UAT, PROD). http://www.forbeslindesay.co.uk/post/42833119552/permanently-set-environment-variables-on-windows
As far as I am aware, web.config is never a requirement in .net core.
Can you lend any advise as to what it should be ? I'm not using the cli just webpack
If you are using VS you can generate a starter site with auth and basic management already built in. You can then use that as a base or bring the code over to your project. New Project&gt;Visual C#&gt;Web&gt;ASP.NET Web Application Pick the type of app you like and click the Change Authentication button to select the Auth template you want. If you are managing your own accounts you likely want "Individual Accounts"
Out of curiosity. What's the use case scenario here? In the real world?
Thank you for elaborating. I see others have narrowed down some methods a bit so I won't otherwise veer you off track!
Very interesting approach, thanks for posting. This [application](https://github.com/leaderanalytics/AdaptiveClient.EntityFramework.Zamagon) demonstrates how to build a scalable service layer. It demonstrates some neat dependency injection tricks you can use to make your service layer persistence and transport agnostic ([AdaptiveClient](https://github.com/leaderanalytics/adaptiveclient)). 
A web.config is required when hosting .Net Core on IIS. It won't work if it's not there. The .Net Core project itself does not need it.
Google has bunch of stuff. But this is where you proxy requests to different ports in dev server (eliminating need for cors)
So when it comes to production, do I have to change my URLs in my services ?
&gt; I understood the need to reduce the complexity of controllers. The bottom line is that a controller is like a UI in a lot of ways. It provides access to your logic, but shouldn't define it. I like to ask the 'console application' question about my controllers. In other words, how easy would it be to port by API to a console application?
https://github.com/webpack/webpack-dev-server/issues/793#issuecomment-329223834 like this?
I like that test. I think I‚Äôm gonna borrow that.
IAlthough I‚Äôm very familiar with .Net, I don‚Äôt have much knowledge of Docker. Would you mind giving a kind of ELI5 for what this project is about?
This is a great idea. 
Yes, you‚Äôll be under :4200 port while working with dev server
Cool! I have a few pieces of feedback. :) First, this is badass, and I was actually thinking about building something like this. I especially like the fluent design, since people have become so familiar with LINQ and other similar libraries. I recently built a command executer using a fluent design pattern. You can check it out here: https://github.com/twitchax/sheller. The first thing I would suggest is to get ahead of your XML docs. I know it is not super glorious work, but all of your public thingies should have complete docs. Doing it now is good for two reasons: (1) your library will feel more official to end users, and (2) you can start enforcing good docs now. Next, I would recommend turning all of your concrete implementations into interfaces and passing those around instead (e.g., the same way LINQ returns interfaces everywhere). It allows others to use your library more generically, and it ensures that your library is extensible. Lastly, and this one is definitely more work, consider returning a `new` instance upon every fluent invocation (e.g., sort of similar to LINQ [it doesn't actually return a new instance, it just modifies the enumeration, but, regardless, it does not touch the calling instance]). There are a few benefits here, but the most notable is that you can limit code reuse. For example, you could do something like this without worrying about mucking up the state of `nginx`. ```csharp var nginx = new ContainerBuilder().WithImage("nginx"); var http = nginx.WithContainerPort(80); var https = nginx.WithContainerPort(443); ``` All three of those would be separate, and distinct, instances, giving a lot more flexibility for reuse. Good work, and awesome project! :)
I just viewed this post from another account and it says "\[removed\]". I don't recall doing that.
Integration tests. You can instantiate a fresh container with an exact environment, config, db etc. and throw it all away as the test finishes.
Yea that's not gonna work unless you use some image recognition algorithm and train based on your criteria. Read about Tinder ELO
No, it doesnt need to nearly be that complicated. Just swipe right every 60 seconds to stay active and gain the most matches by maximizing the time spent online
If you are just starting out and playing around, no reason not to use 3.0 But 2.2 would likely be just fine as well.
I‚Äôm not sure how many resources out there are for 3.0 (outside of Microsoft docs, which are admittedly very good). You‚Äôll be fine either way, though. Microsoft didn‚Äôt do a massive overhaul from 2.2 to 3.0, so if you learn 2.2 you will be able to catch up quickly with 3.0.
I‚Äôd start with 2.2 if you‚Äôre learning, since most of the samples and stack overflow questions will be related to 2.x. Admittedly, I ha net cracked open the docs on 3.0 yet, and didn‚Äôt even realize it was officially released yet
It's not gonna work if you swipe right everyone. Again: look up tinder elo
From a beginners point of view, you're going to be hard-pressed to tell the difference. It doesn't really matter.
.Net Core 3.0 has C# 8 improvements, so yeah there are some new things in 3.0 that don't yet exist in 2.x
IMO index operators and default interface implementations aren't that significant to a beginner.
[removed]
I suspect the people in here that are saying there is no difference haven't built a project with ASP.NET Core 3.0 yet. Its going to be months yet before 3.0 is officially released (Fall is the last estimate I heard). You can't even download a professional or community version of an IDE with 3.0 support yet (just the enterprise preview of 2019), and VS Code doesn't have support for ASP.NET Core 3.0 yet (Omnisharp pukes over the project type). I would strongly recommend starting with 2.2 so that you don't have to conflate preview issues with any of your own confusion as a beginner, especially if you plan to build any production web app in the next 4-5 months. If you are only learning...then I'd still stick to 2.2. Most of the 3.0 features are not documented yet, and you may have to scour the github issues to find answers to common questions (Source: I made a mini ODBC REST wrapper windows service with 3.0 and had trouble finding answers to some simple things without going through github issues and blog posts from M.S. insiders, as the documentation didn't cover them yet). That said, I **would** recommend going with ASP.NET Core 3.0...**if** you are trying out Razor Components (previously known as Blazor with the server side hosted model). 
Hey...your original post got caught in the spam filter and was removed automatically. I can approve it but since it was posted a while ago, you might not get many views. If you want to delete this post and re-submit, let us know. We can approve it if it trips the spam filter again.
4200? My web api is at 5000 and my dev server is at 8080
For the record, preview releases of VS are always Enterprise version.
Nope
I just meant if they are new that they won't know which features are Enterprise vs Community/Professional and they will have to install again for the full release. It could be confusing, or at least an annoyance.
Very true
.NET is a framework(set of libraries) + runtime(Virtual Machine), C# is the language by the way
LOL asked nobody ever
3.0 is not production ready, so that already answers your question.
Yah
I know that but I want to use it with ado.net. can you clarify me that asp.net identity is new version of authentication right?and the old version is member ship provider?
Like @reasner said. As you can see in my example I start a fresh nginx and check if it's available. You can create your specific test environment, run you tests against it and throw your environment away in seconds. I use it for example for setup testing. Start a Windows container, run the MSI setup and check the logs at the end. Or start 10 containers at once and test my performance or async methods.
I still get a bad request error :(
Personally I would consider an HMAC based solution similar to how the Azure Storage &amp; S3 api works.
Also, GenericContainer pulls/starts the containers through void methods who call into asynchronous libraries without awaiting. So I guess there is no guarantee that the pull task has finished before the start task is called?
Yes, this are definitely things I‚Äôm aware of and I will improve within the next releases. I startet with a simple example to get people involved into the project. I really would like to work with a bunch of people together and learn new things. I‚Äòll add your suggestions to a GitHub issue. Thanks!
At the moment it‚Äôs guaranteed that the image is pulled. But I‚Äôm not satisfied with the implementation at all. This gonna be one of the first improvements. I also would like to keep the asynchronous behavior of the API. 
They're called accessors. 
The thing with vim is not to think of it as a bunch of commands to learn, it's a language for manipulating text. 
Thanks man! That worked! :)
Any reason you want to cache it? Is the query slow to run? Trying to reduce load on db? Is it 45KB per user or does every user use the same data? If it‚Äôs the latter, you should probably stick with server-side in-memory cache as that‚Äôs really easy and very low requirement from a server. Even if you want to scale out to multiple servers; distributed cache is an option.
Yes every user has same data.
I've had the same entity in multiple schemas. It sounds like you have different entities in different schemas for the same table though? If my guess is right then maybe make it one class ?
You mean different sql-server schemas ? no no, I only have one schema in my database and that is the default dbo schema. Let me spell out what I am doing, all my tables are of the form dbo.MyTable1, dbo.MyTable2, etc. However i have two EF DBContexts, say Context1 and Context2, and dbo.MyTable1 appears in both contexts.
Sorry im half asleep. I meant the same entity in two datacontexts... I'll double check when I can. Do you use the same class for dbo.mytable1 in both contexts? 
I think I had identical problem few years back. In my scenario I had 2 edmx in the same .cspoj with a table with identical name. It doesn't matter that these tables are in different namespaces. There are two solutions I'm aware of. 1. Hard and I don't recommend this one: Changing EDMX manualy. Pros: You can leave both context's in the same project. Cons: It's easy to break edmx and every small uprade will override your changes. You could change T4 but it's a lot of trouble. 2. Move one context to different .csproj Pros: It works :) Cons: Not aware of.
No, I used two different classes under two different namespaces. i.e. both classes were autogen when the edmx wizard creates the context. But never mind, i have even found an issue on Github, which apparently is never going to get fixed... ho hum.. pathetic. [https://github.com/aspnet/EntityFrameworkCore/issues/941](https://github.com/aspnet/EntityFrameworkCore/issues/941) &amp;#x200B;
Thank you for your reply. I am worried that no. 2. will not work because let's say i create Proj1\\Context1 Proj2\\Context2 What happens if I have Proj3 which must reference both dll's from Proj1, Proj2 ? The safest option for me is 3. Merge everything into One Big Context, which is what I tried to avoid in the the first place ! 
Here is a github issue relating to this.. [https://github.com/aspnet/EntityFramework6/issues/362](https://github.com/aspnet/EntityFramework6/issues/362)
Ah. I do code first so for me I just use the same class across contexts. Idk much about using edmx
In my opinion it's safer and easier to split this Context to different projects. Referencing Proj1 and Proj2 to Proj3 will not result in the same problem you are having right now. One BigContext is almost always a bad way to go. Remember that if you have on BigContext every change you make (Update) will result in updating entire edmx. Sepparation allows you to make specific changes without worrying about the broader context. EDMX is a hell and heaven in the same place. Your code will generate automaticly but it's hell to manage it. Code First is the safe and correct way to go but it also takes more time to create one from scratch. 
I have never used code-first because it sounds like extra manual work. Why do I have to write classes by hand, with all the props and data types, if the EDXM wizard can just generate them for you ? ( Or have i been mis-understanding code first, and you can somehow generate all classes automatically from existing tables ? )
From existing tables you can use a command in command line to auto generated. I'd make a new project though and test it first to see it's ok
I know, I explain them in the video.
Thanks for assuring me Proj1 and Proj2 idea will work. I will keep this in mind for future projects, but not the current project :-) I know BigContext is a bad idea.. and i tried to avoid it, but i hit this roadblock, and i don't want to really introduce another project (I only have 3 dbContexts in my EFLayer.csproj, and to add another EFLayer2.csproj is ugly haha). &amp;#x200B; I have never used code-first because it sounds like extra manual work. Why do I have to write classes by hand, with all the props and data types, if the EDMX wizard can just generate them for you ? ( Or have I mis-understood code first completely, and you can somehow generate all classes automatically from existing tables ? ) &amp;#x200B; \&gt;Code First is the safe and correct way to go ... Why? To me, the correct way is to design your database first, model the data / entities that your application will need, design ER diagrams with appropriate relationships, place the appropriate constraints at the server level, etc.. and then just generate the corresponding classes. For me It is much easier to visualise this with the ER diagrams, than diving into the code, ensuring it compiles, blah blah blah, etc.. don't you think ?
Who doesn't use them? They're even created for you if you double smack tab 
Why not include OData?
The GitHub issue for the problem has a fix for it: [https://github.com/aspnet/EntityFramework6/issues/362](https://github.com/aspnet/EntityFramework6/issues/362) \&gt; In case it helps, in one of the most recent minor releases of EF6.x we added annotations that can be put in entity types in the EDMX to identify the CLR type they will be mapped at runtime deterministically, which avoids scanning assemblies for all possible candidate CLR types and avoids the exception. &amp;#x200B; \&gt; The EDMX needs to be edited manually to add the annotations since the tools won't add them. For a simple model with a Person entity, the ConceptualModels section of the EDMX would look like this: &amp;#x200B; `&lt;ConceptualModels&gt;` `&lt;Schema Namespace="ConsoleApplication33"` `Alias="Self"` `annotation:UseStrongSpatialTypes="false"` `xmlns:annotation="`[`http://schemas.microsoft.com/ado/2009/02/edm/annotation`](http://schemas.microsoft.com/ado/2009/02/edm/annotation)`"` `xmlns:customannotation="`[`http://schemas.microsoft.com/ado/2013/11/edm/customannotation`](http://schemas.microsoft.com/ado/2013/11/edm/customannotation)`"` `xmlns="`[`http://schemas.microsoft.com/ado/2009/11/edm`](http://schemas.microsoft.com/ado/2009/11/edm)`"&gt;` `&lt;EntityType Name="Person"` `customannotation:ClrType="MyApp.Person, MyApp, Version=`[`1.0.0.0`](https://1.0.0.0)`, Culture=neutral, PublicKeyToken=null"&gt;` `&lt;Key&gt;` `&lt;PropertyRef Name="Id" /&gt;` `&lt;/Key&gt;` `&lt;Property Name="Id" Type="Int32" Nullable="false" annotation:StoreGeneratedPattern="Identity" /&gt;` `&lt;Property Name="Name" Type="String" MaxLength="Max" FixedLength="false" Unicode="true" /&gt;` `&lt;/EntityType&gt;` `&lt;EntityContainer Name="Town" customannotation:UseClrTypes="true"&gt;` `&lt;EntitySet Name="People" EntityType="Self.Person" /&gt;` `&lt;/EntityContainer&gt;` `&lt;/Schema&gt;` `&lt;/ConceptualModels&gt;` &amp;#x200B; \&gt; Notice in particular the customannotation:ClrType on the Person entity type and the customannotation:UseClrTypes on the entity container. It might be possible to update the powertools to do this and submit a github PR, but I won't count on Microsoft doing that work.
Not everyone knows everything, and even the basics are worth explaining to beginners. 
I saw that too.. but nowhere in my EDMX did i find a node beginning `&lt;ConceptualModels /&gt;` Under my main MyModel.edmx all I can see are sub-containers for MyModel.Context.tt, MyModel.Designer.cs, MyModel.edmx.diagram, MyModel.tt,
I agree with this - the overhead of management of the distributed cache infrastructure like Redis is probably not worth it. I do love Redis, but this sounds like minimal amounts of relatively static data. I'd use the standard .NET MemoryCache to store the data in memory and just accept the overhead of each individual machine making its own DB call. You run the risk of different machines having different data, but as you say, it's mostly static. You can set caching policies on the MemoryCache object to combat this. I'd also consider allowing the entire 1200 items be shipped to the client in one call. 45kb is not so big, assuming your users will be on decent bandwidth connections. It will simplify your front end app, and probably offer a better UX during paging operations.
*Woah!* It's your **5th Cakeday** anonveggy! ^(hug)
You need to edit the edmx as a plain text file (not in Visual Studio for instance), using something like Notepad++ Screenshot of my app's EDMX file from the TFS code editor
It's not that Code First is better that EDMX but in most cases it's better. I'll explain why to use CodeFirst after scenarios. Scenario 1: Huge database where you use most of the tables and you are short with time - go with EDMX Scenario 2: Small database (for me it's 10-20 tables) - CodeFirst Scenario 3: Huge database where you use only some tables like 10-20 from the entire database - CodeFirst My reasoning on why use CodeFirst in scenario 2 &amp; 3: * With code first you can create context with only tables (and columns) you want without uneccecary bundleware of tables that you don't use in your project. I.e. you use 2 tables in a project but entire database has 1000 tables with multiple relations you don't need. * It let's you name your objects (tables and columns) the way you want not the way DB convention forces you. Example mapping: public class MyTableConfiguration: EntityTypeConfiguration&lt;MyTable&gt; { public CostCarrierConfiguration() { ToTable("my_database_table", "mySchema").HasKey(t =&gt; t.Id); Property(t =&gt; t.Id).HasColumnName("id"); Property(t =&gt; t.Name).HasColumnName("nameofsomething"); Property(t =&gt; t.Code).HasColumnName("xadfx"); Property(t =&gt; t.IsActive).HasColumnName("Yes"); } } * It's easier to version code than database model - if database column changes name you need to update your entire edmx instead of changing the mapping. * For new solutions you create columns you need and then adjust database to your needs instead the other way around. Your new code should drive changes, not the database. * **You can start testing your application without any database in place. You could in theory finish your project and test it (UnitTest) without having a database. Moq (framework) is very useful.** There is more reasons to use CodeFirst over DatabaseFirst but these are the ones that come to mind first. 
If your focus is on learning asp.net core, I'd learn 2.2 and then migrate to 3 when it's production ready and the documentation is better. That way you're spending more time actually learning stuff, and less time trudging through issues, blogs, etc for preview level content. That said, it's not a bad idea to read about some of the stuff coming in 3 so you get an idea what to look for, but yeah, I'd start actually developing with 2.2 if your plan is to start right now.
If your focus is on learning asp.net core, I'd learn 2.2 and then migrate to 3 when it's production ready and the documentation is better. That way you're spending more time actually learning stuff, and less time trudging through issues, blogs, etc for preview level content. That said, it's not a bad idea to read about some of the stuff coming in 3 so you get an idea what to look for, but yeah, I'd start actually developing with 2.2 if your plan is to start right now.
Editing edmx is a bad idea as everything will be overriden during next edmx update. Editing TT template is the only way to persist your changes to EDMX.
Some of the graphics libraries are out of date. ImageProcessor (mine) doesn‚Äôt run on Core and Structure.Sketching is a clone of an ImageSharp alpha (also mine) that hasn‚Äôt been worked on in years. 
I'm sure I have co workers who don't know why we use them. Some people came in at a time and they were just taught to use them and they do. They don't know why. Helpful vid.
Updating EDMX doesn't touch custom annotations -- this change will be preserved. It is not possible to update this field via TT template, since it goes into the compiled form of the EDMX not one of the generated files.
Exactly, never assume, nurture. :)
Are you allowing contributions to port? 
[removed]
Start at .NET Core 2.2. Do your exercises at https://github.com/dodyg/practical-aspnetcore
mouse middle click?
You can indeed generate code first classes from an existing database very easily.
wow treasure!
I rolled a simple jwt solution with the available dptnetcore jwt libs. It seems to be the way to go at first for me.
I‚Äôm sorry I thought this was the dot net subreddit not the warhammer 40k is now reality sub reddit?
Thanks for sharing this, great collection
Same for me guys, I am confused between simplcpmmerce and nopcommerce
Adapt the code you don't like. The old identity setup is deprecated. 
This is great. Thank you!
That link says it was closed because it was already fixed in EF7 (EF Core).
Only if you pay the subscription.
Learning how to find the right information is a very important qualification to becoming a developer. Search this sub, there's some good solutions posted. On the flipside, generate the template in a dummy project and then use snippets of that code to fit your needs. The #1 rule of auth is to never role your own from scratch. I'll let you in on a secret -&gt; create a dummy asp.net core **2.0** project with auth/individual user accounts and use that code. Anything newer will use that bullshit "auth as a service" crap that the identity team is trying to force down people's throats. The 2.0 (and under) will create actual controllers and views vs the razor pages solution that's a PITA to customize.
Thanks for your input, sorry for the my late reaction, it sure did help :)
Doing that would be somewhat out of scope and not fitting with our overall architecture (the scenario I talked about is a small part of a very very large project). I am intrigued by your suggestion however, would you mind expanding on how you'd envision it?
Thanks for your input, you're right about copying the company name and such to keep it intact in case when a user would edit it and such, our company is slowly working towards a new CRM/invoice program and we want to move from SQL to MongoDB obviously because of the "hype" there has been lately &amp;#x200B; In the mean time I have been testing as well with tenants and such in mongodb and can say I tested it with 70,000 tenants, 10mil invoices (\~100 invoice lines per invoice) and it was still super fast
[SkiaSharp](https://github.com/mono/SkiaSharp) is the best for .net core, IMO.
There‚Äôs something in me that really wants to write a text adventure as a user space file system.
Judging by these questions, this is too big of a project for you. I'd advise you to spend some more time learning about the framework.
Thanks all for your advice. I will start with 2.2 it seems to be the most logical from what all has been said. 
You should do it now :-)
I had the same issue. The 2nd problem would be that not only you'd need to disable the authorize attribute, but you'd also need to be able to use a "real fake" authenticated user if you check the user's info in other parts of your application. That gets difficult too. What I did is just create a integration test user in Auth0 and used that real token in the integration test. You _could_ automate it so that for a test run starts, the token is updated. Or you just make that token valid for very long, or you replace it by hand. The more you "fake" away in an integration test, the less of a real integration test it becomes. Also, you might spend more time trying to figure out a way to solve this problem than by using a real token. ü§∑‚Äç‚ôÇÔ∏è You _could_ maybe also run the test with another configuration, so you can use compiler directives and change your dependency injection container to work differently. Also not a pretty solution. Some time ago I found a blog post by googling about allowing integration tests passing through the Authorize attribute. I can look if I can find it, but "asp net core integration test authorize" might get you a long way.
You have entered the filing cabinet. Ahead you see 15 more filing cabinets. There are 5 files on the ground. You may exit the current filing cabinet, enter one that you see, or open a file. What do you do?
Wow, thanks a lot for that little secret! I can use that code as a basis for my project! This is why I love reddit üòç
we fake the SSO by changing Authorization: Bearer token to Authorization: FAKE someEMail and we do NOT need to create a fake sso middleware we got an ‚Äússo environment name‚Äù variable that we toggle to ‚Äúprod/non prod/fake‚Äù in case of ‚Äúfake‚Äù we just inject a middleware that will create Claims on the fly based on the provided EMail if claims comes from another backend then you fake the backend so you still return the same DTO but you just map it from the EMail that‚Äôs all we have to do also this allow is to do UnitTest / IntegrationTest and e2e
For users on .net framework does the same apply for asp net core 1?
Can you elaborate? I don't quite understand how .net framework is impacted by .net core. They are two seperate SLAs.
;____)
.Net Core is .Net Core regardless if it's a web application or a console app. There's a lot of terminology issues on this subreddit where people keep thinking ASP.net Core and .Net Core are interchangeable terms. .Net Framework is not .Net Core (e.g. .Net 4.7 is .Net Framework)
[asp.net](https://asp.net) core 1 can run on .net framework. Some people were mixing the two to support old systems. With [asp.net](https://asp.net) 3+, [asp.net](https://asp.net) core will no longer support framework.
As I replied to the other user, [asp.net](https://asp.net) core currently supports .net framework. They are however soon EoLing that functionality, and as .net core 1 is released with [asp.net](https://asp.net) 1, .net core 2 with [asp.net](https://asp.net) core 2, etc, if they kill .net core 1, are they killing [asp.net](https://asp.net) core for framework users too.
did.. you just downvote me? for asking for clarification?
 No? I could take a screenshot, but that's far to easy to fabricate so no real way to prove it
[removed]
Usually when it's missing references in the build server but it works locally, 9/10 it's because the packages.config file did not get updated. When you experience timeouts are you pulling from other repos outside of nuget.org? 
I‚Äôve never had this issue on our build server using the normal windows service/agent for on premises. Wish I could add more but it doesn‚Äôt appear to be normal behavior 
Yes.
Could this be a matter of Conway's Law: use an architecture that best fits your shop's team structure?
Ah ok haha, must be someone else then :p Cheers!
Every "rule" of software development should be tempered, or weighed against all the other rules. Over-emphasizing a single or a handful of rules above the others creates more problems then solutions. And don't forget Keep It Simple. If the latest architectural craze is complicating things and the benefits are slow to flow, hit the brakes. It takes experience and project reviews to learn when and where to temper.
&gt; .NET Core 1.0 and 1.1 will reach End of Life on June 27, 2019 ? .NET Core 1.0, 1.1 and 2.1 are LTS releases. Let me get this straight: LTS releases are only supported for 3 years?
I had some issues with budget failing to connect through a proxy server. The solution was updating the build agent's version of nuget.exe to 5.0 preview 3.
Node LTS is 18 months. Ubuntu desktop is 3 years. Ubuntu server is 5 years. Firefox is 1 year. Java is 4 years. Wikipedia is telling me that 3 years is more like the average than the minimum for application frameworks. Longer for kernels and OS.
I've seen nuget issues where a solution references a project that is also used in another solution - if that common project has nuget references sometimes the build server doesn't restore the packages to the relative location expected by the project.
Out of these which ones do you guys rate as being good packages? I like fluentvalidation I'm looking for a tool or package that can create all the code first mappings for ef core. Keys, relationships and column types, it's tedious doing this manually and I'm not a fan of writing code first then doing migrations on an existing dB. 
Sry but I strongly disagree. If everyone thought like you we would be still living in the stone age. But if you really believe that then what could be a great contribution is giving some guidance not just a vague useless comment 
Just had a quick Google around this, and found two interesting comments on a pretty large chain expressing the same kind of issue. Apologies if you already found this! https://github.com/aspnet/Docs/issues/6882#issuecomment-444263349 https://github.com/aspnet/Docs/issues/6882#issuecomment-452394528 Seems like it is possible to add in both custom Claims and just override the authorisation when setting up a test. Hope that helps!
Fucking hell they need better names for this 
Dude, you‚Äôre asking absolute beginner questions. I wouldn‚Äôt expect you to be able to build anything with the level of knowledge you are displaying. This is not meant to be offensive, it‚Äôs just reality that you need to get a lot better before you‚Äôll be able to accomplish anything that isn‚Äôt a half baked solution.
Subscription? ImageProcessor is Apache 2.0
You can do what you like but I wouldn't bother. ImageProcessor is a pretty old library with many architectural flaws. There's better alternatives. 
Did you have any luck finding it? :)
They probably saw how they've had to support Classic ASP for another 10 years after Windows 8 and thought that implementing proper EOL standards is the best way to go.
Question about Serilog: does it work with old Asp.net Webforms web application? I‚Äôm studying options to replace the custom made/too simple logging lib used in an older app and heard good things about Serilog. But for some reason it is not working from the examples I‚Äôve tried.
No.
Ok. Thanks anyway.
9. I wouldn‚Äôt. I wouldn‚Äôt target anyone specifically. As for developers, I‚Äôd let the specifications and features do the talking. Zero marketing talk. Zero bullshit. ‚ÄúThis is what we have.‚Äù 10. Something that is direct in its message about what you‚Äôre selling and what price. And something that isn‚Äôt emailed at me or in any way specifically for me. Anyone who sends me email about any product or service gets off with the wrong foot with me, especially it it‚Äôs in marketese. 
Not all marketing is about selling. Some initiatives is just to keep you updated on general industry info, and create a relationship with you. But I understand where you're coming from and I completely support it. You're not getting those things from me. My questions here rely upon do you allow yourself to be measured online and, what are your major sources of information. :)
Could you give an example of this industry info that marketing would keep me updated on? I can‚Äôt really think of any examples myself. As for relationship, why would I want to have one with marketing/the instance this marketing is representing? I can‚Äôt really not be measured online considering basically everything is monitoring everything we do. If I‚Äôm asked if I allow it I don‚Äôt. As for information, that depends on what information. Usually the site that talks about the thing I‚Äôm interested in, meaning manufacturer or provider. As for cloud providers, I don‚Äôt use any of those so can‚Äôt say anything about them. 
&gt; Could you give an example of this industry info that marketing would keep me updated on? Sure, so something along providing documentation for things you may need in your industry such as how to prototype your first cloud-connected IoT project, free eBooks that may interest you, best practices for containers, etc. &amp;#x200B; &gt; As for relationship, why would I want to have one with marketing/the instance this marketing is representing? Say you're already using our services, of course you can always google what you're looking for, but we can direct you to the best sources of information and documentation regarding your situation, and start providing additional documentation preempting your needs. This is simply to create a good relationship and make sure you're perfectly aware of how to use your product and if not, we're to do the best we can to help you out. In turn, hopefully, you'll have a good opinion of us. :) &amp;#x200B; &gt; I can‚Äôt really not be measured online considering basically everything is monitoring everything we do. If I‚Äôm asked if I allow it I don‚Äôt. An answer I received was someone who used a Pi-Hole to avoid tracking. Another just used Adblockers. Maybe you use NoScript or similar? &amp;#x200B; &gt; As for information, that depends on what information. Usually the site that talks about the thing I‚Äôm interested in, meaning manufacturer or provider. So you go directly to the source and nothing else? Is there any person or publication you follow to keep you on top of subjects from your field? &amp;#x200B; &gt; As for cloud providers, I don‚Äôt use any of those so can‚Äôt say anything about them. Does your company have its own cloud solution or you have no need for the services? How about for personal projects, do you have a personal preference? (Please note I'm trying hard to not mention the company I work in, or lean in any direction, because I'm asking this on a personal note, and I'm not trying to market here or anything, I really just want genuine answers) &amp;#x200B;
We've never had issues like this. We have had issues with the older version of nuget that TFS runs, but you can add steps to download nuget to your buildbinaries and run it from there for an updated nuget. This sounds like something wrong with the machine that the build agents are configured on. Maybe try setting up another build agent on another machine with VS Build Tools installed to see if you can do it successfully.
This post is an advertisement. 
I still don't understand why would his example deadlock? If there are threads available it shouldn't deadlock every time.
\^
How to conduct a survey: 1. Go to a survey website. 2. Build the survey. 3. Post it.
Surveys are about statistics and getting a big sample of answers. I'm looking to start a conversation with anyone willing to engage me on it. &amp;#x200B; Would you like to choose a topic?
You're firing off a list of (mostly irrelevant) questions. That's a survey, dude. &gt; Would you like to choose a topic? Not with you, since you apparently aren't a dev and can't program.
&gt; You're firing off a list of (mostly irrelevant) questions I'm pretty sure that's subjective. They can be irrelevant for you, and that's fine, but they're not irrelevant for me, otherwise I wouldn't be asking. &amp;#x200B; &gt; you apparently aren't a dev and can't program. I said as much in my intro. And that is the reason I'm asking the questions. &amp;#x200B; But I'll gladly share information regarding my field, if you're interested in it.
Nah, not interested in marketing. It's why I'm a dev and not a marketer.
&gt; Nah, not interested in marketing. It's why I'm a dev and not a marketer. That's fair, don't want to bore you with unnecessary information. Although I'm a marketer interested in dev, so they're not mutually exclusive. :) &amp;#x200B; &gt; Good luck with your survey. Thanks, it's more research, but don't want to bore you with marketing technicalities. :) &amp;#x200B;
The await causes the synchronization context to be pushed onto the stack. Normally when the awaited function completes (kind of like the task reports completion back to the main thread via a callback) the main thread would restore this context and resume execution where it left off. The problem is the main thread is blocked because it is explicitly waiting on the __Result__ of the GetAll() method, which it can't provide yet. Because the main thread is blocked waiting on the result, it can't acknowledge and process the callback from the awaited function and restore the context. Clear as mud?
It's not an issue of threads, but of context. The synchronous block on the original context is holding the context, not allowing anything else to use that context until the block is released, but the block cannot be released because the async code that wants to complete, requires that context in order to complete. Not only does sync code block threads, but it also blocks contexts.
The TPL treats a continuation as a next part of execution so it waits to become available. However, the blocking call to .Result means it will never become available. An unavailable context means the .Result is never satisfied so it will never proceed.
Many companies are starting to realize the marketing to developers is 100% different than the typical market. There's a whole new field called Developer Advocates. Basically, devs are so cynical and weary of typical sales and marketing that companies are building teams of developers who build stuff, speak at conferences, write technical articles, etc. that don't "sell" their product but simply help developers learn, improve, etc. You did hint at this, but I think the survey here is actually an example of a traditional approach :( - not to be mean, but hopefully helpful :) By interacting with devs and building real relationships that can then expose the product to developers in a non-traditional way that seems to work. So a huge part of it is being a developer and therefore already knowing the answers to these questions, and then simply building relationships with real developers and helping them. Some dev rel (Developer relations) strategies also involves building relationships with influences in your target market. The help is replicated, in general, and if your product is *actually* useful then these influencers can be a springboard to reach a larger audience organically. 
I am surprised no one mentioned service fabric
I couldn't have said it better myself. &amp;#x200B; &gt; Many companies are starting to realize that marketing to developers is 100% different than the typical market. I agree with you completely, and that's why I think the research that's going to be made by the conventional team is not going to be complete for me (thus this research). &amp;#x200B; &gt; There's a whole new field called Developer Relations / Dev. Advocates. I'm more or less on this field, but in a more general sense (from what I've gathered so far). &amp;#x200B; &gt; Basically, devs are so cynical and weary of typical sales and marketing that companies are building teams of (real) developers who build stuff, speak at conferences, write technical articles, etc. that don't "sell" their product but simply help developers learn, improve, etc. Right, and this seems like the best approach as it's less intrusive, would you agree? &amp;#x200B; &gt; You did hint at this, but I think the survey here is actually an example of a traditional approach. Not to be mean, but hopefully helpful :) It is, but I'm working the opposite way. I believe most of the answers will be negative, but it corroborates what I state in first block of this reply. I can then go back and say "we cannot use traditional measuring methods for this audience, because they're not the same". My personal opinion on the matter is most devs stick to the tried and true sources (StackExchange, Google, etc.), do not use social networks at all, do not allow themselves to be tracked online and absolutely hate marketing ploys. The reason for this last one is because it usually deters or at least adds a step to the end goal. I'm only a power user, but this is how identify myself as well. Or maybe I didn't quite understand where you were getting at. &amp;#x200B; &gt;By interacting with devs and building real relationships that can then expose the product to developers in a non-traditional - this seems to work. &gt; &gt;So a huge part of it is being a developer and therefore already knowing the answers to these questions, and then simply building relationships with real developers and helping them.Some dev rel (Developer relations) strategies also involves building relationships with influences in your target market. The help is reflected back, in general, and if your product is *actually* useful then these influencers can be a springboard to reach a larger audience organically. Agree 100%. You should've applied for this job. :) Any influencers you'd like to mention? &amp;#x200B; I've already had a couple of responses (not as many as I'd like), and although they've been insighful, this is the best answer I've gotten so far. Thank you very much. :)
In my experience, sql server temporal tables have been gods gift to history tracking. I believe its only available on sql server 2016 and newer. Ive been yet to find any other solution that comes even close. 
Just a guess, do with it what you want: overload SaveChanges and Use the ChangeTracker of EF. i do not know if this can compare old and new, but tracking changes is what you want cuz then you can log it. If you can't compare old and new, you can technically first retrieve the entity you will change and somehow use that with the ChangeTracker before calling SaveChanges. You can just use system time for the current time and save that and log it. Otherwise, if you use CQRS, you could have an Audit trail command handler decorator that creates an Audit object from the command, the user, the current time, etc. Each audit object would be a new state of the application and thus you _could_ compare the difference in states.
So it‚Äôs a solution with multiple projects. The one causing the issues is the project that I updated the target version. I also updated a couple nuget packages, which created a different issue entirely. So atm the only thing that changed is the target version, but it created a huge amount of package reference conflicts in the build. Appears to be losing track of the DLLs for all of the references. :/ 
This is a good article explaining the feature. I don't mind that C#8 is getting this feature, but it does beg the question: If you're on .NET Core (because .NET Framework won't get this feature), should you ever use abstract classes? With default implementations for interfaces, they can now do _almost_ everything abstract classes can do, except you can inherit multiple interfaces and you cannot extend multiple classes. The only thing abstract classes allow you to do is set the maximum protection level of a method, so for example if you have `protected Foo()`, then a subclass cannot expose it as `public Foo()`. Will you guys start defaulting to interfaces with default implementations instead of abstract classes once this lands?
@twitchax FYI: I updated the repository and added some of you suggestions, thanks a lot!
Other database are starting to offer this as well. I think many of them call it "system versions tables" or something like that. 
I hate the idea. &amp;#x200B; Make a base class that implements the methods. That is your default.
&gt; I wouldn‚Äôt. I wouldn‚Äôt target anyone specifically. As for developers, I‚Äôd let the specifications and features do the talking. Zero marketing talk. Zero bullshit. ‚ÄúThis is what we have.‚Äù If you are a business whose tech targets developers, this isn't a very good strategy.
To clarify.. When you say pass the request off the a queue running in a microservice, this is how I see it: The microservice is a separately hosted webservice that has at least two methods: GetDataAndCache(parameters) GetCachedData() Behind GetDataAndCache is a queue to which the request gets added, and thus our MVC controller doesn't have to worry about it anymore. Then the GetCachedData method will return the cached data if it has been fetched and is not expired. &amp;#x200B; Does that sound about right? I'm not too familiar with the concept of microservices (although ofcourse I've seen it thrown around a lot)
Multiple inheritance has its uses.
Yeah, I can see where this will cause some unmanageable spaghetti to happen. The idea of an abstract class implementing the interface and providing default implementations sounds a lot better to me.
If I understand the argument, we have to do it because C-sharp's reflection is too limited to retrieve variable names. So if Microsoft fixes reflexion, we could toss them. I understand if one wants to programmatically control the setting and getting, accessors are needed, but one could wait until an *actual* need arises before accessor-itizing a given field rather than pre-accessor-tize everthing, since it's only needed roughly 2% of the time. &amp;#x200B; &amp;#x200B;
That‚Äôs cool, when did you join the team? Are you in Redmond by chance?
Auto-bloat is still bloat. Less code is a better solution if it can be achieved without side-effects.
There is a lot of fear of this issue, but I could see how it will be useful when you want to share a bit of implementation between implementing classes, but not a hierarchy (which in the OOP world is *supposed* to require quite a few constraints if you follow SOLID). 
Not a huge fan. If your interface method is being re-implemented the same way 10-20 times, then you could probably argue that it should be extracted into it's own specific interface/class set.
I joined and moved to Redmond in Nov last year, but I'd been working remotely for a couple of years
By less "intrusive" I think I should say really "less direct". A survey is not bad, but most devs would prolly just not care. Less direct would be more like finding what problems or tech devs are struggling with (research them on reddit, etc.) and helping them solve those technical problems. Influencers really depend on the market you're in. You need to know what niche you are targeting (desktop .NET devs, web nodejs devs, etc.). Just targeting devs in general is too broad... As far as convincing your company: check out Mary Thengvall - she answers this exact issue here: https://pages.vanillaforums.com/value-developer-relations-webinar
wouldn't every call like that deadlock? Im not getting it in either asp.net nor wpf applications while using .Result
I'm excited for this because I differentiate between interfaces and base classes with the thinking "has-a" vs. "is-a".
If you use azure sql, you can create as many DBS as you like! And scale.
Is it an enterprise product or a consumer app? Single DB + tenantID greatly simplifies deployment, especially if you're using some kind of CI/CD tool. &amp;#x200B; However, many large enterprises like to have control over when new features are released to employees, so having the flexibility to delay a release can be useful. To simplify things you'll still want to automate deploys. We're moving our home-built deployment tool to Octopus and so far it's been pretty solid.
Why not just have multiple inheritance? 
It's just a relatively small thing. I made it in my previous job to manage some things and it was really useful so my idea is to recreate it and sell it on! But it'll mostly be targeting small-medium companies and only in the UK to start out 
Interfaces also can't have state e.g. no fields.
Abstract classes also allow you to define base constructors. So that's one reason to still keep using abstract classes
I did this using reflection in one of my many attempts at change tracking and the performance was awful but it did work pretty seamlessly once it was created
Why do you hate the idea? Any default methods that an interface implements, given that they have no state, must rely contextually on the contract that they represent. If you do a lot of work with interfaces, and abstract classes that have to do the lifting where a certain % is all the same, you can do away with some of the boilerplate code. I agree that it's not going to be used as \*often\*, but I'm interested why you hate it, and why you think abstract classes are a better way?
Because it's hell, most likely.
yes and no. They can have properties (and in many cases assume autoimplemented properties) that they can interact with. 
`Composition over Inheritance.` gets hammered again and again. Default Interface Methods makes composition easier to achieve without creating a crap-ton of boilerplate code. 
It's great, until that generalised abstract base-class isn't good enough and/or, you want to add something to the interface. Remember that providing default implementations in an interface can't break the contract, as it can still only expose it's functionality based on the contract the interface originally provided. This means that you can add additional functionality, without breaking any contracts. Most of the time - I agree, you're not going to need this feature, but it's a welcome addition. I think a lot of C# programmers don't get involved in heavily-generalised code (not an insult!) and therefore don't often come across edge-cases where this may be useful.
Just put it in one database with tenantid. If you ever need to migrate a big client to their own instance it's trivial to get their data out as long as every table has tenantId. It makes deployment and tuning a lot easier. 
What is so interesting to me about this is that you can use this to define collections of implemented behaviors and build classes off those prebuilt collections. You can string together multiple collections of behaviors into classes by just implementing them all as interfaces. Say for example I want logging behavior for 100 or so of my classes and perhaps that logging behavior is complex and does all sorts of things. I can implement that once as a default behavior on an interface and plug that interface into all the classes I want it on even if they are extending another class. And I could do this with dozens of other behaviors and implement all those on as many classes as I like very quickly with just a colon or a comma and the name. Basically all the benefits of multiple inheritance without the drawbacks; if I have multiple interfaces that define the same behavior on a class then I simply have to define the behavior myself on that class or it won't compile.
I think the entire idea of introducing this feature to allow changes to interfaces that would previously be breaking changes is wrong-headed. * By definition, the default implementation can be done with nothing but other members of the interface. Thus, this is nothing that couldn't be done in an Extension Method that would leave the calling code *exactly the same*. (If you have rights to edit the interface definition, then you have rights to add the extension method in the same namespace.) * If the Interface is growing because of a fundamental new aspect of the interface with attached behavior, then *that should be a breaking change*. * If the new addition to the interface is not a fundamental aspect of the original interface, then it should be in a new interface that inherits from the old one. Interfaces are not just a way around the lack of multiple inheritance. They are contracts. Changing those contracts *should* be a breaking change.
&gt;They are contracts. Changing those contracts should be a breaking change. &amp;#x200B; I'd like to focus on this point particularly. I believe that this feature \*isn't changing the contract\*, and therefore isn't a breaking change. These default implementations don't get magic from somewhere that is confusing, they can only operate on the contract they're already a part of. The contract that originally existed, still exists. I still think it will have niche use, but in heavy-generalised development, it may find it's niche. I completely agree with you, that if the interface is growing because of the behaviour changing - then it should be a new interface (because a behavioural change would probably be a contractual change). As for your (very valid) point about extension methods, remember that there is no such syntactic sugar for extension properties. Whether that is an issue to you or not is entirely up to you.
They provide absolutely nothing you couldn't get from extension methods. 1) Declare `IInterface2` as a descendant of `IInterface1` with the new method. 2) Create an extension method on `IInterface1` that implements the new method. The code looks 100% identical to the callers. Unless you have StyleCop rules preventing doing it in the same file, it's almost exactly the same amount of code.
Think I mentioned it in my other reply to you, that this works fine with methods, but not with properties :) 
I would recommend _starting_ with a `TenantID` and making things logically separated, and being able to shard your tenants into databases that fit specific ilks together (e.g. "small" tenants in one DB, "large" tenants get their own DB, etc). This can always easily change to "One tenant per DB", but allows you to do that in the future if you'd like without a ton of extra work right now.
I think abstract classes still have their place for 99% of cases. These "default implementations" in interfaces will have their use, and I look forward to seeing their uses.
&gt; As for your (very valid) point about extension methods, remember that there is no such syntactic sugar for extension properties. Whether that is an issue to you or not is entirely up to you. And putting a default implementation of state manipulation in an interface is a *fucking terrible idea* and there shouldn't be default implementations of properties, either. &gt; I believe that this feature *isn't changing the contract*, and therefore isn't a breaking change. These default implementations don't get magic from somewhere that is confusing, they can only operate on the contract they're already a part of. The contract that originally existed, still exists. At the risk of drawing a bad real-world analogy, would you tolerate if a business partner just started adding things to a contract you had previously signed and said, "don't worry, it doesn't affect you, trust me"?
Most people think of "has a" as composition vs. "is a" as inheritance. I would imagine if you used "has a" to mean that your class implements an interface in a conversation, the other parties involved would be confused. https://en.wikipedia.org/wiki/Has-a https://en.wikipedia.org/wiki/Is-a
\&gt; And putting a default implementation of state manipulation in an interface is a *fucking terrible idea* and there shouldn't be default implementations of properties, either. Wouldn't the default implementation with our abstract base-class also do this? \&gt; At the risk of drawing a bad real-world analogy, would you tolerate if a business partner just started adding things to a contract you had previously signed and said, "don't worry, it doesn't affect you, trust me"? Same here really. I understand what you're getting at, but if we define an interface, then an abstract base-class that the world and his wife inherit and use - we're at the same risk. Now consider this, if we define an interface and have an abstract base-class implement that interface - it fulfils the contract, but can do anything it wants above and beyond the initial contract. Then you have a whole bunch of stuff that uses this boilerplate code. Given your real-world analogy, a default implementation \*cannot\* break the contract (it only has access to the contract it has), but an abstract base class (and therefore future implementations) may adhere to the contract, but do whatever they want. Given your "bad" real-world analogy (I actually don't think it was a bad analogy), to me the default implementation is just making an existing contract easier reading. The contract hasn't been changed. Apologies if none of the above makes sense, kinda tired, but am enjoying the discussion :) 
 \&gt; I would imagine if you used "has a" to mean that your class implements an interface in a conversation, the other parties involved would be confused. You think they would? That is exactly what I would expect it to mean.
&gt;Most people think of "has a" as composition vs. "is a" as inheritance. I would imagine if you used "has a" to mean that your class implements an interface in a conversation, the other parties involved would be confused. You think other people would be confused? That is exactly what I would mean by saying it.
[removed]
[removed]
ü§¢ü§Æ
The only question you need to ask yourself is if the functionality needs to be available across multiple inheritance chains. If it does then use an interface with a default method. If the functionality is specific a single class inheritance chain then use an abstract class.
SOLID and Unit testing, learn to build low complexity components its fundamental if you want to become a happy dotnet developer.
Think resp. read up on loose coupling and dependency injection, interfaces, generics and unit testing. That is what you will.be confronted with if the code base is any good. 
I assume you know the basics of CS. Visual Studio is an important part of developing in .NET quickly and effectively. If you don't use its features you're tying your hands behind your back. I've seen more than one junior developer try to code from text editors and fall behind on sprints, creating bottlenecks. You may be able to get away with this more if you're doing Javascript based front end development but you won't if you're developing middleware or backend components. Work yourself into the cadence of your team. If the team is using Agile sprints they should assign you some learning spikes and a mentor to bring you up to speed. If they don't, I'd be worried. Ask questions. Use face-to-face, Slack or whatever the team is using. Don't be afraid to ask but try to retain what you're told. Take notes, photo whiteboard sessions and so forth to keep you on track.
Doesn't this make interfaces more akin to Scala traits?
Email whoever interviewed you (e.g., your future boss) and ask the same question.
On your commute to and from your work listen to podcasts like https://www.codingblocks.net and https://www.dotnetrocks.com This will help you put the things that you read or hear in the right context. Also the S.O.L.I.D. design principles and dependency injection are very important to learn. Also the G.R.A.S.P. patterns will help you make the right choices.
I have run into a few cases where default interface implementations would have helped me in that moment. Although, I don't think I would advocate designing around them. I would probably only use them to avoid the 'breaking change' issues this article says they are meant to solve. 
There's pros and cons to it. Used carefully, it's extremely useful. But most developers are about as careful as a tree mulcher (primarily me). I do like how Python resolves multiple inheritance and I've used it for monkey patching to do some dumb shit in tests (check that the action defined for a permission defined in a controller had both actually has that action - since it's just a string name - and the permission has a definition - because the permission name is also just a string). As well as adding middleware to requests' http client (you only get one hook and adding a decorator class is more trouble than it's worth). But neither of those are compelling examples for including it in C#, in fact they're probably good arguments against it. But part of python is sometimes taking a square peg and getting it into a round hole without changing the hole.
Only if you don't plan 5 minutes ahead. I've been working in C++ for 7 years now and have encountered the so-called "diamond of death" only once or twice. In every case, it was solved by a simple 10 minute refactor.
Sorry, I meant to say: it's hell to implement by thr compiler team.
That's completely fair.
Yeah but properties is just sugar for methods. 
&gt; By definition, the default implementation can be done with nothing but other members of the interface. Thus, this is nothing that couldn‚Äôt be done in an Extension Method that would leave the calling code exactly the same. The main difference is that an interface method, default implemented or not, is virtual and thus has dynamic dispatch. This isn‚Äôt the case for extension methods. Default interface methods are used a lot in the core libraries for Swift, for instance for what is LINQ in C#/.net. 
Dynamic dispatch. 
This will save me so much headache. Whenever I add a new interface method, bam dozens of services using my library break because they don't implement the interface. Now it's no biggie.
The problem is that C#, for perfectly sane reasons, doesn't allow multiple inheritance, but there are circumstances where multiple inheritance is the appropriate solution to a problem. I feel very mixed about this feature. On the one hand my gut reaction to this is that I hate it, but on the other I understand why they're doing it and I don't have a better solution to the problem, and it is a real problem. If I'm honest I also just really can't see how, aside from making me uncomfortable, this will actually create new problems, aside from people not knowing it exists and not understanding code. 
IMO discoverability is something. My main issue with extension methods is that generally the consumer has to know they exist to find them. They may be in an entirely different namespace than the interface itself. In fact, this is more common than not. Default interface implementations, on the other hand, are ‚Äúvisible‚Äù in any scope the interface itself is.
An interface is just that. Should be nothing more. I'd rather have my compiler tell me that I have an error because I didn't implement the code instead of some default implementation which could cause run time issues
If you've never covered it before, have a quick look at some of the recent popular design patterns so you can at least identify them. https://www.developerfusion.com/article/8307/aspnet-patterns-every-developer-should-know/ If it's a Microsoft only environment, I would probably consider freshening up on SQL as most MS shops use SQL server. 
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/latexandloaf] [Building Microservices On .NET Core ‚Äì Part 3 Service Discovery with Eureka](https://www.reddit.com/r/LatexAndLoaf/comments/asvowt/building_microservices_on_net_core_part_3_service/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
If you have edit permission to the interface to add a default implementation, then you have edit permission to put your extension method in the same namespace.
A person ‚Äúhas a‚Äù leg...Joe inherits leg from person because joe is a person. Joe ‚Äúis a‚Äù lawyer, ‚Äúis a‚Äù father, ‚Äúis a‚Äù little league coach....he implements those interfaces. 
&gt; Wouldn't the default implementation with our abstract base-class also do this? Yes, but only for classes that inherit from that class for their implementations. Abstract base classes are *for* sharing implementation. Extension methods (i.e. static methods on static classes) provide the same purity of interface-based-only implementation. ABCs are for doing it in a polymorphic way with class inheritance. Different things. And I want to keep ABCs out of this discussion, really. Interface-immediately-implemented-by-an-ABC is just one design pattern that uses interfaces, but interfaces can exist without any canonical ABC implementation. There is no one root ABC for IComparables. &gt; Given your real-world analogy, a default implementation *cannot* break the contract It's not the default implementation breaking the contract, it's the fact that you're using the feature of default implementation to allow what would be a breaking change to the contract.
That is a good point, but relying on dynamic dispatch for methods defined in an interface seems to be blurring the line between interfaces and classes too much.
Yep and read anything by Uncle Bob (Clean Code/Refactoring) to at least get used to seeing the common patterns in production level code. And just to reiterate what /u/CarpeTecno stated Unit Testing/Integration.
Thanks. I juxtaposed the terms in my head.
I shall definitely look into this, thanks.
The Midwest has tons of .Net job openings. If you don't live here and are willing to relocate, there are jobs for the taking. If you live here basically everywhere will hire a competent .Net dev. 
Dynamic dispatch is pretty much how interfaces work, though. A method receiving an interface doesn‚Äôt know what type the object implementing it has, so it must use (a variant of) a virtual method call to invoke methods. The alternative is to provide the compiler with enough information to make direct calls, by making all methods that accept interfaces be generic. This is an approach used a lot in Swift as well, since interfaces (called protocols there) can often not be used as types of variables or parameters, unlike in C#.
It doesn‚Äôt have compatibility. The 2.2 NuGet package shows it requires &gt;= to 2.2. The 2.1 package shows it requires &gt;=2.1 &lt; 2.2. They kind of correspond to the .NET Core version so keep them in check. Update the package or downgrade the version of .NET Core in that project.
There are also cases when you feel you need to add convenience method, but adding it to interface is a burden for implementers, and extensions are not overridable. 
It kinda works in this example. Look how Linq's First() is implemented. https://referencesource.microsoft.com/#System.Core/System/Linq/Enumerable.cs,bc8ae402a61dd9d6 They check if IInterface1 implements IInterface2 and call that. That's a bit hacky way of doing stuff, but it works "dynamically". 
Yeah, I am aware. Most LINQ methods do this, almost always in order to get away from the weak enumerables and into the stronger collection.
Apparently it was nothing of the sort lol...I took a step back and looked at it like the Pro IT guy am. I ended up uninstalling the 2.2 SDK, installed 2.1 SDK that worked. On a hunch reinstalled 2.2. Tried to make a 2.1 project and it worked. Installed the 2.0 SDK. And it worked as well. &amp;#x200B; What was odd is when I tried to install 2.0 and 2.1 earlier after I had 2.2 installed the installer opened up in the Repair/Uninstall mode. Go figure....All seems ok now. Appreciate the response. &amp;#x200B;
I get the aversion to changing what an interface is, but what run time issue is this actually going to cause? If you implement all methods your version gets called, if you don't the default is. The implementation of the default interface can change, but that's true of literally any third party code you have. Changing the core definition of a concept is a big deal from a cognitive load perspective, and it feels icky, but I can't actually see how it creates new problems. 
&gt; I've seen more than one junior developer try to code from text editors Are you serious? Jesus christ
Ya, but what job board? I'm looking to post jobs.
I was a contractor at the time, brought in to help clean up the mess. It was the typical "Mythical Man Month" mistake of bringing more people into a failing project. The original team of contract developers they had hired were all junior and had no .NET experience, only Java. I assume they got them cheap. The lead developer, a company employee, was decent but overwhelmed. I was there about 3 months, trying to get things to work, before upper management pulled the plug. Very frustrating experience but it paid the bills.
Damn what a nightmare indeed! 
I get lots of Node.exe processes when debugging my SPA in vscode. It's a pain.
Or Jet Brain‚Äôs Rider. Many places are switching over, due to MS‚Äôs insane licensing fees for VS. 
I'm so excited to see .NET turn more Unix-y. I was about ready to jump ship forever. Which I guess is why Microsoft pushed .NET Core.
Git
There is "feature capability" and there is "how you use it". You can write very ugly and convoluted code in almost any language. Just because you "can" doesn't imply you "should". As always, I expect good practices and guidelines will follow from experience. The feature does add a lot of ease for some use cases (e.g. traits). But you don't have to use it if you don't line it. The most important aspect is that it doesn't break your existing code.
Why require two constructs when one can suffice with this feature? 80% of the time if I have to make a base/abstract class just to implement one piece of logic that will in practice rarely be different if ever, and can also be defined using the rest of the contract (consider simple helper functions), then also having to define an interface isn't helping me at all, it's just an extra piece of bloat in my code. Patching things up with extension methods spreads things out in a way that can be less intuitive to maintain. This gives interfaces you define more potential to be useful and keep things concise. On the other hand, the breaking-change-aversion "benefit" described in the article is pretty useless to me and a terrible thing to list as a primary selling point. It seems pretty harmless though; your analogy takes the word contract a bit too literally. I think the idea of the "contract" you're concerned about it still in tact, the contract is an expectation of implementing classes, not of the interface itself. The contract dictates a class will implement certain requests, but now the contract writer doesn't have to force the class to figure out everything on its own. It also can't force the implementer to do anything it wasn't before. Rather, I don't see it really being a terribly different scenario than linking to upgraded code that has behavior changes (non-code contract changes) and assuming everything's fine--something to be careful about regardless of the features of the language.
Honestly I‚Äôm seeing a lot of micro service structures with events. Some of the principles include not writing unit and integration tests. Pretty insane stuff.
Good advice all around in this thread. However, I'm going to touch on something that isn't coding related and will help you immensely in your career. **Don't be a douchebag and treat non-technical people who ask the same dumbass questions over and over again with respect.**
404 on Run the command git clone
Linq and async/await are good things to know about. 
To add my own to the mix, ask your team lead before downloading / using 3rd party software. My company pays for 3rd party libraries, and novices will often download nugets that they used in college. There is more to getting the job done, you need to be a team. 
I assume they mean something like sublime text or vscode? (Hopefully)
Great advice. I would also add that you make sure to communicate any issues you encounter early that put your project plan at risk, so that others can be prepared if you wind up missing a deadline. No one wants to hear that you‚Äôre held up on something that could of been resolved days ago. Also, this is some general advice for anyone working a shared project: -Know where you‚Äôre at on your assignment and be ready at any moment to give a quick status to your lead/manager. -If you‚Äôre held up on a task, know what‚Äôs holding you up and what current actions are being taken to remove the roadblock. -Always elevate issues early (when applicable). That way your lead can start helping to remove the roadblock before you‚Äôre stuck and can‚Äôt proceed any further. These are traits that aren‚Äôt easily learned, but if you can master them you will make your work life much easier and less stressful.
Be honest in what you don‚Äôt know and ask a lot of questions. Say thank you when someone helps you. You should be willing to be wrong. You should be willing to be right. Read the existing code base and find parts that you don‚Äôt understand why something was implemented. Find a good mentor! Seriously - ask questions and admit when you don‚Äôt understand things. 
How popular is Azure Devops?
Spam
Yeah! Respecting others is for douches! 
Although this is not .NET specific, but whenever you hit into problems you can try to solve it yourself at first , but if you are struggling, don't just sweat over it for a day but go and ask for help from your colleagues. Also, always go and ask for/take a new task whenever you are finished. Be proactive! 
This is another sample to show how the boundary between frontend and backend is essentially erased https://github.com/dodyg/practical-aspnetcore/tree/master/projects/3-0/razor-component/service-rss
Your post has been removed. Self promotion posts are not allowed.
I got same problem. Is there a way to rename processes when starting them?
Definitely. Had so many issues moving to the next environment. Docker is looking very appealing 
If they want my business, it is. And I‚Äôve noticed lots of others also want clear information, no marketese, and no direct communication without us initiating it first. Why do you think that‚Äôs not what works?
I don‚Äôt really see it as marketing if someone writes tutorials etc. And personally I wouldn‚Äôt want to be contacted about such things anyway. Have it on a web page? Sure. Allow me to show interest in hearing about them? Great. Contact me to tell about them? No. And as for relationship, if I need information I can come to you. I‚Äôm not sure if I‚Äôm misunderstanding marketing here as something directed at me, not just ‚Äúwe have stuff on our website.‚Äù Latter is fine, of course, but I don‚Äôt need marketing or relationship to come to the site to learn how to use things if I‚Äôm already a customer. I know to come there. But as I said, if I‚Äôm too much focusing on direct contact an that‚Äôs not the case, then I have the wrong view and my answers may be off. I don‚Äôt follow publications but I do follow aggregated feeds on subjects I‚Äôm interested in, and some vocal people on Twitter etc who post about new things they or their companies are working on. We have our own server systems and for personal projects I also have my own, so that‚Äôs why no need to use cloud providers. Would be more expensive and more restricted to do so. 
LINQ. Visual Studio. Debugging. Attaching the debugger to running processes. Web services. REST. Object oriented principles. Basic design patterns, especially Singleton. Use SPs over complex LINQ. Delete code, don‚Äôt comment it out - that‚Äôs what source control is for. Most importantly, pick up on the coding style of those around you and keep your code clean and easy to understand. You‚Äôll thank yourself later.
One more thing- when all else fails, restart visual studio. You‚Äôll be surprised how many times this ends up fixing your problems 
Maybe I‚Äôll have to try that then. I was speaking from experience on another package, but that one is probably different. Should have checked before replying but was on mobile. Thanks for adding the steps you took to fix it.
That's all fine, but they've still chosen to market in that way. Having good clear documentation, and focussing on developer experience is a marketing choice as much as a developer choice, at least in larger companies.
&gt; Why require two constructs when one can suffice with this feature? Because it avoids conflating interface and implementation, and that's arguably a good thing. If you *want* to tie the interface and the implementation in your internal code, we already have a single construct for that -- classes.
I would say the easiest path for you is to download Visual Studio and do some minor project that can be done within a week. If it's web do something web related and if it's something else do that. That way, you will be prepared for the job next week. Good luck!
Don't write code you don't understand.
Abstract classes aren't just for defining contracts, they can be used for DRY to reuse behavior - including adding state which interfaces can't do. Yes I understand composition over inheritance but sometimes abstract classes can save a ton of boilerplate.
It's here: https://github.com/JaimeStill/FullstackTemplate
Have the the right mindset, try to solve problems by yourself but if you get really stuck don‚Äôt be afraid to ask for help. Don‚Äôt ask the same question twice. The ‚Äúcode-stuff‚Äù you will learn in time, but important concepts are dependency injection and unit tests.
&gt; Don‚Äôt be afraid to rip up legacy code if it needs to be ripped up. Some of the worst arguments I've seen in development teams have been over someone doing this. "Don't touch my code" syndrome is a big problem, especially in teams that are dysfunctional already. &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B;
After you get used to Visual Studio, get the resharper plugin. It brings the refactoring tools that VS is oddly missing. I would not code without it. 
In general, most problems you face have been solved, and probably done better than you would have come up with yourself. Use official libraries and minimize the code you write yourself. Chances are, if the class or method you're writing is huge and has a lot of state to manage or a complex decision tree, you're doing it wrong. 
Ask questions, don‚Äôt be afraid, those who know today are those who asked yesterday, don‚Äôt be afraid to show what you don‚Äôt know
&gt;By less "intrusive" I think I should say really "less direct". A survey is not bad, but most devs would prolly just not care. Less direct would be more like finding what problems or tech devs are struggling with (research them on reddit, etc.) and helping them solve those technical problems. That's what I thought. I could write up a survey a post it somewhere, but a) I won't be able to engage in a conversation and ask situation-specific follow-up questions, and b) What developer is out there willingly completing (non-compulsory) surveys?? &amp;#x200B; &gt; Influencers really depend on the market you're in. You need to know what niche you are targeting (desktop .NET devs, web nodejs devs, etc.). Just targeting devs in general is too broad... Got it. Most answers are suggesting someone who has provided a significant contribution to the specific language is a good bet. &gt; As far as convincing your company: check out Mary Thengvall - she answers this exact issue here: [https://pages.vanillaforums.com/value-developer-relations-webinar](https://pages.vanillaforums.com/value-developer-relations-webinar) Thanks! I've downloaded the slides and will see the video first chance I get. :)
[removed]
I suppose I‚Äôm unconvinced there is a problem. The line is already fairly fine between abstract classes and interfaces, but an interface still isn‚Äôt a class and vice-versa. My priorities must be different. I value readable, concise, maintainable code and I‚Äôm seeing a lot of potential from this. The feature potentially reduces duplicate/boilerplate code. So far in this thread, arguments about how ‚Äúthere is something else‚Äù seem to be more concerned about following old conventions than highlighting specific problems with changing those conventions. It also seems to brush off the limits of what exists. Multiple inheritance is a scary and this solves pretty much every time it would have been useful, without taking the full dive. There‚Äôs potential for misuse or misunderstanding of any construct, this is no exception, but it‚Äôs a weak reason to suggest it shouldn‚Äôt exist. I wouldn‚Äôt recommend any complex code or things attempting to modify state going into default implementations (this has also bugged me about some of the examples). Things like returning null, simple logic against other getters, etc. are where the real power is. If there are other negative situations to watch out for, that‚Äôs what I‚Äôm looking for. I don‚Äôt see the point in rallying so strongly about things you don‚Äôt have to use (will you likely ever notice or care that libraries you pull in use it or not?)
Don‚Äôt get overwhelmed, you won‚Äôt learn it all at once. Dot Net is just another framework and c# is just another language. The basic concepts of code don‚Äôt change that much between core languages. Do be prepared to always be learning though as these things change constantly. Consider grabbing vs community edition or vs code. You may want to ask if a coding standard is followed or not. It is fairly common for the ms standards to be followed for Dot Net. Don‚Äôt be scared to ask questions and use google ;) Otherwise good luck! 
I wish I had seen this 2 years ago. That would save me so much time.
I remember having this same feeling a long time ago, reading through MSDN docs and understanding OOP as a whole helped me immensely. I also recommend looking at some basic design patterns that you will encounter in the solutions you will soon be seeing (strategy , builder , factory) etc. Sad fact is that (in my experience ) university does not prepare you for the work environment as well as it should , Ive seen guys coming out of code bootcamps of 6 months do better than CS grads in their first role(not implying this will be your situation - just mentioning) . Welcome to the world of dot net otherwise, its an awesome frame work to work in and I hope you enjoy it just as much as I do!
Without knowing exactly what you are doing it's hard to say honestly. A lot of stuff people have mentioned on here are good to know but depending where you work you may never use. I have no degree in cs but have been coding for 8 or so years and I have become a decent programmer. Lots still to learn. Anyway here are my suggestions, 1. Google the shit out of your questions first. It's ok to ask for help people expect it but if you haven't at least spent a few hours trying to figure it out yourself people will get annoyed and it's a bad habit. You can never become a "rockstar" if you dont learn to solve complex things on your own occasionally. 2. As someone else said non technical people will have a lot of dumb questions be patient and help them understand in a simple way as possible. No matter good of a programmer you are if you don't work well with your clients and your co-workers no one fucking wants you there. 3. The best way to learn my opinion is just by debugging through the code over and over and over you won't know the code base and how it functions until you spend time debugging it don't try and just read it and know what it's doing actually take time to step through and see it work. Everything else should fall into place over time
Hi! My name is Maxime Rouiller. I'm currently a Cloud Advocate with Microsoft. Prior to that job, I was either a developer or a consultant for 15 years. My best advice that I can give you that isn't covered is... write. Learning something new? Write an article that explains the concept to an audience. This has two advantages. One, by writing it, you're absorbing the knowledge even more. Two, if you're publishing it, it may help someone else. Lastly, it will help you move on to higher roles which may require you to communicate clearly. Way easier if you've done that for a few years.
What problem is this feature trying to solve? It seems to contradict the tenets of SOLID OOP. 
Like what? What problem does this solve? 
I didn‚Äôt see this mentioned in the article but if I‚Äôm going after memory allocations a really quick and easy tool that generates an HTML report of allocations from a dump file is Debug Diag by Microsoft. 
+ Also not mentioned but you can open Dump files in memory profilers like dotMemory and see a whole bunch of useful information about the object Heap.
[getseq.net](getseq.net) Seq allows you to collect your logging as a stream from multiple apps and then you can filter it or create dashboards out of it. Use serilog to send it data so you also get context being passed that you can filter on (not just a line of text). You can send it request info, user info - literally anything. 
Jon Skeet's article on [parameter passing in C#](http://jonskeet.uk/csharp/parameters.html) provides for some good additional reading.
I'm not a fan of multi tenant single db, but it's an easier way to start. It's harder to mess up security on multi db approaches, but it's fairly easy to offer both.
I would do this - read a .net book head to toe without trying out the experiments, just to familiarize with the terms - read another one - learn c# by example 
Well I exaggerated. Skip step 2 I guess
This is literally like every other intro tutorial to nlog. Why not create one that actually shows logging exceptions and other errors one may encounter.
You can certainly create your own templates based on those templates. I have my own version of `dotnet new angular` on [GitHub](https://github.com/JaimeStill/FullstackTemplate). There's a whole section in the [CLI docs](https://docs.microsoft.com/en-us/dotnet/core/tools/custom-templates).
We use it for all of our projects. Its already integrated into VS which makes things just an absolute breeze for keeping up on what task you have, attaching commits to the stories, and general managing the flow of a project. Its definitely not perfect, but I find it pretty straight forward.
Do you want to learn MVC 5 or Core? &amp;#x200B; The Microsoft tutorials leave a lot to be desired. I suggest you go through Pro [ASP.NET](https://ASP.NET) MVC 5. I think the book is well written covers unit testing, dependency injection and explains the framework quite well. &amp;#x200B; Even if you don't retain everything don't worry. I have been developing for over a year and I still have not mastered everything when it comes to MVC 5 but I can manage.
I have rarely seen anything .net on HN. I mostly look at Indeed and honestly I had pretty good luck with recruiters although I assume I could get a higher starting salary by not using one.
This is a poorly asked question, I apologize.. &gt; All the following tags are staying the same. \^ Obviously what is wrong with the code. html tags and aspx are rendered differently at runtime! Duh! &amp;#x200B;
Another option is to add a custom key per site in ApplicationInsights to query sites directly. This is what I do for when I have multiple services and put them all together.
https://github.com/dodyg/practical-aspnetcore This is my project. Try all the samples. Each sample is tiny and designed to use the smallest number of code to accomplish anything. 
Please don't take this the wrong way, but for future reference [StackOverflow](https://stackoverflow.com/) is probably a better resource for troubleshooting type questions than this subreddit is I'm glad you were able to resolve the issue though!
Cool. Now try convert these MVC code to Razor Pages. You will like it better.
No worries, I was searching around StackOverFlow for it, but just like this post, I was asking the wrong question. It took me to read it back to myself to realize, I think that's called 'rubber ducky debugging' ??? Either way, I'd rather ask a stupid question here to potentially have a beneficial conversation around a general subject, than ask a stupid question on StackOverFlow and literally get murdered by the whole SO community
Ahhh ok, that's totally understandable. SO does indeed have a reputation for elitism, so I can understand why you would choose here instead. Web Forms is probably one of the more annoying platforms to work on. I have the pleasure of maintaining a really garbage system...I know the feels.
sry im new.. but where is the difference between mvc and razerpages?
It is super annoying, however, if never work on anything else you can never realize how annoying it truthfully is! Like if no ever told you business logic is better in a BLL than a stored procedure in your DB, than how would ever experience the fun of query optimization?
In the interest of not spamming this subreddit, maybe you can offer a suggestion for next steps in a side project? As you can probably already tell, i'm in the earlier stages of a dev career, so i've an API i've built in EF CORE and built out all the tables in SQL, using SSMS to manage it. I want to deploy this API to be able to access via HTTP in other, front end app that I will be building. I've got a domain that has a brochure website [www.testsite.com](https://www.testsite.com) and would like to use that for the API url, [api.testsite.com](https://api.testsite.com). How would you suggest I host this? Azure? or something else? Hosting is something that is completely new to me. Any tutorials you might suggest?
There's a lot to unpack here but I'll try my best to answer as clearly as I can. If I understand you correctly, you are building a website for some kind of brochure? Firstly, I would need to know a bit more about the use case of this site. Writing an API + single page app is all the rage these days, but it also adds a bit of complexity to your hosting, deployment, and maintenance work. For example, you could accomplish quite a lot just using Razor Pages nowadays...however. If you've already built the API or you really want to go this route for learning, etc. then ok. When you say you've built all the tables out in SQL, are you saying that you have `.sql` files that create the tables etc, or are you using Code First in EF? Either approach is fine, but Code First has some advantages especially for newer devs. As for hosting, it really doesn't matter all that much in terms of tech and pricing...but Azure is probably the easiest place to deploy .NET core apps. They have plenty of tutorials and guides on their site which go into much greater detail than I could here. Another option is AWS, or DigitalOcean, but those would require more learning and trial and error... Hosting a site or API is just one small aspect of the bigger picture that is application maintenance. There's literally thousands of tools out there that deal with the devops problems...automated deployment, rollbacks, db migration on deploy, etc. It can get very complicated, very quickly.
Any reason why to stick with MVC 5 over .NET Core? Isn‚Äôt core the newest version? Also seemed a lot faster for me
When I was looking to move to Core recently some stuff that I used was not available. Plus, MVC 5 is still really popular in my area. However, Core is the way forward. &amp;#x200B; I believe a similar book on core is available called Pro [ASP.NET](https://ASP.NET) Core MVC but I have not looked at it yet.
I see! Thanks! I come from MVC5 and am very happy with the switch, made most things easier except for the packaging, works horrible on my mac. Do you know why or more when to use either mvc / razor pages with code behind? Or is the razor pages with code behind/inline the new way to go? 
I think i'm getting bogged down with the how many options and what the best one for me is. &gt; you are building a website for some kind of brochure? Sorry to confuse you with that term. To simplify, I am working a very small business/start up on the side. Currently, I've built them a website that acts in a brochure style manner (information only, not a SPA). It is growing super fast so i'm building them an API the can be used to stream line some of their business bottlenecks and also store data for reporting. Currently spread sheets are used, and are very unreliable. I have used the Code First EF approach, which I went for right away. I come from a SQL/DBA backround so I was interested in learning this approach. &gt; bigger picture that is application maintenance. Yes, yes and yes. In this instance though i'm trying to put the horse before the cart. The amount of users will be low at first (2) so hopefully that is something I can manage myself, before allowing maintenance to get out of control. There will be a phone app for data entry and a web app for reporting. The phone app with be super straight forward with entry fields and a singular image being posted each time. The DB with have CDC changes enabled to compile reporting numbers on the web app. &amp;#x200B;
Good
Ok, so then yes, I would say Azure would be your best bet. It scales really easily and to be honest, even a small instance can scale to thousands of concurrent requests if need be. Assuming you are using async properly and your code is mostly efficient :D
Clicking the link on the page goes to: https://github.com/JaimeStill/Fullstack &amp;nbsp; Not, https://github.com/JaimeStill/FullstackTemplate
It wasn't intended to be a link, it's just how it ended up being formatted by Medium. Sorry for the confusion!
No worries
You mean N'sync right? Best coding music there is
+1 for Pro ASP.NET MVC 
Yes, but extension methods have worse discoverability
VS community edition is free even for small companies. It really packs a lot of features. 
Or, even better, CodeRush. 
So this way you create one AI resource and add a custom key (that is the same) for each app/site? Is it straight forward to separate the sites with the queries? thanks
Thanks, nice read
A PK constraint automatically creates an index. A FK will not automatically create an index, you should specify these in your fluent model. https://stackoverflow.com/questions/970562/postgres-and-indexes-on-foreign-keys-and-primary-keys
There is not big differences between new versions of .Net framework. If you use async/await methods you could get a better exception handling. C# 5.0 does not support await keyword on catch block. New features like conditional catching, nameof or string interpolation are great!. Unfortunately you will need to refactor your codebase. If your system runs third party components you may need new licenses.
I found this article by Andrew Lock to be really handy. He goes into some of the fundamental differences between MVC and Razor pages. https://andrewlock.net/an-introduction-to-asp-net-core-razor-pages/
Well I remember there was some serious security vulnerability with 4.5.1 and 4.5.2 was released pretty quickly to remedy this issue. I was trying to find if anyone knows something with security that could be an issue in 4.5
No, it‚Äôs free for up to 5 users. Otherwise you‚Äôre breaking usage agreements. Above 5 users and it‚Äôs $45/mo
On phone so apologize for the links for direction, but yes, it is straight forward. For adding the custom property, you‚Äôll attach the custom key to (every request[https://stackoverflow.com/questions/29036729/adding-custom-properties-for-each-request-in-application-insights-metrics] and for querying, you only need to (extend the query)[https://stackoverflow.com/questions/43392240/application-insights-how-to-sort-by-custom-dimension] adding the custom dimension. Hope this helps
No, security issues will get patched through windows update anyway, if the reason you want to upgrade is‚Äôsecurity vulnerability then that doesn‚Äôt work, as long as it‚Äôs supported it will get patched.
Thanks for the comment, that was great. Notice that I am not making the case for not using **get** or **set** which are just the accessors. The benefits of that are very clear for both of us I can assume given the quality of your comment. My point is using **{get; set;}** vs just use public Field. Even there I am not advocating for using or not using Public Fields, I am purely addressing the consequences of not having as a Property if you mean that to behave like a Property. &amp;#x200B; There is a case to be made why use Public Fields in the first place. Potentially, Microsoft could enforce public fields to be automatically compiled to enable getter and setter if not specified otherwise (example private-set or encapsulated \_xxx field). I'm don't have a opinion about that because there is also an argument to be made, if you want expose the getter setter just write it down, therefore, {get; set;}, one could say it is safer. &amp;#x200B; Regarding people rarely using reflection against your type, well, I am not saying the caller writting specifically reflection code to extract the members from your assembly. Reflection happens all the time using Visual Studio visual tools for example. Binding is one of them. Try to bind classes that used to have properties with getter exposed to public Fields, changes are it will not work. &amp;#x200B; I hope I addressed everything, if I read again and feel I missed something I will reply again. &amp;#x200B; Thanks &amp;#x200B; &amp;#x200B;
 (gwmi -class win32_computersystemproduct -property UUID).UUID
Is running a supported version not enough of a reason?
from [https://support.microsoft.com/en-us/help/17455/lifecycle-faq-net-framework](https://support.microsoft.com/en-us/help/17455/lifecycle-faq-net-framework) &gt; Support for .NET Framework 4, 4.5, and 4.5.1 ended on January 12, 2016. Customers and developers must have completed the in-place update to .NET Framework 4.5.2 by January 12, 2016 to continue receiving technical support and security updates. The point is, if there is a security issue, Microsoft isn't going to tell you about it, and they're not going to fix it. You should very definitely not be running on 4.5. The compatibility bar is very high for .NET Framework, so if you're updating to a supported version anyway, I'd say you may as well go for 4.7.2.
4.5 is end of life, no longer supported and not secure. Upgrade everything to run on 4.7.2. 
What i mean by programmatically is, would this look like in c# code, for example; `string s = (gwmi -class win32_computersystemproduct -property UUID).UUID;` What are the constructs in code that would return the same strong to be stored in the variable s? Thanks. 
When is .net going to no longer updates?
And be replaced by .net core?
More like go into full eol maintenance, being supplanted by .net Core as the place to develop going forward.
Thank you. Greatly appreciate the info.
That is a good point. Thank you.
That is a good question. I feel like it really should be done.
Use ManagementObjectSearcher. In the constructor, pass in the namespace and query. Then iterate over it invoking the query with the Get call. I'm not sure what the correct namespace is. ManagementObjectSearcher s = new ManagementObjectSearcher("root\\CIMV2", "SELECT UUID FROM win32_computersystemproduct"); foreach (ManagementObject id in s.Get()) { Console.WriteLine(id.ToString()); }
I know they‚Äôre creating .net standard so I feel like that will replace the framework. But with .net core 3.0 comes the ability to support GUI so it might be the end game for the framework
I know they‚Äôre creating .net standard so I feel like that will replace the framework. But with .net core 3.0 comes the ability to support GUI so it might be the end game for the framework
Thank you so much! 
Updated NuGet packages posted today.
I thought 4.7.2 was going to be the last release?
That isn't what .NET Standard is at all. .NET Standard is just a specification of which APIs are available in the implementations (which are either full framework or .NET Core).
Happens all the time to me with VSCode on Linux and macOS. `$ killall -9 dotnet`
Oops! My bad man. My bad lol
4.x is supposed to be the last major release. 4.8 has been in the works for a good while already.
&gt; C# 5.0 does not support await keyword on catch block. The language and the framework are different things. All you need is a newer compiler that understands the newer language features. There's no needed framework support for awaiting in a catch that is needed between v4.5 and 4.7.x. You can open up VS 2017, target v4.5, and await in catch all day long.
That‚Äôs already happened. 4.8 is not getting features like JIT support for spans (they work but you don‚Äôt get the performance boosts seen in Core) or default interface implementations.
[https://marketplace.visualstudio.com/items?itemName=DanielGriffen.WhackWhackTerminal](https://marketplace.visualstudio.com/items?itemName=DanielGriffen.WhackWhackTerminal)
Thank you very much, I'll look in to this
Cool!
Any modern image processing libraries recommended?
I‚Äôm working on one just now that I think is pretty sweet. (I am biased) ImageSharp. Nearly ready for release, just adding some final polish. 
Data goes in a database, you should not be putting html in one. Look into how partials work, things like nav and certain components like a search box or maybe a reusable table or other elements can be partials that get injected into the page. I'd highly recommend getting a pluralsight trial and finding a basics class to follow. 
Ok...so no HTML in database...but can I have content in the database? e.g. wherein something like &lt;div&gt;some content&lt;/div&gt;, the tags will be part of a view but the "some content" portion will go into database? Thanks of the reply.
The database is absolutely meant for your content
Sure, if that data makes sense in a database. Let's say you are building a movie website, you could have all the movies and their info in a database and pass that data into your view from your controller by way of your model. Then maybe you do a Foreach loop on your list of movies: @foreach(var movie in Model.Movies { &lt;div&gt;@movie.name&lt;/div&gt; } That would make one div with movie name inside for each movie in your list of movies. 
Well...my content is more like paragraphs of text and bulleted lists...like articles...in that case, does it make sense to put them in database? In the end, I want this content to be searchable.
Yes, that would definitely go in a database. You could write one page that is essentially a template for your articles. Your page would have an ArticleViewModel with properties like subject, body, date written, comments, etc. The page would use what data is in your view model to display in whatever format you'd like.
If you‚Äôre using VS, CodeLens will show you how many times a method is called. Sadly, I don‚Äôt know of another tool or the ability to find the methods most called. Hopefully someone can help there!
Razor Pages is better than MVC for building pages. With Razor Pages, you can just pass all the data you need as properties and it will be available to the Razor View individually. With MVC, you have to create a GIANT ViewModel that pass your view data and input data or resort to ViewBag.
If you're using Visual Studio, you can use the profiling tools to identify hot paths within your application at runtime: https://docs.microsoft.com/en-us/visualstudio/profiling/performance-session-overview?view=vs-2017
Yes I am getting it a little bit...the thing is that not all articles are same...some have bullet lists but some don't, some have one illustration, some have two, and some have none at all. So a common denominator...some kind of template would go to a partial view. Now...if not database, I will end up with several Razor pages. If I am getting it correctly, I need to achieve some balance...no need to create huge number of razor pages / templates, and at the same time don't put lot of HTML stuff in database either...is that right? &amp;#x200B;
We are currently on 4.5.2 (the minimum version of 4+ still supported by MS) I would recommend you upgrade immediately to at least this version as MS will not announce or patch any security vulnerabilities for 4.0-4.5.1. 3.5 is also supported, but only for a few more years iirc. &amp;#x200B; Moving to 4.6.1 allows you to consume .netStandard 2.0 libraries 4.7 "improves TLS support", again very useful to apps that do any kind of internet communication. See [here](https://docs.microsoft.com/en-us/dotnet/framework/network-programming/tls) for more info. This is probably the big sell for your boss. I can't think of any other headline features, but if you are going to 4.7, I would jump straight to 4.7.2 and be done with it. 4.8 is coming (soon) but it's probably too early to make any plans over it
Full changeling for 4.8 thus far: https://github.com/Microsoft/dotnet-framework-early-access/blob/master/release-notes/NET48/dotnet-48-changes.md (It's massive.) It seems to be only bug fixes, I wonder if there's a separate page detailing the new features in the framework itself (any new API calls) that warranted the runtime major version increment, per Microsoft's conventions. 
Use eventsource and perfview http://www.aaronstannard.com/creating-your-own-ETW-source/
SFML? Seriously, Fuck My Life? 
It's been a long time since I saw flowerboxes in source code.
&gt; C# 5.0 does not support await keyword on catch block. He's talking about the .NET version, not the C# version. You can use C# 5.0 with .NET 4.0 without an issue.
Thanks for the answer and the SO link, it helped me a lot... I was definitely searching in the wrong direction. &amp;#x200B;
Sounds like it's heavier in a JavaScript framework when you see views like that Have your tried to use the chrome developer tools network tab to see which resources are loaded? Use the xhr filter. Once you get a URL, you can search for a part of it doing a full text search. You'll find either the calling code js code, or the API controller it's hitting, either because of name, signature, or something like a route attribute..
If only I stated small companies, eh? Visual Studio is still the IDE for .net. However having a competition isn't bad at all. Go for Rider if you prefer it, but I doubt that it features everything VS does, like i.e. Xamarin. 
Less than 5 members are extremely tiny companies. ‚ÄúSmall company‚Äù is valid up to a couple hundred people. 
Here's the abstract: &gt; Have you ever stopped to think about all the things that happen when you execute a simple .NET program? &gt; &gt; This talk will delve into the internals of the recently open-sourced .NET Core runtime, looking at what happens, when it happens and why. &gt; &gt; Making use of freely available tools such as 'PerfView', we'll examine the Execution Engine, Type Loader, Just-in-Time (JIT) Compiler and the CLR Hosting API to see how all these components play a part in making 'Hello World' possible.
Where you talking to me? Because I was expanding an old asp.net web service that was created back in 2014. I'm fairly new to asp.net and other than it's syntax and a few applications I know nothing. That's why I'm asking, because I've never used asp.net to upload excel values to a database
One reason is that most of the job market still is, and will be based on old stuff, so if he'll be looking for a job, he'll have much higher chance knowing MVC5. You can always learn newer stuff in your own(or company's time) later on.
Hi, the volume is waaaaay too low. Compare it to a few random videos to see what I mean. 
Thanks! I'll see what I can do to adjust.
How does SFML compare to Monogame?
:) I'll give it a watch anyway, the content looks interesting. I just have remember to turn the volume way down after watching if I don't want a cat terrified out of its wits :)
Yes, in that case things like img tags with the url of the image would be ok to store with the body of the article because there is no reliable way to template that out. Same with bullet lists. These are part of the body of the article. Essentially anything you would add to the article with a wysiwyg editor, you should encode and store in the db. 
Thanks for the answer, I was eagerly waiting for it. Also, got a month of free access to pluralsight...so will start with Razor Pages basics. &amp;#x200B;
Interesting thing but I have some thoughts: \- in DDD you have repositories only for Aggregates Roots. \- you are generating services in Domain Model. What are these services? Domain Model should have only Domain Services which are not associated with one particular Entity (from definition). \- you are generating controllers (GUI), application services (Application layer) and some mappers. I think this is not good idea because all of that things are separated concerns. I appreciate the work you put in this solution but i think this kind of code generation doesn't support Domain Model isolation which is one of the main goal Domain Driven Design.
You should be set. 
Never was an SDK issue. There were one or more files blocked that were extracted from the project zip-file. After running Get-ChildItem and piping to Unblock-File, compiling the solution worked as expected.
I'm pretty sure from "dotnet new" to "hello world" is: dotnet new console &amp;&amp; dotnet run :) Just joking with ya, hope someone gets something good out of what you've created.
Maybe I didn't explain well, or at all, in the video, but those files being generated and where they are being pushed into specific projects. So feel free to correct if I'm off base here. &amp;#x200B; 1. Entities, Models, Interfaces are being created in the Domain Project 2. Mapper Creates a Mapping File in the Mapper Project 3. Services for CRUD belongs to the Service Project 4. Repositories, Database Configuration Files, Database Project 5. Controller - REST Project &amp;#x200B; Would you agree this is the correct approach? And if I'm understanding this correctly, an aggregate would be a separate project in the Application Specific Context that would contain the Domain project? &amp;#x200B; I do appreciate the feedback! Cheers!
What do you prefer that provides similar lightweight cross-platform functionality?
Has rider improved on Code-First migrations? The last time I tried Rider I loved it, but it was a little clunky for running code-first migrations. * Doing a migration did not honour the external appSettings file \`&lt;appSettings file="User.config"&gt;\`. We have the User.config ignored by git, and store our connection strings in there. That way we are messing each others connection strings up. Rider did not honour this file during migrations. * All our migration are in a seperate assembly from our default project (data layer dll), and it was a pain to tell rider to look in that dll for the migrations, as opposed to the default project. There are some small fixes/refactorings that I have noticed 2019 is missing from Resharper, but I could live without them. I do like how resharper lets us enforce code style across our projects. I have tried to replace this with a .ruleset file, but it wasn't quite the same. Plus we have a couple years worth of resharper rules, trying to port those to a .ruleset would be painful... I wish there was a tool to do that. Enforcing the rules is probably the main reason we use resharper.
Yeah, I guess you are working with pretty simple builds :) Anyway‚Ä¶ I think the only ways to get NET 3.5 SDK is to get one of the paid versions of Visual Studio.
Hey, if I understand this issue correctly, you can just use Prometheus to track what method gets called and when. https://prometheus.io I just recently worked with it, and it is actually quite simple to implement. 
I'm not at home right now, but you can use `System.DirectoryServices.AccountManagement` in conjunction with Windows Authentication. When I get home, I'll show how I accomplish this in ASP.NET Core.
This will give you much better performance. public void FunctionICareAbout([CallerMemberName] string calledBy = "") https://docs.microsoft.com/en-us/dotnet/api/system.runtime.compilerservices.callermembernameattribute?redirectedfrom=MSDN&amp;view=netframework-4.7.2
In case anyone finds this abandoned post, I decided to use Aspose.Tasks
I just passed the 70-483 exam after a week of prep (maybe 20 hours), and signed up for the 70-486 today for about a week and a half out. 6 years experience in C#. I am using the Microsoft Official Preps from MeasureUp to prepare. The MeasureUp prep had 150 questions with very detailed explanations of why an answer is right and others are wrong. I found this invaluable for the exam, because it presents the type/formats/structures of questions you will be asked, learning how to answer these questions was the hardest part (I was never tested like this even in college). I went through the entire deck twice reviewing the explanations, writing down topics that stumped me, I got wrong, or felt weak in, it was a decent sized list. Then I spent a few days researching them in a high level, more on contextual usage not understanding every extension. Then I took the mock certifications, got consistent passing scores. Spent the rest of the week, taking the entire practice deck couple times a night. I did quickly memorize them, but still forced myself to read the question and all of the answers then the explanation or just explain it yourself. The exam is similar but none of the questions from MeasureUp were in the actual exam word for word. I did skim a dump, couple days ago, I was turned off because right away there was a wrong answer. But I did notice questions from that dump in the exam. &amp;#x200B; Also this is what I had my employer purchase, I am pursuing this on my own because I wanted to increase my level of "text-book" knowledge on these subjects as I felt it will help me easier communicate and understand ideas to my team members: [https://us.mindhub.com/microsoft-certify-with-confidence-pt/p/MSFT-Cert-w-Confidence-PT?utm\_source=MSFTmarketing&amp;utm\_medium=msft\_offers&amp;utm\_content=weblink&amp;utm\_campaign=certify\_with\_confidence](https://us.mindhub.com/microsoft-certify-with-confidence-pt/p/MSFT-Cert-w-Confidence-PT?utm_source=MSFTmarketing&amp;utm_medium=msft_offers&amp;utm_content=weblink&amp;utm_campaign=certify_with_confidence) &amp;#x200B; Not sure if this helps but some insight 
The consequences of thread stealing can be quite interesting/surprising. I think this speaks to no matter how well designed all abstractions leak. 
What can I say, I'm not exactly a wizard of iMovie, screen casting, this list could go on :)
It's pretty tricky actually, it's a skill in itself. I think the material is worth it, so if necessary ask for help from people who it better than me :D Lots will help :)
There are a lot levels of security and it depends on what you‚Äôre looking for. I would recommend looking into OWASP. We run scans using Zap as part of our release process. This will help identify possible security issues. Along with that we always add proper middleware so we can create audit trails when needed. 
In general you don't trust employees as if they were malicious actors. But for instance if company has fully controlled environment that has mandatory antivirus software for internal application I would skip explicit virus scanning for instance. Though you still should have AV on server anyway. &amp;#x200B; Next thing to acknowledge is if you are developer you can propose security measures. Then team, product owner, team lead, business have to say if they prioritize it or not. Please don't get angry if they say they don't care and will put your propositions on the bottom of backlog. You are not in charge of where to spend money and if product owner accepts risks it is none of your business, just keep mail or reference to your proposition in case something bad happens and they try to search for dummy to put all blame on.
Great work! I love to see more xplat .NET libraries being released. 
You‚Äôll probably won‚Äôt to create a repo for the referenced libraries and check them out when building the project in the yaml script. Other than that you could just place them on the build server and then add them to the project while compiling.
I think you're looking for nuget packages.
This makes sense to me, I really don't want the overhead of hosting nuget packages. Thanks for the idea, this kinda broke my writer's block!
We do this internally as well - host your own nuget server and publish common libraries there. Then make it accessible by CI server (extra points if CI server is hosted on a different network).
I was going to post this all right here, but apparently it was too long for a comment. So here's a Markdown Gist showing [ASP.NET Core integration with Active Directory](https://gist.github.com/JaimeStill/539af65518091f7b8e6b9e003a493baa). This is just the beginning, as you can setup Entity Framework with custom Users and Permissions tables. Then you can do route Authorization for controller endpoints, and even route guards in Angular (which I do!). If this is helpful and you would like to see a demonstration of the Entity Framework integration, Controller Authorization, or Angular route guards, just let me know!
I suppose it depends on your company and their policies. At previous enterprise jobs we used windows auth on basically all of our LOB apps because usually if you're doing something meaningful you're going to want to know who's accessing the apps, and it's very common for LOB apps to need various levels of access/permissions (often tied to AD groups). One question you'll want to double check is whether your company is using on prem AD or is using (or planning to move towards) Azure AD. The former uses traditional windows auth while the latter has your app authenticate with Azure AD using an OAuth flow. 
Could be wrong, but looks like that only gives the immediate caller name and not the full stack trace down to the method?
Roslyn is already used for your build. C# Language Level are determined with the msbuild property "LangLevel" which can be set in the csprojs. The nuget package you have there is for when you have to anything with the binaries at runtime.
Yep. That's the trade off.
&gt; the overhead of hosting nuget packages Took me all of about half an hour to set up [NuGet.Server](https://www.nuget.org/packages/NuGet.Server/) and I haven't touched it outside of a couple version updates over the course of several years. https://www.nuget.org/packages/NuGet.Server/ Or you can just sign up with MyGet or similar. Whether or not packages vs. sub-repos is better depends on a variety of factors. Either is usually workable.
That package is used so you can use newer C# features in Razor views.
Hey there - yes, you can. No PHP is running on the server with this, you can give it a try at wpdotnet.com.
You can use a file share as a NuGet repository. We didn‚Äôt want to set up a server to do it so we just put it in a network share and point to it with our NuGet config. Devs should want to do that anyway because it‚Äôs much easier to manage internal NuGet packages than pull in libraries manually. You can set up build pipelines for the libraries too to automatically publish the packages to the share. Doesn‚Äôt take much time.
It's probably worth going all the way and setting up something like Identity Server to act as a gateway and then use ASP.NET Identity. It's more work upfront but it's reusable and allows your applications to not have to worry with how a user authenticated.
That's actually really cool and I'm saving your comment for future reference. If you have time for the other demos, I'll certainly give them a look over.
If you're a junior dev and they are expecting you to handle security, I would be looking for a new job. That is a pretty big red flag that you either won't have mentors or even worse will be mentored by people who probably shouldn't be writing software.
As wazzamatazz pointed out you can find hot paths using Visual Studio profiling tools. But that assumes you're able to exercise all your various code paths under the profiler. Sometimes with certain systems that's non-trivial. So if you're not able to use the profiler this would work. However this will most definitely add time each time that function is called. Are you putting this behind some sort of a #if (DEBUG) ? Are you planning on extracting this to a common method, calling that, and culling that extra method off the stack when you process the logs? 
&gt; In general you don't trust employees as if they were malicious actors. Ohhhhhhhhh yes you do. Most data leaks and malicious activity on an internal system WILL be an employee. I have seen this happen first hand on more than one occasion!
I'll bring it all together tomorrow :)
Oh I didn't know that. I doubt this is actually what he was asking about though.
This is awesome, thank you!
They'll be staying with on prem AD. They looked at Azure briefly but they didn't like the cost apparently. Thanks for the pointers.
I've been looking at IdentityServer recently, so it still has it's place even when using AD to authenticate?
They're not expecting me to, it's more something I'm doing off my own back. There's nothing there at the moment and figured it would be a good learning experience. Equally if I did nothing about it, nothing would be said.
Zap looks great! Is it safe to use on production sites?
They do: unlike extension methods, you can choose to **override** the default method in an implementing type. LINQ extension methods often cast the IEnumerable around and then pick an implementation that is best suited for that kind of collection. Meaning, any new collection would have to be added in many, many methods or the less efficient default implementation will be used. &amp;#x200B; With interface methods, you can simply override the default method body and provide a more efficient alternative. This works for properties, too.
You guys are missing a crucial point: a default-body interface method **is not a member of the implementing type**, unless you implement it like before. If you have an IFoo interface with a Bar() method and implement it your KungFoo class, you cannot call Bar() on a KungFoo instance. You need to cast to IFoo first. This is precisely how the diamond problem of multiple inheritance is prevented (for classes), the method doesn't become part of the class. Thus you can implement as many interfaces with a Bar() method as you want, you need to cast to the respective interface first anyway ‚Äì or implement the method, in which case *that* method will be used, just like before. &amp;#x200B; This is a pretty big difference to abstract classes. In general I would not consider this to be a replacement for them, default-body methods serve a very different purpose. They are here for when you have and *want* an interface (for all the existing reasons) but then you either want to extend it in a non-breaking way **or** want to provide a common default implementation that can still be overwritten (unlike with extension methods). Virtual methods are not the only reason why we would pick an abstract class over an interface.
How would you implement a Log() method in your ILog interface that is used by 100 classes? You have no access to anything of the implementing type, only to things in the interface or base interfaces. &amp;#x200B; I'm a proponent of this feature, but I don't think your use case is one that will work with it. 
Narrow minded much? What if I told you this feature has more uses than be abused as abstract class? Which, by the way, it can't properly since default methods don't become part of the implementing class. It's like saying "I hate this drill! What's wrong with hammers? Anyone can remove a screw, that's terrible! Nails are a lot harder to remove when you hammer them in!". Like with any new language feature, it's a good idea to read up on what it is *intended* to solve, not condemn it for the first lazy idea that comes to your own mind.
One: add a method to an existing interface without breaking a shit ton of existing types that implement it. Currently, extension methods were the only way to achieve that (think LINQ). This new feature has the **huge** advantage of still allowing implementing types to override that default method body, unlike with extension methods. LINQ could be done a lot more efficient with this feature because every collection could choose to override a specific LINQ method if it can do it in a better way than the often suboptimal default implementation. &amp;#x200B; Two: sometimes you have multiple behaviors that are similar in a number of classes and you want a common contract for that behavior. Currently you can pick one abstract base class and any number of interfaces to add behaviors to your types. Now you could also add actual logic alongside one of these interfaces and not just require your types to implement it. Say you have an IFoo interface with a Name property and an IPrintableFoo with a Print() method that 90% of the time just returns the Name. Now you can write Print() =&gt; Name; and only override it where necessary. Abstract class is no alternative since your types already are in an inheritance relation. &amp;#x200B; I'd say Two is a more narrow use case, but I can think of a number of occasions where it would have been useful. One is the primary reason in my head.
You'll need to find the system functions needed to do this and pinvoke them. I'm afraid I don't know how to do it. But if you can find a c++ way of doing it that should give you the required calls.
I‚Äôd recommend only passive scanning against production. We have a staging/testing environment that‚Äôs a replica of our production environment. That‚Äôs what we run the full scan against. If it passes then we continue with the release pipeline and queue a build/release for production. 
EAD
He never got home! Somebody call the cops!
I sure did! [This](https://www.reddit.com/r/dotnet/comments/atk8zw/security_with_internal_aspnet_core_applications/eh2605u] is my other comment. I fail at reddit I guess.
I dont think I'd necessarily need any information about the implementing class for this, I would just need parameters on the method and would represent the elements to be logged.
It is a good start. Have fun localizing the text in your JavaScript.
Just poking fun. Have a good day!
I am not a big fan of resource files. Otherwise nice post. But I don't see a big problem with JavaScript files, there are plenty of solutions to that problem.
Simply create a dictionary of string and string then serialize the dictionary to json. Then you can use this dictionary as your string table.
That is a good start, might be enough for many apps as well. Now, where do you inject those strings? In the page itself? Or do you get them via an Ajax call (might be good for a shared component that isn‚Äôt viewed much)? We use a rich-text editor that has separate files to download for each language. I tend to work on large enterprise applications. We have over 10,000 strings and they are translated into 14 languages. Each page can use hundreds of text strings, and as we move to more ‚Äúsingle page‚Äù style apps they get bigger and bigger. So for us, there is no one simple approach we can take. We use several, each one to help optimize load time and developer productivity.
Vuejs,React,Vanilla JS
In an app I made long ago, I created javascript files on startup, and then pages would reference them as needed. But that was before Angular2 and React was a thing.
Build your own personal website or a website related to some interest or hobby of yours. Or several websites using various technologies. Key is that it is interesting to you. 
Learn CSS, JS and SQL Server first. Don't become an expert in them, just enough to get by and Google when you need more help. These skills can still be used if you decide you want to be a python, or php, or node or any other kind of web developer. Bootstrap is just basically applying classes to html elements, very simple to use and most new dotnet projects come already utilizing it. jQuery is just slightly simplified javascript syntax and is very easy to quickly pick up if you are working on a project that uses it. Don't actually learn jQuery unless you plan on getting a job somewhere that uses it. Same goes for React but React has a much higher learning curve. I think for being a dotnet developer you would be better off spending more time developing C# skills stuff like MVC, WebAPI or Razor Pages.
I typically know more jQuery, css, and bootstrap than other developers I know, because I've also designed professionally (still do -- great side money). It's good stuff to know. You may very well land yourself on a project where it wouldn't hurt to have the skills. But, the way the world is going seems to be SPA. So something like Vue, React, Angular may be better for you to focus on. From most modern-day projects, you won't need much custom css/jQuery (and - if you do - there is probably someone on the payroll handling it already). One of the greatest things you can know (from like a job perspective) if you want to focus on .NET is more of the SQL side. That can come in really handy. People that are both .NET and SQL experts can do massive amounts of work. If you want to go ahead and jump into .NET Core, it offers projects that come with bootstrap on them, and it offers a project already set up in Angular. Core and Razor pages are really easy to build little projects quickly to get you some practice. Like in an afternoon, you can have a decent grasp of what Angular is doing. Just some food for thought
Skip on MVC and learn Razor Pages
Razor pages are really only good for very simple views that are read-only or do basic data input. MVC is much more robust. 
And a note about jQuery...in the beginning, don't try to "learn" it -- instead, learn what it is doing. So any element can be gotten, altered, affected, detached from it's place, and re-attached elsewhere (based on other elements). You can reference siblings and children of elements. In theory, you could write all your CSS from jQuery (you never would, in real life -- just a way to 'grasp' what jQuery does). But, beyond this, jQuery is also a way to hold and maintain your back-end data model(s) in JSON. So, once you understand what jQuery can do ... then one day, you'll have a unique problem ... and you'll be able to KNOW what the problem requires, and you can Google your way to the correct syntax to handle it (but, you have to understand what it CAN do first).
I believe so, yeah, but it ultimately depends on your goals and requirements. Here's the architecture I was talking about: http://docs.identityserver.io/en/latest/topics/federation_gateway.html Keep in mind that IdentityServer is just one possible route. You can accomplish mostly the same thing with AD FS as well.
Yeah, let‚Äôs direct the newbie to an old tech that‚Äôs probably semi-deprecated in a year
I would not recommend jQuery at this point. Angular, React, and Vue are the frameworks of the day (as of this morning, but just give it five minutes...), so they are better investments. That said, I wouldn't *start* with them. Get familiar with JS and it basic Web technologies first, then maybe learn TypeScript, then move on to a more advanced framework.
Why are you not a big fan of resource files? I've translated my site with them. Is there a better approach?
Are you referring to MVC? Because it absolutely won‚Äôt be. 
Not sure if there is a better approach in general. But we rolled our own. We stored the translations in our database, and that allowed our translation team to use a UI we created to translate all languages. As time went by we added more features, such as "missing translations", which made it easy for our translators to handle new phrases that were added by our developers. It kept the developers more agile, and made handoff easier for both sides. We also added "local translations" that made it possible for each customer to change the phrases themselves. Our customers were schools, and sometimes they had other terms for processes than we did, so that allowed them change things as they wanted. More features were planned, but I left before I could make them. There is no perfect fit with localization, but for me, I like to be able to change it on the fly, and not have developers involved.
You too!
Alright
I built a retro video game db/api to learn dot net core
It's actually exactly what he's talking about since he asked about "using C# 6+ features in the views."
You can include this library and it shouldn't make a difference performance-wise at runtime. If you're worried about it, you can pre-built the views at publish time (the option is unchecking whatever box to "Allow changes at runtime") and then the Rosyln folder that gets generated isn't actually required.
You clearly have no idea what you‚Äôre talking about. 
How different is TypeScript from JavaScript?
Thanks for that, appreciate it.
Can‚Äôt you just spin up a new project and take a look? 
RemindMe! 1 year
I will be messaging you on [**2020-02-23 17:45:55 UTC**](http://www.wolframalpha.com/input/?i=2020-02-23 17:45:55 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/dotnet/comments/atwyx7/should_i_learn_jquery_css_and_bootstrap_or_focus/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/dotnet/comments/atwyx7/should_i_learn_jquery_css_and_bootstrap_or_focus/]%0A%0ARemindMe! 1 year) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! ____id____) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
It's not *that* different, but you'll likely appreciate it more once you know vanilla JavaScript. TypeScript is something Microsoft wrote as a *superset* of JavaScript, one that acted a bit more like C# and other statically-typed languages. It can't be run directly in the browser, so it first has to be "trans-piled" (as opposed to "compiled") into vanilla JavaScript, something that can be done automatically by various development tools. TypeScript has a lot of quality-of-life improvements over JavaScript that JS developers tend to appreciate. YMMV, of course, but I'm definitely spoiled by it and don't enjoy going back.
My thoughts as well. With your background this should help a good bit. The MS docs are great as well.
Can we have the github link, if that's not a problem? 
they are almost the same, your core project might even have used the old helpers like Html.TextBoxFor instead of tag helpers so even views will be the same
If you were using full VS rather than VS Code for your .net core development, then it shouldn‚Äôt be that different. There are some project file differences and you are tied to IIS with framework but most of your C# code should be similar. 
Long ago, we built a UI into the app for translations. A magic key combination opened a dialog that listed all the text on the screen and had a column to enter translations that were stored in the database and applied on window creation (desktop app). As the selected row changed in the dialog, the text was highlighted on the screen so it was easy to see where the translation would go and the text's context. The translations were keyed by window_name.control name, so when text appeared more than once on a page, different instances could have a different translation if necessary. The translations were applied as they were entered, so the translator knew when they were too long and had to be shortened. It worked remarkably well. We had a native Spanish speaker translate it for a Puerto Rican health care company. The client didn't like a lot of translations, because of differences in Spanish between the Puerto Rican dialect and whatever our translator spoke, and because of health care-specific terms -- so we shared the magic key combination with the client and they customized the translations to suit themselves. The client wanted a global search-and-replace feature: every time they change X to Y, change it on all windows. (There were about 35 windows.) We hadn't thought to build in that feature (and thought it was a bad idea, so we didn't want to build it into the framework), so we created a separate app to do that. This post probably isn't that helpful in the web era. I'm just being proud of a long-ago achievement, I guess. 
I second this - with the addition that using PO files are much more convenient IMO. It's not a Linux-only thing nowadays, we have some great multiplatform tools for it (like my favorite, POEdit) and there are some parser libraries available (I happen to be the author of [a Netstandard one](https://github.com/adams85/po).) But, of course, you can get along with Resx files, too. It's a matter of preference. &amp;#x200B; At the end of the day, what makes a big difference if you automate the process of extracting the strings to localize or do it manually. Doing the former is a massive time-saver and it's not a difficult thing to implement using regex or Roslyn. I saw this method in Orchard CMS first and I've been using it since then with great results. This is what really improves my translation process. If you're interested, you find more on the topic [in this SO post](https://stackoverflow.com/questions/52499874/add-localization-to-an-asp-net-core-2-0-application/52502761) and [in this article](https://github.com/adams85/po#real-world-application).
It really depends on the client. Enterprise level companies are usually slow to adapt new technologies and stick with what works. I‚Äôve worked on projects at several fortune 100 Finance/Insurance companies and have yet to encounter .NET Core. 
Thanks. Actually I was working with OrchardCore.Localization package and PO files. Everything was great until I found out a bug where data annotation error messages didn't switch after changing the locale. It was reported as a bug and then as fixed. But it still was happening. So I switched everything back to RESX.
OrchardCore.Localization nuget package version 1.0.0-beta2-69590 has a bug that made me switch. The data annotation messages were stuck in the first language they appear in.
if you wan¬¥t simple structure of an [asp.net](https://asp.net) core 2.2 mvc project here: &amp;#x200B; [i wrote this and i learn a lot](https://github.com/cetoxx/BlogCoreEngine)
Yup I already did that, actually I should have been more clear, what I meant by the differences is not the project configuration but things like DI cause I know that DI in .net framework is quite different than .Net Core. So yeah stuff like that. Sorry for not being more clear.
Yup, I'll refer to the docs!
Yup I know about those, thanks!
I used both, and I'm familiar with IIS, thanks üëç. Also can you still use app.Use() method to write middlewares or is it different?
Nope. Middleware was a new feature in .net Core. The .net MVC way of achieving this is using HttpHandlers and HttpModules. [HttpHandlers and HttpModules](https://docs.microsoft.com/en-us/previous-versions/bb398986(v=vs.140)) 
/u/FullerAwesome /u/ScrewAttackThis Here's the full [Active Directory authorization workflow](https://gist.github.com/JaimeStill/468fca767ffabb977346eff81e2ace0c) in ASP.NET Core and Angular.
Thanks, I'll look into it üëç
Learn the fundamentals of JS, SQL and CSS. React, jquery and bootstrap and SQL server are just technologies, which you will have a better understanding of if you know the foundations.
I love the Pro ASP.NET MVC book series. There should be one for whatever version you are on, and it will give you a really in depth understanding without being too daunting to get through.
I don't think it's a bug of OrchardCore.Localization. I use my own implementation yet encountered this issue. Unfortunately, localization of data annotations has always been somewhat broken (at least up to .NET Core 2.1 when I last checked it). However, there's many ways to workaround it. You can get some useful ideas from[this GitHub discussion](https://github.com/aspnet/AspNetCore/issues/4848) or do something similar to [my approach](https://github.com/adams85/aspnetskeleton/blob/NetCore/source/Web/UI/Infrastructure/Localization/DataAnnotationsLocalizationHelper.cs).
This is awesome! This will definitely prove useful for me later on.
I did something very similar. I created a WCF interfaced cache system that kept the translations close to the webservers which improved performance a lot. You wouldn't believe the speed of WCF with binary serialization over tcp or named pipes.
Check these github repositories: https://github.com/dotnet-architecture
as a starting point, look for the Controller classes. They are, for the most part, where a web request is first handled. You can start there and walk down the code to see how it dives into the core.
you can use asp.net core MVC on Mac. Start here: https://docs.microsoft.com/en-us/aspnet/core/?view=aspnetcore-2.2
Is it completely the same as Asp.net MVC 5? As I bought a course for it which I‚Äôm about to start
No, it's different enough that the course will lead you astray. Ideally you refund the course and get one for asp.net core 2.2. I think there MAY be a way to run MVC 5 with something called Mono but someone else will have to help with that since I have no experience there. But keep in mind that asp.net core is where the technology is headed. Some of the MVC 5 ideas will be transferrable, but if the course didn't cost much, just get a refund or eat the cost and find something newer.
Ah I understand. Thank you!
I think it's cool when you build something unique that suits your case! Thanks for sharing, I would be proud too.
You can write middlewares in old MVC using OWIN.
Glad it will help!
Thank-you! :)
Hi, I am a newbie to this kind of stuff. I'm working on a mac, how can I make windows domain to work? 
Unfortunately, this won't work on Mac. However, you can still use this app stack (ASP.NET Core and Angular) with a PostgreSQL database. And instead of using windows authentication, you can use an authentication provider, like Google or Microsoft, to get the same results. I've started a [series for this stack](https://medium.com/@jpstill85/full-stack-series-intro-510873f6e211) on Medium, and the [second post](https://medium.com/@jpstill85/full-stack-series-stack-demo-e973ac94b1bf) has an [example app](https://github.com/JaimeStill/FullstackOverview) using Microsoft as an authentication provider. Y ou'll just have to follow the PostgreSQL configuration steps.
Well, I thought so. Thanks for the posts anyways. I'll check them out.
I inject them between script tag and convert the string using JSON.parse. We don't do large SPA so we don't have problems of giant translation table problem. 
Project file is shit in legacy .Net
Please let me know if when you figure this out.
I got it working thx
I built a prototype of that same concept for the web a few years ago. It worked pretty well for the obvious things: enter edit mode, click on a translation-enabled DIV (they were highlighted on the page), and add your new translation. The URL contained the language code, so it was easy to see which text remained untranslated (English) and saving the changes to the database was easy. Unfortunately, "out of sight, out of mind" applies here - if a translator doesn't click on all the buttons and look at every view, they will miss some of the text that needs to be translated. It's also a challenge to translate temporary text (like short progress indicators). Nice work! I'm glad you were able to find a good use for the technique.
[removed]
ill definitely give this a read when im back at work tomorrow and see how it compares with what we do (which isnt much). thanks for the effort of putting this together.
No worries, glad to pass on the knowledge! Check back and let me know how it goes.
Try these samples - they are super small and very specific. https://github.com/dodyg/practical-aspnetcore 
I haven't tried but I think that cloning the git repo at https://github.com/dotnet/corefx would be the easiest way
Thanks for the tip, I will keep that link for future reference
Resharper does this. It will navigate to source, and if there isn't source - like there is for the BCL - it will decompile the assembly to show you source.
resharper does this for me. If I press on something like "go to implementation", it will either try to download or decompile the source. Very nifty and something I use decently often.
Thanks!!
As others have said, both Resharper in Visual Studio and Rider do this out if the box.
Think you need sourcelink: https://github.com/dotnet/sourcelink Haven't used it myself. * "Source Link is a language- and source-control agnostic system for providing first-class source debugging experiences for binaries. The goal of the project is to enable anyone building NuGet libraries to provide source debugging for their users with almost no effort. Microsoft libraries, such as .NET Core and Roslyn have enabled Source Link. " 
Id suggest you look at Mutli lingual toolkit - https://developer.microsoft.com/en-us/windows/develop/multilingual-app-toolkit I personally only used it with Xamarin at the moment, but im hopi g i can use it in other types of projects too - https://blog.xamarin.com/add-languages-to-your-apps-with-xamarin-and-multilingual-app-toolkit/ You can also get it to create the translations for you by hooking it up to Azure Transaltion API - https://azure.microsoft.com/en-gb/services/cognitive-services/translator-text-api/ Also it can export a xlf file which is a widely used format for translators to use, and when the text is imported it updates the resource files. 
You do realize that businesses move slowly right? I promise you the vast majority of ASP.NET sites in production aren't migrated to core. Not to mention, MVC is alive and well in core, and still makes much more sense than Razor Pages in a lot of use cases.
Just FYI, .NET Core is the future framework. There will not be another .NET Framework after 4.8
.. So you think what you learn today is still relevant in 3 years?
it will navigate to symbols. I know it's mostly the same, but because sourcelink is quickly becoming the go to method for library authors, we should be careful with terminology. SourceLink downloads actual source files from source repositories. Go To Implementation of ReSharper and Visual Studio (if you enable the experimental decompiler) does codegen with IL and PDBs if you have access to them. ReSharper's "download sources" downloads symbols not sources.
Sounds slick!
Wow that looks ugly. I hope nobody takes this serious
&gt; Pro ASP.NET MVC book series. Series? are you talking about the versions are does that have more than one book? I do have the version 5 and the book "PRO ASP.NET MVC 5 platform."
You can use [https://source.dot.net/](https://source.dot.net/) \- I know, it's not really integrated in your IDE but it will do the job. Also, if you need .NET Framework source code you can check out [https://referencesource.microsoft.com/](https://referencesource.microsoft.com/) as well.
Is this the programming equivalent of ‚ÄúI‚Äôll show you mine if you show me yours first‚Äù? Just browse Github for people‚Äôs profiles...
Visual Studio also does this without resharper.
You can set up Visual Studio to navigate to source code for you. There's an extension as well which overrides the F12 key to navigate to the referencesource site if you press it on a method from .net, and it's free too on the VS marketplace. Resharper doesn't give you the real source, it just decompiles on the fly. It can be pretty close though, or so I hear. It didn't really work for me. I'm on the mobile now but later I will google some links. Basically there's an option in VS, but it needs some setup, because .net only went OS relatively recently.
ok here [https://github.com/cetoxx/BlogCoreEngine](https://github.com/cetoxx/BlogCoreEngine) now send your github
I'm currently using heroku, you can create free web apps and there's also a free postgres db! It's also really easy to work with and comes with a lot of functionalities out of the box.
For personal dev and discovery: Azure with scheduled shutdowns in case I forget to shut it down manually. It costs a several dollars a month. If anything needs to be running 24/7 I‚Äôm hosting it internally or on the cheapest shared hosting I can find. If traffic and security becomes an issue then the project better be making money for me before I throw additional resources at it. 
I'm pretty sure there's a free tier on Azure as well. You might want to check that out.
AWS Lambda has an "always free" tier and supports .NET Core. I have a couple apps (node + .NET) using S3, Dynamo, Lambda, API Gateway and Cognito and my monthly bill is less than 15 cents.
Yes I use Heroku for Java and Node projects, but they don't support .net officially so I haven't try it. Do you deploy it with Docker or just push it on the traditional way and let Heroku decide the configuration?
No nothing does need 24/7 running time, they are just hobby projects so they can sleep after x min (like heroku).
I'm currently using an unofficial buildpack for .NET core [https://github.com/jincod/dotnetcore-buildpack](https://github.com/jincod/dotnetcore-buildpack) which works as expected.
I run a VPS on DigitalOcean. They have a $5 tier that should be more than enough to host simple hobby projects. (I personally use a higher tier because I'm doing a bunch of stuff on it, but I used the $5 tier in the past with no issues.)
Azure has free web apps. They work great 
I have a site that i pay $120 a year that gives me a database, .net and all sorts of other items. I have been using hosting services for my own sites for 20+ years since it gives me more control than say Medium 
FYI azure app service (like heroku) gives you 10 free sites perpetually . It works great for .net core and a multitude of other languages/frameworks. I also have a $5/month droplet on digital ocean and run a few personal projects there too.
What hosting service do you recommend for .Net Core?
I have been with https://www.webhost4life.com/ forever and a day, but since I have not worked with Core (I have been learning VR and have basically no knowledge of, I can't be of any help there. Sorry
I have been with https://www.webhost4life.com/ forever and a day, but since I have not worked with Core (I have been learning VR and have basically no knowledge of, I can't be of any help there. Sorry
I used gear host for a while. Free shared servers. 
AWS has lightsail. 3.50 a month 
Looks like a good vendor, very complete, except no .Net Core: &gt; ASP.NET 3.5 SP1 / 3.0 / 2.0 / 1.1
Same here. This buildpack works great! &amp;#x200B; &amp;#x200B;
Azure has a free tier. I use that for a playing. I know a guy that changed his default search to Bing, then used rewards towards his Azure account, not sure how it works though.
I use Azure App Service. You get 10 websites for free. 
Excellent work! I've had to write something similar, but not as elegant and full features as what you have done. We created an auth service that returns a token that has some of the user attributes including the ID. Then the main gateway service just requires a token, and does not need to be Windows Auth.
There is. It spins down periodically, so it can take a minute to load if you haven't hit the app in a while. Also, it doesn't support custom domains or SSL. But for hobby stuff, it's fine.
Thanks! This is the culmination of a lot of trial and error / streamlining my process over time. I've even been able to get a similar setup running with Azure AD. I'll probably put together another guide for how to use SignalR with this setup for sockets pushing to individual users.
VPS on Linode.com
for hobby sites I've never had an issue with the freebie azure websites. I then throw cloudflare in front to handle dns and improve perf. Runs great
Azure free tier
I use a couple of VPS on Aruba cloud. I pay about 1‚Ç¨/month per VPS. (It was the cheapest option I could find at the time.) At that price, the memory is a bit limited, but for Go (which most of my work is in), it's fine.
On a server in my basement running Docker. But soon I'll be transitioning to Blazor and just deploying on S3.
Simple mode for some of what you‚Äôre asking about: .Net 5 is .Net Core - a while back they decided instead of just making the next major iteration of .Net to instead took all they learned over the years and basically rewrite everything from the ground up. Microsoft has .Net Core ported to MacOS and Linux as well as windows. For a time they were not going to include the win forms api for it, you‚Äôd just make web apps and consoles, but I think external pressures convinced Microsoft to port win apis over... but don‚Äôt quote me on that. .Net 4.7.2 and soon 4.8.x should be the last normal iterations of the overall 4.x of the Framework and from there on .Net Core going forward for Microsoft. MVC is just Model View Controller pattern Razor pages is just the front end View Part getting the Data Model being passed by the Controller.
4.7.2 is the latest version of the full .Net Framework Runtime. Separate from that is the latest version of the .Net Core Runtime - v2.2. Both of those runtimes implement the .Net Standard v2.0 API. Next you have ASP.Net Core. The latest version is 2.2. You can create an ASP.Net Core application and target it to run on either the .Net Core Runtime - in which case it can be run cross-platform - or the full .Net Framework Runtime - in which case it would only run on Windows. The only reason to do that latter would be if your application had dependencies that are not compatible with the .Net Core Runtime. ASP.Net Core v3, which will be coming out maybe later this year or next, will not be able to target the full .Net Framework Runtime and will require the v3 Core Runtime. MVC and Razor pages are two different architectural styles for how your views and view logic/data interact. MVC is Model-View-Controller. MVC in ASP.Net Core is very similar to ASP.Net MVC v3-5 that runs only on the full .Net Framework. You'll have to forgive me as I'm not that familiar with Razor pages, but it think it is instead an MVVM - Model-View-ViewModel - pattern. You won't have much luck creating .Net Core applications with Visual Studio 2015. Use the latest version of 2017 or VS Code.
I have VS 2017 community. Didn't seem to be any reason to go backwards since I already was using that. I have VS code on here too. Thank you that was a good explanation
I first through MVC (as in .net mvc) went away with core, but it seems like it is still part of it. (I'm coming from a webforms background, which was completely different)
Not as far as I know... actually made a .Net Core MVC app earlier in the day as I was playing around with IdentityServer 4 for the first time. It probably isn‚Äôt going anywhere. But you will find people boosting WebAPI tho, and those who preach that will probably advocate something around AngularJS or ReactJS or other popular JavaScript libraries.
Thank you! I don't have anything yet. When I do, you'll be the first to know. 
This is why I love the .net community so much. Everyone is just so kind. 
Thanks for the recommendation! I'll have to take a look some time 
I host them on a Raspberry Pi. Works perfectly. It doesn't seem to have any trouble although my hobby projects are pretty light weight. 
Normal caveat for answering questions like this - these are my opinions only, although they are based on weekly experience with Blazor since 0.5. Firstly note that only server side Blazor (now called Razor Components) is worthy of your time at the moment. This dictates dot net core 3.0 and VS2019. Do not be tempted to try getting Blazor working in its dot net core 2.0 form, because you will be wasting your time. Also do not be tempted to dabble with client side Blazor at this stage - there isn't even a joe public way of doing so for 3.0 as far as I know. Note that google is your enemy now. Because Blazor has changed so dramatically over the last year or so, many of the answers you will find searching are just completely wrong now. I tend to go search in the AspNetCore issues section in github as a first port of call. There is an active Gitter community for Blazor where some friendly people will happily answer or ignore your questions! &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B;
Fyi azure has a free allowence on azure functions as well
I'm not sure if I misunderstood you, but the most recent 0.8.0 release of Blazor only supports the most recent .NET Core 3.0 preview. I also noticed they've loved their docs to [docs.com](https://docs.microsoft.com/en-us/aspnet/core/client-side/spa/blazor/get-started?view=aspnetcore-3.0&amp;tabs=visual-studio) 
Indeed I had missed the 0.8 release (which was only earlier this month). Primarily that's because I'd moved to server side as all client side development appeared to stall after 0.7. So I take that comment back - play with client side all you like!
I'm assuming they've been waiting for 3.0 bits to drop
Droplet on digital Ocean. The cheapest one is 5$ a month, and it is capable of hosting many of your hobby projects on the the server without any problems. Then you can very easely get ssl with let's encrypt. And if your project turns into something bigger, it is very easy to upgrade and scale. 
I have 12 working samples for Blazor (https://github.com/dodyg/practical-aspnetcore/blob/master/projects/blazor/README.md) and 4 working samples for Razor Components (https://github.com/dodyg/practical-aspnetcore/tree/master/projects/3-0) Try them out to get a feel of the framework.
Thanks for the tip. This tool looks a lot like RESX Manager plugin for visual studio.
my home server
i personally love heroku :) 
Your post has been removed. Self promotion posts are not allowed.
Confirming a Pi works just fine for hobby projects.
For me this is similar to driving a car. You learn more after you pass your test and go out on the road alone. That's when you become a better driver. You don't have someone holding your hand.
You can run MVC5 on macOS and Linux if you absolutely must (I wrote about it \[here\]([https://coderscoffeehouse.com/tech/2016/01/19/aspnet-linux-setup.html](https://coderscoffeehouse.com/tech/2016/01/19/aspnet-linux-setup.html))) but I wouldn't advise it, especially if you're a novice. [ASP.NET](https://ASP.NET) Core is the way to go.
Note: not conventional use of word roadmap
Yeah it's a wrong title
Should be "Roadmap for learning ASP.NET Core in 2019".
sry english is not my native language how can i edit the title
F
No, .net core is not .net 5, there may very well be a .net 5,6,7 etc still or it may be the death of .net, but either way it‚Äôs all but a .net 5
Maybe something enjoyable like needlepoint or French cooking?
I'm in the same boat. It appears that Microsoft have updated the syllabus, but haven't yet released any study materials. 
You can't. But you should be able to edit the text to clarify this.
Despite its naming, its a solid path to glory.
I was like, "Really?" when I first read your comment - but I looked it up and you're right. My memory of .Net Core becoming a thing was friends in the .Net world at the time were telling me ".Net 5 is being worked on" and then ".Net 5 is going to be renamed .Net Core". Saw some presentation talking about .Net Core and the naming schemes and I was like, "Well, that's Microsoft Naming Patterns again." Always kind of stuck with me that .Net 5 (though apparently, it was .Net Core 5) getting renamed to .Net Core seemed kind of natural. Thanks man for correcting me. /u/marzdarz - apologies for the mislead
Well to be fair their communication on the future of .net is a complete mess
This question comes up here a lot, so I [wrote a blog post about it](https://mking.net/blog/cheap-and-easy-aspnet-core-hosting) The gist is as follows: [Azure](https://azure.microsoft.com) is your best bet - it's easy to use, and has the full weight of Microsoft behind it. Deploying can be as simple as a `git push`. There is a [free tier](https://azure.microsoft.com/free/) for 12 months. After that, you can get 'free forever' Azure App Service instances that have a few minor drawbacks (shared hosting, no custom domains, etc.), or you could pay for some of the cheaper shared instances. If you want more functionality, moving up to the other paid plans is definitely worth it, there are some great features there. Scott Hanselman has a great post - [Penny Pinching in the Cloud](https://www.hanselman.com/blog/PennyPinchingInTheCloudRunningAndManagingLOTSOfWebAppsOnASingleAzureAppService.aspx) - that covers the best way to get a good bang-for-your-buck from Azure App Service hosting. The next best bet is to host on a [DigitalOcean VM](https://www.digitalocean.com/). You can use [Dokku](https://github.com/dokku/dokku) to get your own mini-Heroku PaaS, or manage the VM yourself ([following Microsoft's documentation](https://docs.microsoft.com/en-us/aspnet/core/host-and-deploy/linux-nginx?view=aspnetcore-2.1)). You can get anywhere from $10 to $100 in credit from a [referral link](https://m.do.co/c/aac4e1b54a04) - this will last you a year and a half with a small VM. [Heroku](https://www.heroku.com/) is another good option. Their product is rock solid, easy to use, and has a wide variety of pricing tiers (including a free tier and an inexpensive hobby tier). You can deploy ASP.NET Core apps using a [.NET Core buildpack](https://github.com/jincod/dotnetcore-buildpack), or using their [Docker](https://devcenter.heroku.com/categories/deploying-with-docker) functionality. 
Couldn't your class just have a getter that returns a collection of what is has as a List of ComboListItems? Also you can set the SelectedItem when instantiating the ComboListItems, no need for a special condition.
While everyone's answered most of it, if you can, start working in .NET Core if you want MS' updates to the C# language and new features. They will slowly stop supporting .NET Framework (which only runs on windows) when? Who knows could be 10 years could be 3. As for Razor Pages, it's similar to web forms where you have a "code behind" like page that also acts like the model. It kind of takes the best parts of MVC and some of the ok parts of web forms for creating quick pages without a lot of boilerplate, or allowing them to exist in isolation. See here for more: https://docs.microsoft.com/en-us/aspnet/core/razor-pages/?view=aspnetcore-2.2&amp;tabs=visual-studio
.NET Framework 4.whatever is the last major revision of Framework. Any additional releases there will be incremental. I haven't created a new Framework project in at least a year. MVC is not going away, it's in Core, and, if we're being honest, I prefer over Razor pages. Razor is the template engine designed for MVC. Razor Pages is, as the other person said, a different design pattern. Basically just think of it like the base class is a combination of the view and controller and it's pretty easy to get the hang of. It reminds me a little (very little) of old school ASP. Core has no native GUI framework. Core 3.0 will support a package for doing XAML on Windows, but that package will not be cross platform. For the time being, if you're doing cross-platform apps, they'll need to either run as web apps or console apps. Source: am Microsoft docs author. 
Web API would be the way to go if you're sticking to app building along with a front end technology. React and Angular are both very popular. 
Yet there‚Äôs absolutely no official statement of that. Can‚Äôt you move things internally to get such a statement out?
I responded to the wrong thread on this post (hard time seeing my phone lately, need a new prescription), but please see my other comment. MVC is still around and isn't going anywhere, but Razor Pages is the new thing. 
This is just spam. 
Yeah he usually releases one for each version, and then books about similar technologies and concepts, like the platform one you mentioned, Pro Entity Framework for ASP.NET MVC, etc.
How does one find time to study books while working? 
I have talked to my boss and gotten a percentage of my time earmarked for professional development, so they order me books and I can read them at work. Otherwise I guess you would have to just read them an hour or two at a time in your free time. The Pro ASP ones look daunting because of their size but there are tons of code and html examples in them that bulk them up, they are pretty easy reads.
Would a developer that knows most of this stuff and uses it could be considered a senior? Asking for a friend.
Are they good enough for professional work? 
Disclaimer: I didn't do this in a while so I'm not sure if it (still) works in .NET. What I used to do was the following: 1. Create a class with a set of properties in it 2. Override the ToString method in the class (this is the 'text' property in your case) 3. Add the list of items to your combobox 4. When selecting a different item, the selected item will now be a cast-able object which doesn't require you to search for a specific value, instead you can immediately retrieve the value property of it. &amp;#x200B; A different approach (which seems very overkill for me): 1. Create your class as usual and have each value property uniquely defined 2. Create a hashmap (Key,Value pairs) with the (Object.value, Object pair) 3. Search in the hashmap based on the value you expect &amp;#x200B; I'm not sure if I understood your question fully but I think this might help a bit at least :)
Definitely. The concepts they cover and the examples they use will give you a very good foundation that will apply to most line of business applications.
I would recommend a series by Mosh Hamedani &amp;#x200B; 1- Become a Full-stack .NET Developer [https://app.pluralsight.com/library/courses/full-stack-dot-net-developer-fundamentals/table-of-contents](https://app.pluralsight.com/library/courses/full-stack-dot-net-developer-fundamentals/table-of-contents) &amp;#x200B; 2- Become a Full-stack .NET Developer - Architecture and Testing [https://app.pluralsight.com/library/courses/full-stack-dot-net-developer-architecture-testing/table-of-contents](https://app.pluralsight.com/library/courses/full-stack-dot-net-developer-architecture-testing/table-of-contents) 3- Become a Full-stack .NET Developer - Advanced Topics [https://app.pluralsight.com/library/courses/full-stack-dot-net-developer/table-of-contents](https://app.pluralsight.com/library/courses/full-stack-dot-net-developer/table-of-contents) &amp;#x200B; I also would recommend other Mosh courses which are not on Pluralsight but you should be able to find them on Udemy. &amp;#x200B; &amp;#x200B;
Thank you all very much. There is no hurry for me to learn something ASAP. So no problem playing with actual version. But my main question still remains unanswered. Will i understand Blazor without actual knowledge of [ASP.NET](https://ASP.NET) core, for example? 
If you're not building the backend, yes. ASP.NET Core works very well as a backend for Blazor apps, especially since you can share type definitions across the projects, but Blazor's conventions are its own thing. ASP.NET Core knowledge doesn't hurt, but far from necessary. 
If you're not building the backend, yes. ASP.NET Core works very well as a backend for Blazor apps, especially since you can share type definitions across the projects, but Blazor's conventions are its own thing. ASP.NET Core knowledge doesn't hurt, but far from necessary. 
Yea /u/imkizidor has the right idea. I love Mosh's courses on Udemy. Pay once for the course then any time you feel like you need to brush up on it there it is. I'm a big fan of Mosh's courses. 
Even for smaller ones there may be benefits, but it‚Äôs not always true that async would be better. It definitely shows more in bigger ones where server threads aren‚Äôt just sitting there waiting for things, but if your operations don‚Äôt take long it may even be worse to use async. For example, if a database operation is super fast it may not be worth it to throw it into async land at all. Could you also show examples of the parts that for you caused trouble in converting, so others may benefit from your experiences? Or maybe there‚Äôs even something that could be done differently. 
Just passed 70-486 last week. There are no official study materials to use. You want to be pretty familiar with MVC 5 and Core and you want to know a good bit about **everything** they list on the exam page. Once you feel you have a good grasp of **everything** listed, I would strongly recommend using the mindhub practice exam. Don't use it too early because it only has so many questions and you don't want memorization of their answers to affect your ability to assess your readiness. I have done work in core but decided to buy a book for it anyway to dive a little deeper. That wasn't really necessary. I watched a lot of pluralsight videos on Core/MVC/Security. The mindhub answers have links to MSDN pages to learn more about topics. There are a few CSS/JS questions so having taken the 70-480 first helps. Honestly, the exam page very accurately represents what you need to learn. Unfortunately, if you don't already have experience working with a lot of it, you're going to have a bad time. Here are a couple blogs from 2015 and 2016 about studying for it. Keep in mind that the exam was updated last year so reference the change docs to make sure you study the new stuff too. If you're new and this seems like a lot, it is. But take a deep breath and work through each sub topic one at a time. [FailedTheTuringTest](http://failedturing.blogspot.com/2016/05/microsoft-exam-70-486-study-guide.html) [BarbarianMeetsCoding](https://www.barbarianmeetscoding.com/blog/2015/05/25/a-short-study-guide-for-the-70-486-developing-asp-dot-net-mvc-applications-exam) It was a hard exam to study for. 
I already have a custom class "ComboListItem" that have a value and text property. I load those into the combobox.items.add(X). But what I am trying to do is when I load a master record IE employee record I want to select corresponding value's in comboboxes using a collection.indexof instead of for eaching thru the combobox values until I find a match then selecting please see code example. This seems very wasteful especially if the combobox has tons of values. &amp;#x200B; Dim ls\_CodeFromMasterRecord as string ls\_CodeFromMasterRecord = datareader.item("txt\_employee\_state") For Each c As ComboListItem (My Custom Class) In Me.ComboBox1.Items If c.value = ls\_CodeFromMasterRecord Then 'c.Value will have the State Code 'c.Text will have the ComboListItem display value Me.ddlb\_Fac.SelectedItem = c exit for End If Next So, The above code works just fine. BUT I am trying to make it faster by casting the generic collection held in combobox.items() to a collection of my custom class ComboListItem and using a .IndexOf instead of for eaching my way thru the entire combobox list items
I personally wouldn't choose it. It's so early in its life cycle there will likely be lots of breaking changes as versions come out. But I would add javascript to that list. Your almost always going to need some.
Thanks. I added examples of the issues I ran into.
I think they thing are not clear internally at MS. Maybe some want core to take over and others want .net framework 5 
To the untrained eye, it might seem that way... But to a thread master, who breathes async for a living and exhales threads, it's all worth it. 
I've never seen the need to use TransactionScope. Why do you need it? How do you measure that it's working or not working?
c# 8 solves the foreach problem
Not necessarily. You have to have working knowledge of 90% of this to be a decent mid level developer. 
&gt; asp.not IDK why but this really amused me. ASP.NET is a framework for developing web applications in C#, and is based on (a subset of) .NET (dotnet) which is a framework for developing general C# applications. You've got different variants of these frameworks, though. .NET Framework is the older runtime which only runs on Windows, whereas .NET Core is a more modern and cross-platform runtime.
If you're doing multiple updates to the database and need to rollback if you get an exception. How do you measure that it's working? Run an update and then throw an exception before you do your ts.Complete() and see if the data changed. Hint: It doesn't.
Oh, that's good to know! Still a pain...
But... is it worth the pain to a non-thread master?
This might be safe with small numbers of items, but without knowing about whatever constraints might exist on how many items might be in "appointments" you could easily exhaust the thread pool going with this approach.
So it's more of a DB layer then than an ASP.Net thing, did I understand that correctly? You still need it in your pipeline, so I get why you mention it. 
While to an extent this is personal preference, \`List&lt;T&gt;.ForEach\` is a fairly useless method. An actual \`foreach\` loop (using language conventions like you've shown here) is lighter-weight, and it also doesn't have gotchas like you've pointed out here--your example doesn't work because your call to \`ForEach\` above doesn't (can't) wait on a particular execution to complete, so it's going to start all of the functions as fire-and-forget.
That's what I learned from this exercise.
That's correct.
I don‚Äôt know about web apps. In a mobile app made with Xamarin, it is absolutely impossible not to use async methods. One had to decide case by case!
There is no other path to the dream that is being a thread master. We get discounts on MSDN. You'll get there my friend. 
You can write a ForEachAsync extension method if you want that just returns Task.WhenAll(enumerable.Select(action)).
Easier than classic threading code.
I don't know the current situation, but originally UWP was supposed to be that way as well. 
That sounds horrible. You really should look into doing batch updates instead of processing one record at a time. You'll spend more time on network I/O and logging the database than you'll spend doing the actual updates.
HttpClient only has async operations now, so you pretty much have to if you‚Äôre calling third parties.
It might not be everybody's opinion, but the old "stop and wait" paradigm is perfectly serviceable. Ifn you scale up, there's some benefit to going async (especially with `.ConfigureAwait(false)`) to give you some extra scalability, but the big win is in cases where waiting causes incidental problems (like freezing a GUI because you're opening a file on the main thread) or where you've got multiple remote resources you're pulling in (this is possible with threads, but relatively inconvenient because all the ergonomic development went into async/await).
That's not just a personal preference, Microsoft's position is that it was a mistake. Which is why we don't see a `IEnumerable&lt;T&gt;.ForEach`.
Why would it exhaust the thread pool? The whole point of a thread pool (original or Task based) is that you can queue up as many items as you like and the runtime would decide how many threads to use. With async operations, it shouldn't even max out the number of threads (default max is 100). The intent is that it will only spin up new threads if it has a lot of threads waiting on blocking operations (i.e. pre-async/await).
Your situation may be different, but here in the US, nobody seems to care about certifications any more.
The main thing about `TransactionScope` is that it libraries are supposed to silently honor it so you don't have to manually manage transactions in the DB code. This is especially helpful when making calls across multiple, transactional dependencies. You could, in theory, have a transactional message queue not permanently remove items until the database commits. 
Be sure to take the course on udemy, you get no help in teachable
The subject is interesting ; however this is difficult to read. 
It was taken down over this weekend (2019-02-23). It doesnt appear that it was a DCMA, fwiw, but the backend API was also disabled so even the EXE is largely unusable. 
Specifically to thread pool exhaustion, what you've expressed is the general idea but it does not always happen that way in practice. Furthermore, the thread pool is not a local resource--it's across the entire process, and we have no idea what other processes are using it (such as for async completions...). Other components will also throw exceptions *if the thread pool is low*, which (regardless of how anyone feels about that as a design decision) has to factor into how the thread pool is used. More generally, unbounded parallelism that is managed by something that doesn't have to consider specific use cases (e.g. dumping everything on the thread pool and letting the runtime sort it out) is something that sounds attractive because it's easy but is rarely advisable. For instance, we have no clue what UpdateApptResource does, but I would *bet* that at some point it allocates a SqlConnection object and calls Open. Which, under out of the box configuration, will either open or repurpose an existing hard connection against the SqlClient connection pool. Another example of a transparent shared resource coordinator, though at least in this case it's local to the connection string being used. Maybe we have 10 items in that list. Maybe we have 200. Maybe we have 1,543,545. We don't know. But you can bet that as that list grows, your rate of exceptions where calling [SqlConnection.Open](https://SqlConnection.Open) times out while waiting for an open connection from the pool. All because we paralleled something without sanity checks and guardrails around how many to try to do at one time. The point is we have no idea how many items would/could be in that list, nor to we know what the function does. We can't blindly throw the whole collection at the thread pool and say "Well, the runtime should figure it out!"
 foreach(var appt in appointments) { await UpdateApptResources(appt); } Does that execute sequentially or does each call to UpdateApptResources immediately return a Task object, allowing the loop to complete potentially before the first call to UpdateApptResources has completed?
To provide a source for this: https://blogs.msdn.microsoft.com/ericlippert/2009/05/18/foreach-vs-foreach/ Very good read.
It may not "exhaust" the threadpool in the sense of "the threadpool isn't making use of the available CPU cores despite having work to do", but shoving huge numbers of tasks into the threadpool does tend to break the "if I put something on the threadpool it'll likely happen sometime soon" expectation of code that uses the threadpool (such as timers).
Why it's difficult? 
Parallel.ForEach() not cover what you need?
await Task.Run(() =&gt; Parallel.ForEach(strings, DoSomething));
Have you heard of this little thing called ASP.NET? It allows for a virtually unlimited number of requests to be thrown into the queue, each of them waiting for a thread-pool thread. If out current situation was really as dire as you make it out to be, async/await and ASP.NET wouldn't work. 
This is also handy for async for each https://github.com/Dasync/AsyncEnumerable Yeah it's a pain, but less of a pain than your web server 503'ing because the request queue overflowed while your db was transiently unavailable.
True, but you wouldn't be using this pattern in the first place unless your goal was to get a single logical task done as quickly as possible at the expense of all other tasks. 
Thanks, that's the one I was thinking of.
That removes the concurrency advantage of using async/await. `DoSomething` will be processed synchronously, blocking threads for each I/O call. But if your only goal is to not block the UI thread, then it's not a bad idea.
Databases are really expensive on Azure and AWS, but I've found they're 1/3 of the price at Google Cloud. Besides that, beware of the free tiers - to my knowledge it's a bit of a loose term. I always end up paying a bit more than I anticipated for the lowest of the lowest tiers.
How do you manage to get them for free? In my experience I always end up paying, even for the supposedly free tiers. I might be doing something wrong. I'm talking about deploying a .Net Core 2+ Web Api project.
I use a app service plan on the free dev tier. 
&gt;Have you heard of this little thing called ASP.NET? &gt; &gt;It allows for a virtually unlimited number of requests to be thrown into the queue, each of them waiting for a thread-pool thread. I have, which I think you know, and I don't really think the level of snark in this response is constructive. I'll answer this, but I don't have an interest in engaging in a battle of sarcasm. I don't intend to make out the situation to be dire, but I am suggesting that the idea of "I have a list of unknown (to us) size, and I need to do something (with unknown implementation and side effects) to each element of the list, so I'll throw them all onto the thread pool at the same time without regard for either of those unknowns" is unwise. Particularly when it is suggested as a drop-in solution for OP's current code, which is completely sequential, without calling out what it will actually do to someone who doesn't (I assume) have intimate familiarity with what async/await actually *do*. Your [ASP.NET](https://ASP.NET) analogy is a red-herring. It is well-known that [ASP.NET](https://ASP.NET) handles requests concurrently and that developers should consider the fact that requests can/will be attempted to be run in parallel (whether they SHOULD consider this is different from whether they DO). Furthermore, there are limits (both practical and technical) to how many operations can be run concurrently or queued, and the implications of queuing them.
The await causes this to run sequentially. Without the await, it would invoke the function and move onto the next element as soon as the first Task object was returned from the function (if that function is async, then essentially as soon as the first await is called in that function)
I also really enjoyed Pro [ASP.net](https://ASP.net) MVC 5. I started building "professionally" by just searching with only basic understanding of MVC 5 and some knowledge of c# language(I did have CS degree but mostly used java). It was rough but I made things that accomplished the required tasks. Code was trash, maintenance is a nightmare. Now, I make improvements when I need to change something. I read the book after making all the mistakes and I think it is great. Author covers building a complete application with mocking/unit testing, explains things in good detail too.
Sequentially, because of await. If you wanted concurrent execution you could do something like await Task.WhenAll(appointments.Select(UpdateResources)); However depending on what UpdateResources does, you could very well be shooting in your own foot. I would advise extreme caution 
I started with MVC 5; you can watch all the plural sight videos in the world but getting your hands dirty is really gonna help you learn the most. &amp;#x200B; Learn Dependency Injection Really well; its tough to setup correctly and to choose a container Learn Unit testing with DI and how to build the necessary mock objects Learn the Routing Engine for MVC5 (not super challenging but powerful) Learn how to write custom model binders for MVC5 Learn the tools needed to work with creating webservice objects and REST clients for MVC 5. These are built into VS Learn the OWIN pipeline and how to write modules for it, or if you are using Katana if you should migrate Learn Identity, and how to manage sessions Learn some of the design patterns used in .NET, objects for accomplishing common tasks Watch Clean Code (they have a Core and MVC 5 version of this) for project structure and organization, download the sample application Learn the CQRS pattern (not saying you should use it but its good to know it in case it fits your project, covered in Clean Code) Learn how to write custom model validators (they do a good job of this in clean code) Learn how to do all of the Entity Framework configurations (some cannot be done with data annotations) are you doing code first or database first? Learn how to do migrations or manage the db first model in an easy way. Learn about Domain Driven Design and Onion Architecture (this will be a godsend when you are doing planning) Learn about Microservices, and how to break applications apart (building aggregate roots and different applications) Learn about Nuget Package Hell and how to avoid it, sharing projects between solutions and dependency versions can be crippling a couple of years down the road Learn about a UI framework, React, Angular, Kendo, or Jquery UI. You are gonna have to display the data and just knowing MVC is not gonna cover this Study up on Javascript, you are gonna have to use it a lot to update the UI of your application or work with your UI framework, learn the differences from JS and ES5 and ES6 and what you need to do to maintain compatibility with different browsers (Typescript is also an option) Learn about the Bundler, this helps bundle and minify scripts at runtime, how to configure it to use CDN's and how to build fall back logic to load scripts from your server when a CDN is down Learn about build scripts, dev ops is key to not spending an entire night deploying What hosting environment are you using? Learn how to configure it; and how you should deploy. Are you going to use Docker? learn how to set that stuff up now Learn how to use the HttpClientFactory, short story too many instances of this class is bad and they have a new implementation that uses .NET Standard Learn about .NET standard and its compatibility with .NET framework 4.7.2 projects (this is still MVC5) you can get the benefit of many .NET Core technologies from new packages that implement this. And then you will also be setup for .NET Core when you can make a project using that Are you going to be emailing things out from the application? Pick a 3rd party API and write up and integration for it like sendgrid. Will the applications need processes that run on a schedule? Learn about how to run console apps that are jobs on your server, if using azure learn functions or webjobs. Functions are just that that can be triggered where as a webjob is a full app containing Functions. Use them for nightly tasks Learn about message queues and why you need them, how they help with long running tasks or 3rd parties that may not be available. Learn about exception handling, should you throw them? Should you catch them? How to setup a global exception catching setup. Learn how to setup a logging framework, Log4net was the main pick for many years on MVC5 but many others have popped up with .NET core. I restructured the wrappers and configuration I use to be used in .NET core and this also works in MVC5 as I used .NET Standard. Consider learning about a 3rd party caching technology and how to setup a Session State Provider, if your app is scaled to multiple instances then you cannot guarantee the server the user hits is always the same one and will need to be able to maintain a consistent session. Something like Redis Think you may need to do testing at the browser level, learn about automated browser testing using something like selenium &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B;
SFML isn‚Äôt a game framework. It‚Äôs a multimedia framework. Think of this as one level lower level than monogame. You‚Äôd use this if you wanted more control over the architecture of your game. 
This isn't accurate. [Task.Run](https://Task.Run) would indicate to start on a new thread pool task, but simply selecting tasks will not do this.
Spelling and grammar mistakes all over the place. Makes it difficult to read and process.
The point is that we don't know *what* will happen because UpdateApptResources (which, if async, should have the Async suffix) is not available to us. If, for example, its first await is for IO-bound activity, we may well exhaust/flood the IO completion thread pool. If its first await is for CPU-bound activity being invoked via [Task.Run](https://Task.Run)(), we might exhaust/flood the user thread pool. Or we might allocate too many threads if they're declared as long-running. The point is we have no idea what any of it does and suggesting this as a "try this first" option (particularly without disclaiming the enormous difference between this solution and what OP's code does) is not smart.
I now see what you mean - I would have said that it's the most correct approach and efficient for having good async code run in parallel across a collection. The code itself there doesn't specifically do anything to eat up threads. You're just saying it facilitates shooting yourself in the foot if the collection is big. I agree - whether using async or plain old threads / thread pool work, running a large number of things in parallel is a bad idea. But async would be the better way to do it, right? 
What does UpdateApptResources do? 
Exactly; if what you truly want to do is say "I want to run an async method for every element of this list regardless of any other considerations (number of items, ordering, side effects, etc.)" then yes, this would be the most correct and idiomatic way of doing that. It's just that from a practical perspective unless your list is of trivial size (and you know that this is somehow enforced) and the operation is trivial you are probably better off approaching the parallelization in a more intentional way (with some kind of throttle, whatever synchronization primitives are needed, etc.)
&gt; The whole point of a thread pool (original or Task based) is that you can queue up as many items as you like and the runtime would decide how many threads to use. What???? No!!! The point of the Thread Pool is that you don't need to create new threads for a bunch of small asynchronous operations. Thread Pool growth is gated at 2 new threads per second. And for good reason. If you don't understand why, spin up a million new `Thread` objects doing SpinWait() and see what happens to your operating system. If you "queue up as many items as you like", you *will* exhaust the thread pool. This is absolutely one of the top performance mistakes people run into. You'll see something simple like Task.Run( () =&gt; Thread.Sleep(5) ) take 30 seconds or more to complete, because it's waiting on a ThreadPool thread to become available.
&gt; If out current situation was really as dire as you make it out to be, async/await and ASP.NET wouldn't work. "Virtually unlimited" is nowhere near correct. `async/await`, by itself, doesn't mean you're using a ThreadPool thread. That's one of the great things about it. e.g. HttpClient.GetAsync() is using native IO and doesn't use a ThreadPool thread, but anything started with Task.Run() does. You will run into ThreadPool exhaustion any time you are receiving new requests faster than your ThreadPool threads can execute plus 2/sec for a sustained period of time. ThreadPool exhaustion is probably the #1 cause of "it worked fine until the load increased and then it fell over completely and everything stopped working".
It is an abomination. 
What's blocking you?
You say this, but I've had several harrowing discussions over the last few years about why "A processor can't work at more than 100% of its potential". 
Your still dealing with the overhead of spinning up threads, which is not insignificant. Setup a concurrent for loop of your own and limit the threads to the number if logical cores your CPU has...
&gt; If you "queue up as many items as you like", you will exhaust the thread pool. What? You think the thread pool is just going to lie down and take a nap? No. The tasks will be queued up until the thread pool gets around to them.
Indeed. Contrary to naive reasoning, doing things in parallel is often slower than doing them sequentially. More specifically, doing things in parallel badly in your own code doesn't scale as well as doing things sequentially with async/await and letting the webserver handle multiple requests in parallel. It will shave time off of an individual request at the expense of overall scale. Sometimes, that tradeoff is necessary. But if you think it is necessary to spin off an unknown number of tasks to do a bunch of parallel work, seriously consider dropping that parallel work in a queue and processing it out of process.
[Says otherwise here](https://docs.microsoft.com/en-us/dotnet/api/system.threading.tasks.task.run?view=netframework-4.7.2)
You mean agrees with me entirely? Read what I said again
&gt; Thread Pool growth is gated at 2 new threads per second. If it actually does that until you've spun up all hundred threads (or whatever max you have set) working on CPU-bound tasks then performance is going to suck. Ideally it only runs one thread per CPU, but that's not always an option if you have I/O blocking a thread. &gt; If you "queue up as many items as you like", you will exhaust the thread pool. What? You think the thread pool is just going to lie down and take a nap? No. The tasks will be queued up until the thread pool gets around to them. Thread pool exhaustion is a problem when you are using blocking I/O and all of the threads are blocked. This is NOT an issue with non-blocking asynchronous calls. &gt; Work Stealing Queue &gt; &gt; Let us assume that worker thread 1 completed all of its tasks in the queue. It scans the global queue for any task and if nothing there, it scans other worker thread‚Äôs local queue. In this case, let us assume there are two tasks in WT2 queue. WT1 enqueues first-in task from WT2 queue which avoids contention issue. Getting tasks from other local queue is called as work stealing. This again results better performance. http://udooz.net/blog/2009/08/net-4-0-work-stealing-queue-plinq/
What you did there, I saw it.
&gt; You will run into ThreadPool exhaustion any time you are receiving new requests faster than your ThreadPool threads can execute plus 2/sec for a sustained period of time **AND you have blocking I/O preventing the threads from doing work**. That last bit is rather important. 
That was my concern; does anyone even look for certs anymore? I know they used to be considered a big deal since MS ones were known to be difficult. But now 6 month developer bootcamps prep their students for entry level MS certs. 
I think I'd wait for the c#8 support personally. This is based entirely on a very bad time with the old Wintellect async-y enumerable-y library. I'd rather fix the db performance issue, it's a better investment of time imho.
I am of the opinion that you can't really know something until you've implemented something meaningful in MVC5. You can read the theory all day but until you've applied what you've learned you may not really "know" it. I'll admit everyone learns differently though! Since I don't really know your background, I'd also suggest reading https://www.manning.com/books/c-sharp-in-depth-third-edition 
The whole point of `Parallel.ForEach` is that it will use the thread pool, nearly eliminating the cost of spinning up threads, and take into consideration the number of logical cores. Of course you still have to pay for "the overhead costs of partitioning the source collection and synchronizing the worker threads". https://docs.microsoft.com/en-us/dotnet/standard/parallel-programming/potential-pitfalls-in-data-and-task-parallelism 
Thanks, I'll check it.
Ah I see what you mean now, makes sense.. Not sure if there‚Äôs a better option. Have you tried filtering before in your custom class collection and then just casting that to the combobox selected item? Not sure if that‚Äôs possible but it would probably be quicker at least I think.
You do not need to create a dedicated class for that. You can add your underlying objects directly to the combo box and then you can assign the underlying object directly to the SelectedItem property. As the other guy said you override .ToString to control the text displayed in the ComboBox for a specific item.
I'm so sorry, you are absolutely right. I'll edit my response :) 
I have heard about this book but the instructors who taught me MVC told me that only a basic knowledge of C# is sufficient. Should I learn C# in depth or not?
Work experience is more important. If you don't have that, you should work on your Github portfolio. It's easy to look at hobby projects and contributions to open source projects to get a feel for a person's talent level.
If you are doing sql transactions that are sometimes rolled back, I would not do Async. What benefits does it get you?
If you have to breathe a feature for a living to use it correctly, its a bad feature and should not exist.
Message the admins about it. I flagged it on botbust already.
While that is the main cause of work not finishing, the statement is true regardless of the reason. If you are not releasing ThreadPool threads faster than requests are coming in, you will eventually run out.
Aside from the extra overhead involved with having too many threads running at once, once you do hit the threadpool limit, you can run into unexpected deadlocks. Basically, if enough threads block waiting on threads that can't run due to being indefinitely queued, everything halts. It's a very rare issue but I see it occasionally crop up in libraries as edge cases.
&gt; Thread pool exhaustion is a problem when you are using blocking I/O and all of the threads are blocked. This is NOT an issue with non-blocking asynchronous calls. It is if you're wrapping those calls in a Task.Run() to do naive parallelism. &gt; No. The tasks will be queued up until the thread pool gets around to them. And when "until it gets around to them" becomes longer and longer, eventually your service falls over. If you're hitting the ThreadPool expansion limit due to high traffic and it starts being a cause of slowness and that high traffic is sustained, that quickly cascades into everything taking longer and longer and a deeper and deeper queue until you're spending almost all of your time processing requests that have already timed out from the client side.
Yeah.... in my experience `Parallel.ForEach` is horrendously slow, I've gotten much better real performance out of managing my own parallel loop. Not that it doesn't have it's place, I just wouldn't use it anywhere where you need a tight loop.
Is this a joke?
You are right. The async model in dotnet has added a lot of complexity for potential performance benefits which most people probably don't need. Your example is even on of the more simple problems (which gets solved in the next c# version). &amp;#x200B; At NDC 2018 David Fowler &amp; Damian Edwards talked an hour about everything that can go wrong, working with async/await [(video)](https://www.youtube.com/watch?v=RYI0DHoIVaA) . Then there is this [async guid](https://github.com/davidfowl/AspNetCoreDiagnosticScenarios/blob/master/AsyncGuidance.md) which talks about stuff you have to watch out for. If you are not building high performance applications, you are getting a lot of complexity forced upon you.
A basic knowledge of C# is sufficient to learn MVC. That means you could probably wing it through a course and be totally fine. You could even start a job and do fine. Eventually, you will run into a roadblock /somewhere/ down the road where you don't understand why your application is not performing as expected and I bet it will be related to not understanding C# and how it works. At my previous job, I was pretty much "self-taught" C# and did quite a bit of MVC stuff. I thought I knew enough to get the job done and I did most of the time but every once in awhile I'd be completely stumped or doing something in an overly verbose way. I was lucky enough to sit next to a really smart developer that would often help me out with these problems. He really knew the in's and out of C#. I focused on learning the cool/fun stuff first (like MVC) but I really benefited from going back through the basics of the language. 
I agree, ive been in a position of Dev hiring for a couple of years and dismiss the certs over a technical interview unless that cert is really prestigious
If you know or are willing to learn a little Docker, you can include a Dockerfile with your code and Heroku will build a container for you. Like a buildpack that you get to define the functionality of. And there are official dotnet and dotnet-sdk base images from Microsoft. https://devcenter.heroku.com/articles/build-docker-images-heroku-yml
If you don't know what benefit you expected from refactoring an existing application to have an entirely asynchronous API, why did you do it? Just some food for thought when making large-scale technical decisions in the future. It's easy to get caught up in all the blog posts and hype and just assume something is inherently good because that's all you ever hear about, but that's never the case. Even if some new technique, tool, library, pattern, etc. is entirely beneficial in all technical aspects when implemented, there's always a trade-off to be made when it comes time to actually implement it. Understanding these trade-offs at a higher level is a skill that's well worth learning. This is a skill that will help you increase your impact and value as a developer. Whenever you see something that just triggers you and instinctively makes you want to refactor it because it's "so bad", stop and look at it objectively. Why exactly is it bad? Can you quantify how bad it is? Can you quantify the benefit of fixing it? If some technical debt is making code harder to work with, how often are people actually working with that code? By what factor would a refactor actually change that scaling of effort? This also works in reverse. Taking on technical debt isn't always bad. Technical debt is a tool we have at our disposal, and as long as we understand how it works, it's OK to use it. If you can learn to properly justify your technical decisions, you'll make better technical decisions.
Use .NET Core 3.0 and set Output Type to Windows Application.
Using build: `dotnet build -r win10-x64` Using Publish: `dotnet publish -c release -r win10-x64` [https://blogs.msdn.microsoft.com/luisdem/2017/03/19/net-core-1-1-how-to-publish-a-self-contained-application/](https://blogs.msdn.microsoft.com/luisdem/2017/03/19/net-core-1-1-how-to-publish-a-self-contained-application/)
I should clarify that the win10-x64 part of the commands can be changed depending on the target OS you are going to run / host the app on.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/windowsserver] [CWE 327 "Insufficient Diffie Hellman Strength" fix?](https://www.reddit.com/r/WindowsServer/comments/auq5ll/cwe_327_insufficient_diffie_hellman_strength_fix/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
I don't see an issue with that. Depending on the systems already in place, as long as you have a way to pull that data (like the necessary libraries and connections strings and whatnot), then you can definitely create an API that retrieves all of that data for you. You should definitely abstract everything into class libraries as well. They could even be reusable later on down the line. 
So when building an API you must remember you are attempting to decouple the logic of the API from the data itself. Your API should work no matter what data is in the Database it reads from. I would recommend looking into [https://docs.microsoft.com/en-us/aspnet/core/tutorials/first-web-api?view=aspnetcore-2.2&amp;tabs=visual-studio](https://docs.microsoft.com/en-us/aspnet/core/tutorials/first-web-api?view=aspnetcore-2.2&amp;tabs=visual-studio) . Its a good start on using ASP.Net Core 2.2 for APIs. Hope this helps.
...and then the items go into the queue until you also run out of memory.
How do you avoid this kind of problem while using threads? Asking as a non c# expert. 
&gt; &gt; &gt; &gt; And when "until it gets around to them" becomes longer and longer, eventually your service falls over. That can happen to anything that allows an unlimited number of requests from clients.
Async/await has huge benefits for expensive IO operations only partially dependent on the number of calls. For me it feels very elegant to just say what needs to be done but not to say what needs to be done at which time in which context. It‚Äòs kind of similar to Parallel.ForEach or lock() where a lot of magic happens in the background that you don‚Äòt want to think about. If you use async/await from the beginning it‚Äòs not a big deal to include sync code. The other way around is basically impossible. If you prefer composition over inheritance, delegate work according to the single responsibility pattern, work against interfaces and separate business logic and data objects (some people call that anemic IIRC) introducing async/await can be done from the surface/controller to the ‚Äûbusiness layer‚Äú without problems (I did that before). If you heavily rely on inheritance, abstract classes and methods and combine business logic and domain objects it can be really messy and I‚Äòd consider to not go the async/await route (I also tried that before but you need to touch too much production code to be on the safe side) to improve legacy code. The problem is we typically wouldn‚Äòt mind to include async/await in the controller but there‚Äòs no benefit and w‚Äòd like to but can not include it in the ‚Äûbusiness layer‚Äú for IO operations because we‚Äòd need to sync-over-async or touch many many classes. I‚Äòd recommend to implement both sync and async methods for new IO operations even if the async is not used atm and only use async in all upcoming controller/actions even if they call sync code. At some point async paths they will meet without problems.
Again, it is something that I've used for moving CPU intensive tasks off the UI thread.
Take a look at https://www.hass.de/content/setup-microsoft-windows-or-iis-ssl-perfect-forward-secrecy-and-tls-12. (They also have a 1.1 version if you need to support older infrastructure). It's a really good SSL/TLS baseline and should get you to where you need to be (especially setting you up for ECDHE). 
No, not yet, sorry.
I also giggled. I think they should get rid of PlatformNotSupported exceptions and replace it with a DotNot exception 
Since Visual Studio is not available for Ubuntu I guess.. no?
Is there a replacement for that in Ubuntu?
Isn't use Visual Studio Code an option?
Exactly what I wanted to hear üôÇ I pretty much know how to extract the data from existing systems, my biggest issue really is how to get started with writing the API itself. All the tutorial stuff I've found is focused around building on top of a new and dedicated database. Do you know of any good resources for me to check out? 
I think there's great benefits to the async model, but there's a lot of pitfalls that are too easy to make if you're not careful. Having to plaster ContinueAwat(false) _everywhere_ is a sign to me that there's a smell there with the implementation under the hood. All that being said, once it's done it's a fantastic addition to your app. To this day I don't really have issues with async, I only have issues when I have to do something async from uncontrollably synchronous code (or vice-versa).
Thanks for the link üôÇ I've done this tutorial once and it was nice and easy to follow, but it's unclear to me how to fetch data from databaser or files from other systems. If you have any pointers to tutorials on something like that, please share üôÇ
Quite true. The problem with ThreadPool exhaustion is that 1) It happens when you have plenty of resources (CPU, memory) available 2) It causes a cascade failure as longer blocked tasks cause more tasks to block causing more tasks to take longer, etc. I don't think we're really disagreeing, here. DO use async/await, as they *do not* block the thread when they are using underlying native IO. DO NOT use Task.Run() on a per-request basis for anything that is going to take longer to finish than the full request itself. DO NOT use Task.Run() on a per-request basis in any situation where the number of tasks created is specified by the data in the request. AVOID using Task.Run() for parallelism in a per-request context unless you are certain you need to reduce the per-request latency (it is better to just use `async/await` in a serial fashion and leave the parallelism up to the webserver). DO move long-running background work to a background queue, in-process our out-of-process depending on the circumstances. DO establish the scaling limits of your service with actual load testing at a sustained level. it is better to reject requests outright when you reach your scaling limits rather than accepting more work and falling into a cascading failure.
This I can agree with.
Look at the Open API 3 And this tool to define your API https://studio.apicur.io Then you‚Äôll be able to generate an normalised api in the language (with the routing etc.) of your choice and start coding/linking with your internal tools
&gt; if a database operation is super fast Say that again when your network is flaking out, or your HA cluster is failing over.
vscode is your best bet
Isn't 3.0 still in Beta/RC stage at this time?
Visual Studio Code is the only replacement I know of, but it's a text editor and not a full fledged IDE like Visual Studio is. You may want to inquire as to whether the course has Windows computers on-campus or something you can use. I do use VSCode on my Ubuntu machine, but learning .NET is going to be much tougher than just using it.
The API is just a controller. A controller that specifically returns JSON. It doesn‚Äôt use any fancy or special way to connect to the database. There‚Äôs tons of ways to actually connect to databases in .Net Core, and honestly, that is easy enough to Google. Generally, API -&gt; Services -&gt; Repositories -&gt; DB. Then, you just Ajax everything through the API. 
Could you provide more details?
Parallel.ForEach doesn't work nearly as well as SemaphoreSlim locking
Maybe we can explore *specific* scenarios &amp; use-cases where they help or hurt. We can then weigh the probabilities that such will occur, and explore alternatives. Talking about it in generalities makes it hard to communicate realistic problems well.
That's true :) However, then it works more like the old .NET Framework. Here's the relevant changelog: [https://docs.microsoft.com/en-us/dotnet/core/whats-new/dotnet-core-3-0#default-executables](https://docs.microsoft.com/en-us/dotnet/core/whats-new/dotnet-core-3-0#default-executables)
I see your threads are returning out of order.
Often there's pressure to "keep up with the Joneses" and try all the trending technologies and new features. The problem is your employer may be stuck with the technical debt of your experiments. It's a curious thing about our profession.
Are you talking about dependency injection ? You want your dbcontext injected into your controllers ? If so, you have to configure it into your startup.cs file ! Go look at it !
Does your school offer access to Microsoft Imagine (formerly DreamSpark)? Fairly easy to run Windows inside of a virtual machine.
Cookies are how *your* app keeps it's authentication session. By adding cookie auth as the default scheme your app will always look for a cookie to see if it recognises the user. Consider it *persistent authentication*. Adding the other auth mechanisms adds different *challenge authentication* schemes. They are used to validate who the user is and get their info which is then changed into a cookie (the default auth scheme) when complete. 
JetBrains Rider is another option. Its better than visual studio in many cases. It does require a license after the trial though. Well worth it in my opinion 
Nartac iis crypto. Easiest way to do this. 
I would check if the projects will be .net core or .net framework. If framework your only option will be a VM. If core, using Jetbrains rider is probably the best bet for a full function Ide. Try a free trial or student licence? Depending on the project complexity you might have issues with scripts/ dbs / who knows what else but nothing that couldn't be sorted. 
No everything is ok the question is wasted
Do you only "have access" to Ubuntu because you do not want to install Windows or is it an issue of cost/licensing? Many schools have free or deeply-discounted licenses available for students and faculty.
Nicely stated.
Thanks. I am not qualified for the free or discounted licenses. If I don't activate Windows 10, will there be problems with installing free versions of Visual Studio, SQL server, and programming with them, and .Net, Nunit, etc, for web applications and services?
Not that I am aware of, no.
Sometimes you just gotta learn some shit, maaaan
There should never be more than 4-5 resources in an appointment.
I got my MCSD this past summer. The exams had just been updated around then to support a lot of Azure material so you wont find a one stop book. Hell, even those brain dumps were useless for it. Believe me, I checked. My saving grace was getting a Pluralsight subscription. I found incredibly useful videos that covered the exam topics pretty well. You get to learn from a lot of experts in the industry.
It's only 1-6 records. Batch updates is overkill.
It wasn't a decision just out of the blue. I needed to use the Google Geocoding library, which does not include a sync option. It's all async. Rather than doing Task.Run, I thought I'd spend the 2 hours to convert my relatively small app to use async/await. I didn't realize how many little pitfalls there are. I've since reverted back to non async code until I have a need to architect it that way.
Async/await makes it easy to say "make these 3 api/db/whatever calls concurrently and resume my code when that's done." This can make your app respond faster whether you have 1 user or 10,000. Async/await makes some hard things easy (concurrency, scaling), but at a small cost of complexity to everything you do. Don't use it if you don't need it.
I've worked on an application that uses TransactionScope to enforce atomicity when updating multiple databases and/or with multiple database connections. As long as MSDTC is configured and working properly, it works great.
That's maybe a little true, but very unfavorable. Turns out the OP wanted to use a library that has only an async API (due, likely to issuing web requests to do its job). The truth is that even if the old way works fine, it's often double effort to support a "best tool for this job" mentality. Not everyone who tries to simplify their life by using something that's more modern is just trying to cash in their buzzword bucks.
Yeah, this seems to be the unfortunate truth about async code. The syntax is much better than the old callback hell, but since it's shoehorned into an existing rich ecosystem, there are more "gotchas" than there might have been. Ultimately, things are likely to continue to become more async-centered as many apps, especially with microservices are basically just `curl`ing a few other servers and glueing the results together. I haven't seen a compelling reason to use async database code yet, but where I'm working, that's the only thing that isn't async by default.
But web application developed in asp.net will run on any platform right?
No he's being a fanboy. Avoid the licensing cost and use postgre or mariadb.