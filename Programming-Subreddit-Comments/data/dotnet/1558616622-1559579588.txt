You're quite right, `_context.Attach(LoadTable).State = EntityState.Modified` is the problematic line. I'll double check the value of Id. For the solution, would I need to do this for every property? It's a sizable form so may not be a viable solution in the long term. Thanks!
I can't really suggest you book for a language but as you are transferring from PHP, reading Clean Code - A handbook of agile software craftsmanship could be benefficial for you. I also liked O'REILLY books, I didn't read this one but checkout "C# 7.0 Pocket Reference: Instant Help for C# 7.0 Programmers" . However fastest way to get into new language is actually writing the code, so try something like HackerRank, you will just need to google a lot at first, but you will get into it.. Also try reading some open source project's code.
What are the full class properties for LoadTable?
Strings mostly, with a DateTime, int and Guid (Id).
Ids match up to the database by the looks.
Yes, you'd need to do it for every property. If the form isn't likely to change (and as such the fields aren't either), I think I'd just bite the bullet and do it manually for every property. Alternatively, you could write a method to copy the values using reflection.
I see. I was thinking it might be a foreign key or key conflict.
I put a breakpoint next to `_context.Attach(LoadTable).State = EntityState.Modified;` and Id is just filled with zeros, so looks like it's that.
Ok so it doesn't have a value, then has the correct value, then when trying to save, it appears to generate another and save it. I suspect where it can't find the generated Id, it's returning the error. So somehow need to stop that generation.
Can you throw more light please i really don't get or if there is any link where I can find such implementation
So I fixed the controller. Set it up, works good. Make the GET request in POSTMAN and it returns a 204 No Content. And in the return view there is nothing.. So this value is NULL?
The value it has when trying to save, is that the bunch of zeros you mentioned in your previous reply? A Guid has a default value of `00000000-0000-0000-0000-000000000000`, like an `int` has a default value of 0. What I suspect is happening is that the Id property doesn't have a corresponding field on the form. I'm not totally up-to-date on how Razor pages work (that is what you're using, right?) However, I suspect that when `GET`ting the page, the LoadTable property is set and its properties are used inside a view, in order to fill out the form with the current values. Then when the form is submitted, the framework creates a new instance of the `LoadTable` class, then it grabs the values from the request and sets the corresponding properties in the (new) instance of `LoadTable`. But since there's no ID field on the form, it cannot set the ID property and as such defaults to the default value of a bunch of 0's. If my guess is correct, then the solution is to add a new field (you can make it hidden if you want) to the form and set the value to the ID of the LoadTable.
OK. So I got working, thanks to your help and patience. It was just me being stupid and over complicating it. Thanks Dan THE MAN!
https://microsoftgarage.uservoice.com/forums/918727-xaml-studio/suggestions/36562690-please-make-this-available-as-a-typical-win32-app
I've tried both SwashBuckle and NSwag and have decided to go with the SwashBuckle 5.0-rc2 pre-release (it has a bunch of breaking changes from 4.x, but mostly generates valid OAS 3.0 unlike 4.x or NSwag) due to its improved support for the ANC ApiExplorer api and being based on Microsoft's OpenApi classes. https://github.com/microsoft/OpenAPI.NET The api explorer namespace is rather poorly documented by microsoft, but it is an introspection layer which follows the logic used by ANC. https://docs.microsoft.com/en-us/dotnet/api/microsoft.aspnetcore.mvc.apiexplorer?view=aspnetcore-2.0 (documentation is needed for example creating custom validators and how they interact with api explorer or documenting response types or polymorphism or general introspection and how to review the metadata) I think the most powerful thing about SB5 is its reliance on Microsoft's OAS implementation. With a document filter you can initialize a class that derives from https://github.com/microsoft/OpenAPI.NET/blob/master/src/Microsoft.OpenApi/Services/OpenApiVisitorBase.cs and then use `new OpenApiWalker(yourinstance).Walk(document);` to make whatever wide impact changes you want (for example I've renamed a number of the schemas I am dealing with).
No problem, happy to help! I'm interested now, what was the issue?
If I could upvote this a thousand times, I would, thank you! Are there any disadvantages to this approach?
Ya so. If you look at my initial screen shots, I have 'DBConnectionString' in the configuration, but not under 'Application Settings'. It's nested under 'Connection Strings' , which need to prepended with the connection string 'type' like \[" SQLCONNSTR \_DBConnectionString"\] which is also something I was doing initially, but wasn't connecting to AppSettings but rather trying to pass that into Environment.GetEnvironmentVariable(). So all in all, I was doing something stupid and wasn't taking a very calculated approach, but rather throw shit at the wall and see if it sticks.
Thanks! As far as I'm aware, this is the way it's supposed to be done. Unless you store the ID of the record you want to update in some server-side session storage, you have to send the ID to the client, so that it can tell the server which record it wants to update.
Generally for operations like this, you shouldn't really need to work with the state manager at all. You can just let EF handle it. Just pull a fresh instance of the object from the database, and modify its properties. So replace this line: _context.Attach(LoadTable).State = EntityState.Modified; with this: var existingLoadTable = _context.LoadTable.FindAsync(LoadTable.Id); existingLoadTable.Name = LoadTable.Name; // for example existingLoadTable.Modified = DateTime.Now; // etc... Since `existingLoadTable` came from the context, it is already attached to the state manager and being tracked, so you don't have to attach it yourself.
I just wrote an ASP.NET Core 3.0 app to be deployed to Azure App Service (On Linux..) and the configuration worked for me when my connection string was stored inside the App Service configuration connection strings (in your screenshot). [Have a look at the documentation for Configuration in App Service](https://docs.microsoft.com/en-us/azure/app-service/configure-common) .NET Core takes in configuration from environment variables, appsettings.json, web.config, [secrets.json](https://docs.microsoft.com/en-us/aspnet/core/security/app-secrets?view=aspnetcore-2.2&amp;tabs=windows) or any other provider you add. However, the way the connection strings are stored should NOT be of concern to your app, because all configuration strings are key value pairs, and nested ones are represented using colons ("ConnectionStrings:DBConnectionString") or underscores ("ConnectionStrings__DBConnectionString"). The reason for the underscores is because some platforms don't support colons in environment variable names so they use two underscores instead. Connection Strings in app service are provided as an environment variable to your app (even when using docker containers with app service) so to access it you would use: `Configuration.GetConnectionString("DBConnectionString")`. Your post is missing details. You do not say *where* you are accessing it from and your *environment* (local or azure). You have tried it but you say the value was null. Are you sure that you are accessing it after your app has read the configuration and started up? When you have the connection string set up in Azure (eg, with Azure SQL), it should not be null. For local instance however, you can add the connection string to your appsettings.json ` { "ConnectionStrings": { "DBConnectionString":"...." } .... } ` or using [dotnet user-secrets](https://docs.microsoft.com/en-us/aspnet/core/security/app-secrets?view=aspnetcore-2.2&amp;tabs=windows) which is the recommended method, especially if the connection string you're using is nor for LocalDB `dotnet user-secrets set "ConnectionStrings:DBConnectionString" ".."`
This is a shot in the dark, but is the report in an assembly that hasn't been loaded yet? Try loading it? Assembly assembly = Assembly.LoadFrom("Qqest.TimeForce.Reporting.dll"); See this blog post: https://weblog.west-wind.com/posts/2012/Nov/03/Back-to-Basics-When-does-a-NET-Assembly-Dependency-get-loaded You could run this line before to see if its loaded: var assemblies = AppDomain.CurrentDomain.GetAssemblies();
Azure now has a dedicated service for App Configuration called Azure App Configuration in preview. It is not a replacement for KeyVault but can be used for setting non sensitive variables. https://docs.microsoft.com/en-us/azure/azure-app-configuration/
Compare the fusion logs of the assembly load for both of the Dev environments.
I love reading stuff, even if I don't understand them yet. Sooner or later i read something else that just makes it click, and thats a good feeling. Reading stuff where one understand most of it already is usually a waste of time, but sometimes necessary for picking up beginner-knowledge you might have missed when you were a beginner, stuff that the more advanced tutorials never mention because they assume it is common knowledge.
https://docs.microsoft.com/en-us/dotnet/standard/microservices-architecture/implement-resilient-applications/use-httpclientfactory-to-implement-resilient-http-requests I'd bet something like that is occuring.
Thanks for the suggestion. I added that line and checked the list of assemblies. It shows that the assembly containing the report is loaded prior to calling the GetType method. So no luck there. But thanks for the suggestion.
Read what you find interesting, don't force yourself to read something you don't. As you grow you'll find certain things are more interesting or less interesting. This is normal and healthy.
Enumerate Assembly.GetTypes() for the assembly and see if you find the type there. Try appending the assembly name "typename,assemblyname". Are both the assembly and the executable referencing the assembly built on the same computer? (potential .NET framework version issue)
Not OP, but for us the fact that it's still in the "preview" stage means it's not ready for our production environment. The fact it's moved from experimental to preview is good, and for a small startup then perhaps a preview/beta stage is fine - but I'd struggle to get it past our management processes until there's a proper stable, supported release
You have a phone, right? NuGet is an app-store for libraries/packages and plugins that you might want to use in your development projects. You need a way to send Facebook messages on your iPhone? Download Facebook Messenger from the App Store on your phone. You need a way to handle the Facebook API in your project? Download a Facebook SDK from NuGet
I wouldn't bother looking into blazer atm.. I'm finishing up something similar to what you want to do. Vue was our choice and I can't recommend it enough, really simple but so powerful
Then it's loading a different version of the assembly that does not contain the type.
Type.GetType tends to return null unless the string you’re passing it is a fully-qualified type name (i.e. it includes the assembly name), for example “MyNamespace.MyClass, MyNamespaceAssembly”.
"added some stuff, idk, might refactor later"
I wish he had a commit comment something like "did some stuff"
When I was a kid, from 12-18, I basically read every single issue of Popular Science, Scientific American and Discover cover-to-cover. I read all kinds of challenging science books, even if I couldn't really understand them. As a result, I had a general scientific knowlege that felt very... I dunno. Rewarding. Worthwhile. It made me feel competent. &amp;#x200B; I've always bemoaned the fact that I have all that random science knowledge that I can't really use in my day job as a programmer. I had imposter syndrome, too. However, the last few years I've gotten into the habit of reading random stuff on Hacker News and programming subs, even if it's about low-level C++ stuff or something totally unrelated to my areas of expertise. &amp;#x200B; Now that feeling is coming back. I feel much more literate about the entire field of computer programming. Even if many of those articles on machine language and Spark clusters initially soared way over my head, now the terminology they use is familiar territory and my brain is primed to learn more next time I see them. &amp;#x200B; I also feel I have a better sense of general "best practices" which informs my intuition when I'm working in C#.
Either you have an old version of that assembly in your GAC and that's the one being loaded, or there's a binding redirect for that assembly on your machine only.
why the fuck are you posting this here
Install NET 4.0 SDK?
So it does! Well I'm glad you sorted it either way :)
Dump the full list of loaded types (IIRC AppDomain.GetAssembies() and Assembly.GetTypes(), then Type.AssemblyQualifiedName) to a text file and have another dev where everything is working do the same. Compare the lists.
https://unhandled.wordpress.com/2018/02/01/using-azure-application-insights-with-on-premises-servers/
Data is still sent to Azure's servers though isn't it? Even with the agent on an IIS sever.
I would say yes. You never know when understanding something on the fringes of your daily work will help you understand larger systems or propose out of the box solutions. It may be a long time for that to pay off, but I tend to think it will. If you want to move into system architect down the line having a wide breadth of knowledge is critical. Same reason I'm not as fast to poo-poo the leetcode interview practice. It can be important conceptually for stuff that is beyond your typical CRUD and webdev work.
Seq? [https://datalust.co/seq](https://datalust.co/seq)
I always want to know this. We should set up a sub for recommending providers. Mine are sub par but worth sufficiently. I'll move to Azure in a few weeks when I have time.
Since you have the assembly loaded, have you verified that the type you're looking for is actually contained in the loaded assembly by iterating through the assembly's types for a match?
You'll get some tech replies I'm sure, but what problem are you trying to solve? Projections are not current state based, they're eventually consistent. All distributed systems rely on some sort of eventual consistency. You don't need ES if you don't need ES. Why do you think you need ES?
You could use https://prometheus.io/ with Grafana.
he seems like a "bro". I find it interesting to look at people's posting history. Hell, mine is very interesting. You never know what things you find out... \*evil grin\* &amp;#x200B; but I second it, why the hell is he posting it here? email the author and kindly ask for it. However just for spite, If i was the author i would send him this. &amp;#x200B; ╭∩╮（︶\_︶）╭∩╮
An attempt to reach out to him, as email wasn't available. My intentions were not to upset you.
You can take a look at the ELK stack
I'm politely requesting something from him, and his email is not available so this was my attempt to reach out to him. Intentions were not to be disrespectful.
Azure. AWS.
That would be a good idea
Why would you want to do that? Especially spawning multiple clients seems a bit out of the ordinary. Can you explain your reasons for wanting to do such a thing?
I mentioned about "not needing ES" because I wanted to avoid answers like "go for ES". I know it will be eventually consistent. I simply want to scale read part of the system, but without complex ES approach. Just as CQRS says - I want to have system, that when needed I can scale read side separately, and that's why I need to have projections from write side db (which is source-of-truth) to potentially scaleable read-part-db.
What happens if you use the [Fully Qualified Name](http://msdn.microsoft.com/en-us/library/30wyt9tk.aspx)? Is the Assembly definitely loaded?
I am an author of this open source project https://github.com/dmitry-pavlov/openapi-connected-service Give it a try. Feedback is much appreciated!
Thanks, that solved it :)
You can use the local installed open source version of exceptionless.com Great exception analysis but also log analysis and feature usage reporting is included
:) You get a cookie then :) "Go for ES" is a nightmare. I still have some concerns about your system, but I'm not there, so always come back with questions :D
what concerns do you have?
Does this project have other goals than existing swagger code generators? e.g. https://github.com/swagger-api/swagger-codegen
[removed]
UI tasks should be non-blocking... so if they consume relevant time they are not designed properly. Also why benchmark something that is used by a single user?
This would be a really long post which is why I said "ask questions". I could have explained that way better. &amp;#x200B; Honestly it's a weird thing you need insight into the company :) &amp;#x200B; Sorry if that's a weak answer :/
[Azure](https://azure.microsoft.com/en-us/services/app-service/web/)
[removed]
Vue would be a lot simpler than React, it would just plug right in to your existing html. Convert the backend (all but the mvc part) to core now, start writing the api part in a .net core project. You could even do some sort of frankenstein bring data into the page with mvc and manipulate it in vue to partially update a page.
This sounds like a perfect use for a Message Queue (aka [Pub/Sub](https://github.com/upta/pubsub)) architecture. In a Pub/Sub architecture, Publishers send messages of different types, and Subscribers listen for those messages and act on them. In this case, you can have a ViewModel for your Search tool. When a search is performed, the Search VM can *publish* a "Search" message containing the parameters of the search. The VMs for your Sections, Subsections, etc. can *subscribe* to Search messages. When a Search message arrives, the handler can check to see if its parent VM matches the search term, and flip a bit to mark itself as "Highlighted". Pub/Sub pattern is well-understood and there are tons of .Net packages that implement it.
azure, heroku
We have grafana setup to monitor all projects &amp; pods in our kunernetes environment (redhat openshift) which is awesome for automatic/out-of-the box monitoring of cpu/memory/network. With that said I do want to look into Open Tracing from the Cloud Native Computing Foundation. I think that can be used to give stack remote tracing and debugging across multiple pods even using different languages, so I'm pretty excited about that. The idea here is for more complicated deployments where we have 5-6 pods in same project workspace but with just one external route, then I can trace the execution context throughout the project.
We have grafana setup to monitor all projects &amp; pods in our kunernetes environment (redhat openshift) which is awesome for automatic/out-of-the box monitoring of cpu/memory/network. With that said I do want to look into Open Tracing from the Cloud Native Computing Foundation. I think that can be used to give stack remote tracing and debugging across multiple pods even using different languages, so I'm pretty excited about that. The idea here is for more complicated deployments where we have 5-6 pods in same project workspace but with just one external route, then I can trace the execution context throughout the project.
Since this app will continue to grow and more "tool" functions are requested (like the upcoming Compare), I wanted to avoid placing implementation logic for these functions in the viewmodels themselves. Having each viewmodel subscribe to a publisher and listen for these tool requests would require viewmodels to then implement that tool logic (unless you have an idea how to avoid this). That's why I opted for a visitor-like pattern that accepts the root-level viewmodel and performs the logic specific to it's functionality and sets its IToolResult object on a viewmodel. But, having to place this IToolResult object on the viewmodel is making me squeamish because I really wanted the viewmodels to be completely unaware of a tools existence.
&gt;Having each viewmodel subscribe to a publisher and listen for these tool requests would require viewmodels to then implement that tool logic (unless you have an idea how to avoid this). You can send messages that include `Func` properties which would serve as callbacks. The subscriber could simply execute the `Func` without knowing or caring what's in it. Different tools could send their own implementations of the `Func` in the message. The other alternative is to have some sort of backend `ToolService`, injected into the VMs via a DI container. The `ToolService` would monitor all of the VMs and instruct them on when to highlight themselves. New tools would be implemented in the `ToolService` directly, and the VMs would be none the wiser. They'd just listen for Highlight messages from the `ToolService`.
We use this and I really like it’s SQL like querying
Also consider keycloak which can be run from a docker container if you don't want to get "locked in" to a service ... although in reality you are not really locked in, all those services use OAuth and/or OpenIDC
You really should have a firewall whitelist for inbound and outbound traffic. Nothing is going to azure servers unless you put them in the outbound whitelist.
I've read a lot of detective novels, I am pretty sure I am the next Sherlock Holmes. For some reason the local PD has stopped answering my calls, though.
&gt;Go for ES This is fine advice if you have competent developers who will handle event storming, properly modeling the domain, understand the ramifications of eventual consistency, etc. Unfortunately, there are a lot of shit developers who are used to just diving right in and learning as they go. That will get you in a world of hurt with ES.
I've been wanting to try out cloudscribe for some time - [https://github.com/cloudscribe/cloudscribe](https://github.com/cloudscribe/cloudscribe) the hope and the dream is that it makes multi-tenancy just a nuget and some config. I just haven't gotten around to trying it yet, so YMMV
To make sure performance doesn’t degrade over time. As you’re adding new features, refactoring code or hunting a bug, good practice in engineering recommend to use test driven approach to make sure that the build doesn’t break in production and to make sure to not have feature regression. Thing is, nothing stops code’s performance from decaying over time. We should always aim to at least keep it at the same level or new changes are improving the system’s performance. From here, profiling the state of a WPF app provides not only stability but grounds to investigate memory performance issues such as leaks! Spawning the app multiple times to keep at the same scenario will provide reliable results.
Then choose a simpler (probably simpler) model. A remote cache layer. The cache is fed from the events raised when something is modified and saved, an represents the actual state of the system. &amp;#x200B; (Still cqrs, but I took out the scary :) &amp;#x200B; The developer issue, first assume they can code. When that doesn't happen encapsulate the above intoa nuget anwrite a .md file that shoes how it works. Worst case, do a 30 minute present prentatin one afternoon. Do not to it at lunch, first thing or last thing.
Create a Claim for your application that defines the account the user has access to when logged in. Ask them which account to log in as, then set that claim. I have yet to find a way to store per-account access in a way that fits most models when the user has access to more than one account.
Look at the settings. Depending on how it's setup you could be causing it(The client) to not ask for a new IP. https://github.com/StackExchange/StackExchange.Redis/issues/289
https://blogs.technet.microsoft.com/ashleymcglone/2013/05/29/dude-wheres-my-gpo-using-powershell-to-find-all-of-your-group-policy-links/
https://docs.microsoft.com/en-us/dotnet/api/system.management.automation.powershell?view=pscore-6.2.0
I wrote something to do just that, but in C# using/wrapping the [LGPO.exe](https://blogs.technet.microsoft.com/secguide/2016/01/21/lgpo-exe-local-group-policy-object-utility-v1-0/) tool from Microsoft. There's likely a way of doing it without wrapping an external tool, not sure how complex that would be.
You miss-understood me. &amp;#x200B; I said you should separate the layers but not because you \*might\* one day need to change databases.... But because you do gain 'separation of concerns'.
Any plans for rider version?
I definitely did. Early morning Reddit is bad.
Sorry to be a little late to the party on this response but I did see you mentioned Azure Logic Apps; this is a good approach but you may want to take it a step further and look at an Azure Web Job which is what a Logic App runs under and will allow you much greater control over the tasks you are trying to do. Then I would take it a step further and add a message queue service; Azure has these in the forms of Storage Queues; Service Bus Queues, Service Bus Topics, and Event Hub. They each fill a different need in terms of scale, size of message, and capacity. Another commonly used one is RabbitMQ. You can queue up a message for a job and then have a Web Job process that message. The approach I took was to have a Web App that the user can initiate a job with; this places the first message in the queue. Then in my Web Job I wrote a function that handles one of the tasks/steps of my process. By default it's configured so multiple instances of the same function can run simultaneously on each message and this is configurable. The webjob queue trigger which is designed to essentially poll the queue in the background looking for work will manage kicking off when a message is available, locking it, and marking the message as complete when completed; it also can mark a message as failed to process if an error occurs while processing it or the lock expires. There is also out of the box functionality to attempting processing a message multiple times in case of failure. The benefits of a setup like this are * Messages wait in a queue if all workers are busy * If developed correctly you can guarantee the data is correct, eventually but not immediately this is the benefit of a message queue pattern * Retry handling * Web jobs exist in an app service container so no additional cost is necessary if you have an App Service, and only use resources when running (small amount of overhead while idle but this is negligible) * You can add messages to a queue from any thing; you are essentially posting a message to an http endpoint and a nuget package exists to do this. * You can setup a worker to kick off processing items in Azure storage instead of the message queue, basically lots of boiler plate for monitoring for files to process is handled for you * Automatic scaling of multiple instances of the function running for you, but also the ability to create a singleton function * You can run multiple instances of a webjob if needed as well and singleton locking works across all jobs if they use the azure storage (where locks are stored) * After a message is processed it can be posted into another queue so a single message can be moved through the queues Some points to consider * The most up to date packages are for .NET Core * Your worker functions need to be idempotent * You need to build in something to handle your dead letter queue (failed messages) * Consider having the webjob hit endpoints in a web app to post updates so the request has tracking along the way so you don't have the web app where the user put in the request hit the queue * DI requires some careful configuration as per request handling is not a thing in a webjob and the out of the box functionality does not inject all items into a function as one would expect (this should be fixed as the bug on git hub was closed but there has been no documentation) * You can split your different processes you do into different webjobs so each can be deployed separately * Changing the lock length is cumbersome in the azure portal but this can be done in code from the queue management package or in 3rd party tool which also lets you view messages in the queue
I don't recall Heroku having support for .Net applications, though I may be mistaken.
Have you looked at using display and editor templates? Maybe setup a common display and editor templates for the controls you commonly build in your apps. You could make it a nuget package and distribute it to all of your apps moving forward and have it drop them into the needed directories for you; then customize away to fit that application. If you are already scaffolding out your views what else do you have left that is not business domain specific besides defining your object domain and running code gen tools?
Shouldn’t be that hard to wrap it up as a cli tool so it’s available for anyone to use? Haven’t looked at the code though so who knows.
Unless you are writing custom controls in WPF, you are better off performance testing your view model. Ideally, there should be no business logic in code-behind, so having your benchmark drive the view model will give you good results.
ok, so the ultimate question is: can you provide link to example project or to tutorial, how to create state based projections from WRITE DB to READ DB in CQRS? As I didn't found any with google :-(
There's [NSwag.MSBuild](https://github.com/RicoSuter/NSwag/wiki/MSBuild) for this.
it does you can host using .net core build packs
Web app services are **not** cheap, though.
what would you recommend instead?
The very cheapest instance is free...
I can't give you any actual references but this is basically how we used to do it. Imagine you sell coats via your shops to customers. You have information about coat type, shop location, customer name and address. Microsoft have a build in tool for this called [Analysis services](https://docs.microsoft.com/en-us/azure/architecture/data-guide/relational-data/online-analytical-processing) Something like that would solve all your needs as it allows you to take your model (warehouse-&gt;coats-&gt;shops-&gt;customer) and have it update a view, perhaps one showing just one number, total coats sold) when a coat is sold. Here's the bit for you. It's not based on an event, it's based on a new sales record in the coat sales table. &amp;#x200B; The second option is to build your own. Write a stored procedure or bit of sql that expresses the projection. This is fine for low volumes, but gets heavier the more data there is. You can cheat a bit here using database triggers. When a coat is bought by Mr A, from shop B and it's coat C, the transaction might look like 1 record in transactions with customerFk, shopFk and coatFk (Plus a timestamp, unique key, sale time and date, etc). A trigger will run when that record is inserted and also update "stats" tables. So it would update the record in the total coats sold by day. If 2 for coat C have been sold, and this new sale arrives, the row for Coat C with a date (not date time) would be incremented to 3. Now if you want to run summary reports for example, there's less to aggregate. You can have loads of these summary tables. It's important to know how to keep them in sync. With triggers and a transactions it's fairly simple, nothing is every totally simple. &amp;#x200B; Get the basic ideas?
\&gt; Having each viewmodel subscribe to a publisher and listen for these tool &amp;#x200B; [u/unndunn](https://www.reddit.com/user/unndunn/) is absolutely correct. This is exactly how this is supposed to work. Remember you can have one global messenger, or individual messengers that just chat between a subset of viewmodels. You want the UI to change when someone does something. This is specifically what the ViewModel is there for, it converts the model, or service outputs into stuff the UI is bound to.
It's a connected service extension for Visual Studio, not a Java command line tool.
I understand the goals you have and also that you want to use an automated approach to get to those goals. But I have some doubts if the approach you take is a correct one. When running Client UI applications you will always be very dependent on the machine that the application is running on. Even more so when the application is a WPF application. Simulating an environment that represents all the different environments that your application will actually run on is very hard. Getting reliable results by spawning a couple of client instances will probably not work. A better approach would be to implement some kind of instrumentation that enable the client instances that run in the actual production environment to report on their performance. You can then benchmark against that when deploying new versions. Having that in place you can probably use static code analysis and testing frameworks to help find common pitfalls before you deploy a new version.
Well actually there are some things that you cannot measure from invoking the view models from a test framework. One of them is the data binding mechanism that can introduce subtle but very annoying memory leaks. Also testing the view model does not allow for correctness testing of the UI presentation.
You can host multiple websites on one single app service.
What functionality do you need?
Does your client assume the risk?
R/W the serial port, so I'll need the System.IO.Ports lib.
The client is our branches. We have to monitor some UPS's AC/DC I/O for our own servers safety.
I don’t want to simulate an environment. There are different cases causing leaks and having an automated approach enables developers to standardize QA work while testing the app. Here I want see the reaction time to say, load a file or export an excel sheet. You can say all right, now we know the time when you’ve just opened the app, what’s the performance when you do other things and do the same action 5 to 25 minutes after opening the app. Do I still get the same performance or am I leaking memory, or something else. I understand that client environment is important for understanding issues they have on their side. But you seeing downs in performance can also happen on the development environment because we only had foreseen the usage of a feature at a given moment. Something like this would help assess not only functional requirements but business requirements too such as at any time in the app session, it should take at most 1,5 s to export an excel file from the session.
Can you take a look at my comments in the thread? Tell me what you think
Don’t get me wrong, I understand profiling in an enclosed sandbox to see alone and in a given scenario, how does the back-end fair. But, there pesky problems that can arise at any point and a tool such as thing would be helpful to detect them earlier.
[removed]
According to this 4.5.0 is available: https://www.nuget.org/packages/System.IO.Ports/ Unless you need something from the preview version?
But those are outside the scope of benchmark.Net
Does it work like native or does it already native just not incorpored in .NET Core 2.2?
I use smarterasp for like $3/mo compared to azures $54/mo. My web apps are small and have really low web traffic so I can't speak to performance under pressure. It's been 2 years, no complaints.
Claims it Works on anything that implements netstandard 2.0, so yes.
Not sure if this could be an option in your situation, but in the past, I've used serial to Ethernet adapters to communicate with devices in the field. They supported direct network communication so my app didn't have to know anything about com ports. We used something like this: [GridConnect NET232+](https://www.gridconnect.com/products/net232-serial-to-ethernet-intelligent-cable-adapter). There are probably cheaper options available, though. Good luck with whatever solution you decide to go with!
Looks good. Does anyone know if the current debug tool people are working on Core 3 tools that will make this stuff pretty? JetBrains, Ants, etc.
https://github.com/Ellerbach/serialapp is an example of a .NET Core 2.0 app on RPi using Serial Ports. It seems like the preview version of `System.IO.Ports` does run on .NET Core 2.1 (and has support for linux arm64 using the`runtime.linux-arm64.runtime.native.System.IO.Ports`) but I'm not sure if it works properly with .NET Core versions below 3.0 - it seems like the versioning uses .NET Core Preview versioning but the package only uses .NET Core 2.1 APIs..
I think you would have to use HTML5 and JavaScript for that.
.NET Standard 2.0 does not mean a library becomes cross platform automagically. System.IO.Ports (non preview ones) is a part of [Windows Compatibility Pack](https://msdn.microsoft.com/en-us/magazine/mt814807.aspx) and will not work on Linux. It will fail with a PlatformNotSupportedException with the message "System.IO.Ports is currently only supported on Windows."
4.5.0 will not work, it's a part of *Windows* Compatability Pack
use it with no worries and communicate with the netcore3 team about anything that comes up. I used netcore2.2 while it was in preview out of necessity and it turned out to be a pleasant experience
There's /r/webhosting which is fairly active, I think.
You thinked right.
That would be awesome!
When do you need the 3.0 code to be in production? I see little risk in starting development on 3.0 now for projects that won't go live before the stable release.
Run VS as admin. [https://stackoverflow.com/questions/2952166/visual-studio-has-insufficient-privileges-to-debug-this-process-to-debug-this-p#2952330](https://stackoverflow.com/questions/2952166/visual-studio-has-insufficient-privileges-to-debug-this-process-to-debug-this-p#2952330)
Already the case
The Pull Request Dashboard will show all PRs assigned to you.
Thanks, I'll have a poke :)
If your application is very simple you can set up the routes in the program.cs file without any needs for a setup.cs. Do anything more complicated and I will find you like Brian Mills.
Udemy has decent courses for $10 each.
Everything is a file in linux and every .NET can access a file. Would that work for you before .NET Core 3 is out?
ha ha yes i know its bad practice but as sandboxing then its really nice to be able to work in a single file, but agree ofcourse that if you want to expand then you should follow a proper structure. But that is interesting if that is possible
Depends how new you are I suppose. The Microsoft docs have good tutorials and run through Razor, EF and creating a CRUD app. You'll need a solid grounding in C# first though to get an idea of what's happening.
This is a really clever solution. Combine that with stable core 2.2. Honestly, I wouldn't be using Core 3 in prod for server UPSes until its been stable for a good while.
I heard positive things about Mosh Hamedani, but his ASP.NET course is centered around .NET 5, not Core.
I made a smallish program with WPF and XAML some time ago, but that was before Core came about. Otherwise I know very little about it. The Docs have also some free courses linked, but they seem outdated (2016-2017). Though I think it wouldn't hurt to just read the docs themselves. I was just hoping to find a course where I build a project from start to finish and learn along.
Have a look here and work through it. Good for the basics and should give you a good grounding. This is for 2.2 which is the latest until 3 comes out later this year. [https://docs.microsoft.com/en-us/aspnet/core/data/ef-rp/?view=aspnetcore-2.2](https://docs.microsoft.com/en-us/aspnet/core/data/ef-rp/?view=aspnetcore-2.2)
Would running your project on Windows IoT Core on the Raspberry Pi be a solution, or can it only be on Raspberian (or other Linux flavor)? This might allow you to use system.io.ports 4.5? Here is the download link: [https://www.microsoft.com/en-us/software-download/windows10IoTCore#](https://www.microsoft.com/en-us/software-download/windows10IoTCore#)! Generic link for boards supported by Windows IoT Core: [https://docs.microsoft.com/en-us/windows/iot-core/tutorials/quickstarter/PrototypeBoards](https://docs.microsoft.com/en-us/windows/iot-core/tutorials/quickstarter/PrototypeBoards)
We have 5 different projects with lots of repositories within them. I wrote a web page that aggregates all the pull requests together so that everyone can see all the pull requests. We have some projects that are common libraries that are shared across teams so it was important that everyone had visibility. https://github.com/BertCotton/TfsAdvanced
Yeah, at my job we used vue to patch up some bad performing mvc parts. Its a Frankenstein solution, but it works
You assign users to the PRs manually when you create the PR. You can see any and all PRs past or present (assigned to you or not) by going to: Repos --&gt; Pull Requests
Do you have any Debugger.Launch() or Debugger.Break() calls in your code?
Our current process is to assign reviewers at the start of the sprint so devs can account for the load of having to do reviews during the sprint. So we have these cards on the board for reviewers and then we have the PR reviewer assignment and nobody knows what's their responsibility. I would say the PR assignment makes the most sense and maybe we dump the reviewers on the sprint board.
We have a task under each PBI for peer review and consider that as part of our definition and done and include it in the estimation. When it’s ready, the review is open to all other developers and anyone can pick it up.
\^ This is how it should be done.
Please see Iwells49 response below. :)
Just start writing. Stack overflow will get you through issues. Learn as you go.
One annoying thing in ef core is the necessity of join entity in many-to-many relationship. I personally failed to make it working. It is described here: [https://www.entityframeworktutorial.net/efcore/configure-many-to-many-relationship-in-ef-core.aspx](https://www.entityframeworktutorial.net/efcore/configure-many-to-many-relationship-in-ef-core.aspx)
If intended platform is Raspberry Pi why not use current stable version of .Net Core and forward your I/O to node-red that can talk pretty much to anything including serial. On one of my projects I integrated .net core app with node-red in order to use RS485 and control modbus devices. Works like charm.
It’s not going to help but even though we use Azure Devops as CI, repos are on Bitbucket which makes PR reviewing very clear and very simple.
We basically enforce code reviews before going back into develop, so someone writes code, they branch of develop and create a PR to go back in. Everyone needs to do code reviews. We are a pretty big team now though.
[Dev essentiials](https://visualstudio.microsoft.com/dev-essentials/) inlcudes free plurlsite and other training.
You _could_, but I don't see why you would need to. Are you looking to be able to modify the code on the fly? You have to recompile and redeploy it, anyways. Maybe a container is a better idea?
Shawn Wildermuth's course on Pluralsight (free trial I think) [Building a Web App with ASP.NET Core, MVC, Entity Framework Core, Bootstrap, and Angular](https://app.pluralsight.com/library/courses/aspnetcore-mvc-efcore-bootstrap-angular-web/table-of-contents)
more to work in a single sourcefile for smaller projects, feels abit im flying around in folders and config files
Can you reference the secrets from the environment, either through environment variables or a .env file that the developer maintains on their local machine, instead of a config file?
I've never gotten that to work. It says free, but then always ends up costing - perhaps is a regional thing?
Yup, but it's still quite pricey. However, they've introduced a shared hosted (beta) solution that is quite a lot cheaper.
I've used shared hosting from other providers in the past and I never want to go back to such platforms. They always introduce very restrictive rules, like no uploads of exe's, limited access to reflection, limited websockets, ... Also they often lack behind, old versions of .NET framework installed, no HTTP 2, no web deploy support, ... Meanwhile Azure app service simply gives way more bang for the buck IMO and less headaches IF you are hosting .NET applications.
Only free for 1 month.
Ideally I'd use App Service, as it is very nice to work with. But 54$ a month for a hobby project is too steep to justify for me :-)
I get that. I guess it really depends on what sort of apps you are creating. As lead web developer in my company I've decided to host all our enterprise apps on Azure. The cost of hosting pales in comparison to the hourly rate of developers, so it's only a natural choice to go for something which requires a mininum of oversight (thus no VM) and a maximum of features. Hobby projects are of course a different story. But if you are registered as a company I would advise you to take a look at [MS BizPark](https://startups.microsoft.com/en-us/). It's basicly MS subsidizing your business with free cloud credits and VS licences.
The book, ASP.NET Core in Action, is remarkable.
Different licensing correct?
I thought changing DPI often fixed this.
.NET 5 **is .NET Core**
Yes, reference source is used to figure out exactly what a library is doing. You can't use the code yourself (copy it etc.) and MS wasn't talking pull requests.
You could add a robots.txt telling bots to ignore the offending links, but I would guess any bots that are messing up your URLs are probably also not the kind to check your robots.txt Is this affecting your SEO or causing some visible issue?
I don’t see the problem. I understand it’s not what you want, but that looks like standard behavior to me /another-page is relative to your current directory If you want it relative to home, you need ./another-page
Maybe this is it
I’d pick this book over any video course. It’s just that good.
Slash at beginning means relative to root, otherwise relative to current.
I don’t know if there is an equivalent for C#, but for F# you could use fsx files with the fake tool and even have the package management in the same file. Should be possible, yes.
Totally agree. For a business case I would shell out the monthly dough for an Azure App Service instance.
Require at least one reviewer and a smoke test build. We throw them all into a slack channel and we kind of know who should be the reviewer, although anyone can go and review.
I would hit Pluralsight and sign up for the free 10 day trial and cancel the subscription before they charge you. You can learn quite a bit in ten days on there and they have several courses dedicated to .net core mvc.
I’m actually in the middle of Mosh’s MVC course right now. It’s actually not for .NET 5, it’s for ASP.NET MVC 5. I just checked in the videos and he’s using visual studio 2013 and building apps in .NET 4.5. The course is a few years old. So you won’t get .NET Core out of it, but it may still be useful to you if you find yourself working on software that’s a few years older (as I do). For the record, Mosh’s courses are very good.
Just do it! I came here to say this. Glad to see someone already did. Cheers. People learn by doing. The struggle is what helps you remember it when the light bulb goes off.
Exactly. Maybe it’s different, as I do technically have a degree in software engineering, so I’ve been classically exposed to concepts, but man, fuck books. Just start writing in a logical way and you won’t come across issues. Is my code perfectly optimized, through knowing ridiculous trivia about a framework? No, but it doesn’t need to be.
I don't know, if you are very very new to .net, that is going to be a hell of a lot of stack overflowing ... I say go find a quicky short course...then just start writing.
ASP.NET Core uses [tag helpers](https://docs.microsoft.com/en-us/aspnet/core/mvc/views/tag-helpers/intro). They accomplish the same thing but are MUCH easier to use.
Asp-for is what are called tag helpers. They were created after @Html which are called HTML helpers. However, some things can only be done with an HTML helper, whereas the helper tags didn’t replace HTML helpers entirely. But when you can use helper tags, use them. They were created to make the markup look much more readable/HTML like versus the @Html syntax. Helper tags are not razor syntax, while HTML helpers are. The @ symbol usually represents razor syntax.
We have a status/column for Code Review each story need to pass on its way instead of a subtask. Simple and works
The brown one ..Manning Publications; 1 edition (July 13, 2018)? There are two similarly named titles.
Okay..so use the asp-for type syntax whenever I can, if I understood that correctly.
Correct.
What you want to do is optimize for shorter code reviews. First step hopefully you are using pipelines to automate your builds. If not start doing that. Next you want to remove as much need for a manual code review. Use linters to enforce a consistent code style. Put in static analysis tools to catch easily catchable issues and treat everything as a hard blocker. Use automated tests to validate for business logic. Next start doing Trunk Based Development and reject PRs that are too large. Typically I reject a code review that is over 100 lines of code because it's just too much work for the reviewer. I require PRs to be as small as possible so it's easy to understand the change to the system. Let developers self organize who does a code review. The team should be able to figure out who is best to review a change. On previous teams of mine we basically picked either someone who has done something simliar before, someone who wrote that section of code, or whoever has free time. a code review should not be onerous and should't take up enough time that you have to schedule for it, if it does you have too much WIP and should reduce the size of your PRs.
Why does it need to be tasked explicitly? Just include it in your existing estimates. Do you also include the time it takes for a developer to turn their machine on in the morning, set up their development environment, and grab their morning coffee? If you do then go right ahead, but this feels too micromanaged. Developers should autonomously check for pending reviews, and communicate with each other if no one is looked at their PR. You can also integrate PR alerts into Teams / Slack so everyone is immediately aware when a PR is made.
Go through the samples https://github.com/dodyg/practical-aspnetcore
I haven't heard a good reason to do this yet.
This is probably the best bet. It would probably be easy to add some DllImport the "open" and "write" c functions pretty easily. See this: https://stackoverflow.com/questions/6947413/how-to-open-read-and-write-from-serial-port-in-c
It's fine. Most things will carry over to ASP.NET Core 3.0. The biggest changes are on ASP.NET Core is Endpoint routing. You can check all the samples for what's new on ASP.NET Core 3 here https://github.com/dodyg/practical-aspnetcore/tree/master/projects/3-0
An uncaught exception was thrown in your application. If you click debug you should be able to see the exception in visual studio and debug.
Scripting and prototyping
one file project instead of spreading it across controllers etc, its pretty nice to work with for small snippets that arent production. For example creating rest api's in a console application for net core ?
Thanks!
Thank you too!
Look at [this SO question](https://stackoverflow.com/questions/29005877/what-is-the-advantage-of-using-tag-helpers-in-asp-net-mvc-6) for a good explanation of what advantages tag helpers have over html helpers. Basically, it boils down to html helpers having not much customization beyond what their properties expose. With tag helpers, you can use anything that normal html tags support, without needing to write extension methods or anything.
Yes because Core 2 and 3 are very similar, and double yes because Adam Freeman writes a lot of good books on a lot of different subjects.
This has been one of my biggest frustrations with where .NET is and has been for a good decade now. Those that are entrenched in latest and greatest love it, but for those of us working with older tech, you can't possibly get a book in time for the tech to still be latest. Things are just moving way way too fast these days.
This is built in to Azure DevOps using the checklist icon in the top right near your profile photo and viewing the "Pull Requests" tab.
This is more or less how we do it. PRs aren't really assigned. We use WebHooks to just slap all PR openings into a Microsoft Teams (RIP Slack...) channel and the team is responsible for watching that channel for notifications. People aren't as responsible with this as they should be though, so sometimes a PR can sit for too long.
If you don't mind me asking, what's the benefit of several projects vs a single project with all repositories?
How so? If you ever used Java, C# is pretty much the same.
We have multiple teams and each team has there own projects. It allows us to control who can push to a repository. If I had to guess I’d say we have well over 100 repositories. We are doing a domain driven micro service approach and each solution file is in its own repository. We’ve also broken out the service side and the web side. Each team does its own planning and sprints so having multiple projects allows for each team to control that. It gives the options if one team wanted to do agile and one wanted to do Kanban. We also have a thing where we have a common code base and formed projects for multiple clients (as al alternative to feature flags). That way we create a new project with the forked projects for the clients.
Is Castle still actively maintained?
I assume you're talking about Roslyn? And do you mean after seeing that up, you can use one of the AOP implementations, or that you wrote your own? Thanks!
CS-Script sits on top of Roslyn, CodeDom, and something out of Mono. It's not my project but I have found it to be useful.
Yes, it is maintained. Take a look at their github repository and you will see recent commits and activity in the issue tracking.
Yeah. You forgot a reason other than "nice to work with".
Reading that will introduce you the whole idea. After that, you can keep up with Microsoft Docs,Channel 9 and NDC conferences videos. Also there are some advanced topics like caching, token-base authentication, SPA integration, etc, that I haven't seen on any ASP.NET book I read.
Sort of depends what you're trying to get out of it. Even the very first ASP.NET PRO MVC book that Sanderson wrote was really good. The book is a good example of solid MVC architecture. I still refer back to it from time to time as a reference because it is the thinnest of all of them. In terms of the latest ASP.NET MVC info, well, yeah, the first book ain't gonna have that. The Core2 book should still be largely up-to-date. I'm sure there are important changes, but even between the 1st and 2nd and 3rd books, you could see how the main foundation was put down in the 1st book and then they all kind of build from there. Even though they are all stand-alone books in their own right.
Why would one post a guide for 5 when 7 is current version?
You don't actually need a csproj file, you can run csc.exe from the commandline. https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/compiler-options/command-line-building-with-csc-exe
There's a Pluralsight course called ASP.NET Core Fundamentals that was just published in January 2019 and uses .NET Core 2.1. I just started it myself and the initial project setup is an ASP.NET Core web app with Razor pages. The entire course is 5h 44m so it should be something you could get through in a free trial period. As others have said, it really depends how you learn. Video courses aren't for everyone. Good luck.
Use create-react-app to make the front-end "project" and use the web api c# template for the backend. Don't mix them for development purposes. Use the built-in proxying in create-react-app to call your web api so you don't have to worry about CORS while learning. If you want to host it on the public internet, you can either build the React app and host it in your API project, or just host both things separately and config CORS correctly. I've built several apps like this, personal and professional, and don't have a compelling reason yet to do differently.
5+ means it will work with 5 and later.
I am currently using Angular and .Net Core and I could not get formdata to work when providing a content type. I have an interceptor that automatically adds content types based on request type. When I set it to multipart/form-data, model binding failed on the IFormFile (was always null). Removing content type header for specific requests when including form data resolved this issue. Not quite sure why but I didn't have time to dig into detail.
Hello! Can you share an example? IFormFile can be null if your keys mismatch. Example: from frontend you send "file" (in formdata), but your controller's action parameter accepts "fileContent".
Was not an issue with parameter mismatch because it worked through postman using the exact same for data parameter type. I'm on mobile atm but can check tomorrow for an example
you need to use the F1 plan. that‘s the free one (not time limited) https://azure.microsoft.com/en-us/pricing/details/app-service/windows/
After digging deep through release notes, the earliest I could find was in 2004 for NUnit 2.2.. Net came in 2003, so I still wonder what they used before that?
This sounds promising, thanks.
.NET came out in 2002 and was in beta even before that
NUnit 1.0 seems to have been done by Philip Craig in 2000. Supposedly at XP2000 conference. License has some dates http://www.copyleftlicense.com/licenses/nunit-license-version-10/view.php
Thank you!
What about MSTests? 2005?
MSTest was released with VS2005 which came out in October 2005 https://en.wikipedia.org/wiki/Microsoft_Visual_Studio#2005
Is not available for Net Standard projects?
I don't have access to a Windows Computer at the moment, if I was I could fork the project and try it out. However If you were to change the CS proj to multi-targeting it might be quite simple.
I recommend putting the transliteration in separate language-specific packages. It will keep the size of the main package down, allow clients to choose what languages they want to support, and make adding new languages simpler
Interesting! So you'd say to completely avoid the SPA templates built into.NET Core. Honestly that does make sense. They seem to not really be kept up to date. I had thought maybe I was just starting this at an awkward point in the cycle for .NET Core 3.0, and maybe they were leaving work on the templates till closer to release. I had been thinking maybe I need to go with 2.2 instead for now and upgrade to 3.0 once it's actually released. But I guess if I just don't use those templates at all, that isn't a concern.
I haven't looked deeply into code, sitting on mobile ATM, but 2 things I'd think about are: 1. Port it to dotnet core and/or netstandard and utilize Span&lt;T&gt;/Memory&lt;T&gt; wherever possible to avoid unnecessary (in core world) string allocations and copying. External API could expose both string and Span&lt;T&gt;/Memory&lt;T&gt;, but internally it should only use those fast types. 2. Expand the fluent API. Overall it's good but I really don't like the`.Apply(new InversionEffect())` methods used as standard API calls. I'd prefer overrides like `.ApplyInversion()` etc. Could be a simple extension methods wrapping current calls in easier to find methods. It's much easier, when using intelisense, to see what methods you can apply, instead trying to remember all types you can new. I don't think there's any simple to filter types that implement certain interfaces, for example. Generally I'd say, leave the `.Apply(new TypeEffect())` for special cases, extensions, plugins, and use `.AplyTypeEffect()` for the standard cases.
Could you elaborate? Is this a custom field within Azure DevOps? Is it on the PBI level? And what type is it? A Boolean indicator showing the code review has been done? Or can it maybe be a Code Reviewer and a developers name can be selected? We do pull requests. All commits need to be reviewed prior to merge to develop. Maybe that is enough?
Yes, MVC is a joke, it is the php pig with lipstick , I work in MVC but should really be doing a JavaScript front end with web api, just can't be bothere to change jobs.
We do Pull Requests. From a feature/ bug branch into Develop. And we have a verbal rule that a PBI shouldn’t be marked as Done until the PR has completed. This brings about issues. It’s verbal. So “Done” could be selected prior to PR. But it kinda works.
Yeah. This seems like a lot of people’s thoughts. I am wondering though, if Core 2.2 has made MVC a better contender. Kind of like EF. EF6, I liked. But it had issues and I moved to smaller ORMs such as Dapper. But with EF Core - it seems things may be better and turning back to EF is an option. Just wondering if MVC has had the same renaissance.
Take a look at Blazor - https://dotnet.microsoft.com/apps/aspnet/web-apps/client . It's in preview, but looks very promising IMHO. You can do SPA with it.
exactly
A lot of developers over complicate things. &amp;#x200B; Personally for a lot of web apps MVC style application with unobtrusive JavaScript are perfectly fine. It really depends what they are doing. Those that laughed at you aren't probably not that mature in their technology choices.
What are you on about? PHP has it own MVC frameworks as well. It is simply a way of organising a web application logically. BTW Web API uses the same pattern as MVC, they are so similar Microsoft merged parts of the framework. [https://stackoverflow.com/questions/32353866/what-is-the-difference-between-mvc-controller-and-web-api-controller-in-asp-net](https://stackoverflow.com/questions/32353866/what-is-the-difference-between-mvc-controller-and-web-api-controller-in-asp-net) Consider the following: * Why should the front end be JavaScript? * What is the benefit of it being JavaScript? * Can it be done without JavaScript? Unless there are solid answers to those questions you are most likely just guilty of cargo cult programming if you are going for the SPA approach. [https://en.wikipedia.org/wiki/Cargo\_cult\_programming](https://en.wikipedia.org/wiki/Cargo_cult_programming)
Don't. ASP.NET framework will be supported for quite long. I would say: develop new stuff on .net core, slowly deprecating your asp.net framework codebase. 10 years down the road, all your customers would forget your old app.
**Cargo cult programming** Cargo cult programming is a style of computer programming characterized by the ritual inclusion of code or program structures that serve no real purpose. Cargo cult programming is typically symptomatic of a programmer not understanding either a bug they were attempting to solve or the apparent solution (compare shotgun debugging, deep magic). The term cargo cult programmer may apply when an unskilled or novice computer programmer (or one inexperienced with the problem at hand) copies some program code from one place to another with little or no understanding of how it works or whether it is required in its new position. Cargo cult programming can also refer to the practice of applying a design pattern or coding style blindly without understanding the reasons behind that design principle. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/dotnet/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
Thanks. I looked at that 6 months back. But it was extremely new. But you have reminded me to take a peak and see how Blazor is going. I hope it does well. But because it has “Microsoft” all over it - I wonder if it would be adopted by the current JavaScript guys. Hopefully. Because in theory- it sound great.
I wouldn't think in terms of frameworks or what is in fashion. It isn't a bad idea to learn different approaches and learn where they maybe more appropriate. TLDR; "Use the right tool for your problem"
&gt;Yes, MVC is a joke, it is the php pig with lipstick Stupid opinion, not a reason at all on why MVC would "suck".
Thanks. In answer to your questions. I’m not sure if the front end should be written in JavaScript. With React- I guess we have partial dom updates. So maybe less screen flickers? Less payload between server and ui. But - with today’s browsers and internet speed - is that a factor? I’m not sure. So as for benefits of JavaScript- I suspect quicker ui updates? If you have something like Redux or some state management - maybe fewer UI to Server calls. Can this be noticed or handled equally well with MVC? Maybe. I guess I need to spike. Can it be done without JavaScript? I hope so. I personally get really bogged down in React/JavaScript. Probably because I’m crap at it. But it seems very disorderly compared to c# code. So I hope the answer is Yes. But not sure.
Seems like first beta was made available late 2000. https://jonathanparker.wordpress.com/2014/12/05/list-of-net-framework-versions/#Table_of_.NET_Framework_versions
Currently migrating from classic asp 2.0 to .net core, I'd love to have your problems instead
It really depends on what you are using it for. Would you use a street car to join a F1 race? No, because a street car is significantly slower than an F1 car. But you can do a lot of things with a street car that you can't do with an F1 without modifying it heavily. MVC is the street car. You can do most things OOTB with little to no customization. The scaffolded UI code will be reliable and pretty secure so fucking it up will be harder than with a SPA. SPA is the F1 car. It can be fast as hell but you need a lot of maintenance in comparison to a MVC app. You need to do everything server-side and client-side and if you don't know what you are doing, it can be very insecure and buggy. There might be better analogies, but I hope it's enough to clarify things a little.
1) Change the existing application to use [Friendly URLs](https://www.hanselman.com/blog/IntroducingASPNETFriendlyUrlsCleanerURLsEasierRoutingAndMobileViewsForASPNETWebForms.aspx). 2) Page by page, replace existing ASPX pages with MVC Controllers/Actions at the same URL. 3) Once all Web Forms pages have been removed, switch from MVC to ASP.NET Core. Step 3 is pretty trivial; step 2 is going to take a while.
Products don’t always work that way. We’re still actively evolving and selling a web app that dates back to 2003.
They’re not that different - they both boil down to a complete rewrite. The Web Forms one might be easier to rewrite in place, but that’s *more* work than a ground-up redo like you’re faced with.
Start over from scratch...
Personally, I would avoid MVC. It certainly has it's place but it also has it's downside. Unless you're working with legacy code, most modern projects use "hard separation" between the front and back end. This separation allows you a bit more flexibility when it comes to changing requirements in future. It also allows you to test things in isolation easier, e.g. test the API call X returns model Y given precondition Z, which can be a bit more difficult with an MVC architecture. With an isolated API, a mobile app, a website, or a shell script can be used to drive your site. The API is a product of its own. Any any point I could think "Do you know what, I want to turn this lovely website into a console application!" and you shouldn't have to make any changes to the API, you only need to write a new UI layer (console, web, desktop, etc) that communicates with the API. If you're starting something new, I would definitely recommend isolating your API layer (whether than be C# Web API, a set of raw HTTP listeners, or some C++ based server). Would also recommend learning *a* JS UI framework. If you haven't used a JS framework before, it can seem a little silly. About a year and a half ago I was of the opinion "pure JavaScript does the job, why would I need to look into a custom framework". It's not until you start working on a framework that you realise how much easier your life has just become and you feel a bit more comfortable getting creative. You should look up what is in use in your current area. We have started using Angular and .NET Core Web API for our new projects, but it'd be worth looking into React, Flutter, Vue. It's important that you not only pick a good framework, but one in which you can hire locals that are ready to develop. If you start an Angular project in a city that only has React developers, it's going to be a bit more expensive to hire appropriate employees.
My questions were more of "When starting a new application, what architectural decisions do I need to make?". I also should have been more specific and said a SPA frontend. So lets be clear about definitions. When most people refer to: * [ASP.NET](https://ASP.NET) MVC - A Web application that is a mix of HTML that is rendered server side with some JavaScript that is used for animations, calls back to the server for minor UI updates. * A SPA is where almost all the frontend is rendered by JavaScript and the frontend communicates with the server using JSON via Ajax calls. You can build an [ASP.NET](https://ASP.NET) MVC site with no JavaScript and just use GET, POST, session state and cookies to manage the state of the application. You could create a SPA that loads HTML generated via the server using Ajax. React / Angular are just a SPA frameworks that does most of the heavy lifting of dealing with application state, component interaction on the front end.
This, break your code into stand alone APIs, use gRPC and protobuf since net core 3 supports it and wrap your grpc calls restfully if needed. Create a spa using react and redux or angular and ngrx, use the APIs you just made
Thanks. Good points. Separation is important. I forgot about that. We expose apis to different clients and other systems. So that’s a very good point. I use ReactJS at the moment. Have been for a year. But I’m still not confident in it. I find it all very - loose. Hard to navigate. And the enter Redux and I’m clueless. How the hell did that property get that value?! :) I like it though. I wish I was more a guru. I get other developers to work on it. Your points are all very valid. Much appreciated.
I work for a large publisher. We strore them as HTML with all the formatting tags (sup, sub, strong, em, etc) including references to external resources (images and video on a CDN). We render the pages in an HTML view control.
Thats really interesting... but you then show it in a specific web page? Im aiming at this being shown maybe both, phones and web, but mostly phone app. How would that work then? Also the way you do it, wont the looks be fixed?
So you can use an SPA on top of an ASP.NET Core MVC API. The dotnet 3.0 React template has authentication available now, and the auth pages are all Razor Class Library views. I’ve deployed React + ASP + whatever db a few times now. It REALLY depends on the app and the use case. I like the hard separation, but would I spend weeks on an internal-use-only web app for simple CRUD operations on a couple database tables? Hell no, scaffold that sucker up from the ground with Entity Framework Core in a few minutes and turn it loose
One thing I will say is find a good book or set of tutorials and force yourself to go through them. I've had it easy working with C# and WPF for the last year and a half. I know what I know, I know what I don't know, and most importantly I know what to Google. I was thrown into a mature Angular project without having experienced before and without giving myself the time to actually do any reading. I was able to work, but I was unsure of every action I was making and I found it hard to Google because I didn't know the correct terminology to use for that technology. Recently I've been taking time out of work to sit and read up on certain things, e.g. RxJS for Angular, and I've found that I'm not longer "stumbling blind" and although I still don't know a lot, I know how to Google for the right things when I do get stuck.
byte array.
You can still edit CSS files that you download from you CDN. So you still have control on how everything looks.
Hmm how would that work? Not worked much with byte arrays. Is that just to compress it sizewise? What would be needed for frontend to play this file? maybe I should have mentioned this is aimed to be used by a mobile app! thanks a lot for your answer!
oooh nice! Also what is a CDN? xD Im kinda new to this stuff! But in mobile apps they dont use html, so how would it work for mobile apps?
Where as we are migrating from classic asp to web forms.....
A CDN is a bunch of servers from which you download files like JS/CSS from.And you can definitely use HTML for developing mobile apps (not so sure about iOS though, but for Android you definitely can). However, there are some restrictions like not being able to access the sensors on your phone IF you are doing HTML-only apps.
So you would load the file as a byte stream and it would populate an array of bytes. If you are targeting mobile, I would recommend a framework like gRPC because you can easily setup a bidirectional stream, where each streamed response is a segment of the byte array, that way you can buffer loads. As far as storage of the files I would not use a database necessarily, I would use something like the AWS S3 or I would setup some form of network storage.
Yeeeah my wallet is limited for this project so Im trying to keep away from cloud :P But thanks, this is obviously something very new for me so a challenge! Hope it goes well hehehe .. Seriously thanks so much for sharing knowledge!
Now add all the steps for how to make authentication and authorization seamless between the old web application and the new one. How to make it so that the client doesn't even know that a part of the menu now opens up pages that are executed on Core, because it all looks identical.
Exactly. We have a Webforms web application (authentication, authorization, dynamic menu based on auth, etc.) that was in development until about MV5. Then we realized you could host MVC5 and Webforms in the same process, so it was easy enough to develop from that point on on the MVC5 side of things. We were able to reproduce the look at feel on the MVC5 side of things, identical to the Webforms. In other words the client didn't even realize there were 2 technologies at play, unless they looked at the url (.aspx or no .aspx). It seems to me we're at the end of the road here, since Core will have to be in a different process, hence different web application all together. To integrate that with the existing site would be to work out some sort of seamless signle sign on that would retain the authentication and authorization. Hopefully make it's quick enough where transition between menu clicks are more or less seamless, without a lot of redirects etc, where the client still feels that they are on the same site. I don't know the best/easiest way to accomplish this. I do know slowly "deprecating" is not an option without rewriting those pieces. Those are all core business functions, clients aren't going to somehow forget about them because they've been around for a while.
What are you running on then? I would just setup a directory for you to place the files and store only file paths in a database so you can load them that way. No reason to tax a dB on essentially file storage. Also look into S3 pricing, it's very cheap: https://aws.amazon.com/s3/pricing/ You don't have to use any of the other Amazon stuff, you could use just the s3, although even a simple server would only cost 8-16 a month and would probably do more than enough in terms of what you need.
I had never heard of SPA framework before: https://en.wikipedia.org/wiki/Single-page_application (for those curious wtf it was...)
yeah, don't stop selling this web app. Just replace it with other web app built on newer technology as time pass. First as simple "add on" until you expand more and more feature. Look how .NET Framework is getting deprecated in favor of .NET Core! Microsoft does not drop .NET Framework, they just took several year building something else on the side that grow slowly until making the old product deprecated.
Honestly, this sounds like the right answer. ASP.NET MVC brings a lot of benefits to it and if you need to create a SPA, then just slap a SPA on top of it. But you still have the flexibility to scale out with MVC if need be.
I wasn't suggesting running on Web Forms and [ASP.NET](https://ASP.NET) Core simultaneously. Porting to MVC on [ASP.NET](https://ASP.NET), and then doing the [ASP.NET](https://ASP.NET) Core port in one shot once everything's in MVC, seems to me like the safest way to do things.
That... is a mistake. Ten years ago that would have made sense, but now you're just moving from one deprecated technology to another.
Ah yes, I love the often "just port your stuff to Core" arguments on forums. We have over a year of development for multiple people to port the web application over. There is about 0 chance management will go along with that until the technology is literally end of life.
I wonder if the URL of the article in 1) is supposed to be ironic
Depends. Use the stack to fit your projects’ needs. I typically run API, since most of my projects share data between applications so it makes sense. If I were going to have a massive site with a single database or running off mostly existing services, then MVC would be easier to maintain for a team.
Hmmm I see. Thanks so much! Im gona use xamarin so I'll see what fits it best. And think around what functionality I need and if html is good enough or not. thanks a lot!
Xamarin is a really good entry framework for building mobile apps, especially if you are already familiar with C#, so it's an excellent choice. Good luck and have fun.
YEah I need to think about security. But yeah I thought just buy a domain and have the db and server given from that. No cloud yet. But I'll think about the free storage ! Thank you so much!
Thanks!!
That's why I suggested doing the port to MVC first. That can be done alongside existing work in the existing application, without significant disruption. (Each time you would touch a page, rewrite it in MVC instead.) Then when it's all done you do the port to [ASP.NET](https://ASP.NET) Core. Assuming you don't have any other technologies unsupported by [ASP.NET](https://ASP.NET) Core (e.g. SSRS, server-side WCF), the final port should be a few manweeks of effort, not multiple manyears.
TypeScript is built by Microsoft and widely accepted by the JavaScript community. If Blazor turns out to be a good, stable, and fast platform, I don't think the association with Microsoft will hurt it too much.
It really depends on what you want. It's always a good idea to plan out than just outright slapping an SPA for everything. An SPA adds maintenance complexity to your requirements as you'd need to validate stuff two fold. If you're gonna share your API with other apps then yes, an API is a good candidate for that. If it's just a single app that does simple tasks (basic forms and CRUD without needing much interactivity) a good old Server rendered HTML via Razor and a sprinkle of JS is many times simpler and at times more secure as you'd only need to validate on the server for most of the part (in an SPA without proper code-reviews one could forget to add validations on the API side and just leave it to client-side validation). If you'd need alot of interactivity and dynamic stuff, or complex forms then an SPA is a better fit for the requirements. As one would say, "don't try to use a backhoe for digging up a small plot for your garden when a shovel can do the job just fine".
Yees, having used mvc for past hmm 5 years, makes this more than an opinion, did php back in 2000's, so I got a few years for my stupid opinion, what you got? :)
Doc reference is here: https://docs.microsoft.com/en-us/windows/uwp/design/controls-and-patterns/web-view I think the feature you're looking for... which is what we use is the third one in the example: &lt;!-- Source file is in the app package. --&gt; &lt;WebView x:Name="webView3" Source="ms-appx-web:///help/about.html"/&gt; Because it's HTML you can still use responsive web design. We find it's the easiest way to maintain content for UWP apps. If you wanted the same content for both phone and web... you'd could just reference the HTML content on the server using example #1: &lt;!-- Source file is on the web. --&gt; &lt;WebView x:Name="webView1" Source="http://www.contoso.com"/&gt;
It doesn't matter how many years you got under the hood. Even an experienced programmer can use his knowledge in the wrong way. The fact that you fail to see this makes you look even more like an amateur, and an arrogant one at that.
I've never heard of a domain also getting you a server that you can easily deploy custom software to. Not sure what provider you are going through. Best of luck!
It depends on how you want to listen. Assuming a website. The audio must be transmitted in a format compatible with your browser, e.g. mp3. If your audio files are already in the right format, all your API needs to do is send the file. The file is an array of bytes (compressed as mp3). .NET Core has a FileResult you should look at which is meant for sending files from an endpoint. I can't remember but you may need to set the media type, e.g. audio/mp3.
did php back in 2000's, did webforms and moved to mvc as soon as it was available, watched our SPA programmers not having any of the idiotic problems caused by server side of processing of what should be handled on client side. Thanks for the cargo link, but that was around back in 2003. I don't think the archtectural reasons would make sense for you, but back in the day I wouldnt do js to save my life, so in 10 years time you can answer those questions yourself. I am too old to give a shit about who likes to do mvc or spa, I'll do either myself if work dictates it without problem. I gained nothing new from the counter views to doing client side programming. none the less thanks for letting me know Cargo thing is still a thing.
We’ve got a webforms app in our stack that uses the old asp.net identity model. We’re mid migration of it. If the app is of any size, it is a large investment. First thing was oauth implementation. We ended up using both principals (AD + oauth), but if you’re using forms logins, you shouldn’t have a rough time moving to openidconnect. I’d probably migrate the users and roles, force a password reset, and go from there. There isn’t a massive refactor there unless you’ve gone totally custom. We pushed a lot of our business logic into webapi, and used the janky webforms async handlers to call out. We embedded an angularJS app into the master page, so any new things become angular controllers calling out to web api. I’d use VueJS at this point, but our Angular stuff went in years ago. The JS framework helps migrate off of webforms, since it can be hosted in anything that spits out html. Next steps for us: translate webapi business logic stack into Core, which is our largest task. We can piecemeal it, since it’s already disconnected from webforms via Rest. Our own scaffolding is hardest to account for, since our old stuff is a lot of static business layer implementation, the new stuff is separating those methods into specific non static classes for use with MS DI. Then translate any remaining postback stuff into a JS framework. (Rest of the f’ing owl)
Yeah, authentication is what’s killing us right now. We want to go from forms auth to JWT so we can migrate to Core for new features, but it’s hard when we have multiple apps depending on the old style of authentication.
Again I have no idea what you are on about. TBH none of what you said makes much sense.
From what you said you dont even sound like having the knowledge to even sound arrogant, keep doing what you do, you don't even look like an arrogant amatuer , maybe you can get there too in 10 or so years, best of luck :)
I agree with Scott Hanselman (who I actually was lucky enough to see talk about the future of .NET at a conference this Friday)... Keep your existing stuff in .NET Framework, do your new stuff in .NET Core (there will be a .NET Core 3 Release Candidate later this summer, there will be no API-changes between then and the release of 3.0 in September.)
OP is asking about using MVC vs SPA. I really wouldn’t recommend jumping on a complete paradigm shift that is only in preview to someone that is looking for an Enterprise-level application.
Keep your existing stuff in Framework. If you have extra cycles (if you do I’m supremely jealous), start migrating shared libraries to .NET Standard. That way if you do ever decide to make the jump to Core all you are converting is one project. That being said there really isn’t a reason to migrate at the moment since there isn’t a planned EOL for .NET Framework. That would have catastrophic consequences on the Windows OS and all of the current customers using Framework. So there are steps you can take but I wouldn’t prioritize them until a true EOL is announced unless there is unallocated time to do so.
This. I would think most corporate CRUD apps are pretty boring to most developers, so they tend to try to make things more interesting for themselves. High percentage of these apps would be better off in a traditional Monolithic architecture to allow low cost maintenance, in whatever platform you want to use.
Yes.
Nope, if only because MVC doesn’t foster separation of concerns and good decoupling like building an entirely separate service with a well-defined interface and a thin client that talks to it.
Let us know what you did once you figure it out.
I would also prefer extension methods on `string` rather than the `UseWordyTo` stuff.
I don't like having too many extensions on base types - they really tend to clutter the intelisense. It's even worse if you use things like resharper or IntelisenseExtender add-on - which list all, even not-yet-loaded-ones, overloades and extensions, that you can call. I like the way FluenAssertions do this stuff. You have one extension on types - `.Should()` - and then the rest of the extension are on the `.Should()` type/call. This way you have the relevant options nicely grouped up, without going through massive list of all potential extension methods.
I would NOT, think about effort vs gains, there is probably BIG imbalance
I’m not sure how this is an argument against traditional MVC. Just because it’s easy to abuse MVC and build in a manner where the front and back end are strongly coupled doesn’t mean you have to do things that way. You can still build out an MVC app where you treat your service layer _as if_ it were a REST API. Then the only thing the “MVC” portion of your app is doing is converting results of those service calls to dedicated View Models, as well as the bare minimum needed to handle HTTP. Then, if one day you decide you want that console app, you can whip up an actual API in a matter of hours that’s just a pass through to the services you’ve already been using in your MVC app, and there you go. To me, the decision should come down to how interactive your front end will be. It does take experience working with a variety of front end systems to be able to anticipate what will technically be most difficult in the Framework you’ve chosen. Assuming your app is simple enough, you can avoid a ton of headaches by keeping the your rendering serverside. But the inverse is also true; some front end apps are so complex and dynamic that attempting to build them in MVC may be way more trouble than it’s worth.
If you have requirements around starting to use containers and autoscaling with Kubernetes, that’s a reason to switch. Most ugly .NET apps I’ve seen though aren’t easy or pretty to convert. So many sticky sessions and relying on HttpContext to where it’s impossible to start unit testing.
Too true about the testing (sticky sessions are evil) but to do a 1 to 1 switch there are Windows containers with IIS. Switching to one of those containers isn’t bad even with the sticky sessions until you want to start auto scaling.
To each their own, I guess. Personally I don't care at all about cluttering intellisense, and no one on my team uses ReSharper or IntellisenseExtender. I think you could still do the single extension method thing with this library though. Something like `.Transform()`.
Why not just say 7+ though? Who is still using 5 when the upgrade path is so easy? Why use an old version in a tutorial?
Pretty sure it runs fine in OWIN and. Net core. No?
Oh, wow, NancyFx is **not** dead and they **finally** released the 2.0.0 version? Only took them over 2 years since the last preview release.
Why not just use ASP.NET Core with Kestrel? That thing is super scalable and you can just use Middlewares and not touch MVC at all.
I want to deploy as a Docker container (or containers) on a Linux server. Maybe [this article](https://docs.microsoft.com/en-us/aspnet/core/host-and-deploy/linux-nginx?view=aspnetcore-2.2) shows how I could do so using your idea?
Nancy is a very performant and scalable web framework. It isn't an alternative to a web server, it runs it's own and has number of different options (see https://github.com/NancyFx/Nancy/wiki/Hosting-nancy-with-owin for some options). Most web applications these days run as two tiers. First, as you mentioned, something like Apache, IIS, or nginx as the primary web host. There are a lot of features you may want, including serving static content, request caching, https termination, etc that these offer that aren't really the concern of your application. The actual application requests, e.g. what would be handled by Nancy, get forwarded to your application that's running its own host. You don't need the Apache layer. You can certainly start up a Nancy application and expose it directly to the web with great scalability (e.g. you can host it with ASP.NET's Kestrel, which is one of the fastest web hosts ever created, way above Apache), but in most scenarios, you'll have a want for both.
Where are you actually hosting this? Your own server? A VM? It seems like you're somewhat new to all this. Most new apps these days are run in some kind of Platform as a Service offering, like Azure Web Apps - where you can simply provide the container and it handles the rest. You don't need to be configuring something like Apache yourself.
Thank you for details! I will investigate.
If you can enumerate the loaded assemblies, if I remember right, you should be able to call .Location on the assembly object to see where it has been loaded from.
Ultimately, I'd like to deploy a Nancy REST service that talks to a PostgreSQL database alongside a Node-hosted ReactJS web app that calls the REST service, all packaged ed up in one or more Docker containers, and deployed to a public Linux host like Linode, DigitalOcean, or to Amazon Web Services. I favor NancyFx because I'm more comfortable using C# for the backend, and love how easy NancyFx makes it. I tend to develop on a Windows machine, but greatly prefer Linux over Windows for the deployment environment.
Thanks, will investigate!
I will investigate, thanks!
Sound files are exactly as they sound - they are files. Therefore you should store them in a File Storage provider like Amazon S3 or Azure Blob Storage. In the database, you store the location of where the file is and then either return a URL to that file, or download the file and return it as a byte array.
Broadly speaking, I think most would agree that SPA is a technically better solution than server side rendered applications. That said, there's pros and cons to everything. If your priority is simplicity from a development perspective, MVC is probably still better. In pretty much all other respects though, I'd say SPA is superior.
Store the audio to a file system and a file identifier in the database.
So your addition to the "keep the supported legacy code base" comment is "use an experimental component which went to preview only a week ago". Chill. Let grpc mature and in the meantime use techniques that asp.net core has perfected. Regular web APIs without strong binary interfaces like protobuf.
Yeh. I think once you get more than 3 layers (Presentation, Business Logic and Data Access Layer) it probably too much.
You can easily run a standard .NET Core application in docker container on a linux host without Nancy. The Google cloud tools visual studio extension lets you easily deploy a .net core application in kubernetes on GCP (GKE) with a click of a button. It’ll provision a public IP and route it to the application for you if you so desire.
Why not migrate to 2.1 first and go to 3.1 when it's in lts at the start of 2020? Migrating from 2.1 to 3 is less of a problem than from web forms to net core. At least with 2.1 they have a LTS release.
We've been using grpc in .NET since 2016. It's not new technology. The Grpc.* And Google.Protobuf.* packages and tried and true techs. This is actually the approach we took: moved legacy stuff to grpc on .net windows, port web frontends to use it (and remove direct db access), then port web frontends to be on asp net core, and then slowly migrate grpc backends to .net core
We use jira for our stories and sprints. In jira you can create custom statuses on a ticket. So basically we have bunch Todo, blocked, feedback, in progress, code review, released to uat, done I'm sure you can do somerhing simular on Azure Dev ops?
JS folks ... don't worry about them. If you are talking about a developer, they'll be more concerned about what's a solution that fits the needs of the end-user. I haven't used Blazor yet, but at a glance, I'd say the potential reduction in developer population that can work on the front end in JS will be more than made up for by server-side / C# developers who will be able to build SPA apps in a language they know well. MS seems very serious about Blazor, so I'd expect it to be around for at least as long as ASP pages, WebForms, MVC, etc. That said, it is not yet at a full 1.0 release, and server-side Blazor will be available before client-side. It may not be a suitable choice for your use-case yet.
Would you have any documentation (presentation, book ?) to do so ?
Totally agree. If a consumer wants to have their custom apply supported via that simpler API then they can open a PR.
You mention that you want to avoid cloud charges. If this is just a pure learning project for yourself, you can develop on your home machine in Visual Studio Community Edition at no cost. You can run a local / development instance of * SQL Server - database - a local version is bundled with Visual Studio, but you can also install the [Express edition](https://www.microsoft.com/en-us/sql-server/sql-server-editions-express) separately * [Azure Storage Emulator](https://docs.microsoft.com/en-us/azure/storage/common/storage-use-emulator) \- Files / Blob storage for your local machine that emulates the Azure cloud services - free * [Azure DevOps](https://azure.microsoft.com/en-us/pricing/details/devops/azure-devops-services/) \- store your code in a cloud rep - free - that also connects to related services for building, testing, deploying in the cloud. Free for up to 5 users. Maybe you want to build a team to work on this with? There you go, the free tier supports that. [Azure has a free cloud tier](https://azure.microsoft.com/en-us/free/free-account-faq/). It should be more than enough for you to work with, and learn the basics of developing locally and deploying to the cloud. Look at that page and you'll see the App Service (where you would upload the app) supports up to 10 apps in the free tier. Some of the discounts and free access are limited to the first 12 months, but that's enough to get a project like this off to a good start. Also, yes, store files in the code as byte arrays. Put them into a file on the file system or storage services like Azure Blob storage, then store the meta data, file location, etc. in your database.
Wouldn't it be easier to have multiple projects, but residing in the same TFS or GIT? Then packages each as nuget package, and import the needed ones in the other projects.
FFS, who in their right mind is recommending Unity in 2019. Go get yourself Autofac and use WebForms plugin https://autofac.readthedocs.io/en/latest/integration/webforms.html
Should have told them, I use MVC for my backend core application which supports any client side JS framework.
Yeah. To be honest, I get a bit confused here. Either it’s MVC or it’s WebAPI, right? So if you go MVC, you’re choosing to do your front end in .Net MVC with server side HTML and all that. But can 3rd party users make use of your controller methods - like in WebAPI? I guess they don’t serve JSON - so probably not.
Thank you, I will investigate that.
What your looking for is load balancing. Nancy is really designed around ASP.Net MVC so it's best run on IIS or kestrel. No built in load balancing there but it can easily be done. You already mentioned docker. So I suggest you check out Traefik it's not the best option but in my experience it's the easiest to setup I've ever seen. https://docs.traefik.io/basics/#load-balancing Note. Nginx would be faster but it's notoriously difficult to setup.
This [link](https://en.m.wikipedia.org/wiki/Inuit) has some info, but I don’t see how it pertains to this sub.
Desktop link: https://en.wikipedia.org/wiki/Inuit *** ^^/r/HelperBot_ ^^Downvote ^^to ^^remove. ^^Counter: ^^259787
**Inuit** The Inuit (; syllabics: ᐃᓄᐃᑦ, "the people", singular: Inuk) are a group of culturally similar indigenous peoples inhabiting the Arctic regions of Greenland, Canada, and Alaska. The Inuit languages are part of the Eskimo–Aleut family. Inuit Sign Language is a critically endangered language isolate used in Nunavut.In Canada and the States, the term "Eskimo" was commonly used by ethnic Europeans to describe the Inuit and Siberia's and Alaska's Yupik and Iñupiat peoples. However, "Inuit" is not accepted as a term for the Yupik, and "Eskimo" is the only term that applies to Yupik, Iñupiat and Inuit. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/dotnet/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
I think you may want to familiarize yourself with how server-based projects such as this are deployed before you commit much more into this. It sounds like you're still learning and might not have a full grasp of everything you'll need. Buying the rights to a domain simply gives you the rights to a name that you can associate with an IP. That's it. What IP you use is going to be the IP the server you use is assigned from that servers ISP. Buying the domain name doesn't give you a server; you're just renting the mapping of name -&gt; your servers IP. Amazon S3 or Azure Blob Storage are both great resources for storing binary data like sound bytes. Like others have said, there are free tiers you can use to try things out. And I believe there's also a free (or at least extremely cheap) tier of EC2 on AWS for hosting your code (the server you'd buy a domain name to point to). This isn't meant to discourage you at all, I just don't want you to run into an unexpected surprise that forces you to rethink something after the fact.
Its more like you get a domain a server and a db. You pay for it and the size of storage is limited but yeah. Not sure how normal this is. I may look if free azure works . Thanks!
Its for an app thats going to be used. Although its the first time I take on such a project!
Is it different for an app? (Android &amp;ios)
Any ideas how I specify that setting in the SessionStateProvider? In Web.config I have: &lt;sessionState mode="Custom" customProvider="Redis" timeout="20"&gt; &lt;providers&gt; &lt;add name="Redis" type="Microsoft.Web.Redis.RedisSessionStateProvider" host="cname.alias.to.cluster" port="6379" accessKey="password" ssl="false" retryTimeoutInMilliseconds="100" /&gt; &lt;/providers&gt; &lt;/sessionState&gt; But looking at the docs, that's not an option/parameter I can specify?
gRPC can be used without using net core 3... It isn't experimental, you simply treat the rpc server stub as a singleton, and inject a service scope factory so you can create scopes per request. Our company is and has been doing it just fine
Everyone I have seen say it's new hasn't done their research. You don't have to use asp net to use grpc. Net core 3 isn't and hasn't been a requirement for a long time..
To be clear, I am doing exactly this (.NET API, Node/React Frontend, PostgreSQL) with Docker. They should all be separate containers (you can argue that PostgreSQL should be PaaS or at least installed native on a dedicated machine). However we use [ASP.NET](https://ASP.NET) Core with Kestrel and it's been nothing short of great. I would highly recommend looking into that over Nancy.
Sounds like exactly the problem, but given this is happening inside the RedisSessionState module, I don't think this is something I can change the behaviour of! That said, I've found a way to attempt to force a DNS flush, so I've added that to the code in my error page. If I hit an error, it will now attempt a DNS flush via the DLL (i don't know if this is doing a 'dns level' flush, but the example I had talked about doing it within the application pool, so.. *fingers crossed*)
This is so spot on...
The article you linked to shows how to set up reverse proxy for Kestrel on Linux with nginx. However you do not need a reverse proxy set up in the docker container, and even for production , Kestrel is web ready so you don't really need one to go online. Follow [this](https://docs.microsoft.com/en-us/aspnet/core/host-and-deploy/docker/?view=aspnetcore-2.2) or [this](https://docs.docker.com/engine/examples/dotnetcore/#create-a-dockerfile-for-an-aspnet-core-application) doc to see steps for Docker deployment.
You can use NancyFx with Kestrel and .NET Core and it should scale fine (and you don't need to use it with Apache, ngnix etc) Also you may want to check Carter which is similar https://github.com/CarterCommunity/Carter
MVC and WebApi merged into MVC; so it might be a little misnamed now. You can implement everything as WebApi with MVC and have no server-side pages. If you are using ASP.NET Core you can type `dotnet new webapi` to create a new webapi project and see what its like. Also `dotnet new` will show you all the template options you have installed.
I've did that years ago, mostly to learn MVC and knockout... The catch was I ended up writing all of the client side stuff twice, once for MVC, once for knockout. I same problems would apply to (angular, react, vue).
Of course you can do grpc and use older nob-experimental packages. But as OP specifically said "with net core 3 you can do grpc", he was specifically referring to the Microsoft maintained grpc system in preview right now.
Your right, but once you have substantial experience with Angular or Vue or god forbid React, your not going to go back to MVC... &amp;#x200B; e.g. You just spent a year solid on Angular / Core Api and have solved all of the major issues I am going to come up against... Authentication? Written, Localised Dates? Uploading files, Pagination, Modals, Confirmation Boxes, Displaying Errors... All Written. Why take a step backwards on an outdated technology? &amp;#x200B; On top of that I would struggle to justify it for a business. What happens when I leave? They are going to need to go and find an MVC programmer... Chances are all the good developers have moved onto a JS framework so the application will be taken care of by someone that isn't any good.
Yeah but I don't have a say in this matter 😥
[Joel would like to have a word with you about that.](https://www.joelonsoftware.com/2000/04/06/things-you-should-never-do-part-i/)
NancyFx was good before .NET core became a thing since it was the only way to allow .NET to run on \*nix devices, with monolib. &amp;#x200B; Over the last few years it's generally recommended to just use [ASP.NET](https://ASP.NET) Core whenever possible.
**Do not migrate to a preview release\*** &amp;#x200B; \* furthermore make sure that migrating is the right course of action. I work as a freelance software consultant/architect and in some cases it's better for the company to end support for legacy software and focus on writing a new leaner and cleaner solution to provide to their clients, weather they be inhouse or exterior. &amp;#x200B; Make sure to weigh your options and see what would make more financial sense. &amp;#x200B; but if you do settle on migrating and see no other option then make sure to leave yourself a lot of room. I'd say at least 2 months or so. Keep your software stable and running while you preform the migration on a separate branch.
If you use [vertical slice architecture](https://jimmybogard.com/vertical-slice-architecture/), your Monolith doesn't need to become a big ball of mud.
MVC is still a relavent, not an outdated tech. Yeah some people have moved over to SPA's for everything but just because the only tool you choose to use is a hammer doesn't mean everything becomes a nail. If I was building an internal enterprise app, I would MVC that bitch all the way. If I wanted something public facing that was snappy, I might go with a SPA, but then again an MVC app might just be fine for that too. It's all about picking the right solution for each situation by assessing each one individually.
Don't mean this as an offense, but it seems that you're a couple of years behind the times. .Net Core runs natively on Linux and in Docker. There are .Net/AspNet Core docker images prepared and published for this purpose by Microsoft. Mono, on the other hand, is a dead end. Both in terms of support, performance, compatibility and pretty much everything else.. AspNet Core Mvc has come a long way and the set up is very simple. NancyFx showed the way in some aspects but that was years ago and the project is mostly on life support these days. Apache could not and would not help you scale, other than as a load balancer. But there are much better options for that. If you're using a big cloud provider they can provide you a managed one. You should know though, that a .Net Core application is very performant, both on Windows and Linux. It will take a *lot* of traffic before you need to scale out to multiple instances for the sake of performance. Finally, unless you're doing Server Side Rendering, an AspNet Core app is very capable as a static file server, so there is no need for a NodeJS server to serve the React app.
Depends what you are building, what your endgoal is and who your target audience is. &amp;#x200B; I work as a freelance software consultant/architect and I see this a lot. The golden hammer problem, there is no one solution best solves all problems. There are key infos missing from your question, such as how important is SEO, how old is your target demographic rougly, what technology does your clientele use, what technology are they used to, is the finished product a product or is it a service, is it a website, webshop or webapp, what problem does it solve, what are the platforms it should run on,how likely is it that there will be a native mobile app for your product/service. &amp;#x200B; &amp;#x200B; That and much much more are the questions you need to ask yourself.
If you have both target frameworks in each project, you only need to build once... Also .Net framework 4.5.2 does not implement .Net standard 2.0. Feels like you are making things more complex than they are. Just type dotnet build
&gt; e.g. You just spent a year solid on Angular / Core Api and have solved all of the major issues I am going to come up against... Authentication? Written, Localised Dates? Uploading files, Pagination, Modals, Confirmation Boxes, Displaying Errors... All Written. Why take a step backwards on an outdated technology? LOL. What "localised dates" you need a JS framework for WTF!! Outdated technology, what are you on about? It is just a way of framework for organising how your requests work. They merged quite a lot of MVC and Web API. If you understand how JavaScript events and how to modularise your code (just google JS patterns) and learn how post backs work. You can do component interaction without tons of the usual jQuery mess or having to pull in a massive framework. &gt; On top of that I would struggle to justify it for a business. What happens when I leave? They are going to need to go and find an MVC programmer... Chances are all the good developers have moved onto a JS framework so the application will be taken care of by someone that isn't any good. How can people do C# for ages and not know how to move from MVC, WebForms, Web API and back? It is just C# and MVC is well documented, it is supported and it will be supported and documented for quite some time. You are talking nonsense.
Headless oriented with feature tooling [https://github.com/apincik/BlogNet](https://github.com/apincik/BlogNet)
Nice but It's not so mature.
Since this is a greenfield project, go directly to ASP.NET Core 3. The Endpoint routing mechanism is really cool. I've made some samples about them here https://github.com/dodyg/practical-aspnetcore/tree/master/projects/3-0. ASP.NET Core is also BLAZING fast https://www.ageofascent.com/2019/02/04/asp-net-core-saturating-10gbe-at-7-million-requests-per-second/
&gt;If I wanted something public facing that was snappy, I might go with a SPA if you will develop news site, please, don't use any dynamics... only good old school static content without subscriptions, ADs, popups, autoplaying video and similar.
&gt;Would also recommend learning a JS UI framework. Even for backend developer? I suppose C# devs are backend devs mostly
Just noticed a new post this morning that should be worth investigating: [https://www.reddit.com/r/csharp/comments/btegm1/top\_open\_source\_aspnet\_core\_content\_management/](https://www.reddit.com/r/csharp/comments/btegm1/top_open_source_aspnet_core_content_management/)
&gt;Mono, on the other hand, is a dead end. Not exactly. It's still going to be supported and developed as a part of .NET 5 but mainly for uses where .NET Core is not viable https://devblogs.microsoft.com/dotnet/introducing-net-5/
No such plans yet. But as an option, for a while you could use https://github.com/RicoSuter/NSwag/wiki/NSwagStudio - GUI and just open .nswag files from Rider to generate code using GUI.
Posted yesterday an example of using this tool: [How to Add Generated HttpClient to ASPNET Core Dependency Injection (Right Way)](https://medium.com/@dmitry.pavlov/how-to-add-generated-httpclient-to-asp-net-core-dependency-injection-right-way-fec21b3385f1) \- have a look.
Forgive me if I missed something, but wouldn't omitting the --framework parameter fix the issue?
That only makes sense if your existing stuff is short-term. I’m not sure we can count on long-term dev tool support. Yes, the runtime framework will be there forever, just like it was with VB6 and classic ASP; but I haven’t seen them guarantee that VS2021 or later will continue to support the old framework.
i have a solution like this with 122 projects inside.. I only do **dotnet build** and is building fine but I do have another batch file running that pulls all the libraries and put them into a single folder for easier picking of outputs.
Awesome. Thanks for sharing. This is exactly I’ve been wishing for.
As mentioned, Vue would be A LOT simpler then React, because of standard approach to HTML/CSS, it's much easier to learn and use if you have no experience with React/Angular. Vue wasn't meant to be a full JS "framework", started as a library but as community was getting bigger, this library was also growing so it became "framework". I am strongly suggesting you to choose Vue, you can start using just parts of it as a JS library, for operations that are needed, which is great because it minimizes needs for obsolete code/packages. And as time will go by and you will start to recreate frontend as SPA, you will be already familiar with Vue and everything will be simpler. Even though I am big fan of Vue, I will mention some other options... Other framework which you should checkout and consider if you are not sure with Vue is Total.js. Last option I want you to consider is, if you really need a JS framework and want to load and use big number of huge node modules, that are not always secure and also it is really easy to set everything up in not correct way, which can result in big, slow and unsecure web app that could be done in half the time and better with "older" approach.
A web application runs on a server, so there is no .exe file. I suggest you read a bit about the differences between desktop applications and web applications before continuing your project.
That is what i am doing now, but i find it hard to gather information. I was thinking about having a consol app run with a web ui, but i have no idea how to set it up and there are very few tutorials.
Look [here](https://docs.microsoft.com/en-us/aspnet/?view=aspnetcore-2.2#pivot=core), go through those articles, they should be more than enough for you to get started. And a console app does not have a web ui. Typically, you have console apps, desktop apps, mobile apps and web apps. You won't find any info on how to do console apps with a web ui because you are searching for the wrong things.
It is possible to run a small webserver within an application, but usually it doesnt make sense, except for special cases. Your application then must handle requests and produce valid html as a response. Check Nancy for example&gt; [https://github.com/NancyFx/Nancy/wiki/Documentation](https://github.com/NancyFx/Nancy/wiki/Documentation)
If you’re willing to use C# instead, look into self-hosted ASP.NET Core applications. Unfortunately VB.NET support has been dropped from the Razor view engine in ASP.NET Core, and the team is refusing pull requests to add it. You could write the backing assembly in VB.NET if you wanted too, but the view can only use C# now.
VB.net is effectively a dead language, and why Mono when you can use .NET core?
nah, MVC can be used for you web api, just instead of serving back a view over http you just return some form of serialized data. It's much faster then using a webapi framework like service stack, but requires you to build out all the handlers. This is made even easier tho with the middleware implementations in dotnet core.
Good to know! Does Roslyn not work on Linux?
Use grpc because net core 3 supports it is not the same as use net core 3 because it supports grpc
looks awesome! I‘ll give this a try. btw. did you look into codegen for existing graphql APIs?
The thing I like about Nancy is that it is so nice and minimal. I can code up and run a REST service in minutes, with just a couple of source files in a simple Console app. No need for any server to configure and deploy to. I don't know how to achieve that simplicity and ease in [ASP.NET](https://ASP.NET) Core. Is there a way?
of course there is a way, go for an empty ASP.NET project template and only use what you need.
Net core 2.1 does supports only non-ms supported grpc. Net core 3.0 does both. Why would he refer specifically to a framework which isn't out yet to refer to a package that doesn't have that requirement. That line of argumentation simply does not make any sense.
Well, Nancy lets me create and run a REST service with just a couple source files, as a simple console app. Super simple. Isn't ASP.NET complicated to learn and use? I don't want to learn Razor, I don't want MVC. Just a simple REST service, with minimal source code. Is there a way, using ASP.NET Core 3?
Yup. It's called Middleware. It's been there since 1.0 but it's not widely advertised. https://github.com/dodyg/practical-aspnetcore/tree/master/projects/3-0/new-routing-4
Yeah. You can do everything in one source code. It creates a console app host with built in server. Everything in 10 lines of code.
I would assume that Roslyn works on Linux.
You can just create an ASP.NET Web API project, it won't give you MVC or Razor or any frontend at all. Since .NET Core 1, ASP.NET only asks you to "pay" for what you actually use.
No, I have not. What would be the purpose? To move from one implementation to a dotnet one?
Can’t wait for SPA to die
Yes! I just posted: https://www.reddit.com/r/dotnetcore/comments/btv7ey/looking_for_scaffolding_for_clean_architecture/
Why?
Localised dates? Have you never had to deal with displaying dates in multiple time zones? Sure its trivial, but its just one of the many things you need to resolve when building a website... Hence it was in a list of things you have to deal with when building a website. &amp;#x200B; The rest is just straw manning and needlessly insulting.
As in classic old web forms, or actual 'classic asp'? If the later, oooh my sympathies.
Seriously, why? At least go to mvc
I did none of that. Nice try though.
The actual classic asp, about 20 years of development effort, to be replicated in 2... Should be fun.
ahh i got it the wrong way around. thought this library would generate graphql queries from LINQ expressions.
Looks more like 'How to use a template in Visual Studio'
&gt; Also .Net framework 4.5.2 does not implement .Net standard 2.0. He never said that. He said some of his projects target both .NET 4.5.2 and .NET Standard 2.0, multiple target frameworks in one project.
Hm... jon skeet? marc gravell?
after changing the package source, I am able to download Bootstrap 4 but now is show my project is Incompatible Use Bower instead.
I literally wrote the piece you are making arguments about. I'm done.
You might want to check out this talk by Jimmy Bogard: https://www.youtube.com/watch?v=gjtFGx0yX5M He shows some examples on how to build composite UIs on different layers. One example specifically shows, how to hook into MVC.
Bootstrap is just one JavaScript file and one CSS file. It's probably easier and more effective to just download it directly from the Bootstrap website and add it to your project manually. You won't need to update Bootstrap frequently; most projects I've seen that use it update once every year or two - or never, in the case of many internal line-of-business apps. Given that it's only two files that don't need to be updated frequently (if at all), I wouldn't bother with a package manager for Bootstrap.
There's some good stuff recommended there.
For something really simple like this on Mono, you could try using [Nancy](http://nancyfx.org/) with [self-hosting](https://github.com/NancyFx/Nancy/wiki/Self-Hosting-Nancy).
&gt; the java.exe file that it has no permission to run. &gt; &gt; Any clues? Make sure the IIS user has the permissions?
You don't need portfolio. Your knowledge and experience is good enough.
Yup, this is always the cause of access denied errors for me. By default the IIS AppPool user has access to nothing until you grant it access.
ASP.NET is designed for use using IIS Express or IIS so you will not get an EXE file. AFAIK legacy .NET does not have a built-in web server. Your best shot is probably ASP.NET Core which can run a standalone web server without IIS.
You can limit the extensions in intellisense by requiring a `using` to see them. You can even split between multiple namespaces if you want.
Pretty good video :)
+1 for C# digest
Assuming you mean automated testing, Pragmatic Unit Testing by Hunt and Thomas is a pretty good starting point.
Yeah this is pretty out of date and does some things I would not recommend you do like direct linking to entity framework instead of nuget package
WPF has incredibly steep learning curve, and it's theming and styling approach are not good. Also, it's huge, both as API surface to learn, and binaries to redistribute. I am hesitant to declare it "rocking". That said, I use it for my personal projects, and I find it better than WinForms even for the simplest UIs, just because it generates well-behaved apps on resize.
Put it all on github, show some examples of what you did. You don’t need to use actual code from the companies just recreate it as best you can.
Tests are only needed where you want your code to work properly.
I use an extension (well used, since last VS adds it to default options) to show all available types/overloads regardless of usings. This is also a resharper feature, I believe. It's a really handy feature when working with bigger projects with hunderets of namespaces and types spread across multiple, referenced assemblies.
I have been a backend developer for 15 years. I have nothing online, and I don't need it. Instead I have created a resume with all the assignments I have had, my roles in them and what the work consisted of. Works like a charm, bud.
I am going to answer in a general Rule-of-Thumb aspect. **IMHO, you don’t need a book to tell you what to test because it is a judgement call you have to make.** &amp;nbsp; ##Prelude If you have taken Computer Science classes, the beginner level courses teach you the following two concepts. * Pre-Condition * Post-Condition Pre-Condition is another way of saying *Input*. Post-Condition is another way if saying *Output*. In layman’s terms, *you assumed* that — when you call a function with *specific input parameters*, you *expect* certain things *MUST* happen that conforms to *Business Requirements*. For example, your expectation is that if I am drawing $100 from my Bank Account, a new transaction record needs to be created successfully to record it, you go write a Unit-Test for your `drawAmount(decimal amount)` implementation. &amp;nbsp; ## Concept Behind Testing **If someone changed a piece of code for whatever reason, it shouldn’t break conformance to your business requirements.** Testing *your assumptions* of expected program-behavior/output for a specific given input is a *judgement call* that you as a programmer must do. Writing tests is nothing more than verification of *your own* business requirements in *your own* code. ## Background Knowledge To be able to write unit testing, you need to have the following technical understanding. * Dependency Injection * Mocking They are easily google-able to understand what they are. Dependency Injection book by Mark Seemann is a good book, and more than enough.
Back end guys doing mainly Line of Buisness stuff rarely have portfolios, CV should be doing the bulk of talking for you,
Are you building as AnyCPU or x64? I don't think you can use them on anything but x86 builds.
If you have an MS Office installation on the machine, check the bitness of it (32 or 64bit) install the same bitness OLEDB driver, and build your app with the same bitness, it should work then.
You probably need to install the OLE database component. If it's Access, you either need the 12.0 version of Office installed or the 12.0 version of the Access Database Engine (a free download). 12.0 would be the 2007 version.
State in your resume for which companies did you work for and what work have you done. Add extra lines explaining the solutions you provided for these companies and how you tackled problems.
You could also have a small side project that you can work on in your spare time which demonstrates the principles you've utilised in previous jobs. That way, you can demonstrate your knowledge without breaking any NDAs.
I am not certain if I see a trend of people having one monitor, but I know I went with an ultrawide monitor that is like having two monitors without as much hassle. LG 29" 29UM60-P to be exact.
I use 3. But that's mostly because I also run racing and flight simulators. I have my development environment on the middle screen. Right screen is for email and other communication tools. Left screen is where I run and test my code. So I can have the window/browser/whatever running there, and not overlapping my development environment when I am using the debugger. Obviously that's flexible - I move stuff to where I need it at the moment. But that's the default.
I have duals, but I know people with single ultrawides that love them. I like being able to fullscreen something on one monitor, not sure how that would work with a single ultra though
I use three. One’s an optional one for email only - I could ditch that and get by with two. Of the two main ones, one is for my browser for testing code, and one for Visual Studio for developing what’s being tested. The problem with one big one is needing to manually monkey with window sizes. Double-clicking the title bar to maximize is too convenient.
Three: Code, Live (Web), Docs &amp; Specs.
I'm a digital nomad so I run a laptop and an ASUS portable monitor (similar to [this one on Amazon](https://www.amazon.com/ASUS-ZenScreen-MB16AC-15-6-Inch-Monitor/dp/B071S84ZW7)). The portable is on the left with MS Teams (it's what our team uses, and it works OK if you don't mind switching between its tabs constantly), [Franz](https://meetfranz.com/) for all comms except Teams, Chrome (signed into my personal profile), and Chrome (work profile: Azure DevOps, time reporting, SO). My main monitor is for Visual Studio, [mRemoteNG](https://mremoteng.org/) for RDPing into client servers, Chrome (work profile: all client env connections), SSMS, PowerShell (through [ConEmu](https://conemu.github.io/)), [Q-Dir](https://www.softwareok.com/?seite=Freeware/Q-Dir) for file system stuff, and Notepad++. I'd buy another portable monitor in a heartbeat if I didn't need a USB-C hub to support it! I &lt;3 MULTIPLE MONITORS.
I use 4 monitors now, usually at least on vs instance on one, then live web on another, usually docs on another, then finally the last is just my communication and entertainment. I’m debating a 5th though, as I often have multiple vs instances up
Two: depending on what I'm doing, the legacy code base and spiffy micro-service rewrite on the other, or just communications/JIRA/Confluence/browser on the one and VS on the other.
I use 2. I realized a 3rd monitor slows me down rather than making me more productive. One for code, one for web, database and documents.
I have been using multiple monitors since Windows 98. For many years I had two monitors, but for at least the last decade I have had 3. I require at least 2. One for the app, one for the code. This way I can see both at the same time. The third monitor is great for additional items; email, browser, tool-pallets (Photoshop, Unity, etc)
It probably depends on the license that the original was released under.
Depends completely on how it's licensed. Is it a standard open source license or something custom?
It all boils down to having more real estate in terms of physical inches of screen to put content on. You could get one huge 4k monitor for the same effect. I have two monitors attached to my laptop dock at work giving me three total. Monitor on the right I keep reserved for E-mail, IM, and web browsing. IM-based meeting content gets fullscreened there. Left monitor is usually exclusively Visual Studio or some other IDE I am using, maximized. It is also for Unity's Play mode window which is used to run through your application, also maximized. Center monitor is for Visual Studio Code maximized, Unity's main window maximized, and any misc windows such as Explorer or Command Prompts. At home I have a 2K monitor and a 1080p monitor on the right. Right monitor hold various game service friends lists, media player, Discord, and mIRC (I don't use it much nowadays but it's still there). I'll also throw anything on there I want to look at at downtime between game rounds or anything I want to use while watching full screen video. Left monitor holds pretty much everything else, especially anything I want to go fullscreen such as video or games.
Somehow I am not willing to give someone my email and use "The morning brew" RSS: [http://blog.cwa.me.uk/](http://blog.cwa.me.uk/) &amp;#x200B; I would like people to use RSS instead of mailing lists. But that's me.
*runs away in terror*
Hmm, I'm not sure what you mean. I've been going through core tutorials on linked in and been seeing a context set up and some things in the start up file. Are you talking about using dependency injection? I thought I knew entity framework, but it was a db first old web forms way with an edmx, and I think maybe that's not done now. That was a PITA.
I run 4 monitors. A 34inch Dell Ultrawide and 2 AOC 32 Inch QHD. I also use a small Mimo 7 inch one dedicated for Skype. Ultrawide I think is ideal for web dev as I can have the Browser (with dev tools in the bottom half) on one side of the screen and VS on the other side. The others I mainly use for browsing the web, playing videos etc...YMMV but it's perfect for how I work.
C# library under MIT license
 C# library under MIT license
It is possible to do: https://docs.microsoft.com/en-us/aspnet/core/security/cookie-sharing?view=aspnetcore-2.2#sharing-authentication-cookies-between-aspnet-4x-and-aspnet-core-apps I've done this before and it worked nicely with a mixture of ASP.NET 4 applications
This is not dotnet specific, maybe try /r/programming ?
Hard to say without know what you do professionally. If it was purely for my own development outside of a professional context, I'd probably enjoy the work shop you enjoy, but I think I'd also be interested in that WebAssembly workshop too if I was already familiar with Blazor (to get a better understanding of its internals)
for unit testing? some people say as much code coverage as possible. I think this is a waste of time. Just unit parts of the application where - The logic / features in the algorithm / code workflow change often - The logic is complex - The code is business critical I don't end up writing many unit tests, its a huge time investment. Just test where the critical areas are in your application. 100% coide coverage is pointless, who cares if a controller returns a view? its usually a one to one mapping. I'd also like to add that I dont ever use repository patterns in my service layer, I've never seen a good repo pattern that doesnt lead to useless code bloat. (if you think im wrong, reply with a link, github). in the service / domain layer i always query against dbsets / dbcontext. You can still "unit test". create a .net core console app query your db to get datasets from your service / domain implementation, these are your fakes. create a in memory sql project, populate the entities in your repo layer with the fakes you obtained from the console app. Use an extension like "export objects" to extract the result set into populated data sets in c# code. i say "unit testing" because its not a pure unit test as there is a dependency on in memory sql, but at the end of the day, it acheives the exact same thing. The benefit of the db testing approach above is that you can change the data retrieved from your queries against a production database, manually change result sets to create any scenario. This is much easier than mocking away stuff with a repo pattern. the only advantage in a repo pattern is to decouple dbcontext for "pure" unit testing, at the great cost of code bloat and dev productivity, the disadvantage is gone with a the test setup i describe.
It is .NET/nuget specific. I'm trying to figure out what to specify in modified .nuspec and .nupkg
If you want to move to one, try an ultrawide monitor. I am using a 38’’ monitor and although it takes some setup, it is similar to two 27 inch. As it happens I also have a second 27’’ monitor but I rarely use it or just keep a browser open in there.
So my non-lawyer, random dude on the internet advice is as such: MIT license means you can do whatever you want as long as you include the original copyright and license notice in any copy of the software/source. What I would do is: 1) Include a copy of the `LICENSE` (or whatever it's called) file in the project. If you're licensing your fork as MIT as well, a single `LICENSE` file with the MIT license should suffice. 2) Make a statement of copyright in the `README`. Something like "Copyright for portions of $PACKAGE_NAME are held by /u/BusyCode as part of $ORIGINAL_NAME. All other copyright for $PACKAGE_NAME are held by /u/BusyCode." You could put this in the Nuget copyright line as well. Other than that, it's your project. Mark it on Nuget as such. You could put a bit in the blurb about how it's a fork of such and such project.
It's interesting how many of us 3-monitor folks have developed a similar workflow.
I'd second this, and say taht my Docs &amp; Specs page often becomes my extended view for code. I have that monitor in portrait mode instead of landscape, so working on really long files or reading documentation (or reading Reddit) becomes really convenient
Well I'm looking right now, but I've worked in Microsoft stack, .net etc, for years. I'm working on learning core now. I was tempted to take the python, but I figure that is probably an easy one to learn on my own.
Thanks. This is helpful!
I find that multiple monitors in portrait orientation is ideal for coding and document editing. But it's not great for gaming, media, etc and you also have to deal with some apps and sites that work better with a wider screen.
I use 2 screens, one is a 4K monitor, the other is the Surface Book screen. The bulk of my work occurs on the 4K monitor (VS, SSMS, Vivaldi &amp; Excel mostly). The Surface Book screen hosts communications and task lists. However I could happily drop down to the 4K only if required. Alt-Tab for the win! When screens were smaller, I used to use 2 and for a short while 3. But thankfully those days are behind us...
Reach out to the original author(s). Might be possible for you to take over the original repository.
(Not web dev but) Have 6 at work, 4 wide screens and 2 standard. I have to monitor some dodge ass prod systems while also working on projects so I have emails, status page and chat / Bloomberg across the top. Along the bottom two with IDE and one with a console or two split screen. Maybe it is the difference in workflow, but sometimes I really need to have 4+ monitors with code (highly templated c++) and reference papers, that is quite rare though
It's kinda the path of least resistance sort of thing. When you have two monitors there are specific patterns we use, add another monitor and then it changes the pattern. At one point I had a projector as 4th monitor, so films/tv shows/youtube were on that. Now I have a Rift so that's my 4th.
I'm in the long time 3 monitor crowd (2 since 2002 or 2003, and 3 for 8+ years). Most of the time I'm running VS on one monitor, and the app on a second, with documentation / email / web browser / notes / etc on the third. I also find tearing tabs out of the main VS window and throwing them on the second and third monitors can be super helpful if I'm working on something with a lot of source files and I want to group them, or watch different ones for different issues. I also occasionally have two copies of VS open with different projects / solutions in them, and sometimes have several different apps in our main solution running at once, so being able to have everything scattered over several monitors is nice.
When I'm working at my desk I have two 27" 4k monitors. One in portrait. The landscape oriented monitor usually has side by side windows. Portrait monitor is Visual Studio. &amp;#x200B; I will also do a lot of work on my laptop. Productivity pace is probably a little slower on the laptop but monitor setup is rarely the bottleneck in my development process. I can crank out some code on the little 13 inch screen.
This can actually break some of those contacted, bad advice
If you are not testing then you don't know which code is easy to test and which code is hard to test, and you are not gaining skills on writing more testable code. So pick something and try to test it. If it seems too hard to test, pick something else. If it's still too hard to test, perhaps your code is too tightly coupled. Look into dependency injection.
Maintaining and updating an application is a good way of learning the necissity of unit tests. Can't count the times anymore I already have cursed because my predecessors haven't wrote unit tests for logic because they wanted to save time, whilst in the end losing more time than you gained developping while the knowledge is still fresh.
You don't necessarily need a portfolio for backend development in general, but what you can do at least is build a small sample application and demonstrate your skills using that small application. I've been building something like this since January, where I created a sample electric bill tracking web app. As a full stack developer, I did both the front and back end. The front I built with Vue and will rebuild again using React and Angular. For the back end, I built it several times over with Laravel, Slim, Flask, Django, Express, and Sparkjava, and I'm currently building it for the seventh time with ASP.NET Core 2.2. Each time I redo one end of the app with a different framework, it goes in its own folder with the name of the framework.
Why don't you put Teams in Franz as well? Also, take a look at VS Code. Awesome thing, and with the right extensions it's crazy powerful and an awesome tool to do all kinds of things - you could use it to replace N++ and do PowerShell on it!
Can you post to nuget under the same name as the abandoned project’s package? I.e. will existing users of the package see the new version and be able to upgrade? This seems like an issue we will get more and more in the years to come. Nuget needs to give us a way to specify antecedent packages and allow users to follow to the next from the abandoned package
Think of your code how you currently test it. You write the project get it to a point that compiles then verify it as the app runs. Depending on the application it can be a pain to get to that code you are trying to test and verify that it does not have any bugs. When writing unit test you break your code into smaller manageable parts that you can test without having to start up a big project. Do a google search for SOLID Principles it will help you to understand how to write better testable code and goes hand and hand with unit testing.
elo is no longer used
Six. I'd still like more pixel space, but physically it's hard to work with more than six screens.
In this case, no, as it's a different project entirely. Ideally you'd contact the original maintainer and ask if you can have the name or take over the repo, but that doesn't always work. It would be nice to flag yourself as a fork of another package. I wonder if you put "Fork of defunct Package X" in the nuget description and search for Package X in VS if it shows up? I don't know.
You should read up on SOLID Principles and Test Driven Development it sounds like you are just about there. TDD helps you to make a cleaner API/Interface since you think about how they are used up front instead of after the code is written.
A similar approach I’ve used is to start up a REPL and try to use the code I’ve just written. If it feels awkward to use from a REPL then there’s usually a simpler design.
Been on that solid food for quite a while. My process is more DDD with tests, not the full TDD red / green cycle. I’m thinking about the cases where solid will rule out a whole load of potentially bad designs but there are still choices in how to decompose the domain. I work in a field that is complex, ie the industry will always have some edge case that doesn’t quite work however you want to try and model it
I do that a lot more with python because it seems like it wants you to work that way, but not so much with c#, but yes, using it as a quick way to jump to some executable code without rewriting program.cs all the time with whatever I’m thinking about
Maybe it’s an rfc to post to nuget. I spent far too long working out which versions of Unity (DI) and CommonServiceLocator were meant to work together after they change all the package names a couple of times
Has Franz improved at all over the past 6 months? I was using it on my super beefy work PC at the time, and it was managing to eat up an \_alarming\_ amount of RAM.
Clean Architecture seems to be a good way to go when you have to do a lot of design around the domain. For my job it’s mostly a lot of smaller apps that seem to stay simple with a much smaller domain to program for so we tend to stick to a N-Tier architecture with smaller services to break the logic apart. We have another group at my job that’s working on a much larger application that has about 150 developers currently that works on a huge domain. They mainly do Clean Architecture and use NServiceBus to break the thing apart into microservices.
launchsettings.json is as the filename sounds, its settings for when you launch your app. You can do some fun things like pass command line arts and set env variables and whatnot but generally you wont touch this file much. Or anything under properties for that matter. Everything under obj/* is a part of your .NET build. If you delete obj and bin and run `dotnet build` you will see they get regenerated. As a web dev you'll never have any reason to mess with these. The .csproj is your project file. You'll define what framework you're targeting as well as some other settings like sdk, language version etc. This is also where your package dependencies get stored. Again you'll rarely modify this directly. If your project is a package itself, you can define most of its metadata here. I cant remember what else the default template generates. It might add .cshtml files. Those use razor syntax which I believe is essentially C#'s templating language. I rarely work with those so I could be slightly off base there.
JetBrains Rider has a fantastic C# REPL environment.
Ah ok, I was wondering where packages get get defined so that clears it up for me. With the "new webapi" command it doesn't generate the cshtml razor files unless I do "new webapp" or create them manually. I noticed that one of the nuget files list iis with a bunch of other ASP packages. Is it specifying that theres an embedded server?
The Properties/launchSettings.json can configure how dev tools such as dotnet run or Visual Studio launch your project. This is where you can set your localhost ports to avoid collisions. Your app.csproj file is your MSBuild project file. It will reference an MSBuild Sdk, which will do the heavy lifting of how your program is compiled. In this file, you can override which .cs files will be compiled, which files will be included as content, which frameworks you target and more. This file also lists the NuGet packages your project references. If you go really deep you can completely customize your build process, but the default setup is usually good enough. The obj folder is for intermediate compiler generated files and, like bin, should be ignored in source control. The obj/app.csproj.nuget.g.[props/targets] are also MSBuild files which references props/targets files in your referenced NuGet packages.
That makes sense haha I should have payed more attention to which template you were generating. I believe those are integration packages for running your app on iis. Its not a requirement though. If you prefer, kestrel is the .NET core web server. It will be bundled with your app and you can run it anywhere you cant run .NET core. I'm sure there are other hosting options I'm unaware of too. Most of the necessary ASP.NET packages are included in the Aspnetcore.All metapackage. (Which will be getting some minor changes in 3.0). The other packages should be more or less optional, but the template includes them to get the full ASP.NET core "experience" right off the bat
3 ide, web, and team chat
2; One for copy. One for paste.
I’d say no, most of the companies will do a tech interview, and also a practical test, in order to check that, so in this case, only a resume / curriculum is enough. Having a GitHub account or something that can show them your code will help, but it’s not mandatory.
No you are thinking about things in the right way.
the dotnet cli option: https://www.hanselman.com/blog/CAndNETCoreScriptingWithTheDotnetscriptGlobalTool.aspx can `#r "foo.dll"` your assemblies (or nuget) from CLI and all that, but sometimes, i'll give it a subfolder (`init`) in my project and use that as a scratch-pad, where unit tests may or may not be born. nothing jetbrains/fancy obviously, but pretty damn portable @ `dotnet tool install -g dotnet-script` :)
Oh right thanks for letting me know what to keep put of source control. Wasn't sure which files to ignore with git
I don't mean to start a holy war, but I generally dislike following strict TDD for the same reasons. When I'm designing a group of classes, sometimes I don't know if the design works as planned. Writing a bunch of unit tests and then having to scrap them because my design wasn't quite right is a waste of time. I code the happy path and once I'm satisfied I can start writing tests to validate and fill out the specifics. My biggest gripe with TDD is that it presupposes you have all of the requirements correct and your design is trivial and will fit on the first take. I'm skeptical when someone says something like TDD will make your API's cleaner/simpler. TDD should not replace design. SOLID, IoC, and unit tests in general have made me a much better coder.
So I am still learning C# (my favourite language) anway, it turns out I needed to add the migration name attributes to the class: [DbContext(typeof(DatabaseContext))] [Migration("20190528221051_CreateNoteTable")] public class CreateNoteTable : Migration
1 monitor. 42" 4k screen. Once you try it you'll never go back. I've converted many coworkers to one large screen. Less cables and shorter mouse movements. Having VS open and a browser with live troubleshooting on the same screen....and seeing the database queue and the documentation and stackoverflow with some spaghetti code you just fixed up. ALL ON ONE SCREEN, FULLY VISIBLE.
r/accidentalTDD
ITT: People who need to learn Alt-Tab. Haha, j/k. But wow, 5 monitors?
Easy. Always test, and test everything. In fact, write your test before you write your code.
You clearly are very new to this field, or self taught, so I recommend not giving advice when it’s this bad. You should be testing near everything with simple tests (seriously, no test takes more than a couple minutes to write properly), and not using a repository layer is just plain bad programming. Adding an interface and an implementation of that is not “bloat”. You are the spaghetti coder.
Read the " Gotchas " part in the from "Pragmatic Unit Testing in C# with NUnit 2nd ed". I'll get to read it . Thanks for the recommendation mate!
First of all , thanks for taking the time to go in such detail. I'm familiar with the concepts of pre/post-conditions . &amp;#x200B; &gt;**If you are confused about how to organize your testing code, I group it by business requirement domain area because it makes it easy to fix tests when your business requirements change.** I'm used to test on per service / per controller level. Next project I'm going to give it a shot !
yes, within reason, you could break the NDA contract, just as talking about it in the interview would, but if you used dependency injection or other design patterns, put some of that knowledge on GitHub. If you implemented a net core webservice, show that. Not specific tech or proprietary solutions, just show your core competencies. Alternatively, as Thinker3000 says, a savvy company will see your understanding from the overview of the tech you've used in your resume history.
No. This is exactly what Design in Test Driven Design is. Sadly, most devs are ignorant of this fact.
ive worked at 2 companies where we code directly use db sets with iqueryable, smart guys, i guess they are all new and self taught spaghetti coders too, unlike yourself of course.
I added Css and js folder of bootstrap manually and it should be working. Thanks for the simple clarification !
Nah, interface design is actually a major component of TDD.
Word. I think understanding the TDD mindset is a useful stepping stone to discipline your thought process such that you are considering testability while designing, but once you have it figured out following it strictly would slow down creativity. The time I do like it is when you know there is a bug in an existing codebase, then the red/green cycle helps me verify I have pinpointed an error and can then work on it
Linqpad works for me as a quick coding environment with Intellisense and NuGet support. I’ll take it over a REPL any day.
One 32col, and sometimes the notebooks display, but usually just one large. I rather use alt-tab to switch between apps than refocus on another display, got used to work this way.
IIS has a dedicated module optimized for asp.net core. If you host your app inside IIS, it will communicate via that package for better performance. If you host outside of IIS, the package simply does nothing.
Default gitignore from GitHub for "Visual Studio" takes care of everything you should ignore.
&gt; The appsettings.json files seem like configuration files for certain web aspects like logging, but not sure what else is set up there. Read about configuration in asp.net core. It's a pretty extensible framework that allows really flexible configurations. https://docs.microsoft.com/en-us/aspnet/core/fundamentals/configuration/?view=aspnetcore-2.2
Yep. This idea you start a new application with a blank page and a failing test that proves your implementation of "Add" works is largely the work of agile coaches teaching a basic strategy for TDD, always with a contrived example. I quite often start with a test as somewhere to bat code about, but I might as well use Linqpad or similar. Usually I just want to get a feel for where I'm going before committing to the price of a ticket. The idea of TDD informing the design is part myth, and another damaging one from the annals of the agile coach. The application can end up with a garbage design following TDD, what it does is **inform your design how to worth with a mockist style of TDD**. This is what we call Test Driven Design Damage. For example, where a one line method becomes 20 classes with 15 separate interfaces purely to allow it to be tested in a mockist way (exaggerated example obvs). Oh and finally, because it's taught as an easy way to make code perfect rather than that tests should be perfect code, you get really crap, copy pasted tests that prove nothing. Writing tests is as hard if not harder than writing application code. I've focused on the negatives, there are good points too.
Two unless I'm on laptop. I only use one for the actual coding, usually with a web browser, email, messaging on the second, but as soon as I'm debugging, running tests, profiling, it's much easier to use two.
I use 3. One of them in portrait mode for reading specs, docs... I tried using 4 for a while but that did not improve my efficiency. On each monitor I usually work in full screen mode.
Can’t you keep your protos in a third domain project so you only have it in one location referenced by both server and client and don’t have to maintain 2 copies. I haven’t played with grpc tooling but having to copy the proto seems like issues waiting to happen vs having it in its own library.
The Microsoft package wraps the StackExchange one. It may be best for you to create your own wrapper around the StackExchange client to implement better connection handling to what the Microsoft package is exposing. The other option would be to implement a healthcheck, which triggers an app pool recycle. Just depends on how urgent this issue is or how often this happens.
I do F#/TypeScript dev on a MBP with an ultrawide monitor. I absolutely love the monitor, but it's not a static "Here's my window layout for every single day". Some days, I'll have VSCode open with 2 code panels, VSCode taking up 2/3 the screen, and Terminal taking up the other 1/3; Slack will occupy the same 1/3 as Terminal, and so will the browser for docs. Other days, VSCode will take up the entire screen with 3 panels of code. And on other days still, VSCode will take up half the screen, and the browser will take up the other half. It just depends, and the ultrawide gives me a lot of flexibility to do whatever feels best for a given situation.
&gt; In our existing TypeScript code base, we take advantage of dynamic types frequently, and in the C# version of the code we had to define more concrete types. Should have used F# instead, which provides more type-related features (e.g. discriminated unions or much better generic type constraints).
You could put them in a seperate project but you also need to reference the physical file for the tooling to be able to perform the code generation, you can see this in the .csproj of the client. &amp;#x200B; As this is a simple intro post I've followed the lead of the official MS docs, as they say to copy the file. As I explore this more and get into some more real world stuff I'll be sure to point out a "better way".
"Credit to : The lazy bastards who stopped work on this forcing me to carry on when I want to spend time with my kids..."
It’s one of those things hopefully the tooling will evolve and I really hope they rework the formatting for the position numbering as string name = 1 looks wrong and hurts my soul Maybe an attribute or something but setting a string equal to an integer for positioning in the binary seems wrong lol
The Microsoft code-first EF core with a local sql dB is probably the easiest to follow [link here](https://docs.microsoft.com/en-us/ef/core/get-started/aspnetcore/new-db?tabs=visual-studio). Start with the one that’s simple and make sure you understand that first. There’s so many different ways to use ef, you just have to start somewhere.
I'm sure it will, there seems to be a lot of effort going into this from MS &amp; Google. I do agree though the numbering looks very weird! lol
Yes, that's what's confusing me. I will follow your suggestion, and start by that one. You don't recommend any resource outside of microsoft docs?
And here am I. Working on a .NET Core project that invokes a nodejs module.
Lol, F# is very rarely the right choice.
Down voted for not properly submitting the link.
They are. Not having a repository layer makes it incredibly hard to maintain code, and no professor is ever going to suggest skipping that is okay.
Lol, you sound like someone whose dotnet experience doesn’t encompass anything more than a “Hello World.”
Agreed, F# DUs are 🔥.
Most C# applications can be written just as well in F#. Often even better, and nearly always with less code.
I would recommend starting with a local dB and just playing around with it. Try to edit the schema with the fluent api, look at the migrations, edit the migrations... from there you can just go ahead with what you want to do, searching how to do things as you need them.
All in USA :(
I am talking about his tutorial on Creating the repository pattern with entity framework. You can tell this is old because he mentions unloading the project file and checking where entity framework is referenced. Its one of his tips. Number 1 we haven't had to unload csproj files in a long time. Since Microsoft introduced the new csproj format with packagereferences inside the csproj. Additionally during that tip you can see he is doing a direct reference to the entity framework dll which is a bad idea. For whatever reason he is also creating his own LoggerManager which is just wrong on many levels since there is a perfectly fine logger abstraction in Microsoft.Extensions.Logging which aspnet prefers you use. Overall the tutorials seem at least 2 years old with multiple issues here and there that you might not notice but will put you on a bad path.
To start, I would just say c# and Javascript
There a r/csharp and r/codereview which I've used to get feedback before. Outside of that if the software is good, people will flock to it eventually (I hope anyway I'm still waiting lol)
Steep learning curve? It feels much easier than everything else if you already know c# and dotnet. Took me a loooong time to move from WPF to web (even webforms).
When it comes to monitors this big, I find it useful to have window management software. I've been using a AutoHotKey script, though there are many available: https://autohotkey.com/board/topic/79338-simple-window-positionsize-manager-similar-to-win-7-snap/ https://www.autohotkey.com/boards/viewtopic.php?t=4986 https://github.com/cezaryfalba/bigscreenahk
Hi, I think you're already quite out of date. We log objects to destinations like Elastic, have a look at Serilog as a good example, and the number of targets it supports. You've exposed a custom target interface which is good. You've got a dependency on JSON.NET. Kill that now. It's a PITA having to deal with JSON.NET compatibility issues between versions. You're also using v9 which is quite a way behind the latest version. Was 9 the last version that didn't add .net standard support? I can't remember. I also don't understand why you're redesigned string formatting. .NET does string formatting really well, just take a standard string format string, or perhaps a lambda. The LogEvent class has some issues, which might reflect on the framework itself. I don't know why you have setters on everything, or why Message is a string. Is this related to JSON.NET above? Don't serialise things until they need to be serialised. I don't understand what "Silent" does, it feels like a hack. It's nice you've provided pretty good code comments but some are annoying. on "public LogEvent()" which literally sets a date and a thread, you repeat that exact same information in the comment. It's totally redundant. I know it sounds picky, but I read the code, then read the comment which was longer than the code and sighed. In the same light, you have a comment " // We haven't figured this out yet, figure it out, cache it and return the results ". Tag it with a issue id, or at least a "TODO:" otherwise it will still be there in about 30 years :) In the same class you have a constructor which takes a params array and does a .ToList on it. Does Tags even need to be a List in this case? Tags is also a read write property. In LogEventDispatcher you convert the collection back to an array (without checking if it's null) and then join them. If the property is read write there is no guarantee it won't be null. &amp;#x200B; XML! Config in code please. Keep XML as an option for people with old applications, but none of my config comes from XML if I can avoid it. &amp;#x200B; Those were the first things that jumped out at me. It was only a cursory look, so I may have made some mistakes. I tried to pick a mix of things, some occurred more than once, so I just listed one.
Get over yourself
Absolutely agree. Also aquasnap is a great software to manage segmenting your screen.
Less code does not always equal better, especially in large projects where future maintainability is the most important because you can't assume that someone is constantly mentally aware of how the code works in every single module. Javascript is a great example- yeah a lot of times simple things can be done with less code...but that doesn't mean it's a good thing.
As developers I think we learn the most by doing stuff. I would recommend building an app (this might just be replicating something already existing) and learning as you go. Name droping: .NET Core, Entity Framwork, LINQ, async/await. If you want to dive a little deeper I would also recommend to get an Azure subscription free trial and deploy your app to the cloud. This is just what first came up to my head first, it also depends what your goals are as a developer.
Hi, how does this differ from structured logging? Wouldn't it be possible to emulate tags with structured logging? I would recommend that you add an example of Log or LogNow method with tags in the Getting Started docs and some examples of passing objects or values. I had to dig into samples source code to get a better understanding how to use the logger.
&gt; Additionally, developers on our team prefer NuGet’s policy of “lowest matching version” rather than npm’s encouragement to use “highest matching patch” or “highest matching minor version” (using the \~syntax in package.json by default via npm i). You should really use yarn and yarn.lock instead of relying on package.json annotations at all
&gt;but none of my config comes from XML if I can avoid it. Why is this? Would you consider the entire System.Configuration with ConfigurationSections format outdated? Why is that the case?
&gt; Less code does not always equal better, especially in large projects where future maintainability is the most important because you can't assume that someone is constantly mentally aware of how the code works in every single module. I absolutely agree with the statement, and it's actually a very good point **for** F#. In F# the types and functions must be declared in order. You can't just recursively access every type in the assembly as you can in C# (unless explicitly declared as such). This reduces the scope of where the type / function can be used. Also the immutability-first approach (if you make use of it) reduces the necessary cognitive overhead. Once the object is created you can be sure it won't change anymore. Sure, you can do that in C# too, but it takes a lot more work and rarely see people do it. It's usually a bunch of properties that are manipulated all over the place. And lastly you have proper support for optional values (where C# will only get a semi-nice solution with 8.0).
Now if that were true, there’d be more than one major company using it.
Entity Framework Core In Action is a great book.
Downvoted for posting the same thing in /r/csharp thread.
The two posts would have been cross linked if submitted correctly and I wouldn't have needed to repeat myself .
Just worked on an ASP.NET web page that used a React login which used a backend with nodejs, go, Java, and Sql Server. No joke.
Not entirely outdated. The biggest problems are deployment, validation and security. A good historical example was putting Unity mappings in the config file. As it's XML you can't validate the mappings are compatible until you run the app. You can write a test to validate the interface mapped to a concrete instance of the interface, but this should be a compile time constraint not a runtime constraint. When it comes to security you don't want passwords embedded in the configuration file. This used to happen all the time. Once people realised it wasn't a great idea you end up with weird hybrid systems of managing configuration in config files with secrets from a separate source, or ineffective security policies that prevented everyone who needed to check a config file (developers) from accessing them, while giving support total access. Using XML is error prone. You can have a schema but with in code configuration you get proper intellisense. I can't mistake Colour.Sausage with Color.sausage as a parameter, and I can see all the parameters available to me. 90% of XML config is common/boilerplate. WCF was a great example of this (and all the above problems). You could (can) build a WCF server and client in a page of code with only an endpoint address being provided. I do like the MS WCF config editor though, it's a well designed solution to a problem that should not have existed. XML as a tech is as old as the hills and comes with a lot of baggage. You can use transforms to generate environment specific configurations, but again there's no simple way to test the transformed config is valid without being able to either run code against it, or write code that essentially replicates its correct values. XSLT is the devil imo. Why would anyone want to learn XSLT to replace an AppSetting with a slightly different value? It's harder to update config on the fly if the configuration is stored in an XML file you're not allowed direct access to. So you start moving the non repeated parts to a remote source, simple example, bung it in a database, let the app reconfigure itself if it spots a change. Remember what I said about being able to configure a WCF client or server with just a URL? Now I can get that URL from a database. Which leads me to the (almost) final point. Changing a deployed XML configuration file is not really audited. If I put that WCF URL in a database, I can give admin a UI to change it and audit which admin changed what, at what time and from what value. Final one :) Microsoft don't even like XML any more. File based config is almost always JSON these days. They even tried to change .csproj files to JSON, but that was a total ClusterF. Long answer I know and some points might be contentious, but I hope it helps :) &amp;#x200B; EDIT: had too many final points :)
I knew I wrote more than a paragraph, I was not expecting there to be quite that much of it :)
Honestly the best way to get people to use it is to plug it, but at the same time explain why it is better than any of the most popular logging frameworks out there. We're pretty spoiled for choice. You've mentioned tag based and therefore better, without maybe giving an example as to why, and why it couldn't be done in other frameworks. Having a look through the docs, I'm unsure as to why I'd choose this over Serilog or something more product "rich" like App Insights. And that's not a criticism really, you've always put a tonne of work into this and props for that. Think you might just need to explain things a bit more.
Hah, basically sounds like the summary of what I've read after going on archaeological digs on the internet on the subject of XML: it was super popular, people tried to do literally everything with it, and it just wasn't a good fit for most of those purposes. And all those sub-optimal "solutions" left a bad taste for xml itself. I'm still not convinced though. I love XML, and System.Xml.Linq makes it a breeze to work with. Schemas will give you intellisense when writing xml in Visual Studio, if that's even a work process besides config files. I actually despise json. It's like python to me; lots of abbreviations and uncertainty where there shouldn't be any. When doing any amount of relational stuff then it's just forcing a cube through a round hole.
Was this as terrible as it sounds?
Worst XML story of my history; we built a system and a colleague suggested we make it work off XSLT because "Then the users could write XSLT files to configure it themselves" :/ Second worst XML story; someone was concerned a table in a database was getting too wide so they added a column in which they could store all the extra fields in XML, because that's the solution to wide tables &gt;_&lt; XML has a place, I worked on a standards committee for a bit and XML was at the heart of it so I don't hate it much :) JSON can be rubbish or good depending on whether you want context, oh and we have [YAML](https://yaml.org/start.html) now which is basically XML and JSON having an utterly unreadable child :) [Be careful of using a cube in a round hole analogy](https://www.youtube.com/watch?v=whpPoaYdmzM) ;)
&gt; Worst XML story of my history; we built a system and a colleague suggested we make it work off XSLT because "Then the users could write XSLT files to configure it themselves" :/ I've lived through this the last 2 years at my workplace. Only it was SQL instead of XSLT. But that hasn't made me dislike SQL, I just dislike the approach and everyone who allowed and enabled this guy to write [horrible code.](https://www.reddit.com/r/programminghorror/comments/8p93b5/code_reviews_no_we_dont_why_is_there_something/?utm_source=share&amp;utm_medium=web2x)
upvoted to counteract your down vote - I don't normally vote.
 Thank you for replying. Could you maybe recommend learning recource for [ASP.Net](https://asp.net/) Core?
but thats the beauty of it. It can be relatively easily done from .net core as the base
Lol, that code is a riot. Literally bottles of petrol with rags in :) I also did not know there was a ProgrammingHorror sub, so I'm in :D Being as kind as I can to your co-worker, I play on CodeWars sometimes and have been quite embarrassed by my solution once I see everyone else's :)
Actually, the biggest factor to consider in terms of future maintainability will be the team's proficiency with a given language and ability to find talent to fill that role. Finding C# developers are waaaay easier then F#. Yes, they can relearn. The question is, is the productivity boost of F# language features are going to justify that learning investment. IMO, not
Have you built previous apps using .NET Core? If not, you could begin with this [tutorial]( https://docs.microsoft.com/en-us/aspnet/core/tutorials/first-web-api?view=aspnetcore-2.2&amp;tabs=visual-studio) that goes through the basics of building a web api. Microsoft has really good tutorials on its website.
&gt;Being as kind as I can to your co-worker Pff, I'm a beginner, I was looking for a mentor and tried to come with suggestions for this application early. I even showed him Entity Framework, and at that point I didn't even realize what I had found; I was just learning the basics of programming and C#, yet I managed to discover a very future-proof way to deal with data. It was dismissed in favor of ad-hoc DataSet wrapped in a class he called Database. &amp;#x200B; Then he... does the SQL stuff. The SQL lives in xml files as serialized objects. Written by hand, not serialized from code. He deserializes them and fetches the query from a string property. The idea was that engineers could write their own SQL logic, but he ended up basically putting the entire business logic for the application into these sql queries. It's pure insanity; thousands of lines of sql, in one file. There are dozens of files. All queries bottleneck into a single table in the DataSet, writing things to excel and clearing the table when he needs to processes different data. I took the issue to the top, they gave me the typical politics spiel to diffuse the situation. No one ever looked at the code, and instead a company-wide email was sent on how to raise issues in the future. Effectively "write your problem in an email and send it to noreply@hr" &amp;#x200B; If this senior is going to get paid twice my salary while creating the biggest technical debt mountain I ever think I'll witness firsthand, and managers won't do anything about it, I don't feel bad posting his shite code. He's the guy you as an employer could give glowing reviews and recommend to hire, and whoever hired him would have a very good case for lawsuit, as you basically set them up for sabotage. Not even kidding this scenario has happened. &amp;#x200B; I'm asking for feedback on my code, but they can't be bothered. I give them polite feedback on how we could do things differently and they get offended. I have no more patience for that sort of incompetence. It's a big industry though, with so much money flowing through that the slow-motion trainwreck can be kept alive for decades. But it's been going on for decades. I think we're coming to a head very soon.
I'd move on if it's viable. It's remarkable how often I give that advice. It sounds exactly like the sort of systems we would build in... ... counting... 2000 and before. But worse in so many ways. My last project was in a progressive organisation that had a legacy app that needed some modernisation. The first thing I did was remove 90% of all database access and replace it with messaging and distributed caching. I would hate to have to do that if I had to deal with SQL in files, it's as you say a mountain of technical debt. Don't get too invested in it though. Companies change when they need to, whether that's as a desire to progress or a need to survive. Another option might be looking to see if there are any internal transfers available. Depends on the size of the company of course. Saves the hassle of having to remember to commute to a different locale :)
ooooh yeah. Thank you
I'm not sure OP was looking for such an in-depth review. These kinds of criticisms can be hard to hear for someone not used to it.
I'm reading this right now and I agree. Accessing and working with data is a major part of most applications. Although ASP.NET Core tutorials often cover EF they don't go into enough depth for such a key part of the application. I'm finding this book to be a great way to build my depth of knowledge on this topic.
I'll add that I've heard good things about the ASP.NET Core in Action book as well, but have not checked that one out myself yet.
I'm going back to school to get an engineering degree. Get some weight behind my words. &gt;Don't get too invested in it though. Companies change when they need to, whether that's as a desire to progress or a need to survive Indeed. I heard rumors that different parts of the conglomerate are having meetings about the future without my employer company involved. Abandon ship. (That's a pun by the way, we deal with ship automation) I still sorely miss having a mentor though; I'm slowly trudging through .NET Framework constantly confused as to why this entire library or that entire framework (ex:wcf) is being ignored, when popular new libraries seem to just re-invent the wheel with only 5% of the features. I still can't figure out why web api http is being treated like a total replacement. Doesn't wcf do so much more? Having someone experienced tell me the whats and whys would've been such a boost in my programming career, but unfortunately I'm stuck figuring out myself so I feel like a novice even after 3 years of self-study. I feel cheated; the "experts" at my workplace know less than me.
&gt; You've got a dependency on JSON.NET. Kill that now. It's a PITA having to deal with JSON.NET compatibility issues between versions. Can you expand on how to accomplish this? I recently released a library that has a JSON.NET dependency as well (version 12, not 9) because I need to make HTTP requests and deserialize objects from the JSON responses. I'd like to be dependency free, but I'm not sure if that's reasonable unless I write my own JSON serializer.
You can still use RSS with C# Digest http://feeds.feedburner.com/digest-csharp
But it's so sexy. Designed by a 23 year old "architect"
Downvoted to counteract your up vote. You should always vote.
It's really really hard. You can use the MS JSON serialiser, or if you don't mind sleeping for six months, James Newton-King has been working on the MS, dependency free JSON serialiser. In your case it's probably more effort than it's worth unfortunately. For the logging library I couldn't see any specific reason that it needed serialisation. It should have been farmed out to a separate sink dll. But again, I didn't read all the code. Sorry that's a crappy answer which doesn't solve your question directly. Don't try writing your own though unless you've got a butt load of time :)
Ships are easy to automate, you just automate all the parts of the ship. There's probably a github project to do it ;) The changes generally reflect changes in architectural approaches and are sometimes cyclic. My favourite example is MVC being invented in 1973 :) WCF is still relevant and there's a strong(ish) push to get it ported to .NET Core as people rely on the fact it literally does everything, but for most people they want HTTP and REST because that's how modern app's are constructed. It's not so much about .NET to .NET any more, but almost every other system exposes a REST endpoint to either submit or control. We have things like gRPC coming up which is a faster RPC mechanic than simple HTTP REST endpoints, so more like, well RPC servers of old, things like DCOM (gross over simplification). A lot of programming is muscle memory and some people forget how to develop new muscle memories. So they're capable of producing functional software but don't exceed the patterns they learnt early on. It sounds like you're learning constantly and that's worth a load. In the last few years we've seen some pretty dramatic changes, not so much in the actual technology innovation but in technology adoption, so being willing to learn is key :) Remember the "experts" don't define you, so carry on regardless and focus on your own progression by investing and trusting in yourself.
lol...if you always vote then you didn't counteract my vote. You would have voted anyway. But I forgot to downvote and have now
I picked a handful of things that stood out in a brief look through. u/NullPointerExpert is welcome to ask questions and I only took the time to do it because I felt there was talent there. I'm slightly annoyed you're gatekeeping, but I get the intention and it's entirely honourable. I've done the same when I've felt people are being put under undue pressure. Essentially we're both trying to look after a developer. It's already quite a big project compared to some of the empty folder Github solutions people ask us to critique, so deserved more than a few lines. OP, don't feel overwhelmed or discouraged. Programming is about taking a big problem and turning it into a lot of little problems, work with that concept when you ask for a code review on everything :)
:) thank you. I'm good with it though - I've been coding for 20 years now, over 12 of that professionally. One mistake I made though - was I left the original code base at the root of the repository - all the new stuff is under "Take2" - so it's hard to tell what feedback is for which revision of the library.
I screwed up and left the original code base at the root of the repository :/ That one did, in fact depend on [JSON.NET](https://JSON.NET), because I was trying to have the config driven by JSON. "Take2" - which is the rewritten (and better) version, has no such dependency.
Thank you! I certainly will. The difference is with structure logging - emulating tag based logging is a hack, and sketchy at best. With this, it's built-in.
I will definitely be looking into the alternatives - thank you!
Thank you for the feedback! [JSON.NET](https://JSON.NET) was removed for "Take2" - so I'm wondering if you're looking at the old version of the library. I was an idiot and rewrote it in a subfolder, and left the original write at the root of the repository :/ Noted about Serilog. I redesigned the formatting for flexibility, and for performance - however, it's been a little bit since I've looked to see what Microsoft has done to improve it. "Silent" was a hack in the first version - it was used around trace logging, and was temporary for performance testing. It's since been removed in "Take2" The whole "figure it out" bit has been taken care of, too :) Config in code is on my hit list for future functionality adds. Thank you so, so much for your feedback! I really appreciate the fact that you took the time to take a look at this. I feel awful realizing that you spent your time reviewing the old version of the library though :/
:) Not a screw up, just development. I only spent a few minutes scanning the code. I had a poke in the package configs because a huge problem with people building libraries is depending on a dozen nugets which ultimately make it impossible to use in loads of solutions. There are always compromises, but JSON.NET is a specific problem that MS are working on a new JSON parser in Core 3 (also written by JNK).
sure vs code can be used to create .net 5 apps.
But how do I compile them?
Deployment is your first concern, but config files are the easiest thing to deploy - you don’t have to recompile anything. Despite the errors, it’s still far better than code configurations for that reason alone
[https://www.mono-project.com/docs/getting-started/mono-basics/](https://www.mono-project.com/docs/getting-started/mono-basics/) ## ASP.NET Hello World Create a text file with the name hello.aspx and the content: &lt;%@ Page Language="C#" %&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;Sample Calendar&lt;/title&gt; &lt;/head&gt; &lt;asp:calendar showtitle="true" runat="server"&gt; &lt;/asp:calendar&gt; Then run the xsp4 command from that directory: xsp4 --port 9000 Use a web browser to contact [http://localhost:9000/hello.aspx](http://localhost:9000/hello.aspx)
:) I really did just take a quick look, so it's quite possible I was in the wrong directory. The best thing to do is to move V1 out altogether, but if you want to keep it, create a new fork for it so you can return to it. Git is pretty powerful as a source control system. You're welcome, as I mentioned in another comment, I only spend time on this stuff if I think someone has talent. That's basically a combination of dedication and programming ability. Don't worry about me looking at the old version. If the criticisms made sense already then it means you're on the right track programmatically. Also, I didn't look and I'm not able to access Github at the moment, were there any unit tests? They're really helpful for developers to get an idea of how stuff works, besides the obvious use. Final thing. There are at least two logging abstractions out there at the moment. The first is Microsoft's and the second is .. Crao I can't remember and can't look it up. Someone here will know. It's worth considering support for one of those, probably the one I've forgotten the name of as it's dependency free :/ Sorry, in a bit of a rush :)
Yes... .NET CORE
no shhhhh .Net 5 *wink*
Jesus, that makes my project sound like summer vacation...
Gotcha 🤫
The ASP.NET app was a legacy app, the other were really a few open source projects we did not build but had to tweak slightly. We built the react page, but it was simple. Three of those effectively provided by a vendor. We didn't touch the Java app at all, but we had to host it. It's not nearly as bad as it sounds.
While it would be simpler to just use .Net Core for new Web apps. If you're like me and have an existing code base that can't easily be migrated there are options. Recently I was trying to solve this problem and I found that you can build and host the web app in a docker container and even debug it but you're going to need a Windows docker container. Which is possible on Linux or MscOs, it's just a bit of work to get itset up. I'm not near a computer for 2 weeks so I can't share specifics but basically. 1. Figure out how to get Windows Docker Containers on Linux. 2. Figure out how to host a .Net Framework Web app in a docker container 3. Figure out how to connect your debugger to the Web app in the container. Points 2 and 3 can be made easier if you have a Windows system and visual studio to create the project as you can add docker support. Good luck and let us know what you find. It may be useful to others!
Hi! Cool to see a new take on it :-) &amp;#x200B; One tip regarding the original query in your post. I never persuaded anyone to try Serilog based on its API or implementation (nice as I think they are!). The real "aha" moments with Serilog are actually not Serilog demos at all, but demos of what you can do with its structured data in an appropriately powerful back-end. In 2013, when the project kicked off, very few developers in .NET were using structured logging, and so seeing logs sliced, diced, and analyzed with ease, in CouchDB, MongoDB, RavenDB, etc. (way-back-when 😄) was enough to get people digging deeper. &amp;#x200B; If tagged logging is the differentiator for NuLog, I think you'll uncover more interest if you can demo what it means to have tagged logs. I'm not sure which server or service fits that data model best, but showing how much easier tagged logging could make diagnostic analysis would be my #1 priority in your position. If people believe in the utility of tagged logging, they'll bring the enthusiasm and determination needed to get a project like this to the next level. &amp;#x200B; Knowing the existing options well, especially those for text and structured logging, is necessary to give adequate depth to these kinds of comparisons and demos, though. I was lucky enough to try implementing Serilog's structured logging within both log4net and NLog before I realized their limitations at the time (both in data capturing, and how their pipelines dealt with structured data), and so I had a fairly strong idea where Serilog's actual strengths lay. Forking and trying to graft tagged logging onto Serilog or NLog, for a start, seems like it would be a useful experiment. &amp;#x200B; Hope this all helps, good luck, and enjoy your project!
Julie Lerman's courses on Pluralsight. Use the Microsoft Dev Essentials (may have changed names but it's there) for an extended free trial. Then buy a PS subscription when its heavily discounted once or twice a year.
Is there a reason you can’t create a private nuget feed? Then all you have to do in new projects is right click,manage nuget, and add your custom package.
Most .NET developers just have no exposure to functional programming beyond the little bit that linq exposes them to. A completely different way of programming is rarely the right choice unless it's a personal project or you have buy-in from the development team. It has nothing to do with how good or bad F# is (I personally really like it).
Thank you :) I've already restructured the repository and updated the CI scripts - there will be no more confusing the old library with the new one. 100% test coverage (on the core library) :) I built this from the ground up using strict TDD. I'm pleased to say that even with 100% coverage - the tests all run in 4-5 seconds in Visual Studio. [https://sonarcloud.io/dashboard?id=NuLog](https://sonarcloud.io/dashboard?id=NuLog) I'll be looking at integrating with the facades put forward by Microsoft and maybe "Crao"? The thing that really sets my framework and Serilog apart is the concept of logging objects. I can do that right now using my concept of meta data, but it isn't the primary log message - it's a bit "out of the way". I'll be looking into making the next minor release of the framework introduce that, to close the gap. I'll also be adding a bunch of targets, including to Elastic. Finally, I'll be testing the performance between Serilog and mine to see how they stand up to each other. I've put a heavy focus on performance, while Serilog sounds to prioritize staying out of the way. In my experience "staying out of the way" leads to log jams (pun not intended), which cause two things: poor performance, and lost log messages.
Thank you!
&gt; Recently I was trying to solve this problem and I found that you can build and host the web app in a docker container and even debug it but you're going to need a Windows docker container. Awesome! Thanks man
Get out of here with your casual ageism.
Oh sorry, you're right. At 23 they would be "Director of Engineering." My bad.
The angular template is sub par. Use the cli instead. The template starts you off with a bad angular structure not conforming to the layout design from angular. It also serves angular via. Net core. It's better to have two projects, api and ng Cli cmd is: ng E. G. Ng app
I'm using Jetbrains Rider to code C# on Linux. It can use both .NET Core and Mono as compiler.
It's not about age, it's about ability. You would probably discriminate against Mark Zuckerberg, for example.
__*They trust me, Dumb fucks*__
Why would you ever have two versions of code side by side in a non-working branch when using version control?
Oh sorry, I thought you were being sarcastic. I would say there is a nearly 100% chance with someone proposing the above architecture that I would not be discriminating against the next Mark Zuckerberg, I would be discriminating against someone who - with no evidence or actual accomplishments - *thinks* they are Mark Zuckerberg.
Except no, because corporate concerns center around maintainability and minimal expenditure, which you get with your dumpster fire legacy C# winforms app. Hiring F# programmers costs more (see the stackoverflow developer survey). Plus, what is the point of switching from C# to F# if you’re already entrenched in C#? It’s the same environment, same API, same capabilities. All of that aside, if you’re not mixing C# and F# in your projects and playing each one to its respective strengths, then what’s the point of using dotnet?
Scott Allen's courses on Pluralsight.
Is there _too_ much polyglot?
Entirely wrong. ASP works in F#. Hiring F# developers doesn’t actually cost more, as there’s only a handful out there. Nothing about F# actually costs more. No reason to switch, but you’re missing the point that no new companies are picking it up. In fact, there’s only 1 company using it in any significant way, and that is Jet.com. What’s the point in using dotnet? C# is better than Java currently. That’s reason enough. No one really uses F# because it doesn’t have much reason to exist.
I can understand the dependency thing, but it seems like a waste of resources when you still want to write TS on the front end with things like Angular. Let your team use their preferred language if its just between TS Node and C#. No one is a back-end only C# developer in 2019.
Yeah that last comment pretty much confirmed that you have no idea what you’re talking about lol. Boy bye 👋🏼.
If I’m so wrong, so me a plethora of companies using it. If it’s so great, it should be widely used.
You have made it abundantly clear that you have either never used F# or don’t understand it and just want to spread FUD out of spite. If you use dotnet at all I can’t believe you would denigrate a language from which C# gets all of its best features. F# makes the dotnet ecosystem better.
Sure. It had neat features which have been adopted. Again, list the plethora of companies that use it. Successful and good languages will be used by many companies.
Two 27” 4k monitors. IDE on one and browser on the other typically.
If it were me, I'd build it into the web app. For emailing later, add the functionality to email into the web app or if you must call it externally then add an API endpoint to 'get' the report.
I'm not sure I follow what the use case for this is. Wouldn't the "typical case" be more in the lines of just creating all tasks at once?
Just google it like literally any other sane person would do.
Except his comment was clearly indicating that he for whatever reason believes that F# is rarely the right choice. Nothing to do with the paradigm, just some bizarre anti-F# evangelism.
Use Rider or VS Code with mono and the new-style SDK projects. You can use the .Net SDK (dotnet build/dotnet test/etc) with mono just fine, I do this for work. Using this tooling doesn't make anything you do .Net Core in any way.
&gt;F# is rarely the right choice I would largely agree with that. If you are not a .NET shop, I'm guessing there are other functional languages that would be more appealing. If you are a .NET shop, I'm not making the switch from C# (or god forbid VB) would be worth it. I have seen a lot of C# developers really struggle to grasp the concept of FP and I think it would be a hard sell to make that change for an entire department. Maybe it would be a good fit for a team within a .NET organization but I still think that is a recipe for disaster.
MonoDevelop is really your only decent option. I know there are workarounds but I would learn to put up with MonoDevelop. The other alternative is run a Windows VM just for those apps if they really must be Full Fat .NET. I would if you could move those apps so they are compatible with Core. This is a great guide on how to port libraries. [https://weblog.west-wind.com/posts/2017/Jun/22/MultiTargeting-and-Porting-a-NET-Library-to-NET-Core-20](https://weblog.west-wind.com/posts/2017/Jun/22/MultiTargeting-and-Porting-a-NET-Library-to-NET-Core-20)
This is how I'll handle it too. Takes care of versioning, dependencies...
It sounds like you've really got it sorted out :) I honestly can't remember the second logging abstraction I was thinking of, it's not Crao for sure (unless the renamed it). It will be interesting to see the benchmarks too :)
Not really. We'd still have to go through the same change management process to get a config file deployed as we would for binaries. Our deployments are all automated anyway, so it's a one click affair. Where we want dynamic configuration behaviour we add the settings data to a control panel for them so that everything is audited properly. Where I'm talking about code based configuration there are still elements which come from the outside. If I configured file logging in code it would still need to know what path to log to and logging level, so those values would be in appSettings. So the goal is not to remove all external configuration but to remove everything that can have compile time safety. WCF is a great example. WCF endpoints in config files are a pita to get right even with the WCF configuration tool. There are zero occasions where I'm going to need to change a WCF binding on the fly, so we can build the configuration in code and inject the endpoint address. The other problem with doing a config only release is coordinating it across all instances of a particular service. I might have five instances of the same service running, so all need to be updated. Again, in the spirit of CI, this is all a one click operation for us and setting up a job that only deploys the config files serves no purpose. Years ago we used to do config only releases, but this was because we didn't have automated deployments, everything was manual. There were a lot of issues with configs having slightly wrong values.
And I have. There’s only 1 company of any worth who admits to using it, as I’ve already said.
Lmao then you’re as good at using google as you are at using F#. But hey, when you graduate from Scratch programming I’m sure you’ll be more than happy to maintain legacy CRUD apps for the rest of your life you rascal.
It’s a patently false statement. Other functional languages don’t have an iota of the tooling that F# has, and ML syntax is by far the easiest to grasp. Plus, C# and F# complement each other. Using just one or the other is amateur. I recently began working with a group to help rewrite the business end of their medical image reconstruction suite in F#. 1 week in and I realized that C# is comparatively garbage for any serious scientific workload, but it had its merits for the nonessential parts. I guess if you’re just making little crud apps and maintaining some prehistoric monolith of C# enterprise trash then it’s fine to resist modernization, but the only recipe for disaster is being given a fantastic tool that fills a void in many of C#’s deficiencies, and shitting on it because learning is tOo hArD.
&gt; ASP.NET Core's dependency injection features Enough. It' a DI container that can be used in Core not just ASP.NET Core.
Yes, but in asp.net it's automagic with no involvement feom me:-)
What, installing the nuget package?
.Net Core is the future of .Net (.Net 5 is .Net Core). Better get used to it.
Not that. In asp, I define my controllers with appropriate ctors and they get the implementation of injected dependencies with me doing nothing else. Not so in other kinds of apps.
You have to create the controller which is the dependency root. In other applications any other class can act as the DI root. The only difference is you have to manually resolve that root class, but that's a single line of code.
I second this, his courses were a major resource when I started learning .Net Core and I also recommend Shawn Wildermuth and Julie Lerman's courses on PluralSight. Also, the official docs are amazing: https://docs.microsoft.com/
Read that too. Great book also.
I guess that the entire rest of the industry using Python for ML are a bunch of dumbasses because they aren’t smart enough to see that F# is superior...
I have used it in console projects many many times so tea calling it asp.net di is wrong, but it's not limited to core you can use it in the normal framework to!
&gt; I guess that the entire rest of the industry using Python for ML are a bunch of dumbasses because they aren’t smart enough to see that F# is superior... "ML syntax" refers to the [programming languagle](https://en.wikipedia.org/wiki/ML_%28programming_language%29), not machine learning.
Yep same here! Ah interesting, really?
Schedule an OS level task that hits an endpoint?
https://docs.microsoft.com/en-us/aspnet/core/fundamentals/host/hosted-services
I actually didn't know this. How do you access it in console project?
You could roll your own service, but you might as well use the services already available, like task scheduler or cron.
Even reading the comment multiple times, I’m still not sure if he’s talking machine learning or not. Because there are people doing machine learning with F#. Regardless, it doesn’t really matter to the point that I’m making. Either one is an opinion and I think the industry has chosen other languages and fighting industry consensus on philosophical grounds doesn’t seem like great advice.
Maybe offtopic, but why dont you want to add hangfire?
It's no different https://andrewlock.net/using-dependency-injection-in-a-net-core-console-application/
Yeah this is the way to go. If you try to do it some other way IIS won't know your app is doing anything important and will kill the process when idle.
Please then, prove me wrong. Drop your crusade. Your language sucks ass. Man up, get over it.
I feel like hangfire is an overkill for running simple task once a day. Too much moving parts, if you will.
Quartz is a good fit for this, not heavy either
Well done, but I recommend that you include links to the project home page and NuGet package in your post.
I've done this before, and I guess I just don't like doing it that way, because if the web app dies, then any and all report generation dies as well. Kinda makes a single point of failure. That being said, It's something I have considered if I have not found a way around this issues. Thanks!
I guess I've not really messed around with private nuget feeds. I'll look into it!
It also depends on exactly what the reports are and how you're generating them (HTML? SSRS?) A microservice architecture would be pretty perfect here. Something like an AWS Lambda / Azure Function which you run on demand.
If cloud is an option, maybe go serverless like Azure Functions or AWS Lambda?
Older applications are using Crystal Reports, looking at using something like FastReports or Telerik since crystal reports does not support .NET Core. Sure, I could do that, I'll add it to the list of work arounds. Thanks! It just seems like I should be able to include static files from another project like I have been able to do in most of the previous versions of the framework. Just assumed I was missing something or that they have changed how it works.
I started to replace my other DI with this one as it is super simple, supports .NET Standard, and just works.
Isn't the more common case injecting different implementations into different classes instead of injecting all the implementations into one class?
Yep
It kind of sounds like your collection is metadata, if so, adding a property with the type info seems reasonable
I can see how they are both useful. Maybe you need send the same message out over several services. In this case though, I would probably create another service just for doing that though.
F# is an ML (Meta Language) derivative. There was no context for machine learning. Read my comment as many times as you need to. Read it slowly, even. Fighting industry consensus is what drives progress. By your own admission, C# was a bad idea too, since at the time Java was the industry standard. But I guess cherry-picking your points does a better job of supporting your shaky argument.
Could you elaborate a little on what you mean by metadata? I'm using swagger to document our API, and I can't find a good way to show that our \`Field\` type can have multiple different sets of properties depending on its type.
Or Azure webjobs. Save the money.
Irrelevant... but companies use any of C++, Haskell, Julia, R, Crystal, OCaml, Scala, Go, and Rust for ML. Believe it or not, *the entire industry doesn’t use Python.*
Please, for the love of god, do not do this. I’m dealing with an inherited codebase that does this right now. And we aren’t talking about a quick “keep the app pool alive” kind of thing, we’re talking about third party integrations that take hours to run and when they fail (constantly) crash everything. The comments already have great recommendations. For the simplest I would also recommend a scheduled task (or cronjob).
In an api I work on, we supply definitions (metadata). The UI/client reads the metadata to determine what types of value it should put into a dictionary of objects. eg Metadata: [ {Name:Thing1,Type:ThingType.Integer}} {Name:Thing2,Type:ThingType.Text} {Name:Thing3,Type:ThingType.Selection,Values:{"A","B","C"}} ] The client sends back { Thing1:1, Thing2:"muh text", Thing3:"A" }
If you want to handicap yourself by not using the dotnet environment in its entirety, that’s on you. You gain nothing by shitting on F#, which has been the premise of *your* bizarre tantrum/crusade. People like you are the quintessence of bad developers. Now, back to r/python with you.
That’s like saying you’re not using the JVM if you aren’t mixing in a dozen languages. Dotnet isn’t anything special. It’s a group of languages. Two dogshit, one good. Get over yourself.
Yep, I mixed Java and Clojure all the time. Made for better code. But, you win. There’s no arguing with someone so far along the spectrum.
I would definitely go for the one mixed type array. Also the metadata mentioned in another comment is a concept that you should definitely use. The metadata's job is not only to tell you the type of field but also it's restrictions like optional/required, minimum value, maximum value, default value or formatting rules like a regular expression validating an email field We use this approach in our software and it is one of the best design decisions we have made.
And yet, by your own admission, you’re handicapping yourself because you’re not also using scala, groovy, and kotlin, amongst others.
We are doing this via the OpenApi 3 specification and its schemas. For example we have an endpoint where the user can submit an organization, accepting an ein, name, primary address, phone number, list of additional location addresses, names, addresses and phone numbers for various executives and their relationships to the org. In order to submit to this endpoint, you would post to the /org/create a json document that looks like this: { "data": { "type": "organization", "id": "-1", "attributes": { "name": "test org 1", "ein": "12-1234567" ... }, "relationships": { "address": { "type": "address", "id": "-2" }, "employees": [{ "type": "person", "id": "-3" }, { "type": "person", "id": "-4" }] } } "db": { "address": { "-2": { "type": "address", "id": "-2", "attributes": { ... } } } "person": { ... } } } In our system, the spa knows to create new entities with a negative index and how to follow relationships and maintain this overall object structure (based heavily on json api). The api schema says that the endpoint /org/create takes an `"OrganizationResource"` which is the above object where there is an `"organization"` in the `"data"` member. This latter type has various attributes [attributes are non-object json members] and relationships [typed json members, with a given id that references the type:id:object map under the root `"db"` member]. The eventual goal (of which I have a working prototype) is that in our SPA (using angular), we include a cached copy of the api spec at build time and can have a route like: import * as schema from "./schema.json"; ... { path: 'NewOrg', component: OpenApiFormComponent, data: { schema: schema, path: "/org/create" } }, and potentially be able to dynamically create additional routes at runtime with dynamic routes that utilize a schema provided by calling an api that returns one. --- point is: build your schema api off of an existing standard such as OAS. It might be a little more work up front for some things, but you will save time eventually by not having to work around problems that other people have already solved. Then use the same standard for apis you can define statically as ones that you return from your application dynamically, merely using an additional layer of abstraction.
Thanks!
Sounds like you put put Swagger in front of your API, and then build your UI off of that. It sounds like your usecase is fairly simple. https://github.com/domaindrivendev/Swashbuckle I have found that this type of thing tends to be overkill and not extensible. Every developer wants a magic app where they add a column to the database and then it automatically appears on the UI.
[Coravel](https://github.com/jamesmh/coravel) has a task scheduler that's super easy to use and get started with. It uses .NET Core hosted services under the covers, so no need to install anything other than the package. Since it's .NET native, not a port from an existing library for .NET Framework, it hooks into DI, etc. with zero-fuss too, Might be worth checking out 👍
A colleague at work found NSwag which can be automated from code to generate clients. There are a bunch of caveats, stuff that it really can't handle, but it's easy enough to download NSwag Studio and have a play. FYI more than anything.
If you share a DB (even if don't...), then in your code all commands are modelled as their own "command" classes which internally use entities/aggregates. These entities are NEVER used to display data, only to apply a new state to the system (update, create, delete). E.g. They are used to apply any business rules/validation when the system is trying to be changed. For any queries that are used to display something the UI or via an API etc, then you create specific query classes that map to that specific use case + one specific view model (e.g. a DTO) for that query. The benefit is that you don't mix display and state modification logic. Each query can be tuned as needed without affecting other queries or command logic, they can return as much or as little data as needed, etc. I've been doing this using Dapper with lots of success. I think that's what you mean?
If you want to get technical, I’m pretty sure ML is the abbreviation for a specific language. And I like how you classify my argument as shaky when the entire industry seems to largely choose C# over F#. Even if you think FP is a good fit for your project, there are other more popular languages for solving those problems. Honestly C# with some nuget packages is enough FP for most.
Yeah I am familiar with that, I have written some code generators using it's libraries. There is some overlap between that project and swashbuckle (both can do swagger generation) and you can use both in many cases together. They provide low level libraries for creating clients.
Yep, exactly like I said, F# is a dialect of Meta Language (ML).
I'll have to have a look at Swashbuckle. I'm sure I've heard of it, but never investigated :)
Swashbuckle has more stars than NSwag on GitHub. Aside from that i'd say its more popular in general just because of its ease of use, support and active development. Where you get into the power of NSwag is the client generation, and they develop those together with the swagger generation so the clients can usually be generated from it without much tweaking. Edit: also if you google for aspnet core swagger the first result is [official docs.microsoft.com mentioning how to use Swashbuckle.](https://docs.microsoft.com/en-us/aspnet/core/tutorials/getting-started-with-swashbuckle?view=aspnetcore-2.2&amp;tabs=visual-studio)
Having tried both NSwag and Swashbuckle (both for aspnetcore) I recommend the prerelease version of Swashbuckle 5: https://www.nuget.org/packages/Swashbuckle.AspNetCore/5.0.0-rc2 It has a number of breaking changes compared to SB4, but that is because it has aligned closer to ApiExplorer and to Microsoft's OpenApi implementation: https://www.nuget.org/packages/Microsoft.OpenApi/ As of right now, SB5 is the only one I could get to produce OpenApi 3 documents mostly correct. The readme is pretty good also: https://github.com/domaindrivendev/Swashbuckle.AspNetCore/blob/master/README-v5.md
Core targets Standard which means Framework can reference Core libraries, so yup!
That’s news to me? The only two dialects I was aware of are OCaml and Standard ML. It appears that ML does not have a strict definition. Some people agree with my understanding and other consider F# to be ML. Not that it is related to the original point at all...
Metadata is data about data. If you want to build scalable interface, this is a solid route to take.
I will have a play in the office tomorrow :D
Yep, I'm going to play with Swashbuckle tomorrow :) I've got a new project and this could solve a few issues :)
https://blog.maartenballiauw.be/post/2017/08/01/building-a-scheduled-cache-updater-in-aspnet-core-2.html
I strongly recommend following this spec: https://jsonapi.org/
If your want people to adopt it, first thing I would do is make a write up that makes the case for why developers should prefer this over any of the many existing, mature, and popular frameworks out there. Off the top of my head, there's * Log4Net * Serilog * NLog * Microsoft's own first class offerings Also, you may want to consider how your framework is going to integrate with enterprise app monitoring platforms, especially free ones like ELK.
What is this self promoted blog post giving us over and above the official documentation? (Aside from ads)
What are some use-cases for this? It looks like an awesome project and one I plan to play around with.
Does anyone know what became of this project? I seem to recall seeing an MSDN blog of a Microsoft employee mentioning this project.
thanks for explanation, but that part I understand and I apply on my everyday work. I was more asking about how to make state based projections from Write DB, to Read DB. Ideally a tutorial or github example.
There are a few things not covered by the built-in `.ToString` on expressions: * The compiler generates closed-over variables as fields on a hidden class, and this is how `.ToString` represents them: var i = 5; Expression&lt;Func&lt;int, int&gt;&gt; expr = j =&gt; i * j; becomes: j =&gt; (value(sampleCode.Program+&lt;&gt;c__DisplayClass0_0).i * j) * Conversion operations are not written as they would be in C#: `(float)i` but rather `Convert(i)` * Types are rendered using the `.Name` property -- `List\`1` instead of `List&lt;string&gt;` * Only one possible rendering -- C#-style code The string rendering library solves all of these: * An improved C#-style formatter: * closed-over variables are written with only their name * type names are represented using C# keywords, and C# generics syntax * conversion / casting * A Visual Basic formatter * Other formatters (currently only 1), such as the factory method formatter Each formatter can also provide information about which part of the expression tree is represented in which part of the text. ```csharp string s = expr.ToString("C#", out Dictionary&lt;string, (int start, int length)&gt; pathSpans); foreach (var kvp in pathSpans) { var path = kvp.Key; var (start, length) = kvp.Value; Console.WriteLine($"{kvp.Key,-17}{new String(' ', start)}{s.Substring(start, length)}"); } } ``` prints: ``` Parameters[0] int j Body.Left i Body.Right j Body i * j (int j) =&gt; i * j ``` This is what powers the visualizer selection sync -- choosing a node in the treeview, the corresponding text in the source is selected, and vice versa. An additional goal for the visualizer treeview is to reduce the noise around the expression tree, and only focus on properties and related objects that are expression tree node types -- `Expression`, `CaseBlock`, `MemberBinding` etc.
Probably not getting the full picture but there are components that make this easy. EG Aspose Cells for Java : https://github.com/aspose-cells/Aspose.Cells-for-Java
*Beep boop* I am a bot that sniffs out spammers, and this smells like spam. At least 66.67% out of the 6 submissions from /u/Hautzy appear to be for courses, coupons, and things like affiliate marketing links. Don't let spam take over Reddit! Throw it out! *Bee bop*
Not impossible but a significant amount more work unless you fork out for expensive libraries. Even then still quite bit more work. Considering how easy it would be to change to csv's usual a good call.
 [https://www.udemy.com/csharp-vom-beginner-zum-progammierer/](https://www.udemy.com/csharp-vom-beginner-zum-progammierer/) that's the link, enjoy it
Sod off with your spam. The original video is an MS video from Virtual Academy: &amp;#x200B; [You can find it here along with the intermediate and advanced versions](https://mva.microsoft.com/en-US/training-courses/aspnet-core-beginner-18153?l=VM5gy36dE_6611787171)
only a wild guess (first time I ever heard of that): maybe VS.code is the result of this project (not unlikely: build around typescript instead of LISP, easily extensible, runs everywhere, ...) \*or\* the project was abandoned
Yeah, that’s sensible.
Possibly several proof of concept projects were started by different small teams, then after a while they converged into making VS code.
It makes sense to me (disclosure: I work in the finance industry). CSV are pure data files, while .xls or .xlsx files can contain a lot of things (macros, styling, graphs) which makes them a pain to parse and more likely to have errors and regression (the OOXML format is a pain to work with). I'm not sure what kind of data quality checks are required in your girlfriend's case, but on my side the traders have no issue producing CSV files and also importing them back. That makes the job easier to everyone since we can agree on a simple (and human readable) exchange format between them and the applications.
"easy"
I wouldn't say they are lazy, but fully supporting Excel is a considerable effort and the ROI is probably not there. Uploading something in a parsable format is a fairly standard practice, regardless of stack, so I'm not sure why this is posted on r/dotnet instead of r/java.
The insurance company receives datasets from their customers in Excel. These are emerging markets, so often the data is not as clean as the developers would require it to be. Not incorrect data, but often data in one column would be seperated by a comma (which is a problem when converting the file to .csv) it sometimes also includes the ID numbers in scientific notation, which must me set back to the number format before the .xlxs is converted to .csv As there are thousands of policies to be checked, she asked if the developers are able to automate these checks and fixes (data quality check). They said this cannot be done.
&gt;They said this cannot be done. With the resources they have.* IE: time and people Checking the integrity of a million different formats sounds complicated as hell. Commas in single columns are not an issue, CSV supports quotes. a,b,c,x,"y,z" 5 columns, not 6
I use the c# version of this, and its very good, but pretty expensive...
 [https://www.udemy.com/csharp-vom-beginner-zum-progammierer/](https://www.udemy.com/csharp-vom-beginner-zum-progammierer/) here is the link. sry that it is only in german but I'm not the best with languages ;) but I will try to translate my resources in the github repo into english if you need them [https://github.com/Hautzy/csharp\_beginner\_course](https://github.com/Hautzy/csharp_beginner_course)
How is this a dotnet question?
Easily earned back by reducing the amount of manual labor hours spend on converting it. Also the new Excel is horrible in saving csv files. It only uses ; as separator and reopening and saving that CSV file will save it as text file without separators. Having an automated conversion will quickly earn back it's costs.
Thanks for the clarification 👌 And no, I don't know of any 😥
&gt;back Yeah I was on the [ASP.NET](https://ASP.NET) team at that time. There were a bunch of web and desktop prototypes floating about. A lot was to do with the cadence of VS releases vs [ASP.NET](https://ASP.NET) (remember Web Matrix?).
I used to work for GEICO, and her situation regarding data cleanliness is absolutely on par, even with as a big of an insurer as they are. If they're issues with unescaped commas (unescaped means they're not sanitized to be in separate commas) that means the tool they're saving them to CSV format is busted, probably excel if I had to take a guess. Any reasonable size insurer should be willing to chuck out the money it costs for Aspose... it's worth its figurative weight in gold for these types of tasks. I know someone mentioned this on the post, and it's pretty accurate. That said, $$$. If they're not willing to do that, then using C# for Excel interop should be the next best thing. If the developers are unwilling to use C# for a task like this, then yes it's just laziness. If they claim they don't know C# that's pretty lousy of them. *But if the organization has so much red tape against it, then their hands might be tied.* That was a pretty common ordeal.
&gt; If the developers are unwilling to use C# for a task like this, then yes it's just laziness. If they claim they don't know C# that's pretty lousy of them. Ah yes, the lazy developer who doesn't want change up their entire process, spend months learning to setup, deploy, and maintain something they aren't familiar with while building out an application that has the ability to fuzzy match different formats, all to save one person 2-3hrs a month. Screw those lazy developers.
&gt;Ah yes, the lazy developer who doesn't want change up their entire process If a developer doesn't want to change their process due to their inability to meet customer requirements, then yes, that's laziness. &gt;building out an application that has the ability to fuzzy match different formats, all to save one person 2-3hrs a month 1. You don't know it's just one person, or that it's only 2-3 hours per month. That said, that's still an entire manweek per year in cost savings, which is pretty valuable, and definitely worth investigating. P&amp;C insurance runs on paper thin margins. When I was last working, Allstate actually operated in the red, but made it back in investments. 2. Aspose for Java is option number 1, as it's the best of both worlds, but it does have a direct cost associated with it. 3. I never said the entire app had to be in c#... it's pretty trivial to make an intermediary step that takes in excel files, and spits out correctly formatted csv files. Honestly, they're probably libraries that do that specific task already for you. 4. To do the task they're asking (at least the way I understand it)... it'd probably be a few days task already knowing C# well, 2 weeks just knowing Java. Not months... no where close. The languages are *that* similar.
There are libraries that make it easy to deal with Excel in .Net, but you still have to deal with the Excel data. We have a client that provides data in Excel. They are very inconsistent and frequently change. Things like merged cells can make it difficult to clearly identify columns names for mapping to other things, formatting can hide real values leading to unexpected values being displayed on the web. There is no automatic import for this stuff, we validate and adjust the code with every "update" to the file. &gt;They are requiring my girlfriend to do data quality checks (to fix formatting) before uploading any files onto the new system. This makes it sound like there are predefined formats that were agreed on. They should be able to accept the data in excel and export to csv in code, but it is very reasonable for them to reject messy files. ... Gold in gold out.
Personally, a certification on a resume is negative points when I'm looking to interview. I've never met a dev with certifications I've been impressed with. To answer your question, experience is the best way to prepare. Find a great dev to mentor you, learn from how other software is designed (inside and outside the dotNet space), keep up to date on software trends and learn why old trends fail.
Have you tried EPPlus? Are there features that make the apose library indispensable for you?
Hi and thanks a lot for the answer. In general I agree with you, experience is the best. But let me ask you about the situation I do not know how to go through. Basically I have learned until now by myself and I learned a lot since beginning. But when I started I have been not conscious about lots of useful things in C#. And I was doing projects so slowly, because I was learning while I was doing projects. Like a LINQ for example. Then one day I have discovered it - it changed my skill and approach a lot. And since this day I was so much more productive and better. I was able to implement the next issues so faster than before. If I knew it well before I would save lots of time and build previous projects faster. And I want to learn all the important things before I start to implement my ideas so it would be smooth and most efficient. Do you get me? The conscious about all the possible things is what is the problem. I think still I am not aware about lots of good stuff that I can learn. I am just not conscious. That is why I look for certification. Because I believe through this way of certification I would get aware about all possible stuff, so I would get consciousness and I would be able to learn in practice the best things, but only when I would get conscious about them. This means the tools in C# and others .NET frameworks, bit of frontends, architecture of Windows system like GAC, registry, assembly architecture etc. This is what I know about. But surely there is plenty of things I do not know about at all, so I can't learnt about it. Do you get me? I still have in mind possibility that I can be wrong, so just want to discuss. With all the respect for you!
Well, I started using the Word Aspose library ages ago, when there was no real alternative. Its a very nice library, and since we were licensed to use it, ive since used it for Excel too. Now we have XML format documents, its probably easier to come up with an alternative, but back then, it was .doc and binary lumps... no thanks!
If the issue is Excel Interop, there's things you can do about that. If the issue is that the Excel files are trash, which is what the issue actually is, then there's very little they can do about it.
I’ve done this in over 40 big data production apis and reading from an excel file takes the same amount of development time compared to reading from CSV and there are free libraries. I personally prefer clients uploading in excel because it is more reliable. If a value has a comma in a CSV then it will throw off the columns while in excel you don’t need to worry about this. The only time I recommend csv is when reading large data files because CSV loads instantly.
Discriminated Unions please!
Monitor 1: Google / Spec documents Monitor 2: Work Monitor 3: Skype / SSMS / other references
F# says hi.
The certifications themselves won't help you to learn more about .NET technologies. They are really just a test to signify that you understand the course material. The training materials are what you would learn from, and in my opinion, certification is a waste of your money unless you find an employer that cares about them. Like with any testing, it truly only displays that you have memorized the course material, and not that you are actually capable of using the knowledge to full effect. Stating that, it's the training that you need to become a better developer. The Microsoft documentation is a great place to start, where you can choose the type of development you're interested in, and start following tutorials. It's really only through practice that you will get better. Check out this site for finding documentation and tutorials: [https://dotnet.microsoft.com/](https://dotnet.microsoft.com/) As an anecdote, before I began doing ASP.NET development, I had only done client/server development. At my place of employment I was tasked with doing PHP development for a few years, and .NET kind of fell to the wayside. My employer was approached by a company for a large project, but it required ASP.NET, and they wanted certification. I had about 3 weeks to become certified or we would lose the project. I ended up memorizing the training materials and getting my certification. For the life of me, I had no idea how to piece that all together into an application. Lucky for everyone I was able to learn on the job, and through practice at home, and I completed the project. I'm now still working with ASP.NET 12 years later, but there's no way I would hire someone at this point for their certifications. What is important to employers is experience. Pick up some tutorials and start playing with code. Create some toy project on GitHub to show potential employers. Anything you can do to display your understanding to an employer will go a long way.
Really hoping record types make it in this time.
As one of the commenters has suggested, going through the .NET documentation is the best way to go about this. Going through their tutorials - which are very good - and learning why they're doing certain things is what you really need. Aiming for a certification while doing this is going to end up being a waste of money for you, and something most employers just don't care about. Go through their documentation, have a solution open, and follow along while playing with the code in different ways to see what will happen. :)
I fairly disagree with you. Having interviewed dozens of candidates for tech specific roles in the Microsoft Stack, certifications can be a positive point. The way to find out is simple: why did you do it? And I bet I don’t have to go to great lengths for at least have some agreeing with me.
Same, they'd save a lot of headaches for sure.
Fair enough, I was just talking about my personal experience. It may differ from job market. Most developers I've interviewed that had certifications appeared to get them either because they had too much time at their previous jobs (screams personality conflict with a high performance team) or they lacked in the skill department. A couple of defending points. - Hackers eithic from MIT, hackers exist in a meritocracy, degrees and certifications mean nothing if you can't perform. I've seen candidates that couldn't check for prime, but had a masters in CS. I've meet directors of engineering that shouldn't be writing code. - Most devs don't have certifications, most sysops do. This shows the market doesn't care about certifications. If we found then largely useful to prove skill, wouldn't we be seeing more of them? And I bet I don't need to go a great length to find some agreeing with me either, actually I recently just had a discussion about this with developers in different companies. 😄
Type classes, please!
The use case will be the time which you have let's say 1 million tasks to do like when you are dealing with the batch processes , and similar situation where it will impossible to allocate that much threads therefore you will need to divide the whole operation into Chunks and let's say 500 threads have to process it all
&gt; worked on the ASP.NET team &gt; username has `scott` in it Yeah that checks out.
Love that Miguel de Icaza is quoted too, he was still at Novell back then!
Its a good way to highlight that you didnt get a degree and are over compensating... Well at least in Australia, your milage may vary.
What are you looking for? Paid work, or project ideas? Since you say finance, have a look at what these guys are doing iot-sas.tech Finance always needs better security, and accountability. They have hardware solution, with C# bindings.
What is the advantage of something like this over just using the concurrent queue directly?
I get you. I'm not sure if a certification is worth paying for. There's a lot of resources online, some really good architects with blogs, there's a lot of open source projects, including some massive ones by Microsoft. Find user groups, attend some local dev conferences, build some open source projects.
Yea I'd quit
That seemed disappointing
I'm tired of making empty interfaces and pretending they're a union type
Your post has been removed. Self promotion posts are not allowed.
This is a very fat-but-vacuous blog post for what amounts to a very thin wrapper around standard library calls. And lest anyone think “oh but what’s the harm”, the harm is great when someone lacking expertise masquerades as an expert because others will follow them anyway.
No English Version??
Not at the moment but in development
Indeed. F# is a nice language which I have used but it has other problems.
As for representing it in swagger, it sounds like [oneOf/anyOf/allOf](https://swagger.io/docs/specification/data-models/oneof-anyof-allof-not/) might suit your requirements.
I tend to agree.
That's not "free" in C#, is it?
Is there a name for this metadata pattern? I have a feeling this is what I'm expected to create for 'settings' values haha any pointers for the right direction to look would be really helpful
I'm not sure that I know what you are asking but I see that you are calling save changes before adding the file when it should be done after. f\_Entities.SaveChanges(); f\_Entities.PerformedExercises.Add(file);
It's the same answer as last time you asked about this: The user your application pool runs in must have access to the folder. This very likely can't be done with Plesk.
**This is the best answer yet.** I also ask it in another subreddits. Thanks a lot. **By making certifications I was thinking about:** buying the book for exact certification (I heard Microsoft provide it) - study it (read and highlight best parts and then repeat highlighted), then try those things in code a bit. Then pass the exam. And do few of them. This was in my mind what I had in mind. However **after you post** I think is better to stick to tutorials in documentation. This would take me even less time I guess. And the covering of such a topics should be wider in documentations and tutorials. So actually it helped me to change my mind a bit, changing the source from books for certification into tutorials in documentation. **One more question: do you think next to the documentation from Microsoft - are the courses like pluralsight etc worth to go through?** By the way: this is nice anecdote. Wish you well for the further work! By the way2: I do not need certifications for employee, rather I was thinking to do it as the way to prepare myself to be fluent in implementing my own ideas. King Regards Sir!
 I do not need certifications for employee, rather I was thinking to do it as the way to prepare myself to be fluent in implementing my own ideas.
I do not need certifications for employee, rather I was thinking to do it as the way to prepare myself to be fluent in implementing my own ideas (study Microsoft books which are preparing to the exam and then pass it for fun). I expect it would stabilize my knowledge and fill gaps. I have already work commercially for 3 years and I want to start implementing my own apps. But I am not aware about 100 % of dotNet yet and I want to be conscious about most (like 80%+) of dotnet so if I start implementing my own apps I would not stack for long time and I could choose best C# and dotNet tools for my apps.
I agree with both of you, I would start with documentation. This can be similar but better way than stick to Microsoft books, even dedicated for the certifications. Thanks a lot :)
Thanks a lot for your contribution to the topic :) And you and @OreoCrusade and @progcodeprogrock have convinced me. I would start stabilizing my knowledge and filling gaps in it with the tutorials from documentations of dotnet. Then maybe some blogs. Also I like idea of meeting with devs at local like in conferences. What do you think about courses like pluralsight and so on. Is there something worth to learn from? Regards! and thanks again.
Do this on the JDK folder. https://stackoverflow.com/questions/14934006/iis-iusrs-and-iusr-permissions-in-iis8
This is exactly what I need. Thanks! Do you have any idea how to embed this type of documentation into Swashbuckle for asp.net core?
I don't believe there's a huge overhead - interfaces do have some performance cost, but that's due to the fact that all implemented methods are virtual and therefore cannot be statically bound. If you're not actually implementing anything, it's effective just a tag for the type checker. Feel free to correct anything that's wrong here.
How do you like OData for Core? I think I should have gone this route from the beginning for my app. Instead I did a traditional REST API and implemented all the filtering, sorting, etc on my own.
No knowledge about OData but I did the same and learnt a lot throught the process. Nothing wrong with reinventing the wheel to see how it works.
I do like Odata (for .NET Core) as a queryable (read-only) api and its good integration with EF Core / SQL-like databases. For the command/write side I use plain webapi in combination with MediatR. The blog-post above is part of a series exactly about this topic (pragmatic CQRS with [ASP.NET](https://ASP.NET) Core/Odata/MediatR).
No problem, unfortunately it doesn't look like it's possible to use these properties with Swashbuckle out of the box - see https://github.com/domaindrivendev/Swashbuckle.AspNetCore/issues/955 It may be possible to implement a custom solution specific to your requirements that will enable it, but I don't know enough about Swashbuckle to point you in the right direction I'm afraid.
No sweat. Thanks!
I'm very interested in the responses to this. The two biggest issues I have with SPAs is the amount of extra work and hand-rolling you seem to have to do for both security (whitelisting / blacklisting / field length / field content / removing direct object references) and validation. Both of which are usually handled nearly automatically in most server side frameworks. I guess I have always assumed that it was my lack of familiarity with these client-side frameworks, that seamless and productive avenues for performing validation were out there. So it this really the state of development using SPAs in 2019? Developers have to write duplicate methods, roll their own validation etc?
Nothing is perfect! And I love F# :)
I'm not too familiar with odata and EFCore integration. What's that look like? What are the features?
The thing is with React and [ASP.NET](https://ASP.NET) Core the big comps decided to go some steps back and "restart" the tech stack. If you only do React with lets say react-scripts (the boilerplate from the fb team), then you will notice that you need to bring in a lot of other things (validation, state management, routing etc.). [ASP.NET](https://ASP.NET) Core also for good reasons is not a one-size-fits-all solution. Some years ago I was accustomed to a super opinionated framework that did everything for me. It did 80% in a super nice way, it also provided great flexibility to some point. But some problems were incredibly hard to do, and just didn't fit into the programming model. And I think this would be the case with any big solution that takes away these burdens. So I think this big reset is worth it, now we have a much better modular lower level layer. Big companies are able to provide the difficult details (cross-platform, open source, performance, security). And open source communities/developers provide abstractions on top. Currently I am not aware of too many great integrations between [ASP.NET](https://ASP.NET) Core and React (or other SPAs). Hence I am trying to dive in here, and for me the lower level layers are so well done that it actually is easy to do the integration. As outlined above exposing validation is quite straight forward. In one of my next post I will address how I would use this with react (and some specific form state management library). And maybe to come back to your question which might not yet be fully addressed. Yea I think this is just the pill we need to take with SPAs. They provide great power, flexibility, decoupled view/business layer etc... But in the end we now really have two applications. So communication overhead/complexity and other problems need to be tackled. This is probably much easier doable with a server-side frameworks, however there too you need some framework or library that implements the logic right? So maybe there just are not yet good [SPA-ASP.NET](https://SPA-ASP.NET) Core frameworks/integrations available.
In the simplest form it can enable a GET action method (webapi) to be queryable, meaning: pagination, filters, orderby and select (ref [https://www.jannikbuschke.de/blog/webapi-enable-query/](https://www.jannikbuschke.de/blog/webapi-enable-query/) ). Here is my "getting-started" post for odata: [https://www.jannikbuschke.de/blog/odata-getting-started/](https://www.jannikbuschke.de/blog/odata-getting-started/) Instead of using hard-coded data you can just return a EF Core DbQuery property (which represents a SQL table).
I have added more explanation to the beginning of the article as well, I hope ot will be helpful to understand it better
Ah that last part is what I was curious about. I know a lot about EFCore but not how it can integrate with odata
You should take a look at this video series on Youtube: [https://www.youtube.com/watch?v=4IgC2Q5-yDE&amp;list=PL6n9fhu94yhVkdrusLaQsfERmL\_Jh4XmU](https://www.youtube.com/watch?v=4IgC2Q5-yDE&amp;list=PL6n9fhu94yhVkdrusLaQsfERmL_Jh4XmU)
A portfolio for anything other than a front-end web developer with public-facing apps doesn't really make sense. Typically, the people hiring don't know how to code and even if they do, I can't see them looking at a lot of code to determine if you can code. A good resume and references and maybe a short whiteboard test is all that is usually required.
At the moment there is a significant amount of nontrivial work to be done when writing a SPA in order to do client validation. You can work around them some by doing validation like this article suggests, particularly with a middleware solution similar to the 3rd style in the article where you simply apply a filter to all controller methods instead of the ones with this attribute looking for a x-validate header or something similar. However these solutions involve a second round trip (and if those require a preflight, suddenly you have 4 server hits for each valid request). This is getting better as libraries like Swashbuckle get better and are able to better specify the validation necessary for a given request and client libraries arrive to perform validations against an OAS schema or a Json schema. For example, given an OAS schema as a json object and https://github.com/apigee-127/sway you can register a Sway instance in your DI container for react/angular and then validate an operation with var validationResults = apiDefinition.getOperation('/the/path', 'POST').validateRequest(request); then handle the validation errors. Of course this is only as useful as the OAS document you are able to build, but you can get pretty far with this.
Not directly related but if you run Angular on .net core, make your life easier and use Swashbuckle + ng-swagger-gen. Never write client side API services again.
If you use "0.0.0.0" as your bind address, that will open the listener on all interfaces, local *and* public. Then on your LAN use the local IP to communicate.
https://www.reddit.com/r/fsharp/comments/bvd9dk/candidate_features_for_c_9_type_classes/epq946c/ &gt; I wouldn't put too much credence into this article, which wasn't written by a Microsoft nor Microsoft-affiliated person. Typeclass encodings have been on the docket of "potential future C# features" for a few years now, and this article is going off the //Build talk where potential futures are typically talked about for a bit. The reality on the ground is that we're trying to land C# 8, especially Nullability (which is perhaps the biggest C# feature ever done in terms of work). Put differently: if runtime support for typeclass encodings is to be added, then F# will implement feature work atop it.
Yes, that's is still the current state of affairs and makes SPAs take so much more time. This is why I recommend for even complex apps to stick with MVC pages and just inject small JS components on the page if necessary. Vue and React already support mounting the JS components into whatever element you need, and Blazor supports this too now.
I have added more explanation to the beginning of the article as well, I hope ot will be helpful to understand it better
I have added more explanation to the beginning of the article as well, I hope ot will be helpful to understand it better
I think they community knows what and where they shall read and they know also Microsoft.
Front end framework it's all about hype sooo checks Google trends 😱
Most places I've seen jobs for use Angular JS 2+, React or Vue.
I'd pick one of the main 3, Vue, React or Angular (2+). Blazor is still very experimental, so I'd be hesitant picking that for a real project. Ive used both React and Angular and I found Angular was a much easier transition from C# and the desktop dev I was used to (MVVM). Typescript baked in makes it more C# like (though the others work with TS too), but the way it handles dependency injection and the templating/view-model (Component) with data binding, was nice and familiar. It's also got a great CLI. The ecosystem is more unified so there's less decision fatigue of what to use (you just use the Angular router, Angular form integration, Angular HTTPClient etc, rather than having to work out what the latest and most supported third party library is etc). I'd recommend React for those coming from the JavaScript side of things. It's much more 'JavaScripty", more functional (as in functions, not effectiveness) and looser.
good article, are you the author? It would be great if there was an article that covered creating a full application in docker container(s) e.g. angular / .net core / sql RDBMS i just posted a thread asking for help with this exact setup https://www.reddit.com/r/dotnet/comments/bvq2z8/im_moving_my_webapp_off_azure_app_service_net/
[removed]
I've used all three of the most popular ones (Angular, React, Vue) and my favorite is Vue. It makes the most sense and has less fuckery than the others. So take that for what it's worth, lol. I'd recommend Maximilian's course on Udemy for Vue. And when you're comfortable with that, move on to Nuxtjs and you'll never look back!
Hey! I recently did this and it was a fucking pain in the ass learning because 99% of tutorials out there are just "intro to docker" stuff that don't actually cover real world scenarios. I'll make a post this evening to explain everything.
I've been personally delighted with Vue (using it currently both as SPA and in MPA with Razor as a replacement for JQuery). I might be biased, but Vue vs Angular is like writing ASP.NET vs Spring. Vue and C# can just do more with less noise.
I’ve used Vue and Angular and I think Vue is a good fit for a small to medium project, and Angular for something large. Vue probably also works for bigger stuff, I just never got the chance to try. Angular feels bloated to me with lots of moving parts. All sorts of weird markup notations and injectables and material ui thing. I’m sure everything makes sense if you get around to straightening all of it out in your head, and work exclusively with Angular, but I never had such luxury with time and don’t work with it exclusively either. Vue has less moving parts, for me it was easier to grasp the core concepts and doesn’t require much overhead to understand some old Vue code when something needs a touchup.
This is so true. It's like a dog chasing its tail. There is no rhyme or reason, it's churn for the sake of churn.
Vuejs is essentially the modern Angularjs, if you are comfortable with a MVC setup with angularjs, you’ll find Vuejs right at home and intuitive to use. The new Angular tho, is a great place to start learning the separated front end design. It’s still heavily under development, so you haven’t missed much and can see all the changes and ideas been thrown around between each version; which would help you have a better overall knowledge of the front end stack.
if you could do this is really appreciate it. do you have a github?
The reason for the “complete separation” between front and back ends is just because it’s a good idea. What if another team wants to build a backend for your admin dashboard in python/flask? Wouldn’t it be great if you had well-defined interfaces your front end already calls that they could replicate and become a drop-in replacement for your backend?
There is some change tracking that goes on in the background I am not sure this is possible; but it could be. I would try adding the tables to the dbcontext one at a time and doing a migration on each add. Remember if you have navigation properties on your classes they will bring in the entire tree so you may need to comment them out and add them as you add each entity to the context. You can manually edit each migrations as you see fit but a good chunk may be wrote for you using the automated tools, is there a reason you want to hand write them?
I'd vote for Angular. If you are building an Admin Dashboard, it's going to be a very complex app. Angular works very well for large apps like that. We're building something similar, and have had great success with it.
I prefer Angular myself, and you already have experience with it. "Complete separation of front end and backend" shouldn't really be much different from what you've already done with MVC and AngularJS. Was your MVC just essentially serving an Angular app shell, or were you mixing Angular in for page enhancement in a more traditional, non-SPA app?
Just started diving into angular 7, typescript is amazing.
I know everyone is recommending Vue and o know nothing about it. But I fucking LOVE Angular. It is such a nice experience deving in a complete frontend framework. Their CLI is basically magic and does everything for you. Their are very few concepts to understand to get up and running, maybe 10-15? Its built on Typescript which feels like C# so that is super fucking nice. Their documentation and stack overflow support is great.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/visualbasic] [How can I securely store my remote database connection string in a VB.Net application?](https://www.reddit.com/r/visualbasic/comments/bvs731/how_can_i_securely_store_my_remote_database/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
I'm currently building a large-scale social web app/site using Vue (with Nuxt for server-side rendering) for the frontend, and .NET Web API for the backend. Database is a combination of SQL and CosmosDB. Everything's on Azure. It's all working pretty well - particularly Nuxt and the entire frontend. I'd definitely steer anyone unsure towards the Vue ecosystem over Angular or React.
Three levels of security come to mind. 1. Connection string stored in plain text in the app.config - Most of the time this is "good enough", depending on what you are doing. (Storing credit card numbers? Not secure enough. Anything without PII, probably ok.) 2. Encrypted connection strings stored in app.config, with encryption keys stored in the application. Someone would need to decompile your app and have access to the config file to get at the connection strings. 3. Encrypted web.config files using a machine stored key. PCI requires this level of security.
You can’t. You need to assume that any publicly exposed DB methods will be exploited. You can encrypt the config file, but that won’t stop a determined attacker (it takes a few hours to break) Your best (easy) solution is to create a restricted DB login that only has enough permissions to do what the application needs - no more, no less. That will reduce the damage caused by a malicious user. You can’t rely on any security restrictions inside the application. The best (hard) solution is to create a hosted webservice that manages DB interactions, then the app interacts with the service, not the DB
Once I fully understood that React renders a snapshot of state/props, it clicked. Change state and the page re-renders. For me, the UI is now easier to describe and manage with state changes. I once saw React described as JavaScript with HTML, whereas Vue and Angular were more like HTML with JavaScript mixed in. And the better you learn JavaScript the better you'll be at React and vice-versa. In case it's not clear, I really like React. But like another comment mentioned, it's just one decision in your stack and it can get tiring trying to decide. The good news is there are lots of quality options and it's not too hard to change your mind as you learn more.
Couple pointers (I'm not an expert, take with grain of salt) . Get rid of mssql, the cost is insane and support limited outside of Azure or on prem solutions. Go with PostgreSQL. . For Linux distro, it doesn't much matter, but you should go for as light as possible. Check out the alpine images. . I'd stick with one container each for the app and api. Just simpler. . Don't containerize your database - whatever cloud you use will have offerings for hosted PostgreSQL, or you can put it on your own infrastructure (like on an EC2 instance) I'd recommend their hosted rds offerings. Containerized db is fine for local dev, or test environment, but not prod unless you get into some more advanced stuff like sharding, etc. . AWS is certainly capable with their elastic container service, but check out kubernetes. It's getting darn simple to deploy. Check out GKE on Google Cloud Platform. Gitlab has awesome integration. Hth
Build a web server to act as a proxy. Your app talks to it, it talks to the database. It's a pain in the ass, but it's the only way.
Just learn JavaScript well and TypeScript.. the pick React or Vue..
No framework is also a choice.
Blazor isn't experimental anymore. It's in pre-release, which is not the same thing. But I would agree that it's generally a good idea to not invest too heavily in a 1.0 release of anything and that what front-end framework to use is highly based on personal preference and how much of a learning curve you are willing to take on, the largest of which I think would be with Angular.
And that may be a good enough reason to pick one of those. Personally, I've never used any of them and likely never will. If I had to learn one, I think I'd go with Vue, but I'm holding out for Blazor and just using Razor Pages with page handlers and/or Web API until then.
They are all a variation on the same idea tbh.
Eventually, your app has to send something. That means I, the person with the machine running the app, have full access to everything the app does,and thus, everything it sends or thinks. You cannot secure your database if your app knows how to log into it, because I can observe your app running or otherwise reverse engineer the app. Think of it this way - your app is an extension of the user's brain. You give their brain an upgrade (your software) so that their brain can talk to your database. But it's still inside their brain. It is possible, somewhat, to solve this problem. Your database itself can implement authentication, identification, and authorization. But that means they log into your database with their own username and password. You have to give each use a unique username and password. Each resource in your database has to have permissions on it for your users (though, thankfully, you can use role based security to make it easy to administrate). Fun fact. You can deny permissions to a table, but give them permissions to access a stored procedure that uses some that blocked table, and the stored procedure will still be able to work. .. That said, this design sucks. Build a web api to act as a client gateway that handles client connections.
That sounds a little like graphQL but in reverse.
Like others have said, you should probably build an api to talk to the database, and have the clients talk to the api instead of directly to the database
As a matter of interest, what sizes are you currently running your services in Azure? Often resources get massively over provisioned when they are created with defaults, it's possible you can scale these down and save money. Docker in and of itself, won't save you money, like any cloud solution you are paying for compute. Docker just packages/serves your app in a different way, but your app still requires compute to run, which is where the cost comes in. Running your app on Linux on the other hand will save you money (little-no licensing costs). Aim for Alpine Linux, much smaller base image, which can make a difference depending on where you end up hosting it. Note that the base image your container targets does not need to match the OS of the VM or "node" running your app. The container shares the kernel not the OS. Don't run the DB in a container for prod, unless you can mount to local storage on a VM with persisted disks, even then it's probably still easier to just use a DBaaS option. Seriously though take a look at the sizes your are running your app on currently and scale down while checking on performance. Also possibly look at other regions nearby, some regions are cheaper than others. Dropping to the lowest tiers you should able to run the app and DB for less then $50/m. Otherwise running on a cheap VM is also doable, just means you need to manage and update it. If you go down the VM route and want to run the DB on the VM as well, make the move to PostgreSQL. Running on a VM could be as cheap as $10/m. In saying all that, Digital Ocean seems like a fairly cheap alternative. I've not used them, but most users who do usually rave about them.
Lol "jquery spaghetti code" ... vs 500 lines of client side router spaghetti code to do anything non trivial
You’re entire premise is flawed You start with this as a bad example: foreach (var duration in TaskDurations){ await Task.Delay(duration); } You can easily improve this with a very simple change var tasks = new list&lt;Task&gt;() foreach (var duration in TaskDurations) { tasks.Add(Task.Delay(duration)); } await Task.WhenAll(tasks) The new code will start all of the tasks, then process each one as CPU resources are available. It will execute on multiple threads automatically
Sigh .... That is a false dichotomy. You can do some really nice jquery if you learn some js patterns and know what jquery is really doing behind the scenes. Unfortunately when you get to larger application sizes it is quite hard to scale. But I suppose I should have expected the usual "lol frameworks are soo large" idiotic response.
Coming from always using a more structured language and despising javascript jquery type crap.. Angular all the way from me. It makes complete sense and you always know what's going on.. I dont know why anyone would actually dislike angular as it forces you to properly structure your SPA like an actual application instead of spaghetti code that used to be web pages.
&gt; Get rid of mssql, the cost is insane and support limited outside of Azure or on prem solutions. Go with PostgreSQL. yep im with you on postgres, i came from a pure ms shop, so azure, sql server, .net etc. my credits are gone and when i had a look at ms sql server pricing tiers, no way! besides my new job uses postgres so im pretty comfortable with it now. &gt; For Linux distro, it doesn't much matter, but you should go for as light as possible. Check out the alpine images. great thanks! as i was thinking about docker, the only reason i wanted to use centos is because we are switching our environments from windows to centos and hosting everything there. We plan to run the .net core apps from the centos machines. However as i started reading into docker and then kubernetes. i realised that this is actually a better alternative. i told my manager about it but i obviously need to do a lot more reading before even thinking about rolling this out to prod at my new role. &gt; . I'd stick with one container each for the app and api. Just simpler. Makes sense. So the setup would be - Alpine linux distro with nginx having both the api and angular on that docker container and postgres sql as standalone &gt; Don't containerize your database - whatever cloud you use will have offerings for hosted PostgreSQL, or you can put it on your own infrastructure (like on an EC2 instance) I'd recommend their hosted rds offerings. Containerized db is fine for local dev, or test environment, but not prod unless you get into some more advanced stuff like sharding, etc. Thanks, i was thinking that containerising a database seems like a bad idea, which is why i was hesitant to do so. My site is mostly just reads though. its a video aggregator, the only writes i do is when someone clicks a link so i get some metrics on what videos are popular. This is my site https://www.mmavideosearch.com &gt; AWS is certainly capable with their elastic container service, but check out kubernetes. It's getting darn simple to deploy. Check out GKE on Google Cloud Platform. Gitlab has awesome integration. I checked out kubernetes, looks very promising, but there is so much more reading i need to do. ill have a look at what you suggested. Thanks for the well thought out response, much appreciated.
Not really. I like frameworks. But there is literally nothing you can say to the fact that in "slow, old, ancient MVC" routing was like one line of configuration and "amazing, new modern SPA" is like going back in time to Struts 1.0 (lol) in terms of routing. You have to hand roll your own validation. Security is an afterthought. You need a masters degree level of knowledge to anything trivial, and your knowledge expires after 2 years. So yeah, not sold.
Your missing the point why you wanna use a SPA. People use the wrong tools for the wrong jobs and make a mess. Don't blame me.
&gt; As a matter of interest, what sizes are you currently running your services in Azure? Often resources get massively over provisioned when they are created with defaults, it's possible you can scale these down and save money. I'm only running B1, its actually all i need, i dont get that much traffic unfortunately, i built the site for myself mostly. As i wasn't a fan of the search features on ufc fightpass, i was going to unsub from it but decided i could make it better, i train bjj so i want to search on fights that end in specific submission types which you cant do on the ufc site https://www.mmavideosearch.com is my site. i checked out my billing, its not too expensive. so for the time being its fine. &gt; Aim for Alpine Linux, much smaller base image, which can make a difference depending on where you end up hosting it. Note that the base image your container targets does not need to match the OS of the VM or "node" running your app. The container shares the kernel not the OS. Thanks, good to know that the distro difference doesnt matter! &gt; Don't run the DB in a container for prod, unless you can mount to local storage on a VM with persisted disks, even then it's probably still easier to just use a DBaaS option. Yep, the other comment said not to do dockerised dbs, i was thinking it seemed like a bad idea. very cool re Database as a service (DBaaS). I didn't know about that. my db is actually pretty small i can just cache the entire thing in memory. there are very few writes made to the db as well. so the DBaaS option looks perfect. &gt; eriously though take a look at the sizes your are running your app on currently and scale down while checking on performance. Also possibly look at other regions nearby, some regions are cheaper than others. Dropping to the lowest tiers you should able to run the app and DB for less then $50/m. Otherwise running on a cheap VM is also doable, just means you need to manage and update it. If you go down the VM route and want to run the DB on the VM as well, make the move to PostgreSQL. Running on a VM could be as cheap as $10/m. In saying all that, Digital Ocean seems like a fairly cheap alternative. I've not used them, but most users who do usually rave about them. Yep, so im running B1 so i dont think it gets any cheaper than that, i need a custom domain and an SSL cert. As for the VM route, i think i still want to go with docker because i want exposure to the tech to learn it, Kubenities too if its the right fit for what i need. i still need to do a lot of reading etc. Appreciate the response, theres so much infromation out there, thanks!
She. In the same easy that "Jumping of a bridge" is a choice. If you're writing an SPA of any size or complexity, you'll want something to help you with that.
In the comments above you got good advices on how to manage the containers in this case: - 1 container for angular app and one container for .net core api. You can find a lot of tutorials out there in how to host asp .net core in docker and also how to host node apps inside Docker. The only thing is missing is communication, but passing ports from container to host machine and then using dns or making local requests should save the day - don’t create a separate container for db, more reliable solution will be to use hosted dB provided by a cloud vendors - host your containers on any Linux distro you like, but inside container people try to use some lightweight distros like alpine to lower the weight of the container and reduce amount of data you are transferring through network - in your case k8s will be an overkill. Try to find information about Docker compose. In the end you will need only 2 containers which can be handled even manually.
I just want to mention flutter as well :)
Yup API is the way, more work but it means it means a layer between your app and you database details. It also means if you want to change where data is how it is sorted etc you can easier as you just update the code in the API to get stuff from wherever and present it in the same way as before to the app
You should do the second one. Never expose a database server directly in the internet.
Beyond all the recommendations of separating out the db to another web api, you'll eventually run into a bootstrapping problem. At some point, you have to authenticate. Two thoughts come to mind: consider digging in to Azure Key Vault. Also, consider protecting your application from disassembly via something like Crypto Obfuscator.
Seconded. I love react and jsx is much more natural and powerful than attribute based logic(for/if etc)
Frontend is not all like .Net environment. It’s a huge world of options. I would just say go React and you won’t regret it.
I can recommend React + AspNetCore. Be aware though that you need to basically start at 0 and learn a lot (with your experience that could be doable).
maybe you are right , so i have updated the article accordingly to be more clear about its point , thanks
Regarding the number of containers, you should have (imo) one each for the angular app and the dot net api.
Yes it is a choice. A very bad one
That course on Vue on Udemy, is it a bit terse or is it one of the contestants of lowering the amount of content per minute of video? Might sound a bit flamy, but most of the Udemy courses I followed so far, they were al so slow and so many videos.
Do you have to use webpack or suchlike to use Vue with an existing MVC/MPA solution?
I worked on an Aurelia project that was the exact opposite of being very opinionated, which was the reason it was chosen as part of the system design by the tech lead. I can honestly say that it was a nightmare to work with simply because there was no direction on how the JS side of things should be designed. I pity the people left to support that shitty solution. Aurelia itself is fine, as long as you have very experience vanilla JS dev's to work with it, which we didn't. Overly opinionated is exactly what I want from a JS framework. That way everyone know how they should be working instead of second guessing everything.
Wow thanks! I’m very surprised by all the positive feedback! So thank you so much! I think I’ll continue my journey with Vue and maybe later compare it to angular and react, I really miss the proper support for Vue in Visual Studio, but it forces me to use visual studio code, and separating the front end from backend, which I consider a good thing!
The answer depends on what you are trying to build. &amp;#x200B; \&gt; normally when I construct a new website I would use MVC with angularjs, ... &amp;#x200B; For the most **websites** an SPA framework (some kind of an "fat web client") is an overkill. If you build a website you need performance for a better SEO score etc. I don't say that it's not possible with an SPA, but it's a lot more work to do.
I won't speak about efficiency of the MPA solution, as you should definitely bundle, minify, treeshake your js - but Vue works as simply as dropping script tag into the page. And it's progressive - I've got pages where I've dropped in Vue for toast messages, pages where there's mixed Razor and Vue layout (f.e. an MPA without vue-router, I use Razor Url helper to generate URI strings and stick it in hidden input / use Razor partials to host Vue Components, then hide those in a section then render it as part of the layout). I'm not so sure I would want to point customers to such implementation, I'd rather choose webpack-bundled SPA or even better, render serverside with Nuxt. But for certain applications (my MPA solution is an internal application, which brings some freedoms, as in you can be sure people have most recent browser, and are on 500Mbps connection etc.) or when refactoring - it's possible to just drop it in. One big minus though - you can't really use SFC (single file components) without webpack.
If I were I check out https://aspnetboilerplate.com/. There are also some youtube vids explaining the possibilities.
On the server side use type inheritance and attributes to model all the rules. This object graph is serialized to json. On the client side we use the GOF abstract factory pattern to deserialize into data objects and validator objects. We use separate requests to the server to get the data for the data objects and the data for the validators. This way we can cache the request for the validator objects to reduce the amount of data requested each time data for the data objects is requested Don't know about any pattern describing this
I would appreciate it as well, because, as you said, there aren't any quality tutorials out there
I'd highly recommend the [Vue Mastery](https://www.vuemastery.com/courses/) courses.
I had to migrate away from Aurelia to Vue because Aurelia just took too long to get on board with Webpack and still to date doesn't have a well-tested and documented server-side rendering solution like Nuxt.
If you want, I'd be down to cross-review each other's logging libraries. Mine will also probably never see the light of day, but I had a blast writing it and would love to know what another such author thinks!
API is the way to go. Don’t overthink it. The Api will as a proxy. Maintaining or fixing issues related to the database connection will be easier that way
json-api-dotnet-core and ember work beautifully together in such Harmony :)
Yeah, just keep in mind that what in popular isn't always good for your usecase
https://www.reddit.com/r/dotnet/comments/bt6s7l/is_mvc_a_better_choice_than_a_webapimodern/eovd50r
I would be interested in some examples of this.
If you use stored procedures, you can grant the login only permissions to execute the procedures and not the data itself.
No one here can tell you when you’re ready, that’s a function of the free market: try for the job you want, if you don’t get it or do get it but fail, then you’re not ready. Pretty simple.
Thx!
Ok this looks promissing. One question. This looks like it is still in production (newest videos are recently posted). How comprehensive is this? Are there alot of more videos to come for which I should wait for or I could just start with it and learn as I go?
It is still in progress. He keeps things fairly simple, but does cover all the important topics. It is for beginners so he doesn't go too deep. I expect him to hit 100 or more videos in the series before it's finished. He does put out a new video every day or two.
React/redux has the advantage that there is very little api to learn. It is mostly just javascript, so you aren't learning many framework specific concepts. And you have the full power of an actual language instead of the framework specific idioms to work with. (ie, array.map vs asp-for special syntax) This is an intentional goal born about from experience dealing with previous frameworks. The talk, Rethinking Best practices covers this topic in depth: https://www.youtube.com/watch?v=x7cQ3mrcKaY
Thank you very much.
I personally think Blazor will be the go to framework for C# developers, period. From what I’ve seen, only tooling is kind of meh but improving. People have been complaining about server side Blazor (which is in pre-release right now) but in reality most applications that would benefit from Blazor would need a WebSocket implementation regardless, and server side Blazor already provides that by default. Most known third party components providers have started adding Blazor on their portfolio, which sort of makes it easier to find high quality components for BLOBAs. I’m betting on it, since it is likely that WASM is here to stay.
Take a look at each cloud providers always free offerings. Depending on your needs, those might work and you'll pay nothing. Azure: [https://azure.microsoft.com/en-us/free/](https://azure.microsoft.com/en-us/free/) GCP: [https://cloud.google.com/free/](https://cloud.google.com/free/) AWS: [https://aws.amazon.com/free/](https://aws.amazon.com/free/)
you already have a lot of experience as a developer. much of it will translate into web development. you just need to learn and get familiar with the asp.net technologies which it sounds like you're doing. it will depend a bit on your local geography and job market if you should focus on .net framework or just dive into .net core. most shops will have older apps in .net framework and are starting to make new stuff in .net core im job searching myself, and i'm finding (in nyc) that .net is most common among larger companies. there's fairly low adoption among startups. unfortunately, larger companies tend to want someone with a bit of experience because they have the budget to pay for it, while smaller companies are more willing to pick up juniors. again, this is just what i see in ny; it may be different in other regions. as the other person suggested, give it a shot! apply for some positions, see what kind of feedback you get. before really diving into one of the js frameworks, i'd see what's in demand in your local area. personally, i don't see many companies asking for vue devs. it's mostly react, and some angular where i am. good luck!
This is the only real alternative to an API.
I think I figured it out, and updated the blog post with the answer.
You are ready. Apply now. Read the descriptions if any, most often you can get yourself familiar with some of the requirements between the time you apply and the when you get the call.
&gt;frontend I got this to work and its exactly what Im looking for. Thanks! But how do you handle development without hot reload? Or have you got that to work?
Agree with most of what have already been said. Creating a good C# based configuration API is pretty much expect nowadays. You could also go with a ".NET Core First" approach where this is designed for .NET Core only (well net standard). I'm thinking in the terms of the configuration system in .NET Core here. Interesting to see an alternative approach to having log levels. To be honest, I don't really understand your tag based approach from the documentation. Since this is the main differentiator, maybe tags should be part of the quick start example? Also, if you hope for cloud logging vendors (I'm working on [elmah.io](https://elmah.io) and may want to create a target if your framework becomes widespread) to pick up on this and create a target for their service, you probably need to explain how to map tags to levels. Most systems are based on levels already available in log4net, nlog, and serilog. I've seen your example of emulating tags as levels, but I think you need a better explanation of how to interpret tags and how to map them to levels if that's what the target system is built upon.
I think you are right. I will work on my resume today. Thank you very much!
Ty sir. I will just apply now. And tell them the truth of me.
Keep it up brother
I haven't been quite ready to take the plunge into complete front-end frameworks just yet. Instead, I've started looking using Web Components via [StencilJS](https://stenciljs.com/). To get that Spa feeling, I'm looking at [Turbolinks](https://github.com/turbolinks/turbolinks). Once I finally feel the need for a full-blown front-end framework, I hope that Blazor is ready to go.
Please, can you explain why containerize database is bad idea? (just im new with docker)
Containers are designed to be ephemeral - easy to destroy and recreate quickly. For this to really work, the containers should be stateless. This is incompatible with the traditional rdbms. If you want to get into some complex replication scenarios then you can get great high availability for your db using containers, but this is advanced stuff.
If you want something lightweight and super simple I suggest ... [https://riot.js.org/](https://riot.js.org/)
i had a dig into the google offerings, very interesting, i hadnt considered them as a hosting provider as i didnt think they would be able to host .net core, but they have kubernetes. thanks!
Just as a side note, no point in try/catch if all you're doing is a throw on catch.
The main code path has exception logging. The idea was to bubble the exception up. But I could change that. Wherever the exception is logged, that code path needs to hit before I can dump the stack.
https://medium.com/@steveolensky/using-vue-js-vuetify-and-vee-validate-in-asp-net-core-mvc-razor-pages-925ad537bcac This article is a good introduction.
I believe mixing blocking and non-blocking calls inside an async function is considered bad practice. You can read more about it here: https://msdn.microsoft.com/en-us/magazine/jj991977.aspx
If any code running in a separate thread throws an unhandled exception, it kills the entire program. That includes async code. If an async function returns a Task&lt;T&gt; the result must be accessed and have exception catching. If an async function returns void, it must catch any exceptions inside it, before returning, or that will kill the entire process.
Take the case of reader.ReadAsync() crashing the program, code in DbDataReader shipped by Microsoft. Maybe NpgsqlCommand has code w/out exception handling. I'll look there. thx.
The author in your link is saying don't do things like call Sleep or Task.Result, Task.Wait, etc to block the thread in his "Async all the way" writing. None of my code is blocking.
You’re re-throwing the exception, unless you’re catching those somewhere else higher up they’ll crash your app.
There is logging higher up for the Exceptions. As it stands, they aren't being thrown since they aren't being caught first.
Latest version 2.3.1 includes `ChannelReader.Transform` and `ChannelReader.Filter` functions.
[NpgsqlConnection.Open](https://NpgsqlConnection.Open) calls GetAwaiter.GetResult on a Task, so you actually are mixing sync and async. &amp;#x200B; See: [https://github.com/npgsql/npgsql/blob/dev/src/Npgsql/NpgsqlConnection.cs#L119](https://github.com/npgsql/npgsql/blob/dev/src/Npgsql/NpgsqlConnection.cs#L119)
How is that an explanation for an empty catch / throw?
This may be totally irrelevant but what pops into my head is VS2019's kinda-ambiguous project template UI. Without filtering, these items are 20+ items apart, each: https://i.imgur.com/7DPCDjS.png The VB one is normally way way down there under Empty Solution and Unit Tests. There are filter options tucked in the top/right of that screen though.
The project was created in C# instead of VB. Create a new project and make sure to choose "WPF Application Visual Basic" and not "WPF Application C#"
Do you have the sdk installed for the version of .net you are building for? Is your project .net core or framework and what version?
Remove dataType and contentType, GET doesn’t have a body so it doesn’t have a content type and JSON can’t be passed through. It must be through query string.
Ah ok thank you, so it's just url : "&lt;name&gt;" + ID without the elements you mentioned?
Try url: "url?rowId=" +ID
thanks for sharing!
Good place for a breakpoint tho :)
Thanks a bunch for explaining!
Well actually some companies care about certifications. In order to be microsoft silver\\gold partner company has to have several certified developers of appropriate lvl. And some customers want to work with MS Gold partner for example. &amp;#x200B; Certification is a good way to make your knowledge solid. I mean selfeducation usually leaves a lot of blank spaces, yes you know what you actually needed for work but many other usefull things will be left behind. &amp;#x200B; For example i'm preparing for 70-486 mvc exam. And only 40% is about coding. The rest is about deployment, security, architecture. Parts which you won't find in docs about technolodgy. In guides usually it looks very easy, but in reality you will face a lot of other problems. &amp;#x200B; When you developed the feature and think that the job is done, but in fact it's not. It will be done when this feature will be deployed in customers environment configured and start working there. Often it causes a lot of pain because of security restrictions or business recuirements which we thought as not important because it's not coding.
For development do the following steps 1. Run the application 2. Run the command \` npm run dev\` seperately This will watch for any changes made to the files and automatically rebuild them. Hot reload is not present but you can simply hit F5. Rebuilds are under 2 sec. Also, maybe you can make this work as well, have not tried it yet. [https://github.com/danijelh/aspnetcore-vue-typescript-template/issues/6](https://github.com/danijelh/aspnetcore-vue-typescript-template/issues/6)
Here-here. Now that I can’t hit Systems.Windows.Forms, something has to pick up the slack. Is this that? Inquiring minds want to know.
Hey, I have been working with .net core for two years, Do you recommend me some books to learn DDD with .net core for beginners?
If you want less memory hungry than Electron, and language doesn’t matter, take a look at : https://github.com/revery-ui/revery
Oooh thats cool, i actually thought ReasonML will become more popular seeing as its JS but faster basically, hovewer i don't see much buzz around it, but this looks cool thanks!
Thanks a lot for the reply. Well I was thinking your way before I started to asking here and on other subreddits too. However all of the people was the opposite way and like not seeing the possibility that there are lots of useful things someone would not reach by only practising. So we agree. I decided to go with tutorials instead of certification and think that maybe I am wrong. So I am in dilemma again :) Well maybe I would go through tutorials and after that try to pick first exam (actually exam is just the last step and stuyding the book to the exam would be the essence). So that seems to be plan. Do you or anyone have an opinion about this way? I remind I want to do it just to prepare myself to write my own app, not for an employee. Regards and thanks for the reply! :)
So, one thing that is wrong I can see right away is in your endpoint you have the result = linq(p.ProductId == p.ProductId) so that should just be true all the time, so you’re not fetching the results based on the passed in values
 &gt;The idea was to bubble the exception up Then remove the try catch. It's currently serving no purpose. I'd at least log the error before rethrowing. Or better yet, log and throw an error with a meaningful error message.
&gt;why cant Microsoft add their own version of multiplatform gui for .net-core? Neither Microsoft nor any other company has successfully managed to develop a powerful and intuitive cross-platform GUI framework. You always lose something when you go cross-platform. Linux and Windows use different graphics APIs and even those are bound to change sometime in the future. Windows works differently than Linux in a billion low level ways and making a framework that targets both of them is bound to cause headaches. See Xamarin/React Native/Qt. Why aren't they more popular? What do devs who try to use them on non-trivials project say about them? Cross-platform frameworks have always products that are way worse than any single-platform framwork can produce.
Just use OpenAsync is what you mean. To be fair, in OP's case, thy sync version should be fine.
Thank you
The solution is not perfect, but it is a way to learn.
Unfortunately, I'm unable to answer whether Pluralsight and other similar sites are worth using. For myself, I have trouble learning from video, and prefer reading material (especially physical books). I have heard all positive reviews of Pluralsight if that helps.
[removed]
Thanks a lot. That answer help me. I got that I need to try it as if this fit to me - this way of learning. Test it at me :) King regards for you sir, have a nice day!
QmlNet is fully featured (thanks to leveraging Qt/QML). https://github.com/qmlnet/qmlnet PS: I'm the author.
I would pass exams mostly for myself, simply because it gives confidence, and i'm planning to change my job soon. Regarding employment - of course this certificate won't replace a real expirience, and company will test my skills anyway, but certificate won't hurt anyway. It's not such a big money to have selfconfidence and a pretty badge in linkedin profile :)
How do I do that?
Select the list of product IDs out of the list of sales. Then see if product IDs list contains p.ProductId. assuming Sale has a product id on it. var productIds = sales.Select(t =&gt; t.ProductId).ToList(); _context.Products.Where(t =&gt; productIds.Contains(t.ProductId)).ToList();
It was a NET Standard and I realized this morning I wanted NET Framework. Opened a quick project in that, and there was System.ServiceModel in dependencies. Essentially, it looks like I created the wrong project type. I guess it's not too big a deal since I hadn't started anything.
Please write a web app instead, unless it is very, very important that the app work offline. Guess what - HTML is cross platform.
Add the following onto all your async calls: .ConfigureAwait(false);
Microsoft now owns Electron; a successful cross-platform GUI framework. They just haven't been able to do it by themselves :)
Electron is not a GUI framework, it's a browser. And they don't own it the same way they don't own Chromium - which it's based on. Electron is completely different from an actual cross-platform GUI framework like Qt or Avalonia.
We have a rule at my company, "should" isn't allowed. How can you know the GetResult() inside the sync version of Open will never cause the kind of deadlock illustrated in the article linked by the top comment? Better yet, if there is an async method available, and you're in an async context, what good reason could you have for straying from the convention/best practice and mixing in a synchronous blocking call?
Well, we have similar mind then. I think to start with tutorials, check pluralsight and then try a first exam, but without the mind that I need to pass them all. Let's check it how it goes :) I wish you good luck with exams and the rest! p.s. Yes I know all this coaching style. And indeed this is smart to measure your goals. This is like additional, second priority point for me, however that is correct as well :) Regards :)
Measured by memory used and CPU cycles consumed, Electron must be the most successful framework of all time.
&gt; Electron is not a GUI framework, it's a browser. Pedantic.
Also worth noting in general async functions should NOT return void unless a delegate type requires it to (eg event handlers).
Open Exception Settings in Visual Studio and fully check CLR Exceptions. This will force VS to debug caught exceptions which should reveal the problem.
That will only force the async code to run in a new thread which probably won't fix OP's problem (which is likely something in his code).
This is good stuff. Thanks for sharing!
Nah, you can just check CLR Exceptions in Exception Settings which will automatically break on any exception (by default it's only uncaught). Works a lot better than a breakpoint in a catch since by then it might be too late to look at things like locals.
If your Main function is async void, your program is going to exit before your first async call finishes. If you instead use async Task Main, then C# will generate code to wait for your task to finish.
This is mostly just a working list of things that got bumped beyond 8.0 and are potentially large development items or would require a runtime change so they couldn’t appear in an 8.x release. Inclusion in this list does not mean they’ll happen, just if they do that 9.0 would be the earliest version they would appear in.
It is not pedantic. You are limited by what the Web standards allow you to do.
This was what I was going to mention...😅
just go for it. apply to any web dev opening. be up front about your experiences or you can fake it until you make it.
If you're considering other languages, also look at F# + [Fabulous](https://github.com/fsprojects/Fabulous) in Xamarin.
.NET Standard is used for making libraries that will work with .NET Framework or .NET Core (and in the future, for Mono, Xamarin, etc). So you can only access other .NET Standard libraries and not .NET Framework-specific ones. You can't create a non-library project in .NET Standard. .NET Core is the future of .NET but for now .NET Framework is probably what you want. You should be sure you are targeting the correct version of .NET your team uses.
And you are limited by what Qt allows you to do. That doesn't mean it doesn't effectively fill the void of a GUI framework.
I do a lot of react-native work. It mostly just works. The build process and tooling can be flakey, but mostly because of native module setup instructions can be difficult to follow and prone to errors. It's not terribly difficult though. Mostly it just works. Platform-specific behaviors are usually handled with a special component that is named with .android/.ios in the name and the rest of the application just sees the generic component api you define. The biggest pain points are usually designers wanting near pixel-perfect adherence despite the varying device sizes and complicated animations. This can cause an explosion in the complexity of implementation and ultimately performance issues trying to hit very specific behaviors. You can do better using native tech, but it's going to cost many times more money to do so for each platform whereas with RN you'll generally reuse 90-95% of the code, and your team can work on all the platforms, not just their piece of the puzzle. You also don't have to coordinate each platform team, which is rarely trivial. If you have a small team/budget/time constraints and want to do a multiplatform solution, RN is a good solution. If you have gobs of money, time and developers, building out native solutions for each platform might make more sense, but it is a non-trivial commitment you'll need to maintain, whereas you likely have react/javascript developers on hand all the time anyway. I don't see a fully native solution being a good decision for all but the largest companies.
OP: &gt;I have a project to make for university that is basically a C# entry level gui program
Properties/launchSettings.json - Configures how the application is to be launched when using Visual Studio (VS Code may also use this too). So it's basically for your IDE. "dotnet run" may also use it, not sure, I don't use dotnet run. obj/ - Temporary files created during compilation, and kept to speed up future compilation. *.csproj - The project file for the application. Stores things like which .NET Core version to use, what packages your project depends on, and which files to include/exclude from the build and how to build them.
Message Queue?
Yeah I've been tinkering with a sample project and based on the vs code launch.json file, the debugger seems to use dotnet run under the hood along with the "build" task to compile beforehand. When I check the output, the logger says launchSettings.json was used so I assume yes, the command does use it
Hangfire maybe ?
I will give a look on Quartz. Rabbit is a dream to a future.
Can I use Hangfire with my IoC container? I mean, the same way the .NET framework answer the requests to endpoints. And it's possible to use without the database layer? Just controlling in RAM?
So you have to use razor pages then? It's a bummer you can't use a front end ui framework like Vue or react.
When you realize that you can learn whatever it takes to make a project happen you are ready.
Copying the sample projects in the Github is a great way to learn.
That's correct although I can't exactly explain why in detail. I am limited to razor pages.
Yeah, I feel like if I understand c# I can understand other frameworks as well. Just need some time to get familiar. But I am just worried that people required experiences over all those frameworks..
Using IHostedService, or TimedHostedService maybe?
 Can I use Quartz with my IoC container? I mean, the same way the .NET framework answer the requests to endpoints, some kind of Mediator implementation?