ActiveX and modern stopped being in the same sentence about 16 years ago. :-/
Prefer PC (using a Surfacebook 2 13” now) but I do have a MBP 13” as well. Shifting to .Net Core for two upcoming website rewrites and I couldn’t be more excited. I still prefer the full blown IDE and all it’s benefits with VS2017 but I open up VS Code for small html edits and things of that like. I recently heard of SQL Operations Studio but yet to try it myself, I’ve spent a ton of time in SSMS so it would take a lot to move me out of my comfortability zone at this point. ;) 
What are you planning to use the "ActiveX" control in? I only ask, because using in Access is doable but is a bit of a pain. I have a customer that is stuck in Access but I have been adding new features as ActiveX OLE Controls.
What is even the point of a troll like this?
You're feeding the troll
Whatever you're doing is wrong. Stop it. 
Not familiar with Heroku, specifically, but it appears to be a cloud *hosting* solution. Which means that the only things you can upload and expect to run are software packages that output http(s) content. MSSQL server, even the one meant for Linux, is not a web app. It cannot output web pages or any other sort of http(s) content. As such, you cannot just upload it and expect it to work - the entire underlying structure that is controlled entirely by Heroku is where it would have to go, and I doubt they would install MSSQL server just for you. I strongly suspect that if you want to work with a database, you will have to subsist on Heroku’s Postgres database.
&gt;ActiveX Wat. 1998 called and wants its “modern way” back, please and thanks.
From what I’m aware, your best bet is to use the .net core third party heroku buildpack and then point to a sql server that isn’t heroku hosted. Try searching the heroku App Store for mssql as there are options for mysql etc
And [these guys] (https://auth0.com/blog/securing-asp-dot-net-core-2-applications-with-jwts/) 
Waow, Angular CLI And Angular Universal out of the box, that is awesome!!
Did you even read the blog? The example is not about their product. They explained how to secure a .NET Core application with JWT token. The last paragraph is their example of using their product, but the example is about JWT support in .NET Core, and a good one if I may add. 
&gt; html to pdf with webkit engine. wkhtmltopdf remains good choice for PDF exports of various reports/documents of business application (tables, invoices, orders etc) as it supports customizable page header/footer (with numbering), automated table of contents generation and may other useful features. Main drawback is usage of outdated Qt-WebKit (version 4.8) which doesn't support full set of CSS3 and doesn't support flex/grid layouts. PhantomJS is another alternative that also supports customized page header/footer and based on Qt-WebKit 5.x. Both these tools are cross-platform so you can use them with .NET Core and non-windows hosting environment. If you don't want to waste time for writing .NET API wrapper you can use existing wrappers like [NReco.PdfGenerator](https://www.nuget.org/packages/NReco.PdfGenerator/) (maybe most popular wkhtmltopdf wrapper with 227k nuget downloads) or [NReco.PhantomJS](https://www.nuget.org/packages/NReco.PhantomJS/).
well shipping chrome with the application could be a bit too heavyweight... also, it seems chrome doesn't support custom page header/footer with numbering: https://stackoverflow.com/questions/44575628/alter-the-default-header-footer-when-printing-to-pdf if this is true then without this feature chrome is useless as HTML-to-PDF conversion tool in most cases.
Are there gonna be versions for React with Typescript?
What’s a dev gotta do to get Ember?
Custom templates installable via nuget over CLI, what a time to be alive.
maybe not. the templates are now CLI based. so the react template uses the create-react-app for bootstrapping. so you can add typescript support similarly like you do for the same stand-alone create-react-app. :
Anglesharp does this and it runs without headless browser 
you can request this template here, https://github.com/aspnet/JavaScriptServices. Currently the preview templates only offer support for Angular/React/ReactRedux. More templates like Vue and Aurelia is on the way
How is the Surface Book 2? How much ram do you have? I want one but the base model is $1500 with underwhelming specs.
I'm building a web app so it's not an issue to ship chrome. I turned off the header, but it you need custom I would try secondary post processing via another pdf library
Meh. I find SPAs, as actually found in the wild, a uniformly terrible UX.
You're talking about when you declare them as injections like with `Services.AddSingleton()`? Do you mean two initialisers on the same database or two different databases? If you mean the same DB, why not just combine into one initialize call? If you mean two DBs, one way would be to call `AddSingleton` twice, with the constructor method for each having the initialiser. Is that making sense?
i have the surface book 2 15" (16db ram, 512db ssd). Do NOT get the base model. Spend the 2500+ and you will be quite happy. Power of a desktop but convertible into a tablet artist workstation. If you're a creative you'll love it.
In theory, if you switch the Postgres provider for Entity Framework Core, wouldn't there be mininal coffee changes in your app, since it also goes through the EF Core interface?
I'm trying out the new react template now. It's def better than the last one - a lot less extra "stuff". The last one had so much damn extra code and libraries tacked onto it.
This tutorial is for running .net core apps on docker, and using heroku to host/run your docker container. This is a bit different than using heroku to run a .net core app directly. The biggest issue is there isn't an official heroku slug/build pack yet for .net core. Some party really needs to make an official one and host it on GitHub, *and keep it updated*.
He/She absolutely did not read it. I just read it and it's probably one of the best tutorials I've seen on adding JWT for authentication.. 
It's crazy how many down votes you are getting for this. It's an interesting argument. I published a [getting stared guide](https://purple.pizza/where-to-start-in-dotnet/) a few days ago and had to really contemplate if it was a good idea to still point people to full framework. In the end I just tried to make it very clear that newcomers should probably stick with .NET Core, but there is a time and place for full framework, even if that's only because of missing libraries like /u/airbreather mentioned. At this point in time [even Microsoft still recommends people use .NET Framework for some use cases](https://docs.microsoft.com/en-us/dotnet/standard/choosing-core-framework-server), but with all the momentum for Core it's hard to believe that they will continue supporting it in the very long term. I'd love to hear your thoughts on that.
These laptops are crazy expensive but it is a unique device that seems to have lots of quality. I know there were some issues with the original Surface Book but I am crossing my fingers that revision 2 will not have those. I really think you lose too much performance with the 1,500 base model and you would be better off with any other configuration. I got the 13" 16 GB Ram/512 GB SSD with the GeForce 1050 and I couldn't be happier. It's a great balance of power and portability. I've had the Razer Blade, Dell XPS 13 and Surface Laptop but so far I am enjoying this model ALOT more than any of those for my personal use case. 
I hate how expensive these machines are (makes it a hard recommendation) but my experience has been great so far. 
If the performance is truly that terrible on AMD I'd suggest asking on SO to get some attention from the .NET team, tweeting them, or just raising it on Microsoft Connect. More likely it's the C/++ code that's the bottleneck though, assuming you're using that somehow during the serialization? It might have a whole bunch of Intel specific optimisations. Did you make sure to benchmark your code and find which lines of code are actually causing the bottleneck?
&gt; For example, we implemented a loop that's being run 10 thousand times, where the BinaryFormatter is being called. That block of code takes in the Intel System around 7 seconds to finish, while on the AMD Ryzen System it takes over a minute! Intel CPUs have better single threaded performance compared to Ryzen because IPC performance is better, and the CPU is clocked faster. Your description sounds like a very trivial single threaded testbench favouring Intel. Ryzen excels at multithreaded and multicore workloads because you can get more cores at a cheaper price compared to Intel. 
A lot of stuff you mention is irrelevant. Like SSD, setting to only x64, etc. Also I doubt that Intel is that faster in this case just because of better IPC. As the guy above suggested, I'd report this case to MS. There might be some code being generated that really hurts Ryzen for some reason (obviously). 
@strajk, it would be helpful if you could do the following: 1. Log a bug on dotnet/coreclr (please tag me - @tannergooding) 2. Provide a simplified repro (or the original code), if possible 3. Compare the native codegen produced by the JIT to ensure the Ryzen CPU is producing the same code. Feel free to message me here if you need assistance with any of the above steps Tanner Gooding (Microsoft) https://github.com/tannergooding 
I'll look into it, at the moment I don't have access to the sourcecode to test this out, this text post was a repost since silly me posted this in the VisualStudio subreddit first instead of doing it here from the beginning.
Yeah, we know exactly when it happens, we narrowed it down pretty strongly. I'll share some more info about it on a later date, don't have access to the test project at this moment. This post was a repost since I posted this issue in the wrong subreddit first.
What about server side pre-rendering with react/redux template?
Intel's performance used to better than AMD's a little over 12 years ago not because they had a better product, but they made sure code generated for AMD machines was not properly optimized. Intel got caught on that point later, but it put AMD in a worse market position for years. The SSD would be relevant if they were pulling lots of data from storage, but if it is mostly residing in memory and not swapping, then storage isn't going to affect performance any.
Any (crappy) 3rd party anti-virus software installed on the AMD machine?
OK. I suppose if this comment is illegal, mods will remove it. I am trying to do something that should be ridiculously easy. I am working with Rockwell Automation's FactoryTalk product. Its purpose is to enable engineers to create displays to show what their factories are doing. It should be possible to create all kinds of shapes and colors and whatever an engineer could possibly want to display. It should have all kinds of widgets imaginable. It doesn't. Any shape it has should have any of its parameters dynamically adjustable so that the shape would change as a process variable changes. It doesn't. Despite the fact that the display I want to create can be drawn just by drawing three concentric pie charts, I can't do it. The one thing that FactoryTalk can do, supposedly, is accept ActiveX controls. Supposedly, I should be able to write an ActiveX control, drop it onto a display, and use FactoryTalk to connect the control's public properties to process variables. I much prefer writing C# to writing C++. Also, if there is no way to connect process variables to ActiveX control properties, which would be both unthinkable and not surprising, I have a library that a C# application can use to connect to process variables but I don't have such a library for C#.
Please see my response to another comment in this thread.
In my company we're stuck in Access. My chef thinks it's the most futureprooved and easyiest way to programm. I try to convince him to switch to c# and wpf since 2012. He rather would spend 10h to implement an existing winforms control as an ActiveX OLE Control. 
Okay, this is seriously out of my depth. Honestly. All I can say is good luck, I hope you manage to make this work.
I have not used it for a long time, but... When I still used Identity, it was common for me change screen layouts to fit in with my overall application theme and remove controller actions and views for features I did not want. Beyond that, I left most things in place. Not sure if that's the sort of tweaking you are referring to? 
Not to this degree. IPC difference is in range of 5% - 10%, clock maybe 10 - 20%. Thats nowhere near 700%...
700% difference = almost 100% sure it is software bug - JIT compiler most likely. This is waaaay too much for architectural and clock differences.
[removed]
What's up? I've made about six APIs in Core so far. Maybe I can help.
Check your ram speeds. Ryzen is very sensitive to them.
Yes. That and also the roles that it doesn't support. It supports claims. How do you implement custom roles with identity?
you fuck my mother
i am not troll i have many doller in the tinsikniy manaket bank
I pull it completely apart so it fits into a repository pattern with GUIDs instead of numerical IDs. It’s got a few warts but I love how it works. All I have left are roles and claims, everything else is superfluous.
Bookmarking because I'm interested in hearing the responses to the points you made.
Regarding the plumbing done in startup.cs this is the normal thing in an N-layer app. Layers are independent (e.g. You can change your repository layer without refactoring the services layer) and you just need to make the plumbing in your application layer (here startup.cs) You can compose startup with other classes or partial classes to make it more readable I haven't already had the time to read the rest of your question. PS: I am wondering if you should publish apps client ids and client secrets on a public github
long post. i sort of rolled my own startup sequence. i have an interface that abstracts the startup, the options, and any post setup. i run everything as a console app. we have "workers" that are just regular console apps, and servers that are kestrel servers. i use a builder pattern, where a "withX" adds a class to the configuration abstraction that injects that type. like .WithDatabaseX() means that now that thing is a accessible to that service. There are generic constraints on that method that insist the configuration exists, so it puts the configure object into the chain and can somewhat be verified statically. And your controller now has access to that service. I've used this to great effect, and it works REALLY well. If you're interested in seeing how it works, maybe i can boil down the code and remove any corporate stuff. I felt the same way, that dependency injection doesn't buy anything unless you are actually decoupled. So i poked around and built something that at works for us. There are still at one hacks, like i use specialized interface types (without new members) to avoid ambiguity, that sort of thing. I don't think you're missing anything, the boot process is very hard coded to the hello world scenario. Our configurations are encrypted, at runtime they don't don't from source control, and come from remote sources, so this whole "just load it from your json file" is nonsense. Configuration and boot are the hardest problems. Happy to help if i can. FWIW, the code that does all this magic is shared between every service we have, and it, itself, has no dependencies. So the abstraction around boot can exist cleanly. Even the hosts for the servers stunt know about how things are implemented. Only the entrypoints know. If you're building something that doesn't need to worry about reusability, then this is a waste of time. But if you have many services that should share a common core, it's totally worth doing.
&gt; PS: I am wondering if you should publish apps client ids and client secrets on a public github no secrets secreta should ever be on github. we have encrypted secrets on a private github repo, but even that makes me nervous. But with regards to your response, it sounds like the app in question is a "one project solution", everything lives in one of project. In that case, abstraction doesn't matter. no matter how many tiers the application has. It burns you real quick, though, when you actually need to use that database from a different logical service. then you need real abstraction over the layers of the app represented in code. it becomes more than the helloworld project real fast.
The DI container that ASP.Net Core ships with is intentionally a very basic implementation - if you need more than that, use a more complete library such as Autofac or Ninject. These typically some sort of abstraction for their configuration - Autofac has the concept of Modules, for example. These also give you much finer-grained control over the dependencies and their lifetimes. There's a good write-up at https://autofaccn.readthedocs.io/en/latest/integration/aspnetcore.html and an example project at https://github.com/autofac/Examples/tree/master/src/AspNetCoreExample 
Regarding Validation - what do you mean by "validating a controller?" 
You can clean up the startup file by copying what asp does. You don't list out the 200 services for MVC, you call services.AddMvc(); https://github.com/aspnet/Mvc/blob/dev/src/Microsoft.AspNetCore.Mvc/MvcServiceCollectionExtensions.cs Look at the code for it, it's an extension method that just adds all the services. So I generally have a file like that in each of my components that adds the services that component needs via an extension method. The startup file is then just adding the components you want.
Re: reusing database dependencies etc Those dependencies, and their configuration, can be abstracted and follow the logical structure of the emerging app while being called from your ASP code. The example provided is what it looks like in its most consolidated form. If your datalayer has a DB dependency your ASP project can reuse that dependency, wired up in its startup but reusing the configuration from the DB app. For most of the apps I work with that would mean using the same DI framework in the webapp as the rest of the code. This tends to come in the form of framework specific packages (ie Autofac.AspNetCore, or whatever), that let you point your webapp to your primary configuration. Those frameworks then have all the library scanning, and "automagic" configuration that fits your taste and needs while the webapps have a minimal config.
Aufacs lambda based constructors are an absolute lifesaver - highly recommended.
Let's say I have pagination for a resource. If I want to limit the page so it's positive and not greater than 100 as an example I'd add validation. In the model this can be done using `[Range(0,100)]` but that can't be done without the model. You can't just add validation to specific parameters for specific controller endpoints. A full example would look like this: `public async Task&lt;PagedResult&lt;Article&gt;&gt; Get(int page = 0, [Range(10,100)] int pageSize = 10) { ... }`
Hmm. It still feels weird to put everything together. Every other platform I've worked with (mostly Spring) has this abstracted away, still it feels like this would be a pretty significant point of contention and could cause a lot of tech debt to build up, especially if you get into a situation where you need to build it fast. The sample from the ASP.NET team that I linked in my post has pretty much everything in it: Auth, Localization, Databases, Configuration, Logging. Seems like that will grow pretty quickly. Their code is already pretty messy and it's a sample application. How is something like this normally tested? I don't see an easy way. Also, regarding the secrets. It's not my project. But I 100% agree, don't leak secrets. Thanks for keeping an eye out!
If you're really opposed to adding a `PageRequest` model class - which seems to be the most idiomatic way to do it (not least because it's going to crop up in lots of places) - you could put [validation logic into an ActionFilter](https://damienbod.com/2016/09/09/asp-net-core-action-arguments-validation-using-an-actionfilter/). 
I'm interested to know more about this relationship you have with this client. How did it come about that they specifically asked for some technology choices that are not on your usual list? The fact that your firm isn't familiar with the technology would be a giant reason to consider using something else. One would really need to know more about the context of the problem to know what the best solution might be. At the moment your question is purely "generic technology stack" versus "other generic technology stack" and you won't get any answers that will ehlp you much in the long term, I suspect.
That looks like what I wanted, I'll give it a try tomorrow. It seems to behave and be positioned in the application stack how I want it.
Sometimes for simple scenarios I used their role system. But for more complex applications you will probably have to roll your own authorization system.
If you look at the linked [Startup.cs](https://github.com/aspnet/MusicStore/blob/dev/samples/MusicStore/Startup.cs) this is what ASP.NET does in their examples. The problem isn't all the ASP stuff, like you say that gets handled cleanly with `AddMvc()`. When you add configuration, auth, localization etc though you either need to add more extension methods, call some helper classes that do the configuration or implement something even more complex. That's where I'm getting concerned.
Great question! As others have already replied to you, the built-in DI implementation is minimal but it can be easily extended with libraries that are specialized in the role. This allows you to create your registrations in other files. Yet your question remains unanswered because, even if it's in other files, the startup class is the one invoking (directly or indirectly) those files. But, truth be said, this is exactly what the startup class is for: wiring up all the different parts of your application. As for the model validation, I think it goes by taste. ASP.NET is modular enough for you to customize how you want to use it. Especially if you are part of a team, it might be worth spending some time creating the tools that you and your team agree you need. For example we have a controller with an action that is used to serve requests for a very big family of URLs, varying by language and other parameters. By using action filters we have a pipeline that allows us to process those URLs and eventually serve the action with a very standardized set of parameters, regardless of the original requested URL.
In this particular case it seems like you want to do something a way you prefer rather than the way many would suggest. In a case like this I would always use a mode class rather than accepting the named parameters in your action. This lets you modify your structure over time without having to change your action signature. This is useful because most parameters coming into the action are probably not being used solely by the action but they are being sent along to services or libraries where your actual business logic is implemented. Adding a new parameter would mean altering method signatures potentially through a few layers. And if you’re just adding one parameter you might think it’s easier to just add it through the stacks and look for compile errors to figure out what’s impacted rather than refactor out to a model class and updating those signatures once. And then it happens again and again. Or maybe not. The point is it’s not much work to use a model up front and it can save you trouble later. And as a bonus, you get a straightforward way to add validation annotations. If you’re concerned about adding a check for a valid model, you might be able to create an action attribute like ValidateModel which would check the model state and only allow the controller action to process it if valid and otherwise redirect to an error page or whatever you would have done if you wrote the check in your action directly. To be honest I’ve always been a little annoyed with that bit of ceremony but not enough to have thought about this before.
But there's no reason you can't make your own methods to do those things and put them in separate classes etc. And call out to them. We have our own security library for handling auth to our database, we then need to configure the asp auth middleware to use it etc. All that is in a separate library and we can't just call services.AddSecurity() to do it all so it's a one liner in startup
Also keep an eye on what they are doing for 2.1, ways of validation that will be enforced prior to an action method being called.
There is a Test Host class for testing specifically.
On DI: you should create a folder of extension methods/factories which extend the services object. That way the configuration concerns are separated, but you get to benefit from composability in Startup.cs On validation: this is quite a common complaint about C# and OO, that you needs classes to do anything. Generally it's cleaner to just define a model and put your validation in there. It's better separated concerns and means you're not fighting the framework.
&gt; We did notice that the performance was almost the same if we did the loop only 3000 times instead of 10000, in that scenario AMD was only around 500 millisecond slower than Intel. When memory intensive processes slow down dramatically and disproportionately with increasing number of operations it usually is related to a memory caching issue. The affecting cache could either be the CPU cache or the disk cache. You can try to isolate the problem by eliminating disk access and writing to a memory buffer to see if the slowdown dissappears.
Spring is an architectural horror. You have no idea what it's doing or how it works. It's all built around AOP magic which means that the code you write and the code you generate are almost completely unrelated. At some point you need to actually tell the application what to use and that should be coming from the top layer of your application. 
Yep, SSD doesn't matter here (also about Intel getting ahead of AMD). Setting to only x64 doesn't matter as well, since the app would run by default (Any CPU) in x64 regardless of the configuration. Also the amount of RAM is potentially meaningless unless app accesses a lot of memory - which in this case is probably not - should check with memory profiler. If I was OP I'd check the execution using a perf. profiler (besides reporting to MS) -it could show something interesting.
I felt the same way. I ended up storing the assembly names to load in config file and used a single marker interface that returns the types and registration info in a way the startup file can use to build up the container. This requires a shared .Common project but totally worth it. For DB, I dislike injecting Dbcontext directly so I do that via a factory instead. I want to control the lifetime myself and kill dbcontext upon leaving the repository. For validation, I dislike the whole asp.net validation model because if you want to share your code with a wpf app, you need to implement the validation logic for each new UI. Instead I do all of that in my "service" layer and throw a Brokenruleexception. Then each UI handles that in its own way. Plus, you can do DB hits or anything and not have the attribute limitations.
Yeah, never ever use Guid.Empty. in fact, I'm disappointed that SQL server allows you to store Guid.Empty as a UniqueIdentifier. It should error out like if you'd said 31st of February. It's really just an artifact of c#s value types - they must have an all-default default constructor.
If source is available, I would try to do some profiling, and narrow down and check which instructions are to be blamed of the performance loss. Trying to reason about a big black box... Is harder
One thing I would do quickly is remove your keys for Google, etc from start up and add them to [secrets] (https://docs.microsoft.com/en-us/aspnet/core/security/app-secrets?tabs=visual-studio) or use [environment variables](https://docs.microsoft.com/en-us/aspnet/core/fundamentals/environments). See if you can remove them from github as well. 
Content aside, that's a terrible site layout. Even if I reduce the width of my browser, the hero image on the left takes precedent.
I don't really mind the layout. But since we're discussing layout. I have difficulty reading these thin low-contrast fonts, so I used the development tools to make the text black and bold prior to reading. 
https://github.com/0xd4d/dnSpy I have had success with this tool. 
Thanks for the feedback, I'll take it into account as soon as I find some time.
Sorry for the late reply. I'm assuming you are talking about extending their implementation and adding custom roles stuff?
And examples of this implementation I can look at?
I wouldn't mind seeing some examples of this setup.
Thanks, it's not my project. The sample code is from the ASP.NET team.
I know dnSpy, its pretty decent but it's not integrated with Visual Studio. I'm not sure if this allows to debug integration between your code and third party libs. You can also setup doPeek as symbol server but the process is more complicated than using Resharper decompiler.
Guid.Empty is not a Guid, sure. But the authors easily dismisses the fact that it comes way back from C#1, where it was necessary for nicer "unset" Guid handling. It would be easy to remove it, if not for fact that there are billions of lines of legacy code which will be broken by that. Extension methods seem nice, but they are newing-up new structs on each call, which certainly is not better than static field which is newed-up once. If somebody would like to use those methods, I would advise replacing `new Guid()` with `Guid.Empty`.
No one has mentioned yet so I'll throw in our way of handling Dependency Injection with reflection. To solve the issue where we could end up with hundreds of mappings we use reflection to loop over the specific assemblies where we keep those classes. We mainly have 2 types of services Stores (CRUD operations) and Managers (checks permissions, then validation, then uses then uses a Store operation). We have a custom attribute we place on our interface and we pass in the lifetime for DI, type (store/manager), and the type of Entity it's backing. Using reflection we can find interfaces with our custom attribute and the implementation that matches the criteria and then map it. There may be an easier way than reflection inside Autofac or Ninject but our principal engineer wanted to use purely ASP.NET Core's DI.
[Persistence-Ignorant ASP.NET Identity with Patterns](http://timschreiber.com/2015/01/14/persistence-ignorant-asp-net-identity-with-patterns-part-1/) - 4 parts, what I use is a modified version of this but the vast majority is directly lifted from these articles. I typically slice out the third-party auth (nearly all projects have not called for it) and move the Store and Identity folders to a separate project for common code that I call Common. Keep in mind that if you expand the User table you will also have to touch Identitiy to match, so the UserIdentitiy file in the Identity folder will have to be expanded as well.
What a stupid rant. Whats next? String.empty is not a string? The empty property is for checking if guids are really guids and not just zeroed memory. Guids can come from DB/files/net and might not have a valid value... so there obviously needs to be a way to express and access this state in code. 
It would be nice if the compiler would flag default-initialized guids as a warning. Possibly datetimes too.
Didn't quite get what were specificslly your problems, but I had to write a lot of stuff that you would guess is baked in the framework. So I agree on the sentiment. 
I do not agree with that rant; we’re all familiar with value type initialisation, and nullables do not fit every scenario. What is also completely left out: The so-called “Nil“ UUID is even part of the RFC 4122 (section 4.1.7) that specifies UUIDs versions 1 to 5. It’s also found in other APIs and often called “Empty”, just like in .NET. 
Ahh got it. I didn't notice that. 
Thank you. Will take a look at this.
I think you need more examples of patterns and libraries to use. I point people to this: https://github.com/gothinkster/aspnetcore-realworld-example-app
This was a good presentation and a fun watch. My only issue was that it seemed to be pretty broad involving the history of Microsoft technologies and legal issues. Can anyone point me to some resources on the evolution of .net, specifically why newer features were added and what type of problems those new features were implemented to overcome? For instance, LINQ was added to overcome this, and serialization was added to enable this, etc. I'm currently teaching myself C#/.Net but I find it helps to have knowledge of the "why" of the concept to help understand the "how" to use it.
i know im quite a bit late to the party here, but another thing to think about is that .NET is a very large ecosystem so don't try to tackle everything all at once. Think about what you enjoy building (web apps? desktop apps? other?) and then go down the path of finding the specific .NET tools for the job. [This is a decision flow chart](https://purple.pizza/where-to-start-in-dotnet/) that might be helpful to get you started. Since you're brand new I would probably stick to the right side of the chart.
Also another thing: the author has not managed to deal with migrations in that article, while I have figured it out (I can provide you with instructions). However, auto-population of user accounts are something I have not been able to build into migrations; I have just built one-time hardcoded actions in my controllers that I manually run on the empty DB and comment out before the project is pushed to production.
I find `Guid.Empty` useful for default values, both in the database (lookup tables only) as well as MVC forms that do double duty for both inserts as well as updates (Guid is empty, do an insert. Guid is not empty, it’s an update. Same form, double duty). Plus, with MVC models this saves me the trouble of continually having to convert back and forth from a non-nullable type to a nullable type and back again, helping me to avoid bugs. And if I want to tamper-proof my hidden fields, I need *some* value there, as you cannot hash a null, so an empty Guid works great.
Well, "empty" guid is never globally unique. Empty string is sometimes really a string as indended. Of course, most encounters with "" are not meaningful: name is never actually empty. If it's not there, it should be tracked in the type system as Nullable&lt;string&gt; -- that's of course problematic until C# 8. IsNullOrEmpty is a funny construction when you think about it further -- and it's very similar to the "guid not null &amp; nonempty example" from the article.
Oh, and about guids coming from network: that's a good remark. There is a leap of faith when introducing such id as guid -- it's like any cast. The article is about not doing things that are guaranteed to break invariants we care about.
I would rather see a null than an empty guid.
Uh, what's with the down votes?
For validation, you can add an action filter and do the Model State.IsValid there so you only have to do it once.
For validation, you can add an action filter and do the Model State.IsValid there so you only have to do it once.
I never used it ever. There was too much extra work that it always paid off more to just my own everything. 
And he doesn't even mention https://msdn.microsoft.com/da-dk/library/system.guid.newguid(v=vs.110).aspx which is how they should be initialized if he read the documentation
[This flowchart might help.](https://purple.pizza/where-to-start-in-dotnet/) There's a time and place for all .NET tools right now, you just need to pick the best one for the job. It's not going to be a good use of your time to try to learn everything. .NET Framework and ASP.NET are probably the heaviest used in the market but .NET Core is Microsofts new direction.
Yeah, there are a lot of different ways to do the same thing unfortunately, BUT for what you need to do, you're in luck. Don't overwhelm yourself thinking about all the different technologies you can use. Try to keep it simple and go one section at a time. Perhaps start with the database and stored procs. Then build a data layer that can work with the DB and those procs. (Personally I think building a basic repository pattern and using standard .net sql libraries to work with the database is FINE and more than adequate for most use cases.) Then build the API using .net core controllers. Finally, do the front end with the bare minimum you need. How complex will your UI be? How interactive is it, is it just displaying information? Start with HTML and CSS, then pepper in some javascript to communicate with the API. Is it starting to look like you'll need more than than? THEN consider something like React or Vue. [Check out this flowchart](https://purple.pizza/where-to-start-in-dotnet/) to maybe clear up some of the fuzziness around .net tooling. Hopefully that helps, I know I'm like 26 days late, I'd love to hear what you decided on. I may write an article about this in a clearer way.
It's hard to argue against the standard -- and in the light of Nil UUIDs, the headline looks very baity, sorry for that. Nevertheless, the point stands: in a strongly typed program, actual Guid (i.e., GUID that is globally unique) should have a type. If standard says that Guid is actualy Guid?, we need sum types to get us from this mess and say type Rfc4122Guid = | Nil of unit | Value of Guid Then we have something to pattern match on on the boundary, and then we have name (Guid) to use in all of our logic when, again, having implicit Guid? everywhere is highly problematic.
In my case, some of my use cases (the hidden field hashing) throws a null error exception if I have a null Guid. So I have to use an empty guid.
&gt; now needs to know about every class I want to inject. Yeah, I wrote myself a 'container' so my controllers and services only need to inject one object. My guess is they have it ctor only is to streamline the flow for performance sake. I don't mind that. 
I hate it. Its a really dated architecture. DotNetCore exposes all the needed bits for hashing passwords and writing cookies/tokens so you can inject security without injecting obtrusive business logic.
I'm assuming you're using DI in your program for testing purposes. I think you're missing a layer in your design. You need a repository, or logic layer that your controllers call. Then the controllers are the part of your program that inject the dependency via constructor injection. When testing, your test classes are injecting your mocks or fakes into the logic layer. This way all the controllers are doing are checking modelstate.isvalid, then passing the model into the logic layers method for doing stuff. I can provide a code example if you want, let me know. 
Just some quick research, Linq was born out of [Cω] (https://books.google.com/books?id=8OxGcCJViU4C&amp;pg=PA776&amp;lpg=PA776&amp;dq=linq+c+omega&amp;source=bl&amp;ots=WNP6Y1iwuV&amp;sig=kizJeKk98WOkH_stLDwoniuo-YA&amp;hl=en&amp;sa=X&amp;ved=0ahUKEwjL2MC05IDYAhWERSYKHbDICB4Q6AEIPjAD#v=onepage&amp;q=linq%20c%20omega&amp;f=false) 
I've seen several people recommend this and completely agree.
Same!
Wow, thanks for linking that!! Looks very useful! 
Have you tried adding a modelerror to the modelstate without having a model class? It should still work.
You're making it sound as if exes do not exist on other platforms. Do dlls exist on them to you?
Because I don't want megabytes of same stuff copied around? That has an impact on the overall system performance. There's a reason why .net assemblies are ngen-d when installed, you know...
For testing I'm specifically curious how you'd put Startup.cs under test to confirm everything is setup correctly. For example in the linked example from the Asp.net team how would I test that localization defaults to en-us?
Thanks friend,at present I am learning HTML,CSS,JS will start with ASP.NET as soon as I am confident with those 3.
Nobody will tell you that, but the important reason is wanting to start from a clean slate. Old .NET is 15 years old now and dealing with legacy is ungrateful and hard.
Your second phrase is contradictory in itself. Old .NET has **a lot** of Windows-specific stuff in it that Core just does not.
People are building and running Linux and other systems executables built in C, C++, Free/ObjectPascal and a wide host of other languages and programming platforms though.
I absolutely agree. Half of the window is wasted with a useless picture.
Easy to write an analyzer for if you want.
Remind Me! 6 hours "watch"
RemindMe! 6 hours "watch"
I will be messaging you on [**2017-12-11 14:02:30 UTC**](http://www.wolframalpha.com/input/?i=2017-12-11 14:02:30 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/dotnet/comments/7itco5/the_history_of_net_from_the_ndc/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/dotnet/comments/7itco5/the_history_of_net_from_the_ndc/]%0A%0ARemindMe! 6 hours ) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! ____id____) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
&gt; depending on requirements If you can read...
The contradiction is &gt; depending on requirements &gt; I'd **always** now choose So does it depend, or is it **always**?
Reasonable answer: someone needs to add the code, to the compiler, to produce an actual exe on various platforms. Someone needs to add bootstrapping the CLR from that exe. That hasn't happened because nobody was bothered enough. Perhaps it never will, Java RE never did it (but there's 3rd party products to do it). All other comments here are hollow rationalizations. No offence meant :-).
There is no difference between new Guid and Guid.Empty. It’s a struct. No memory allocation takes place, no logic takes place in the constructor, and 16 bytes are copied on the stack regardless of which method you take.
True about initialization, that's what happens when you comment while half asleep. Still I consider that `Empty` gives more semantical meaning to usage.
Hm, this is not getting enough attention. I was going to build myself a Ryzen system soon. If this turns out to be true, I might hold off for a while. At the very least I'd like to know what's going on...
Very interesting. I'll save this for the next time there's PDFs to be generated.
Does this have something to do with .Net?
With other libraries to supplement for missing assertions, in the end you're still left with the testing framework. I went the xUnit path because I was tired of the bloated build up/tear down structure ceremony. That said, if anyone finds a comprehensive unit testing golden hammer, hit me up!
Is zero not a number?
Wow, empty catch handlers - not like that'll come and bite you in the ass....
1. Similar approach to Xamarin native 2. We all need to make clients too
&gt; Perhaps it never will, Java RE never did it (but there's 3rd party products to do it). At least in case of java you can bind .jar to open with Java on windows. Can't really do that with .dll
A special case that immediately comes to mind relates to differing perspectives on FRP. If you look at your application's data as Observable, it can be aggregated monoidally. But if you view it as "a persistent object with a current value that might observably change values" then it acts like a semigroup.
They can be run if you install the dot net core framework.
They actually do. Linux has operated on shared libraries (linked libraries) for years. Those libraries can be dynamically linked or statically linked. As such, Dynamically Linked Libraries have existed in the Unix world since inception, just aren't .dll files. http://www.yolinux.com/TUTORIALS/LibraryArchives-StaticAndDynamic.html
That sounds like an excellent path. Good luck
&gt;If there were exes then it wouldn't be cross platform I know, I am making /*.so-s on a couple of UNIX flavors myself. The comment above is just horribly confused. An executable is an executable, something that exist on UNIX for longer than it Windows itself exists... Sure it's not something.exe (but I know of people who do exactly that) - but does it matter!?
[see here](https://www.reddit.com/r/dotnet/comments/7i5kao/why_no_exe_for_core_console_app/dr38nu8/)
Angular CLI has a lot of additional functionality that is nice, but not a must. For instance, want to generate a component? `ng g component test-component`want to run tests? automate `ng e2e` and `ng test`. I don't think it's as big of a deal as a lot of people make it to be - the dotnet new angular already comes with webpack, so... Anyway, if it's for a small application, you are perfectly fine, but I would recommend to not if it's a larger application. Separation of concern, and if you have a UI designer, he can write the UI with a separation from the actual database running, etc.
We use it and it works well. Saves a lot of time.
And of course the button you’ve highlighted is the one with a spelling mistake. 
Some of the values take the first found. Some take the last Some provide and aggregate Sometimes you dispose after finding the first, but continue to loop?! Sometimes you don't dispose at all Sometimes you just suppress stuff in an empty catch, sometimes you don't This is very inconsistent...
RemindMe! 7 days "Check for new answers"
What I really want is something that can handle dynamic test generation. For example, I want to say "run this set of tests against every class that implements interface IFoo". I've managed to make xUnit do that, but its an ugly kludge. Oh, and better support for integration tests. Not some cheesy mocking library, but something that can actually simulate network traffic using loopbacks. 
Unfortunately, it doesn't look like they're making much progress in the GitHub issues linked above. Pretty annoying.
The issue is that EXEs are a Microsoft construct in place of a shell interpreter. It has become part of the community to assume that anything ending in .EXE is executable in a Microsoft environment. While we can both agree that excutability has nothing to do with the extension of the file in reality, the fact is that the Linux / Unix community would not make the same assumption in their environment. Just like /u/euclid047 references, pick the best tool for the best project, but also avoid ambiguities. We've been taught for years that best practice is to assume nothing about your audience. You should do the same when writing in a cross platform environment. There's a reason Java has its own executable format. 
Damn. I've been looking for a solution for quite a while now
I'm on the verge of researching how code coverage tools work so I can write one myself or port OpenCover to Ubuntu.
* PC * .NET Core * Both. Also starting to use Rider more. * Linqpad * Both
A couple concise thoughts I have as I can over some other answers and didn't notice anyone else say: Dependency Injection: Better that your Startup.cs have a "dependency" than your controllers have the hard dependency. Your code is flexible. The DI framework doesn't create something until it's needed, so stuff in there is mostly harmless. Refactor them out into profiles (based on use cases, perhaps) if you have lots of stuff. Validation: You don't have to use literally *every* feature of the .NET Core framework. Validation attributes are one of those things that are nice for quick validation of data coming in. I like to create DTOs or ViewModels that are mapped as inputs to my controller actions for validation. Once valid, I map them to something more appropriate to do work.
 So no.
do you mind posting this alternative to SSMS? I know the SSMS 2017 is cross-platform, but not sure if you're referring to something else.
The "other thing" refers to the product OP posted in the original question "SSMS over SQL Operations Studio?". 
 Ah I did not see that. Thanks
Just implemented the repository pattern in my new MVC app. I'm pretty new to starting a project from scratch, and consequently have never designed tests.. thanks for this as it relates directly to what I'm working on now!
You ask what the advantage is of using the CLI, but I want to turn that question around: What advantage does hosting the Angular application inside the ASP.NET application give you? Why do you want to do that?
Me 3
xpost https://www.reddit.com/r/dotnetcore/comments/7iv8af/how_to_handle_connection_strings_properly_in/
You're going to want to look into something called web.config transforms. Or you'll want to use something like azure key storage. 
We use environmental variables to store connection strings. 
How do you authenticate yourself to the azure key storage service? Do you have another azure key storage account that has your keys to the original azure key storage account? And how do you authenticate to that second service? Is it turtles all the way down?
Those keys can only be accessed by resources that are authorized to do so. Either through your Azure Resources or your account resources. Basically you set the keys up for your app service to have access to them and for your local developer environment which typically uses visual studio. https://docs.microsoft.com/en-us/azure/key-vault/
As long as you don't do the repository pattern wrong, it's fine. But don't do it wrong.
Ah, that makes sense. Vendor lock-in, but at least it's not infinite turtles.
I mean. The alternative is really that you store them as encrypted environment variables which some version of a machine key to encrypt/decrypt them. variables. But you'd still have to store that information as a backup somewhere or go get it from the live sever if need be. 
While I strongly agree with using a distinct service layer on even simple projects, I find the tests to be laughably bad. Consider this line: List returnedStudents = service.GetStudents(testInstructor.Id).ToList(); And its implementation List GetStudents(int teacherId) return students.OrderBy(s=&gt;s.LastName).ToList(); Can you see the bug? The test can't. 
Redundant use of ToList()
Why go to all the trouble of building a repository? Why not just mock the entity context with in-memory db or Effort?
i personally wouldn't test anything in startup.cs, it's configuration. You can test that configuration is set up correctly by calling something that uses localization (not startup itself). So for example if I was using some localization class FOO for en-us with interface IBar i would use IOptions to register it in startup.cs with that mapping. Then on a page that needed localization like a web controller, I would add an IOptions&lt;IBar&gt; locale parameter to the constructor. your bar class should be injected in the app. Lets say you also create another locale class BAZ with locale fr. In your test class, you create a new controller with (FOO) and make sure its locale is en-us. Then instantiate another controller with (BAZ) and make sure its locale is fr. Easy tests because you're injecting your dependencies at time of instantiation (vs startup), and registering them in startup.cs if you need a default. That's the jist of it using constructor injection DI flavor. 
Maybe. The way I'm looking at it, the service isn't being disposed. Which implies that it doesn't hold open database connections. So while the ToList in the test is redundant, the one in the service is appropriate. If the service is stateful (i.e. it needs to be disposed) then the test is still wrong but you gain the option to return an IQueryable.
There are advantages to creating a repository. But even still, I would just point the ORM to an in-memory database instead of using a mocking library. ref: https://www.infoq.com/articles/repository-advanced 
&gt; repository pattern in my new MVC app Why? Don't take this as an attack. There are plenty of good reasons to implement a repository separate from the service class. I am asking "why" because I want you to think about what you are actually getting from the repository over just using the ORM directly. I wrote a couple articles on the subject because I got tired of seeing "repositories" that still required me to handle all of the bookkeeping at the service layer. (e.g. audit columns, history tables, logging, etc.) * https://www.infoq.com/articles/repository-implementation-strategies * https://www.infoq.com/articles/repository-advanced Now I'm not saying you necessarily should use all, or any, of these ideas. But I do want you to think about why you have a repository and how it can benefit your specific project.
How do you handle standardizing environments? Docker?
No azure, just an old fashioned private cloud (vmware) with a sql host and a web host.
Decent introduction. I don't think anyone cares about refcounting as much as talked about, not in .net world. &gt; allocating memory in a mark-and-sweep style garbage collector such as .NET or Java is a simple matter of a pointer increment Eh, not really. First, there's a function call obviously, in fact several of them, then, there's a check that there's space for the object and finally, that needs to be done in a thread-safe manner. This simple "just move forward" implementation is known as a "linear" or "firward allocator" in the allocator design theory BTW. It **is** faster than a "standard" allocation though, obviously. Other than that, the linked Bouma article has more relevant detail and info.
There are databases who allow you to get notified when stuff changed, e.g. [like so in SQLite](https://sqlite.org/c3ref/update_hook.html). I am not aware that this is a "standard" DB feature however. One could imagine that DB systems don't like this being done because it brings an unknown performance change. The normal way to do this is to close the database for direct modification completely, add a layer that receives data changes and broadcasts them.
I use CacheManager (https://github.com/MichaCo/CacheManager) as my caching library, then you can simply create a user "service" layer (or maybe whatever you're using already has the CRUD operations exposed) and in your CRUD you also pass commands to the cache. For example when a user is updated you would do your update as normal via the DB then also send that update to your cache engine (http://cachemanager.michaco.net/Documentation/CacheManagerUpdateOperations). So the overall approach is to have some sort of method that either hydrates the cache with all the users on startup or implement it a bit deeper and have the caching layer hydrate each user object once it's requested (i.e. GetOrAdd method). Hope that helps :)
Read Clean Code and The Clean Coder to produce higher quality code and be a better software professional. Learn about design patterns and architectural patterns to produce software that is easier to maintain and extend. Learn about proper testing; practice TDD and BDD, so your software has fewer defects and actually aligns with what your customers need. Learn a couple of new languages; given that you know C#, I’d recommend F# and something like Python. Improve your soft skills, so you can collaborate more effectively and communicate better with people outside the dev organization. Learn about best practices in non-functional requirements, such as security, monitoring and performance. Learn about different paradigms, such as event-driven architecture, or the actor model. Never stop learning new things, even if you don’t intend on immediately using them. Awareness goes a long way. These are just some suggestions. 
Yeah the test is bad because I couldn't think of a really good example that didn't require a lot of background. That being said, the reason I've used `.ToList()` is because in the `CollectionsAssert.AreEqual()` method takes an `ICollection` object, not `IEnumerable`. So I have just converted it to `List&lt;T&gt;` for the sake of the test.
As a general rule, you shouldn't be returning `ICollection` or `IList` anyways. You should accept the narrowest interface that allows your method to work. But your return should be as explicit as possible. The .NET Framework Design Guidelines go so far as to recommend a strongly named collection (e.g. `StudentCollection`) so you can later add additional methods to it if necessary. For internal projects, I'm a little lax on that and return `List&lt;T&gt;` instead. `List&lt;T&gt;` is especially good because it is faster than `Collection&lt;T&gt;` and much faster than `IEnumberable&lt;T&gt;`. Especially in .NET where the runtime cannot devirtualize interfaces. https://www.infoq.com/articles/For-Each-Performance 
Regarding examples, look up AdventureWorks. It's a well known sample database for SQL Server upon which you can build examples. Start with a full set of CRUD operations on the tables. 
Agreed.
Alright. Thanks for the info.
So, this is tricky question, and unfortunately there is no a clear path... Some advice, although not what you want hear is take some side projects. But, build stuff you haven’t touch thus far, try core, try Nancy fx , try some mvvm wpf, after this try soa, upgrade soa to use a queue transport , make them all communicate . Also, the attitude is very important, is you say you are a 7 but you can not match the speed and or “elegance” ( what ever this means ... ) of a senior dev you probably are mid level, before moving to advanced patterns , read up on c# language stuff, look for tips and tricks and by all means follow the reading list. The one thing that I learn in my 8 years of working professionally is that you should constantly learn and adapt, if you truly want to be an architect or solution designer, one more thing you should be is trying out various other technologies, node ( see how they do stuff there, is it better ? Worse? Understand why ) , php ( how is it different ? The runtime ? ) after fundamentally understanding this also look into storage, sql, no sql , flat file, caching memoisation... why mongo ? Why not raven ? Postgres json ? TLDR; In order to be an architect / solution designer you need to be an “ expert”, and an expert is basically some one who did most of the mistakes that can be done, to make mistakes you need to try out all sorts of stuff, to not break clients / employers bank and dreams you should make mistakes in your spare time, on you side projects , so get to work and good luck :) 
To be honest, I always forget about it too.
Admittedly I only skim read the other comments, but I don't think anyone suggested contributing to open source projects. You'll get some exposure to the different ways to do certain things and learn new techniques as well as possibly some bad ones that you will begin to recognise as inefficient or poorly designed. Plus you are working on something that's used by a variety of different people for a lot of different purposes which helps with designing good, usable, extensible apis for your libs. My other suggestion would be helping out on SO. Read through the new questions, replicate other people's issues, help debug them, read official docs/source code and post a well thought out and helpful answer. You'll learn a lot during this process, especially when someone else posts a better answer and you're like "I didn't even think about that, have an up vote" 
&gt; Improve your soft skills, so you can collaborate more effectively and communicate better with people outside the dev organization. This is so very important and often ignored. Soft skills are **very** important for leads. No one gives a shit about your expertise if you're an asshole. You must be a team player, you must understand how to approach people.
Immediately after add/update/delete, purge the list from cache. Then, the next time you try to read the list from cache, you’ll see it’s not there, and you can pull the latest user list from the database and store it in cache for subsequent reads.
Depends on your circumstances really and what you need them there for. Personally I keep all app data outside of the project folder simply because of deployments - if I make a release definition in VSTS I'm going to publish with the 'Clean' option, and I don't want data before removed. There are ways of excluding folders from clean etc but it's just another thing our devs have to remember when setting up release definitions.
I'd split it into two of I were writing a job spec: *Soft skills* Communication, leadership, problem solving, can-do attitude, constantly learning and trying different technologies, evaluating existing team working, supporting others' learning, etc. *Technical skills* Here I'd refer to something like the programmer competency matrix: http://sijinjoseph.com/programmer-competency-matrix/. I'd expect a senior dev to be mainly 3s, though the table is a bit outdated in a couple of places. The key thing really though for me is attitude and enthusiasm. Ok so you don't know how to set up automated builds which run unit tests, generate documentation, release notes, and tag in git all in the same build definition, but you're both willing to learn and capable of picking it up sharpish.
If you don't want to explicitly register all services in your `Startup` class, you could use convention-based registrations. Most containers in .NET already has this feature built-in. If you want to stick with the default container, I've written a tiny library, [Scrutor](https://github.com/khellang/Scrutor), that enables this.
Environment variables, or, if they can use trusted connection with the app running under an AD service account, that keeps them out of source control. You can store them in external configuration files (as in, separate to the web.config), and then reference them from web.config. You can still do ARM or infrastructure deployments then and just pass in a separate config file with the credentials, leaving no secrets in the application source: https://docs.microsoft.com/en-us/dotnet/framework/data/adonet/connection-strings-and-configuration-files If you're worried about people with VM access getting to the connection strings, you could encrypt that config section (see above link again). Though, I tend to think that if someone gets access to a VM running an app then if they're determined enough they'd get to the database somehow; these are slowing them down and giving you time to kick them out and patch more than anything. Azure Key Vault is next on my list, but most of our apps are on-prem VMWare so we won't be adopting it widely for a while.
Regarding validation; version 2.1 of MVC will introduce a more opinionated approach to writing APIs. This will include a new .[`ModelStateInvalidFilter`](https://github.com/aspnet/Mvc/blob/7f214492b80a562b2f537dc535a77ee49f19c6a3/src/Microsoft.AspNetCore.Mvc.Core/Infrastructure/ModelStateInvalidFilter.cs), which will automatically return a `400 Bad Request` response if validation fails.
I'm a software architect focused on .net technologies across an entire organization and I also lead two teams as my "day job." As others have mentioned, soft skills are just as important as tech skills. You want to learn how to get buy in from developers while also explaining business value to non technical folks. For example, trying to talk marketing into extending a deadline to give the team more time to refactor and improve performance. You also want to practice speaking clearly in a meeting and make sure that you are able to break down complex technical jargon into easy to grok speak. From a tech side, definitely read clean code , clean coder and clean architecture. Look into Domain Driven Design and read a lot of Martin Fowler. Also Read [Continuous Delivery: Reliable Software Releases through Build, Test, and Deployment Automation](https://www.amazon.com/Continuous-Delivery-Deployment-Automation-Addison-Wesley/dp/0321601912) by Jez Humble it's a great book. As an architect, your folks will be on coding practices and ensuring the team follows standards, but also on understanding the business domain. You need to be able to realize when a change doesn't make sense or could potentially impact the system overall. Lastly you want to ensure that the team follows modern devops best practices to ensure that you can release software safely and quickly. For example, our team pushes our .net application to production once a day and we hope to move even faster with multiple builds per day (hence the Jez Humble book). It's also important to set standards and have regular architectural meetings with devs. These are tricky because you can't just issue edicts and expect everyone to follow. I've seen architects try to do this and it always fails. A better approach imo is to use this as a learn opportunity to help devs better themselves while introducing mechanisms to measure success (code reviews etc) Lastly, go to a lot of community events. Meetups, Code Camps (free conferences on a weekend) or professional conferences. By going to these events, you'll not only learn about new technologies. You'll get to meet and network with other technologists many of which are architects. When I have a problem, either personal or technical I have a large number of friends that I met through developer community events that I can call and get advice on. I've gotten great feedback this way.
Excellent points!! Just one more point : try to get into at least one Open-source project and be active ! (Active in the chat/discussion group other than dumping the code) 
Checkout books by Dino Esposito, he is always on the cutting edge of the .NET stack for Enterprise solutions.
I found The Expert Beginner to be an eye opener. https://www.daedtech.com/how-developers-stop-learning-rise-of-the-expert-beginner/
My secret was to outlast everyone until I became default architect. Fail proof!
&gt; I'd expect a senior dev to be mainly 3s, Sorry, random side track. I couldn't help but laugh when I read this, not because *you're* wrong, but because it makes me feel better in expecting more from our senior dev. The senior dev I work with I would classify most of those as a 0 - 1 average with maybe a 2 on some of the things. I've been a professional developer for a few years now (going on 3) and self-taught doing my own thing for about 15 before that. I understand so much more about our project than the senior dev it's not even funny. I'd be more than happy to help him learn more, but unfortunately he also thinks he knows everything and refuses to listen to reason. Good case to why soft skills and tech skills are important. He's not stupid, but he lacks the ability to evaluate himself and admit that he has more to learn. 
ok
One of the problems with answering this question is that the term "architect" means different things to different organizations. In some places it's that person who has been a developer a long time, and he wants that title, so he got it. In others, it means a really good coder that handles those tough problems and knows the design patterns. In others, and in my opinion, it is neither of those. I'm going to mostly write about my thoughts on architecture, and how I view it as a practice, so prepare to be bored. Architecture and development are related, but separate disciplines. As a developer, you own the implementation and maintenance of products that meet functional specifications dictated by the market (ideally). As an architect, you own the codification of standards and practices that satisfy all non-functional requirements, quality attributes, and keeping your company competitive in your market from a technology standpoint. One misconception is that an architect needs to be the best developer ever who knows multiple languages, all the design patterns, and can code circles around anyone else. Really, that is a principle developer and not an architect. Hell, the right person in SysOps can make an awesome architect. So, really, what do you want to do? If you absolutely have the need and drive to code and be in the implementation details, then I encourage you to follow a lot of advice in this thread. Learn languages, get your code cleaner, become pragmatic, strive for efficiency and elegance. Check out Erik Dietrich's writings on programming and ensure that you're not an "expert beginner." I don't always agree with Dietrich, but he makes fair points. One thing I will say, is that you can not say that you are a senior until people look to you as one. If you aren't being asked for advice, or respected in that way, you aren't there. It doesn't matter how highly you rate yourself. Soft skills and mentorship ability are a must. Find yourself a true senior and learn from them. If you want to be an architect, then you are moving more toward a management and business path. Architects, generally, are targeting VP and CTO level. It is cross-discipline, so you need to know a bit about development, business process improvement, management, sales (not just company sales, but selling your ideas), and infrastructure. I encourage you to know your quality attributes (Microsoft has a pretty good write-up in msdn about them), approaches to implementing and validating them, and even take a look at IASA's Five Pillars of Architecture. Frameworks like TOGAF are nice to see how to organize and communicate your ideas in an workable format. Architects should strive to be a transformative influence on the company, and head up initiatives in that regard. It's not always about the code. I wish you the best in your growth. My advice to you is to just evaluate what you want every few years, and adjust your path. Look at yourself critically (are you really a 7/10 and not a principle? Why?), and grow the areas that energize you. Don't flagellate yourself on trying to master your weaknesses, just work to build and influence teams around you that complement your personality (this is another thing that could be another essay, and you will often still hear the sad mantra, "but you need to constantly build up your weaknesses"). Be open to things (I used to think "No way in hell will I be a manager," yet I've found that I enjoy many aspects of it), and take jobs that make you feel at least a little uncomfortable. You may find that your real contribution is is neither of these roles.
I just can't look at the c# code that doesn't use var. Those types all over the place reminds to dark VB days.
&gt; add a layer that receives data changes and broadcasts them. This ties in very nicely with the other poster suggesting an open source caching library. This seems like the best route to take. Thank you very much for the help!
Thank you for the suggestion man! This helps a **TON** - I'm going to work on implementing it today :)
I like this approach since it's so straight forward and simple. I'm going to implement it this way with the help of a caching library. Thank you!
[removed]
Switch to Linux.
We're moving to SQL Always Encrypted using key vault to hold the encryption keys. This way, we can manage secure configs within a DB table that's encrypted and grant access using Azure Active Directory. No more credentials stored in configs. Period.
Yes, so this is the other thing really. This is a massive difference between senior devs where I've worked here and before. There also sometimes is a pride issue - one senior dev in mind who would only ever ask mid-weight devs questions when everybody else was out of the office. Being a senior dev doesn't mean not asking questions or being a higher rank necessarily. Often they'll be the person people go to help for, but equally not all senior devs will know everything the mid level devs they work with know. Important to learn and another reason to factor in soft skills like you say :) 
Depends on what your app is doing, have not heard much on OBA. Might be better off with MVC and a good JScript framework. You can leverage stuff like Azure AD to make security less of a headache.
I'm being completely serious with this. Do you like the taste of butt hole? No? Ok, then learn to like it. Skills don't mean anything at alot of companies. If you serve up the right people, you get to where you want to go. All depends on what your standards are at.
How does one simulate a quantum computer? 
By not looking at it.
Youu
We've crossed into the dangerous territory of mixing dad jokes and quantum computing. I half expect the entire Universe to groan in protest.
Kaspersky is renowned for false positives. It's a shitty virus scanner. That being said, if you can't afford it (and I just looked it up; that's crazy expensive) then live without it. I have never used it and I don't have any problem using C#. p.s. Your VS pro isn't "free" either - I'm sure your work MSDN sub specifically says it's not intended for personal use.
/u/802vermont -- this is Kasey from the .NET and Visual Studio team. Can you elaborate more on what the issue is or file an issue on our repo with details? https://github.com/dotnet/roslyn/issues Thanks!
&gt; That being said, if you can't afford it (and I just looked it up; that's crazy expensive) then live without it. I wouldn't call $129 crazy expensive. &gt; I have never used it and I don't have any problem using C#. If you've never tried it then of course you can't miss it. It's like those old schoolers who reject IDEs because it's all gimmicks and vim does all what they need. 
its expensive when you add up all the other software ive paid for, im in australia too, so its even more than 120 for me
Ack, I was on the "Businesses and Organizations" page where it was like $300 a year. 
ಠ_ಠ i wish i could say you were wrong.
Building a new page? Build it in something other than WebForms. Fuck that noise. No, layout elements on the page should not interfere with postback. Make sure you designer.cs has updated appropriately. Maybe try using an asp control instead of a flat HTML control so that it does. The least you could do is use an ajax callback to populate your second dropdown to prevent a whole-page postback. I hate postbacks.
Have you considered going with the [monthly option](https://www.jetbrains.com/resharper/buy/#edition=personal)? For the base version, it's only $12.90/month for the first year&amp;mdash;which works out to $154.80/yr, so it's a bit more expensive than the yearly option&amp;mdash;but the upside is that you can cancel it if you later decide you aren't using it enough to make it worthwhile. Paying $13/month might seem a little more tenable than the full $130 up front. There are also discounts for uninterrupted years of subscription (20% after 1st year (~$123.84/year), 40% after 2nd year (~$92.88/year), which is still slightly more than the yearly purchase) and, if you stay subscribed for a full year you still get the perpetual fallback license. 
I groaned as I typed it. 
[Linkage](https://docs.microsoft.com/en-us/quantum/quantum-writeaquantumprogram?view=qsharp-preview) to an example of the new Q# language.
&gt; Read Clean Code and The Clean Coder to produce higher quality code and be a better software professional. And then read Agile Principles, Patterns, and Practices in C# by Robert Martin And then buy &amp; watch Bob Martin's Clean Coders videos And then send cash or money order *directly* to Uncle Bob Praise Be to Bob.
The order sounds like something Angular should handle for quick feedback. You could also do some small date checking in it, and do the same on the .NET side. Never trust client-sent data to be completely valid.
Maybe by approximating how qubits would behave based on our understanding of them? I'm only guessing. They said in their ["hello world"](https://www.youtube.com/watch?v=v7b4J2INq9c) example that it takes 16gb to simulate 30 qubits while 40 qubits takes 16tb. So we can only simulate a small number at a time.
https://www.youtube.com/watch?v=Ccoj5lhLmSQ
Schrödinger's Studio
yeha i might just buy it yearly. i do use it a lot outside of work
Here are some things that come to my mind: * Client-side scripting: I don't see JavaScript in your list, but getting familiar with a Grunt/Gulp/WebPack pipeline to build a simple SPA using something like Angular and TypeScript would wet your toes in an entire ecosystem that directly complements the one you've already mentioned. * Deployment and Automation: write a sample app and try to deploy it to a cloud provider on a virtual private server. Or try to deploy it as a container somewhere. Then automate this process from an SCM using a Continuous Integration product like Jenkins or TeamCity. * Mobile: Try making something like a Flappy Bird clone that works on both Android and iOS, using Xamarin or Unity C#, as a way to familiarize yourself with the paradigms of those platforms that are different from the C# web world. * Network: No, the other kind. Seek out local user groups. If you can't find a .NET one - go to a Linux one, or a Docker one, or an Android one. Talk to these people about what they do and how they do it. Not only will you learn new things, but you'll also be visible as an *active* participant in your local development community. (Don't be a "dark matter" developer.) * Cultivate Culture: Don't just read books and try solo side-projects - try to get your coworkers and current employer on board. See if your employer will buy books for a developer book club that can meet during lunch breaks. See if your employer will give you "10%" time in some form (even if it is Friday afternoons or only at the end of big projects) to practice your skills with things like katas or side-projects as either solo or pair/group opportunities. Pair-program with coworkers if you don't already. Get your coworkers to peer review your code if they don't already. Good luck!
It's also worth mentioning that they do offer free licenses to people who work on active open-source projects. Might be worth looking into if that's the kind of stuff you do. 
way too basic of an article imo. 
ive contributed in the past mainly just bug fixes but ages ago. to i have to provide some kind of proof?
there is no way to learn how to architect good code for enterprise standards from books, tutorials or videos. they do help but after ive picked the brain out of every architect who was any good. they all said the same thing. You learn it by doing green field projects and learning on the job. The company i work at now has prob the best architected code ive seen, my lead architect contributes articles and writes blogs. but ud never get the true story unless you could ask him questions which i do often or work on a project, ideally greenfield or something big. theres a lot of people out there who claim to know what they are talking about but are totally off. you learn to know whats a good approach with experience. So to sum it up, read read read, code in your own time, build projects. get into a good organisation where they can coach you and have good projects. its the only way imo. Coding on your own time helps as well, ive been deving for 10 years. .net for 7 or so. when i look at my old code on my personal projects, even from 2 years ago i cringe. the learning never stops. for context im a senior dev, i dont really want to be an architect, but id like to contribute more to design as i progress in my career.
Amen, brother (or sister!)
&gt; I'm sure your work MSDN sub specifically says it's not intended for personal use An MSDN subscription is tied to the person, not to the employee, so he's allowed to use it at home.
It looks like [you have to be a project lead or core committer](http://www.jetbrains.com/buy/opensource/?product=resharper) to qualify... but they do have [other options for free or discounted licenses](http://www.jetbrains.com/resharper/buy/#edition=discounts) that you might qualify for. 
PLEASE DONT put business logic in your database
You could be right, but every place I have ever worked that was a Microsoft partner (and hence had an MSDN subscription, etc.) the software was licensed to the company, not the employees. We certainly weren't allowed to install any partner software at home just because it was available at work.
From [Visual Studio Licensing Whitepaper](https://www.visualstudio.com/wp-content/uploads/2017/11/Visual-Studio-2017-Licensing-Whitepaper-November-2017.pdf): &gt; Where the Software can be Installed and Run The licensed user can install and use the software on any number of devices. The software can be installed and used on your devices at work, at home, at school, and even on devices at a customer’s office or on dedicated hardware hosted by a 3rd party. Most subscriber software can also be run in Microsoft Azure VMs. However, the software is otherwise not licensed for use in production environments. There is even a nice example that says that there is no difference between a device at home and a device at work.
Well there ya go. Thanks!
Does your work pay for Resharper too? As long as you're violating the MSDN license, you might as well use your Resharper license at home too.
&gt; that will have a .NET backend and an AngularJS 1.x frontend If this is a new project you are doing yourself a serious disservice by using an old version of angular and you'll be increasing your technical debt for no reason from day 1. You don't upgrade from AngularJS to modern Angular; you rewrite.
Where would you recommend putting it?
I am definitely trying to go with something that will be quick. That's why I don't really like the idea of having to hit a database to make some kind of decision. BUT I'm trying to avoid having business logic right in the javascript. I know that's the quick and easy way... but is it the right way?
Its the tool, it automatically does it. And it doesn't host inside - technically it just spins up a node app along side it without using noticing and adds Cors automatically to said site.
I'm learning to create asp.net core web apps. I just wanted to know what would be the best way. It's just a practice crud app. I just want to be able to access the files when running the app I'm not sure if there is a better way.
So what I currently do, if the files are just stored on the same computer as the web app, is I add an app settings to the web config with the file path and store them outside of the website directory. E.g. on Windows my website might be in D:\Websites\MySite, so I'd store my files in say D:\Data\MySite. Then I'd add an appSetting with the data path: https://msdn.microsoft.com/en-us/library/610xe886.aspx E.g. &lt;appSettings&gt; &lt;add key="DataDirectory" value="D:\Data\MySite\"/&gt; &lt;/appSettings&gt; Happy days from there. Where to store app data is actually near the top of my list of things to look into alternative options for next. These days I'd rather have everything on Azure with a storage account then it's completely separate but that's a bit of a way off for our organisation at the moment :) 
Can we make a sidebar link item that just has the official Microsoft article on this different content can be posted?
In short, yes. TLDR? Yes
Because MS is like a decade or two late? Funny, I tried to argue this years ago on HN and I got flamed to fucking death for it. You still see it though. The same reason that the FOSS community is weak in the .NET arena is related to the same reason that everyone comes in here and drops every community project the second that Microsoft releases something "official" that has 1/5th the features or stability of the existing community project. IDK, .NET isn't going anywhere. As .NET2 settles, I think this'll change. Or maybe Java really will get it's ... stuff... together and start iterating on the language to close some of the gaps. Because java as a language doesn't feel super hot these days.
You're not the only one. I like C# and I like .NET but it's undeniable that the Java ecosystem is better at the moment. It's not surprising - Java has been open and cross-platform for decades. I hope that as core gains more traction we'll see the .NET ecosystem flourish.
Well, it certainly is hard to compete with hundreds of thousands of on the clock engineering hours poured into projects. It is frustrating, I agree. However, some of the things you're talking about i.e. IdP, API gateway.. those are appliances that speak HTTP. What does the platform they run on have to do with the platform choice for implementing your application? Right now I'm using Azure Api Management pretty heavily but if I wanted to spin up a VM and run ApiMan from a docker container instead, my only concern is feature parity not whether I should have written my back end in Java. 
cna u ur liscence on two different machines?
I agree that JVM ecosystem is richer than .net one in terms of languages as well in terms of any middleware that you may need (e.g you need latest Kafka driver that does x y z etc.) and probably worth evaluating if you want to do .net or jvm eco system for your next project. However, the use cases that you have mentioned above are more for a middleware (service mediation). IMHO This middleware should be transparent to your back end services and often in larger organisations should play nicely with the backend written in some other tech (e.g. go, .net or whatever). I would be very nervous if a choice of one middleware would drive you to go wall to wall along another choice (app server or software stack or eco system). So perhaps you may want to choose your eco system (say jvm) and then choose middleware that is independent of your eco system as much as possible. Similarly you probably you want middleware as decoupled as possible from your software stack (so down the line when you want to migrate or scale your software assets you want to do this independent of middleware replacement at the same time) HTH 
&gt; That hasn't happened because nobody was bothered enough. Err, what do you mean? As everyone else suggested in here, this is a standard feature and has been available forever. And it works great.
What is the cold start time on Azure Functions? I messed with lambda with .net and it was several seconds, so it was unusable for the API I had in mind
I simply mean, nobody in the .net Core ecosystem, with enough pull and/or will, did not bother to do it. Of course it's the standard way of running programs, I didn't mean to imply otherwise. .NET Core or Java way isn't.
See if this helps - https://www.hanselman.com/blog/Stateless30AStateMachineLibraryForNETCore.aspx
Is Always Encrypted available in SQL Server 2016?
I don't think I understand what you're saying. What you described here: &gt; someone needs to add the code, to the compiler, to produce an actual exe on various platforms. Someone needs to add bootstrapping the CLR from that exe is already a standard feature in the .NET Core SDK since forever, and it works well. Perhaps I'm mis-reading your posts, though?
Eh... You can create a huge "all in" executable, which OP doesn't want. We're talking a small executable using .net Core libraries on the host. Yes? 
Exactly...Currently I am heavily using WSO2 as my middleware with service written in Java, python, perl and .Net. I personally am a .Net developer and a python learner but there is no reason to believe the WSO2 work better with 1 language backend server and not with other.
Yup, it works with non-Azure SQL. Though I haven't researched how keys are secured. https://docs.microsoft.com/en-us/sql/relational-databases/security/encryption/always-encrypted-database-engine
You're not putting business logic in your front-end, right? Just client-side validation. Which is very standard. Then do all the real validation on the .NET side
I guess the "nobody bothered to do it" part of your statement is referring specifically to minimizing the size of a standalone application. I don't think anybody has linked it here, but there is some tech for that, although I don't know how well it currently works: https://github.com/dotnet/core/issues/915. It's supposed to trim down the set of published files to what is truly needed.
I've been a one-man ISV for the last 10+ years. I used to periodically check the web for cracked versions of my software, and every single one contained some kind of malware.
Dang, I really need to get up to speed on... most of that stuff. I've been developing for like 5 years, and there's evidence that I'm smart guy, but I don't know nearly enough about programming. How do you guys learn all that stuff?
Free, but not open source. Be vary of spending too much time and getting too dependent on a tool that may increase in pricing at some point.
Thanks I'll do that :)
Thanks for the reply. We are using SAP web services and hoping for something more integrated with SAP but also cross platform that we can deploy via the cloud. The Duet partnership looked like a possibility as well but we also don't want to get locked into sharepoint simply because not all of our current user base have it but they do have Office. 
I do microservices but i don’t subscribe to the api gateway. That is a single point of failure waiting to happen. And throttling via software cose will never be as good as WAF.
If they communicate with a common protocol (e.g. http) why does it matter what language they are written in?
In fairness, I'm not actually a senior dev (though I have just applied for a senior role). Some of this I learnt on my comp sci degree. Some of it is outdated now (I haven't had to touch SVN in years). A lot of it I just try out on my local computer. Some of it out team isn't in a position to do yet but I would love us to do. Test-driven development and unit testing for example I've read and watched videos on and I've done some really small test projects on my computer. Our team has just got up to speed with git, git flow, automated builds, code reviews / pull requests, deployments happening from a remote build server, and a bunch of other things. Unit testing is one of the senior devs' next things, but they've got to find time to try it themselves, then agree some standards on it, then run a workshop for the team on it. Once we're up to speed with unit testing we can look at TDD. I'm a scout leader and a firm believer in 'learn by doing'. Make test projects to try things out. Read up. Watch videos. Take the free Azure/AWS credits, use the free API calls, etc. If you're an employer - allow your devs time to just play and try stuff. 
Yeah, I am not trying to get hung up on the technicalities of exactly how it is done. I am simply trying to understand what the advantage is for them wanting to use host an Angular inside an ASP.NET app as opposed to not. Is it as you state because of the tooling? That .NET developers see the template and think "oh this must be the easiest way to get it done"? Or is there another reason? I am not trying to say what is right or wrong. I am trying to understand the reason.
It is trivial to simulate. It's hard (in the mathematical sense) to simulate quickly and in low amounts of memory.
I think it has also to do with vendors that tend to push wall to wall stack. Unfortunately some of the FOSS products are becoming very enterprise flavoured, in mainly how vendors support it, etc. However there are new products on the block like NetflixOSS, isito, etc.
I've been programming professionally for nearly 20 years and fall short on a few of them. Reading that list I don't think it's possible to be level 3 in everything, at least not consistently.
See this https://github.com/Marusyk/Simple.HttpPatch/issues/5
C# is anything but dying. A lot of the enterprise companies I deal with are looking to .NET/.NET Core as a replacement for their JAVA stacks... Now if you want to talk about a language that is dying...
Extraordinary that this pretty uncontroversial comment has been downvoted, which illustrates the close mindedness of some in the .NET 'community'.
Java doesn't need to be super hot really, it's the JVM that's more important. A big win of the JVM is you can use its rich set of libraries while coding in Scala, Clojure, Ruby, Kotlin etc.
1.) Good enough, but compared to someone who makes a living utilizing JavaScript? Eh... 2.) C# isn't dying. Not even close. But, make no mistake: if you're jumping into this field in a position not related to .NET, you're most likely going to be pushed and pulled to different ecosystems. That doesn't make C# or .NET bad. A lot of young companies or inexperienced companies prefer the latest and... "greatest". 3.) Yes. 4.) Yes. 5.) Unpopular opinion: If you are writing .NET Core apps, I would suggest staying away from Visual Studio in the beginning and stick to something lightweight like Visual Studio Code.
1) I am bad at Javascript, but if something need to be done in NodeJS absolutely, I can do it. (With productivity divided by 10) 2) Not dying. Backend in pure NodeJS for any large application is a joke, will cost fortune to maintain. React Native is great though, I don't know if Xamarin will catch up. 3) Yes. 4) Yes, production ready. 5) Visual studio Code is a lightweight IDE, I use it also for NodeJS/PHP/Python coding. For C# I prefer my good old Visual Studio though.
* Decent but I am no webpack ninja * C# is getting better by the day. The language is getting new features every year. * ASP.NET Core is super fast * Yes * Visual Studio
The platforms matter simply because they don't run themselves, and small teams likely have to develop the expertise to administer them if it's not part of their existing stack. You can spin up a docker container running ApiMan in two seconds - the problems come when you need to start digging in and customizing or production-readying (or worse, troubleshooting). Every app server/OS/framework/whatever that you add to your environment is another possible point of trouble that better be worth the effort of supporting in production. Cloud is really the solution, but isn't an option for us quite yet (and Azure's API Mgmt is ~$700/mo. for a production-level plan).
I should have been more clear - I mean this is a frustration only from the standpoint of the developer trying to manage across multiple stacks. Yes, my app can be written in anything, my API gateway doesn't give a damn - but my small team and I are responsible for supporting both, so having one be a completely different stack from the other means an additional layer of complexity that isn't always necessary. Really, the only reason this is a discussion is because the app CAN be written in any language without any other component of the system being any the wiser of it.
WSO2 (and any other infrastructure-type app) doesn't care about who it talks to, you're absolutely correct, and I don't mean to imply that I think my apps will work better if they're all in Java rather than C#. Rather, I mean that for a small team, the more heterogeneous the environment, the greater the support and administration burden that needs to be dealt with. And therein lies the problem - if I already know I have to support e.g. ApiMan and KeyCloak (and thus WildFly and CentOS), does having much of the rest of my infrastructure running on a very similar stack reduce complexity (and thus headaches and stress) for my team?
Doesn't matter to the applications - does matter to the app developers and administrators.
That's just it - the JVM is trending in the direction of being the de facto runtime behind infrastructure software. It's not that .NET is incapable of doing that, it's just that the JVM had a huge head start and now, when you start overloading some part of your infrastructure that's currently Python/Ruby/whatever, you optimize to something on the JVM.
.NET certainly isn't going anywhere... there are 3 trillion SMBs out there that have ASP.NET apps or Winforms apps that underlie some core part of their business. The problem occurs when those SMBs look to break out to the 'cloud', to start working like their larger competitors who offer suppliers APIs and whatnot - it's an entirely different world and .NET doesn't necessarily have the same place in it as it does in the SMB world.
Fair point. But I think it comes back to the classic use the best language for the job. If hosting apps from multiple languages is going to be a problem then there's no reason to.
Basically you'll have to access the RoleManager service to add roles to the role table. Then, when you create a user you can use a method on the UserManager instance called AddToRoleAsync. This links the user id and the role id in a separate table.
Sounds like being coursed for having multiple choices :-). You may also find that if you make a provision in your architecture for components but defer the choice of the specific component your stack may simplify itself by the time you revisit your unmapped components - you may also find that some components are not needed for your implementation... At any rate please share what you have come up - it would be an awesome reference architecture for .net that is maybe not so readily available - I would imagine that there is some reference architecture for jvm eco system on WSO web site.
What I ended up doing was putting my roles in my database seeder and checking to see if the roles already exist, then add them if not: foreach (var role in RoleTypes.RolesList) { if (!await _roleManager.RoleExistsAsync(role)) { await _roleManager.CreateAsync(new IdentityRole { Name = role }); } } In this example, `RoleTypes.RolesList` is just a static property with a getter, but you can implement it in a number of different ways: public static class RoleTypes { public static List&lt;string&gt; RolesList { get { return new List&lt;string&gt; { "Regular", "Manager", "Administrator" }; } } } In my `startup.cs` under `ConfigureServices()`, I add a new service for authorization: services.AddAuthorization(options =&gt; { foreach (var role in RoleTypes.RolesList) { options.AddPolicy(role, policy =&gt; policy.RequireRole(role)); } }); Then, I can adorn my controller classes with an attribute that checks to see if the logged-in user is able to access any methods from within the controller: [Authorize(Policy = "Administrator")] public class AdminController : Controller { ... } You can then also limit what the user can see by adding some razor code to your view (assuming you're using razor views): @if (User.IsInRole("Administrator")) { &lt;button&gt;Create&lt;/button&gt; }
Not open source because I don't have the time to also maintain an open source project. No plans to make Codetrack payed, it's just a hobby project. On top: you can download now, keep it and use it forever. But of course you're free to not use it if you don't want too ;-)
No, I am referring the way old .NET apps are built. Shared libraries exist since the dawn of time :-). And no, they are not shared if each app has its own copy. 😀 As I said else-thread, there is a very good performance reason why old .NET dlls are NGEN-d when installed.
Yes, but not at the same time. Switching between home / work works fine.
I wrote a really simple solution that's super easy to follow here ... https://github.com/matthewblott/simple_aspnet_auth Here's the brief tutorial I wrote for it ... https://coderscoffeehouse.com/tech/2017/09/05/simple-aspnet-auth.html
The scaffold command does not generate views, just the models/classes it reads from the EF tables. AFAIK, you have to create the controllers/views on your own. Also, as a fellow .NET dude working on Mac, I'd suggest looking into Rider as your IDE instead of Mac VS, plus you can get it for free if you're a student.
So I've been trying to scaffold the views and controllers based on my models, but VSMac and VSCode doesn't have built in tools, and the aspen-codegenerator tool isn't working for me either... Frustrating. Thanks for the suggestion on Rider, I'll check it out!
for an admin account I might not make a UI to manage it depending on how much backoffice I will need to do. Generally I would just create an Admin role. Create a use either manually in the DB or through the registration process that should be in you example template then just add that user to the admin role. Put an auth attribute requiring that admin role on anything you want to secure for admin only. As far as the UI you may have to have some minor checks in your page templates to show additional menu items. In general I just associate a user model for an IsAdmin property or use an extension method on the current user principal. Then you can have template code that just checks IsAdmin and renders/does not render depending on your rules. 
Okay, I understand what you are saying now. You're right -- that isn't possible.
I’d also like to hear about experiences with SteelToe. 
So grab a Java project and port it. It's not hard and we've done it countless times before.
Even better, find a need that isn't met by .NET and fill it. Don't just port Java libs, write something better. We've got the tools to do it, after all.
While I certainly wouldn't tell someone to not do that, the advantage of porting a Java project is that you can inherit their documentation and test cases.
Hmm, Java might be out of favour (though it's still huge and will be with us for years) but the JVM is still king in the server world. Companies would be more likely to adopt one of the other JVM languages than move to .NET.
If your dev team is more .Net savvy than Java, then why would it even be a consideration to use Java instead of a .Net language like C# or VB? 
I'm interested in rules engines too, and would be keen to hear from anyone with practical experience. A bit concerning that NRules [disappeared for 8 months](https://stackoverflow.com/questions/38305050/where-is-nrules-documentation-gone) before the author resurrected it. Drools seems like the clear leader but I'm not sure how hard it would be to use with .NET.
I used to use Drools extensively when I was at a purely Java shop. It straight up sucked and did NOT work as advertised. It worked just enough for you to get going, but there whole game was to get you just invested enough so that they you'd feel the urge to hire "consulting" in which case they come in with a version/fixes that made it actually work as advertised. At least that was my suspicion. This was nigh on 10 years ago, so it may be completely different now. And yeah.the whole it's only for Java is a deal breaker for me. 
For the reasons I mentioned - there is so much more available software in the Java ecosystem that can be leveraged to build a 'modern' architecture than there is in .NET's world. If I leverage that, my dev team has more time to spend on our core applications rather than having to build some of those pieces ourselves (or dealing with a more-complex heterogeneous environment). And the 'bus factor' would lead me to want to make sure I wasn't the only one who could do more than restart the app when necessary. And I don't mean to minimize the effort, but to me, going from C# to Java (as a dev) is more about the toolset than the language. And if I have a young dev team (like I do), they're not so invested in their tools that swapping out VS for Netbeans or teaching them how to deal with Maven/Gradle rather than .NET's NuGet stuff is prohibitively painful. 
I'm not talking about a CSV parsing library, I'm talking about stuff like Eureka and Hystrix or whatever. You really think those are 'not hard' to port? And once you've done it, you now are going to have to keep porting over changesets. Some projects like Akka.net may be able to successfully pull that off, but ask any of them how easy it is to do it.
Hey so another question. I got the aspnet-codegenerator to scaffold my views and controllers based on the models and db, but now I'm getting a InvalidOperationException: Unable to resolve service for type '&lt;ContextName&gt;' while attempting to activate '&lt;ControllerName&gt;' Ever seen that before? I'm guessing it has to do with an issue in the controller but can't place it 
I recall if you make a MVC web app not core, it creates the CRUD for you. But since your on mac and not using full Visual Studio you probably have to write it hand. Honestly, if you're trying to learn this doing it manually will probably benefit you anyways.
Have you looked at the client code for Eureka? Once you drop the many, many unnecessary interfaces there is only a few dozen classes. And really, once you start adding in C#-specific idioms such as async/await or events instead of observer interfaces, those future changesets won't be interesting.
&gt; if Java has a dozen FOSS apps/solutions that already handle those concerns, and huge parts of my software architecture are going to be Java anyway, then why wouldn't I just suck it up and start build around Java right now? SQL Server is written in C++. Does that mean we should ditch C# and Java for C++? The whole point of .NET is that you can use whatever damn language you want. Hell, plug in IKVM and you can directly use Java classes in your C# code.
I've used Windows Workflow, but I found the hard part about this sort of problem is actually the editor for non-technicals. Just an idea, but the last time I did this I had rules that had to execute on top of a KNOWN structure, and would always output a known output structure, and had no side effects or external dependencies. Essentially: Each rule was a PURE function, and I needed people to write these pure functions. For the interface, I used Blockly, a project that was built to introduce people to programming with a drag and drop sort of interface. It's good enough to put together MOST pure logic things I needed at the time... and it will output a Javascript script. Every rule would start with a custom function wrapper that took a known input, and put out a new output, and everyone just needed to define the rules that modified the output structure in between. Then I just stored these functions, and when I needed to execute them I'd get together the "known input" structure I needed, and then executed the Javascript right in .NET using one of the libraries that enable that (They basically take a string of the JS to execute, and usually a list of params to input). I wasn't sure about it at first (executing JS INSIDE of .NET... ewww...) but damned if it didn't work so nicely that I got over it.
Hmm..that's pretty cool. So are you able to inject your objects into blockly..say a business object with 50 properties so they could "Blockly" it? It seems like there would a robust rule editor for .NET out there.
1. The language I'd be comparable on, even though I don't like it. Tooling and frameworks change every week though, and any dedicated JS dev will be more up to date on that stuff. 2. Let the hipsters worry about what's popular. I get paid better, and there are more jobs for .NET or Java, and they are not going anywhere. I'm a backend guy though, and the competition for UI dev mindset is completely different. My take is that of the "develop once" frameworks the Electron / React Native stuff seems to be the best, with it's own nuances... but of course nothing ever beats native UIs if a company has the people to dedicate to it. 3. They are comparable. Node's big claim early on was about scaling because of its "async first" nature. That's cross pollinated to .NET and most of the frameworks are all async there too now. And that's been both directions, since the new async/await stuff in ES is heavily influenced by .NET's implementation. Promises and such all sucked, and that should get significantly easier once the new async/await stuff is full standard on the JS side. 4. Yes, as long as all your dependencies are ported. Production ready depends on your stack needs. Core is alright, but there's still a lot missing, and tooling is still significantly behind... but it's comparable to at least how bad node's tooling is. 5. Absolutely. VS Code is great, but it still has a ways to go to be a replacement for VS.
Yeah, thats basically what I did. .NET built up the object in code like normal, and then just handed it as input to the Javascript engine, which JSON serilialzed it, assigned it to a variable as input on the function. Windows Workflow was sort of the defacto rules engine thing for many years, but its pretty stuck in WebForms and such if I remember right for editing, and worked sort of like building a LINQ chain for your "rule" where you defined each function along the way... which didn't work for non-technicals really. Like I said, the big question was how do you make it into something that a user can work with, and the blockly sort of approach actually was a good fit. There's also things like "node-red" out there too, that you could pretty much build a "rules service" out of. It'd work like an appliance application that would expose an endpoint to take your inputs, pass everything through whatever advanced rules you wanted, and returns some standardized result. This would actually be significantly more capable than the blockly approach (making external service calls, etc. could all be done easily this way), and obviously would take a lot more effort in terms of infrastructure setup, etc. Hell, I run my entire home automation system off node-red, and I use it as a mocking tool for service dependencies sometimes. 
Looking around Awesome.NET (https://github.com/quozd/awesome-dotnet) and saw Peasy.NET (https://github.com/peasy/Peasy.NET). Might be worth some investigation.
I believe the startup time mainly depends on whether you are using the consumption plan or the always on plan as consumption based functions will effectively "go to sleep" after a while of not being used. What I can say is that AWS Lambda leverages .NET Core for their functions whilst Azure uses [C# Script Files](https://stackoverflow.com/questions/25405941/what-are-csx-c-sharp-files-for) which use .NET Framework and can only be ran on core with the usage of a 3rd party tool/library.
It is possible, but only if your goal is to check items off that specific list. Like, I don't know what red/black trees are really because performance isn't a huge concern for software with at most two concurrent users. If I needed them in my job, I could quickly Google them.
Why do so many people think Javascript is gonna displace everything? &gt; Can the latest Asp.Net keep up or be as fast as Node for heavy usage ? some programmers told me about single thread issues and that Twitter had to switch tech at one point cause they were scaling too fast IIRC, Twitter went from Ruby to JVM based languages. Probably because Ruby suffers from the same issue that Python suffers from (to be specific the reference implementations of both before someone points it out), that problem being a global interpreter lock. Turns out V8 has one too. Javascript tries to get around it by being callback based by default (make no mistake, Promises are a pretty face on callbacks and async is just a pretty face on Promises). So you won't get around CPU heavy usage by using node instead and you'll probably just make things worse if you do. 
There's pretty much nothing viable except for K2 but expect to spend tens of hundreds of thousands. 
What about sharepoint? It gets a lot of bad rep as for the most part it’s used inappropriately. Defining rules for workflows, including good long running workflow support, is something it excels at. The visual designer is relatively user friendly. Racking the state of instances of the workflow as a user is straight forward too. 
Then go to the Java sub? Why post this here? 
 // I'm using id ?? 0 to convert int into a nullable int. you've already tested for null. just use id.Value there's no reason to use the null coalescing operator.
1) I get the angular work done when im tasked with it at work but im not as good as the FE devs here, but imo just get good at typescript and you can deal away with a lot of the headaches of JS. 2) not dieing, asp.net core is saving .net, if microsoft didnt do this then yeah id say it would be dead to jvm and node running in docker containers on more light weight linux OS. 3) yes and more, it's multi threaded while node js is not, technically only when doing IO bound stuff. but with asp.net core you can spin up threads to do cpu bound work and take advantage of multiple cores to do intensive cpu work e.g. Parallel.ForEach 4) yes but still lacks some features 5) i prefer visual studio, even with javascript / typescript. its a pain to setup. but eh im stuck in my ways. i wouldnt argue against someone that coding front end stuff with visual studio code is better, they are probably right. adding files alone is a pain in the ass in visual studio, in vscode it just picks them up from the directory. the annoying thing about vs code is having to use the command line all the time. 
We just built it ourselves. As we eventually realised it has to exist as JS too for the results to be effected in real-time
You can set the culture globalisation property in your web config: https://msdn.microsoft.com/en-us/library/vstudio/hy4kkhe0(v=vs.100).aspx Or with DataTables you can manually set the formatting: https://editor.datatables.net/examples/dates/formatting.html I also, being in the UK with daylight savings times, manually set the time zone environment variable in app services: https://blogs.msdn.microsoft.com/tomholl/2015/04/06/changing-the-server-time-zone-on-azure-web-apps/. It might not affect you buy did me when the clocks sprung forwards! 
This only works if you only ever use a single implementation of `IHelperWorker` at a time. It's probably fine for unit tests when there's a binary choice between the real thing and a mock, but imagine you want to do some kind of online migration from one data store to another and need your services to access two different `IHelperWorker`s at the same time. A real DI solution would allow you to create multiple identical services that use different dependencies.
My palms sweat every time a potential customer ask for "customizable workflows". Is it actually achievable at reasonable cost?
Yup
Xamarin forms is ready in my opinion. I just finished an iPhone/Android app using it. There are a few gaps in the framework that are easily filled by the community with nuget packages. 
Rich UI or not ? Rich UI: better to go for Xamarin.Android &amp; Xamarin.iOS Normal UI: Xamarin forms
I was just thinking some standard organisation App. So normal UI. UI should just be easy :D I am a backend guy :P
I develop with XF since 1,5 years and I find it still buggy and not ripe yet. every new release there seem to be a new major problem. speaking from developing with Visual Studio
Sad to hear that. But what I expected :/
So I started thinking "Oh wow haven't seen the old .NET logo for a long time" and after looking at the article I came away thinking: "What the actual fuck is this trash?" * Talks about .NET Standard 2.0 but uses the old .NET Framework 2.0 logo just to fuck with people and despite mentioning the .NET Framework, there was no explanation that .NET Standard 2.0 and .NET Framework 2.0 are totally different and this further confuses people I've already seen getting confused on this topic. * Keeps incessantly calling "dotNET" and also "DotNET" in the link and page title. I mean, if you're going to do a bad job of reporting at least make your inconsistencies line up. It's ".NET" not any of those other names. * "The prime issue faced by dotNET core was the missing third-party libraries. Just for instance, at time of 1.0 release, known logging libraries like log4net were missing. Using dotNET core will not only help you to focus on full dotNET framework but even help you to solve all these issues." What the fuck does this even mean? The first sentence makes some sense but the rest sounds like they just let autocomplete write the rest. Using .NET Core will let you focus on .NET Framework? No, you mean .NET Standard, the subject of the article? * "Well it is guaranteed that you are eager to hear about this..! The Visual BASIC (Beginner's All-purpose Symbolic Instruction Code) is now supporting dotNET core! If considering the present scenario it will not allow you to develop any class libraries and console application." Well, I suppose all 5 people might be glad VB is on .NET, but at least the author is spelling the acronym out in case, you know, you've literally never heard of BASIC... Basically, this is a complete non-article devoid of content, quality, and English.
I have developed a handful of production mobile apps with Xamarin Forms targeting iOS and Android and have been super pleased with XF. in those apps I put almost not platform specific code in. The only platform specific code I had to write was for things like getting thumbnail for video file that was in the device's video gallery.
But why is it completely fucked up with typos and, formatting errors and wrong numerisch? At least get someone to Proof-read your post 
Xamarin Forms is good now. It's owned by Microsoft now and even included with VS2017 so no need to install it seperately. Xamarin Live player also makes debugging IOS much easier.
Looks like something a bot wrote.
As long as you hold off on updating your tools for a week or two each time they push an update it's not that big a deal. Give time for the dust to settle.
Xamarin Forms rocks. Try it.
Could you please list some of these problems? We use XF since a while and are actually quite impressed by how well it works. (I did some WPF applications years ago - and had way more problems with that than I have with XF now)
I use Xamarin (but not Forms) in my day job and I'm very unsatisfied with it. Visual Studio for Mac is an extremely slow and buggy IDE and of course lags behind in features massively compared to Android Studio and Xcode, which are both fine tools. It's also gotten worse over the years (I first started using Xamarin for iOS and Android development in 2013) rather than better. You can of course develop in Visual Studio (the real one, for Windows) too but you'll still suffer the same build tooling and deployment experience. I love the .NET platform and C# and used to be a big fan of the idea of writing everything in C# and saving some time on the business logic because you don't have to implement it twice. But you lose *so much* right now from having to develop in VS for Mac rather than in Android Studio or Xcode that I literally think you'll be saving time and your sanity by not using Xamarin.
About six months ago I tried to make a few xamarin apps for my phone. I spent about two weeks but I couldn't get any of their official samples to work. They would compile and run, but didn't actually work, e.g. camera app doesn't display, no picture saved, throws exceptions. Then I tried react native and had a working camera app in less than 5 minutes. It's at that point I gave up on xamarin forever. If I'm going to make an android app, i'll learn java, or use something like react native or some future .net core, but not xamarin, never again. 
This is complete gibberish. Makes no sense.
for example with the latest XF version + latest VS version we are unable to deploy to iOS (simulator and device) for some the simulator turns black after deployment of the app (iOS) the above are the 2 latest problems. then we had an signing problem on android once, where it just couldnt deploy on android devices with our custom keystore (needed also a workaround for that...) the endless building bug... i could go on and on but the most annoying thing is the building time (we once had arround 3 minutes for an android app!!) 
Xamarin Forms is 90% awesomeness and 10% total bullshit. You can already make amazing cross-platform apps but the experience is still far from perfect. It's still worth it though, considering how much time you can save.
If you have to always support the newest OS versions with the new features that is not that easy to do
Xamarin.Forms with Prism is a joy to work with
Don’t you still have to have an apple for the iOS debug target or have they fixed hat as well?
In which file would you put foreach (var role in RoleTypes.RolesList) { if (!await _roleManager.RoleExistsAsync(role)) { await _roleManager.CreateAsync(new IdentityRole { Name = role }); } } How do you, with your code, set the roles for certain types of accounts? I don't understand where you place a role for a certain type of account.
You probably need it for publish and deploying to the app store of course, but supposedly the new feature allows you to and view Xam Forms apps as you develop them directly from an IOS device.
it's literally a week or two in case there are any major bugs. Feel free to update immediately if you favour shiny newness over stability. You're not going to be using the latest OS features on release day unless you were using the alpha/beta dev tools anyway.
You still need to have a Mac for builds. That can’t be changed. Also, unless you have VS Enterprise you have to do your debugging in the simulator on the Mac. VS controls it and breakpoints and whatnot are set via Windows VS but interacting with the simulator is done on the Mac
Some of this is fair, some is more a criticism of Vs for Mac which is also fair, but not a commentary on Xamarin. To be clear VS for Mac is garbage imo. Every time I use it for Xamarin dev I immediately miss VS on windows. For instance, the complaints about the debugger are more about VS on the Mac. I use Xamarin for both Forms and native development on Windows and while it has its problems, it’s not quite this bad. 
Some of it is the IDE, some of it is the build tooling. All are developed by Xamarin and it speaks volumes about the quality level they put out.
Out of curiosity, what did you find was the most efficient way to manage the data access (if you needed a data store)? Mono still doesn't support SSL connections to SQL databases so EF is out of the picture.
No doubt it has issues too. The Xamarin equivalent of “turning it on and off again” is typically to clean bin and obj folders and restart and is used WAY too frequently. That said I have much fewer problems working on Windows and once it’s working, it can even be pleasurable. 
I had pretty simple needs for data storage. I know there is a x-platform SQLite implementation but I found it unreliable(I believe there was a fork at one point and a bit of churnin the community) but I’ve been using PCLStorage as a Key/Value store and its a breeze. 
I had pretty simple needs for data access. I wound up using PCLStorage as a KeyValue store and it’s been a breeze. There is a popular x-platform SQLite implementation that I tried but found it to be unreliable. (I think there was a fork to the project and seemed like a bit of churn as to which version was to be used)
Is anyone else concerned about having to re-write their XF apps due to Xaml Standard? I love the idea behind Xaml Standard but from the few examples they've put out it seems that the idea is to make XF eventually adopt UWP Xaml standards which could mean having to re-write your views everytime Xaml Standard gets released. Or am I seeing this all wrong?
Xamarin has been stellar for our company. We had an aging iOS app with a desire to have an Android app and not much time to support or develop either. That meant a few things: we didn't want the thrashing of a js build chain (React native or web-view alternatives) and we wanted some depth of support that we could look to when we were stuck. Xamarin served these purposes and then some. We have a massive library that sits between the two platforms. Basically each platform, still in C#, calls to the library to boot the application. We have access to all native features and can expose them using some lovely Dependency injection features. Xamarin Forms gets your UI about 70-80% there and you can down-and-dirty as needed. XAML is great if you fully embrace it; we had made the mistake of writing a lot of manual C# without data bindings that led to some awkward and embarrassing bugs. Throughout the process I think we felt a few pains that are totally manageable and that we're improving on now. This is more of a pain than something you fix, but when you need to get into closer-to-native code to work on a feature it's hard to grok all of the things needed to get what you want simply because Android and iOS are very different. Android requires lots of context and strange incantations whereas iOS tends to be a bit more straightforward, from this perspective. It's just an added layer of complexity to have a deep library of your own that uses Xamarin/Forms and still have to consider the base capabilities of each platform. The other main problem was just that we went about building a pretty structured app that we clearly learned a lot from as we went. We had some little memory issues, network issues, page management, and data binding issues that are all being resolved. We ended up rethinking how we structure the application, while also getting better at using Data bindings and Page/View models. These are manageable problems and I can safely say that we have an operating app on both app stores and can release them in lock-step. Despite some of our issues, which are more our fault than Xamarin's, the app feels quite snappy to me and improving every day. It feels like we got all the benefits of a native application, a little complexity here and there, but one single codebase to support and release. Also, C# is delightful. I would recommend using it to people who want to have a single codebase for multiple platforms. I will probably use it on my own projects regardless of class-platform at this point, simply because I prefer it now. 
How is the Android startup time nowadays?
It was awful for some time, but I found out I also had a silly Emulator configuration. I have something like [this one](https://forums.xamarin.com/discussion/comment/288013/#Comment_288013) and it helped quite a bit. 
How is the Android startup time nowadays?
Cripes, that sucks. I've experienced none of these issues and we tend to track latest version on everything. When I've experienced issues at that level it's one of: mobile platform, packages, our own poor app-boot choices. We've definitely experienced bumps as they've been releasing pretty big underlying changes, but nothing like that in some time. What versions of VS, Xamarin, etc. are you using - if you don't mind me asking?
Are you implying directly connecting to a remote database as the generalized app storage system? That would be risky on a number of levels I would think, but I guess it hadn't crossed my mind until you said it. Yea that seems highly irregular unless I'm missing what you were asking. Anyways, not affiliated with /u/smithygreg, but if you're interested, you could take a gander at [Realm](https://realm.io/) we've been eyeing that up for some time to buff up our app's offline access. Eventually, we might consider using its ability to sync up to a real server. For now we just use a pretty basic REST API that we access using [Refit](https://github.com/paulcbetts/refit) then use the data in memory - it's GC'd as pages are GC'd so we end up re-requesting certain data periodically but it hasn't proved too problematic yet.
I don’t have much of a frame of reference to other mobile tools. It’s definitely slower than starting a Windows app. But once it loads on the emulator or phone once, It seems like it pops up quick enough. You do notice how spoiled we are as .net devs working in visual studio building windows apps and how fast that is. 
Ah yes, that was pretty slow to get to device, but works fine once it's there personally. It seems to have improved over recent months for me but that could just be perception
&gt; But how do I handle them in the server side, if those elements are generated in the client side? They can have the same name and be posted as an array in the server-side while not having an ID on the client side. If you do NEED an ID for those elements, typically, I'd just append a number to the name for the group of elements, txtChild1, txtChild2, etc.
I can't speak towards the cross-platform part of it (I don't have a Mac or any iOS devices I could even test anything on), but I did use Xamarin to create a fairly simple Android app. I ultimately stopped supporting it because the purpose I created it for was essentially made redundant (previewing YouTube and other video links while browsing reddit through the *reddit is fun* app without having to actually open the YouTube app), but if you want to see it, I can link you to the repo. The main part of the project is the Android-specific part, which has the UI and handles making the actual requests. The second part is a portable library that really just handles the conversion of the JSON payload (using `Newtonsoft.Json`) and loading it into the data model. I created the initial repository on Mar 13, 2017 and had a working beta on Apr 21, 2017. Considering I only worked on the app as a side project and had little experience with Xamarin/Android development going into it, I think it went pretty well. My biggest issues were really with getting the layout to look nice on different screen sizes and different screen orientations... but I think that is likely more of an issue of understanding Android's different layout quirks than anything. Other than that, though, I felt like the integration with Visual Studio was nice. My biggest complaint would probably be that (at least at that time) the Intellisense integration with the XAML designer was kind of lacking. 
This would work. Also, if you have a model with your owner and color on it you can get the model binder to give you a list of your model by making the name of your owner textbook [0].Owner and your color textbook [0].Color and then just increment the index if you add more rows
Why link to an image instead of the actual software??
Are you using angular or some other UI framwork to add your rows client side? Its ok to have multiple inputs with the same id, but its better to have a row number as part of your id. https://msdn.microsoft.com/en-us/library/4ba5htte(v=vs.80).aspx 
IDs should be unique according to the HTML spec.
My company uses Xamarin for all of our apps. We target millions of users. We are happy. We share &gt;70% between the ios and android version. To achieve that we created our own infrastructure library... We would be happy if microsoft would pour more resscources into xamarin and stopped focusing only on xamarin forms, but other than that it works for us.
We just had a developer do an app in Xamarin. He ran into two previously undiscovered bugs that took a week or so for Microsoft to acknowledge which was frustrating (but one they knowledged it, it was fixed within a day). His biggest complaint though was that he mostly just ended up programming two apps because of the gaps in framework.
I haven't used mvvm light so I can't compare the two libraries but it brings support for MVVM, DI, navigation, etc
I'll respond to your questions with another question - do JS 'developers' really consider themselves developers?
Since when has it been acceptable to have multiple elements with the same ID??
You could create a static class in every lib with a static method that accepts IServiceCollection param and put your registrations there. At least that way every lib has it's own DI. As for using a controller as a model or service is a no no. Move your logic to a service and put your validation in the service. The controller is a thin wrapper and shouldn't do much. FluentValidation is better than the default component model validation. It seems that this is a personal project and you don't care about best practices...? 
tell the op ;)
tell the op ;)
No it's not OK to have multiple textboxes with same ID, IDs should be unique within the document.
Nice. Like it (Q#) much better than IBM's graphical "Quantum Composer".
hey pls PM me if you have some tips how to improve the ios deployment performance i would be really greatful. and how you use behaviors to archive such specific UI needs. I am very grateful to learn something new about xamarin!!
What do you think about having shared business logic in a single project? I think that's a great benefit of Xamarin that can't easily be solved with independent native projects.
you would never have to rewrite anything. the old way would still work, the new way would be opt in. your stuff won't break. old win32 apps still work, even through wpf, the weird windows 8 shit, and now uwp. back compat ia a big deal. basically it will be either backwards compatible, or it will be disjoint (you'll be using one or the other, maybe mixing but having to be explicit about it). nothing to worry about.
Cool thx for the clarification 
Why you say that ? JS as changed a lot since its scripting days you can't consider them all scripting kids etc its a full language now surrounded with solid frameworks etc.. it's no C++ but don't do the mistake John Carmack did when he said later on he didn't know web development
Thanks for the tip. I tried to do that a couple years ago for other reasons and never got it working. Would be amazing to get that going though. 
I feel like it should be pointed out that these are issues not specific to .net core, they are problems to overcome for all web development
I stopped using Resharper since VS2017. Created a related post. VS2017 + some tweaking does all I really need. Plus Resharper was slowing VS quite a bit.
The good news is that features like row-level security in SQL server are making contextual access control easier to get right, and possible to write in one place.
Thanks I ended up converting it to a string: Date.ToString("dd-MM-yyyy HH:mm:ss");
I would go with the following sites: * [.NET Conf](https://www.dotnetconf.net/) * [.NET Foundation Meetups](https://dotnetfoundation.org/events) * [Channel9 Events](https://channel9.msdn.com/Browse/Events) *Here are all the free to watch events* 
That's kinda my point :p. Does XF supports prism module etc system?
What they mean by "for net core" is that these examples are net core specific. It does not say these issues are net core specific, but rather these examples are. Which is great, we need more net core specific examples.
Arent there just libraries you can load which allow you to generate images like this in app? In the two languages I've looked for this theyve had libraries
I would recommend [highcharts exporting server](https://www.highcharts.com/docs/export-module/setting-up-the-server). It's easy you use and you can host your own if you need to or just use the public one that highcharts has.
Having never been to a conference, in the opinion of those who have, is one like anglebrackets worth the $1600 entry fee plus $1500 for hotel?
I was about to ask the same thing. 
Are you asking about anglebrackets specifically or about conferences in general?
I don't know about ordering properties by name as I never needed such a refactoring. But go to type functionality is there, and also the extract method refactoring (which in my experience works better than Resharper's), along with a few others. Check the post I mentioned for some extensions suggestions: https://www.reddit.com/r/csharp/comments/6oeqds/resharper_vs_vanilla_visual_studio_2017/ (sorry pretty busy at the moment, currently working on a different project, using VSCode this time)
To be fair, I hear iOS native devs making the same complaints about each new version. So it's hard to say where the blame lies.
Except their solution is wrong. .net core has resources based authorisation, so rather than check the object properties you’d use the resource auth pieces to use the same type of authz policy you use on controllers. Seems like someone just recycled an old asp.net article for hits.
Can you provide some examples please? 📒
If you've never been to a conference then I'd recommend first attending a low-cost independent polyglot conference to see how you like it. I'll be attending CodeMash the first week of January. http://www.codemash.org/ It's VERY well run, has a lot going on, and the Thurs+Fri tickets are only $300. The session listing is up now and tickets are still available. Other similar conferences: KCDC, Codestock, MusicCity Code, Revolution Conf.
Sometimes you also have to close and start again VS for no apparent reason. I had to do that every time it decided that I should not have the right to debug the app.
IME (which isn't extensive, granted) conferences are good and you'll probably learn useful stuff, but they're primarily about milking money from corporations. The last one I went to was Xamarin Evolve 2016, and we did a two day training session on top of the conference. I had fun and learned good info on several topics, but the total on the expense report that I turned in was close to 5 grand. If your employer is footing the bill, go for it, but going to a conference if you're paying your own way is crazy, IMO.
Interesting! Sorry you didn't like the article. It's more just me making my way down the OWASP Top 10 for 2017 and writing notes as I go, then turning that into a blog post :). The list only just got released and it's got some pretty interesting new entries in it. In terms of the resource based authorization, how have you found it in practice? I always feel like it's quite a bit of code to just compare two properties. And when it's more than two properties (e.g. there is a third object that needs to be checked), it can't handle it. I generally don't like writing about things I've never used, so that's why I didn't use it. 
It's very little code to create one controller and one view. Rather than get frustrated with generators (like I would), perhaps take a stab at writing it yourself. Find a basic MVC tutorial or perhaps [this razor pages one](https://docs.microsoft.com/en-us/aspnet/core/mvc/razor-pages/?tabs=visual-studio) and go from there.
If you're already a programmer, it takes less than a month to learn a new language and a large part of a stack. So I personally don't worry about the cost of learning a stack or tools. I think it's better to improve yourself with things like productivity, focus, strategies, patterns, and the like. Build stuff, practice. What do you think?
It looks like my point is proven since I've been down voted (you?). I said 'some' people so you clearly didn't read properly.
I second this. I have not been myself, but I know people who have and they have nothing but good things to say about CodeMash.
Oh yeah... [I know the feeling](https://purple.pizza/what-to-do-when-your-skills-feel-outdated/). You have your head down in a webforms app and then poke your head up to of .net core :) Yes, the javascript frameworks like React, Angular, and Vue are very hot now and any of them are fine to start playing with if you're looking to learn some new skills. I actually put [this flowchart](https://purple.pizza/where-to-start-in-dotnet/) together for the very purpose of sorting through a lot of the changes happening, PM me if you want.
Not sure if it helps but I've found hardware connected and streaming data to com ports can cause the pc to recognize it as a serial mouse at power on, and hence the port in use issue. I've not seen this since probably win8 era, but at about the same time moved from making uart based hardware to usb based.
Interesting! One of the two devices, the one that is most often the problem, actually, only accepts commands, it doesn't stream data.
What makes you think he's even using this for a web project?
So 95% of the people at conferences are there because their companies pay for it. The price points and other costs associated with it (hotel, flight, etc) are such that it probably doesn't make much sense for an individual unless they're trying to network or they're a consultant and their clients are paying for it indirectly. I've been to a conference on my own dime and wouldn't recommend it. Even if you get a lot out of it, it's hard to justify the thousands of dollars it will cost you unless you either land a job or a client out of it (and if that's your goal make sure your going to that specific conference to meet with a specific client or a specific person who has a job opening) All that being said, if you can get your company to foot the bill, then they're definitely worth it. Between the change in environment, hearing from others about what they're working on, talking with speakers, and general "networking" stuff I feel that most conferences are a net benefit. Also, if there's something that is presented at the conference that you want to integrate into your work back in the office, I've found that the conference helps justify spending the time on whatever that new technology is. If you get a ton of push back, then the "then why did you even send me" line does well in having people give it a second thought. As far as conferences themselves, try and make sure that the overall focus of the conference, the speakers, and the specific topics are interesting to you and are applicable to what you do on a regular basis. That's the best way to stay engaged and to get something from the conference. Nothing will make a conference feel like more of a waste of time than topics that don't interest or don't apply to you and/or your work. Not that the topics are similar from year to year, but you can get a good indication of what the conference should be like by looking at prior year's speakers and topics. It's helpful if you need to budget or book a conference well in advance of the actual sessions being published. All in all, the other advice already in this thread is good, and I'd second it as well.
DogFoodCon is another one in Columbus, OH http://dogfoodcon.com/
So... 16 comments and 169 retweets (#10) is your definition of "broke the web" ? How about fuck you and whatever product you are trying to advertise? - disappointed
&gt; which illustrates the close mindedness of some in the .NET 'community'. So you are saying that a handful of close minded people in the community illustrates that there are a handful of closeminded people in the community of millions? Not sure what your point is trying to illustrate because there will never be a community of over a million on any topic that doesn't have some members that are stubborn to change their opinions. 
I am not sure what this article is about. It talks about MS past and current and then blabbers something about empowering developers and classrooms and what not. In my uni course C++ and .NET are the primary languages and really it does not matter what you use in the classroom. As long as they teach the actual concepts well. &gt; it is a good demonstration of how learning a single set of skills like C# and F# in conjunction with the standard curriculum can greatly empower the next generation of computer scientists Did I miss the demonstration part?
If you have any capabilities of disconnecting the Rx pin (even if you have a breakout box) it will tell you if its some power on issue.
Thats interesting. In the U.S that is not the case in many instances. For one reason or another (cost I presume), Java is usually what is used. In the current state, the recent native cross platform/device tools and services has the potential of allowing students coming out who are already comfortable working with these tools to have an easier time creating apps for many devices/platforms. Switching from Java/Scala would be relatively seamless and mostly synctactical. For all intents and purposes the functionality, especially as it pertains to the fundamentals would be similar. 
make sure to use an Intel haxm emulator, mine starts in about 10 seconds. After it starts, it takes only a few seconds to build and run it in the emulator.
Is there one you'd recommend? That's the currently one I'm planning on going to as my first conference.
There's so much going on at Codemash it's hard to even explain. So many sessions, a maker space, game room, and the food is great.
Core is more similar to Zend or Laravel in the PHP world than it is to WordPress. Core is an application framework whereas WordPress is a full-blown application/plugin framework. Professionally, Core is more valuable knowledge to have in the long term so I would encourage you to keep working with it, but if WordPress is sufficient and more profitable for you in the short term, I wouldn't force Core.
I am not sure of the exact question, but I would agree with your earlier statement, it is not a 1:1 comparison. .NET core framework is a development framework while WordPress is a CMS (Content Managment System) You can surely develop a CMS with .NET or find an existing one that is already written with .NET. It all depends on what you are tryin to achieve. 
I would like to freelance dev, and I've never heard of anyone using the core framework or similar, for freelance development. That's my goal for the moment. Is it common to create a barebones CMS with something like the .NET framework?
I intend to freelance mainly. Do you think it is viable for me to use the core framework or am I shooting myself in the foot?
There's nothing really wrong with building websites in Core but you should build on top of a CMS so that you aren't re-inventing the wheel with every website. That will also let your clients make content updates without constantly involving you. However, the danger with Core is that the ecosystem is smaller and changing more rapidly because it's new. And on top of that, the big .NET CMS applications are still working towards Core compatibility (and are not really close to ready). So it really depends on your timeline.. Core will eventually have a robust CMS that you could compare evenly against Wordpress, but it doesn't today. I wouldn't suggest building sites from scratch but you could definitely help with a project like [Orchard CMS](https://github.com/OrchardCMS/OrchardCore)
Pretty sure you want to setup and automated deployment process with something as simple as a powershell or bash script, to as complex as creating a build server with artifacts which get deployed on a triggered process such as a schedule or the merging of a branch. 
Is right in the fucking ASP.net official docs. Can we please stop posting these?
Why *build* a CMS? Use and extend Orchard. Word on the street was that they have already released their Core version, although I haven’t looked into that myself.
Freelance *what*, that's the question. If it's "slap up a presentation website for a small business", then Core is a **bad** idea for that business (not so bad for the consultant though). But "slap up" with wordpress can be taken pretty far, way up to e.g. a full-blown e-commerce site.
Solid post mate. Very much on point.
I went to Anglebrackets in Vegas in 2013. It was a while ago but it is still the best conference I have attended. The speaker lineup was amazing and the topics were interesting and relevant to me. The quality of speakers I have found to be the single most important thing at conferences. As far as worth I don't know. It was paid for by my employer. If I was to pay for it myself I would probably find something cheaper.
I'm off to NDC in January, can't wait
What makes you say this? .NET Core is a framework. WorsPress is a CMS. It has plugins for e-commerce. They're not comparable. If you wanted a presentation website for a small business Core is fab. About 5 clicks in Visual Studio and you have a bootstrap MVC site ready to go. Or building it up from scratch only takes about an hour, or less using a boilerplate (I prefer my own mind). If you want a CMS there are plenty of Core CMS' out there already. Ditto if you want e-commerce, just install and extend an e-commerce platform.
I think .NET Core is fab for freelance websites however you won't find nearly as much work as if you did WordPress or Laravel - so many freelance buyers want PHP sadly. However, it depends where you are looking for work. If you skip over these freelancer bidding sites, you can consult with your clients a lot more and demonstrate why another platform might be ideal. I predict this changing over time with Core being open source, cross-platform, having decent IDEs that don't cost a fortune and only work on Windows, etc; but it won't be overnight.
I'm the one writing this blog post and I wanted to publish my input as well. First of all, thank you for all your input. It's highly appreciated. I very much agree with a lot of the comments here. I have been participating in conferences in more than a decade and have a pretty good idea of what works and what doesn't. As pointed out in other comments, getting a lot of hands-on knowledge, isn't the purpose of attending a conference. At least not during the "normal conference days". A lot of conferences offer workshops, as an alternative or supplement to the session-based days. In my experience, these days are great as an alternative to attending a course elsewhere. But most of the stuff actually are available as training courses elsewhere. Attend the workshops if you want something practical to bring home. If you are based in a place with little or new training offerings, attending workshops as part of the conference, could actually make it cheaper, since you don't need multiple trips away from home. As for the session-based conference days, I think ThereKanBOnly1 has some good pointers. I don't attend these days personally, to gain knowledge about a specific technology or subject. I use these days to be inspired. Since there are breaks throughout the days and typically a range of social activities, this is also a great way to network. As a former freelancer, I have gained a few gigs from conferences, but I think it's more network and keeping in touch with former colleagues. Finally, being on a conference can be a good excuse to leave home once in a while. Especially if you have kids, one days takes the other. Traveling to a foreign country on the companies expense (if you are a permanent), is a great a cheap way (at least for you) to experience something new. 
That is like comparing apples to zebras.
I didn't write the article moron
Is Orleans still really a thing? I thought it was just the experimental version of Service Fabric and was long since obsolete. 
Thanks for the insight. I considered getting a corporate job last night and I saw there are no positions for core. So is the transition between MVC 5 and core easy? I also noticed a trend that every job available required senior level experience. Is it right to assume a lot of companies only have very few .net developers so they fill the spots with senior developers? I live in a booming area full of corporation HQs so I'm sure I can find something, but that struck me as odd.
Thank you! Would you recommend I use MVC 5 until core matures? I like that core is cross-platform, but there appears to be no support or jobs around core, yet.
I'd go straight to Core unless you can identify something specific you can't do in it. It's got a clear roadmap, a large support community, is cross-platform. With regards to jobs, I've convinced a few clients pretty easily to go with Core because the end result for them is a more maintainable, cross-platform codebase which can be hosted in IIS just like Framework if they wish without any issues. Clients will have their own preference.always and you won't be able to please them all, all the time.
Why do you recommend Visual Code over Studio? I tried using VS Code last night, which I enjoy using for the front-end development, but anything core related is a pain. Creating a new class? The new file is completely blank. Creating a controller? Also completely blank. It seems like a lot of useless typing. If I'm missing something and VS Code can intelligently create files I would love to use it.
I've implemented IoT solutions in both. Orleans was far simpler* and was much more performant. \* Except Service Fabric simplifies network partitions, which some could argue is all that matters. I still preferred the Orleans method.
Of course, the two are not comparable - at all. Wordpress is a **massive** CMS. Going in with ASP.NET Core MVC is like North Korea threatening the US. Sure, you can make a website skeleton in 5 clicks, but that has 0 real value. ASP.NET Core MVC is what one would use to make WordPress (among other things :-)).
That's not a question anyone can answer. The technology behind a project is going to be unique based on the task you are assigned to. If you are building a custom app then core is right for you. If you need a cms then you might want to look else where unless you plan to roll your own. 
If you already use some js charts you can use tools like wkhtmltoimage or phantomjs (that are actually headless fully-functional browsers) to render web page with a chart to image. These utilities they could be executed on your server from C# code with System.Diagnostics.Process, or use existing .NET wrappers that provide simple API to do the job.
You shared it...
I went in January this year, I had a great time. Hope you enjoy yourself.
It's not about the emulator, but the released app. XF startup time for Android was horrible. Not sure how it is now.
Thanks, nice to see some other Suffolk folk about as well!
https://www.pluralsight.com/blog/it-ops/developing-microsoft-azure-and-web-services-microsoft-exam-70-487 https://channel9.msdn.com/Series/developing-windows-azure-and-web-services https://www.edx.org/course/building-azure-skills-toolkit-microsoft-dev224x-0 https://www.microsoftpressstore.com/store/exam-ref-70-487-developing-windows-azure-and-web-services-9780735677241 Nearly all these were from a quick google search and the MS exam site. https://www.microsoft.com/en-us/learning/exam-70-487.aspx I'd just buy the book and study it cover to cover. 
Thanks for the response. The video from Microsoft's site was retired and the book got terrible reviews (why I did not pick it up) I was consdering going the pluralsight route you linked. Even though it is not directly related to the exam, it does cover all the topics on the exam. 
Again? Stop posting these shitty "dotNET" articles you keep writing, as I said the last time: https://www.reddit.com/r/dotnet/comments/7jqtjd/dotnet_standard_20_everything_you_need_to_know/
The pluralsight link did look pretty good, and I kinda wish they did that for other exams as well. This statement might sound weird, but MS will test you on what they deem to be the content for the exam and they will test you on all of that content. It doesn't matter if that content is 3/4 years old and it's dated. It doesn't matter if there have been new options that supersede what the test was originally built around. It also doesn't matter if the technology has minimal utility in your line of work or was broadly rejected by the community. If it can be on the test, you'll be tested on it. So the book doesn't have very stellar reviews but even still I would recommend at the very least using it's table of contents as a reference (you don't need to purchase it for that). Courses, videos, and blog posts will cover what the author deems interesting or useful about the topic and are not guaranteed to cover all the things you need to know. If MS published a book for the exam, even if the topics are not covered well, all the topics you need to know will be in there. I've failed certification exams because I didn't know absolutely every BS thing that MS thought was useful for a given technology. My recommendation is to ensure that you are familiar with the entirety of the topics MS covers in the exam, and IMHO the best way to do that is with MS curated material.
A lot of companies are still making the transition, not hiring for .net core devs explicitly. Find a shop that's building new product, and you can find a .NET core position. It's pretty much the same as full framework as far as development goes.
On my job we only care about .NET Framework, because our .NET projects make use of either EF6, Oracle ODP.NET or WPF. I think it will take awhile before .NET Core actually becomes relevant.
Core is not widely used in the industry by any standard. Also I find most jobs want mvc these days.
This is right. Young codebases and/or startups using .NET will be more likely to be using .NET Core.
While it's going to be a monster to migrate a larger solution from 4 to core2 you'll probably find performance to be a little faster. That said, there may be a number of solutions, but I personally would start to look through client side frameworks to handle element display, especially if you are looking at a few thousand dom elements. Is there any reason why the table/element list isn't paginated or otherwise broken down into smaller parts?
Could you wrap the `Open` call in a `UnauthorizedAccessException` try-block and retry if it catches?
Yes, I did start to wonder if moving over to something like Angular/VueJS would be a better option but I would never get the sign off for something like that as it would probably be a much bigger undertaking than potentially moving over to core. I also researched them a bit and also found that dynamically constructing templated UI's also tended to be a bit difficult in a lot of frameworks - for example in Angular it seemed like you would be having to dynamically compile modules at runtime which didn't sound like it would be great either. As for pagination, yes, we do limit to 20 on screen at a time and jquery is used to dynamically show/hide the correct page of elements as the data queries to fetch the data can be quite slow and hence makes paging with live data query quite painful - when the 100 rows are fetched in one hit it's instant to page through, but the initial rendering of those 100 rows, even if its just rendering essentially 600 spans for 6 columns, seems very slow at the MVC end, seemingly down to the partial views aspect. I suppose I might end up having to sit down and knock up some comparisons between the two technologies, as well as seeing if ViewComponents have any particular performance benefit over partial views. I was hoping there might be a magic better way but I guess I am clutching at straws a bit there!
Are you using entity framework? Also what part of the app is slow? 
Your second question is key. Is it the actual rendering that is slow (from __return View()__ to the browser's first draw)? 
OP should add a profiler instead of guessing. Most micro orms will probably be a large improvement over speed vs ef but that's just my opinion. We also saw a huge improvement going to service stack especially prior to core but that could be a huge change. 
The problem is I don't know which COM device will get the next port.
Well if it's an internal tool, you'd likely just host in on an IIS server in their local network 
Ok great. I have little knowledge in hosting applications in IIS and a lot of the documentation seems to 8-10 years old. Do you think the docs are still accurate?
Not, sure I haven't worked with Core any. This should point you in the right direction though: https://docs.microsoft.com/en-us/aspnet/core/publishing/iis?tabs=aspnetcore2x
Awesome! Thanks
yeah, without knowing much about your setup I don't know what your best approach would be. 
I don’t think you’re going to have much luck. In particular because it’s usually HR folk who write the job descriptions. They probably don’t know the difference between .net and .net core, so will just shorten it to .net.
Why do you specifically want a Core job? It's too early days to expect ads specifically for it, IMHO. If you go for a progressive .NET shop on Framework then they'll likely start using it at some point anyway.
Honestly I would just toss a login screen on it and host it in azure. If this is your first time doing freelance work and you haven't used iis you're going waste a ton of time trying to get that setup and keeping it updated
Eh idk about that. Then you’re introducing potential security concerns, especially with someone who is new to this, like he mentioned. At least developing on IIS internally, the application will be behind their firewall. 
The dotnet core web projects come with authentication out of the box. Its trivial to use even for someone new to it.
What kind of problem domains are suitable to be solved by using framework like Orleans?
Find conpanies that work with microservices and regularly add new features. Convinve them to use core for the new services. 
I don't know about 2 years, but it certainly takes a long time to learn all the aspects of WPF. MVVM, bindings (one-way, two-way), update notifications on your objects, observable collections instead of lists, error validation, value converters, custom controls, dependency properties, data templates, component templates, styles, transitions and much more.
Thanks, it looks like you've given me a checklist of things that I need to learn :)
At our company, we are only *now* starting to port some of our applications over to .NET Core. It's going to be a long process, and I feel like many other businesses are in the same boat. I'd love to work somewhere that uses Linux environments and .NET Core, but you kinda have to pick your battles. (C# + Windows vs. Java + Linux) ¯\\\_(ツ)_/¯
Any framework needs time to understand well. The actual number thrown will vary depending on the framework and what is considered by "understand".
It's purely the render code - as I mention above, if I literally replace the @Html.Partial with a hardcoded &lt;span /&gt; the speed increases hugely - all that is happening in the partial is a hardcoded &lt;span&gt;@value&lt;/span&gt; - there is no other processing or logic. I have done very heavy profiling of all this with tracing and Glimpse, that is why I am so confused. One example of how I profiled it - in the CSHTML I create a stopwatch at the top and start it - immediately afterwards I loop through the already fetched data and columns collection drawing a grid and then after this code in the same CSHTML I stop the stopwatch and output the time as a trace. This is where I am directly seeing the big render times.
It’s a desktop console application. 
I don’t think these work on console (no gui) applications?
The ones I found are related to form applications. I am building a console application.
Also how to deallocate parts so that the memory is really released. Things like event handlers, bindings and so on. 
Yes, of course. My question is more to do with just how complex is WPF (incl. MVVM, data-binding, etc.)? When people have thrown out the "2 years" figure, they are basing that on if you were using it full-time as part of your day job. To me, this suggests that is more complex than learning something like ASP.NET MVC. I want to understand why it is more complex and what are the different parts I need to be aware of. I think that /u/kalroth has given me a pretty good idea of what I need to be looking at.
Can you cache it?
Make sure you have an IIS server that meets the hosting requirements for. Net core Windows hosting bundle. 
I don't know if that's true. At least for my company (about 33k employees, and around 10k engineers), we've got a huge push to going .net core purely for the AWS advantages. Everything new is now .NET Core, and a lot of our old stuff is being rewritten in it.
Unfortunately not - the data is liable to quickly change and certain aspects of the rendering (visibility etc) are affected by the data itself. I am just a bit surprised that the use of partial views like this can be so slow to begin with!
Clustered location transparent applications, or via buzzword "microservices". Really really easy to write such applications without knowledge about networking, multi threading or clustering. This is the up AND down side, you have less control but lesser stuff to worry about
I have used .Net Identity before and could implement a login screen. Honestly, after doing some research, I'm strongly considering just hosting it on Azure or some other Third-Party service. The application doesn't contain much, if any sensitive material and they were just using Google sheets before. This is also just a side project and I don't want to be responsible for any future problems that could arise and I also have very little experience with hosting.
I have recently re-written a Windows service from C# into Java so that it could be executed as a UNIX daemon, due to lack of ODP.NET support.
You could put together a proof of concept in core but I think there is still something off here you could address. We were getting pretty bad performance with mvc4/5 and switched to service stack with orm lite and an spa and the improvement was astounding. 
You are missing the key point: the actor model You also don't need the actor model for microservices
They will work, you just have to create the chart within code, supply the data to it and then save the generated image to the hard drive.
In the same vein as /u/lucuma, can you put together a brief example of what your current render logic is doing?
The reason it generally takes so long to learn WPF and XAML in general, is because most developers are used to using WinForms. There's a huge learning curve for WPF in my opinion, which is why I have only made 1 program with it, and at that it was really just a few web pages.
It takes 1 week to be productive and about 3-6 months to understand 95% of WPF. The last 5% are what might take longer.
Unfortunately DevIntersectino (which includes anglebrackets) is my only experience. I've actually glad that this was posted and that others have suggested some other conferences, as I'm very interested in the ones people have mentioned. I do agree with /u/adthomsen in that the people they have speaking are a lot of the big names in whatever scene you're interested in. It's good to go and talk to people who are big in the front end space, or the actual people at Microsoft who are building the products, and so on. I just don't feel it's worth the outlay (even if it's the company paying for it). You can probably meet up with these people at other conferences, chat with them online, etc.
I’ll look into it, but in my experience I had to use System.Windows.**Forms**.DataVisualization.Charting and that’s not working.
Thanks, this seems a bit more like what I was expecting. 
Everyone here is saying IOS but I thought with Core you could just run Kestrel on any server? I believe you can run Kestrel on literally anything and avoid paying for the whole IIS thing 
I too am just getting into Core. So I'm kinda using this as a learning experience as well as a freelance project. But after doing some research and talking to the business, I think I'm going to go with Azure and just have a login to authenticate. Even though it won't be internal anymore, it will get the job done and it will save me and them from a lot of headaches. I plan on learning more about Kestrel and IIS though.
I did a basic one on Azure too and it was pretty simple so you should be good
Angular5+ &amp; Telerik's KendoUI (grids etc) seems to be in fashion lately regardless of whether you are in MVC5 or Core
Yes, you can host with Kestrel as a self-hosted process. You can also dockerize the application. This is what I'm doing at work, and anything public is passed through a reverse-proxy.
RoutedCommand and the ICommand interface.
The real question is, what kind of IT setup does this company have? Do they already have web servers/database servers and someone to maintain them? If they do have some sort of IT department that already owns servers, you need to talk to them, since they're going to have to maintain this app after you're gone. If they're a typical local small business with no real IT presence, then I would just set them up in Azure.
They have no IT department at all. It's just a small construction company that just needs something small and accessible. Planning on using Azure, although I haven't worked with it before. Does Azure have good customer support? Because I really don't want to have to deal with any hosting issues in the future if they may occur and I plan on drafting a small contract that will explain this.
Yes with v2 Microsoft support kestrel as an edge server. But they don't necessarily recommend it*. IIS or Nginx are suggested. However since this project sounds internal, there should be no issue. * Source asp.net core 2.0 security talk I attended at NDC by Barry Dorrans
Oooh that is good to know, thank you!
Like anything I takes as long as you spend studying and practicing. Like another commenter said after watching a few tutorials on Pluralsight and creating a few applications you will become productive. Any platform I believe takes years to master and there is always new things to learn. It never stops.
Because it does. Winform you can be productive almost instantly. Wpf and most XAML based UI systems are very complex and IMHO idiotic. The problem they were trying to solve with XAML simply didn’t exist in the real world and they created this monster to try and do it. 
Why do you need a partial just for a span and value? Send the value in the original view model. If that's not practical, replace the partial with a JQuery POST request to get the value and render it in the span. 
If you only host small application, then try shared hosting. Asphostportal provide .net core hosting, you can go with them
Well. Pretty sure you'r not going to find Dotnet core specific jobs. Most places allready have big codebases and only just start doing DotNet core. Where I work we have used dotnet core for 1year and are looking for more developers doing Dotnet Core. But we also require them to get down and dirty with the old codebase, so you can't just have a linux machine.
Thanks for sharing TrikkyMakk.
Hi oskaremil, Thanks for your comment. I appreciate you vocalizing your thoughts. :) In an effort to justify why this comment made the list, I wanted to let you know that the list was combined based on certain criteria and with what the Twitter search engine has to offer it is quite a challenge to source tweets that lack searchable attributes (think hashtags, mentions, etc). I am sure that there were Tweets during 2017 that did have a higher impact, and I will make sure to thing of another method of sourcing them for next year. Thanks and have a nice day.
There is also themes, animation, custom controls (different from user controls), shapes and more. Really, just get one of the WPF tomes, the one i have is 4 years old and 2.5in/6.4cm thick. From a webapp world it's SVG, HTML, CSS, parts of React all in one
Check this channel: https://www.youtube.com/channel/UCJ3AxeCHGPZkMi3kRfCuiHw. Good playlist on WPF.
Thanks mate, I'll check it out.
Not true, Azure has internal cloud options though that is probably targeted at larger enterprises.
Interesting. I might have to try this someday. Since I've got quite a few files to replace in my application, I just trigger a batch script which kills the app, replaces all the files, and restarts the app.
&gt; if (currentAssembly.Location.ToUpper() == destinationFile.ToUpper()) It's $"currentYear", why do people still make these mistakes, vs magazine people no less :( Not only does this allocate memory just to perform a comparison, it's broken. Apparently these folks have never heard of the kind of problems this causes, typified by "the Turkish i problem": https://haacked.com/archive/2012/07/05/turkish-i-problem-and-why-you-should-care.aspx/ You should use one of string equality overloads: String.Equals(string1, string2, StringComparison.OrdinalIgnoreCase);
&gt; January 2018 So good, OP travelled back in time to share this piece. ;) 
I actually didn't know this. Thanks for point it out!
Perhaps the date is rendered with Javascript, where month 12 results in year+1/month=1. 
It's a published piece that is part of the January 2018 MSDN issue. 
I still have yet to read about a real-world example of how this is useful. I just can't imagine ever needing to worry about manipulating just parts of an array or string and the possible overhead of doing so. 
binary based networking solutions mostly. For instance I support a game networking stack that runs on unity / dot net core. Being able to pass my payload to api consumers on the stack without an additional heap allocation from an array copy is going to be super useful.
fucking javascript
A simple example for strings, extracting parts of path or file extensions &gt; in building large solutions 30% - 40% of all MSBuild string allocations are short-lived and would greatly benefit from a StringSegment-like type https://github.com/dotnet/corefx/issues/20378#issuecomment-334328891
This one is my favourite: https://www.nuget.org/packages/GeorgeCloney/1.0.0.9
Parsing and deserialization.
That's interesting but crazy edge case for most things. But your right you should really use he equals anyway.
I don't like calling it a crazy edge case - it might break for everybody running your code on a machine with particular culture settings. Taking the Turkish problem and flipping a little, if your code is running on a computer with Turkish culture, the normal strings "FILE" and "file" are not case-insensitive equal when using CurrentCultureIgnoreCase. Sometimes turkish letters break your non-turkish culture assumptions; sometimes your turkish culture settings break your non-turkish letters. In a related case, I tend to break a lot of .Net software I test because I set my date format to '18-Dec-2017', and now folks who make assumptions about date parsing don't work.
If the wording is poor or there are any ways to improve how I am asking the question, I'd appreciate that as well!
A few questions: Are you using a framework like IdentityServer4 or something with this? Is this .NET core or 4.x? If I'm understanding correctly, you want to log a user in and assign a token to them that they can use to make API calls with?
Sorry, it's .NET 4.x (Don't have my personal machine with me at work, but I believe its 4.5) It's not for my own API, I'm trying to use the Spotify API. So my understanding is that after the initial authorization request when the user logs in, it should redirect the user to the redirectURI I specify in the first request with the access code in the URL. My question is should my redirectURI be another controller route that has a service that gets the access code from the URL and uses it to request an access token? Maybe my understanding of the protocol is flawed and that's entirely wrong lol
Ok. Which flow are you using? See here: https://developer.spotify.com/web-api/authorization-guide/ 
Authorization Code Flow, I am reading user account information like library and artists for the app.
IEnumerable&lt;T&gt; solves part of the problems described in this article, but the layers of abstraction make it slow. It sounds like Span&lt;T&gt; is made to be more performant, and more focused on a set of objects/primitives rather than IEnumerable which applies to ANY sort of enumeration. I imagine the use case is similar: Now for any API that might normally take, say, a string array, it will instead accept a Span&lt;string&gt; and you can pass in any object that can be cast to a Span&lt;string&gt;. So you don't have to .ToArray() your List or whatever.
I blame daylight savings time.
Basically what you want to do is specify your controller and action that you want to use for your call back. For our purposes, we will use mysite.com/auth/spotifyCallback. Your method signature would look like so: public ActionResult CallBack(string error, string code, string state) From here you would handle whether it's an error or it returned a code successfully. Use the code to make a call back to spotify with HttpClient. See step 4 of the Authorization flow for the call. If you get back an auth token, then you are all set. How you store the token and handle the next steps is up to you. From then on out you use the auth token on subsequent calls on behalf of the user. When the token expires, you'll use the refresh token to get a new auth token.
That is exactly the breakdown I needed! I wish I could upvote you more than once. Thanks a lot my dude
No problem. Let me know if you run into more issues.
I call it edge case because it is only applicable if your app is used by that culture. While it is a massive edge usually you know where your app will be used. If it's going to be globalised then you should be doing this anyway and using English string literals in the first place rather than resource files is a big no no. If you are using a custom datetime format string you should always use ParseExact that's different.
&gt; If you are using a custom datetime format string you should always use ParseExact that's different. You're missing my point. If you're not using a custom date format, and you don't use ParseExact, then your date parsing will likely fail on my machine. 
Again you should always use the current culture for parsing dates and numbers.
Cool but this doesn't address the issue of how to ensure your application has completely closed before the new version launches. What I did is because our app is distributed via installer (NSIS specifically), I added a flag to the installer which instructs it to watch until the caller application closes, then it can proceed with a silent install (which NSIS supports built-in) and then relaunch the application (which was already functionality behind a checkbox in our installer) with a special flag indicating we auto-updated from an old version so we can then do additional things in the application on launch if we want.
It's mainly a performance thing so you're never going to see its value if you're looking for a new use case. Instead it's about making existing implementations and situations require less allocations and/or ugly workaround-code.
That's a rather simplistic point of view. Don't you think that's going to be problematic when you consider the wide range of ways you could end up dealing with culture-sensitive values? I'd say instead, you should use the culture of the source of the information, and not just the thread or UI 'current culture'. Heck, remember the entire bug we're talking about? `StringComparer.CurrentCultureIgnoreCase.Equals("FILE", "file")` will return **false** if your thread culture is turkish. There's rarely one good answer: * Reading and writing values to a config file? Then you should read and write using the invariant culture. * Parsing and displaying values with the user using a UI? Use the UI culture. What if I send your server a request containing en-us culture-formatted dates, and your server is in turkey and thus your server's thread is running with current culture = turkish?
Wait, String doesn't implement IEnumerable&lt;char&gt;?
Not sure how that would help? But you can `foreach` a string
Span only works for memory-contiguous collections with no additional data. 
Skip and Take
How to forge an antiforgerytoken?
We have some controllers that have an HTTPPOST and they get JSON information back, not a form. So I can't just do the @Html.AntiForgeryToken thing.
var htmlHelper = new HtmlHelper(new ViewContext(), new ViewPage(); Can you generate an antiforgerytoken from that?
Good example, I too was struggling to see the benefit but removing additional memory allocations makes sense.
Sounds like you just need some sort of authentication on your httppost instead of an AFT. AFT requires a request before a post in order to transfer the token. So you could do the same thing or use a different method of authentication that a direct post to an API like that is ok.
Among other things, accepting a Span&lt;T&gt; makes your API a bit more flexible without sacrificing performance. Using stackalloc to get a span is especially useful.
Hey, there. Look into a custom view engine as my first guess is that your view is being loaded from disk every time you call Html.Partial. You may need to write a custom one with caching to prevent the file browsing that happens internally to get the view. Using JetBrains profiler should show you where your CPU usage is maxed, and I'd guess you are burning a lot of cycles on slow HD lookups.
(function(){ var data = JSON.parse(@Json.Serialize(ViewDataDictionary.ToList())); // TODO: register event handlers. })()
How about you generate a token in backend , with an unique id, save it in database (or where you store your data) , attach token to the request and when the response comes back check if for that unique id you have that token.
According to [this sample](https://github.com/aspnet/Entropy/blob/7a4ca4bfedebdffca133bc6ff10b4ccc6dc7a834/samples/Mvc.FileUpload/Filters/GenerateAntiforgeryTokenCookieForAjaxAttribute.cs) you can manually generate one with the code: ActionExecutedContext context = [...]; var antiforgery = context.HttpContext.RequestServices.GetService&lt;IAntiforgery&gt;(); var tokens = antiforgery.GetAndStoreTokens(context.HttpContext); Console.WriteLine(tokens.RequestToken); // this is the token It seems like, outside of a filter, you could use the default IoC container to grab an instance of IAntiForgery, which seems to be 'built-in' without having to explicitly registered.
Serious question, how much disk space would all of nuget take up?
Each call to Skip/Take requires a new Enumerable (even if it's a struct, it needs to be boxed to IEnumerable), calling ToList()/ToArray()/new String() is a new object.
Interesting. /r/node was just saying that npm reached 600,000 pacakges. That puts NuGet less far behind than I thought, actually.
We benchmarked our server a while back, and about 75% of its CPU time was spent serializing and deserializing JSON. A significant speedup to string parsing with a lot less allocation would go a long way.
Package count doesn't say that much. While Node has lots and lots of small packages, sometimes even a couple of lines, NuGet has a lot of large libraries. 
For example: https://www.npmjs.com/package/left-pad
More than u got
When you do the `@Html.AntiForgeryToken` thing, it generates a hidden input with a known id. Grab that hidden input value and attach it as part of your post request using the ID the system generates as the ID of the parameter in your request. (I think its as easy as appending to the URL). 
Most likely not that much. Most packages are only a few KB to a few hundred KB. I would be very surprised if caching all versions of all packages would cost you much more than 1 TB.
What a load of shit. ".NET Framework" was promised and you give me mono. .NET Framework != Mono 
I could VERY well be misunderstanding you but pretty sure packet sniffers would read the JSON and see the token. Also, the point of the token is every session its new so someone can't hijack someone else's session (I think?) so if we always use the same token value then it doesn't prevent anything. I could be strongly misunderstanding your idea though, if so, sorry for my lack of understanding.
Can I ask why you chose to use Interop? I had a similar project and went with Mailkit. As easy as fetching the emails and the different parts you want, and iterating over them to parse them/do whatever you want.
Im pretty exactly 1 year in and yeah 2 years sounds about correct for "full understanding". I have yet to even touch any animation and just today got into really looking at how themes/skins work. From that background i guess bindings and XAML will take a while to grock. I was coming from mostly Android on the UI side so felt quite comfortable in the declerative ui thing. Some articles that helped me understand some of WPFs features: http://www.codemag.com/article/1405061 Just about any other article tagged with WPF is worth reading on the CODEmag page, unless it uses their inhouse wrapper. http://www.codemag.com/Magazine/ByCategory/WPF 
It'd be nice to see more open-source activity now that .NET Core is starting to become more well-known. I think there's the potential of having a really nice cross-platform/open-source development ecosystem. 😄
Exactly, they are libraries, not like they'll have images and stuff that is usually the bulk of applications
Thanks for the response... ..and the links. I'll check them out. 
So my idea is to generate a token just before sending the request. So it's not related to the session. Every token will be unique and after you verified that the response's token is the correct one, you delete any reference of the token from db(or where you store it). It will just be a one time request token. Maybe another idea would be to check the origin of the request that contains the JSON and accept only from certain origins. Also I don't know much about the capabilities of packet sniffers regarding request content
You should just use an API for that
Yes.
If [this post](https://stackoverflow.com/a/13622061/564755) is true, the "forgery" guarantees provided by the AFT are not nearly as strong as you think they are - packet sniffers are easily able to read the AFT as anyway. The **only** thing the AFT protects you against is CSRF.
definitely IMO
Correct. HTTPS (TLS 3.0) is what protects you from packet sniffing and there is no (viable) alternative to that for that sort of protection.
Node is an good choice for certain projecfs, but nowadays I wouldn't recommend using PHP unless you have a specific reason to use it. That said, .NET Core is definitely a good framework to use for smaller applications
.NET Core is great. I have been using it for the past year with VS2017 without notable issues. Just a warning: TransactionScope support is currently unstable. Should be fixed in Q2 2018 as far as I remember.
Does it still bog VS on "standard" computers ? My computer is not top-notch. Neither is its performance in the lower regions. I like R# but had to cancel my subscription due to VS (2017) slowing down to the extremes with R# activated. ಠ_ಠ
Localdb is generally not for production. MySQL is free. You don't need any special account. MSSQL is easy to install. Just google around and you will find MANY tutorials on setting up databases. You should probably ask for more time because if you haven't hooked up your database yet... You aren't "almost done" 
Resharper uses the old compilers. So yes. It still is vs2017 Roslyn design time compile and then resharper old netfx compile.
Azure is probably the best way to go. Have you tried [these steps here](https://docs.microsoft.com/en-us/azure/app-service/app-service-deploy-local-git) to get it up and running? Another option is to use ZEIT Now. [I wrote a blog post giving a simple example of how to get started deploying an ASP.NET Core app on ZEIT Now](https://mking.net/blog/hosting-and-deploying-aspnet-core-apps-with-zeit-now). You'll need to host your database elsewhere though, as this is just for the web app. Finally, you could janitor your own linux VM on DigitalOcean. It's a bit of a learning curve but it might be valuable experience. [The official docs are a good starting place](https://docs.microsoft.com/en-us/aspnet/core/publishing/linuxproduction?tabs=aspnetcore2x)
The performance recommendations are interesting in theory, but the recommendations are basically just a list of built in vs2017 features that you could turn off. It feels like a distraction from the fact that almost all your performance issues are going to be with resharper.
Are you referring to entity framework 7?
If the performance recommendations are any good, maybe they can use them on the app itself. ;(
I'm using it for my own little projects 🙂 
Does the Regular Expression Validator window show up again?
I have found that it is. :)
How did you get to this point without a database? Are you doing any data access yet? In a project where I use Entity Framework and Code First migrations I do the following: * Setup SQL Server Express on my machine * Create a context in my project * Add the connection string to the webconfig i.e. &lt;add name="MyContext" connectionString="data source=.;Initial Catalog=mydatabasename;Trusted_Connection=True;Persist Security Info=True;MultipleActiveResultSets=true;Timeout=1800" providerName="System.Data.SqlClient" /&gt; The connection string changes for production when I point it to an MSSQL Database hosted on AWS. 
Always
Some might argue it's IDEAL for small private projects ;)
Wow that's a lot. Thanks so much! I'll check everything out as soon as I get off work.
You can also try https://appharbor.com/ they have a free tier and it's easy to setup.
I think this is just a shots fired about the vs2017 "Resharper is slowing down visual studio" message. The options, for the most part, are things I've turned off for years. They would make anyone's visual studio faster.
+1 for recommendeding Entity Framework
To expand on this: * Use @Html.AntiForgeryToken in your razor page, it generates a hidden input like: &lt;input name="__RequestVerificationToken" type="hidden" value="abc123" /&gt; * Make your jquery post to the endpoint using the ValidateAntiForgeryToken attribute like follows: $.ajax({ type: "POST", url: "/ValidatedEndpoint", data: { __RequestVerificationToken: $("input[name='__RequestVerificationToken']").first().val(), AnotherDataItem: 123 }}); 
Ask your lecturer if any in-memory database is OK. You would need to seed the data and it wouldn't be persistent, but for an assignment it would be the easiest path. https://stormpath.com/blog/tutorial-entity-framework-core-in-memory-database-asp-net-core
Hmm... the trouble is the rest of the application relies on GET and POST requests to a database for comments and posts. It's essentially a message board system. Would this solution still work even considering the above? Thanks.
If it's designed for multiple users, then no.
What's he on about then? How else can I do it?
ASP.NET Core is especially suitable for tiny projects. You can use * ASP.NET Core MVC Pages (e.g. https://github.com/dodyg/practical-aspnetcore/tree/master/projects/aspnet-core-2/razor-pages-basic) * ASP.NET Core UseRouter Extension (e.g. https://github.com/dodyg/practical-aspnetcore/tree/master/projects/aspnet-core-2/use-router-2)
What JSON parsing library are you using?
Use SqlLite as your DB 
That’s cute, you think you can be ‘finished’ 😉
Check that your web.config file is being generated and installed properly. .NET Core has had a lot of changes in the way it handles configuration, and documentation is almost all out of date or just plain wrong on this issue.
Firebase?
I went last year to Codemash and it was my first developer conference, loved the experience and am all set to go back this year (only a couple weeks away!!). It has a nice diversity of sessions and the casual events were great too. 
Don't worry. I figured it out. I believe exporting the database as a "bacpac" file is enough and allowing the lecturer to re-import it on his side using SQL Server Management Studio is enough. Thanks though!
Have you looked into SQLite? It is a file based database that you can run locally for things like demos. It’s not a production ready thing for most web applications, but it is easy to start up. Just specify a path to where the database file should exist and it creates it on the first run. 
Ok, thanks
It's dacpac.
mvc core doesn't need IIS. You can just run it as a console app. You'll probabally need to use sqlite or inmemory instead of sqlserver. Either send a pre-seeded sqlite file in your .zip, or have it automatically apply migrations and seed at startup.
Look into sqlite, which just stores the database as a file. There might be some minor tweaks needed to your app, but you don't need to install anything. SQL Express is quite easy to install (there's a lot of options in the installer but the defaults are sane, just hit next a bunch of times). This is the simplest as it should just be a change to your connection string. MySQL is also free, they just want you to sign up s they can spam you or sell you a support contract. You want the community edition (a.k.a. GPL edition). However I personally would recommend against MySQL. Personally I'd suggest hosting a database in Azure (or AWS/Google Cloud/etc.) rather than install it yourself. But for a demo tomorrow, I'd go with sqlite.
alternatively you could just "backup to file" and send that. DacPac is usually generated using an SQL project. Where as you could just backup the database using SQL management tools ... Either way the lecturer will have have to re-import it.
Yeah but Span is hardly a fully-fledged StringSegment.
Question, was this just a side-project for learning or is a product for a hospital or to sell to hospital. If the latter, is is HIPAA compliant? 
The over 9000 edition
Roslynator has the sort properties by name thing and some other cool stuff
Have you tried using localsb and commuting the *mdf file into source control?
It looks marketed since you can buy it, so I say its for real. 
If this id just a side project for fun, awesome work. If its not, fuck off with your product advertisement. 
You've heard of Google Chrome, you've heard of Electron and Slack, now there's a new company in town looking to suck up as much memory as possible! Introducing...
My first c# job was strictly WPF MVVM and no code behind. The learning curve was steep to say the least. After about a year and a half I was able to really know my way around WPF but I was still learning new things every day. We used entity framework and ALOT of powerful LINQ queries, used alot of generics, and became really fond of anonymous types. There is alot you can do with WPF. It is very powerful. The biggest thing in my mind is that with WPF you need to think a little differently. Everything is modular and generic so it can be scalable. The clear seperation between data models / view models / view can sometimes blur. There's alot more emphasis on theory as well. Your skills need to be on point to write really nice WPF code. 
Thanks for the feedback. I've watched a couple of pluralsight courses on it now, and it doesn't seem too bad. Definitely harder than say ASP.NET MVC, but not too bad. I guess the real learning will start when I get my hands dirty as I learn best by doing.
Yeah I wanted to include the sample data and the scheme itself. So that's why I did a bacpac. 
I don't know. I'd hesitate to buy something as large and as important as a hospital management system from a vendor using an @gmail.com address. 
Upon further research, it looks like I was mistaken. I wasn't aware there was a thing called a bacpac file, I always thought it was only dacpac. So, in short, yes, you're right.
Wow, that's a lot of info! I'm going to be doing this for a side-project, so I'll definitely read the whole thing when I have time.
Welp. Hug || Punch
No Problem. If you'd like to see some wpf code you can visit my github: https://github.com/jwizzle29 and take a look at some stuff there. You can see how much goes into a simple wpf application. 
Thanks, I'll take a look. It's always good to see how people structure their code.
I'd still go with the later; there is no value in this "article" except advertisement of the product - no code, no design. This doesn't belong in this sub.
How do you aggregate and search the logs from the various microservices?
How is he making the framework look at the features folders for the .cshtml views?
Hi. If I were you I would check out Cabana, Logstash and ElasticSearch. I don't know that much but I know that it's used for what you describe. https://www.elastic.co
Kibana.
Thanks man
I use Papertrail as my host / repository of logs and send it up using NLog
Ok cool. Just making sure. Thanks. 
Great article, thank you!
Btw - thanks for the addition/code example. I couldn't remember the field ID off the top of my head and didn't want to give the wrong info :)
Cool. Didnt know EF could do that. Just used EF to generate a Postgres DB and migration for the first time last week, worked like a charm. Yay EF!
1. Right click project. 2. Add new item 3. Click data in the menu 4. Select data entity 5. Select a database with code first 6. Select all the garbage you want auto generate 7. Click finish 8. Done
I thought you were being intentionally vague by giving enough information to find the solution without giving the actual solution itself. That is 100% my normal mantra in my other life (Tableau forums) but in this case I was enthusiastic because I knew the actual answer through experience! 
The ELK stack is perfect for this type of log aggregation. Logstash (the L) is a logging aggregation and enrichment system. Note you might not require it depending on if you just want to sink your logs to elastic search directly via its http endpoint. Elastic search (the E) is a time series database which has many uses, putting logs into it is just one of them. Kibana (the K) is a visualization dashboard that you can use to make graphs and other metric types of all your data.
Using this add feature folders extension: GitHub - https://github.com/OdeToCode/AddFeatureFolders NuGet - https://www.nuget.org/packages/OdeToCode.AddFeatureFolders/ Install it via nuget then in `startup.cs` in the ConfigureServices method add a call to `.AddFeatureFolders()` public void ConfigureServices(IServiceCollection services) { // Add framework services. services.AddMvc(opt =&gt; { opt.Filters.Add(typeof(DbContextTransactionFilter)); opt.Filters.Add(typeof(ValidatorActionFilter)); opt.ModelBinderProviders.Insert(0, new EntityModelBinderProvider()); }) .AddFeatureFolders() .AddFluentValidation(cfg =&gt; { cfg.RegisterValidatorsFromAssemblyContaining&lt;Startup&gt;(); }); services.AddAutoMapper(typeof(Startup)); Mapper.AssertConfigurationIsValid(); services.AddMediatR(typeof(Startup)); services.AddScoped(_ =&gt; new SchoolContext(Configuration["Data:DefaultConnection:ConnectionString"])); services.AddHtmlTags(new TagConventions()); }
Hi, I'm the JHipster creator/lead dev - thanks for your comment! We do have a number of companies who would be interested to have a .NET backend with JHipster. After all, we already have several front-ends (AngularJS, Angular, React), so why not several back-ends? If anybody is interested they can post a feature request on https://github.com/jhipster/generator-jhipster/issues and try to form a team. I'd be happy to help! 
I hadn't heard about jhipster before. It seems cool but not that useful, as it forces you to use a certain technology stack (spring boot + angular 1.x). Now, for .net, code generation has existed for a very long time (google t4 templates), and visual studio does provide you with project presets and scaffolding for MVC and entity framework applications. It's not the same, but it gets you far enough when it comes to setting up new projects.
Actually you can choose angularjs, angular, react, redux or jquery. Spring boot is very similar to .net core. The spring framework is akin to the asp.net framework. I think that’s the reason. The scaffolding out of visual studio has been good enough. At the same time there are a lot of people doing .net starter projects (cloudescribe comes to mind) It would be great if they could combine forces.
That's actually quite cool that it supports multiple frontend stacks! Thanks for letting me know! And yes, Visual Studio's scaffolding is good, but it does have its quirks too. It's not that customizable that you can use uml to control it.
That would be really awesome and something I would really like to get involved with. I did think about it a few years ago when .net 4.5 was prevalent. That version of .net did not lend itself well to this type of project because you required iis. Now with .net core being cli driven it seems like a much more plausible. I will create a feature request in the coming days.
Using .net core you make it possible to run on any linux too. So you could go with a linux host. Now if you are going to need mssql you could go with SQL Express. If you think that azure cloud is expensive for your taste you could go with a vm or a dedicated machine and use the sql express as your sql server. Sorry if i dont be much help. You could give me follow up questions if you want anything explained. Thanks
UML Code generation is baked into VS: https://msdn.microsoft.com/en-us/library/dd409445.aspx
You can install SQL Server 2017 on some Linux distros as well - openSUSE, Ubuntu, and RHEL. So you could potentially do do a free or cheap Ubuntu BOSS, install dotnet, SQL Server, and host your app there. Or change your app's databad provider if it's not much work. 
Honestly, Azure is the way to go. How big do you think your database will be? Azure App Service + Azure Cloud SQL may be suitable, and the price is fairly decent there. However, if you really want to cut costs, and are willing to put in a bit of extra work, you can host on a relatively inexpensive Linux VM. There are a ton of hosts in this space, so I'm sure you can find one that suits. [DigitalOcean](https://www.digitalocean.com/) is my go-to recommendation (you can ask around on Reddit for a referral code, or use [this one](https://m.do.co/c/aac4e1b54a04)). Some other alternatives are [Amazon Lightsail](https://amazonlightsail.com/) and [Vultr](https://www.vultr.com/). There's also [AppHarbor](https://appharbor.com), and I think even [Heroku](https://www.heroku.com) may support ASP.NET Core now that they support Dockerfile deployments? These two aren't always cheap though - it really depends on your use case. 
Damnit, EF. Support Views already.
Have you tried the .Net Core CLI commands? `dotnet new angular` or `dotnet new react` This command scaffolds an MVC project in the current directory with AngularJS (Angular 5) or REACT components. Here is a [List](https://docs.microsoft.com/en-us/dotnet/core/tools/dotnet-new?tabs=netcore2x) of commands from the MSDN source. Alternatively, Yeoman has an ASP.NET Core scaffold template as well. Though, due to the baked in CLI commands, I no longer use it.
Really depends on what your trying to do :) I host my blog on Azure. I play arround with AWS with clusters and stuff and love DynamoDB. Some times when I just need some cheap machine with Docker I start Digital Occean and let it run for a couple of days. (or months) when I forget to delete it again. Tried Linode for a while, but didn't really like their UI. Using Google's Firebase for easy authentication. So really all over the place :D I just like to try out the different vendor's. At work we are using AWS for all our stuff, but moving all over to Azure (Not sure if I am allowed to tell why).
Don't really understand the question. Are you only going to Create a RestAPI? Or do you have to make a frontend aswell? What kind of resources are you looking for? Is it a school project or work? (School by the sound of it). 
Linux host OS + PostgreSQL or MySQL and you’re all set with a netcoreapp. I’ve been using webapi + Postgres with entity framework in production.
Hey Just found a youtube tutorial for vs2017 which seems to work (activex control written in c#/winforms running in access) https://youtu.be/jaoltvDVTpw 
There's plenty of great resources to be found by googling asp.net tutorial. For a simple user friendly interface for your new API I would advise checking out Swagger. 
[Linode](https://www.linode.com) is my go-to nowadays. It's similar to Digital Ocean and if you look at both pricing models you'll see it's quite obvious they are competing with each other. Currently you get pretty much the same specs, but double the amount of RAM for the same amount of money on Linode.
If you've setup an LLC or corporation, Bizspark provides a nice monthly Azure balance for three years. You can go the VM route there and then migrate to another host later on, or go all in with Azure services as others are mentioning. I liked them, but if you have low revenues it can be hard to justify the expense. If you also have low volume, then a low-priced VM elsewhere (digital ocean, etc) works if you don't mind going with Postgresql, MySql, etc. Obviously if you have higher volume you'll have to spend money at some point.
Yes it is rest api which I need to implemented in my school project (asp.net). I do add pizza product, edit pizza information and also Product page which allowed customer to add their pizza on cart before they fully checkout to payment. I need some suggestion see which Rest API can used in this situation (pls include tutorial url if can）.
Not "CREATE" rest Api. Is research on current new technology API. E.g. Google analytic, Facebook login Api, Google chart API and more. But I need suggestion from u whether u implemented Before any API on this situation ?
The best advice here - don’t. If you want to move logic out of controllers then look in to CQRS and the Mediator pattern - Jimmy Bogard (creator of AutoMapper and MediatR) has some great articles on his blog about this.
So the question is what are you trying to do with all those points, as that's going to determine what your options are. Frankly, while .Net can deal with this kind of thing, it's not really meant to. So if the answer is that you want all of them in memory at the same time and to have a visualization of the points while running some analysis, then C# may not be the best answer for you. Yes, you'd be better served by having a "3D index" with the most easy (and I say that with a grain of salt) to understand and work with are [Octrees](https://en.wikipedia.org/wiki/Octree), but there are more effective methods of indexing/partitioning 3D space. I am not aware of any .Net Octree implementation, but I'm not a game dev. &gt;I am aware SQL Server has support for spatial types but this is not the path I'd like to go. May I ask why? The reason being that SQL's capabilities here are as close to "out of the box" you'll get in a .Net environment, as there aren't good 3D libraries that I'm aware of. Also, I don't know why you think you're going to want to parse and load 10gb worth of files without some sort of persistence and easy retrieval. If you ever need to reprocess the dataset, it'd be much easier and quicker to load from SQL rather than reparse the raw CSV files. Not to mention you can use the spatial indexing in SQL as well. Overall, I think you need to figure out how you might begin to split your problem up into smaller chunks. Despite what language you try and do this in, trying to process the whole dataset as one is both a herculean task and one that will likely be slower than a sloth. 
**Octree** An octree is a tree data structure in which each internal node has exactly eight children. Octrees are most often used to partition a three-dimensional space by recursively subdividing it into eight octants. Octrees are the three-dimensional analog of quadtrees. The name is formed from oct + tree, but note that it is normally written "octree" with only one "t". *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/dotnet/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
Thanks for the Octrees :-) The plan was to convert these CSV files into binary ones so you skip the parsing next time. There might be also different sources. As for SQL Server, the Express edition is limited to 10 GB database size and buying full license is out of scope of the project. Moreover the application is supposed to be easily installed by people with almost zero IT skills so the SQL Server dependency would make it too complex.
Not to mention I'm 90% sure that the express edition doesn't support spatial types. Either way I can see that it's not an option. You still didn't say what your application was actually supposed to do. Assuming people with zero IT skills are supposed to be using it, I'd say you have your work cut out for you. I'm still not sure that there's a compelling reason to do this in C# other than that's what you know. Dealing with this much data and the algorithms needed for mesh generation are not strong points for C#.
Not speaking of your language, but this doesn't make any sense. Your API is what will be a go between between an app and the server, e.g What pizzas are for sale? What is their price? Put in an order with my details. Your website is going to be different, and doesn't need an API. Analytics tell you who is visiting your website. Login APIs let you use google or facebook tokens instead of using your own password scheme. I think you need to go figure out what exactly you should be doing. Because your question is really, what should I use to make the internet.
I only took a quick look, but checkout the Authorize attribute. It allows you to put an attribute to make sure that the user is logged in without having to have the code in each method. You can even decorate the class with it. 
Yea use the Mediator pattern so instead of having 2 Repository classes with 30 methods you can have 60 classes. Much cleaner and simpler. /s I'm not saying that the Mediator pattern and CQRS have no place, but for a lot of applications doing basic CRUD they're totally overkill. You shouldn't talk about these things so dogmatically. Everything in this field comes with trade offs and our job as engineers is to weigh the pros and the cons, not proselytize whatever religion we read a few blog posts about that week.
I'm pondering why you'd need 30 methods on a repository. All I can really think of would be: * Add(TEntity) * Remove(TEntity) * Remove(TId) * Find(Expression) * Get(TId) Maybe an AddMany and RemoveMany that took an array. If you return an IEnumerable from Find I think you'd be able to do further refinement on the query (limit, offset, ordering) before execution. I could see using methods to wrap a stored procedure but I could see that being an exception rather than a rule (and depending on the sproc, might fit better as a service). 
Cheers, I've been looking into AWS and Google Cloud Platform too. Mine would be a similar setup. Web API (+ frontend ASP site for admin users), backed by a Postgres (or PostGIS) database using code first EF. What sort of costs are you looking at each month, if I may ask?
I think C# is still nice and clean while I am used to work with pointers from C++/Delphi era so unsafe code is an option. Found something https://github.com/Nition/UnityOctree
Hey thanks for the reply. I actually have a WordPress site for my wife's business on a Vultr instance. Honestly, it's quite slow - but I am on the tier 1 plan, and I'm not sure if that's the hardware or WP itself. The issue with Azure is that it's a bit costly for my situation. I'm developing and running a startup from scratch (by myself), so I may not have customers and I'm not really in a situation to pay $100/mo for use of SQL. Although it's nice, I guess I could save money by going with Postgres, etc. Any reason you say Azure should be the go to? It seems easy enough to set up, but I don't mind doing a little extra work to save money :) Have you hosted anything in production using the sites you mention? Thanks again!
Thanks Nick. Do you know if SQL Express can be used with Azure? If not, I'll probably find a well-reviewed Linux host and pop it up there in production. While developing and testing, I'll probably use Azure for the ease of use though.
Would love to help in this project. Should be available from February, let me know if you start working on this. Github profile is Pungyeon :) 
Hey thanks for your reply. Would it help if I gave you a little background for my project? It's just a Web API that listens for mobile clients in the field to report location data. The data is received by the Web API, processed, and certain information is then stored in the database (SQL at the moment, but probably will move to Postgres), and eventually sent back to the client. In production, this will happen every 10 - 15 minutes per device, so there could be potentially hundreds of incoming requests eventually. Are you able to tell me if there was a problem with AWS, or more of an incentive from Azure that caused the move for your company?
Thanks mate, always helpful to have some competition to evaluate.
Thanks dude. I'm just a one man startup with an idea, so not sure if I qualify for that. Could be worth a shot though - is it hard to get in? No issue with spending money, just trying to cut startup costs while I (hopefully) build a customer base.
http://calculator.s3.amazonaws.com/index.html AWS has this handy cost estimator - it varies by cpu/storage/redundancy levels. For a basic low traffic single host you can probably do under $40/mo. Amazon also recently added shared VPS hosting for 5$ if you want to start dirt cheap.
Maybe you have multiple entities per repository. Maybe you have a complicated filtering/ordering you use often. Maybe you're marrying up information from some API and a local database like say a location and the weather(that you get from a weather API) and you want one method for just the location and another for the location with weather to prevent needless API traffic and latency when weather isn't needed. The possibilities are endless. &gt;If you return an IEnumerable from Find Unrelated, but in general I try to return IQueryable so that further filtering can be done by the consuming application. &gt;I could see using methods to wrap a stored procedure Stored procedures aren't always available. Sometimes you only have read access and need to put the logic at the application level.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/angular] [Using the autocomplete feature in ngInputTags with full stack app. Need help!](https://www.reddit.com/r/angular/comments/7lc9gx/using_the_autocomplete_feature_in_nginputtags/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
It's worth looking into various programs offered to startups, although many require an LLC/Corp. There are also free tiers in general that may be "good enough", including for Azure, AWS (the first year free tier is useful, after that less so). I never had any issues joining any of them, although I did have to create a new email address for Azure as there was an issue when I first applied (at least at the time, they wouldn't let me sign up with the same account even though it's only use was for the first attempt. Weird, but what can you do).
Hello, If you are using the AppService no you cannot. If you are using a vm you can. I'm not aware if there is a db plan that uses the sql express. There is also a mySql option on your AppService although i have not researched about it.
&gt; Maybe you have multiple entities per repository. Maybe you have a complicated filtering/ordering you use often. I would absolutely advise against multiple entities from a repository. &gt; Maybe you have a complicated filtering/ordering you use often. Fair point, repositories are all about convenience. &gt; Maybe you're marrying up information from some API and a local database like say a location and the weather(that you get from a weather API) and you want one method for just the location and another for the location with weather to prevent needless API traffic and latency when weather isn't needed. That doesn't sound like two methods that belong in the same repo to me. But a service that queried both sequentially makes sense. &gt; Unrelated, but in general I try to return IQueryable so that further filtering can be done by the consuming application. Does casting IQueryable to IEnumerable cause the query to be executed? I was thinking in terms of providing the most generic interface so testing is easy but is still useful in the actual application. 
Oh also, here's what I'm wanting to do if that helps. https://www.reddit.com/r/dotnet/comments/7l8gun/host_recommendations_for_a_net_core_rest_api/drl3lv7/
There is a project which separates frontend (Angular 5) and backend (asp.net core 2.0). It uses the best practice such jwt based authentication &amp; authorization. On top of it, it uses Identity for ease of use. You may download them and run it to see what's happening behind the scene. https://github.com/kkagill
It’s more than just class and method counts. You’ve totally decoupled your logic from anything web-related, so now you can test your application logic in isolation and leave things like WebAPI to be not much more than a routing engine and model binder. You still maintain low-level access to your EF context, so you can optimise performance using things like projection and it’s advanced features such as NoTracking for query operations. You are right that we are to evaluate and pick the most sensible approach for the problem but a repository abstraction over an EF context is, imo, something that has virtually no benefit - and indeed quite the opposite. 
You can accomplish this using partial views. Say you have a page that contains both a login and a registration form. You create a LoginPartial page and a RegisterPartial page. then in another file (say "LoginOrRegister") you call it with something like @await Html.PartialAsync("_LoginPartial", new LoginViewModel()) and similar for the registration portion. Then in the controller you have three actions. A HttpGet action to return the LoginOrRegister page, and two HttpPost actions for the login or register forms. If the model state is invalid, you redirect back to the LoginOrRegister action. &gt; can i return to the original view, if lets say the ModelState is invalid, WITH the original model? That's a little bit trickier, and I don't have an answer for you. Hopefully someone else can chime in here. Maybe you could use ViewData or ViewBag to accomplish it?
In azure, you can automatically scale your DB size depending on your needs. Do you really need 100$ DB up front?
You are correct. I thought parials where removed, but only html.actions where. Thanks! 
Was about to make the same comment.
&gt;over an EF context is, imo, something that has virtually no benefit I actually agree with you, I didn't read the article before my original comment. EF DBContext IS a repository pattern. Extend the DB context if you need functionality.
Thanks! that sounds really useful. Using that attribute, is there a way to redirect the user if they're not authorized?
Those methods are already in dbcontext. What use is it to repeat that behavior in a custom class?
It will do that automatically actually. I’m not sure how to override
It's about relying on an abstraction you control. All the user of the repository needs to know is stuff like I give Find an expression and it returns an IEnumerable of Users. Maybe it's coming from the database, an external api, an in memory storage. 🤷‍♂️ If you inject the dbcontext it knows where stuff is coming from and worse, it has access to everything in the database. It's also easier to fake a repository in tests than a dbcontext. 
Long term you're going to want to move a lot of that code you have in your controllers into services / repositories. 
Hopefully not, but I'm not exactly sure what costs I'd be looking at if I'm being honest. I've never had much to do with maintaining a database in a production environment. One way to learn! I got the value from [here](https://imgur.com/a/QkcMR), which seems to be the lowest price tier there is.
^(Hi, I'm a bot for linking direct images of albums with only 1 image) **https://i.imgur.com/vQhF3lc.png** ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme) ^^| ^^[deletthis](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=delet%20this&amp;message=delet%20this%20drlar4f) 
Imho it's just an abstraction over an abstraction. Also i haven't had the need to swap an dbcontext with an api over the past ten years so that might make me a little biased perhaps. And it hasn't been a problem for unit testing either 
That's the pricing for an 'elastic pool', but it sounds like your use case just needs a single database. Check out the 'single database' pricing on the second tab on [this page](https://azure.microsoft.com/en-us/pricing/details/sql-database/). You can get a basic instance for $6/month, or start with the smallest standard instance for $15/month and you can scale it up from there.
Another solo startup founder here. I would strongly recommend AWS over pretty much anything else, especially Azure. I've used both in production and AWS is far, far ahead of Azure when it comes to stability, 3rd party tooling support, developer documentation, and really just things working the way you expect them to. The free tier of AWS lasts for a year and allows you to run a small VM + DB for free for that time period. You can also apply for $1000 in AWS credits as a solo startup, which will last you even longer. I would take a serious look at: 1. Elastic Beanstalk for hosting your API. It uses EC2 under the hood, and t1.micro instances are free for a year with the free tier. 2. RDS for a managed database solution - it supports SQL Server, Postgres, MySQL, MariaDB, etc. I'd recommend either Postgres, MariaDB, or MySQL over SQL Server as well, mainly because of cost concerns for a solo startup.
Have used many hosts, but for my .Net stuff Azure just gets it right. It is not the cheapest, but its not that much more expensive either. Its really full featured and just makes life a breeze. Even if it saves me an hour or 2 a month in not having to deal my hosts, I more than made up for the 10 or 15 bucks more I am paying them. I have an Standard: 1 Small plan and a couple of DBs thats just over 100 bucks. And I host about 6 apps and growing on that without any performance issues (yet). I was even lower tier earlier, but easily scaled up when I started hitting a wall.
So I figured out my query issue with the backend but still coming up short on getting the front end to mix properly, for whatever reason it doesn't like my query string ".../tags=q" and I think it has to do with the ngInputTag library i'm using, anyone got any experience with it? I can share errors if needed.
How about we disregard EF altogether, store the data in Excel workbooks, wrap a DataSet in a class we call Database and then store all SQL procedures as string in a property of objects which we then serialize to xml and store in the user workspace. We then deserialize and directly execute them each and every time someone clicks a button. I've seen some shit. I don't think my coworkers are aware there are such things as "patterns." This isn't some legacy application, this thing was coded from scratch 2 years ago.
This is correct. It will redirect to your login page by default. If you need to redirect to an error page, you can override like this; https://stackoverflow.com/questions/13284729/asp-net-mvc-4-custom-authorize-attribute-how-to-redirect-unauthorized-users-to
Moving some things to an attribute would be a good idea to keep things a little cleaner, but it's nothing I would label as "wrong." But this advice is the biggest, your controller functions are a bit fat and it's a good idea to make some other classes or projects to handle some of the other common, reused task. Remember to keep things DRY, Don't Repeat Yourself.
I take it services are similar to static helper classes? 
They both accomplish similar things -- moving your code elsewhere. Services tend to be non-static classes that you inject into your controller via the constructor. You register them in your Startup.cs with the services.AddScoped method. You can read more about dotnetcore dependency injection here: https://docs.microsoft.com/en-us/aspnet/core/fundamentals/dependency-injection Typically an app like yours would be divided thusly: - Controllers - handle routing requests - Services - business logic of your application - Repositories - the place that you access the datastore Doing all of this sounds like a lot of work, but it will help a lot with maintainability and more importantly it will decouple your code and make things a lot more testable (unit tests are something you should look into as well).
Thanks a lot. This will definitely be the first thing I do before adding any more features. My controller actions felt like a bit much when writing them, but I didn't know how to rectify the situation before now.
The only problem, is that you can't trust Linode. Do some google searching to see how they've handled data breaches in the past.
&gt; and I'm just a solo startup. Maybe you could apply for the [BizSpark](https://bizspark.microsoft.com) program.
Why do you think the ORM knows? In both Oracle and SQL Server, the truncation message never provides the name of the column. I don't know if that's a limitation of the database engine or just a standard, but the message never includes the column. So if the database doesn't provide the info, why would the ORM that sits on top of the database?
Whelp, I'm an idiot. I read that as a very large number last night, my eyes can see the decimal place now though. In that case, Azure is well within my budget! So hosting the Web API is a free service - correct? Then you just pay for SQL after a year of free use? Pretty sure that's right, but thought I'd check with someone with experience.
The ORM can ask the database for the max length of the columns. You see this in action when it generates classes from tables. Which makes it even more aggravating because they often tag the properties with the max lengths and then proceed to do nothing with that information. 
Be the change you want to see in the world. :)
You can host your web API on the 'free' tier of Azure App Service, but it won't let you have a custom domain (so your URL would have to be something like yourappname.azurewebsites.net), as well as a few other limitations. You can move up to the 'Shared' tier for around $12/mo. That's what I'd recommend. I think Azure will give new users one year of free credit or something, but I'm not sure if that is still the case these days. I'm sure they'll tell you when you sign up.
Check out SmarterAsp.net 
EF6 should throw when this type of validation error occurs, but only during the validation phase (e.g. during saving). What ORM are you using?
Interesting, thanks.
As mentioned elsewhere in this thread, to me it just adds another abstraction with no apparent value. The only value a repository had for me was for unit testing, but these days it is extremely easy (and fast) to use an in-memory database with EF, so even that benefit is not valuable anymore. As for the argument that it allows you to easily swap out the implementation of the underlying data store: In 20+ years of development I have always heard this story about how such abstractions allow you to easily do this. I have NEVER seen this happen - unless accompanied by an entire system rewrite. If you are developing software such as a CMS which needs to support multiple data stores, then it makes sense. But in very few other instances have I seen the actual need for - and advantage of - this abstraction.
EF Core.
Its exactly what bizspark is for. You gotta submit an application and get approved. But its worth a shot. You could cover a smallish VM for a month with their monthly credits. Better yet their web apps are sweet and so easy to work with. A database and web app will be significantly less
TL:DR - AWS for affordability, Azure for simplicity At my previous employer I guided them to the wonders of AWS not only for better and more reliable solution than whay they had but also because of how cheap it is when comparing to the big cloud competitors. We were running several dotnet apps, api, and mvc frontend with mssql db. My current employer, the decision was made to launch with Azure. We have angular, dotnet web apis and mssql db. I’m the DevOps of the team and the “big man” of the entire infrastructure (including previous employer). For me, I believe it comes down to one thing and one thing only. COST. AWS, Azure, Google Cloud, etc. are all great Cloud Service providers and each have their strengths &amp; weaknesses. They can all experience downtimes or issues. I have and still lean towards AWS however, I’ve grown to understand where Azure can shine (for the right end-user). If you’re using MSSQL Standard or Enterprise (which you arent) then going with Azure will save you some licensing costs. If you’re using (or planning on) using open-source databases and running your app/site on open-source languages (aka running on linux) then AWS all the way. Having the experience of setting up infrastructures on AWS and Azure, I would say that each of them are confusing as heck once you jump in. After, a few hours of reading and using the Console/Portal it will make more sense. If I was starting a new app/site and was tight on my budget I would look at my handy decision tree: What is ones time worth? How much time will it take one to complete X (setup &amp; configuration)? I’d make a rough estimate on what your worth is per hour. Then determine how much time it will take to create, setup, configure, and launch your entire infrastructure on the platform. If ones time is “affordable” or you have disposable time (like a hobby) then AWS because it’s the best &amp; cheapest option. If ones time is expensive and/or have disposable cash (or free offers like Bizspark) go with Azure. Specially if you’re on dotnet &amp; mssql. A one man shop, probably working out of VS2015/2017 or VS Code you’re strategy to getting all of this done is significantly simplified by going with Azure but you pay the premium for the simplicity. Hence, what is your time worth? Keep in mind AWS does have pretty amazing tooling for VS as well. Personally, I feel like AWS is for the geeks (me) and those that really enjoy getting their hands dirty and setting things up (also me). While Azure simplifies (dumbs down) most of it at the higher monthly premium. Just like Manual vs. Automatic transmission in vehicles! Cheaper + more performant vs ease of use + some (usually insignificant or minor) performance loss. I enjoy both platforms and am glad to be able to have worked with both, Hope it helps you or others with similar questions.
Avoid mysql for .net core, the driver is buggy as hell.
Thanks mate. What sort of costs would I be looking at after the free year is up? I almost decided on Azure because of the ease of use / official documentation. Could you tell me why you'd recommend against it?
Good to hear, thanks. How much were you paying on the lower tier? Was it just the costs for the database?
I think you have to be a registered company for that unfortunately. I'm just a guy with an idea :). 
Standard is 74, the basic was 55. Have one cosmos DB and one mysql db. 
Thanks mate that's very helpful. With my time, it's my personal time. I don't have as much of it as I used to, but I have less money now too. If this is a once off set up, then I'd definitely prefer to put some time in to deploy it properly, especially if it will save me money in the long run. Have you looked into self configured droplets such as Vultr and Digital Ocean? If so how do you find they compare? Also, what about AWS competitors such as Google Cloud Services? Thanks again!
Is that 55 a month? Yeah that's quite pricey!
3.4 megabyte background image? Optimize dude.
Also, one day someone is going to use that repository without checking its code and call the Add() method from a loop. Causing a multitude of nested calls to dbContext.SaveChanges(), thereby killing performance completely. I fully agree with your point. Too much abstraction is a bad thing.
@OP Using ImageMagick "magick login_background.jpg -resize 1920x1080 login_background.webp" Reduces the size to 1920x1080 @ 200kb in WEBP file format. (or ~300kb in JPG)
I can't really answer your first question without knowing what your architecture looks like, but I'll give you several reasons why I don't recommend using Azure at this time (YMMV): 1. Azure doesn't seem to be able to handle production level workloads very well from my experience. At my day job, we have a site that gets a medium amount of traffic, and we somehow managed to exhaust the resource pool in whichever data center we were in. We had to ping Azure support and get them to reset our limits or something along those lines. We've also had weird issues where our main database becomes "temporarily unavailable" for 15 minute intervals once every few months. 2. The Azure Portal looks fancy at first glance but actually doesn't work that well and is really bloated. The "blade" UI/UX is strange and doesn't scale well when you have a bunch of different things open, and the shareable links don't work all of the time. i.e. I'll send my coworker a link to something in the portal, and the UI I wanted him to look at doesn't open because the portal's routing is hosed or something. ¯\_(ツ)_/¯ 3. Documentation exists, but isn't all that complete IMO. I've had to Google a lot and read through random people's blog posts to figure out certain things. So yeah, official docs are often lacking. There are just fewer StackOverflow posts as well relative to AWS. 4. Unstable devops related APIs. Example: just yesterday I wrote a script to pull information about various web apps we had deployed to Azure -- the official API to retrieve this information full on didn't work and only returned a subset of the APIs we have deployed. Had to file a support ticket with azure, got bounced around to like 3 different people until finally someone competent enough figured out it was a bug on their end, and now I need to wait for them to fix it. Which brings me to my next point... 5. Painful support. Generally, you file a ticket, then it gets answered by some random tier 1 support agent that doesn't know anything, then you get shuffled around to a few more people until they finally give you someone competent. 6. Unstable products that are somehow considered "generally available" - we tried out Web Apps for Containers and when we went to production with it, we started noticing extremely high CPU usage (hovering around 90-100% at all times). Our docker image was only consuming 1-2% of the CPU, so there was some other bugged process sitting on the box that was written/managed by MS; we had to switch to a different way of deploying our app which wasted a few days of our time. 7. Billing that makes no sense. AWS bills are decently detailed; Azure bills that I've seen are...well...a mess. This one might be because my company has some complicated enterprise agreement with Microsoft; their pay-as-you-go pricing might be easier to understand. tl;dr: I think in the future Azure will be able to compete with AWS, but right now it just isn't polished enough or stable enough to be taken seriously IMHO.
Crikey, sounds like a mess. I'm not a fan of MS products at all (Visual Studio being an exception). If Azure is any relation to Office 365, MS Dynamics, Skype... etc then I'd like to stay clear of it. I guess as a flip side to the question (if you still feel like typing), have you had any of the issues above with AWS? Also, my Architecture will most likely be Mobile App &lt;- -&gt; Web API &lt;- -&gt; Database (probably Postgres).
HyperJS, Hyper IDE, so much hyper. Kinda bad to name another developer program "hyper" when there's already an existing developer program with "hyper" in it.
Cheers! Will do. Do you use them yourself?
&gt; Kinda bad to name another developer program "hyper" when there's already an existing developer program with "hyper" in it. Hehe, didn't know that, thx, googling now ... There's a dish at the roof where I live, which says "Hyper", and if you knew me, you'd realise it's an adequate description of me. Half of my stuff is named "Hyper", the rest are medicines my GF prescribes (to others, she's a homeopath) I figured the name "Hyper IDE" was kind of cool, due to its potential dual meaning, arising from mispronunciations, such as "hyper idea" (*a*). In addition, it's using the **Hyper** Text Transfer Protocol and is built with **Hyper** Text Markup Language, so I figured it was kind of neat. But I realised I'd probably at some point be blamed for "hyping" my stuff. I guess you're just to first to out me ... ;) But thx for the tip :)
Anytime! I actually run a personal wordpress site on DigitalOcean for over three years now! I think Digitalocean is great for messing around or learning, getting your feet wet, and light workloads. Why am I not on AWS since I love it so much? As soon as I make some time to rebuild the wordpress site into a simple SPA which can run on AWS S3 for pennies instead of $5. As an example, CDN? Where do you plan to distribute all the images from? What about backups? What about load balancing in the event of high traffic? Most importantly, what about security? Data breach? Security of your data is very important. Companies like DigitalOcean do not offer a full range of features or services like AWS, Azure, Google Cloud do. Nor at the price you’d pay on AWS. I did look at Google Cloud as well (maybe three years ago) and for my needs back then, it was too expensive and not a lot of documentation was available. Unless they were able to drastically reduce prices and go down to AWS price point I would not give them a shot. Why? Because they do not have the same amount of time on the market to have built up a large enough userbase that would contribute via blog/documentation of very simple “how-tos”. I might be completely wrong about Google Cloud, YMMV. Taking us back to “how much is your time worth?”. It’s awesome to run into a problem on AWS and a simple Google search will usually provide many results to your problem which is a large timesaver.
This already exists [JSON Web Tokens](http://jwt.io/)
.NET what now??
Yep, cheapest I could find for my pet project (budgeting app). Hosting a service with an ASP.net MVC project. Working on a WPF application that uses the service. 
Many thanks! I'll take a look when I'm not so busy.
If 55 is pricey, perhaps you don't need an elegant cloud solution. Maybe just try an AWS lambda instance with http gateway. Then database to flavor.
You can start by trying to retro-engineer thoses projects : https://github.com/search?q=+FASTA%2FQ&amp;type=Repositories&amp;utf8=%E2%9C%93 
It looks like it is purely text processing, albeit with big texts. You can look for efficient librairies. If you want to go overkill, you can try to manipulate the JVM, or use WebAssembly.
&gt; The ORM can ask the database for the max length of the columns. To the ORM the SQL error is just an error. Not a "max length exceeded" error unless they build something for it.
TLS 1.2 is automatically supported if your application targets at least .NET Framework 4.6. For framework versions below that, you may need to explicitly enable TLS 1.2 in code or use a registry setting.
You seem to be unable to understand the phrase "The ORM can ask the database". Shall I explain it to you?
I see. Thanks. I think my application is indeed targeting a lower framework, reason why it works with 1.0 and 1.1, but not with strict 1.2 sites.
There's a reason for that: &gt; [hyper (prefix): above, beyond, super](https://www.merriam-webster.com/dictionary/hyper) Nothing wrong with u/mr-gaiasoul using this prefix. Latin is fun. :)
Sounds like https://www.nuget.org/
Typically you return two things. 1. Location Header. Which provides a URL which the client can use a GET request to access the resource 2. The body should co rain the newly created resource. In dot net land that typically looks like return Created($"api/resource/{object.ID}", object); Sorry for bad formatting. On mobile
Thats fine, thanks. You are hardcoding the URI here. Is this how it‘s supposed to be done? Isn‘t there a more generic approach?
You're wellcome I'll take a look to, but next year after my holidays. My boss was glad to hear that I found a possible solution which seems to work. But I'll still convince to switch from access to WPF. (I'll have just to write a good foundation framework for porting our applications) I'm curious what for you'll need ActiveX these days
I merely pointed it out. If he wants to continue using that name, sure. But brand recognition is important when something should fly off and become popular.
Hehe, thank you Sir :D
My response won't change, unless they build something for it the ORM will not interpret the error.
I'll put it this way: I'm struggling to think of any major issues that I've had with AWS during the last few months I've been in production with it. No real service interruptions or anything like that; no random database outages. It just "works." The only downsides I've encountered so far: - AWS doesn't have a "generally available" Kubernetes implementation while Azure does, but I decided against Docker for my app anyway. - Elastic Beanstalk doesn't do blue/green deployment the way I was expecting it to. That's on me for not reading the documentation carefully enough
And you can't walk across a bridge that hasn't been built. You aren't actually saying anything. 
That depends on how you're routing is setup, and similar to what you'd have to do from here, is id have to go look up if its been done. 
Do you have a demo server anywhere? It kind of sounds like a security nightmare.
What made ASP.NET easier for me was the fact that HTTP is stateless and I already knew HTML. Everything is created from scratch at each and every request. 
Sounds like they built an asp.net angular app with auth as an afterthought so just used .net mvc with. Cookie isn't needed unless your tracking the user or need more control over the session methinks.
Actually, I don't think you can enable it using code even. I think it requires dirtier tricks. 
It says "Open Source .NET ��� 3 years later"
I'm not sure that's clarified things
Have added an answer to your SO post!
The garbled characters are supposed to be an em dash "–"
Sorry to hassle you again, but I was just thinking about your comment "strictly WPF MVVM and no code behind". I am trying to understand why you would aim for no code behind, and wondered whether you could explain that part in more detail? I mean, I can understand why you would want to limit the code behind, e.g. you don't want to pollute your UI layer with business logic or persistence. Are there any scenarios where it is acceptable to have code there? For example, what it you where using it to enhance the UI experience, e.g. through animations?
What do you mean by "apm"?
Application performance monitoring
I'm going to assume they meant to use &amp;mdash;
You can install it locally, and running it over localhost, using for instance Visual Studio, Xamarin or Mono Develop on either Mac, Linux or Windows. This allows you to easily test it locally, without exposing it to the web, on a computer with firewall, and running e.g. xsp4 on port 9000. This should not require more than a simple unzip operation, and opening the p5.sln solution file, regardless of what underlaying platform you're on. When that's said, it is built upon Phosphorus Five, which contains a lot of security features, such as storing passwords as salted hash values, etc, and it requires a logged in user to access. But security with this **is** challenging, and something I am working on to further increase. One of the things I am doing to increase this, is to for instance create a role based access authorisation logic for reading and writing files. A "root" user (a Phosphorus "root" user that is) has access to reading and writing to all files. But if you create multiple accounts, with multiple developers, accessing the same server, it will (in the next release) allow you to set it up such that a "developer" account can only write to some special folder, and not read files such as the web.config and the "auth" file (which contains the user/roles and access system). The system runs in the context of the web server process' user by default, such as e.g. your Apache user, unless you set it up in the wrong way. This user has restricted rights on most servers, and hence you don't have access to anything outside of the "htmldoc" folder, as long as you set it up correctly. This is further restricted and ensured by all events (think functions) in Phosphorus Five that reads and writes files, which is what the system is built upon. So even though you're allowed to execute shell scripts (which is necessary to integrate things such as Git and compilation), unless your server is setup wrong, it shouldn't pose a problem. And the actual code for the system itself, is never allowed to read and write anything from outside of its own root "htmldocs" folder. But yes, as I say above, security **is** challenging, and something I am working a lot on, to make sure it becomes as secure as possible. My suggestion for making it as secure as possible though, is to make sure all developers working on the same server creates extremely strong passwords. Then secondary to not install Hyper IDE on the production site, but instead have a production site with for instance Git, allowing you to pull code from some Git repository to update the production server, for then to have a "dev server" with Hyper IDE, from where development should occur, which runs on test data and not production data. All developers should be created as non-root users, belonging to for instance some "developer" role, having write access to only the folder containing the files necessary to maintain whatever one is creating. Then as you create releases, you could for instance create a tag in Git, and pull this tag from your production server into your production server, assuming you create a web site of some sort. Still, this would require you trusting your actual developers though, to not run havoc with your development system (or your code for that matter). Now if you came this far, you would notice I kind of eluded your actual question, which was _"do you have a demo server"_. I'll answer that now, and the answer is **no**, not at the moment. At the moment it is not secure enough for me to be comfortable with allowing some random visitor accessing my servers. Simply since it allows those users to (among other things) runs shell scripts through their browsers, and create Hyperlambda code that would be executed on the server, etc. In the future I might create a demo server, after having secured the system, such that I feel comfortable having some random visitor testing it out, and creating his own code. But not at the moment, for the above reasons. Security is my priority number **one, two and three** though! And great things are coming up in regards to security in the next version, which might make it possible for me to allow _"any random visitor testing it out on some demo server"_. If you're still uncomfortable, you can install it on some sort of intranet, behind a firewall, only allowing LAN access to it, to only your developer(s).
That's weird, yeah I meant for it to be 'Open Source .NET - 3 years later'. I wonder why some parts of reddit handle it okay, but /r/dotnet doesn't? (https://www.reddit.com/r/programming/comments/7lh19z/open_source_net_3_years_later/)
You can try https://gist.github.com/irwiss/f6b1e160c9c974c4a39333950ebbb029 I didn't test it on lower than 4.0
.Net Fringe - you can probably find most of the 2017 talks online
I think you can. And the conference is on the list as well :) Thanks
I am taking the piss. I put in the "���" myself
Press the â key to continue. You may find this next to the ��� key.
Is there a complete list of languages supported? Does it automatically come with the binaries to compile every language or are there further steps to add a language?
I'm not completely sold on New Relic yet (mostly because of price) but it seems like it could do everything you want. IIRC they have tooling to monitor the cluster and pods and you can have the app instrumented with their APM tooling and you could also push custom metrics and then aggregate it all in an Insights dashboard. I'd also look at Appneta (used to be Tracelytics I think).
The number of supported languages corresponds to the languages CodeMirror supports (https://codemirror.net/), but you can choose to open up files it doesn't recognise in markdown mode (assuming any piece of text), so (arguably) it supports anything that have source code based upon text files. However, the number 100+ which I use in the article, comes from the fact of that CodeMirror supports 100+ syntaxes, with highlighting, and AutoCompletion. Some languages have _"real autocompletion"_, such as JavaScript, HTML, and Hyperlambda - While others are using _"anyword"_, which will simply suggest any existing words from your existing document, matching your _"filter"_ (being whatever you have typed from before in your _"word"_). There is also the fact that Hyperlambda by default saves all its files as UTF8, which implies whatever compiler/language you're using, must support text files in UTF8 format, which I don't think is a problem though for most languages I am aware of. There are no compilers distributed with it, out of the box, but hooking up any compilers I am aware of (csc, gcc, etc), would be simple, as it allows you to execute shell and cmd scripts, and edit these as you see fit. Makefiles, Ant or nAnt files for instance ...? So if you're in the _"statically typed world"_, there would be some additional work to do, to setup compilation of your project(s). However, objectively speaking, for a real project, it would probably be most fitting for _"web stuff"_, with lots of HTML, JavaScript and CSS - While for statically types languages, such as C#, it would be _"less optimal"_. However, as a _"second IDE"_, with the ability to do _"emergency coding"_, I perceive it also could be valuable also for statically typed languages, in scenarios where you do not have access to your _"primary IDE"_ ...
I think maybe you're just over-analyzing it. All servers initially get a request and have to serve up something from a file path (routing in a sense). If you were running a nodeJS server, the request would hit that and be "routed" to the index. I think if it's working for you and your users, it's fine.
https://github.com/quozd/awesome-dotnet https://github.com/thangchung/awesome-dotnet-core
The only thing that I can think of is serving the default site and JS with the webserver instead of the application. Basically step number 1 is eliminated from the application and is served through the webserver directly and then the angular app will query routes to your actual application as normal.
Personally, I try to keep my production builds free of diagnostic components, and test thoroughly so I don't have to debug in production. However, I am developing in a low-scale environment. I don't know what the right answer is for a high scale environment.
[@await's latest tweet](https://i.imgur.com/lYJzsC6.jpg) [@await on Twitter](https://twitter.com/await) - ^I ^am ^a ^bot ^| ^[feedback](https://www.reddit.com/message/compose/?to=twinkiac)
Lol so much for 0 downtime ￼ Webpage not available The webpage at https://lachlanbarclay.net/2017/12/deployments-with-zero-downtime-asp-net could not be loaded because: net::ERR_SSL_VERSION_OR_CIPHER_MISMATCH 
The deployment was zero downtime. The deployed application is 100% downtime.
I took the liberty trying to answer some of your questions, and others I have had, in a dedicated blog about its architecture, which you can watch and read here - https://gaiasoul.com/2017/12/24/a-walkthrough-of-hyper-ides-architecture/
Lol. Thanks cloudflare. Is it working now for you?
So with NancyFX you have to build even more custom code on top to get features that better frameworks like ASP.NET MVC Core bring out of the house already.
Horses for courses. NancyFX is a good option for when e.g. you're self-hosting using full .NET Framework and not .NET Core.
When you're self hosting, then ASP.NET Web API is a great choice, which also brings documentation capabilities (`IApiExplorer`). It's a much much more flexible library too.
You don’t need .Net Core with Asp.Net Core, but the notion that Nancy is worse always gets me. Asp.Net core completely ripped off Nancy. They’re doing something right. 
Where did they rip off Nancy? I'm so glad they didn't rip off the `dynamic` and `Tuple&lt;&gt;` shit that Nancy is notorious for using. And I'm glad they didn't rip off the inavailability of extensibility.
They completely copied the dependency injection approach for one
Yeah, good point. I just found WebAPI to be overweight. 
Nancy gives you both API and MVC-style functionality though. If you just went with Web API, you'd still need to handle the client side yourself. Like I said, it's horses for courses. If I was writing e.g. a Windows service with a browser-based configuration interface, I would consider using Nancy for that purpose. I wouldn't disagree that ASP.NET Core is a great default option, but that doesn't change the fact that ASP.NET Core MVC owes a lot to Nancy.
Stop using Oracle...
What is this I don't even
Process the XML, get the needed details, create a table with the data structure what you need, and insert the data? This would be the easiest and foolproof solution. Why do you want to store the XML itself? It just a waste of space and time, it is super hard to search, process, convert... 
I can't. :(
Communication with ERPs like this is usually done through middleware like BizTalk.
This simply isn't true. DI is what everything should aim for, just because one framework happens to start using it doesn't mean they "ripped it off". I mean, you wouldn't say the same if both frameworks happened to have a `ControllerFactory` would you?
&gt; Sorry, an error occurred while processing your request. 
I feel your pain
As someone who has used both, it is clear to me that they coincidentally started using a lot of concepts Nancy had used for years. Middleware in Web API is an example. Sure, NodeJS has similar middleware, but Nancy was the first Asp.Net based framework that got out of your way. And they did that for several years while MVC was tripping over itself. There are too many coincidences for me to believe that Asp.net Core made its choices in a vacuum. And I believe that copying is a form of flattery.
PM me when if you want. I'll devote as much time and energy to getting you away from oracle. I'll help you work through business cases, reasons to not use it, explore alternatives, give price point improvements, and work on a migration plan. There's absolutely no reason anyone deserves to use anything owned by that company. Fuck Oracle, and happy holidays
ASP.NET 4.5 is five years old and no longer supported. What is this?
if the normal form of the data is an XML document, sometimes it's better to store that form than decompose it into relational normalized tables. if the table is a normal table and the column is defined as XMLType in Oracle, one can query the table with special syntax and look for rows with selected values in XML elements. You can even index by values in the XML elements. https://docs.oracle.com/cd/B10500_01/appdev.920/a96620/xdb04cre.htm
Wtf is this?
Are WinForms making a comeback? 
Is this better than DocFX?
WinForms never left. If all you need is a CRUD app aka generic government contract, then WinForms is excellent for that task.
bad technical copy?
Spam, me thinks. 
NuGet, definitely. Both Microsoft and third party packages can be downloaded from here, and it's integrated in Visual Studio.
Yes, if you use vscode it's almost identical sans installation
Except for SQL server windows authentication then you gotta jump through a couple hoops
Really? Care to explain or have a link that explains it?
This link has setup instructions for vscode that also apply to running apps and linux docker containers: https://github.com/Microsoft/vscode-mssql/blob/380cfb4e8acce9d9d8368d2a5f32cfff9c73a933/KERBEROS_HELP.md
I ran into an issue that unless you proxy through Apache or Ngnix (or another) there isn’t a way to get the code to run behind https. I tried to use JetBrains Rider and their support told me I had to change the code of my app, which is not an option. Otherwise, it worked well enough to do dotnet build and dotnet run. 
Not really, since R# decompile sources is missing. I code on windows in vm and deploy to ecs
Thanks!
Does vscode support .sln files? I was having trouble importing a core project I started in visual studio 2017.
I thought microsoft dropped support after 3.0 or 3.5 and said XAML is the new thing with WPF, Silverlight (now dead), and now UWP which seems pretty solid
I don't know that I've ever charged clients for "storing" their source code direct. Tupically I've just tried to include that in my hourly rates enough. Now that being said, I have been hosting my own got repos privately and that cost is extremely low compared to Github. My typical feel is that your ideah isn't a bad one. You may just find that it will need to be modified based on the client work, or perhaps offer it more as an "option" so that you don't always have to be the one by default to host someone's repository
I personally would raise an eyebrow to this. Having a safe place to store your code as you develop is sort of the cost of being a developer, freelance or otherwise. I pay for it myself and just deduct it as a business cost come tax time. If I saw this as a line item, I would think you are trying to nickle and dime me. 
Thank you for your response. I feel that charging my client for storing their source code and not giving it to them sounds shady. But I want to explore all options.
I like your last advice. Adding it as an option if I'm hired to work along side their own developers. I don't think adding a storing fee without another purpose is right since I don't always give out the source code. Are there any other fees you charge?
No but you can use project references loaded into same workspace and it can actually feel like a cleaner separation that way
Kestrel is not designed to used as a front-line server. A robust configuration consists of a reverse proxy with a more full-featured server like apache, nginx, or IIS.
The whole situation you’ve got setup seems strange to me. Generally if someone’s paying you to do programming they typically get the intellectual property rights to it, in which case it becomes their problem to deal with. If on the other hand you call it your IP then it’s entirely your cost to deal with as you are claiming it’s your property. Are your customers aware that you’ve caused them vendor lock-in? Because of your arrangement your customer is left with a take it or leave it situation if they need changes, that means they either dump you completely or you need to make the changes, if you end up being busy on another project you’re going to end up with a really pissed off customer when you can’t deliver to their expectations. Personally I think you should either relinquish the IP and the customer can deal storage or you retain the IP and make a re-sellable product out of it, if the work has no value for resale then just relinquish it. Or at the very least give them a copy in escrow or something.
Absolutely, but I was commenting on the development part. If your code requires https it will take some additional setup. It isn’t as out of the box as VS on windows. I wish it was. 
Visual Studio Team services online??? Free for teams of five or less. Works perfectly for my business....
I would be interested in contributing in a professional capacity if you plan to set up an open-source working group to address this issue. 
Did some research. Looks like you're right. I'll probably give it another go later.
&gt;In order to make sure something like this doesn't happen again I decided to put in my contract a yearly source code storage fee of $120 (github developer subscription) where I would be responsible for the source code. Why does it have to be Github? Not that there's anything wrong with that, but if cost is a concern, there are ways to store your code in source control (remotely or otherwise) that don't cost $120/year. &gt;I do give out source code for a higher hourly rate. Wait, by default you don't give your clients their source code at all? This seems really weird to me, maybe it's just that I've done a lot of work in languages like PHP where you don't really have a choice, but normally it's assumed by default that you don't own the source code, the client does. You're now effectively holding their code hostage if they ever decide to stop working with you, or otherwise want access to the source code of their own product. 
Unless you've very specifically set out an IP retention clause in your contract, the overwhelming majority of freelance work is going to be classified as work for hire. Under work for hire the client owns the source code. Now I am not a lawyer and I'm certainly not your lawyer, but holding onto source like this is both legally questionable and really poor business practice for both you and your clients. You're going to lose a fortune rewriting this code and being legally responsible for holding onto source long term will wipe you out. If it's not shared IP, don't try to restrict it.
In general as an alternative to github you could use gitlab for free private repos. Then you would never have source code storage fees.
Take a look at ngrok as an easy solution for a https proxy. 
Hey no problem! The reason we have a "no code" behind policy is strictly due to the design pattern. We have a Model-View, ViewModel. Just as you touch on you do not want to pollute the UI with things that the UI isn't concerned with. As far as new animations you would probably build a library for yourself and still remain with no code behind. The biggest thing is clear separation of duties and pure Object orientation. When you have no code behind , all of your libraries and classes are modular and robust. They aren't coupled together or piggy back off one another. They work together. The MVVM pattern is very elitist in this aspect. Like I mentioned before you have to have all your ducks in a row when writing strict MVVM stuff. Hope this sheds some light for you!
Thanks mate, that was a great answer. I will try and follow this and will see how i get on. Do you know of any resources that covert this in more detail?
Wait what? My installation detects .sln files appropriately...
would have been nice for this to work over USB, not just local WiFi. I work out of Starbucks and other public WiFi that don't allow hosts to see one another
Unless you have a contract which specifically states you own the source code of the final product, I really doubt you do. Generally speaking as a freelance contractor you're being paid to deliver a product and the source code to it which makes future revisions possible. This could be completely wrong obviously as it 100% depends on the contract you've defined, I'm only calling it out because it's a pretty massive operating assumption. If you do own the source, then you're completely responsible for it's safe storage and you should just build it into your fee. When working with contractors I expect them to be equipped with the tools needed to complete the job. Anything I need to host and run the product is my responsibility, hosting the source would be yours. As I said above though, I think your clients actually own this source in which case I'd say the responsibilities are a bit different. If I were me, I'd have a clause in the contract which states the client needs to provide a repository for their code and/or at the end of each milestone, the code will be stored as a zip file in a location provided by the client (Dropbox/network drive etc). Finally, I'd have another clause which states for your own purposes you will maintain a copy of their code in your own repo while you're still actively working with the client and for at least two years after our last engagement. To wrap up, I'd use Visual Studio Online. You can do git and TFS repos and it's free for an individual like you. 
Awesome, thanks for such an in depth response.
I don't know about support but as long as it works on all Windows versions it will be used. XAML doesn't seem to get much love from MS and UWP is too limiting (Windows 10 only). And throwing together a CRUD in winforms is much faster than xaml imo.
I just played it on Android. Well done! I've never done mobile development. How do you get unity to run on Android?
Can you clarify your question? I'm not sure what you are asking. Are you asking if representational state transfer can be used to expose a queue to a client?
Close. I more or less want a adapter which takes my asp.net core Web-api with, lets say a endpoint called "apples" where you can put/post/get. The adapter know creates a que binding on "apples". Any incoming messages on apples now gets handles as if it would be a http-message to my webservice.
Unless it's a .NET core app, you're out of luck really. Your best bet would be to spin up Windows VM
Thats good to know, just need to be able to tell my boss *something*. 
Windows now have its own docker container images. Not sure if you can run the image on a Mac. Maybe something you can look into 
Your best bet is likely to boot into a windows VM, there are not many applications written to work properly on core yet. Chances are you are running a .NET Framework application. 
To be honest I don't understand your question at all. SignalR via ASP.NET will allow you to push in real time messages to the browser or whatever is consuming the SignalR connection. Those messages could be the messages getting added to RabbitMQ.
$100 an hour? 
If your boss doesn't know this, it might not be a good idea for him to touch anything at all.
&gt; Just to be clear I do use Github for source control but this program was lost somehow. You have to manually type the name of the project to delete a GitHub repo. How did this accidentally happen without your doing? Seems unlikely. 
I have a Web-Api. I have "clients" sending messages to this web-api.1000 - 100.000 messages/s. Mostly short bursts. Most of this messages are post/put messages. As none of these messages are time critical i want to put my clients to put them in a messageque in front of my webservice. i want to know if there is any way to basicly bind my webservice to a messagequeue so it consumes the messagequeue messages as if they where http requests.
What are the operations your queue implementation supports? I.e. enqueue, Dequeue, peek...
You simply inject your message queue into your controller, and add messages to said queue from within the controller action.
RabbitMQ is a normal message que. So all of them? 
Hi. I just realized how uncommon it is to not deliver the source code. Most of my clients right now are Mexican companies and we agree that i will keep the source code but will sell it to them for a higher price which all have agreed so far. My reasoning is that I have my own dlls and knowledge of this niche market that allows me to deliver faster. Most of this work is quoted with a fixed price. I recently moved to the US and by asking here and doing more research I’m changing all my development processes, contracts, and pricing. Reason I wanted to know if it was normal to add that fee. Which from the comments it’s not. 
mhm that would be like this: Client -&gt; Controller -&gt; Queue -&gt; Consumer But what i want is more like this: Client -&gt; Queue -&gt; Consumer -&gt; Controller
No, there is no sane reason to directly expose your queue (RabbitMQ) onto the internet. The controller idea I suggested is better.
Thank you for your advice. Most of my work comes from Mexico right now and I have honestly never delivered source code in the last three years. I realize that this is uncommon and it maybe worked for me because it’s a niche market and it’s Mexico. Definitely will update my contracts and not charge this source code storage fee. 
Nether clients nor queue are running in the internet. All on premise intranet applications, and all server applications. Your idea would mean i would be unable to deploy the api without Rabbit MQ right ? Or i do it like this: Client -&gt; Controller -&gt; Queue -&gt; Consumer -&gt; Controller But thats just all around bad.
What willing the mapping of http actions to queue methods be?
Can it handle machine authentication?
If I am understanding what you're asking, you want your program to intelligently switch between running as a normal REST API that returns a result, and a REST API that dumps requests into a queue to process rather than immediately returning a response? Why not just have your controller/API dump requests into a database and then have the queue iterate over those?
Instead of a VM you could also just bootcamp your mac to run windows, or to dual-boot. Either way you'll still need to get an IDE up and running to compile with.
You're describing bog standard RabbitMQ message passing, aren't you? Your clients publish to a message queue. Another RabbitMQ client, your server, pulls queue messages and uses their payload to call an API (same machine or another). The server-client handles all throttling and API considerations, clients just publish messages. Automagic code reuse in this situation? Not really - prolly some reflection based binding or data contract serialization and generics to get rid of any boiler plate... Odds are you won't have the API surface to care though.
NP :)
Well, around ~ 100 Endpoints unfortunately. So enough to care, but not enough a manual process is out. I just found a api which does exactly what i want(http://restbus.org/). Unfortanly unmaintained.
If you bind your controller to your queue, you would be taking away the async benefit of the queue. You said messages do not need to be processed real time, so this architecture is better: api &gt; controller &gt; queue &gt; ack to client consumer &gt; queue &gt; process A direct connect to your queue would hold the connection open, which is not better than holding the connection open on a traditional web server. 
The routing is normal. The server has to serve the JS so that AngularJS can render the right view. The Multi page application auth seems to mean that they didn't know how to handle auth on the AngularJS side. 
No mapping there. Probably have a look on https://github.com/tenor/RestBus. Thats more or less what i mean.
If you're looking for an easy RabbitMQ library try EasyNetQ. Much more simple to use than standard RabbitMQ libraries. 
Heads up c# was pretty decent in the MVVM pattern. There is also a Heads up design pattern book that is pretty good as well. Try em out!
You can use Parallels. https://www.parallels.com/
With 100 endpoints I'd be a bit surprised if you don't have the reflection/serialization code already written to solve this directly... You have to decide on a messaging layer - is RabbitMQ your ESB? If so you're looking at some core rabbit service nodes, clients push to that, and endpoints resolve by using their names for routing over RabbtiMQ. Think a message envelope with "endpoint name" and "http method" field. The objects generated for WebAPI/RestAPI can be called and used directly for client side for message exchange, which I believe can be called directly using the RabbitMQ .net libraries. On the message handler side you pull from the queues and then use those methods. The restbus project is small enough that upgrading it should be no problem, it's only a year old. Strictly speaking it also solves a different use case than you've described here... I don't know how well suited RabbitMQ is for handling generic HTTP traffic (it's possible, but odd for an 'A to Z' solution), but it is built for handling queueing as you've described here.
We don't. What i am hearing most is "well it did grow naturally". And now it is one of those Systems where doing anything feels like poking a bear with stick. Jep, we want to establish RabbitMQ/ a generic Que as our ESB from where our Customers can Integrate into there respective Systems. Unfortanly our Customers have nearly everything from SAP with different extensions, Microsoft Dynamics, or some obscure systems build just for them. Do you know if there are ESB's better suited for this ? We have a not really low throughput of Data. 1-20 millionen rows/day and. 
How do you expect to use a REST api as a proxy for a data type (queue) which does not support standard CRUD actions without some kind of mapping? For example, GET-&gt;Dequeue, POST-&gt;Enqueue, DELETE-&gt;nothing, PATCH-&gt;remove item from queue and re-add it.
Strongly agree with /u/JoMa4's [comment](https://www.reddit.com/r/dotnet/comments/7m8u77/boss_needs_me_to_make_changes_in_a_dot_net_app/drs64nf/?st=jbo2dnwz&amp;sh=49b1d435). The .NET framework has some...quirks; mostly due to some early snafus or keeping backwards compatibility. And there's a lot of code out there that is very badly written that could cause problems if it's not treated carefully (or re-written by someone who knows what they're poking at). It it's a viable option, you might check what it would cost to pay someone for some 1099 work to make the changes for you. It's not hard to find someone competent in .NET that will do some spot programming work for a modest hourly rate. In my experience, short term indy rates are usually in the range of $50-100/hr with a contract floor in dollars or hours. If you go to a local solutions architect, expect to pay through the ears though.
The Queue saves the Restmessage with the Action as Property in the header. My consumer later comes and gives the request to my controller, and the controller executes the Delete/Post/Delete and returns the result to the queue.
I think you need to go watch some videos on what REST is.
Mhm... Did you have a look on the restbus project ? It explaines/demonstrates pretty good what i want to do.
Well if you have the endpoints you'll have the data objects. Use those as your DTOs and wrap them in a reasonable message envelope before pushing them onto a shared bus. These days I'd take a long hard look at Azure, GCE, and AWS solutions to message queueing. There are a lot of hybrid solutions that can be cost performant, and you've got the scaling story built in... The issue tends not to be the underlying transport mechanism, but more the client connection story. SAP, Dynamics, Bespoke apps... that's not just an issue of messaging, that's generally two way Enterprise Integration Platform to handle the various datatypes. Even then you're left with a fundamental client story around how you're injecting your ESB wrapper code into the clients. Not to mention resilience, which is easy to ensure centralized, but is something you really need baked into client systems. And then, at scale, you're trying to orchestrate the integrations and dependencies in those systems. To be honest I think RabbitMQ is kinda a bad ESB (while being a reasonable solution to that). Regardless you want to be looking at how the clients will be managed over time. If you've already got lots of legacy connections to a SOAP service or whatever, it might be better to 'shard' the endpoints (giving each client a lightweight web API), and route the backends to a shared rabbitMQ cluster for messagehandling.. Kafka will handle the messaging, if that's what you need, but isn't really meant for two way transmission.
Don't worry, this doesn't work for anything except the most basic of apps anyway. You aren't missing anything.
We are pressuring our Customers a bit in the direction of saas or atleast a cloud infrastructure but alot of them are pretty "afraid". The Client connectivity story is a problem we want to tackle later. we are integrated with varius ERP systems, and what we noticed is that we never met multiple customers with the "same" ERP, but all of them with there own customisations. About the 2 way messaging, I am thinking about handling all errors in production(rare) on our side.
No offense, but as it is I would not rate it very well. The game is okay, but very basic. It's more like a "program a platform game in one day" excercise than anything else. Don't misunderstand me, I don't say you should not publish it in the app store, but for the added value of the game the ads are **wayyyy** to intrusive. I'd suggest to release the game without the ads and rather see it as an opportunity to collect feedback, which you incorporate in further versions or your next projects, to create something more unique and worth the ads. As a ballpark: If your game is sophisticated enough that people would pay to get rid of the ads, you can release it for free with ads. 
You need to identify your costs (including asset replacement) and pick a rate that is satisfactory to you and bearable to your customers. Putting something like source code management on the invoice is like listing electricity, coffee and stationary.
Sounds like you need some form of an interceptor pattern. All requests coming into the web API are intercepted by the queue and then the queue eventually forwards that onto the controller method being called. This could perhaps be achieved using a custom attribute filter. The main issue will be what happens to the client while the message is being processed. I would assume a DELETE can't return a 200 if it hasn't been processed yet, unless the client is waiting for a response until the queue item is processed - then you will run the risk of hitting timeout issues and long running requests. 
I provide client all source code and will use their repo if they provide it. If I want a stake I will ask for equity in the company but witholding source code when you have been paid to build it in my mind just isn't worth the hassle. For me having a savvy clued up client is much easier to work with and I feel if I tried to restrict their license based on my rate it would just lead to bad feeling. If you have your own libraries that you don't want to include in the project source then you should create a separate licensing agreement for them.
Then use RestBus?
Thats what i am doing right now. Upgrading it to .net standard 2.0 and .net core. I simply did not find it before i made this thread.
Mhm.. Thats what 202 is for or ? 
Ok, I respect your opinion, it's my first game that helped me to learn the basic techniques of videogame programming, so it's very simple. I will try that the next ones are better and that they are worth paying for removing the ads. Thanks for the advice.
You can download it or buy the engine here: https://unity3d.com/en/get-unity/download and run it in an emulator or compile the apk directly for Android.
If it is .NET Core, then just install the kit and crack on! If it is Framework, you could try mono, but bear in mind that it's not perfect / has some limitations: http://www.mono-project.com/docs/getting-started/install/mac/ Otherwise, bootcamp, or a Windows VM, or Parallels. Also you can code it on whatever OS you want, but building will be the issue. If for some odd reason you can code it on your Mac and build it somewhere else / it doesn't need building then just use your favourite code editor :)
That sir, is an illegal download which is not allowed here
not to disagree with a bunch of people here because all these things are possible but I would really try to boot it natively. my experience debugging and coding from inside vagrant VMs, with the IDE and iis/sql server running inside, is it's a real pain in the ass and slow unless the host machine is a workhorse. even in vmware on a remote machine it can be a bear for a sufficiently large app. if it's a smaller (say &lt;10k lines of code) app then you're probably alright
WCF has this built in for SOAP, but both of those abbreviations are considered evil by so many people these days. I am not aware of a framework that does what you are asking, but sounds simple to implement if you have a standard message class that contains header (HTTP Method and URL) and a body for the payload. Serialize that and put it into the message queue. Your server dequeues the message and uses the header to route to your API controller. Like someone else suggested, I recommend having your clients always call the HTTP endpoint instead of the queue directly and have your server serialize &amp; enqueue the message for a few reasons 1. You can control which clients or messages get queued or processed immediately. You might want to have certain clients prioritized above others for many reasons. 2. You can abstract the queuing mechanism so that it is easy for you to make changes without forcing all clients to change. 3. Easier to enforce the contract of your API from the controller and do input validation to prevent bad messages from getting into your queue. Best luck to you whatever you decide. 
I work on a daily basis using vs code on linux, works great for the stuff I do. No cshtml or tag helpers intelligence though, but I can do without them. 
This is what I do.
If you're contacted by someone to write code for them, they own Copyright on the source. There's no way around that. If you provide the code to them it's up to them to store it securely. If they want you to store it securely on their behalf then indeed you can charge them for it, that's your prerogative. I store everything for my clients, but it's a value added service that I don't charge for. I don't treat my business like McDonald's with up size options, but it's totally up to you what you do.
"I DO THINGS THE HARD WAY!"
Thank you for your answer. You are totally right and I've learned that I do implement some bad practices. It is in our initial agreement that I will keep the source code. All my clients are ok with that and till this day none of them have complained. It definitely works in my advantage but it also makes me responsible for storing and keep their source code safe. I din't have specified in my contract that I would so when I lost the source code for a small app valued in maybe $800 I was thinking that I could be a dick and not be responsible and charge my client for rebuilding it. But after consulting reddit I decided to rebuild it for free and charge them on the modifications. After this I decided to add in my contract that I would be responsible for the source code, and though that maybe I should charge for this responsibility. But I've learned that I shouldn't.
Yes. I've recently increased my rates.
Yeah it's definitely wrong and I don't think my clients would be happy with that. I decided that I shouldn't charge them for that if I'm not delivering source code.
I remember doing some cleanup and moving repos sometime last year. I't could've been deleted there. I honestly don't know.
Two approaches, you can either use HTTP but instead if executing the action right away, just add it as a background task with Hangfire or a similar library. Or you could just use have some consumers and then have a json payload that includes the api call to make. Create an instance of the appropriate controller (https://stackoverflow.com/questions/1481565/string-url-to-routevaluedictionary), and then either hook into Mvcs parameter binding or just deserialize everything yourself using the JsonSerializer. Reflection would be used to invoke the method with the right parameters. Your big problem here is going to be application lifetimes I think. From what I remember, an exception in a thread that's not a worker thread from IIS could shut down your whole application. Not only that, but you have to deal with idle timeouts, resource congestion, or any other situations that can cause your consumer to stop processing. You could look at how Hangfire avoids this (they have some info about it), or you could just not use IIS in the first place. You're not actually using HTTP after all, so unless you're using request data or such, you could make a console application that references your asp.net program containing all your controllers and just invokes them there.
Yeah man that's fair. And since i don't know where you're from I couldn't speculate on your laws, but here we must be careful about statutory something blah blah (really can't remember the name, but it's to do with our consumer guarantees act and contract laws), basically meaning that if I hold/control someone else's property I must ensure I keep it secure and safe, regardless of whether there is an agreement or not. There are many loopholes, but this country does a lot to protect people from each other and themselves. Ymmv of course.
You say your Boss wants you to make changes. Here are a few things that come to mind: 1. Is this a Windows shop? 2. If not, was this done by an outside company? 3. Why is he asking you? &lt;-- Don't take this the wrong way. 4. You have a Mac, why is he asking you? 5. How much .NET experience do you have? 6. Is this a "production" application? 7. How much time do you have to make the changes? Many of the answers below are viable, but for me #3 above is a big question coupled with question #6. If this is an exercise for you to learn .NET then the VM method is a good way to go. If #6 is yes, #7 is less than forever and #5 is not much than there is a bigger problem that is not your problem.
Was the .sln file created with VS 2017? Generating .sln files from "dotnet new solution" generates VS 2015 solution file.
The .NET story around globalization is really lacking. I've done message lookup from databases for a web application before; the amount of traffic can be insane, especially if you don't optimize the lookup (and with 10,000 entries in 50 languages, I think you'll immediately be there). We'll be replacing our globalization solution soon; my thought is to replace it with a JSON file that I can load all of the messages from (and we can push the updates from a centralized web service that way). For unit testing, I don't see any reason why it should take several seconds to mock the dependency. Perhaps your mocking framework is to blame? Constructor injection itself is cheap.
&gt; If you're contacted by someone to write code for them, they own Copyright on the source. There's no way around that IANAL, but this is not strictly true in the US and "work fore hire" situations are not that simple. &gt; ... a work for hire is not created merely because parties to an agreement state that the work is a work for hire. It is an exception to the general rule that the person who actually creates a work is the legally recognized author of that work [From Wikipedia](https://en.wikipedia.org/wiki/Work_for_hire) as a starting point.
**Work for hire** In the copyright law of the United States, a work made for hire (work for hire or WFH) is a work subject to copyright that is created by an employee as part of his job, or some limited types of works for which all parties agree in writing to the WFH designation. Work for hire is a statutorily defined term (17 U.S.C. § 101), so a work for hire is not created merely because parties to an agreement state that the work is a work for hire. It is an exception to the general rule that the person who actually creates a work is the legally recognized author of that work. According to copyright law in the United States and certain other copyright jurisdictions, if a work is "made for hire", the employer—not the employee—is considered the legal author. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/dotnet/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^| [^Donate](https://www.reddit.com/r/WikiTextBot/wiki/donate) ^] ^Downvote ^to ^remove ^| ^v0.28
So you personally deleted the repo, accidentally. How would charging your client $120 prevent you from doing this in the future? Personally, I think it’s ridiculous to charge for something like this. Especially AFTER you lost their source code in the first place. If you lost my code, there is no chance I would pay you to store it after that. 
Windows containers can only run on windows hosts I believe.
While performance won’t be ideal he’s better off trying to get this app in a running state (if he can) in a Windows environment just for simplicity at this point since he’s not primarily a .Net dev. 
I second this. Private, secure, the web UI is decent for tracking changes, and tight integration with visual studio is a huge plus.
I say if you've got existing clients willing to dole out more for the source code, so be it. Just don't paint yourself into a corner by making that something mandatory. If you are negotiating a deal with a customer you need to be clear in the beginning whether their intent is to obtain the code afterwards or not. I think this is a very common practice where a business hires a developer to basically offload work they don't have time for, and then they expect to be able to iterate on that work in the future... not be locked out of it because they didn't pay for access (or worse, be told at the end they have to pay an extra fee that was in the fine print).
When you say a JSON file, would it be loaded into memory in the web service and just accessed as needed, or would you start/stop a read to the flat file every time its needed?
yeah definitely agree with that
The problem you're going to encounter is basically this. No one is going to pay you an ongoing source storage fee, but storing source code is not free and not storing source code, as you're about to find out, is very, very expensive. You need to either make storing the code their problem (you can offer to do it for them as a separate service if you feel comfortahle with that, though you'll need to factor liability into that) or you need to move to a licensing model rather than work for hire so that they have to keep paying you an ongoing cost. Generally speaking, if you're doing bespoke one off work it's going to be hard to find customers willing pay you licensing and development cost and it's going to be hard to make money and provide support and maintenance for a licensed product. If you're not selling it to multiple people it's not worth owning, so make it the client's problem. Right now it's your problem and you're going to realise just how big it is shortly. Rebuilding an existing production system that the client is happy with is just about one of the most horrible experiences in development work. Rebuilding one that the client didn't want rebuilt in the first place and only has to because you screwed up is going to be much, much worse. Best case scenario you do a lot of work for free and probably lose the client anyway. Worst case you have some sort of liability. Beyond all that though, make sure you find the money to talk to an actual lawyer about your contracts and this case if you can. Maybe an accountant too Presuming you're not in Mexico international contracts are tricky business.
Oh, I didn't know that. I did use `dotnet new sln` to make it. I'm actually more familiar with .NET Core and only use VS 2017 at my work. Are VS 2015 solutions not compatible with VS 2017?
Assuming your files are local to the machine (i.e not a mapped fileshare or something) then settings g up a filesystem watcher to read the updated file and update the cache is pretty simple.
jep wcf/soap is out for political reasons. 2. is a really good point, did not think about that till now. mhm... probably i am just to scared to tackle the scaling problems for the http endpoint.
You could implement a custom MembershipProvider and use Forms Authentication. If you don't need things like password reset then just throw Not Implemented in those method overrides
Sorry for not answering your question but I do have to ask this: Does it actually contain the password? If that's the case you might want to consider changing it.
Hey there. Signed up with AWS last night and decided that that's the way I'm going to go. Just wondering if you had to use the Lambda Serverless thing, or if you can somehow deploy a .NET Core API directly to AWS?
Well, if I have understood you right, you want to do it this way. Accepting post and putting request at the queue return successful code if the message is valid. After that request is got from queue and processed. I'm not sure you can do validation, but you definitely can store plain http messages in the queue and after that resend it to your API. It seemed to be an architecture problem because you have messed up presentation and business layers. In case you haven't messed them, you should use your presentation layer in front of queue and have possibility to get requests from different places for processing
I was pretty sure that this was all fixed with ASP.NET Core 2. You should be able to use the same UseHttps Kestrel option for all platforms.
It is more of a pain, but breaking up your translations across multiple resx files will help a lot if speed is a concern. Try keeping common ones in a common file, though. The big issue is that reading resx files gets exponentially slower. It isn't a straight degrade.
Yes, but, in order to do this you have to change the code and provide it the certificates to use. I’m in an environment where doing so would not be accepted. 
If you want Kestrel to do HTTPS on Windows you’ll also need provide it a certificate. How does that differ from Linux exactly?