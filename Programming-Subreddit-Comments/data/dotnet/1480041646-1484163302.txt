holy balls that was easy and super effective. Thanks dude!
MVC5 AFAIK requires system.web so it can't be hosted on Owin. Nancy can be. You might be able to use MVC5 with IIS Express without installing it/running it from the command line (it's an unsupported deployment method).
Their WPF stuff is very questionable a lot of the time though.
I thought they removed the primary constructors again?
Recommend going to university and getting a degree. Don't choose any of the online university like university of Phoenix, etc. Find something better, even a state university will work. Stay with your parents for 4 year during university and move out when you get your first job that would pay double of what you are mentioning in your post. 
[OzCode](https://marketplace.visualstudio.com/items?itemName=CodeValueLtd.OzCode) - Can't imagine myself deubbing without it.
Really? I've found devexpress(web forms/mvc) components to be overly bloaty. At most some components are okay. 
That's also the solution to a number of other problems. Whenever I start seeing plugins randomly failing, even "built-in" ones, that's one of the first things I do.
I recommend Telerik. Which ever you go with, don't use the VS extensions. Just reference the raw binaries.
&gt;9) as and is-operators If you need to use this, you are not modeling correctly
Really slow loading times
That's what I thought when I first read about the feature.
Yea, but I think a many people are going to use it the wrong way, it conflicts with the concept of polymorphism
It might be worth comparing an XDocument version too. https://msdn.microsoft.com/en-us/library/system.xml.linq.xdocument(v=vs.110).aspx http://stackoverflow.com/questions/4383919/performance-xdocument-versus-xmldocument 
My number 1 problem with their WPF stuff is their theming. Their out of the box themes are okay, but if you ever need to tweak anything you are stuck either using the incredibly horrible theme editor to make an entirely new custom theme or you have to replace a huge control template. That's not all, then during upgrades your new theme or template are constantly breaking. There's a lot of other stuff too that just doesn't follow the standard WPF way of doing things. For example they expose might expose properties for left, right, top, and bottom margin separately while the regular margin property does nothing. I've also seen margins being used for border thicknesses. I would definitely check out Telerik, Syncfusion, etc. before diving into DevEx and compare more than just the out of this box experience when needing to maintain upgrades and tweak controls.
Debug it while its running in VS and pause it when it seems unresponsive, see what its idling on.
thanks for the suggestion, this is what i do now. I was hoping to find something more detailed. 
I moved my company off Telerik in favor of DX. There ya go.
I don't run into those bugs personally. YMMV I suppose And I'm fairly okay with modifying their existing themes to my needs. I typically use mulberry and a modified palette. I've also got a "mullberrysmall" with just less padding. You might think it over bearing, and it can certainly be, but it's also powerful when you get the hang of it. I've been using it for just a short time longer than you. About 7.5. 
My only beef with class initilaizers is that properties must have a public setter. I can't make them private, and I can't make them read only. I hate having to compromise on good design for convenience.
Ya, with Tree view and stuff, it is hard.
&gt; loops to LINQ (not always a good idea) This is my number one bugbear. Just because R# tells you to do it, does not mean it is a good idea! It is a suggestion. I have seen some horrendously slow code because someone changed a `foreach` into `LINQ`. People just blindly follow the squiggles.
No effect for me, actually had to rebuild my solution so it was slower to open next time. Worth a shot anyway, thanks!
Wakatime is what I use. Gives a really nice breakdown
I don't know if you're aware that MSBuild is now open-source, JSON came during the while that it wasn't. Not only that, I've been using Preview 3 in VSCode and it works equally as fast. 
I'm not sure what compromise you are referring to. A class can explicitly describe what information is _required_ to construct an object of its type. The key word there is _required_; it is not possible to create an instance of this class without providing the requisite information. If you want to allow additional, _optional_, configuration of that object, you expose properties that have a default value. You can set these properties to _initialize_ the object, but they are not required to _construct_ the object, otherwise they would be included in the constructor. See the difference? An arbitrary example is a PrintJob object. The ctor requires a list of pages to print, but setting the orientation is optional. If you don't set it explicitly to landscape, it will default to portrait. This is therefore not necessary information to construct a PrintJob. 
Damn dude, this looks like what i need!! thanks a bunch:) 
Thanks for the suggestion!
thanks!
Thanks! This is looking good. I can't believe that I have never come across this up until now :)
Yep, Windows, Ubuntu and Mac are supported. https://github.com/Microsoft/msbuild
[Did you uninstall previous Xamarin versions?](https://www.visualstudio.com/en-us/news/releasenotes/vs2017-relnotes#KIXamarin) It's important to note that Xamarin is still in [preview for VS2017](https://developer.xamarin.com/releases/vs/xamarin.vs_4/xamarin.vs_4.3/) and Microsoft does not recommend using it in a [production environment](https://www.visualstudio.com/en-us/news/releasenotes/vs2017-relnotes). I highly suggest you report the issue and downgrade back to VS2015, **specially** if it's for work. 
Have they at least cleaned up the structure of csproj files? They're not impossible to work with but it seems like a lot of them have a superfluous number of nodes.
It's an on-going effort. The initial structure is not final. Right now it's riddled with itemgroups, etc..
MVC and Angular are simply two different things. MVC is a server-side framework that generates HTML for the client with some support for asynchronous operations (i.e.: you don't necessarily have to refresh the whole page to update it). Angular is a client-side framework with no opinions about server-side frameworks. As such, it's vastly more capable and flexible for client development than MVC. It has an entirely different development and operational paradigm referred to half-jokingly as 'thin server'. Think of it as a thick .NET client, except it's written in JavaScript and an alphabet soup of supporting libraries, and is (probably) sent to the client each time you refresh your browser. Most of the action happens on the client, with the server there to do data. (Angular + MVC/Web API is actually a pretty good architecture, IMO, except for the fact that the tricky client stuff needs to be written in JavaScript). If you are writing quick and ready thin client apps, MVC is the way to go. For rich, dynamic, highly functional apps with tons of user interaction, consider Angular with Web API. Here's the kicker though: you're not wrong about the complexity. If you're an enterprise .NET developer who is used to a mature, integrated, rock-solid toolchain, HTML/CSS/JavaScript development will feel to you like a bag of cats. And the bag is on fire.
It's very much cleaned up, yes.
Man for at least half of the year I have been in same situation as OP. And when I finally got it, I realised exactly same thing you described. Damn 
Me too, sort of. I used to do thick client dev on .NET but stepped away for a bunch of years and exclusively built services and backend processes. Then when I came back to client dev I sort of felt like a guy emerging from a cave after a hundred years and wondering who nuked the world ;)
&gt; If you're an enterprise .NET developer who is used to a mature, integrated, rock-solid toolchain, HTML/CSS/JavaScript development will feel to you like a bag of cats. And the bag is on fire. My experience for the last three weeks 
&gt;have a hard time buying into Angular2 over my warm &amp; cozy ASP.Net MVC blanket They're not mutually exclusive. You can have an MVC site serving pages, but then add in angular2 for running interactivity and validation on the client side, perhaps doing things like autocomplete etc by calling back against the api for your site. If you are talking about node, then sure that's a server side replacement (unless it's just being used to compile parts of the solution). But nobody said you had to do that. 
Imo asp.net mvc is pointless if you go angular. I really like using web api back end with an all angular front. It may not seem necessary at first to have an api but at some point in the future something always seems to come up and I'm glad I did it this way.
Can you give an example of why you need millions of scheduled jobs? Would a message queue be better, or both in combination?
Well probably because you can't write native Web apps with .NET
What goes in this folder? My folder(s) were fairly empty except for the .cache file which was less than a megabyte. 
And as someone who was there in the mid/late 90s with the browser wars and hilariously incompatible JS implementations, I have acquired a severe mental block to anything JavaScript. To me it’s the Devil’s invention expressly designed to drive developers insane.
Unless there is a compelling business case, why? Personally, I would rather not double development time and quadruple the complexity and opportunity for flaws just so I can say I’m using the current client-side shiny *du jour*. Anything internal to the company is going to have a fat pipe anyhow, and running things on the server ensures that security is simple, robust and under the thumbs of the sysadmins. Personally, fuck anything client side, it’s all an insane herd of cats that are crazier than a bag of hammers.
I mean almost certainly WebAPI is the way to go for most of it if you're doing ng but it's pretty common to use MVC to just bundle all the scripts and stuff.
A million customers setting up monthly/weekly recurring e-Transfer, on different days/times etc...
Yeah.. personally I'm just going to stop tinkering soon and bite the bullet and do a proper job of learning JavaScript/Angular/TypeScript from the ground up.
It didn't use to and the MVC stuff works just as well.
Yeah but... You can do that in .NET very easily too. 
Alternatively, I'm considering storing cron syntax in a table, and using a stored proc to calculate "next run date". Not sure how easy that is or if there are available t-SQL compatible packages to calculate that.
Angular 2 is made for SPAs. If you are *not* making application in SPA+ WebApi format, then angular2 is not for you. (Even if you are making an SPA, you might want to look at embar, aurelia, react, and vue before starting angular2)
the navigation header looks bad on android mobile btw
I hadn't realised they weren't going to "backport" it, that's very irritating... Sorry, it sounded like nonsense on first read seeing as there are already tools for VS2015 :(
The answer is usually no when it comes to statements ending with a question mark.
Core is The Future(tm) but is far from complete in implementing the entire .NET ecosystem. I wouldn't recommend it for learning C#. .NET proper is mature and therefore it's easy to find tutorials, answers to common questions, etc.
Just to clarify: It's the same C# you're using - Core vs. framework is only a question of libraries. If you're just learning C#, it'll probably be some time before you put anything in production, so you can afford to experiment and be completely up-to-date. On the other hand, you will encounter less bugs with the framework if you stick to classic. So, from a learning perspective go for classic, since it'll give you the fewest headaches. Once you have a solid grasp of the basics, switch to Core since that's what you'll use once you're ready for actual work.
no
I was trying to run a game **Deus Ex Mankind Divided** and it crashes on the startup i have only **Dot Net Framework 4.5.2** installed and i thought maybe it crashes because i don't have the **Dot Net Framework 4.0**
4.5 is an in-place replacement for 4.0. You should no longer install 4.0 as it's no longer supported at all. Apps that run on 4.0 should run on 4.5 as good if not better (better GC) without changing anything.
Nah you'll be ok :) https://blogs.msdn.microsoft.com/webdev/2015/04/30/updates-for-asp-net-4-6-web-forms-mvc-5-web-api-2/
my vs2015 is still slow...still blaming resharper. To me it seems ReSharper has gone down hill in terms of performance over the years. If I disable it, my VS speeds up a ton. I wish there was a decent comparison between CodeRush and ReSharper (latest versions of both)
Im an amateur and i picked up core pretty. People are right in that you dont get as much online help as you would with dotnet although you'll learn how to solve problems yourself instead of coping code from stack overflow. You'll also have a good understanding of your code too because you did it yourself. For learning I recommend core but if you building a larger solution for maybe a company go with dot net as its fully supported and you'll save time having to learn and experiment. 
It's going to be trash, agreed, but it now becomes whether something will get done or not and the fewer concepts involved, the more likely something will be smushed together that meets the requirements.
I have such a hard time even getting _into_ it. So many frameworks, often so-so documented with samples and communities. So many ways to cobble them together with some toolchain. Then when you have done so, you discover there are many different toolchains too. What T Fuck. :| I'm exhaused before I have even begun. Sometimes I've started a Hello World, watching npm pull 200 MB of files into my "starter project", choking on some messed up version dependency that is out of my control. Sure enough, on GitHub the broken dependency is reported, awaiting reply from the single lead developer. I don't understand why it has to be like this. Or well, sure, I do in a way, it's because of organic growth, extreme and fast organic growth and more interconnections between projects than you have synapses in your brain, but... I think I'd rather take some coherent way of reaching both the client via a client-side framework and server from the same company. Imagine the reduction in complexity if the tools and frameworks could start assuming a lot about each other.
I have a nice ASP.Net MVC(VM) SPA with knockoutJs &amp; pager today. How is ng2, with all it's NPM bloat, for me?
Well, I think Win32 can't just die, because there will always be low level stuff that needs it, but for any business application, yes, the future is UWP.
If I'm not mistaken, they are going to allow Win32 apps in the next version of Windows Phone. 
Those are rumors. Until I see an announcement by Microsoft I'm not believing it.
Too soon. Even if there is an official announcement, don't believe it until it actually ships. 
Most people have MSDN subscription, allowing access to latest versions of Visual Studio. 
I hope they will spit out .csproj/xproj files in the same sequence of nodes.. that way, I can use beyond compare against them.
&gt; PropertyGroup, ItemGroup I thought [the purpose behind them](http://rationalgeek.com/blog/msbuild-propertygroup-itemgroup-item-metadata-and-crazy-syntax/) is a valid one. 
You can also inject name/value pairs into JSON for documentation and hopefully unknown pairs are simply ignored. My favorite thing about XML is mixing multiple schemas together.. rarely used these days.
Nice. I didn't think it was so easy. I haven't dug too deep into the built in bundling and minification.
This is a good start https://www.asp.net/mvc/overview/getting-started/introduction/getting-started
Cool!
I would consider .NET Core as that is the future. Using both .NET and .NET core my biggest tripping point are the namespace changes. If you start in .NET Core and never look at .NET you wont have that issue.
Be very, very careful with this point: "Keep your services small." This is exactly how Uber got to 1000+ microservices, and no one wants to end up in that situation. Group your services by domain, but don't keep them too small, otherwise you'll start to wonder "does function X go in service A or service B?" I would also add: make sure every single request and event going through your system has a "correlation ID" attached to it. That way, you can search through your logs and see every single event that happened related to a particular HTTP request from the user.
Valid point, so that'd be small in terms of focusing on a single domain e.g. users or payments which under the hood may deal with a lot of complex business logic. Speaking of the "correlation ID" that's exactly what I do by having a separate service that subscribes to all of the commands and events in order to keep track of their state :).
Even better: [canopy](http://lefthandedgoat.github.io/canopy/).
Does not support .NET Core.
Yeah, neither do any F# tools but there is an active effort behind making it work.
Did you restart? Can you upload the folder? Sounds like something is very off.
ASP.NET MVC 5 != ASP.NET Core (former ASP.NET 5)
I did try that. I can try it again, but it didn't work before.. Still nothing, this is definitely strange, most likely an issue with .NET 4.5, because it worked in 3.5... darn
Whoa, git history is amazing! I've been using sourcetree specifically for the tree but now it looks like I can go standalone code
I did restart Code and the machine. I have since deleted(three times now) the folder but I will recreate today and send a link.
Yes all the seed data is in code. So I've been reading about generating sql files. Instead of running the seed data by code, you can generate a .sql file is that correct? Then you can run the .sql file in sql server? Running the .sql file in sql server will generate the DB much faster?
We want to seed a lot of data for our clients. It's much more than enum fields. Basically, every table in our DB has a few rows of sample data. We have a lot of tables. Also, yes we are inserting one row at a time. I'll looking into bulk insert.
Before you go doing all that it might be important to ask yourself why is 30 minutes an issue to seed the DB? Are you guys spinning up a lot of new instances in which case yeah 30 mins sucks, but if this is something you had to do once and got curious why it took so long it might not be worth the effort of porting and the loss of dynamics code generation can give you or just the time it takes to look into when you could be doing something else. That being said, as per your actual question, you can make sure you guys are calling SaveChanges() only once or every so often rather than for each record and check into `ValidateOnSaveEnabled` and `AutoDetectChangesEnabled` or this https://efbulkinsert.codeplex.com/
I haven't used it, just found it in a project we inherited DbMigration::SqlFile
Anytime dude. You should be proud of it - awesome work!
It's fantastic, man. So simple to use and so effective. Thank you!!
On my last project the source was pretty heavily “corrupted” in that there had been no serious data validation on the original data. Plus the use of `nchar` fields that had been implemented loooong after `nvarchar` became available. When it came time to import I couldn’t just SQL the shit, I actually had to run C# that did the import because it had to massage the data six ways to Sunday. And even then about 2-5% of the data didn’t make it in because it was actually missing critical information that was supposed to fill non-nullable fields. That import took almost eight hours. Yeah, fuck me, right? I had so many if/else forks and case switches that it took every complete record almost 5 seconds to insert across 6 tables. The import script was almost a small program in of itself. Now, if you are working with seeded test data that is identical across all setups, and if the database structure is identical with each setup, why not just seed in only one DB and overwrite the other empty ones with it? I doubt this is the case, but hey.
How often are you newing up a DbContext? EF grinds to a halt if you're working with a large number (1000+) of records through a single context instance. It's counterintuitive but try using a new DbContext for each table or handful of tables. How often are you spinning up new instances? For day-to-day dev work that causes schema changes could you be doing updates instead of having to deploy and seed a whole new instance?
We are using a single context. We spin up new instances every two weeks. For day-to-day, it's not too bad because it usually takes a couple of minutes. However, for some reason it takes much longer (30 minutes) when making a deployment. I was told because of the network traffic? We use octopus deploy.
Microsoft Virtual Academy has some good video series. C# - https://mva.microsoft.com/en-US/training-courses/c-fundamentals-for-absolute-beginners-16169?l=Lvld4EQIC_2706218949 MVC - https://mva.microsoft.com/en-US/training-courses/introduction-to-asp-net-mvc-8322?l=mNEz7Aay_4804984382 I tried the main MVC course on Udemy but I found he moved way too fast and didn't explain the basic concepts very well. The second video series above is relatively short but the guys explain what MVC is quite well.
Just published this package, would love any feedback (comments, complaints, suggestions for improvement, etc.)
&gt; How many gigs of data are you pushing? How fat is your pipe to the deployment target? If doing the exact same deployment locally is much faster than to live that would lead me to the same conclusion. Honestly not sure. That's one area I'm not really familiar with is how exactly the deployment works. 
 Sorry, I mean using VS Code for everything, as opposed to other tools
I presume this is from the HomeForm class. If the method is `static` it won't be able to access the controls on the firm. 
If you want "full-stack" or architect in your future, learn those tools. If you choose to leave DevOPs and deployment up to some other nerd(s), then you can keep your head in the sand and your salary commensurate. If you're building multiple applications on multiple platforms (ASP.Net, WinServices, Class libs, etc...) and deploying them across a bevy of environments, PowerShell is a much preferred tool and adopted by all the top tier configuration management vendors. If you need to know everything from available addresses &amp; ports to machine specs and every asset installed on every server from dev to production. Keeping all that straight and precise is work. PowerShell helps that tremendously.
I think every .NET dev should get familiar. Yes, it is a shell, but it's ALSO a complete .NET scripting language that has access to any .NET code you have, and the entire gamut of the .NET ecosystem. That is HUGE, and it handles data passing as Objects instead of string based like Bash, etc. do, which makes it easier to do a lot of things IMO. The choices for scripting some small but complex operations as a .NET dev are basically a console app, with all of the architecture that comes along with that, and a single file Powershell script (Or, increasingly, Node.js, as it is becoming a defacto standard piece of web development workflows with first class support in VS, etc.). When I'd use Powershell scripts over a console app tend to be around complexity concerns. A single file script, or even multiple strung together, tends to be LESS complex than console app that requires building, etc. Where it has excelled for me: 1. Build and deployment scripts. I'm sorry, MSBuild and NAnt, and other declarative XML based build scripts are a fucking nightmare. As soon as you get outside of "the tool generated this for me", give me code every time. 2. One off throw away scripts. These are things where I don't care about the code or how good it is, I only care about the output of running it a few times, and then its dead. I might go either way here, just depends on my mood or how much .NET specific stuff I need, but I'd try the lightweight Powershell route first. 3. Utility scripts. You will almost always have these, and hands down this is Powershell territory for me. Could be something like "populate a bunch of test data", "clean out the logs", "make nuget package", etc. It's a great tool to know, though probably not crucial at all. Once you learn it though, the idea of spinning up an entire application for those one off tasks starts looking more cumbersome.
I use it daily with TC, Octopus, VSTS and monitoring servers. 
Running VS in such environment is not always an option, but another option would be to take a full memory dump using process explorer and load that into Visual Studio or WinDbg.
Seeding production at all seems like a weird thing... 
Thanks for the videos.
That is a pretty bold thing to say
I use it daily to do these things: Clearing internet cache, Lookups in SQL databases, Run Stored Procedures, Connect RDP automatically, bring text into my clipboard, Search multiple text files. My personal mantra is ["If you repeat it, Powershell it"](https://pcast01.github.io/get-started-with-Powershell/) Anything I have to do more then once I use Powershell to automate it. Powershell is a quick way to use .Net right away without opening up Visual Studio. 
It just gives you an easy way of implementing functionality with a switch, depending in which kind of object it is
Some do feel a bit like "do it because it's new!". They're not battle-proven yet. We'll see.
well then it's not prod.... it's SIT or PREPROD
what's sit if you don't mind me asking?
On top of all these comments, check your DB indexes. Bad / too many indexes will cause inserts to happen more and more slowly as the tables fill with data. Too few indexes will cause reading data to slow down. And you should be checking your fragmentation periodically and doing index rebuilds if it's too high. 
I stand corrected -- figured Germany had a similar cost of living to the US
Code-first migrations are really meant for tiny, file-orientated databases like SQLite. Yes they 'work' with SQL Server, but they are a really bad idea. *** That aside, EF is the second slowest ORM available for C# (the slowest being NHibernate). If you want to quickly populate tables, you should be using bulk inserts via the `SqlBulkCopy` class. Or if not that (but seriously, use that), at least a faster ORM. *** If you must use EF, make sure you are saving after every 100 records (test and adjust as needed). If you try to save all the records at once, EF will choke on adding the records to the data context's collection. As in you will be seriously CPU-bound long before you hit the database. http://stackoverflow.com/questions/5940225/fastest-way-of-inserting-in-entity-framework Also set AutoDetectChangesEnabled = false and recreateContext = true as per the instructions in the link.
Judging by: - https://www.numbeo.com/cost-of-living/gmaps_rankings.jsp - https://www.expatistan.com/cost-of-living/index the cost of living seems to be somewhere inbetween the expensive US cities and the cheap ones. It's just that a job as a developer in Germany won't make you rich. It won't make you upper middle class. It's just an average job. A bad country for an IT career. Keep in mind that income inequality is super low in Germany. All salaries are grouped very tightly together. Earning 100k? Lol you are rich. https://en.wikipedia.org/wiki/List_of_countries_by_income_equality For Americans working in the IT sector looking to live in Germany we have a rule: Divide your salary by two and if you're feeling lucky add a little bit. That's probably a good expectation. edit: while the cost of living is comparable, it might be noteworthy that the standard of living is probably not. Germans don't buy houses, the majority rent. And if they do, then only once in their life. Not like in the US where people buy multiple ones throughout their life. (the concept of a "starter house" blew my mind). Also not as many expensive cars. Lots of people actually don't buy a car, they get one from their employer (company registered cars are more common than privately registered cars in Germany).
Generally, yes. But it's a simple query to see how fragmented your indexes are. MS recommends rebuilds around 30%, and that doesn't come around often. It also depends on your data. Indexes across guid columns tend to get fragmented quickly just by their random nature, numbers and dates tend to increment organically so they fragment less. 
Cool, thanks
If you are using sql server you should look into using datpacs. It was designed for this type situation, https://msdn.microsoft.com/en-us/library/ee210546.aspx
I would start with regular old .Net and then learn about .Net Core down the line. 
Bulk insert has significantly more overhead and may actually be slower than single inserts if there's not enough volume in the table. Benchmark everything.
Guid columns with database generated guids are generally free from fragmentation (or I've been lied to). What I most commonly see is indexes on CreatedByUserKey/UpdatedByUserKey. They fragment quickly and most of them are never used in queries.
Sounds like a really long time to run. I haven't done EF migrations much myself so I may be off-base. I'd imagine you could possibly make any schema changes in code-first and data changes with pure SQL scripts. This would surely be faster than having the extra EF layer in the middle. I'd possibly look into using another method for DB updates. We use RoundhousE for all our schema and data changes and it's hella fast. We can deploy database changes to our 250GB prod database in about 5 minutes. We also push the deployments out with Octopus to all our environments so anyone can do it.
Thanks, sounds good, does this allow me to start with a website?
Then you need to make that clear. I am sure that you can achieve those with existing libraries, if you library makes that easier then show a before/after example.
The amount of times the author kept misspelling "yeoman". 
&gt;People who use relational DBs in production use stored procedures. While this may be the vast majority of cases, it is not *all* the cases. I certainly can imagine green-field projects not caring about not having SPs. Plus there's nothing stopping you from using EF for generated queries and Dapper or some other way to call the SPs.
Are you familiar with sql server? I just tried profiling the seed process using sql server profiling and it said the whole process took 6.5 seconds even though I sat there for a few minutes waiting for it to finish. 
Familiar, but it's been about 5 years since I've used it. I would do your profiling on the C# side first, since that's very likely where the bottleneck is. Reading your other posts, is the sample data client-specific? Any chance you could restore a backup of the entire database with the seed data already loaded? Or at least use that as a starting point, if some data does need to be modified.
The closest thing they have to a sale is the BizSpark/DreamSpark programs. But that's mostly for people who don't already have a subscription.
There is built-in functionality for this. https://msdn.microsoft.com/en-us/library/zhhddkxy.aspx
Yeah, unfortunately I've never heard of any type of sale before. For my personal usage, I've been fine with Community and Express editions of their software for .Net development but I'm assuming you're talking about a more enterprise type of setup. 
No. The tooling and some of the advanced features (many-to many joins, multiple resultsets, optimized queries) are still in Beta.
&gt; get a subscription for free by becoming MVP. I've been buying MSDN for 20 years now, ack. I probably should become an MVP. 
Yeah I thought about that initially, but I still couldn't come up with something elegant using RowDetails. I should try to do it with RowDetails though, I will take another stab at it, thanks!
Thanks for this!
so far as i know, only this https://www.frozenmountain.com/products/icelink/features
So you generate a XML with an invalid XSD? How would that make the XML it generated valid?
Awesome - and this todo app tutorial is relatively up to date? Sounds like a perfect fit. If you have any other advice for me going in, I'd appreciate it, but thanks so much for your help already :)
&gt; When VS 2017 asks you if you want to install WPF for example, that takes like 5 GB or mor Don't forget that Blend will be part of that 5 GB
If you target tge full framework instead of core, you're marrying to windows. You won't be able to run it anywhere else.
Bizspark is well worth investigating - you'll need to look at their qualifying criteria and see if you can wiggle yourself in somehow, though. I initially got refused, but plead my case and was given a code to sign up with.
.NET Core uses Roselyn, it's not compatible with Mono
Figured this out.
I've run .NET Core on Ubuntu but not tried running it under Mono however you can certainly run ASP.NET MVC 5 on Mono. I have production apps using it. Check out my blog [here](http://coderscoffeehouse.com/tech/2016/01/19/aspnet-linux-setup.html) where I have a few tutorials on everything you need.
This is great stuff! My only issue is that the web tier has direct access to Entity Framework. It's generally not good practice to that, but sometimes it is more effort than necessary to add a layer of abstraction.
Actually, I've just built a .NET Core Console app on top of net451/win7-x86 and it ran on mono/x86 smoothly. Now even **the web project ran** with a few modifications. Didn't show any errors, but I **couldn't access** the website on my browser after all. Any ideas?
Does this also work for Google Home?
Just curious, what about these two: - [Learning Visual F# 4.0 Foundations Vol 1](https://www.amazon.ca/dp/1537049968/) - [Learning Visual F# 4.0 Foundations Vol 2](https://www.amazon.ca/dp/1537312022) Has anyone had experience with these two books, particularly in comparison against the [Expert F# 4.0](https://www.amazon.ca/dp/1484207416) book mentioned in the article?
I don't believe so.
Quick &amp; Dirty: 1 x Azure App Service 1 x Git repository See: https://docs.microsoft.com/en-us/azure/app-service-web/app-service-deploy-local-git 
got it figured out and live!
It can't be a .net core app at all, even if it targets .net 4.6 There is a different template for asp.net apps based on the full framework
Alexa skills support calling arbitrary HTTP endpoints. As long as you can talk HTTP and JSON you can build a Alexa skill. Language doesn't really matter.
Currently working on an app where we have it split in pretty much that exact manner. The MVC solution contains the client app project (MVC views &amp; controllers). The API solution contains the WebAPI project, domain, data access, repository and unit test projects. I guess the amount of separation in the API solution could probably vary but the concept would still be the same. The MVC controllers make calls to the API layer to get data for the views.
What is your question?
Update table set value = value + 1
Looks like opening a file on the client from a network drive.
What if multiple people attempt to open/edit the file at the same time?
Looks like Amazon's version of azure functions. Basically, it's a way to have your code execute without any infrastructure maintenance, even a VM or web site.
Can you give an example ? I'm trying to find out why wouldn't I execute a function on my computer for free.
Anything you would normally write into a slim web job can now be even slimmer - for example you could write an up-time function to make sure your web apps are still running.
What is the end goal? If you want your frontend to consume data using WebAPI instead of traditional code behind, than you can separate projects completely. If you just want to isolate processing and data into separate projects, this is more of an organizational issue.
Real (simple) example: a file is uploaded to S3, I can have a lambda to automatically process it (maybe optimize it and inform my database/API). 
Nice For future reference, in Visual Studio, if you login with your Azure Microsoft account, there is a checkbox when creating a new project which says *Deploy to Azure* which will deploy it without you having to do anything.
We would. To do async PDF generation for our web application.
Been waiting for this. Finally!
As far as I know WCF does not even support basic authentication over HTTP. At least back in the awful days when I had to use WCF it was a huge problem.
I totally get it, but this what the customer has asked for. I'll probably convince him to do with a certificate, but since he said it like "if you can't do it with http you can tell me" it sounded like a challenge. :(
I look at it this way. He is paying you for your professional expertise; I personally would push back and present the risks, sharing how it goes against best practices. If they still chose to move forward then I would have them sign a risk acceptance document to cover your butt and implement it as they requested with the understanding it will cost more and take more time since it is a custom configuration not supported out of the box. You would basically need to build your own binding to support this configuration. It looks like someone might have already done that work for you however: [Clear UserName Binding](http://webservices20.blogspot.com/2008/11/introducing-wcf-clearusernamebinding.html)
Yes, I got all the evidence but the customer is being a little dicky about this, they accepted is but as if it where "my fault".
without HTTPs auth is a waste of time and completely insecure so it is not included by default. You can make it work but you will need to write a custom security adapter or pass through a custom HTTP handler shim and let IIS do the work with a security credential passed through to WCF. There are other tricks you could employ too some IIS plugins might help here. I am guessing you want per-user data but its not super secure correct? You authenticating just for basic user name and its not a PC domain password or anything right? Yes its a bit of a pain, MS API's often exclude insecure options or makes them hard to do on purpose.
Yeah, but this is exactly what I am looking for: To create an ASP.NET Core app based on the full framework and then just run it on Mono. In theory it should work, didn't it?
Yes, but its still interesting that the Console app targeting the full framework did actually Ron on mono/x86. So we see that there's at least a certain level of compatibility.
Actually, it will be just one user and password, everything is hosted inside the network. I know it is a strange requirement, but people can be quite special when asking for things they want.
Believe me I understand, users are users. Just make sure the requestor is aware of these 2 facts: * This is not secure at all, might as well leave auth off entirely * This will take extra time and testing simply because insecure configurations like this are not standard and so you will need to setup a custom config. As long as they are cool with it, go for it. If I was doing this I would be looking toward an IIS configuration that does basic auth over HTTP then add a handler that hooks up your WCF service. You MIGHT be able to do this with an alternate WCF host too (maybe nancy?). Google will help a ton here of course.
Pluralsight has a lot of good material. 
I tend to use Grids a lot. You then set the HorizontalAlignment to Strech for Buttons etc. inside of the cells and then use empty cells for spacing. The ColumnDeifnition &lt;number&gt;* syntax can work like percentages, just make sure that all the numbers add up to 100 i.e. &lt;ColumnDefinition Width="70*" /&gt; &lt;ColumnDefinition Width="10*" /&gt; &lt;ColumnDefinition Width="20*" /&gt; Put a TextBlock in the first cell and a Button in the last cell and you get the responsive widgets you need. If you need finer control, then double the values e.g. 140*, 20*, 40* to get 0.5% resolution and so on. One trick I do is to take the pixel perfect design and render the sizes in a Grid witht he star spacing and it will scale perfectly e.g. Say the design has a button width 76px, then 12px space then a huge 1012px TextBlock, then define your Grid as follows, &lt;ColumnDefinition Width="76*" /&gt; &lt;ColumnDefinition Width="12*" /&gt; &lt;ColumnDefinition Width="1012*" /&gt; Now you have a pixel perfect design that scales.
Well, thanks for your contribution. I decided I was going to implement it with the certificate. The only problem was the head of "ETL" department of the other company was the guy who asked me for this, so I was kind in a tight spot telling him he was not secure, but well. 
Xaml bootstrap.
*My first sentence* starts with "Just for practice..." That's the end goal: skill-building.
Watch the panel from re:invent 2016 as soon as they publish it on YouTube. (the panel code was DEV207). It's amazing what they did. It's not only writing a lambda in c#. The tooling and the integration with api gateway is amazing. Last but not least, using a lambda function as execution environment for a full fledged asp.net core api and api gateway as a replacement for iis/nginix. The best part is that adding support for this special execution doesn't affect the program.main (you basically create a new entry point for your application used only by lambda) so that you can f5 in dev and let api gw trigger your function/api in production. AMAZING!
Yes you can. Grow a spine or take some xanex or something or your career is going to fucking suck.
The MVC and WebAPI solutions do run independently. You open each solution in a separate instance of visual studo. Configure the port number in the solution settings in the first solution and when you configure the second you will see it gets assigned different port number (its been a while and on mobile now but I'm pretty sure you can configure the to whatever you like (as long as they're unique). Anyway when you debug/run each solution separately they'll each be hosted at their own port which you can then use to make your api calls from your mvc controllers. The project I'm currently on is a rewrite from an asp.net Web forms app to the mvc 5/Web api I've been describing. If you would like to share your code or at least some representation of the app in its current state I'd certainly take a look at it and tell you what I'd try to do with it. 
Good blog post. I think you always have to be thinking about your next job. Another thing you can do is contribute to open source projects. I heard a number of tech companies look favorably upon these contributions (if substantial) or if you have your own projects, even better. Also, if you're still working on WebForms, you *really* have to update your skill set.
I guess I'm doing pretty amazing in my career. Sorry for you since from your posts your career is not the best. But I'm sure with this amazing attitude you will do great in life. Keep up with the good work, genius!
&gt; Xaml bootstrap the book title say "pro" . i am absolute beginner
My project is taking contribution if you are learning asp.net core at th e moment :) https://github.com/dodyg/practical-aspnetcore
&gt; The scope of this app is to store some data and present them in a sort of grid with some pie chart, nothing difficult. Do you intend to make this a web app, or a desktop app? You should note that there are no GUI libraries for .NET Core.
Web App, sorry I didn't mention that!
I think what OP means is that they want a separate API for managing notifications which are generated by the windows forms app. It's not unheard of to have a client app which calls back to a central server for settings etc. This would be useful in a situation where you had users on different machines at times but need settings to follow them. Soooo, if that's the kind of thing OP is after the yes it's possible but they've got a LOT of learning to get there.
From what I've seen lately, and from within my own company, RESTful Api's, and Javascript front ends like Angular 2, although that might be no different to last year...I might be a little behind
Makes sense angular is growing each year! 
Is there a Windows service behind that Windows Forms app? It seems questionable to have the user-facing app be responsible for monitoring and sending notifications. That would mean the app needs to remain open at all times or you lose your monitoring capabilities. If there is a backend service, I would put the API there and a self-hosted OWIN Web API would be my first consideration. At any rate, you can self-host a web API from any process in .NET using the Web API NuGet packages.
why do you need a Webservice ? If your grid and pie chart are 100% UI (angular / native), sure return your data as JSON and call it a day. If your using something like razor, having your mvc controller call a json api controller in the same application smells.
Yeah all the monitoring and notification functionality is in the windows form project haha. The previous iteration of this program was written as a windows form app by my predecessor and I'm building on that. Sounds like I should remove the monitoring and notification to a Windows service before trying to create the API? Or would it make sense to ditch the windows forms and create an ASP.NET web app? Looking at c# web api documentation they seem to use this project template.
WPF doesn't use pixels. The values you specify are in "Device Independent Units", 1 DIU = 1/96 of Inch, or 1 pixel on 96 DPI (100% scale). WPF window scales well with system DPI settings. 
Here's the session recording: https://www.youtube.com/watch?v=Ymn6WGCSjE4
Custom machine/deep learning training. Seriously, farmers would come to you to ask you to help them sort their harvests, manufacturers would want to better predict quotas, Mama and papa shops would want to know sentiments about their services from social media. Possibilities are endless and the bar is high but the reward is very very sweet.
Explain polymorphism, interfaces, the yield keyword, data structures. Async/await?
We're now taking over a project from a team that was entirely laid off after attempting to implement a new system in microservices and failing to make significant progress within a year. Know what you're biting off before you start...
Write your own implementation of List&lt;T&gt;
Yes, because I's like an API: this service will be consumed from who wants to store data in my application
I would use an external tool like DbSchema or SSMS and generate it from the db itself.
Communication is a huge factor, but also distributed computing is just plain hard. Things that were easy before become insanely difficult. Here's an example: take two separate databases and try to enforce relational integrity between them. Here's some additional thoughts: https://m.signalvnoise.com/the-majestic-monolith-29166d022228#.uz3pu7mq0
These are good interview questions. Throwing terms for them to define is the most common type of coder to coder question, and probably the worst way to get a feel for how they actually code. Any good interview should be about just getting them talking. - Tell me about the last "A-ha!" moment you had on a project. - What was the hardest thing you ever had to develop? - If you said you had a specialty, what would it be and why? If they bring up, any of the terms that peek your interest, then ask them more about it. And you can expect more depth because they brought them up. 
All due respect, DHH is a really difficult person for me to agree with. He talks in such broad strokes with a hint of arrogance, and in this case ignoring the upsides of microservice architecture. You are completely right, distributed computing can be hard. It IS hard for the most part every time, but it really comes down to architecture. The same way you would have to be careful in architecting a monolith (know your pain points, where there will be heavy computations, etc) you will have to do for a microservice architecture. The idea is around separating heavy concerns, and easily recovering if one of them fails. Usually all of our microservice architecture falls into the middle tier; the web app and the data layer are usually poor choices for this, but there is no hard rule around it. Here is an example we used recently... We have a monolith app (in this case it made sense for what it was) but we needed to expand on what it was doing to support other new apps outside of the primary web app. One thing was around formatting responses for our mobile apps because there was a lot of bloat they weren't using, and missing a few fields we were. We also weren't psyched about the response time. In 2 hours while I was still explaining it to my boss about how maybe we should just have a separate service that handles those responses for us instead of us going through the arduous cycle of updating the monolith, one of my more forward thinking devs already had a python service up that was caching our list feeds so the app only had to pull json files instead of hitting a runtime(the slow response time part) and another endpoint which acts in the middle between the monolith to format responses. Even put in a health check alert to ping us in slack if something went awry. if it goes down, it was an easy switch to point back to the old endpoints. It just made things easier than having to update a huge mountain of code in the monolith as apposed to having incremental increases of small patches of code. 
right now we are just making simple microservices.. upload a file.. check a URL... Screen scrape a url perhaps I need to think of scenarios where two micro services share updating a single database? oops I mean two services writing data to separate databases but these entities should be the same ? ? Ill have to think of some real scenerios that will start to make it clear how complex it can get ill read that article later
I agree with you about DHH - I usually dislike his position and attitudes, this particular article just struck a chord with what we were inheriting. I also agree with you that microservices can be done correctly! It's all about knowing what you should and shouldn't do and making good decisions up front. For background, the project we inherited was attempting to split (practically) every table from a previous application into its own PHP-based microservice for "scalability". Each service then had to talk back and forth to each other to get the full picture of the data (think table joins). This got too complicated, so they threw a node.js proxy in front of it and started making "compound" endpoints where the proxy would simply call a boatload of services for you. This performed pretty poorly and was a disaster to make changes to. In short, it was basically insanity and that's why they had so much trouble making any progress.
Good! Keep it simple and success can absolutely be yours! 😄
Http://stackoverflow.com/questions/6569588/count-child-record-and-show-zero-if-empty
I have to agree with that and will keep note to myself to ask next interviewee. I have been realizing lately that it is getting quite difficult to find a good programmer who understands "programming". No idea why.
I am a noob, where do I go from there. This also throws an error when I use it in my case: &lt;code&gt; db.Authors.Select(a =&gt; new { Author, BookCount = a.Books.Count }); The *Author* in *Author, BookCount* is flagged with an error. Thanks in advance &lt;/code&gt;
Are those really things you would want to ask in an interview?
Ok, that makes sense... but, that was is a pretty key fact missing from your original description. 
Well, I wasn't thinking of it that way - they're just good candidates for edge cases. Particularly for a technical interview, an example where something really doesn't behave as expected might be interesting. 'Technical' interview could be a lot different depending on the level of the position. At the last job interview I had, for an intermediate developer position, they gave me a test. I was about halfway through and doing pretty well I thought, when they came back and said they gave me the architect position test by mistake. The regular developer test was a piece of cake. Makes me wish there had been an architect position open. Anyway, the difference in level of difficulty was remarkable. Do you have an idea about how detailed they're going to go?
Triple DES encryption?? I strongly recommend you use something like AES256 instead...
Thanks, will take a look at the available implementations.
Hey, thanks. Of course, you have to use secured connection HTTPS to talk to the API. For the database storage, you can restrict access by setting private network, firewalls or user accounts - but these are really the concerns of the "infrastructure", not the project itself. For the brute-force - I haven't thought about it yet, I guess that you could either prevent it on the server level (e.g. add some policy to prevent spam using NGINX, IIS or other hosting frameworks), but I could also try to implement it in the code. If the database gets compromised all you get are encrypted values and "salts" - the encryption key is never stored on the server, so I think these are quite secure. 
Thanks, sounds good. Query about the client API, you're required to pass the X-Encryption-Key header? How come, since you might as well just return the encrypted data to the client who then decrypts it?
I was thinking about it and I guess I could add such feature but in that case, this project will be merely a container for data. I really wanted to make it easy for the end-user to make use of the raw data and not care about encryption/decryption, but this one shouldn't be too difficult to implement :).
See here: https://www.reddit.com/r/dotnet/comments/57z90x/learning_net_core_by_example/ and here: https://www.reddit.com/r/dotnet/comments/5bnw2s/learn_net_core_by_example_or_micro_example_part_ii/
As long as his app is only running on Windows, he can just specify UNC paths and it will work. However he cannot specify username or password for the network access; it will always use the user account the app is running under. An alternate is to use net.exe to bind network paths to drive letters which will allow you to specify credentials. Crude but it's a lot easier than Of course if this is a .NET Core app on a non-Windows platform none of this will work. It's going to be a pain since this is using proprietary MS stuff from Linux which is a pain by default. Best way is probably to install the smbfs package and add a line to /etc/fstab to mount the directory at boot, then using files on the network drive is trivial. Make sure to set permissions and ownership on the mount point so only the app's user can access it.
Last I checked (to be fair, .NET 2.0) the compilers were included with the framework. Which means your answer is 100% IDE and tools and perhaps some SDK bits that aren't strictly necessary. Not sure about WPF specifically but I would expect it's IDE support, example projects, documentation, tools, etc. The framework runtime itself has to support WPF out of the box to run programs coded for it, as most users won't have Visual Studio installed.
There doesn't appear to be anything in /u/confucious.
Isn't the Authy designed for authentication only, like Auth0 or Stormpath?
You can sync your data between devices, which requires the password to decrypt the data once it's synced.
The problem I have is that visual studios does not recognize the using directive for sendgrid. I have the package installed through NuGet and the account set up on Azure but haven't been able to get "using sendgrid" to build. Visual Studios 2015, sendgrid 8.0.5
Besides making dank memes? I'm going to guess Angular will be big along with .NET Core, at least in the enterprise?
Docker is more for ops or at least devops. If your dotnet devs are worried about Docker deployment, you need more staff!
I would disagree. It's a best practice to perform development within a container. That's kind of the point of Docker...keep your dev/test/production environments as similar as possible
Not production ready so I expect this to change. Command, query, and sync all currently instantiated in same process, but are separate classes in separate projects. Also just console apps so far. Will probably look at windows services, but end goal is containers. 
You could build a .Net SDK that decrypts automatically, as well as document the algorithm in a way that third parties can develop their own language SDKs to decrypt. It could even be optional for convenience.
Interesting, thanks!
That's an interesting idea, will think this through for sure.
what container tech are you planning on using to support the non-dotnetcore services?
AWS Lambda supports C# now.
As I was reading I'm thinking "this sounds like yeoman" and i scroll down to find it is. It's just a command to build an SPA for .net core with options to choose from Aurelia, angular, etc.
I had a similar progression (about 8 years ago). I was a mobile developer mainly for PalmOS and PocketPC and moved to ASP.NET. *Do* pick up ASP.NET Core. It's the inevitable future, and the differences between it and "the old ASP.NET" are not that drastic. *Do* learn Entity Framework and give it serious consideration as your database ORM. There is Entity Framework Core and Entity Framework 6. Core is usable, but still missing a few important features. If you're just doing projects for fun, Core will suit you just fine. *Do* use MS SQL Server Express as your database of choice. It's free and the majority of examples and documentation surrounding databases and .NET online are usually based on MSSQL. *Do* be very, very, very careful when you're reading documentation and reference material online. I am developing a web app in Core and have a frustrating time getting good search results - there are a lot of older .NET Framework documents out there with overlapping names that can trip you up, and even more documents about the framework that talk about features that were added and removed in the betas and release candidates.
Learn a framework other than MVC and then come back to learn MVC. You should go into .net web dev with an understanding of where Microsoft is in terms of the competition. I suggest either Laravel or Rails. Again, you don't have to stick with them. But having an appreciation for the conveniences and conventions they enjoy will give you the best shot with MS tools that try to imitate them.
Learn how CSS works, but learn it through a sensible preprocessor like LESS or SASS. MVC is a good choice for a framework that is fairly easy to learn and can get the job done. Once you're somewhat comfortable with MVC I would also recommend learning about WebApi and SPAs. In general the api/spa setup is pretty powerful, flexible, and encourages proper separation of concerns. 
UWP is more limited in what they can do because everything they can do has to be compatible with a no-fuss self-contained Windows Store install. It can't rely on ODBC drivers or ship with drivers that is installed system-wide and so on. Basically think of UWP as "It has to be happy with only requiring non-administrator user rights and so nothing system-wide, and that also has to work on e.g. the Windows Mobile philosophy". Then you get into the ballpark of what UWP is letting you do. So, with this in mind... Back to your question... ;) * Microsoft [recommends SQLite for _local_ databases](https://blogs.windows.com/buildingapps/2016/05/03/data-access-in-universal-windows-platform-uwp-apps/#LhCJQ9HuzzRDudsl.9). * For _server_ databases and UWP, you should connect to a service that has the database access. For example, a web service could return a JSON-formatted food recipe object from a food recipe table in SQL Server or whatever. You wouldn't worry about the database used in particular, but now you have to worry about setting up such a service instead. :p There are upsides to this though... Suddenly this application will no longer need ODBC or anything else than a network connection, and even run on tablets or whatever, which is core to the UWP philosophy. Sorry for not giving you the easy answer though...
I think the biggest thing to try and understand (that is not yet mentioned here) is the entire HTTP pipeline and lifecycle of a request. [PRG (POST, Redirect, GET)](https://en.wikipedia.org/wiki/Post/Redirect/Get) for instance in dealing with how you handle submitted data. Coming from the hardware/device side, you will be used to having **STATE-FUL** (sp?) applications. HTTP and the web by nature are **[STATELESS](https://en.wikipedia.org/wiki/Stateless_protocol)** meaning you have to approach some of your problems differently. 
For a general use programming job, I'd tend to steer away from code puzzles. Code puzzles prove that you've read an article about code puzzles... I prefer simple "test your competence" questions, such as - What is a left join? (If you know what a left join is, I'm pretty confident you know how the other kinds of joins work) - What is polymorphism? - Explain async/await and how you'd use it for *some very simple task* A handful of questions like that can very quickly exclude those who can't code to a reasonable level. And beyond "a reasonable level" do you really need godlike coders? I tend to say no, and that actually it's more about attitude, whether they keep up to date with developments in relevant areas etc Clever interview questions do nothing other than tell the interviewer how clever the interviewer is.... and they can be a turn off for the best developers, who will often see them as proof of a lack of substance and too much management nonsense getting in the way of their real work.
ASP.NET MVC is based on Rails.
Well, ya, I guess that is true, in that there is a thread "somewhere" that is being blocked, but the consumer of this class wouldn't know it. The main reason I want to do it this way is because non of the current stuff on the web supports WaitAsync with a timeout.
I've stopped using SSMS entirely. I find it to be ridiculously slow and bloated. HeidiSQL is a nice replacement - it's fast, code completion works with Azure DBs, and it isn't an 800 mb install. 
I'm starting with a fundamental of web development and ASP.NET Core in general, following the guide video from MVA. Look like MVC is later into the course. Having to refresh the fundamental on how websites and stuffs work, is pretty great. It is way different from how desktop application works. 
Seems nice.. I am trying to find a specific demo that I can analyze and understand.. especially around when you have micro services calling other microservices and how domain data models are shared
Another useful thing is to nail your understanding of the HTTP protocol. It's a powerful thing.
Thanks for the input. I'm pretty new to web development. How much database stuffs should I know beside being able to write SQL? I took a database course back then and still remember a lot of content from the course, minus the whole database optimization part.
LINQ is my kink
I took a course over networking, built a proxy in C#, pretty much just POST, GET, PUT but I think i got the basic down. Still worth refreshing, thanks for reminding me. Any other "gotcha" that you have experienced? 
I think WebAPI is my final goal. I just aim at MVC first because making website is a more common desire, hence better documentations, which is exactly what I need at this point IMO. WebApp is on my radar, but not sure if i favor it over WebAPI ATM. 
It should be. Whenever you are working with anything like set theory you should be here. It puts to power of functional programming and kind of sql at your finger tips. Very powerful stuff. Very bad explanation.
Know how it is implemented, what the pitfalls are ... And then use the shit out of it!
https://www.owasp.org/index.php/Category:OWASP_.NET_Project The web is a scary place for an application.
There are no alternatives - it is the core of so many .Net related things right now.
Um... but surely you don't ditch writing SQL queries altogether, right? You'd still write procs and get data using EF that way, right? I can't imagine getting a list of twenty thousand employees and filtering after the fact when I only wanted one.
I apologize, I am dense in ASP (trying to learn) Taken from: https://www.asp.net/mvc/overview/getting-started/getting-started-with-ef-using-mvc/reading-related-data-with-the-entity-framework-in-an-asp-net-mvc-application I am trying to connect from the shared link to the code below: db.Authors.Select(a =&gt; new { Author, BookCount = a.Books.Count }); public ActionResult Index(int? id) { var viewModel = new parentIndexModel(); viewModel.parent = db.parent .Include(i =&gt; i.child) .OrderBy(i =&gt; i.parentKey); &lt;&lt; this is where I want to put this code &gt;&gt; I want the number of children for each parent so I can then display it on my index page. if (id != null) { ViewBag.parentKey= id.Value; viewModel.parent= viewModel.chile.Where(i =&gt; i.parentKey == id.Value).Single().children; } return View(viewModel);
Manual loops and hand written SQL...
Repeat after me: LINQ is not an ORM. It has nothing to do with T-SQL or any DBMS. That is LINQ to SQL or EF or whatever. I use LINQ all the time, and still hand write SQL. 
It has been HEAVILY used in every product I've seen over the last 8 years. I've yet to encounter a development team that doesn't use LINQ/Lambda syntax somewhere in their codebase. My current team uses it pretty heavily, and so did my last team. Granted, I have heard a few develops tell me they don't trust it, but they really couldn't back up with defined reasons (which is fine, people make opinions and just go with them...then they don't need to remember why). I've also ripped out LINQ syntax a couple times (really, about twice) because of performance reasons. For people that like functional style programming, LINQ is awesome. 
Yes. /thread
Thanks for the answer, with the new dotnet, can it connect to ODBC ? With your suggestion, if I build dotnet based web service that connect to ODBC, and then from UWP request to dotnet web service will solve the problem? Have to connect ODBC for old databases or connecting to various databases in the future
Please don't say that... Please don't. I once worked at a dev house that had an oddly weighty Data team full of DBAs that were convinced SQL was the be all and end all of development. If you'd allowed them to create a whole web application using sprocs I've no doubt they would've! Give a DBA a challenge and tell them it can't be done in SQL. I guarantee you'll have the most convoluted solution the world has ever known :) I guess it's a case of "When you've only a hammer, everything looks like a nail" which is fine if you've a fair balance in specialities. Not so much when the DB folk have unparalleled power. Side note, I've recently got into Rx(.NET) and you're right to mention it here, an excellent paradigm! Powerful yet conceptually simple. EDIT: "IIS? What's that? A web server!? I've got a sproc for that here. It's just data right?"
&gt;Or are you just asking about Linq to SQL or LINQ to Entities Interesting word choice. To me, Linq to SQL and Linq to Entities are much "bigger" in my mind than Linq to Objects. SQL translation, proxy generation, dirty object tracking, etc. seem like a much heavier set of concepts than the compiler transformation to IEnumerable extension methods. When someone mentions Linq, I only ever think of Linq to Objects until I remember "oh wait, people often also mentally import all this other crap about databases".
I was using "just" because Linq to entities is a subset of when the linq syntax can do. Even tho, as you stated, linq to entities is a much larger technology topic.
I'm really not understanding your question or even what you did. You wrote a datagrid for users to enter data, based on data originally from an excel spreadsheet, with active directory authentication, with the ability to send emails, print pdfs, and send automatic alerts, plus open read and write additional excel spreadsheets? Nevermind. I think I understand. You're trying to figure out if you can access a file on a different IIS server than where your code is running. Depends if the other web server is in your same company and that server can read from and write to files on it. If not, then you might need to write something for that other server to run that can do it for your first IIS server. 
While this is educational, anyone actually trying to write a Windows service should bypass all this and use Topshelf. You're welcome.
&gt; Topshelf [Link to Topshelf overview](https://topshelf.readthedocs.io/en/latest/overview/index.html) if you want some reading on the subject.
LINQ to SQL isn't as popular and it's not getting new features but I believe it's still supported and available. If you use LINQPad (which I highly recommend) LINQ to SQL is the default method for querying databases. 
It's fundamental where I'm at, and everywhere else that I've been. Map/filter/bind/count are all pretty fundamental concepts when working with lists of stuff and treating an application as a set of transformations on data in the system...
LINQ does not provide better performance to loops, for instance. It does provide a clearer syntax for those that are familiar with it. It probably shouldn't be used in performance critical applications if possible, as you've noticed. It's about choosing the right tool for the right job. 
To expand a little bit on Point 1. There are often a lot of unexpected intermediate object allocations for certain types, queries, operators and combinations that aren't obvious purely from the syntax. Until you hit a problem and look under the hood. Always good to know your tools.
To provide some context: I am fairly new to development, most of my experience is with Web Forms. I want to get better at system design, security, and architecture . That being said, I decided to start a side project and thought I'd go outside my comfort zone - I choose .NET Core, Nancy, Postgre, and JWTs for authentication. Suffice to say it's been a struggle, and I made all my changes locally (no source control). Well, the project is now up on Github (where I intend to keep it) and I'd really like some feedback on what I'm doing poorly/could improve upon. Be as harsh as you like, this project is just for learning purposes (has 0 front end).
I use LINQ all the time. I use it to query databases in LINQPad, to gather lists of files relevant to my task. to query the contents of text files, to query event logs on remote servers, etc. The possibilities are endless and if I had to write a for/foreach loop every time I needed to select some data it would take about 5 times as much time and 5 times as many lines of code to do so. I also switch between fluent syntax and query syntax depending upon what is needed. In case you hadn't noticed, I love LINQ and I highly recommend it to everybody that will listen. I do know that some people are hesitant to learn it because it's just one more thing to add to the list of stuff we need to know. In this case I really think it's worth the effort. 
I've worked on an application with 2000+ line sprocs, though I'm not sure if that's a case of a DBA who wanted to prove his doubters wrong or one who didn't know what the hell he was doing.
Och, I feel for you there. Soon gets painful eh? SQL is dandy for querying it's own data. As soon as you start calling DLL\CLR imports, using triggers for anything beyond preparing reporting data, forming presentation layers... All hope is easily lost. I've seen some phenomenal feats achieved in various SQL engines/dialects. Keeping them as curios, great! Go nuts! Fantastic for increasing your knowledge of the system. Push it's boundaries all you like. #JUST DON'T USE IT IN PRODUCTION PLEASE! Rendering stays in the browser. Request parsing in the pipeline. Business logic in the back-end server-side application. Data wrangling in the database (I'm okay with ORMs too, but I respect those who aren't. ORMs in their original incarnation were clunky, and some still are depending on use-case). I used to work in Market Analysis prior to selling my soul to the Web. So y'know, I appreciate database work. I understand DBAs have worked their asses off to learn the nuances of performance in each of their engines. I'm also certainly not against searching for the next best thing. It's just the baffling keenness with which some will stick to the wrong tool with such gusto to the detriment of the rest of the team and their successors. If I'm writing an application/documentation, I'm doing it with a view that in 6 months time I won't remember what had occurred, and this app may very well be in a different companies hands by then.
Available yes, but depricated. I don't know if the designer is even still available. Remember strongly typed data sets?
I wasn't talking about Linq to Objects. I was talking about Rx.Net. Do you understand how Linq Providers work and why they can't be replaced by loops?
I hit each one with a line return and line them up vertically so it reads nicely and fluently.
I would have a look at open source projects and see if you can contribute there. There is a site called up for grabs, located here http://up-for-grabs.net/#/ and just start coding away :) they have a lot of various types of projects, with tasks aimed at people starting out in open source. Good luck!
Yep, love it!
Most of the C# developers I know use the Linq methods, not the SQL syntax. 
System.Linq is an indispensable tool in .Net when dealing with generic sets of data, which is almost any project you would work on. So, yes - absolutely. 
Most of the linq operators are quite simple to implement. Doing so is a great exercise.
I don't use the wacky SQL-ish syntax and haven't ever seen it used, but I use the chainable extension methods from the System.Linq namespace *all the frikkin time*.
I like the LINQ Syntax when using GroupBy and similar style functions. It is more readable. But most code is more of the Where(...).Select(...).First(); variety. Since we have a number of Scala developers on my team, that syntax looks very similar to the Scala collections API and everyone has an easy time with it.
You have my sincerest heartfelt sympathies. Blow their minds with lovely LINQ list.Select(sel =&gt; sel.ToString()).Aggregate((a, b) =&gt; a + "," + b); Whilst they're on elongated sick leave with *canite mentis*\* you might get some less mind boggling temporary replacement colleagues! \* My Latin is awful, so let's pretend that means blown mind.
LINQ to Objects and/or LINQ to Entity pretty much everyday.
Why is this upvoted? It's a completely unnecessary discussion 
Any particular reason why it couldn't be both?
Have to make some unit tests to test that logic? Not happening, sorry.
Heck, I've had the misunderstanding between LINQ and Lync. I was talking about the query language when a guy who I was working with didn't understand a thing because he thought I was talking about the (now known as Skype fore business) app. 
Also, FWIW, I have Travis auto-deploy this project as a nuget package. I'm looking for any feedback, thanks!
A pitfall we have run into is that LINQ makes it too easy to do things like FirstOrDefault to look up data frequently. In many cases, you can get a huge boost by converting to a dictionary or lookup if you are doing this in a tight loop.
Plus the SQLish syntax is just weird. It's out of place in C# land like XML literals in VB.
Yes you're doing amazing... At getting steamrolled by everyone and accepting blame for shit that isn't your fault. Stand up for yourself, I'm much happier now having done so... Genius.
my only issue with linq - is that it can sometimes be a bit harder to evaluate in debug... beyond that though I love it.
I pretty much only use it for joins because I like that syntax better. Other than that I prefer how the lambda syntax actually shows what you're doing in order.
Bah, had to reset my phone last week and it's taking forever to retrain the keyboard.
That was taken specifically from a WMI query build for a SELECT where thankfully the names follow a very specific set of known patterns. No files being generated. Just two or three WMI Objects in a comma delimited row.
Chain. https://github.com/docevaad/Chain
Everybody seems to be mistaking with the terminology. LINQ is the overall feature which can be written in two ways: method syntax and query syntax.
Core Web API doesn't exist, is just MVC now.
I recently set up some local build agents to do CI deployments of projects that are in VSTS online. The title caught my eye, but the article seem low on actual content. I guess it all depends on what they end up supporting for deployment. 
Not sure how I feel about allowing nested functions. 
I don't think it's really a 1 or the other kinda deal here. The 2 products are so different that you really should use both. VS is very solution and project based, whereas Code is very file and directory based. You should really use them both for different purposes. I use them both every day and they are both fantastic, but I couldn't imagine using either one of them for the purposes of the other.
What would they be used for?
You're still going to be more productive in VS for any serious .net development. The upcoming VS 2017 is supposedly very pared down for performance.
Now it looks like javascript. It's got to be good.
Yeah. The problem with nested function is that they can be used to create very convoluted and hard to follow code... I've seen too much javascript where people abused them and created monstrosities!
&gt; It seems the direction things are going is for web .net core work you should get used to vs code and using the command line. What makes you say that? I've been using .net core since the early days and have never used the command line tools for much more than a call to dotnet pack. And I usually only use vscode for my typescript projects as that seems to get its TS version updated a little quicker than full VS.
In regular JavaScript, though, there's literally no other way to prevent the function from being accessible from other scopes.
Thanks I am aware of that, implementation wise they are same but concept of faceless MVC is always Web API.
The pattern matching feature was covered a little too briefly. Here is another blog post with more examples https://blogs.msdn.microsoft.com/dotnet/2016/08/24/whats-new-in-csharp-7-0/
That'd be great if it were true. What about during OOM or other system failures like UAC? Can't those return null?
Things like `FirstOrDefault()`/`LastOrDefault()`, etc. will however return `null` where appropriate, in which case, a [null conditional operator](https://msdn.microsoft.com/en-us/library/dn986595.aspx) can be used to handle it properly.
I use both. VS 2015 for the backend (WebAPI) and VS Code for the frontend (React).
I thought this too the first time I saw them, but the example in this article is actually quite interesting. Getting a subset of the functionality offered by recursion without the overhead is really quite intriguing and I'll have to digest it a little bit. It'll mostly be used for evil of course, but you could potentially massively improve performance in some cases while binding functionality in a way that's not currently possible. Some of the possibilities for scoping are also interesting. It may still be useless and the evil may overcome the good, but I'm at least intrigued.
It's a cool idea but I wouldn't use it because I don't want my class hierarchy disturbed. Or maybe I'm missing something in the implementation details... is there a more concrete example available?
Hey, glad it was helpful. Disclaimer: I have read some about dotnet core, but have not had the chance to get hands-on with it. Most of my knowledge is based on 4.5.2. You are going to want to look at dependency injection. DotNet Core actually comes with a dependency injection framework. https://docs.microsoft.com/en-us/aspnet/core/fundamentals/dependency-injection This explains dependency injection and shows how to set it up with entity framework. What I like to do is keeping the data models in the DAL layer ( and keeping them there, making sure data concerns stay in the DAL ). I then make business-specific classes in the business logic layer and exclusively work with them throughout the application. This has the advantage of being able to model your business based on actual business concerns, not data concerns. 
If you want to handle errors generated by the functions you pass to the LINQ functions, rewrite your functions to return `Result&lt;TResult, TException&gt;` (the either monad).
I can't wait for digit separators. "Is that constant 1 million or 100 thousand? Lets count a bunch of zeros!" ain't fun.
In the "olden" days I accepted this as the natural progression, but I assumed since there's a new compiler, they can - at worst - just drop a product update for VS(2015) for the new language support.
Yes, Roslyn makes this harder to accept when you can add a new language feature yourself. That said MS never said these features *weren't* coming to VS2015. Technically there's nothing stopping them from doing C#7 on VS2015.
It's not only based on resolution. It's essentially pixels per inch. Theoretically if you have a 27" screen and an 18" screen and a display element (for example a button) measured in points, if your PPI calibration were correct then taking a "real life" ruler to your screen and measuring the button on both displays would get you exactly the same result regardless of resolution. Windows does a "best guess" of the calibration based on the reported physical display size from digital connections (thanks UPNP) and you can fine tune from there if you need to. Not sure why you thought I meant just pixels when I talked about display size as it could just be a straight conversion to pixels then so why bother. A "display pixel" as measured with points is dependant on the ratio between physical size and resolution, and is **usually approximately** 1.3 pixels but things like a 4k screen, unusually large physical size, or a low resolution monitor could change that drastically. As a more concrete example, your 15" 4k monitor would have 293.72PPI, where as your 800x600 monitor of the same size would have 66.67PPI. 72 points is close enough to one inch, so we'll make a 72x72point button. On the first monitor it would be about 294 pixels, on the second monitor it would be rounded up to 67 pixels, and if you took a ruler to the screen they would both measure one inch square. 
Ah, I see. That makes sense.
Having used VS Code, it really just feels like a replacement for Notepad++. For actual day to day work, Visual Studio is already almost on par for Core as for regular .NET - I see virtually no reason to ever use VS Code over "proper" VS
Is your browser zoomed in. 
That's the thing, the Bootstrap CSS file is HUGE. It's just the default CSS file that Visual Studio loads when you create an "ASP.NET Web Application," so I feel that if this was the issue, someone else should have experienced it before and might know where it needs to be changed. I'll keep looking, though.
The dev tools allow you to inspect the actual rules applied to the element, with their source if available.
Look up and understand the SOLID principles and be able to demonstrate a real world example of each rule. Classes, interfaces and keywords like abstract, override, etc They'll probably dig into your experience with EF a little more (I know I would), and ask you to explain some of the high level concepts associated with it. nUnit and other testing tools and suites. T-SQL queries and syntax. Good luck with it!
Ohhh okay you mean Chrome's dev tools. That completely slipped my mind! So I used that and found something interesting in the body {} tag of the CSS file: `line-height: 1.428571429;` I commented that out and rebuilt the solution. You know how I mentioned that one of the image dimensions was supposed to be 44x60 and was displaying as 55x75? By removing that line-height rule, that image is now displaying as 49x68. So that made a difference, but there is something else that is still causing the images to become enlarged. The only other thing I can see that might be suspect is `border-sizing: border-box;` but removing those entries didn't affect the display at all. Any idea what I might be looking for?
how do you determine how to decide what to use for what? 
Yes, that helps. 
I use VS for anything that is a project, mostly C# applications. I keep many projects in larger solutions that share code. VS handles this amazingly. You can refactor a function deep inside any file and VS will make the changes necessary everywhere. So I use VS for large applications, WinForms, that sort of thing. I use Code for Perl, HTML, JS, CSS, BAT, AutoHotkeys, PHP, AVR, Lua, stuff that isn't a huge, bundled application. My most recent project had a large Perl backend that could almost be considered a project, but I just pointed Code at the directory and went to work. It was really nice having an almost identical editor for the C# frontend and the Perl backend, as well as the JS and HTML support files. I used to load my backend files into VS and edit them, but it was a bit annoying because VS is project based so I found myself adding and removing files from the project and it became a maintenance issue. The only thing that I liked better having both C# frontend and Perl backend loaded in the same project was I could rename things and keep them in sync. EncryptString() in C# might do the same thing as EncryptString() in Perl. Renaming both at the same time is a good thing to me. I suppose if I was doing .NET Core work I'd probably start out in Code because it sort of seems to be what they are targeting, but I would miss VS for the refactoring. In fact I'd probably spend a day or 2 working on the same project in both just to see which one handles it better.
I really only use vs code on small projects and those that are folder based (as in no csproj,xproj etc to manage things). The right click open in vs code in windows explorer for folders is probably what I use the most, mainly for when I want to check out a github project and want to be able to navigate around the types and files easily but don't need the full blown editor. Best example is many of the react projects like react-router ill pull the code down and open it up in vs code to have a look around at how things are done. But I have a feeling I'll be using VS for this in the future since VS 2017 adds support for opening folders and has a much lighter footprint than VS 2015. For every day programming I stick with VS, front end or back end doesn't really matter I prefer the full IDE.
I'll have to create an example project to replicate this. I'll try to get some time to do that and get back to you. Edit: remove the parenthesis of Count() so you access the property Count rather than the method. This works for me in my example.
you would be surprised how difficult these questions are for some.. I do interviews for people that are suppose to be Sr. and they will get one or two of these wrong.. My favorite is always 'Difference between and abstract class and an interface and why would you use one over the other? "
Images are treated as inline elements, so you can change their `display` and `vertical-align` CSS properties to avoid line-height affecting their size. In Chrome and Firefox, you can select an element and then add, edit, or uncheck any CSS rule to see the changes real time. This will help you focus on the root cause of the problem and avoid the edit, rebuild, view cycle.
Be conservative with your LINQ calls and watch for something like querySource&lt;foo&gt;.Where(...).Select(x =&gt; new FooBar(x)).OrderBy(...) I see this a lot in MVVM scenarios, and it's a good idea in theory, converting your objects to ViewModels, but if that constructor isn't written carefully, you can wind up with an exception. Say for example that Foo has public IEnumerable&lt;string&gt; Things { get; set; } and in the FooBar constructor (takes a Foo as 'myFoo') you do something like foreach (var s in myFoo.Things) { ... } If myFoo.Things is null, that's going to throw an exception. You can reduce that by changing Foo's declaration (C# 6.0 or higher) public IEnumerable&lt;string&gt; Things { get; set; } =&gt; Enumerable.Empty&lt;string&gt;(); You can also run into trouble if you're using Linq-to-SQL and you try to put a function into your where clause; because typically a function can't be converted to a SQL expression. Either refactor so you don't use a function call and express it all in SQL-convertible expressions, or convert the IQueryable to IEnumerable with .ToList() (but understand that this will now apply the Where filtering on the Web Server, not the database, and that can be a major performance hit).
I have definitely made messy code using nested functions in JS. But on the other hand it is useful for when a function is contextually only used in one spot, as well as keeping you from having to pass a bunch of variables around if you can just grab them from the parent function's scope. Keeps your code a little cleaner and easier to follow in such cases.
When possible I always check for states that could cause exceptions rather than trapping the exception. I believe there's a performance penalty associated with catching exceptions anyway. Probably doesn't really matter unless you're optimizing a particular piece of code for performance, I guess. In your specific example, .Where cannot return null. If .Where does not match anything, it returns an empty set, which .OrderBy will "sort" by doing nothing, same with most of the other LINQ methods. Of course you get an error if you try to call .Where ON a null (since it's an extension method you actually can call it but the method will trap the null and throw an exception). The whole point of LINQ is to allow you to chain complex behaviors together in a short, readable line of code. Splitting it up like that sort of defeats the point. :)
It's important to be careful to only use ?. where it is a valid, expected case. You want exceptions to happen when your code does something unexpected, since that means there is a bug somewhere and you'll want to see it so you can fix it. If you miss it it could be more subtle and harder to track down. .First .Last and .Single all have an OrDefault variant, and I would advise you to similarly use the appopriate one for the data you expect. For example, if there should always be exactly one element, .Single will ensure that and throw an exception if there are more.
I found LINQ for objects only a few months ago and was blown away, and mad at myself once I found out it was in .NET since 2.0. Now I use it everywhere. I've written so many extraneous foreach loops... I've also recently taken up Entity Framework Core. LINQ stuff you write there does use a different interface but the syntax is very similar. Apparently it's supposed to run server-side though, which I don't get how that is supposed to work but whatever.
You are right, I opened an image by itself and it appears to be both browsers adjusting the size despite the 100% zoom. So in Chrome I just now set it to 80% zoom, and lo and behold, it displays the images with their proper dimensions. Ugh, but why? Why does the browser think "100%" is bigger than it should be and 80% is "accurate"? My images are 72 DPI, which I thought was the number that web browsers use, and I mean... with all my past experience creating images on different monitors, I've never encountered this issue before, so I don't understand. My amateur web design skills are from the era where most monitor sizes were 800x600, and 1024x768 was becoming the next big thing. Individual pixels really mattered back then, so I'm used to looking at images in the browser and seeing them displayed pixel-for-pixel. If it's adjusting for my monitor's DPI, why is it just the browser that displays them that way, but image editors, Windows Explorer and even Visual Studio's Design mode all display the images with the proper dimensions? Sorry if I'm being dumb - guess I know less about DPI than I thought.
Well LINQ is built around the ideas of chaining together filters and calling developer-provided callback functions. All of that is going to have overhead over using a foreach with all the logic in one code block.
It would be fine if you could evaluate it in Immediate mode but it has problems finding the extension methods for me sometimes ugh. That could just be 2013 which I use at work, I forget if 2015 has that issue.
A strong point for VS Code is that you can use it to write .NET code on non-Windows platforms, especially important for .NET Core. But yeah VS all the way on Windows. VS Code could be useful for non-.NET languages. I personally use it as a notepad replacement and Chrome extension development environment.
Those seem really simple and yet i want to borrow these for interviewees.
Perhaps a nested version scheme. Like 2.0-1.2, indicating family-member versions.
that works! Thanks :)
Yep, mostly this. I don't need to ask pointed questions or terminology on the phone. Just by the way you describe your past work, your current job, problems you've solved its usually very clear if you are just book smart or actually know what you are doing...at least enough that you're worthy of an in person interview. I am of course speaking to more senior positions. I'd probably ask some jr. devs about their school work and hope they can articulate it beyond "its what my teacher told me to do."
God, yes. This is a real weakness.
Disclaimer, my interview style may be a bit different than other people. I assume they're expecting a junior developer so they may not ask the questions I'll list. I would ask them. I don't do this to be a dick or anything, I just use this as a general assessment of skill. Not knowing an answer isn't a bad thing, bullshitting an answer is. You could do more damage that way. There's a tricky medium you have to reach when you get a question you don't know how to answer. Sometimes it's best to say "I don't know", other times it's worthwhile to say what you DO know about the topic, or even how you would find the answer. All that being said... here we go. * The difference between an abstract class and a interface * 3 pillars of object oriented programming and be able to explain them all * What are the different access modifiers and how are they different? * What's a static class? * What's a deadlock? * How do you implement multithreading? * How do you debug multithreading? * What's a race condition? * What's inheritance? You should be able to describe in detail at least one design pattern. Whether it's factory, repository, or whatever. Just understand one good enough to talk about and mention that you've heard of the others but haven't had the chance to play with them yet. Phone screens don't usually go into a lot of detail. They tend to be a bit more broad before bringing you in for the real technical interview. A few general tips. Watch for possibly distracting nervous behavior. For example, I had one guy who started every single sentence with "well basically...". It really distracted me because that's all I could notice. Also, ask questions about the role based off the questions they ask you. Put your self in the position of a developer and imagine your asking questions on your first day. Stuff like * What source control do we use? * What's the deployment cycle like * I notice you mentioned that you use angular 1.5, are there any plans to migrate to 2.0? It shows that you are paying attention to what they're saying and that you're already in the mindset of contributing. If it's a specific product, you could ask questions about the latest features and maybe ask about how they were implemented. All that being said, it's possible that you'll have a generic phone screen by a dev that you won't ever speak to again and only has a general knowledge of what you're applying for. Hope some of this helps.
Grab only the sample collection ref ( so you got a List&lt;ICollection&lt;sample&gt;&gt; ). You can always iterate² later on that, but you won't have a monster collection initialized.. All depend what you want to do with it next! Probably not the answer you where expecting ^^
What's the name of that book if you don't mind? 
Thanks! added to my wishlist :)
I've been doing exclusive .net core stuff since june 28th and I still don't fucking understand it. 
It does :(, and I agree that that would be a HUGE step in the right direction.
It's not great right now because a lot of the pieces are still falling into place, so you have to force things right now by fighting against the tooling which also isn't done. Things will improve a lot when .NET Core 1.2 is out and Xamarin is targeting Standard 2.0... .NET Framework 4.6.1+ | .NET Core 1.2 | Xamarin all running on .NET Standard 2.0
Weird, I was confused by this https://www.asp.net/signalr/overview/getting-started/supported-platforms Thanks!
Which part of .Net Standard 1.4, 1.5, 1.6 and .NET Core 1.01 SDK and .Net Core 1.1.0 don't you understand?
Can you provide a little more detail on what you're trying to do?
They way I've done this in the past is to create a view in the database that uses a recursive query to return the list of a samples. Then you can use EF to map that view to a different collection. If you are planning on having an extreme amount of samples and locations (and lots of location depth) you might need a better solution where you replace the view with some kind of pre-computed table.
I am tasked to do offline data syncing on mobile apps . Mobile apps consume web api. The data syncing should work on cordova. The web api uses an SQL Server database. Most of the solutions I can find especially PouchDB, CouchDB Mobile, Loopback.io. These things do not use C# on the backend and does not use SQL Server. The Gateway Sync server is already in binary. Syncing involves business logic and there is no place to put that. 
This makes a lot of sense. Considering this LINQ to objects certainly gets a lot more complicated.
Unfortunately, [this](https://github.com/refactorthis/GraphDiff) seems to be the only solution. The problem of updating is what makes me regret using EF in the first place.
While it's not perfect, I'd always choose Xamarin Studio (now rebranded Visual Studio, I believe) over VS Code. And if you're using VS Code &amp; Command line, I really don't think there are huge advantages to VS Code over Notepad++ or similar. There's little reason to avoid it, but it doesn't add much either
&gt; The lack of commitment to maintenance has been the death of most UI automation efforts I've seen. We have talked about expanding our test suite here at work. In doing so, we have had several discussions about how this could easily turn a 1hr task into a 4hr task, or a 4hr task into an 8hr task. It becomes an awareness and an estimation thing for us. I know about how much time it will take to make the changes. Add in a little extra for developer testing (I don't handle estimating QA testing, that's for the QA people to add), no need to add any for feedback/remediation as requirements are always correct the first time (right guys, right?), then add time to maintain any tests that have changed due to code changes. It can't just be something you set up once and never touch again.
I had no idea this was a thing. I felt like I was in a Jet.com commercial...
Would here be a no go?
On Azure I use this: https://docs.microsoft.com/en-us/azure/app-service-mobile/app-service-mobile-offline-data-sync Source: https://github.com/Azure/azure-mobile-apps It could be a good resource if you need to roll your own. 
I look on Monster. Am I doing it wrong?
I'm in Indiana, and my fellow .Net peeps are on Indeed.
This may or may not answer your question... I'm a contractor, and I've found a good chunk of my work through recruiters/headhunters. Most of them have found me through LinkedIn, and while I usually don't immediately find a gig when I first get in touch with a new recruiter, the ongoing relationship with them never fails to help me find something when I need it. 
I think that's what's happening now
The last two developers I've hired I found right here on Reddit. 
Maybe you can come to devrantcommunity.slack.com. We all kind of devs hanging out there
It would help if you told us more about what it is you're actually pulling data from? A 3rd party app for what, exactly? Are the requests HTTP? Is it a REST API? What does their documentation say to do to get additional data?
Generally, devs don't like or want to do testing despite being fully aware of the positives that come from doing it. It's like eating food you dislike but you force yourself to eat it anyway because it's healthy for you. 
https://www.indeed.com/
I've found all of my dotnet jobs on indeed.com
If it's real time, are you absolutely sure there isn't a another protocol involved? Web socket, maybe? 
That's what confuses me. There's no "upgrade" value in the response header and Burp doesn't pick up any sockets. BUT Wireshark does show TCP traffic after the initial response. From what I understand though TCP is ideal for this use. I'm not versed with Wireshark or the TCP corner of .NET though. You're probably in the ballpark. Should I PM you the request URI? Or how do I break down the TCP traffic into something I can make sense of?
Found most of my jobs on craigslist. On monster a few times. Never had success with recruiters, from a job seeking or job offering standpoint. 
That's my experience as well. I got my current job through a local recruitment agency who specialize at programming and tech companies. At the company where I landed, they wanted somebody with wide knowledge in multiple programming languages and who had a passion for programming. I had barely written a single line of C# before this job (but I knew Java, C, Python, JavaScript, etc), and now that's what I do daily. Soon I will probably be assigned to develop an iPad app, even if I don't have any prior experience of Swift and iOS. My results in C# so far have been very much appreciated, and my point is that a company is probably more interested in finding a generally good developer who can adapt, as in my case, rather than in somebody who ticks off some specific language requirements.
Do people really do this? Are there really people out there who think 3 years experience with Python is the same as 3 years experience with .NET? Or 3 years of experience building web application is the same as 3 years of experience in game development?
Ah sorry, my wording sounded weird. We do look at things like "x years of experience building distributed services", but we don't really care that they had built the services in .NET, or Java, etc. Hiring someone with just experience in writing firmware to lead a distributed services project would be hell for both sides :) So, it depends. It depends what you did with Python. If you used it to build web services, then I believe you'd do just fine building web services with .NET or Java. Less so if your Python experience is purely for laboratory uses. Make sense?
Recruiters are probably the best way to go if you have the money and are short on time. This is a small business and the budget is tight. 
&gt; wood Good point.
Where are you located? What does your company do?
I work for a large company doing enterprise dev. We have an HR department and they mostly work through recruiters. The recruiters are pulling local contacts the know or advertising on the big sites like Dice or LinkedIn. It is good to get your resume in with or, even better, get to know your local recruiters. They will take you out to lunch just to schmooze and when something comes up they will try people they know first rather than spending on an ad.
I apologize for the shitty context and for not revisiting this thread, I should probably remain a lurker... I do appreciate the responses though. Here's my attempt to lay this out a little better: -"ServerA" hosts the application -"ServerB" is the file share with directories that contain all corresponding files, with many different types of extensions (.xlsx, .pdf, .pst, etc.) -All on same network I wanted the directories to be accessible directly through the application, and file behavior to act as if they are being opened through explorer.exe (IE: .xlsx file will open Read-Only if it is currently open by another user. ) Initially, I wanted to write something along the lines of (System.Diagnostics) Process.Start(application.exe, filepath) that would launch the correct application client-side when clicked, but found that there are many limitations on backend code (understandably) when trying to implement this in a web app. What I ended up doing was adding a tab to the Typescript generated dialog named "Files" and embedded an &lt;iframe&gt; containing the directory on "ServerB." I have not deployed this to "ServerA," but it seems to be working locally... I'm able to open files within the directory just as I would opening them through Windows Explorer, as well as edit and save back to the directory... this seems like it should still work once deployed. Hopefully I didn't cause more confusion, but if anybody has other suggestions on how to handle this or think the &lt;iframe&gt; solution above will simply not work, let me know! 
4.6.2
accidentally 98 megabytes
I have the exact opposite experience. All my clients were always looking for dev with very specific tech experience. Someone with 10 years of exclusive java experience would never be considered for a position requiring 5 years of .net
Idk from what I understand all companies can afford to look for a candidate that has both language experience and specific industry experience.
Freenode aspnet and csharp 
I prefer clients who value my high specialization
Think of Visual Studio Code as a really nice version of Notepad++ with code highlighting and a few other features. Visual Studio is pretty much a full blown IDE. I usually use VS Code for front-end (HTML, CSS, JS) work and Visual Studio for backend.
Yep, the ##csharp channel. It's not a help chat (tho it's often confused with one), just a place for C# devs to hang out and offend each other.
Why is this here? It doesn't really have anything to do with .NET. Edit: perhaps I'm wrong. I think that the article itself is pretty irrelevant to the topic of .NET but the implications of Microsoft's announcement definitely have ramifications for .NET.
I can take a look in a couple of days but I'm a bit busy this weekend. Just take a wireshark dump and pop it somewhere? I'll take a look if I can. No promises though, I've done bits and pieces with wireshark before but not a huge amount of protocol reversing. 
I love LINQ so much, I use libraries that recreate its syntax when I dev in JavaScript and Java.
&gt; experienced This is good advice. I'm going to have you talk to the owner...You might have better luck painting a face on the wall and convincing that face of this argument. Just to be clear I agree with you. 
You are right, this could be part of the problem. What compensation should a mid-level .NET programmer be paid? A big part of what I do with my developers is raise up their skills through training and mentoring. 
Tell me more about this Monster you talk of.
&gt; What compensation should a mid-level .NET programmer be paid? That completely depends on the location. San Francisco requires different payment than some small town, Germany requires different payment than Spain.
You will be able to run WPF or WinForms apps on ARM. 
Ah, sorry. I misinterpreted your question as you were a .NET developer asking how to find jobs. 
I'm sorry, but whilst your argument is vaguely valid, this sub is not - and should not be - dedicated to anything related to Microsoft. It's related to .NET and this development has little to no bearing on the .NET ecosystem as a whole.
Using Automapper: 1. Pull the existing object from the database (Find) 2. Map your disconnected modified object onto the old object. 3. Savechanges It's not terribly efficient, but neither is working with a huge object graph :). If you have complicated collections you may need to use Automapper.Collection to get EF to automatically insert/update/delete.
You know what, the more and more that I read into it, the more ramifications I see for .NET. I still don't think that this article is necessarily a good fit for the sub, but the story itself definitely has relevance for the .NET community as a whole. Edit: [Relevant](https://twitter.com/never_released/status/807649467059073025?s=09)
And if you're writing proprietary code, you can literally drop a nuget package on a fileshare and everyone on your team can add that folder as an alternate, private, no-cost NuGet repo. Great article!
I love the simple and clean look of this site, so many blogs are overly busy. Plus, it's snappy as hell. And it's right. I've have had that, but the antidote is always to create a new application with a team, not by yourself IMO.
&gt; (if the organization you work for is backwards!) Backwards in what regard? You think CIs are bad or..?
Yeah, some organizations make it damn near impossible to establish solid CICD for your code. If you can break out pieces into an approximation of that, you're one step closer. 
Automapper... One of the most beautiful piece of code we have in the .net space with the most terrible documentation. I keep finding new features of this library... 
Or use NuGet.Server, which works somewhat more reliable in my opinion because you can restrict deletion of packages and such. We actually distribute all of our internal libraries via NuGet and never check in the binaries. All our projects which use internal libraries all download them from our internal NuGet server. It works great!
Well, I was hoping that I could use something like this for automatic documentation creation like DocFx, except actually works. The only "recipe" it has though is "blog". Looks good though. Anyone know of something similar to DocFx that: * Works * Doesn't require it's own whole HTTP server just to view static files?
Sandcastle might be worth a look
Thought it was dead back in 2005?
jekyll stock minima theme :)
I am new in mvc5, Here's my code, I don't know if it looks correct. ` public static void RegisterGlobalFilters(GlobalFilterCollection filters) { filters.Add(new HandleErrorAttribute()); } `
The only things I have in the _Layout is -Styles.Render -Scripts.Render -Html.ActionLink -RenderBody() -RenderSection("scripts", required: false) Edit: In my index, I have an Html.Action that return a partialView. When in comments, I'm no longer stuck in a loop, but now my partialView doesn't work. Is there an alternative?
Identity 2.0 handles most everything you need with all the little things. Honestly, the biggest drawback is having to hand-craft a active directory system that works with the db, but once done once, it's done, kinda deal. Once you create a project with identity and the db is set, you have to manage roles at that point, which is ezpz with mvc tags. Edit: and as far as I know, Web forms is dying off so if your starting something new stick to mvc5 or .net core
I found my problem. In my index, I have an Html.Action that return a partialView. When in comments, I'm no longer stuck in a loop, but now my partialView doesn't work. Is there an alternative?
&gt; but now my partialView doesn't work. Is there an alternative? I'm afraid that with so little information, I wouldn't know where to begin helping you. I'm not even sure what question you're asking.
I'd recommend you use Asp.net Identity 2.0. Don't worry about that nonsense of writing your own interface for AD. Just use the Entity Framework implementation and save yourself that hassle. 
my @Html.Action("Calendrier", "tblActivites") call a ActionResult than return `return PartialView(tblActivites.ToList());` Calendrier is a cshtml view with a little calendar with notes in it. It's supposed to write the calendar, but after merging (somone was working on the calendar and someone else on the login), if the html.action is there, it redirect on the login page. 
There is no harm to be done in considering potentially mediocre applicants, that's what the interview process is for.
I was going to remark that it probably takes the .NET runtime longer to startup then it takes a Go static generator to generate an entire site. Hadn't even thought about Nuget. Right tool for the right job people.
Cool. Does it take C# files and generate doc files based on the xml documentation tags on methods and classes etc?
Wyam uses NuGet to deliver modules that have external dependencies (for example, the Markdown module requires Markdig). There are a ton of modules, each with their own dependencies, so shipping them all in the box would be including a ton of libraries that most people would never use. This approach also allows module packages to rev versions independent of the core library if needed. In theory this should all be lightning fast after the first package restore. Once the needed packages are fetched the first time, the NuGet API should just verify the local versions of the whole tree on disk. Unfortunately, those APIs still go to the network to verify the package dependency tree, even if you already have the packages. I still like the underlying concept of delivering a lightweight core generator without any external dependencies and then bringing in the modules that require something extra as-needed. I have some strategies for dealing with this, so we'll see if I can make it better.
I'll echo the other two comments, and add a few things. 1. DO NOT use web forms. It's archaic, and you'll have to build a lot of stuff (login pages, forget password pages, etc) that you get for free from a real identity system. 2. Use Identity 2.0 framework, and utilize roles. 3. Use an external identity system. There are many to choose from, but you can use Azure AD for FREE (up to a certain number of users), which includes login page, 2-factor auth, etc. Within Azure AD you can set up groups that represent your different organizations. Those groups are then returned as role claims in the identity. Guess what else? Does your company use O365? Then they already have an Azure AD identity and you can just use that. Same ID &amp; password. 4. If the corporate security overlords want to keep everything internal, just set up an ADFS server and auth against your AD/LDAP server via Oauth2. You can configure the ADFS server to return AD groups as roles. 5. Want to know how to wire it together? Just open visual studio, create a web project, select the webforms or mvc template, change authentication to `work and school accounts` and it will prompt you for the metadata url. (You'll have to configure your application url in Azure AD and then get the metadata url.) There will be all the code you need to auth against an external identity system using Oauth2. 
Is there a specific extension or NuGet package you are trying to use? You are going to find that Visual Studio tooling for MySQL will come from extensions as the typical relational database choice for a .NET project is SQL Server, so all of the built in tooling by is geared toward that product. Also, I know nothing of the requirements for your project, but I would *almost* universally recommend against connecting directly to a database on the internet from a client app. I know this may just be a toy project, but it is still good to practice using best practices when you can!
Nope, I am an independent software developer and I am creating an application for a guy to edit data on a database. Some of the data is going to be encrypted, so he can't just type it in himself. The reason we're going with MySQL instead of MSSQL is because GoDaddy allows infinite MySQL databases but only like 10 MSSQL databases (or something like that). I know that modifying a database through a client would be not ideal in most cases, but this guy will be the only one using this application so I'd think it would be fine. Anyway, I will look into some extensions. Thank you! 
Do you have any good source to learn this? I'm new to web authentication as well
The interview process is not free. Employees involved in the process probably cost around $25-75/hr to employ. An interview may take a few hours, and may involve paying travel and lodging if the interviewee is not local. Meanwhile whatever energy employees spend on the interview is not spent on otherwise productive work.
Oracle has a MySQL connector for .NET. The version I'm using is mysql-connector-net-6.9.9-noinstall. You unzip the archive somewhere on your computer and add a reference to your project. Use the MySql.Data namespace in your code. The issue with this kind of a setup is that the database username and password are sent from the client to the server. If the connection is not encrypted, then it can be intercepted and read by a malicious user, giving them direct access to the database. A HTTPS web service layer in between increases security manifold for very little increase in development effort. In my case, it's over a local network. So security isn't such a big deal. But we know we'll have to build a web service eventually when the product has to expand over multiple networks (or the inevitable demand for mobile access to data).
I feel like you've never been through the interview process for a programming position. A simple tech test is easy enough to send out and eliminate mediocre applicants.
Most of godaddy"s databases for use with their shared hosting don't allow remote connections, they only allow connections from localhost or other godaddy servers. You likely won't be able to connect to the database from a win forms app. Dump go daddy and jump on digital ocean.
indeed, linkedin, reddit etc. Hackernews does a monthly whoishiring thread, where you can post a job-posting. Depending on your needs, you can go to a local meetup( or organise a dot net meetup) to meet up local dot net developers, on the other end of spectrum, you can post here at /r/forhire . PS: I am not sure if job posting is allowed in this subreddit. 
&gt; But please note creating such an interface is a HUGE security risk. No matter what kind of authorization you use it is easily breakable so do not plan to use this type of solution for sensitive data. Eh? A web service over HTTPs is a pretty common way to transfer all kinds of data, and is sufficiently secure if done properly
Thanks, I joined Gitter and saw what the problem is and your answers. This would be a great feature. I hope I will use wyam for some projects, I like the idea. Another thing that is important is more recipes, I know you are working on this, too.
No, I mean @daveaglick. But it is okay, he answered everything on gitter, mails can be missed, this is for sure. I din't even thinking writing to Scott, honestly. I know people like him are really busy, and while I have nothing important to contribute, I will be silent as lamb! 
Yes, over a securely set up HTTPS. I don't want to hurt OP but do you think he will set up everything correctly? Creating a secure open web service is not the easiest thing especially if you are doing it for the first time. And he didn't stated what he is trying to achieve, it is very possible that he is creating an application for a company or something - I seen such a scenario before, where one of the employee wanted to make thing easier, went thought the same path what OP is tried to do, found out web services, written a simple login page where the application sent a username/password combination, and voila, he was able to download sensitive information and with a query or two you could access basically every invoice, prices, partner contacts and passwords. And basically everyone else who got an access to his application and had about two minutes to decompile the application. And even if you set up a HTTPS web service correctly it is still can be a security risk (especially for developers without experience) as it could be found, and you need to take great care to process and sanitize every input which is often forgotten somehow.
I don't see any reason a professional developer couldn't do it: it's not that difficult: although perhaps working in a medical setting, I'm a little too used to developers being proactive about security
Now I envy you - I used to users and developers has no freaking idea what is this "security" thing. In the current company where I work the previous developer team set up wonderfully everything. We have about three password, one password scheme for users, they used plain text for password storing, SQL commands processed as-is... We stored ten thousands of people personal information in this way. My first two month was to reset everything, write a completely new site, create new database tables, buy and set up SSL certificates - I work here for more then a year now and I since find things which freak me out. The previous site (for some very strange, not understandable way) used about ten ASP web service which handled the data between the sites (all running on the same server), all of them was accessible from outside WITHOUT ANY FREAKING AUTHORIZATION. And the story what I told was from the last company where I worked. I have PTSD from this :\ All I see is security holes all around me.
Don't worry, some of us started around the early DNX betas, and we still don't get it (and are possibly even more confused). 
Yes, I'm aware of that project. I chose to write this validation project instead of use that one for three reasons: * First and foremost because I needed my validations to run asynchronously and in parallel. Some of the code I work against goes against some legacy WCF services and DB2 databases, both of which seem to do a great job of asking stuff really slow. This validation code made asking some of those sets of questions up to 10 times faster. * I prefer decorating my classes with attributes to writing whole new validation classes. It ends up being less code overall. I like less code. * I wanted to be able to validate dynamic types inline. In most cases, I have a model and use the attributes, but there are some things I want to just build up dynamically from user input, then validate, and show the user all the validation errors at once. Maybe I missed something in the documentation of fluent, but it didn't seem to hit those notes, and what I wanted seemed far enough away from what fluent currently is, that it would have been more of a battle to contribute to it than it was just to write a library that targeted those goals.
But once you touch that claims identity you have to hold its hand throughout the rest of the app....
Tons of supported DBs on release. Nice job!
Cool idea, but it's not clear how to use this in the browser with something other than web sql / local. Most web apps need persistence / multi-user. Ideally I'd need a way to have them make RESTful calls to a ASP.NET Web API. SUPER Ideally, we could have a .tt file to generate matching Web API methods / .NET POCOs from an existing database.
I have the Precision 5510, and its a beast. You will love it.
I've enjoyed the Razer Blade. Sharp screen (QHD+), wicked fast, and more than enough power for the dog that is visual studio. I've bought a new one every year as well, they're great machines. And you can play a game on it when you get frustrated with coding and release some of that stress! 
Oh, I understand why it's using Web SQL, I'm just saying that since this was posted in /r/dotnet it would be nice if there was a way to use it in tandem with the most popular .NET backend for web apps (web api).
I pretty much hate OData, but there is a workflow that you could use to generate your TypeScript ORM(ish). If all you're mapping to is an EF context, it's really easy to create OData Web API controllers for them, next, wire up Swashbuckle to get Swagger documentation, then use Swagger code gen to generate a TS/ES2015 library against Swagger.
I have the XPS 15 and it's fantastic. Great keyboard, great screen, great battery life, processing power is ample for coding &amp; compiling etc. Recommended if you end up leaning that way!
How do you mark a column as required/optional?
Typescript? ASP.NET or SQLite?
My experience is that OData works great if all you're doing is following the happy path and directly tying it to an EF context. I prefer DDD, so I have some level of abstraction from my data context. My opinion is that good software should be relatively persistence agnostic; that is to say, I should be able to easily choose to use EF, NHibernate, MongoDB, whatever else... without having to make too many changes above the persistence layer. Within that context, mapping OData across a few layers becomes an absolute bitch. Much more work that it's worth. On the plus side, OData is pretty amazing for querying over a fairly flat remoted context. All you need for that is to map the API model you're returning to an IQueryable (easy to do in any modern .NET data context) and return that IQueryable&lt;TModel&gt; from your controller. You don't have to use any of the OData stuff for that; Web API includes it. That gets you 99% of the cool shit without having to deal with all the headaches. The other downside to OData is that it envelopes everything. I believe that is a legacy thing that they're holding onto because of the desire to support JSONP. If you just use IQueryable, you can set your paging, record count, and other metadata in HTTP headers, which is cleaner and probably more along the way the Internet is designed to work (especially in 2016).
Does anyone know if you will be able to update the RC directly to the RTM or will it require a reinstall? My concern about it being the latter is why I have not downloaded it yet (VS adds **A LOT** of stuff even on a basic install...not wanting to uninstall/reinstall that many items). 
Then it might be worth trying with this update? Depends how bothered you are! I certainly wouldn't use any preview/RC release for "production" though. Even though it's "just" a personal project for yourself, there's still no need to be on the absolute bleeding edge for what you want to do. It's more just fun to play with :)
If you have the ability, set up virtual box with 15P3 installed. That way you don't mess things up even more.
Set the expiry in the past
there is a `nullable` options in the column options, e.g. `@Column({ nullable: false })`
Nice. IIRC the old one *started* at around 8Gbs. The old-timer in me is thinking a clean install would be best though..
I tried that and it did not work. Unlike ASP.NET, ASP.NET Core has an explicit Cookies.Delete method. It can't be more obvious than this and well, it does not work in my computer. 
I have both open at all times, and use each throughout the day. I guess it depends on your individual scenario, but if you don't need VS, then I don't see why you would use it. So, you either need it, or you don't. 
Sorry, but I have no idea what you are saying. Care to elaborate?
Can you tell me what course did you watch? in pp if you cant do it here. I want to learn asp.net core but i am not sure is there any good resources for that. p.s sorry for tarzan's english 
Not really. The framework offers a lot of functionality still and producing the instances is very easy. I just wrote a bunch over the weekend around it all. Way easier than using identity, which is very hairy to implement due to how it overuses generics.
In my experience, having the right connections come from doing the work to get noticed for being a potential MVP. If you aren't visible in the community, it doesn't matter who you know. There are plenty of people who have great skills and know lots of MSFT employees but don't do any community work and only do tech when they get paid. Those people aren't MVPs. 
I'm still not entirely clear on why you'd want to do it this way. It's useful to know by declaring the interface implementation explicitly that it can be hidden, I'm just not convinced on why you'd want to do that. The point of an interface is that it's a contract. All that effort to do this: public void Delete(TEntity entity) { var softDeletableEntity = entity as ISoftDeletable; if(softDeletableEntity == null) throw new NotSupportedException("Entity must implement ISoftDeletable interface"); softDeletableEntity.Delete(); } Why not just do this in the first place? public void Delete() { throw new NotSupportedException("Entity must implement ISoftDeletable interface"); } Or just don't implement that interface if you don't actually support it? You'd get the exact same results. Seems like the author is trying to find a workaround to enable multiple inheritance, rather than just accepting that there's a reason C# doesn't allow it (By design).
I wonder if combining the `And()` and `GetNonZeroIndexes()` into a `yield return` enumerator wouldn't be faster. Would save a lot of array allocations at least.
Using events to build query read models is currently the best known way for scaling queries. Unfortunately its still eventually consistent - its a major limitation in terms of what you can setup for querying. If you have a query whose results change many times a second they will undoubtedly be times when you query and get a wrong result because the proper events have not been processed yet.
In those cases, you can consider using bools in your data model, but converting to a bitmask (or something else) to perform calculations. 
Will try that, but I think using a pre-allocated list will be the fastest since I am always iterating over it. IEnumerable (created by yield) would be the fastest if I would not iterate over it every time. But I will check and let You know.
For a scenario like that: If you look into data streaming tech like Kafka (for example), maintaining a high-speed "live" source off a stream while having "more eventual" consistency in the rest of the app might let you have a nice hybrid win/win. Vaguely like "the lambda architecture"... Just a thought :)
Sounds like it's a bug in CHROME, not ASP.NET Core. The ASP.NET Core team may not be able to do anything about it. The way to be sure is check the Set-Cookie header that ASP.NET Core is emitting and see if it matches the official spec for deleting a cookie.
There is no meaningful answer to this question if you mean the runtime. The requirements for the runtime are trivial; the real memory use will be by the application you are using .NET Core to run. So you would want to look up the memory requirements of the specific application. If you mean the development tools, .NET Core development tools are available for Visual Studio 2015/2017 and I think Visual Studio Code, so you would want the memory requirements of whichever one of those you want to use.
I hit a crash bug in Chrome Stable every day. Hasn't been fixed in months. Don't be too sure. By your own logic. ASP.NET Core is just the new version of ASP.NET, which has been around for much longer than Chrome and widely used, so the bug must be in Chrome.
Thanks. I am clear with the distinction. I am using IResponseCookies.Delete method from ASP.NET Core and found out that it did not work as expected. 
I doubt there is a single line of code from ASP.Net in ASP.NET Core. They pretty much rebuild everything. Anyway we shall see. The bug report has been moved to the [HttpAbstractions](https://github.com/aspnet/HttpAbstractions/issues/743) project.
So you are saying the remote client connects to your app to give it the information? Look into MVC. You'll want to make a controller class with a method that will take the incoming information and store it somewhere. You can assign the method/controller a URL, then the remote app just needs to do a HTTP request to that URL and provide the data in the POST or whatever (you have access to the HttpContext so you can grab POST data on your end). As for the rest of your app keep in mind there's no graphics manipulation so you will be unable to generate a pie chart server-side easily; I would recommend doing it with browser APIs. There are multiple ways to display the data, but I would recommend a second method on your controller used to retrieve the data (for use by the actual web page displaying it), then your web page is just static HTML/CSS/JS that you set your server up to serve using the static files startup stuff.
Thanks.
The free tier is not time limited however there is no free tier for SQL server. Iirc the basic SQL server is £4 a month but I'm not sure - there should be a pricing calculator you can use to find out 
You can find Azure's pricing calculator [here](https://azure.microsoft.com/en-us/pricing/calculator/). The free tier of a web app gets you 1 GB RAM and 60 CPU minutes/month. The cheapest SQL server is just under $5/month, so that will dictate your minimum cost. If you have a Visual Studio Professional or Enterprise subscription, you also get Azure credits that reset every month ($50 and $150 respectively).
I figured it out. Using a proxy was actually messing me up. I ended up installing Bluestacks and watching traffic with Wireshark. Poof, the websocket request appeared. Thanks though
I built a production Azure web app for a client. It's been running for several months and the client said they're paying about $5 a month to cover the SQL db.
.net core web app soon. I'm having all sort of random problems so I bounce between the two
I wanted to create what would be essentially an account manager which would write to the database, and then separate client applications would access this database and check the account credentials. Do you think I should write an asp.net application and host it instead? Or how else should I be doing this? I want it to be as secure as possible, where this winforms app can create/update/delete accounts but the other clients can only log in
Code behind? In MVC? You’re thinking of the obsolete Web Forms. MVC has its business logic in the Models and its DB access in the Controllers. For example, you define a DB table in the model, and use the controller to fill that model and submit it to the DB. Or you have a view model that you fill from the DB (using the controller to pull data from the DB’s model) so that the data can be displayed in the view.
Seems pretty good. I came from webforms so I firstly have to be familiar with MVC, but all you wrote seems legit. Thanks!!
I got curious about what can you use ref return and ref local for and found on the Roslyn github repository [this feature proposal](https://github.com/dotnet/roslyn/issues/118) for ref return and locals. According to the github issue the main objective is to avoid copying big value types when you need to return, for example, one of the parameters, thus saving memory which I understand and is useful when your code must be optimized. This scenario only covers the return ref, I'm still lost about ref locals. Can someone explain me what can you do with these features apart from saving memory ?
Standard is a hard to define term. Boilerplate uses best practice. I don't use boilerplate but I have used the vast majority of patterns in solutions. Which part in particular are you struggling with? I recommend this as a good starting point for the patterns involved: http://aspnetboilerplate.com/Pages/Documents
If you want to get the most out of your spending. I made https://imgsli.com which is hosted on azure app service. It has a custom domain, and ssl/cdn is provided by cloudflare. So I only payed for a small app service plan and the domain. Most of the traffic is caught by cloudflare, and ssl is provided for free. :)
You can tell Azure to suspend service when you run out of credits, rather than charging you extra.
&gt; I want to package it now as an exe file that can be run on PC &amp; Mac (or a file for each). You can't. **.exe** files are Windows only. There are two distribution options: Shared and standalone. With the shared option (which you do not use currently) you get a **.dll** file. This file can then be executed using the .NET Core framework that must be already installed on the target system. The runtime of the system is shared. With the standalone model (which you use) you get an executable file that can be just used at the target system. It ships together with the runtime. But that of course means you need to have a different compilation for each target system. .NET Core does not magically allow the target platforms to execute binaries of a different format. It just allows you to write code once and compile for different platforms.
Yes, I just said .exe as I have 0 experience with macs, I meant an executable file on mac. A file which a mac user can execute to run my code, I don't care what the extension is and not requiring any magic. Just a file a mac user can run. I get an error though when I target mac as in linked article and in my windows folder (which does support exe files there is no exe file).
&gt; The guy never said exe files. Yes, he did. This question on StackOverflow stated: &gt; an exe file The title of the question was: &gt; Making a self contained crossplatform executable That heavily implied that he was referring to an `.exe` file.
Thanks, that seems to have worked, the documentation made it seem like any frameworks listed would be generated on build 
We use Command Query separation. Easier to use than the standard repository pattern (unit of work) which is a redundant anti pattern. 
What extension should I expect after I publish to mac?
Cool, thanks for the thorough response. Right now I'm using Identity and Entity and have managed to pass user information to my view, however, as you mentioned, maybe "Sessions" would be useful here. Right now data from my DB is going from my Controller to my View as an object with properties that are strings. I haven't googled around about Sessions yet, but does this sound like an instance for its use? Also, shot in the dark here, do you know how to cache this retrieved user data? I think it's something that would be handled from my Controller.
The core package is out of preview / 1.0.0 as of Dec 1st - https://www.nuget.org/packages/Amazon.Lambda.Core/ Here's the release annoucement - https://aws.amazon.com/blogs/compute/announcing-c-sharp-support-for-aws-lambda/ To install, just do: Install-Package Amazon.Lambda.AspNetCoreServer -Pre 
It doesn't really matter. (For context) If you were compiling an old-school .net executable then it doesn't matter because you don't actually run it. You have .net run it, and it can have whatever extension it feels like. But it wouldn't matter anyway because... As you are compiling all the way to a native application, the convention on a unix is no extension at all, but it doesn't matter if it has one or not, and it doesn't matter what it is (more on that just below,) since it can still be executed. It may be helpful to remember that extensions aren't really even a thing on Mac OS, not, at least, the way they are on Windows. In Mac OS (and this should be true of all the unixes and unix-likes, really) they are just some characters which happen to be included in a file's name.
You're right, managed to get a use of a mac and the file that ran didn't have any extension (but I initially got blocked as an unidentified developer)
There are plenty of hoops to jump through, that's for sure. ;) Sounds like you're on your way, though, so that's great.
Thanks! That applies only to VMs, and their usage of *Stopped* on the last one is confusing. For an app service like what OP is asking for, I believe the only way to not get charged is to delete the service.
in 2017
We can help you out, 18+ years experience mainly on c# and asp.net, now also mobile and xamarin. Check out http://github.com/okhosting http://okhosting.com (spanish) Free, no comitment quote ;) 
Our company is structured much like what you've outlined and we've had A LOT of terrible employees when we didn't hire people we already knew. I've seen resumes that make you think the person is overqualified for the position, but you bring them in, put them to work, and it turns out that their 5+ years of Excel was nothing more than entering numbers into column A while under constant supervision of someone that knew what they were doing. I would look for people that are used to working without a manager, have worked at a small company or startup, know what to expect when taking a non-corporate job, and can actually jive with the personalities of your other employees. Run everything by your other employees and get their input as well. Programmers can be extremely pessimistic by nature, which is a good thing when looking at resumes.
As a .NET developer I am trying to figure out the other side of the coin. How do I assure another company that I am competent and responsible enough to work remotely?
Offer a trial period where they sign you on a contract for a couple of weeks. If you're already employed, suggest they find something you can work on after hours. Organize with work to cut it early at 3pm for a couple of weeks so you can get some cross over. 
All good suggestions thank you. :)
Do your own side projects that are solely you that you can demo and put them on your resume. It doesn't have to be anything huge - you just need something that demonstrates you can do the job.
I work remotely and while I can't tell you HOW to find what you're looking for I can give some insights from my own experience: 1. Remote developers need to know more than coding. Troubleshooting network and operating systems is essential when you don't have on site IT support 2. Comprehensive knowledge of source control and other related areas like continuous integration / continuous deployments should be demonstrable 3. Accountability for assigned work goes beyond just getting things done on time. The developer must be able to identify as early as possible whether what has been assigned is feasible prior to delivering the work for QA to avoid delays caused by the back and forth that inevitably occurs when something is completed incorrectly
I have been working remotely since 99 (Not looking for work) This is what I do to make sure the client is happy and trusts me. The first week I work on site -- and make sure to show lots of progress. I tend to work at night from the hotel room as there is nothing else to do. Second week I work from home. When I work from home I am always available for phone call, skype call, skype message between working hours. For me I am make myself available from 8 till 6 -- I even reply to emails or take calls on weekends. The third week I am back on site -- again show lots of progress -- by this point I am rolling well with the project. After the third week onsite visits are determine on a need basis at this point the client trusts me. The clients knows that if I need to be onsite I will be onsite. Complicated project I tend to have more on site meeting during the planning and design stages -- planning and design works much better in person than remotely. The critical part is communication -- if the clients sends an email about an update on a certain task which was supposed to be worked on but wasn't do not ignore the email -- reply to the email or call the client. If the clients Skypes you at home and is not the best time -- take the call and ask to call back in 30 minutes. Show progress every single day. The important part is you are working for the client be available for the client. The other part is I don't come cheap -- it is also a function of how much you are willing to pay -- you get what you pay for. 
Skype interview. Once hired, if u have scrum stand ups, Skype video call also. I have seen people interview for someone else. Also a 90 day probation period in hiring agreement so u can get rid of people if he she does not match your expectations. Quick question, where do you post remote jobs?
I'd like to add my experience from the other side of the table. I have worked for the past 5 years remotely using C#. I would like to point out that in every one of my jobs, one of three things happened. Either 1) I knew someone in the company that could vouch for my skills. 2) I met someone who was hiring or knew someone who was hiring at a conference/meetup and kept up with them 3) I contributed to an open source project and was hired because my contribution demonstrated I wasn't a complete fool IMO, the last one is the best. If you can open source something interesting it is a terrific way to attract talent to your team. Even if you can't open source something - give back to an OSS project you use and you'll interact with other developers using the same projects. Honestly, every time I have to hand out a resume to a cold contact - I'm very wary of the opportunity.
&gt; I'd like to find someone that is mature, self motivated and trustworthy where I don't have to worry that things get done. Isn't that true of hiring in general? Why do you think this is only for remote employees? I'm not trying to attack you here; you're in an interesting situation where you've never hired someone you didn't already know. But this attitude towards remote work in general I find baffling. If they are remote, they have to be trustworthy =&gt; implies =&gt; If they work onsite, they don't have to be trustworthy?
Wish he would provide a sample input. I'd love to try this myself. I *love* code optimization blog series.
I basically did what /u/tdubeau said and managed to wrangle a remote-work position incrementally by cutting out early (with approval) to do remote-work projects. First I proved that I was competent in the office. With some established credibility I started out doing an occasional task from home and implemented the use of Slack and Trello for my remote work (we already used TFS/Git for source control). These tools provided oversight to my remote work and proved that I was productive while working remotely. After a while I leveraged that into working remotely more days per week, etc.
Seems like I would just be trading EF problems for Automapper problems. I have some common interfaces and a common base type, so it wasn't too hard to write some helper methods for the collections. 
Good point, we probably should use some screen sharing for the interview.
I'm a programmer myself that needs his Entropy Tower Defense match over lunch :) and understand that you don't have the same level of productivity every day. All we expect is someone that puts in 40h a week. All good points though, thanks!
Haven't thought about the IT aspect, I kind of assumed as a programmer you can troubleshoot your own machine. But now I will look more consciously for that.
We haven't made a posting yet, so far we have a head hunter look for people. But I'm thinking about making a post on indeed.com today.
AFAIK Msft doesn't distinguish: an Enterprise subscription gets you the credits regardless of how you got the sub. This is easy to check, though. Sign in to the [subscription management site](https://account.windowsazure.com/Subscriptions). You should see at least the VS Enterprise subscription in the list, which you can select to load the details. On the right is an info panel that will let you know if you have credits remaining ([example](http://imgur.com/T0kjzsT)).
Thanks for your reply. I checked that link and it doesn't seem to show any subscriptions. I might have misunderstood, I dont have a direct VS subscription, I have access to the Dreamspark program with which I can access License keys to MS Products (Windows, SQL Server, VS, Windows Server, etc.) which I can use to activate the products. However it is not a direct subscription to VS Enterprise, so I assume I am not eligible to any credit. Which is unfortunate since there didnt seem to be any requirements for a credit card, while the Dev Essentials 25$ Azure credit requires one. And as a student I am struggling to get one :/
&gt; All we expect is someone that puts in 40h a week. And with this expectation you will fail, unfortunately. I don't consider myself a unicorn/amazing developer by any means. However, I do think that I'm good. I have multiple apps and shit all over the web and my linkedin is filled material that gives recruiters orgasms. Basically what I'm saying is that I am confident enough that I can hold my own and have been doing so with my current gig for the past 4 years, fully remote. So with your expectation of "they just need to put in 40/hrs a week". For us remote guys, fuck that. I get my shit done in 15 or 20 while the in-house guys struggle to get done in 55. I don't work 9-5. I work 9-11 3-5 11p-1a. Basically, I get my shit done and I don't miss scheduled meetings. You need to get a hold of me if I'm not on lync? Call my cell, I'll answer and get to my computer when I can. So what I'm really getting to - do you want someone who justs puts in 40 hours a week and struggles to get their shit done, or do you want someone who gets all their shit done and then some in 15-25 hours a week? My current gig is full benefits, fully remote, 6 weeks PTO, and there's no set amount of hours I need to work each week. We have an agile board and all my tasks need to be set to done by the end of each sprint. That's the only thing that matters to my boss and his boss (and his boss too...). Don't get me wrong though, there's been more than a handful of times when I've put in 80 hours a week... You just do what it takes to get everything done. That's the expectation that my team has. 
id be the best remote worker anyone ever hired if only i could actually program.
 Hi, a little late to this but I thought I'd offer my thoughts. I've owned a small consulting company for 6 years, and find myself on both sides of this fence. We specialize in eCommerce integrations, and regularly contract out looking for WFH people with experience on a specific platform. What I have learned: 1) I tend to only hire those who have worked from home before. 2) Candidates must have proven deliverables (working at home) through professional references. 3) Are willing to provide detailed work-logs for billing 4) Are willing to meet every day at a consistent time (even if you don't actually meet every day, they need to be willing to demonstrate consistent communication) On my end, I find having the very best specs to hand off can save tremendous heartache. I'll put more effort into getting my subcontractors good specs, then I do on the projects on which I do the development. Don't make it easy for them to sit idle - define the project and timeline as well as you possibly can and demand top-tier communication.
The dataset is in polish. So I don't know if it would be any use.
Haha, it's never too late to learn!
I have been dreaming about using CQRS and Event Sourcing at work for a few months now. It would make life a lot easier. One day...
http://www.hanselman.com/blog/SelfcontainedNETCoreApplications.aspx maybe?
I am aware of explicit implementation, but I am not sure why I would ever use it. And this example doesn't help, because I immediately jump to this implementation in my head. interface IPrint { void Print(); } class TestOne : IPrint { void Print() { //... } } class TestTwo : IPrint { void Print() { //... } }
&gt; hey it's me ur .net programmer Sorry, don't really have any advice.
I have rooled my own oauth library 🙂 took me a week to code the parts, but it works. In this way i dont relay on third party to do this when it is something critical. 
Have you tried using single quotes? I know you're using mySQL which I'm not that familiar with but that might help. Also Try replacing "Server" with "Data Source". Again I am not familiar with your setup and frameworks.
Are you setting that connection string in code or in web.config? Do you have the MySql .NET Connector installed? http://dev.mysql.com/downloads/connector/net/
Some good points raised there! When our dev joined us it was his first remote gig and he was blown away by how mature our platforms are. We invest in tech pretty well and I think we've ended highly efficient as a result. Some apps we use; - Slack - this one is pretty common but getting way better with the introduction of VOIP and now video calling - We use an addin for slack called statushero. It's a bullet point status checkin program which you fill out each morning to summarize what you did yesterday, what's planned for today and what your blockers / risks might be. - Visual Studio Online - TFS and all our software development planning - Frontapp - It's an email program which allows us to hook in mailboxes like accounting, support, recruiting, sales etc, share all those mailboxes and delegate / assign individual items / conversations to other people. We can move conversation across boxes, integrate various API feeds (like our bug reports), SMS numbers etc. We can also collaborate on replies and drafts etc inline, it's great. - Asana - Primarily for our non-tech stream but there's a middle ground with tech. We use this for all of our project plans,action items etc. They've just introduced storyboarding which is a fun concept to share with the non technical users.
You're optimistic. Generally I find that when people choose to implement themselves they've done no research all.
How is ASP.NET Core's cold startup time? My team try to host our Java service at lambda but due to its long cold startup time we try to replace it with something else. So far the candidate are scripting language (Node and Python), but if .NET Core is fast enough, we might be as well using it.
Have a look at controller authentication and authorization filters. 
Thanks! These are totally new terms for me -- appreciate having something new to search for.
Im using the Entity Client
Ah, okay. In that case, you need to use an entity connection string. They have the database connection string embedded in them along with some additional metadata specific to the entity framework. I'm on mobile at the moment, but this link may get you started: https://msdn.microsoft.com/en-us/library/cc716756(v=vs.110).aspx
Ok, thank you. Ill try this out tomorrow
Im using the Webconfig File to connect to my database
Do you have the providerName property set on the connection string? If you omit it, .NET assumes it's MS SQL, hence the error.
Use Identity Server 4. You seem to have a pluralsight subscription so I recommend you watch the course 'Using OAuth to Secure your ASP.NET API'. That is a recent course that covers *exactly* the scenario you are describing (separate JS SPA + token-based auth with username/password or social logins). It is really easy to set it up, I went from not even knowing what OAuth is to having a full Auth Server set up in 2 days.
It's pretty fast. ASP.NET Core is built around only using what you need. In my tests the first time took a few seconds to load the container. Then always quick after. I was using MVC with a controller that returned environment variables of Lambda. The publish package was 1.5 megs which is actually smaller than the base node.js package in the console listing. Java Spring boot always takes longer than ASP.NET Core to load locally for me.
IsReadOnly for the IList interface. No reason to expose it on the public interface.
Look at how ImmutableList implements IList.Add.
Thanks! I'll take a look into these -- the titles sound promising.
Thank you very much for the thoughtful and detailed response. If it's not too much trouble though, could you elaborate a bit on your comment that I can use ASP.NET Identity with Web API no problem? As I mentioned, that was my original thought, but I really haven't been able to find much out there about that use case. Can you suggest a guide or (even better) an open source project doing this?
Thanks for providing the info! I've been working on an IDP which will support OAuth. I'm planning on using DotNetOpenAuth but I'll have a look at those links as well.
How can I go about doing this?
You'd have to research the spec, but it's unlikely OP actually had a legit reason to reinvent the wheel.
The code could be useful for the community :) I worded my question poorly, I'm not too worried about the general OAuth1 to OAuth2 migration, its the "dealing with linked in part". We aren't trying to integrate a LI sign in, we only need to post to new articles/blogs from our client's publishing site to the company page on LI. 
Anything helps, thanks
Have you seen any tools for converting web config transforms into parameters files? 
Octopus Deploy does this if you deploy with it.
Have you looked at a SaaS solution like Stormpath? Sure, I'm biased, because I work there, but https://stormpath.com/blog/angularjs-asp-net-core-tutorial is a WebAPI + Angular 1.x example, and we also have a React SDK. Just a thought.
&gt;The thing is you want 1 single package for all your environments Yes, I'd like to have one package and be able to deploy from it to different environments. At the moment its all in config transforms and we deploy with "publish". Its a "family" of sites, so there is lots of duplication in the tranforms of each site. 
Yes, it is not really proprietary software, and is in fact the most open. The alternatives are SaaS/PaaS like AAuth0 or Stormpath which are truly proprietary. There's also the smaller OpenIddict but I haven't checked it out. 
Are these the `[Authorize]` attributes? The core documentation doesn't exist for this topic :(.
Working remote for 4'ish(?) years in .NET development and here's probably my only advice: Make a deadline for your projects/milestones. Ensure it's reasonable. If they hit it, then they're fine. Bug them once a week asking how things are going, where they're at. I don't think you can really sniff these things out before hiring but it doesn't even matter if they're remote or not, it's an issue with both office workers and remote workers. Man, can you imagine a world where we could actually instantly determine if someone is going to work well or not? Hahahaha.
I've been using OD for over an year now. I simply love it. TeamCity to produce the nuget package and OctopusDeploy to deploy is simply amazing!
You can also make Octopus run environment specific transforms when deploying. I prefer having everything, including setting values, in source control so I try to use transforms as much as I can. Also, transforms isn't something Octopus specific so it's easier for the rest of the team to understand. Either way, Octopus is very flexible so whatever way you prefer it's possible. 
Glad to hear that, that's the direction I was going for.
Save yourself days and days of headaches and problems. Use Octopus Deploy instead.
From some of the testing i've done, Octopus wouldn't build my website without a .csproj file. Unless I missed something? Websites don't have a .csproj, but can have a solution file. I think it was an issue for me because the solution also has other projects in it? What was your setup like?
Websites do have a csproj file, every project within a solution will.
Another thing that may help in this setup is using Library Variable Sets, as these can be shared across projects. 
Consider hiring people through Upwork. As a third-party, they take some fee of course, but you get resumes, portfolios, histories and, most importantly, feedbacks about your potential contractors. .NET programmers are one the most developed sector there.
How? By virtualizating Windows on Linux. Kind of cheating. Does this mean SQL Server actually has better .NET support than .NET Core?
SQL Server has been around for a long time, upwards of 30 years. In addition, SQL is a very performance and memory critical application. As such, I assume a good chunk of the code in SQL targets Win32 APIs directly in a C or C++ type language. By creating what they call LibraryOS which abstracts those calls (think like DirectX for graphics libraries), then can still maintain those OS level calls without really having to have two completely different code bases for SQL. As for the .NET part of this, I don't think SQL server would run worth a flip written in either .NET or .NET Core as the framework presents more overhead than direct native OS calls.
I think thats a reference to sql server clr integration. 
Ever since they announced MSSQL on Linux, I always thought, "Why?" If you're going to have your DB on Linux, then Postgres is such an good fit for an MS dev, has an awesome feature set, and doesn't cost your first born son just to license it on a solid machine. Bring on the downvotes, but that's my 2 cents.
On the surface, yea, I agree with that. I really like what MS have been doing with .Net Core and VS Code. However, if you're serious about using the .Net framework on Linux, then you should also be serious enough to do your research to figure out what the best DB is on the Linux stack. The first issue is that SQL Server on Linux has no track record what so ever. I'm not sure how MSSQL was ported to Linux, but considering that there were some very low level hooks in the engine to have more fine grained control of disk writes, I'm not sure I feel comfortable with it just "popping up" on Linux with very few rumors that they were even working on it. DBAs are some of the least likely IT professionals to roll the dice on unvetted software. Second, anyone who has the mentality of, "oh SQL Server is on Linux now, so we can finally switch" is missing the point. If you want your DB on Linux due to windows licensing costs, then evaluate your different options and throw SQL Server on Linux in there. Having worked day to day with Postgres that was hosted on Linux while my .Net app churned away on a windows server, Postgress can go toe to toe with SQL Server and in many ways trump it, all while costing nothing. Licensing for SQL Server can extend into 6 figures very easily. That's where I have a lot of trouble seeing it as a viable choice. I could go on and on, but I'll leave it there. If I'm making the jump to Linux for my DB, then there's going to be a very narrow range of cases where I think that SQL Server is my best bet there.
I'll add that you should be really nosey about what they're doing all the time. Assume they're trying to fuck you and don't trust your relationship and day to day communications with them. They've been given a gift and need to earn it! That was all sarcasm by the way. I work remotely. Treat them how you'd like to be treated and trust them to do their work, otherwise they'll bounce.
I personally think F# is a better language, the problem is not as much support in the framework and visual studio, e.g. doing WPF with F# code behind.
I just have a hard time thinking anyone would consider Wine "production ready".
You are running the NET Core in Debug mode. If I take your example and run it in Debug mode I get:- `Elapsed Time: 19,185.8573 milliseconds` If I run it in Release mode, I get:- `Elapsed Time: 2,514.0627 milliseconds` 
I don't quite get why people compare F# vs C# as if they are some sort of mortal enemies in a world where there is not enough space for the two of them. They are both fully fledged members of the .NET family and should work together, not against each other. It pains me deeply to see constant versus battles of those two. 
How different is this compared to https://github.com/schambers/fluentmigrator?
It tells you when you are debugging it. IIRC its one of the first things it says.
As it says in the article: 1) Some developers refuse to write SQL 2) Some developers are terrible at writing SQL If you are just messing about then fine. But if part of your job is to use databases (which it probably is for most developers) then please just take the time to learn about databases. It's not hard and will make your apps run much better. The amount of crap software I've had to fix because the developers thought a shit understanding of EF was enough is amazing. Yeah, your app might work fine when you made it. But after 2 years when the volume of data just goes up and up your app will run like shit and you won't have the skills to be able to sort it. 
Well said. I use EF with lazy loading, but as soon as the call slows down, I'll replace it with raw SQL using Dapper. I've seen some people try to work with EF by using eager loading and .Include() calls, but I figure that's more painful than just writing SQL.
There is an optimize flag you can set in the project.json, but it is automatically included in the default Release configuration.
Does it have an implementation of a queue?
Both do very different things that, sometimes, look very similar. Tasks are a way to perform work without blocking the execution thread. Tasks predominantly beneficial for I/O or network calls, but they're useful in that they allow you to implement things like fire and forget methods and background processing much easier than you could before. Ultimately though, tasks are beautiful compiler magic, but don't do much other than allow for easier concurrency. Hangfire is about the infrastructure around doing background processing. In simple cases, you might just use a task for this, but as your application has more that needs to get done, simply firing off tasks is a good way for things to potentially get lost. Adding the infrastructure of persisting jobs, scheduling recurring jobs, clustering, and other things are examples of things that Hangfire does that Tasks were never intended to do at all.
AutoMapper's queryable extensions are actually really great for this. Won't match hand written queries most of the time, of course, but it beats trying to wrangle .Include()'s and so on manually.
Disregard. I was trying to do way too much work. The class was already doing what i needed without me even realizing it.
Yes. It allows you to implement multiple distributed queues for different pipelines of tasks.
Great!
I'll probably start using this and I do need some tools to increase the visibility of my new AWS .NET Core stack.
What about the other parts ?
&gt; That's just immutability, and we already have much more code Do we? It looks to me like we really just have more line breaks type Person = { Name: string; Age: int } let john = { Name = "John"; Age = 27 } let olderJohn = { john with Age = john.Age + 1 } vs class Person { public Person(string name, int age){Name = name;Age = age;} public string Name { get; } public int Age { get; } } Yup, looks like roughly the same amount of code to me. Okay, the C# code is now less readable, but at the same time, the F# code is less readable than the original C# code, so it's swings and roundabouts
"Never attribute to malice that which is adequately explained by stupidity" Or in this case, substitute "stupidity" for "Not realising Debug had any/as big an impact"
I wanted to write about all of my experiences with ASP.NET Core, including routing. There may be similar posts out there, but that's the case with every blog post ever written (well almost). My take on the subject was to write something more compact than the official documentation (which is really good actually) but also something more than just the 10 lines introduction that I've seen a lot of. Thank you for the feedback. Always appreciate it, even when people dislike what I write. Especially when reasoning about a downvote, rather than just clicking and moving on.
Your developers don't seem to be very qualified to be working on that system. 
It's not quite the same though. The C# version only defines the class whereas the F# version is defining the type and an instance followed by an updated instance. for the C# version to be equivalent you'd need some extra lines on top of that: var john = new Person("John", 27); var olderJohn = new Person(john.Name, john.Age + 1); So, in your example even with removing all the line breaks the class definition is still over 3 lines whereas the F# version the record definition is only 1 line and is still readable: type Person = { Name : string; Age : int } 
Hard to say from your example, but likely the reset password function will call a service or a database, so it would be that you would mock, not the user object passed in, which might only supply the user id and old/new passwords. If the reset function is on your user object (not ideal) then perhaps that is what you mean.
I would do this: /api/organizations?withoutLeaders=1 The *withoutLeaders *param would be a bool with a default of false. 
This makes sense, and is certainly doable. I am happy to help but struggling to figure out where your issue is. Are you not sure how to make the function signature or how to organize your data objects? You can certainly set the return type to be an interface or some sort of parent type, but haven't done the later yet.
Simplest example. We have a credit card processor. Lets say ICreditCardProcessor. Hopefully that's a service you are injecting into business logic. So it comes time to test the business logic. You want to test scenarios where a credit card is accepted, declined, over their limit, etc. Now you can moq ICreditCardProcessor to provide the behavior you want for each test (e.g. given this number and fail anything over this amount) without relying on making external service calls. Now, a lot of junior devs panic at this point because this means you need to trust that the normal implementation of ICreditCardProcessor works too. "I like the tests to run against the real one because it will show bugs there too" you might be thinking. But there should be a suite of tests around it too verifying it works as expected. That's like OOP 101 but people forget it once they start writing tests. Now full discloser, I don't fully trust that so we tend to have a Tests and Integration.Tests. In practice there are things that need to be verified. Like making sure a DbContext with the right object lifetime was injected, making sure that results are cached where expected, etc. Tests focus on business logic. We can run 1000s of these in seconds because they don't touch the DB, web services, etc. Then we have a very small set of tests in the integration project that run through all the steps to make sure they are wired up correctly. These take minutes. By using Moq we can add a lot more tests around business logic without worrying about them taking forever and a day to run while having the confidence that, yes, when asked CreditCardProcessor will work when injected.
Thanks I really appreciate it, and I can definitely see by this example how it'd be better/worthwhile but yeah it also can't take the place of the integration testing with actual objects. Thanks for taking the time. 
Correct. Remember with unit testing you want to test a very small section of code. The more code that actually has to run the more likely you're going to be running code that doesn't work elsewhere, leading to you failed tests that confuse what is actually broken. Let's say you have to test a function that logs a user in. That function takes in a user and a database connection object, then checks the database to see if the user exists and has the correct password. While you *could* use an actual database connection, it would be much easier to use a fake database connection that just responds with "YEAH SURE" when you ask it to validate a user. This is where Moq and other libraries come into play, they let you generate these fake yes-men objects easier.
I would go with this option. /Organizations is the resource (a collection of organizations) whereas withoutLeaders is a filter.
I think it's a question of semantics.
Or in IT, for that matter.
I hear you. I work on a system which was originally built 12 years ago so it has a fair chunk of early-2000's development thinking. All of the legacy tables are "supported" by a plethora of pre-generated stored procedures, most of which we don't use - they just thought it would be handy to have them. Thankfully, we are more enlightened now and have rebuilt bits with a much lighter and faster stack.
Since others have already answered your question, I'll weigh in with an alternative approach. If you find yourself building many custom endpoints for simple queries and such it may be worthwhile to create OData (or GraphQL if there's anything production ready for .NET yet) endpoints and allow the client to define their query.
I honestly prefer VS Code to Visual Studio at this point. I like the lightweight simplicity of the text editor. Extensions are nice. Debugging is competent. It's the same on multiple platforms. Great stuff. 
Nopcommerce is nice; lots of dependency injection and other things in there that you can learn from. 
I would do it like withoutLeaders=true
cheers. [link](https://github.com/nopSolutions/nopCommerce) for the lazy
From your description, it sounds like you are only signing the msi. Is that correct? You should be signing both the msi and app.exe separately. If you have a bootstrap setup.exe file, you should sign that as well. If you're currently signing manually via the command line, you can put the calls to signtool into a batch file (a text file saved with a .bat extension) and add its path to your post build action. Or, go full on and automate your build steps with MSBuild.
So how real-time can Signal get? Can it be a suitable fit for a messanger application? I don't know much about .net but im currently building a real-time application with firebase and really am considering switching to Signal and ASP to build it instead. I want custom functionality and firebases security rules just make me cringe. My only fear is that performance will be an issue. 
Thanks for the reply! Sorry, how exactly do I sign the executable? do I need to package my cert and password in the installer? signing the msi happens as the last step of the build in visual studio. I think it's a post build action in one of my .wxl setup files so I build the msi, sign it on my dev machine. I give the msi to a user who runs the msi, which is correctly signed. Then the msi will need to have a step where it signs the executable it installs on the users machine somehow? I'm sure these are pretty dumb questions, but I'm merely a javascript developer who has been given this desktop app project because the guy working on it left and we are understaffed. So I'm definitely out of my element here
https://github.com/Sonarr/Sonarr It's generally a good code base, and I think shows off a variety of techniques. That said its not perfect, but its a full application
Check this page on how to sign the bootstrapper bundle in wix: http://wixtoolset.org/documentation/manual/v3/overview/insignia.html You don't need to run the insignia-command yourself, you can manually edit the .wixproj files and edit the following: 1. Inside the PropertyGroup for your release configuration you add &lt;SignOutput&gt;true&lt;/SignOutput&gt; 2. Inside the &lt;Project&gt;&lt;/Project&gt; tags you insert two new &lt;Target&gt; tags. You need one for the SignBundleEngine and one for the SignBundle as shown at the end in the link above. Then it should automatically sign the executable bundle files when you build the project with your selected configuration as specified in step 1 above. An additional thing to note: In my projects I dual sign the bundles with both SHA-1 signing and SHA-256 signing. The newer versions of Windows (Windows 7 and later) requires that files are signed with SHA256 but older versions of Windows (Windows XP and Vista) can not handle files signed with SHA256. That is why I sign the files with both SHA-1 and SHA-256. To do this you just add two different &lt;Exec&gt; commands inside the &lt;Target&gt; tags in the .wixproj file that you add in step 2 above..
How were you able to add SQL DB without any costs?
Read through this. https://docs.microsoft.com/en-us/aspnet/core/tutorials/your-first-mac-aspnet It's for the Mac but the same stuff applies. 
[TailBlazer]( https://github.com/RolandPheasant/TailBlazer) is a pretty nicely written WPF app.
Breaking the 64-bit input apart into eight 8-bit quantities and then using a 256-element look-up table may be faster, especially if you can get the compiler to elide the index checks. Removing branches would go a long way to improving performance. You may also want to change the signature of the function so that it does not allocate a list, but instead is provided one. That allocation will cost you a lot, if you can make the program perform no allocations, it would also help. At the very least, consider initializing the list with a non-zero capacity so that it doesn't have to resize constantly. 
Probably a little too advanced to fit the "and are great to learn from" though, unless they're already at a reasonably high level. If nothing else, the sheer scale is reasonably daunting
Just to clarify - you should never ever ever give anybody the means to sign something using your credentials - it's like giving away your password. What you just said boiled down to "here, you login for me". Never give away your private key - if someone can sign something and make it look like it was from you, what's the point of code signatures? 
Really nice full stack app(7 repositories) https://github.com/Microsoft?utf8=%E2%9C%93&amp;q=bikesharing360&amp;type=&amp;language= 
I enjoyed the tutorial. I have a question for you, though, since it seems you have recently gotten into .NET Core. If you were to implement a dynamic real-time search (api/db call every 3 seconds from an input='text' element), how would you do it? Essentially, I have been having an extremely hard time finding the equivalent of listeners or events other than form submission or navigation... am I missing something incredibly obvious here???
In my opinion OpenRA (https://github.com/OpenRA/OpenRA/) does a lot of things right and is where I got my start. :-)
To simplify, how would you code a search box that calls a Web API on each key press of the search term? So, requests are made as you are tying in order to show a short lists of results. 
Well yes, but mocking enforces self contained code units. For example, if you are testing a UserController for example, you would know very quickly when it gets out of control and you're mocking about fifteen dependencies 
It's a perfect fit for what you're describing. I've used it a fair bit for real time relay of industrial plant data in both server to server and server to client scenarios and it's brilliant for that. I've always found performance to be very good, but obviously that will depend on message size, transport type (websocket, server sent events, etc) and so on.
Use something like typeahead.js (https://twitter.github.io/typeahead.js/). But your question isn't related to ASP.NET Core in any way. A Web API handling the requests from typeahead, can be implemented in any web framework in any programming language :)
Yeah, I've been waiting for R# to include an option not to flag `int` and `string` for `var`. It looks like you can do this with `csharp_style_var_for_built_in_types`.
ill give it a try and tell you how it goes. 
Sign the EXEs... That did it, now everything is signed correctly. I assumed signing the installer would sign everything else too. Thanks so much for your help I really appreciate it. And same to everyone else in this thread
wow, didn't realize OpenRA was written in C#. Cheers
Arguably it's more readable. My first choice would also be to simply to check the variable in combination with the negative operator. Keep in mind the OP asked for "open source" projects to review. If your offended by someone else's preferred methodology, especially when valid by different to your own preference, then open source probably isn't an environment you'll feel overly comfortable within. 
&gt; If your offended by someone else's preferred methodology, especially when valid by different to your own preference, then open source probably isn't an environment you'll feel overly comfortable within. I'm not sure how that's relevant. I'm not offended by it. The OP is looking for open source .NET projects that have well written code, presumably to learn best practices and good standards. In my opinion, this code base is not a good example.
What I was after was a collection of sources that I could read and just get a feeling of what people are doing lately - everything from minor code style to overall architectural design. In my experience, people's coding style varies significantly and it's important to see how things are overall and not get put off by a few minor pieces here and there if they don't fit within my specific world view. There are many ways to skin a cat, right? For me, it's important to read and learn from codebases, especially since the last 3 major projects I've worked were codebases I architected and set the overall style. These projects have grown, are still active. They are based on SOLID, have high test coverage, some cloud-based and service-bussed. Over the years of my career I've seen architectural styles come and go. Each fit better within a certain requirements. I accept that the world is complex and varied and ever moving, so being humble, knowing I don't know everything, and learning from others is a great way to improve oneself. 
Good discussions happening on [/r/programming](https://www.reddit.com/r/programming/comments/5jdosy/why_exceptions_should_be_exceptional/) and [/r/csharp](https://www.reddit.com/r/csharp/comments/5je0o3/why_exceptions_should_be_exceptional/) as linked from the bottom of the post.
[removed]
I will try that. But to put it as simply as I can, I am just asking how to implement a button click in asp.net core MVC. That's it. Button click
Instead of painting a dot on the move event you could paint a line from last event to this one.
You wouldn't need ASP.NET Core for that. Simple JavaScript can intercept a button click and make a server request.
You can use SSMS to export database structure as scripts and data, or use EF migrations and seeding, if you are using EF. Or (here I am a bit flaky) you can use Publish feature of Visual Studio.
That's the good idea, I will for sure write more on this and related topics :)
*Checks on eBay* …Aaaand it has no tenkey. Which makes it useless for me, as I frequently use extended UTF-8 characters via ALT codes. Good looking system, otherwise, just a real shame not including a tenkey when there seems to have been scads of extra room to do so.
&gt; Next up we try out the SIMD capabilities introduced with RyuJIT in the latest .NET Framework 4.6 Had no idea this was a thing. Sweet!
Thanks for sharing, I've been developing a dotnet core app for a few months now which will be deployed to ubuntu in production so will read through your work with interest, hopefully it'll save me some headaches! Haven't made the switch from project.json yet though, doesn't sound like much fun?
if you want decouple your data access code from specific DB, you need an abstract layer. You can follow the repository pattern to implement your own, or use an ORM framework like EntityFramework.
The above linked page was intended to be a jumping off point. Decide what provider sounds best for your needs, and click the link of the namespace next to it. Read about all of the objects used to connect to a database, execute statements, read results, etc. Review the code samples that are there for each of the objects. You'll be able to piece it together rather quickly. Oh, and no snark received. 
All three of what you listed would use its own library provided by the dbrms. Most libraries are similar to odbc in that they have connection and command properties. You could query your tables and map the results to IDataReader. I typically like to make an abstract base class in the repository pattern. It would handle the data abstraction and mapping. Then pass it back to my domain layer. Once you get the data out of the database you could use Linq to Objects if you wanted to stay within linq. 
Blowing my own trumpet a little here but take a look at ImageSharp. Lot's of neat performance tricks in there and I've tried to make the code as readable as possible for such a complicated subject. https://github.com/JimBobSquarePants/ImageSharp
You can try [Dapper](https://github.com/StackExchange/dapper-dot-net). It abstracts away ADO.NET details, works with all ADO.NET providers and is maintained by Stack Exchange. 
Did you execute `dotnet restore` before? What's the content of your project.json file?
Oh I didn't pick that up from your original question. I'm not sure you'll need a whole book about it if you are going to use bare ADO.Net. [This page](https://msdn.microsoft.com/en-us/library/haa3afyz(v=vs.110\).aspx) from MSDN show a sample with pretty much everything you need. In bare ADO.NET, you open a connection, you make a command with your query, you execute it on your open connection, read the results and close everything down. It's very basic but it won't do anything about your entities. That's part of the plumbing you'll have to do or use some sort of mapping system. There's a reason there are all these ORM and mapping frameworks around. Bare ADO.Net does the job but it doesn't help with much. That said, good on you to learn ADO.Net to see what's under the hood of this "automagic" tools so you can use them better. I've been there before there where options but nowadays I wouldn't go making my own ORM/mapper. But it will make for an interesting learning experience.
yes, that is what i am after, thanks. i have done the basics, e.g. opened a connection, sent sql statements and run stored procs. but that is very basic stuff. that does not explain how you should design your classes to do things safely and efficiently. i want to see the design patterns with examples in c# in a book that was not written 10 years ago. it seems like people like black boxes these days (sigh)
i appreciate what you are saying, about dapper but i want to make my own data access objects, and of course NOT be tied to sqlprovider. ms sure has a long long long way to go if they want to be more open source-ish ... it seems like prior to c#6 they were so tied to entity and sql server that they forgot there is a whole world out there not using them i completely understand the utility of orm's, but doesn't it scare you at all that more and more people seem to need them just to connect to a simple one table database? (mine is not one table, i am just saying new grads don't seem to have ever not used entity if they are from the ms world) i know i know ... in my day it snowed in summer ... you kids get off my lawn
How long do I have to avoid Core though, running on linux is a must-have for me (please no mono) :(.
The buggy part is due to the still in progress support for MSBUILD XML format in .NET Core projects. Simply wait until that part is solid before using it.
The .NET Core tooling within Visual Studio 2017 is labeled as **alpha**. So yes, it's buggy - and it's to be expected. If you want to write .NET Core applications, continue to stick to 2015 for now. While the tooling is still preview too in 2015, it's much more stable than the 2017 tooling.
Thanks! That's what I'll be doing :).
Yes, I can't seem to get the new .csproj support working very well. I am sticking with my current project.json format until it's fully baked (and even that is a little troublesome with a few NuGet packages).
Yes I did run $dotnet restore and it worked fine. here is the output: Microsoft .NET Development Utility CoreClr-x64-1.0.0-rc1-16231 CACHE https://www.myget.org/F/dotnet-core/api/v3/index.json CACHE https://api.nuget.org/v3/index.json Restoring packages for /Users/kulin/workspace/dotnetcore/testapp/project.json Writing lock file /Users/kulin/workspace/dotnetcore/testapp/project.lock.json Restore complete, 667ms elapsed NuGet Config files used: /Users/kulin/workspace/dotnetcore/testapp/nuget.config Feeds used: https://dotnetmyget.blob.core.windows.net/artifacts/dotnet-core/nuget/v3/flatcontainer/ https://api.nuget.org/v3-flatcontainer/
I love it when I ask two questions, and only the first one is answered.
Dapper doesn't tie you to SQLProvider, that's the great part about it. It's a set of extension methods applied to any ADO.Net DbConnection instance, nor is it an ORM but a quick and easy way to say "go execute this chunk of SQL and map the resultset to this POCO". We use it with PostgreSQL a lot, especially since we take advantage of a lot of advanced DB features that don't map particularly well to an full sized ORM, Dapper is just a thin layer to execute and map queries without the ceremony involved with ADO.Net. var accounts = _myConnection.Query&lt;Account&gt;("SELECT * FROM accounts"); vs. var command = _myConnection.CreateCommand(); command.CommandText = "SELECT * FROM accounts"; command.CommandType = CommandType.Text; var reader = command.ExecuteReader(); var accounts = new List&lt;Account&gt;(); while (reader.Read()) { accounts.add(new Account(reader[0], reader[1], reader[2], reader[3]); }
&gt; VS2017 &gt; a few years ago Wut?
His username checks out
I had a lot of trouble using 1.1 in VS 2015 so I switched to VS 2017 and while buggy you can work around them. The .Net core experience just really isn't clean anywhere yet imo.
What's the benefit to running a server instead of using the file system? We're setting one up in the new year and a co-worker thinks the server would be a lot faster for our small but global team. It'd be nice to hear what experiences you guys have had.
.net core
Yours looks like 2 dicks in the air.
Im confused as to why the author is caching data through the session... yes if you configure dotnet to use redis as the session store I guess you could say that's still a way to write to redis, but wouldn't you usually have an IDistributedCache instance injected into your class and read/write cache through that? This article seems very wrong, but maybe I'm missing something.
That was a bumpy ride. Not your fault, just Angular 2.
If you want data to live longer than a user session then yes. Use IDistributedCache directly. I use the interface as a write through cache for reference data in my db. No point in hitting the db for data that rarely changes.
As Adam mentioned, both cases are valid. Session management with Redis is valuable especially across multi servers / multi process. And yes, you made a point. I will extend the article, to present also the IDistributedCache approach, for non session data. 
Yes indeed. There are some boiler plate setup stuff for working with IIS and ASP.NET Core. Thanks for reading it ;)
Thanks, give it a try.
i like reading the roslyn code https://github.com/dotnet/roslyn (although i don't like the design too much "well written" is very subjective) ravendb is neat too https://github.com/ravendb/ravendb. (Ayende's blog is a pretty great resource for dot net too.
You wouldn't hit the database either way. The session store you choose shouldn't change how you use sessions in your app. You wouldn't cache data into any other session store, so you shouldn't cache through the session just because you're using redis in this instance. You would normally read/write cache through an injected IDistributedCache object, which keeps it completely separate to your sessions, and allows you to either pin the data down to the current user or share it with all users through the key, you also have expiration times so if you only want data hanging around for 20 mins that's fine too. I think this article is confusing using redis as a session store, and using redis for caching - two different things with different concerns.
Yep, when you said "I use the interface" I read it as you still referring to working through the session and using that as an argument for not hitting the db, hence my response. Apologies.
I was doing this a few months the ago with dotnet core and this what I ended up with. https://github.com/mzrimsek/dotnet-core-postgresql-react-redux-boilerplate Hopefully that helps. If you have any questions feel free to ask
I would recommend my boilerplate. https://github.com/pauldotknopf/react-aspnet-boilerplate Above all else though, I would NOT recommend ReactJs.NET or JavaScriptServices.
Out of interest, why not? I used ReactJs.NET on a small project and it was fine.
I bet his wasn't small. 
X-Post referenced from [/r/programming](http://np.reddit.com/r/programming) by /u/Giometrix [A Very Markov Christmas](http://np.reddit.com/r/programming/comments/5jz95v/a_very_markov_christmas/) ***** ^^I ^^am ^^a ^^bot. ^^I ^^delete ^^my ^^negative ^^comments. ^^[Contact](https://www.reddit.com/message/compose/?to=OriginalPostSearcher) ^^| ^^[Code](https://github.com/papernotes/Reddit-OriginalPostSearcher) ^^| ^^[FAQ](https://github.com/papernotes/Reddit-OriginalPostSearcher#faq)
Are you attempting to use a single ef context across multiple threads? if that is the case then you are correct it is not thread safe. But that isn't really the way ef was designed to be used. Its supposed to be single context per transaction, or at least something of sorts. So for an insert you would see something like using (var ctx = new DataContext()) { ctx.SomeTable.Add(new SomeTable{...}); ctx.SaveChanges(); //or SaveChangesAsync } simple example but you get the idea. EDIT: https://entityframework.codeplex.com/wikipage?title=Task-based%20Asynchronous%20Pattern%20support%20in%20EF.#ThreadSafety
I think you just need to use a separate dbcontext per thread, and make sure you dispose of the dbcontext as soon as you can. Try searching for your problem on Stack Overflow and you'll find lots of information about it.
I will address your other comment, but just because "ReactJS.NET" ands with ".NET", and you are in .NET, doesn't mean you should use it. Do you plan on doing server-side rendering?
Excellent usage, this is how I learned how to do it. Forces you to use eager loading, keeps everything nice and tidy, and avoids the inevitable bugs and hard-to-diagnose quirks when using lazy loading.
Yeah it sounded like this was more of a simple app (maybe console) so I though DI was overkill to talk about. Should have talked about why the using is important though, good point...
If you care to try something else, Chain is thread-safe. Just create one DataSource and use it everywhere. https://docevaad.github.io/Chain/ Unless you are using explicit transactions, there's no need to use `using` at all. It handles all of the connection management for you.
I have recently done just this. However, it took me learning Nodejs, javascript, jquery and socket connections to make it all happen.Mostly because my app used comm ports, which has been tricky within any web application, until now. (with NodeJS..Sure, there were other ways without js but they were all complicated and stopped working if you just looked at them wrong...) Performance is really not bad, and Nodejs plays very nicely in the background of any windows machine I have tried so far, including WIN XP. This has been a revelation for me and being able to craft a web server how I want it, and not being tied to IIS anymore is brilliant and renewed my interest in web apps. Bottom line is, if you are familiar with C# and keen to learn some jscript and Nodejs, it can be done. Nodejs uses Googles "V8" scripting engine, which is very stable and fast.
Dude. Come one. Think about that question. It's profoundly important that you understand the question. 
The easiest way would be to rewrite it as a classic ASP.NET WebForms application. It was pretty much designed for this purpose. Now, WebForms is long dead, and you would eventually want to move to something more modern, but for the short term it would be the quickest route. A WebForm button works pretty much the same way as a WinForm button. 
Any popular programming language has the ability to communicate with serial ports, even from within a web application. I'm glad node worked for you, but it's definitely not the first language I'd think of for that use.
Except for the lifecycles of pages - eg variables don't exactly stick around like they do in webforms. (unless you stick every variable/property in viewstate...). Then any modal dialogs are gonna need a bit of rethought.
Ask "why" [5 times](https://en.wikipedia.org/wiki/5_Whys). Then ask "how",
I would love to hear experiences with remote apps! It's a neat idea when legacy apps are involved.
It is good in theory but depending on how the app works it can be difficult to get working properly. A company I used to work at tried this and had lots of problems because they relied on registry values and a specific install path that had to be on the c drive. This was several years ago, so I would assume things have improved.
Perhaps you could try some kind of connection pooling? I haven't ever done this in EF (and change tracking might make it a disaster), but I know it's a popular technique other places.
NPM === NuGet You can set up your project.json to create a nuget package using `dotnet pack`, and then upload it to Nuget.org. You can also use CI services like AppVeyor to automate the build and deployment process. An example of this is here: https://github.com/Nick-Lucas/LimeBean
Leave.
RUN!!
welcome to enterprise software development. management that is responsible for creating this kind of environment does not want to pay people to clean up code they've already paid for that ostensibly "works" even if it's terribly expensive to maintain and modify.
Webforms aren't too bad, you just have to really understand the life cycle. I am sort of in the same type of scenario as you. Where my boss doesn't believe in programming patterns, or even really understand OOP. I cringe when my boss goes in and takes care of a bug or adds features onto things that I have coded. He edits will edit the code (not to mention in a hacky way a lot of the time) so it is easier to fix in the now, rather than taking into consideration the entire project and taking the extra couple minutes to do it the way that we all benefit from. Then he will check the code back in with absolutely no comments for changeset. So when I a new bug comes up that lands on my plate, I literally have to go through each changeset and do a diff of the previous check-in of the file to see what was done. He prides himself on "not following the rule book." As if coding patterns/organization causes people to be held back.. I try to code at home so I reinforce good practices to myself so I dont start picking up bad habits. But now that my wife and I had another child, there has been no time to even do that. If I were you, I would find a new job. If we weren't trying to find and buy a house that's what I would be doing. 
Switch countries. Just kidding... maybe. Try learning the basics of C# first. C# is quite similar to Java in its syntax and operation, this will help you get used to the .Net framework. Once you're somewhat conformable with that redo the same projects using VB.Net - 99% of the difference between VB.Net and C# is just syntax. 
Pro tip: Learn C#
Why? So he/she can exclude themselves from most jobs in their country? Get a job and some experience and then worry about expanding your language set. When interviewing, focus on how Java is a great fundamental language that taught you all sorts of programming concepts that transfer to ANY language.
What country? I want to make sure I never move there.
i saw bob tabor's basic c# tutorials also got membership at his website devu he teaches c# along with asp.net web forms , where can i find intermediate to advance tutorials
Hate it or love it, VB.Net having an every-shrinking user-base is a big disadvantage. That's going to limit the code samples, documentation, books, videos. At least as far as I know Microsoft hasn't skimped on supporting the language. I much prefer C# but I wish I had XML literals sometimes. 
Sounds like a horrible place to work...no one is fully in charge, no code reviews, just a bunch of people doing what they like to make what they want. You mention that MVC is not an option, and I've been there before, but MVC and WebForms can co-exist in the same project. What happened was that, with the buy-in of my boss, as I was required to fix or add features to the legacy codebase, I simply added them to the MVC half of the project. As I worked on things, I simply cleaned up, documented, and/or moved bits and pieces to the MVC half of the project. Eventually I had about half of the codebase moved over and it was far easier to maintain. May be a possible option for you to explore if you can get buy-in and get the other developers on board.
Agreed. That is exactly why I would suggest getting familiar with the language that will allow OP to get a job easiest. HR people often don't understand that the languages are interchangeable, so it's best to not give them any excuse to skip over you.
Hey you're welcome. I'm really glad it was useful to you. :)
Sometimes HR/sales thinks all languages are interchangeable, and that's not true either. Source: sales signed a project that requires quite some C++ development, and we're all Java devs. That's going to be a fun adventure :/
We help teams with a lot of legacy app migration. Here is a brain dump of a few tool chain tweaks can make your life easier. 1. Setup a NuGet feed server or file share. This will serve as a home for all that duplicate code once it is refactored into nuget packages. Create a npm feed as well for front end assets. 2. Wrap a build automation pipeline for your monolithic code base. This can be very simple at first, it's important to just start with build. Later as you break off modules, they will get their own build pipeline. 3. Create an automated deploy pipeline that starts after successful build and deploys to the first environment. Add a simple http 200 test that checks for the home page after deploy. You will later extend this to other environments until ultimately you deploy to production. Always deploy the same build, never rebuild per environment, inject environment configuration through variables or parameterized config. 4. Start thinking about: - 1 branching structure - 1 build pipeline - 1 release pipeline Per unit of deployment. There are "app" releases and "library" releases. Libraries have a different lifecycle where "production" starts where they are consumed by apps early in the app lifecycle. 5. Add some course grain tests. This can simply be a testing project at first. Just start small and grow your suite over time. 6. As you refactor the app break off isolated code units or clear cross solution duplicates into nuget packages, wrap them in tests and give them their own lifecycle. Continue over time to break off small chunks and watch your coverage grow. Think about avoiding/wrapping static, accepting dependencies through constructor/method and using interfaces. Don't boil the ocean, start small and build incrementally. 7. Create a SQL server database project for your SQL code. Wrap access to that with a service that will ultimately be reused by the other apps in your domain instead of direct access per app Your main app will probably have some of that nastiness (like classic ASP) in it for a while until you can refactor it out. Like others have said, you can run mvc side by side with webforms and gradually introduce new functionality with MVC and modern JavaScript. Usually creating a MVC layout that looks similar to your masterpage is a good start. Use a front end package manager like NPM to manage front end dependencies similar to how you manage back end dependencies. 
If you are open to it, here are a few good reads to help you on your way. The legacy code book may pay dividends quicker given your situation. Clean Code: https://www.amazon.com/dp/0132350882/ref=cm_sw_r_cp_apa_ruhyybGGV0C34 Refactoring: Improving the Design of Existing Code https://www.amazon.com/dp/0201485672/ref=cm_sw_r_cp_apa_gwhyyb1VRNSKK Working Effectively with Legacy Code https://www.amazon.com/dp/0131177052/ref=cm_sw_r_cp_apa_0whyyb3Y604NJ Continuous Delivery: Reliable Software Releases through Build, Test, and Deployment Automation (Addison-Wesley Signature Series (Fowler)) https://www.amazon.com/dp/0321601912/ref=cm_sw_r_cp_apa_JxhyybA08ZQF8
There is a channel on YouTube called CodeGeek that has a nice tutorial video on VB. It is about 9 hours long and will teach you everything you need to start building apps. 
You could use a framework like wisej.
Look at Microsoft Academy videos. 
i took a little tour at amazon and find so little books for VB.NET so sad
The date is two months ago but it reads like it was written closer to ten years ago.
You really don't need 600 page books for any language to get a job. Practice is what gives you a job, not the books you've read. Just build stuff in VB.NET until you're confident and that's all you need.
Jeezus, how many shitty blogs do we need more? With those idiotic self-promoting spammers everywhere?
This is truly awful. The about area says why: "Csoft Technology is leading offshore outsourcing IT Company based in Indian with the experience of 7+ years..."
Are you sure the line endings one isn't from a plugin? I could have sworn I was able to disable it.
I know the error, but thought it was part of of a plugin. I must have been thinking of another annoyance. Regardless, doesn't this option suppress the warning? [VS Options Dialog]( http://imgur.com/a/ng7bW)
But you probably have inconsistent line endings. My guess is you use git and have different git settings than VS settings. Probably your VS is automaticly making your line endings CLRF (windows) while git transforms them to LF (Linux) everytime you push/pull (not sure about CR (mac)). You can change settings on visual studio side - some extensions deal with this, just type line endings into extensions search and pick one. If you dont like extensions I think advanced save has option for line endings. Or you can solve it on GIT side (set autoclrf in config to true, details [here](https://help.github.com/articles/dealing-with-line-endings/) or [here](http://stackoverflow.com/questions/10418975/how-to-change-line-ending-settings)). If you use some GUI like tortoise git for example you can do that from options. If you use other version controll it probably will be very similar problem, it will need just a little google-fu. Just a little warning, inconsistent line endings might evolve from little annoyance where you have to click 'not now' to gain few pixels of space in window to big problem once you start to use some code generators or automappers and similar tools. 
no. its out of the box updated vs 2015. I always get it
I never seen that one. Is it required to have a check in comment for git or vsts by default ? 
Source?
Install SSDTBI, enjoy error message where the body is just '.' and there's no cancel button. Yay.
To create a "traditional" desktop applications, WPF is certainly what I'd be looking at. You just hear about it a lot less because of all the focus on web development. WPF plus the MVVM pattern is both modern and relatively painless.
It's... complicated? After a long period of stagnation and rumors of complete abandonment, Microsoft reopened Connect issues and made some improvements and bug fixes (e.g. touch event performance and multi-DPI support). However, most Microsoft's desktop UI work is focused on UWP these days, which also uses XAML but with incompatible libraries and different namespaces than WPF. For non-UWP desktop apps, WPF is still the most modern system available.
It's pretty much dead, but there's also no alternatives, so it's your best choice. Microsoft no longer gives a shit about desktop development. EDIT: Also, have a look at ReactiveUI. It makes development with WPF a little bit easier.
The tooling for ASP.NET Core is utterly broken in VS2017 - The deeper you go in that rabbit hole, the more issues you will encounter. File an issue on Github and hope someone pays attention to it. If there is already an issue, subscribe to it. Then happily wait a few weeks to months for a fix.
You can do this with the fluent mappings. Something like this should work //mapping for A HasRequired(x =&gt; x.BProperty).HasMany().WithForeignKey(x =&gt; x.ForeignKeyProperty) Most people don't realize they can leave the HasMany blank when using the fluent mappings.
Think I solved this one on my own (well, *actually started using* [Pro ASP MVC 5](https://www.amazon.co.uk/Pro-ASP-Net-MVC-Experts-Voice/dp/1430265299) that I bought last week), but wouldn't mind if someone feels like chiming in just to make sure my thinking's right. The stock OOBE for MVC5, scaffolding controllers w/ EF bindings, is for when you want to get an MVP out ASAP, right? It'll work as is, but there's hella tight coupling between the MVC and EF, very opinionated, and for enterprise-level apps is generally regarded as a terrible idea. If you want a loose coupling, and just throw everything off to Ninject to resolve you do have to implement the Repository Pattern yourself from the ground up?
If you're using dependency injection (if not, you should really look into it) then the `DbContext` should be passed into the controller constructor. Normally I make my own interface for the context, with your `IDbSet` collections and any other methods you need (like `SaveChanges`). For your tests, now you have two choices. You can either build out a fully functional stub context that operates on lists or other collections in memory, or you can use a mocking library like Moq or NSubstitute to mock out method calls that retrieve data, assert that data is passed in, etc. 
Not to mention that Electron and Electron-Edge exist. 
Because it's a massive security hole? There could be anything in that .csproj file. It's an msbuild script which could do pretty much anything. (Yeah, I never review them either. I really should though. )
Most people don't give a shit about the desktop environment. 90% of the stuff they do is through a browser anyways.
I don't implement the repository pattern wrapping `DbContext` any more for CRUD apps. MVC `Controllers` get injected with `Services` that they need to execute functionality. All `Services` get injected a `Singleton` instance of `IDbContextFactory&lt;MyContext&gt;` and then inside methods there you can `using (var context = _contextFactory.Create())`. So when I'm unit testing controllers I mock out the service interfaces, and then when I'm unit testing the services I can mock out the context factory `Create` method to return a mock context with list backed data. Every time I've let a DI container manage the lifetime of the DbContext I've ended up regretting it. 
UWP also uses XAML markup, but it is not the same as WPF.
&gt; If you're using dependency injection (if not, you should really look into it) then the DbContext should be passed into the controller constructor. You've got a +1 and a -1 there. +1 for using dependency injection, -1 for data access code in the controller. At most it should have `ISomethingService/ISomethingManager/blahblah` injected into the controller.
Personally I'm not a fan of answering "How do I ____" with "restructure your whole application". OP is taking steps in the right direction, if he/she continues down this path pretty soon they'll discover the value in separating logic from controllers. One step at a time. 
Sounds like you have outgrown EF. The Right Way (tm) is to create a view in SQL that represents the join. Then use Dapper (with multi-mapping) or Chain (with Decompose) to map the results to a pair of objects. 
Considering that WinForms is basically VB6's UI model, that's not entirely a bad idea. Especially if it is just a port rather than a proper rewrite.
That's a good motivation for me. I need to learn webforms a little more, which I have been doing since, to be sufficient. I know that I am lacking the knowledge of webforms but I am aware that I am a good programmer and good learner anyway. I intend to do my work as I always do. And as you said, I will learn about my company culture by doing so. Thank you. 
What about that question makes you think he has outgrown EF? It sounds to me like he doesn't really understand EF in the first place, and doesn't understand how lazy-loading works.
Good thought, but when I look at the value of data in the debugger, it shows that it's null. However, when I try an HTML.action(), and don't pass in a page value, the model data is propagated appropriately. Tried it, and no change. 
Removing int? page as a parameter had no change on the value of data being passed in. It's still an empty List. It works in the sense that there was no error! But there's still no data propagation. 
This sounds like a clean design, but don't your service methods end up being very repository-esque e.g *GetUserById*, *GetAllOrders*? Or do you put all business logic into these services, so that every controller action then becomes a one line call to a service method?
Hey, found this http://webcache.googleusercontent.com/search?q=cache:NATgZZPYqd4J:www.smartcard-api.com/professional.shtml+&amp;cd=5&amp;hl=en&amp;ct=clnk&amp;gl=us
is WPF dead? or is maybe desktop development dying instead? (real question) 
My army experience was civilian and in Canada and close to a decade ago so I suppose that might be true in the US now.
Have you viewed the GET Request's contents in FireBug? Is it sending any information?
Desktop is definitely suffering, but there's still a strong business case to choose it over the clusterfuck that is web development.
Same here. It's like a couple dozen research projects all running concurrently and tripping over each other.
oh, of course. but dying as in falling into a sub-business market. instead of products for home consumer use. 
I had not come across that one. I'll take a look. edit: I think Piranha is a cms. I'm looking for a CRM (Customer Relationship Manager)
The click is definitely firing! I've done that, and I've narrowed it down to an issue with the model data being passed through. A SO user just suggested that I need to stringify the model before passing it through an AJAX call. 
Sugar!
Nope, not dead yet. Having to learn it for new job. 
I've worked with one that has some cool features: http://rockrms.com. GitHub: https://github.com/SparkDevNetwork/Rock Edit: demo at http://rock.rocksolidchurchdemo.com
Although it is worth noting that if you pass your object into anything that walks the property graph (like Newtonsoft.Json) you will find your entire graph getting expanded with infinite recursive lazy loads. That's usually bad. In those cases, all the navigational properties become real. Most suggest projecting into DTOs to avoid that, but I prefer just telling EF to disable lazy-load for the queries that are feeding into serializers. edit: graph, not tree.
I'm building a production site in .NET Core, have been for a few months. The only real issue is lack of third-party resources (like blog posts or SO questions) like you have for normal .NET. I've only had a couple problems besides figuring out some of the more nuanced things, like JWT authentication.
FWIW, I have heard some good things about Dapper. Hope I get a chance to work with it someday.
Yeah, no logic at all in the controllers. All I test there is routing, security, error handling, that I have made the right service calls, and what HTTP code I'm getting back for various results. If logic creeps in you find a way to beat it back out. I'd also note that my services tend to be very coarse grained following different silos in the domain, they aren't repository typed toward individual database tables or objects. For instance in a theoretical store app I wouldn't have a `ProductsService` and an `OrdersService`but rather a `SalesService` and a `WarehouseService`. If you look at the app and the org chart you should see striking similarities for all parts of the org chart that are relevant for the app. As a result the methods there are all actions that make sense to a domain expert i.e. `AdjustInventory`, `MakeSale`, `TakeDelivery`, there's no `GetUserById` or `GetAllOrders`. Trying to re-use methods like those becomes an unmaintainable mess and it's just as simple to `dbContext.Users.SingleOrDefault(u =&gt; u.Id == userId)` in place where you need it rather than wrap it with a method. Different consumers will almost always want to add a predicate or `.Include(t =&gt; t.HalfTheDatabase)` some other shape of data for their use case. So while `TakeDelivery` and `ReturnProduct` might have the exact same implementation *for now* they don't share code. Those are different business cases and maybe one day we don't put returned products back in stock or maybe we have to handle them differently in some other subtle way. But in any case we don't have to touch the code for `TakeDelivery` when that specific change to the business of returning products happens. 
Yeah, it's a pretty good example of how *not* to do a security notification; train the user into complacency with false positives. Why can't they just whitelist a normal run-of-the-mill project file and only bug you if there's something unusual like a build event or a potentially destructive task in there. And yes, giving you the option to review it would be great. 
There is a bunch of things I'd like to see done to WPF. It still has no tray icon support baked in. You can use Windows Forms for that, or use a third party thing like https://bitbucket.org/hardcodet/notifyicon-wpf/ however, I'd prefer first class support. The default appearance is still Windows XP'ish and doesn't look nice on the latest OS versions. I'm currently using https://github.com/MahApps/MahApps.Metro to get that modern look. There is also a lot of commercial third party stuff for this. I think that one too should come out of the box. Many people use the Reactive Extensions with WPF. I actually prefer plain WPF as it feels clearer and has everything I need. There are a few long known nasty issues with bindings, and some regarding the tree view. All of those can be worked around, but people still run into them the first time and wonder what is going on. I remember those were not mere bugs but architectural things that would require some refactoring to improve. My current prediction is they will keep supporting WPF with minimal effort. Eventually something new will fill this niche and replace it. What ever that may be. Later, Microsoft will buy this new thing for several billion dollars and declare it to be the new standard, even though they had something great with WPF...
This tools is handy for converting from transform files to parameterization. Its not automatic but better than nothing. http://www.dotnetcatch.com/2014/09/08/parameterizationpreview-visual-studio-extension/
Never knew about launchsettings.json to switch between Development/Staging/Production. I've been manually changing from Dev to Prod in the project properties every time. Thanks!
Type Something ( then start writing here, then close your paren). Only you know how many arguments your method should take. If you do Something and then open and close your paren, how would Visual Studio know you werent intending to do 0 arguments?
Not an accurate comparison which makes sense because it's from Microsoft -- I like how they list "microservices" as something AWS doesn't support. Hint: it does. AWS is also better supported by the community and that alone should be a reason to consider using it over Azure. 
As far as I am aware there is no way to configure Visual Studio, or Resharper, to do this automatically. You would be asking it to recognise that you have written a bracket and try to move the cursor to a the argument part of a method signature that may or may not be there, maybe you've just written a simple code block and then there wouldn't be any signature to edit. What I believe you are looking for are [snippets](https://msdn.microsoft.com/en-us/library/z4c5cc9b.aspx). You can create your own to do what you want, for example you could create one called 'meth' for methods. You could also edit the existing ones to behave the way you want, for example the 'ctor' or 'svm' ones.
that looks interesting. more than just a crm.
You're the only one that knows what parameters are needed. So if you don't know and you want to add them later, the best way I have worked around this is to avoid writing that function manually altogether and just start typing on the line where you want to call your function, say you wanted to create a function called: public void Something(string whatever){ Console.Write("hello")}; and you know where and when you want to call it, just start typing: Something("hello"); on the line when it needs to run then press Ctrl+. (control and period) you will see a preview of the function, hit enter and the function is created automatically at the very bottom of the Class. Intellisense will make its best guess as to what type it will be and also choose an arbritary variable like 'v' or something depending on the type even booleans. (Even then, you still need to know your parameters but at least you'll have a templated function to modify)
I'm also waiting for pipelines to support making docker images. It's good otherwise though.
https://marketplace.visualstudio.com/items?itemName=VisualStudioProductTeam.ProductivityPowerTools - Auto Brace Completion &gt;Supports the following constructs: (), {}, [], &lt;&gt;, “”, and ‘’. &gt;Allows you to press &lt;TAB&gt; to navigate past the next enclosing brace &gt;Allows you to automatically complete a statement in C# by inserting the closing semi-colon and moving you to the next line with SHIFT + ENTER
.NET Core projects had the **project.json** file. But luckily Microsoft changed their mind and they're transitioning back to **csproj** files. But this transition is in the middle of the process.
Yes, it's pretty annoying that it's not yet able to do this. I'm also not sure how they're going to fix that as making a Docker image inside a Docker image isn't supported by Docker.
Which parser? A link would be awesome.
That would work as long as the PDF contains actual text and isn't the image of a scanned document.
It's what I understood from Atlassian's explanation as to why it's not possible to create containers in pipelines yet. Not sure if it's really a Docker limitation or a pipelines one.
very true, in the situation I was using it in, it was a "printed" export from our HR system. it worked well enough that I was able to grab data from the export and turn it into a spreadsheet.
Thanks for all the info and links.
In Visual Studio, create a new Web project. Then, go through the file menu, and find the option that says, "Add existing files". Add the existing files to the project. Now you have a csproj file that lists all the files you scaffolded using the `dotnet` command.
I hope my work will help you out. I am still wondering why Microsoft decided to switch from project.json to csproj... seems political, and not technical.... but these things happen I guess.
How about trying these micro samples? github.com/dodyg/practical-aspnetcore
What's your reasoning behind Azure Functions? Don't get me wrong! I'm a huge advocate for Azure Functions, but I've written some OCR junk and it's not fun. The development environment for Azure Functions and OCR development will be stressful and needlessly frustrating. 
The go-to FOSS speech recognizer is [Sphinx](http://cmusphinx.sourceforge.net/wiki/download), but unfortunately, it doesn't have any .NET bindings that I can find easily. It's non-trivial (but not impossible) to build a wrapper around the API. I know .NET3.0 had a built-in speech recognition API. I have no idea if it's migrated to Mono or Core.
Can I ask why you don't recommend using JavaScriptServices? I'm currently in the process of turning the react-redux template into something I can use for all future projects. I really like the templates they created using JavaScriptServices. Just curious if there is some glaring issue I'm not aware of. 
My understanding is, to go from webforms to MVC means rewriting the front end. Netcore MVC has the Razer view engine which is a totally different beast. It's therefore a good time to move to .Net Core, since you have to do some rewriting anyway. Hard to get into details in a reddit post, but there is a lot of content out there on porting over if you search for it.
There are a lot of old bridges out there. There is a new bridge design. Should we destroy all old bridges because there is a better one to replace them? Maybe eventually, but if something is working perfectly fine, why replace it just because something new and shiny is out there?
Yep, it's still very popular in existing code bases and there are a number of organizations that still will not make the transition to c# or f#. A lot of government software that I have seen is still being designed using vb .Net and webforms. Or classic ASP...
Definitely. I'm a mechanically engineer who uses VB.NET to do some automation and data collection type stuff. The simple and verbose nature of this language is a huge asset to someone who isn't degree'd in software development. Counting brackets is just not what I like to do when I'm trying to push a solution to the floor asap.
Do you know C#? I just finished the book you mentioned. It's a framework specific book so it assumes you already know C#. Apart from that, I don't know how it could be more beginner friendly. What specifically are you struggling with?
Its not that big of a leap. Ibstarred with vb.net many years ago. Your fingers will thank you because the syntax in c# is more concise imo
I think its much easier to make wpf look nice. I find it slower to develop in wpf until you really get comfortable with xaml. Winforms is fast when you need a quick UI
A few reasons (though I'm willing to try something different based on your comment): General familiarity with Azure and other Microsoft products and a desire to use C#/.NET which Azure does well. What do you suggest as an alternate? edit: Another reason behind Azure Functions is because I want to create a simple endpoint available on the public web. Any serverless "stack", like AWS Lambda, could potentially fit the bill.
Most people nowadays use it because they have to due to legacy code and tie ins with regular VB. It pretty much works exactly like C# and its not hard to switch between each language so I dont see the problem.
lol I'm procrastinating my work in vb6 right now
Yeah but F# and C# are literally different types of programming methods (Functional programming vs Object Oriented). The difference between these two are way more than just syntax (unlike C# vs VB.NET)
Love the Simpsons ref!
I'm still supporting vb6 that was written in 1995...
Because it will collapse when the old bridge builders die and the new bridge builders don't want to learn the old method of doing things.
It's more that C# is turning into VB.Net. Many of the next language features that have come to C# were from VB.Net. 
Managing legacy code is part of software development for most people, not everyone can use the latest and greatest in every project. Its really not that different from C# or any other OOL, if you can write one you should be able to write another with relative ease.
Valid point - I'll rephrase that going from VB to C# is mostly changing this IF myvar = 1 THEN Cool Stuff END IF to this if(myVar == 0){ cool stuff in c# } I think how you approach problems and your overall architecture would be significantly different in an F# project. 
The most clunky one we have is a vb.not app that calls a vb6 app...that's business critical and full of bugs the client won't authorise us to fix because they have no money to pay for the man hours...sigh
Point made, taken and accepted, but I was just focusing on your word, *concise*. There isn’t that much of a difference between VB.NET and C# when you turn around and have a look at the same functionality in F#.
my comment would then be ...
I think the in feature is nice. I think it could lead to some interesting paradigm shifts in CAD software, making it easier to use for basic tasks. The whole sketching paradigm is a little over done, the pen, plus multi touch, plus the puck interface could make fluid interactions with CAD a reality.
Those libraries were added so they are loaded at runtime incase you wanted to reference them in a command.
A few things I've noticed: - GUIDs are not designed to be cryptographically secure keys - Silently turning off certificate validation is not great - No built-in rate limiting as far as I've seen - May be vulnerable to timing attacks depending on the cache implementation?
* GUIDs are only used for generating a temporary TOTP, not for signing the JWT. As long as the time it takes to brute-force a TOTP (you can control its length) is longer than it's lifetime (which you can also configure) I think it should be fine. Edit: fixed, now uses crypto PRNG * I will be adding a configuration layer over JOSE-JWT to further customize the JWTs &amp; add extra optional claims in the future Edit: fixed, no longer turns off certificates * As for rate-limiting, I still haven't looked into that; currently in the process of creating a future plan for this project and this is on the to-do list Edit: optional IP address rate limiting will be in the next release * I'm not sure what you mean by that, wouldn't it be just as vulnerable if a full-blown DB was used? As far as I can tell the only time that could be measured is the time for retrieving a token from a TOTP, not the time it takes to generate the token (since that's masked by the sending the email, generating the TOTP, and other things) Edit: More documentation on how to switch to Redis will be added by next release Thanks for the suggestions! Anyway, feel free to make issues/contributions if you feel that something could be better done! 
If you think that's retarded, look at the for loops in C. Or the needless line terminators and how they badly interact with braces and if statements. Remind me where C# gets its syntax...
Can't tell if your dumb or a troll 
the REPL declares a global property $ that allows you to store references to variables, etc For example, $.date= Date(); $.format=String.Format $.excel = new ActiveXObject("Excel.Application"); etc
[removed]
Good stuff, a point you should emphasis (imo) is blogging is a tool to increase your personal knowledge. I look at it more for solidifying and exercising knowledge - also I don't blog so I'm probably full of shit
As you mentioned, most people are a bit snobbish towards Microsoft. Do you have any recommendations for resources that breakdown the current landscape of .Net and explain how they work together and how to get using them? .Net core, asp.net, etc
It's less about it helping other people and more about it being a tool to cement knowledge about something you're learning. The best way to learn is to teach, but if you don't have any willing students you can just blog it in to the void.
I'm working on something like that right now actually!
AFAIK, there is no backwards compatibility. In my case, I am running in an exclusively 8.1/10 environment and I can utilize those libraries in a WPF application.
Exactly how many packages does someone have to be uploading to be bothered by expiring keys and a lack of API to renew keys? It's just a couple of mouse clicks.
rekt
While number of packages is certainly part of the issue, the main issue is how many places you utilize that API key. Many OSS projects and professional companies push their packages via continuous integration using and dedicated organization account. It's just a mouse click to generate a new key yes, but all places that utilize that key might be quite a few more clicks. If you're really organized you push stable when repo tagged/release created and pre-release each merge to master i.e. That way people can have merge right but don't need push right, you ensure correct process where unit &amp; integration tests pass before push and you know which commit generated the pushed nuget package. If a key would expire that would in best case scenario break the build and generate allot of manual work. If you had an API to generate new keys you could make sure you always have an correct key with good margin, without relying someone keeping track of when keys expire and manually logging in, generating new keys and then seeing to that everything/one that uses that key gets updated with the new key. Which is an error prone process vs.the automated alternative. The organization that triggered the post has 26 repositories and almost a hundred packages. But anything more that a couple packages would save time by being automated. And once automated the interval of key expiration is irrelevant, you could then have new keys every hour if you so wished, you wouldn't even know which key you have and even if someone got their hands on the key it would likely already be obsolete. And thereby also being great security win. 
Does your orm have a type? You dont specify which one your using, so might need to refactor there. Why not change it to a long instead? A long is a pretty big number, so that might be a better change to make. 
Change the model property to a long (aka Int64). It has the capacity to hold a bigint and you shouldn't have to do much refactoring. Edit: wow, how did I miss that one of the two existing comments said the same thing? Derp. Upvote airhogg.
Anytime! Glad I could help.
Rotativa, wkhtmltopdf, etc. all now work on AppServices as long as you're on a standard plan or up (e.g, not on shared infrastructure).
This is somewhat painful. EF is great at translating complex Linq, but it does require knowledge of how Linq will be translated. E.g. normally, includes can massively degrade performance (generally outputs unions), but refactoring the join to use actual joins can significantly improve the output. Also, MSSQL is a database designed for joins. That's the primary reason to store data in a relational database. 😋 
You are going to want to learn the language before the Framework. Find some tutorials for C#, the rest is going to be lots of practice. Start with a basic Hello World for .NET Core Console Application and then try to implement something like this. https://stackoverflow.com/questions/13155052/parallel-http-requests 
We already using EF inside repositories, and the article is not about optimizing sql joins, it is about NOT touching the database at the first place. if author data already in memory, why making sql join to get it again from db?
Any recommendations on a book/ course for c# Is this edX course a good one: https://www.edx.org/course/programming-c-microsoft-dev204x-2 or can I better follow a pluralsight course on c# and core development 
I'm glad you mentioned Dapper. I initially refuse to use EF to force me to cut down on joins. I cache "reference data" like names, addresses, etc in memory and Redis then essentially join them together with the "transactional data" which is the stuff that really does change. My cache invalidation happens when code updates the DB instead of events from the DB (hence my use of Redis) but I do the same thing otherwise. Doing this with a simple Unit of Work pattern on Dapper makes things so much easier at the data level. I can then unit test that the correct data is being used too. Glad your results line up with what I'm doing too :)
Apologize in advance if i missed something obvious but Is this available anywhere we can try it out? Didn't see any obvious links in the article and not finding anything via Google. 
Can you rephrase the issue you are having? I don't presume to have an answer as I am not an expert but I have been using TFS onsite a lot so I'm interested, but don't really understand what you are asking.
Hmm. Isn't the argument for turning what is typically an int into a string for the purposes of preventing overflows? In any case, sorry for the lack of info, I was trying to keep it general enough but maybe I should have been more specific about my case. Below is the more concrete example: So if I have a database table called User that has a column called FavoriteNumber that is of a type BIGINT. That BIGINT at some point ended up being such a big number (4-some billion) that when we tried to query for it in our ASP.NET application, errors were thrown. A solution someone considered was to turn that corresponding User model's FavoriteNumber attribute into a string so that our system wouldn't crash if the number ever got quite large. (they also proposed turning the FavoriteNumber column from a BIGINT to a VARCHAR in the database as well but first thing's first...). In any case, they've commissioned me to implement this but I was wary of doing this (for a few reasons) but mainly if it was as simple as changing that attribute type from a int to a string. Sorry, I never feel like I can adequately explain scenarios. It all comes down to: "what do I need to take into consideration if I need to change a Model attribute from a int to a string - even if the corresponding database table is of a type BigInt?"
According to the product page, the API is `PC/SC Ver. 2.0, FeliCa library`. After a quick search, I found the following C# libraries (both using P/Invoke because it has to integrate with native drivers. https://github.com/tijins/NfcLib https://github.com/wnoguchi/FelicaSample There's also an [SDK](http://www.sony.net/Products/felica/business/products/ICS-D004_002_003.html) but I'm not sure if it works with your product.
I was thinking of open sourcing it anyway. I'll be back at work in a couple days and post it. Ping me if I don't.
9,223,372,036,854,775,807 is a pretty big number. For dapper and code first EF i think you only need to change the model and any SPs
Wow so you implemented caching. How original.
Hey, thanks for the response again and I completely agree with you, don't get me wrong, and I'll bring this up to my manager the next time as well. But if my manager does come back and say "no, I want it as a string in the system", is it the same kind of change that's required? Also, what is "SPs"? Again, I do appreciate your response.
Another spam garbage shit article. He frequently posts this, check his history.
Thanks, I'll have a closer look when I get the chance.
I just talked about the idea &amp; the concepts around, will try to make some example and publish it in near future
Is .NET Core on linux production ready? I want to start a huge project and I'm not sure whether it is practical to use it or not.
I suck at English terribly but I think I can write a better article than this :)
Cake doesn't replace but actually utilize i.e. .NET Core tooling, it orchestrates your restore, build, test, packaging, and publishing process(and allot more, there's hundreds of addins on nuget for all kind of build tasks). Cake works with Full .NET, .NET Core &amp; Mono, difference from other build systems is that with Cake there's a C# DSL so you write your build scripts in C# much as you use F# with FAKE or JavaScript with something like Gulp/Grunt. This in away that's cross platform so you can checkout an repository and use same build script on Windows, MacOS and Linux.
That's why i use NPoco.
Honestly, I'm only looking at it from a developer perspective. Deployment and operations is something that I've been lucky enough to be able to ignore.
RemindMe! 2 weeks "Is it done yet?"
You should be able to throw Apache in front of it. It's actually on my to do list to explore how, maybe I'll start that tomorrow. I'm starting up a new cross platform project on .Net core and so far, aside from the frustrating lack of up to date how to guides, it's been relatively smooth sailing (except for getting nunit working. Finally got it today but it was two days of slamming my head on the keyboard fighting cryptic errors only to find out it was a stupid missing dependency.....*grumbles*)
That's the thing that I noticed when I upgraded from EF6 in my soon-to-be-released desktop app. It has SQLite migrations, which is great for me since I'm tired of writing SQL table creation statements, but... I've got an object model that has exactly 4 children, and those children have a few children of their own. I now have to override SaveChanges() to .Include all of them for a cascade delete to work properly. There's a visible delay in doing so, too; just short of a second for each record. Yikes.
I need to get off my ass and post a Core version of my SQLite ORM.
[removed]
Hopefully now we will see .net standard masstransit lib.
That's not normal, but seems like a VS bug more than anything. Could you try it in VSCode?
Seems like VS has generated something for you which is incorrect.. to my eyes any ways. http://stackoverflow.com/questions/1165761/decimal-vs-double-which-one-should-i-use-and-when Suggest you take a look here for more of an explanation. But have you tried : public decimal Price {get; set;} You might find that more forgiving. Edit Woops i didn't see: 'But, I can edit the value from Visual Studio and give it a decimal number (both 9,99 and 9.99 works fine then). However, the value will regardless be shown as 9,99 in the View afterwards.' But changing it to a decimal will work. 
Also, the data is stored in the database as "9,00" even if I put 9 in the HTML form.
Not only that, no binaries at all.
Absolutely agree this is one of the benefits of blogging.
Not a problem glad I could help :) 
Sounds like progress...just let me know when it is actually released.
Is the server component oss? If not, who cares.
There is [LiteDB](http://www.litedb.org/), but I can't recommend since I never really use it. You can also find some [unofficial bindings](http://stackoverflow.com/q/9292648) to Google's [LevelDB](http://leveldb.org/).
Or any large, old enterprise. Or any enterprise that doesn't want to pump its data across the cloud.
SQLite - hands down. Async, code first, EF, LINQ are concepts / .NET features / libs that are independent of the DB engine you use. There's a ADO.NET provider for SQLite, so using it with EF or LINQ2SQL or a micro ORM like Dapper should be easy. 
LiteDB doesn't have async, but yes, could try. Seems there is no silver bullet yet.
.Net was created so that it does not really matter what language you actually write your code in. I wonder why people seem to think VB is antiquated and sub par. VB.net is not a limited language, believe me.
That could be said of both sides.
I switched to EF Core and that took care of my migration desires, but it has some [special issues](https://www.reddit.com/r/dotnet/comments/5lr0dl/getting_started_with_net_core_on_mac_or_linux/dbyy2st/), as I've discovered.
What do you think about the fact the NSQ is designed primarily to be a in memory system. Looks like its more likely to lose messages? NServiceBus + MSMQ + DTC is pretty rebust, which also why it can be pretty slow.
For NoSQL: Couchbase is supposed to have a "mobile" DB which is portable I think, but haven't tried it. Have used RavenDB for portable (and server) for years, but of course it is not free. It's really really good, but the price tag is such a turnoff nowadays. 
SQLite with Dapper. That's what I usually use in this case. 
What do you mean by async exactly? Not the .Net async? 
SQL Express LocalDB? We've recently migrated from SQL Server CE to LocalDB and it's been quite effortless.
Better than having to use C++ for performance related code.
I might be missing something, but how does this differ from appending ? (Nullable&lt;T&gt;) to the return type?
A reference to a variable and a reference type are different.
.Net async, yes. They currently don't support it. https://github.com/mbdavid/LiteDB/issues/124
It's not about what type a reference is, but the purpose of a reference. You can even use "ref" with a Nullable&lt;T&gt; or some other reference type. Once I'm at a computer I'm happy to share some code, until then google is your friend.
Nullable&lt;T&gt; is a struct, not a class. It's not a reference type. Ref is used to, for example, let a method change the value of a variable elsewhere. Doesn't matter if that variable is of a struct or class type, the value gets replaced when setting to it via the ref.
I wish they weren't.
Here you go: https://gist.github.com/eatfrog/1f13cec034e57fc6ef30c39005da080e The nullable behaves still as a value type. You are not dealing with the reference.
At least PowerShell is taking over as the default. Should have been changed back in Win7. 
You absolutely can. I think it's a fine idea and is probably what I should have done when I was playing with ReactJS. I wrote [this post](http://miniml.ist/dotnet/budgeting-app-with-aspnet-core-series-part-4/) on how to put a pure ReactJS front-end inside the .NET Core Web API project if you want to see an example of that. I could and maybe should have used a separate project for the front-end and had it all bundled up and pushed to wwwroot (The .NET Core Web API project also served the static front-end files, is that what you'd do?) If you visit the github project from that post you can also see some basic use of Axios to hit the web api endpoints. By the way, all your concerns sound perfectly fine to me.
This is just a proof of concept to explain what I'm trying to say. It's definitely not the best use of a ref return. This has been added, because there are use cases. You may never use this, and I probably wont either... but it's here to **help** with performance for those who require it. public static class FindStringExtensions { public static ref string FindStringRef(this string[] stringArray, string find) { for(int i = 0; i != stringArray.Length; i++) { if (stringArray[i] == find) { return ref stringArray[i]; } } throw new Exception("String Not Found"); } public static string FindString(this string[] stringArray, string find) { for (int i = 0; i != stringArray.Length; i++) { if (stringArray[i] == find) { return stringArray[i]; } } throw new Exception("String Not Found"); } } var StringArray = new string[] {"1", "2", "3"}; var modifyString = StringArray.FindString("2"); modifyString = "2000"; Console.WriteLine(StringArray[1]); //Outputs 2 var StringArrayWithRef = new string[] {"1", "2", "3"}; ref var modifyStringByRef = ref StringArrayWithRef.FindStringRef("2"); modifyStringByRef = "2000"; Console.WriteLine(StringArrayWithRef[1]); //Outputs 2000 
The more important new feature I see here is `ref var` (rather than `return ref`, which I still think is of highly limited utility)
As long as you buy Windows licenses and even games for it, I think they'll be happy,
Why? (serious question)
I believe Express LocalDB has some requirments for infrastructure like mssql server should be installed
Great post. Makes me want to play around with React more. That's actually a really, really great idea to just push it to the webapi's wwwroot so it can get served together. I love the idea and I'm going to try it out. Thanks so much for the feedback!
Keeping it around is not that expensive, but a lot of organizations will be in trouble idf it suddenly disappears. Don't use it for anything new though.
Alright, real talk: PowerShell and cmd.exe are both horrible. Speaking to PS: the only real upside it has is the ability to call functions in .net assemblies and some syntax highlighting. Downsides: the color theme makes my eyes hurt, the script syntax is just too weird (to the point where I have to constantly Google to figure out the correct syntax), and it doesn't even persist command history across sessions. The latter is a basic fucking feature that should have been implemented with the 1st or 2nd release of PowerShell. And here we are at v5, in 2017, with an improper implementation of the history feature that has been *properly implemented* since 1978 in Unix land. I recommend using Git Bash (i.e. MINGW) or Cygwin in place of anything else. http://cmder.net/ is also worth looking into -- it's good wrapper for any shell you might want to use.
Here's a first pass for sharing here: https://github.com/Narochno/Narochno.Dapper
Web app. C# and aspx.
I recommend leveraging SignalR. Integrates nicely with .Net web apps. Then client-side you could use AngularJS and it's "toastr" module. That might sound like way too much. I've done it this way and had great success.
We use signalr with [webapi notifications](https://developer.mozilla.org/en-US/docs/Web/API/Notifications_API) falling back to toastr if the user declines notifications.
SignalR works really good
Any particular reason you are using ASPX still?
I'd suggest using Razor templates with MVC, or alternatively you could go the whole hog and transition to using client side libraries to do the view and just do the back end with Web API. e.g. If you can do .NET Core, now might be a time to give it a go: https://docs.microsoft.com/en-us/aspnet/core/mvc/overview If you can't, MVC5 is very mature: https://www.asp.net/mvc/mvc5 And for client side frameworks, there are tutorials around for Angular, Angular2, React, Vue etc. There's nothing crazy wrong with using ASPX, it's just very outdated now.
Agreed, once OP knows C# he can just search the framework docs for specific pieces of things he needs and he'll know how to utilize and combine them into an app.
Cool I guess, but if the console window repaints your stuff will disappear. Ideally you'd want to override the window's WndProc so you could repaint when you get a WM_PAINT. I think there's a Windows API to override WndProc? Not sure. And of course I assume console windows repaint the same way normal ones do. And I wonder if this works if your process inherits its console window from the parent. Also your app won't work on .NET Core. :P
&gt; and it doesn't even persist command history across sessions It does w/ the 3rd-party PSReadline module, which is bundled w/ Windows 10, or installable on any system w/ PowerShell 3 or later
Focus on core, especially for a 6 month target when the new tooling hits GA and VS 2017 is released. Most new development will happen in Core.
Hi. I've tried the TC plugin but didn't seem to work for me. I'm currently contributing to a [hubot octopus deploy plugin](https://github.com/brentm5/hubot-octopus-deploy). It's not feature-rich atm ie can't deploy anything. But definitely will have the feature very soon. Would love to know what you think about it and a wishlist of yours for chatops octopus CD. 
You do know that it has been renamed many many months ago, right? It's not named MVC 6 anymore.
Interesting, but it seems like it's not actually bundled with Windows 10 (or at least configured to be turned on by default) considering that I have the latest version of Windows 10 and history is not persisted across sessions.
On the web server.
You probably need to set the corresponding thread pool to run as local system.
I really wish I could use C# on the web. I have a complex graphics application that's built using ActionScript, that needs updating to modern web standards. Writing 100,000 lines of dynamically typed JavaScript is a minefield I'd rather not cross. But modern web browsers leave no other choice.
Have you looked into typescript? It's pretty good. 
Check out Bridge.NET. I've writte a canvas based UI using it. Can't speak to the quality of the generated javascript though but haven't seen any performance issues yet.
Adding on to this, .Select() followed by .Aggregate() is one of the most powerful combinations you can do. They are the _map_ and _fold_ operations respectively.
 just curious - why did you opt for dotnet over javascript? now that javascript is also serverside with node. i realize what sub this is but just wondering what your process was as I am kind of at that stage
project.json is part of history, https://blogs.msdn.microsoft.com/dotnet/2016/11/16/announcing-net-core-tools-msbuild-alpha/.
Absolutely terrible solution. Placing a lock in any solution which concurrency matters will just kill your throughput at scale. TPL Dataflow would be far superior here. At the very least put the semaphore.Release() call in a finally block...
Thanks :) 
Accurate. LINQ is amazing and is easily the best part of writing code in C#. The one thing I don't like about LINQ is how it's used with Entity Framework - if you're new to .NET, it's very unclear at which point the query gets executed and your query gets turned into a C# object. What I would like to see is something like: `context.Cars.Where(x =&gt; x.Make == "Ferrari").ExecuteQuery().DoSomethingElseInMemory()` ...where you explicitly have to call `ExecuteQuery()` to get the resultset back from the database instead of just somehow knowing that a `ToList()` call will cause the query to execute.
Microsoft didn't like to share so they invented Net. 
.Net Core is open source, which uses .Net Standard. That's pretty good as far as 'sharing' their amazing cross platform .Net . https://blogs.msdn.microsoft.com/dotnet/2014/11/12/net-core-is-open-source/ I wrote a webservice using .Net core on my Mac using Visual Studio Code (also open source from Microsoft) and deployed it to a Linux server on Amazon Cloud. Microsoft are currently the biggest contributors to open source projects on Github. I would say they've definitely changed their strategy on 'sharing'
It's called deffered execution and works exactly the same for LINQ to Object, LINQ to Entities and other providers. It's foundation of LINQ and understanting when exactly your query does execute helps with pretty much everything related to LINQ. I think deffered execution should be explained a little bit more for begginers, however in many tutorials, courses it's being skipped.
I use it to decouple from System.Web. There is no logic in my controllers except for SendAsync and PublishAsync invocations.
This is very good as well https://www.youtube.com/watch?v=YI4MurjfMn8
I recently worked on an solution that has a web app and a web job that both communicate through a service bus. It was really easy to set up, you can replicate it elsewhere with azure resource manager and based on the platform you can scale it up/out pretty easily. As far as a local env, you can just run and debug the web job like a console app, since that's all that it really is. One thing I found is: You want to be careful about logging to the console since in the deployment env, they have a limit on console output. 
IIrc they wanted to integrate some COM parts in Java. Sun didn't like that.
Nicely put.
&gt; The answer is cross-platform compatibility. Microsoft is working on .NET Core to allow apps to work on Windows, Linux, and Mac, etc. etc. Not only that. .Net Core is, for all intents and purposes, the new generation of .net with a new runtime and everything. It just happens that it was made with other platforms in mind.
I see we're in the early 2000s again.
TIL: deferred execution happens for in-memory objects as well. Figured another loop would be executed for each successive call. 
Not sure I follow? I define an abstract handler class that does common logging stuff for each request (i.e. "request started" and "request ended") and then log additional details as needed in each subclass of the abstract handler.
Then you added the complexity back, that I feel the mediator pattern gives, that you can't follow the code "with your finger on a paper". Then why not use the mediator pattern?
I think we'll have to agree to disagree if you think pressing F12 to navigate to a base class and seeing the code immediately is equally as complicated as trying to hunt down usages of a command to identify which handler handles it, followed by trying to figure out which other handler in the long chain of handlers is responsible for common logging.
Hi Rob, Thanks for all the feedback. I really appreciate that you took the time to look through the code base and come with suggestions. I'll get back to you with a full answer soon, until then I'd just like to point out a few things: 1. The 'WithPrefetchCount' is not part the client's dataflow, it is RabbitMq's Consumer Prefetch (http://www.rabbitmq.com/consumer-prefetch.html). 2. To my knowledge, the only difference between await and ContinueWith. In some cases, like if task results are used to spin up new task, await makes the code much easier to read. Most of the time, however, I find it easier to follow along with ContinueWith. What I can't stand is mixing await and ContinueWith :) 3. I try to avoid creating tasks by Task.Run (or TaskFactory.StartNew for that matter). The only exception is the message consume, that exists in a sync context where I want to leverage concurrancy. 4. Since you are familiar with RabbitMq, perhaps you know that the IModel (the "channel") is not thread safe in the .NET client. Each channel allocates a port and costs a roundtrip to the broker to establish, so.. it is simply not feasible to create one per publish. This is the reason why the publish is in a locked block (by the way, a new major version of RawRabbit is under development. the most recent code is in the branch 2.0). The side effects on message throughput with lock is mitigated by having a pool of channels used which gives close to the same message rates as when publishing with the underlying client without locks. 5. Serialization is simplified in 2.0 https://github.com/pardahlman/RawRabbit/blob/2.0/src/RawRabbit/Serialization/JsonSerializer.cs However, I do not want to use the static methods of JsonConvert, as RawRabbit uses some non default settings https://github.com/pardahlman/RawRabbit/blob/2.0/src/RawRabbit/DependecyInjection/RawRabbitDependencyRegisterExtension.cs#L49-L63 . It is very likely that the host application uses Json.Net and perhaps uses other serialization settings. Don't want to interfere with that (or that to interfere with the clients serialization). 5. Thanks for the tip on string.Concat - I really thought that the string interpolation complied down to the same thing. Will keep an eye on it and dig into the topic myself :) 5. The default logger is a Console-logger that performs bad. It is really not supposed to be used anywhere else than in dev (or actually not there either, I use Serilog with Literate output). I have considered setting the VoidLogger (do nothing) as default. I try to keep dependencies to RawRabbit at a minimum. The idea is, that if you want to leverage the new things (Microsoft.Framework.*), you should add the RawRabbit.vNext nuget that holds adapters for logging: https://github.com/pardahlman/RawRabbit/tree/2.0/src/RawRabbit.vNext/Logging DI https://github.com/pardahlman/RawRabbit/tree/2.0/src/RawRabbit.vNext/DependecyInjection and Configuration https://github.com/pardahlman/RawRabbit/blob/master/sample/RawRabbit.AspNet.Sample/Startup.cs#L36 Ok, I really enjoy this conversation but I'm out of time as well. Cheers! -Pär
Instead of the tricky nature of keeping the buffer full, I want downstream target blocks to be able to 'pull' from a source without requiring a buffer.
I've got this working by using bounded capacities but I really feel like it would be better if ... depending on how many requesting 'consumers' there are, the output from the source would be increased. Of course this could be done other ways, but I'm trying to stay within the confines (and elegance) of DF.
Neither did Sun... Java itself wasn't open source until recently either...
Have you tried installing something to log your SQL calls? Something like Glimpse?
It is possible you need to specify that the user profile must be loaded, in the app pool settings.
No LocalDB is different than SQL Express and can be installed seperately.
&gt;await Task.Factory.StartNew(() =&gt; JsonConvert.DeserializeObject&lt;CaptchaResponse&gt;(responseString)); Why would you spin up a new thread to do this? It's to be avoided to use Task.Factory.StartNew and await it (Instead use Task.Run, read here : https://blogs.msdn.microsoft.com/pfxteam/2011/10/24/task-run-vs-task-factory-startnew/). But in general you shouldn't really spin up a new thread unless you really have to. 
JsonConvert has a `DeserializeObjectAsync` method, but it is marked obsolete. When I tried to use it, the Intellisense said to use the `Task.Factory.StartNew` syntax instead. I honestly didn't look into why they made this decision at the time. [Looking at it now](https://github.com/JamesNK/Newtonsoft.Json/issues/66) it seems that the `DeserializeObjectAsync` method was a wrapper for `Task.Factory.StartNew`. So yeah, you are probably right, I should just run it synchronously.
&gt; It's foundation of LINQ and understanting when exactly your query does execute helps with pretty much everything related to LINQ. The point is that this isn't exactly well-defined; each provider can do whatever it wants in that respect, and only when you call something that has to execute (ToList, aggregation etc.) are you guaranteed anything. Returning non-ToListed LINQ queries from methods and the like is something I avoid as much as possible.
Yeah, and I wish they were called that. I find it very annoying that they went with SQL-like names; especially since 99% use LINQ on object collections, not databases.
&gt; I can't see many, if any, uses outside of cutting down on cache thrashing in very specific scenarios. And? It's a feature for certain high performance code. Don't use it in general.
Considering the point was to expose SQL like functionality, and SQL dates back decades, I don't see the problem with using 'select'. And it's meaning is completely unambiguous as far as I know. Map, on the other hand, is synonymous with dictionary or hash table in many programming languages. And folding is a compiler design term. Meanwhile "to aggregate" means the same thing in programming and in common English, which is always an advantage.
I know this is a bit old but I wanted to add something. Writing! Try writing about what you are learning. It's been one of the best ways I've been able to skyrocket my .NET skills. I [wrote about it a little more here if you want to check that out](http://miniml.ist/dotnet/what-to-do-when-your-skills-feel-outdated/), but mainly I find that picking something that interests YOU and writing about it will get you where you want to be in the end.
This might be a dumb question, but hasn't GC changed dramatically in the last 14 years or are the "basics" still the same?
Take a look to [select2 jQuery plugin](https://select2.github.io/) - it can turn any select to combo box; it is possible to use it for adding new items.
This. I've remember Immo Landwerth saying that once .NET Core has caught up to .NET Framework, it'll surpass it and will have the newer features and APIs sooner than .NET Framework. This is due to the release path that they can have with Core over Framework. A new release of Framework has to coincide with an update to Windows - to ensure that the largest number of users get it as soon as it's available. Whereas it's up to developers and sys admits to explicitly install the latest version of Core (at the moment), which means that it's up to those devs and sys admins to decide which version fits their problem domain.
Sounds promising, I'll have to check it out next time I have to deal with XML.
New versions of .NET have better controls where you can indicate that you *don't* want GC to occur. There's better control over how you want to GC to run and better abilities to force a full GC compaction. It's fiddly stuff, but I'm sure it matters if you're pushing for minimal pauses.
The thing is, I don't want to reject. :| I want to consume as fast as possible. 
It is a wonder that dealing with XML in 2017 is still very much pain in the ass. None of the XML Schema class generator I found in .NET works properly.
That does seem odd. I've been [using the Angular 2 template](https://jonhilton.net/2016/12/01/fast-track-your-angular-2-and-net-core-web-app-development/) and the html/ts files inside of ClientApp/app/components are included in VS by default when I create a new project. As for the "magic" going on to compile all of these files and include them in wwwroot/dist I believe that is all done via webpack and is probably explained by studying *webpack.config.js*. VS crashing when you try to include those files definitely seems like a bug and not something I've encountered with the Angular 2 template. Have you tried re-installing the latest version of the template pack and creating a new project? Might be worth a go to see if you hit the same problem.